<?xml version='1.0' encoding='utf-8'?>
<collection id="W17">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages</booktitle>
      <url hash="16ddda01">W17-01</url>
      <editor><first>Antti</first><last>Arppe</last></editor>
      <editor><first>Jeff</first><last>Good</last></editor>
      <editor><first>Mans</first><last>Hulden</last></editor>
      <editor><first>Jordan</first><last>Lachler</last></editor>
      <editor><first>Alexis</first><last>Palmer</last></editor>
      <editor><first>Lane</first><last>Schwartz</last></editor>
      <doi>10.18653/v1/W17-01</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Honolulu</address>
      <month>March</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="02f15aa0">W17-0100</url>
      <bibkey>ws-2017-use</bibkey>
    </frontmatter>
    </volume>
  <volume id="2">
    <meta>
      <booktitle>Proceedings of the 21st Nordic Conference on Computational Linguistics</booktitle>
      <url hash="6a4b361a">W17-02</url>
      <editor><first>Jörg</first><last>Tiedemann</last></editor>
      <editor><first>Nina</first><last>Tahmasebi</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Gothenburg, Sweden</address>
      <month>May</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="5e02604d">W17-0200</url>
      <bibkey>ws-2017-nordic</bibkey>
    </frontmatter>
    </volume>
  <volume id="3">
    <meta>
      <booktitle>Proceedings of the joint workshop on <fixed-case>NLP</fixed-case> for Computer Assisted Language Learning and <fixed-case>NLP</fixed-case> for Language Acquisition</booktitle>
      <editor><first>Elena</first><last>Volodina</last></editor>
      <editor><first>Gintarė</first><last>Grigonytė</last></editor>
      <editor><first>Ildikó</first><last>Pilán</last></editor>
      <editor><first>Kristina Nilsson</first><last>Björkenstam</last></editor>
      <editor><first>Lars</first><last>Borin</last></editor>
      <publisher>LiU Electronic Press</publisher>
      <address>Gothenburg, Sweden</address>
      <month>May</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="b3b27922">W17-0300</url>
      <bibkey>ws-2017-joint</bibkey>
    </frontmatter>
    </volume>
  <volume id="4">
    <meta>
      <booktitle>Proceedings of the <fixed-case>N</fixed-case>o<fixed-case>D</fixed-case>a<fixed-case>L</fixed-case>i<fixed-case>D</fixed-case>a 2017 Workshop on Universal Dependencies (<fixed-case>UDW</fixed-case> 2017)</booktitle>
      <url hash="dd3bc789">W17-04</url>
      <editor><first>Marie-Catherine</first><last>de Marneffe</last></editor>
      <editor><first>Joakim</first><last>Nivre</last></editor>
      <editor><first>Sebastian</first><last>Schuster</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Gothenburg, Sweden</address>
      <month>May</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="24f6cab2">W17-0400</url>
      <bibkey>ws-2017-nodalida</bibkey>
    </frontmatter>
    </volume>
  <volume id="5">
    <meta>
      <booktitle>Proceedings of the <fixed-case>N</fixed-case>o<fixed-case>D</fixed-case>a<fixed-case>L</fixed-case>i<fixed-case>D</fixed-case>a 2017 Workshop on Processing Historical Language</booktitle>
      <url hash="61ae72fd">W17-05</url>
      <editor><first>Gerlof</first><last>Bouma</last></editor>
      <editor><first>Yvonne</first><last>Adesam</last></editor>
      <publisher>Linköping University Electronic Press</publisher>
      <address>Gothenburg</address>
      <month>May</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="11e5a86a">W17-0500</url>
      <bibkey>ws-2017-nodalida-2017</bibkey>
    </frontmatter>
    </volume>
  <volume id="6">
    <meta>
      <booktitle>Proceedings of the Third Workshop on Computational Linguistics for Uralic Languages</booktitle>
      <url hash="62424784">W17-06</url>
      <editor><first>Francis M.</first><last>Tyers</last></editor>
      <editor><first>Michael</first><last>Rießler</last></editor>
      <editor><first>Tommi A.</first><last>Pirinen</last></editor>
      <editor><first>Trond</first><last>Trosterud</last></editor>
      <doi>10.18653/v1/W17-06</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>St. Petersburg, Russia</address>
      <month>January</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="f59d4dec">W17-0600</url>
      <bibkey>ws-2017-linguistics</bibkey>
    </frontmatter>
    </volume>
  <volume id="7">
    <meta>
      <booktitle>Proceedings of the 7th Workshop on Cognitive Modeling and Computational Linguistics (<fixed-case>CMCL</fixed-case> 2017)</booktitle>
      <editor><first>Ted</first><last>Gibson</last></editor>
      <editor><first>Tal</first><last>Linzen</last></editor>
      <editor><first>Asad</first><last>Sayeed</last></editor>
      <editor><first>Martin</first><last>van Schijndel</last></editor>
      <editor><first>William</first><last>Schuler</last></editor>
      <doi>10.18653/v1/W17-07</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="c3e780d7">W17-0700</url>
      <bibkey>ws-2017-cognitive</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Entropy Reduction correlates with <a href="https://en.wikipedia.org/wiki/Temporal_lobe">temporal lobe activity</a></title>
      <author><first>Matthew</first><last>Nelson</last></author>
      <author><first>Stanislas</first><last>Dehaene</last></author>
      <author><first>Christophe</first><last>Pallier</last></author>
      <author><first>John</first><last>Hale</last></author>
      <pages>1–10</pages>
      <url hash="349074b5">W17-0701</url>
      <doi>10.18653/v1/W17-0701</doi>
      <abstract>Using the Entropy Reduction incremental complexity metric, we relate high gamma power signals from the brains of epileptic patients to incremental stages of syntactic analysis in <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/French_language">French</a>. We find that signals recorded intracranially from the anterior Inferior Temporal Sulcus (aITS) and the posterior Inferior Temporal Gyrus (pITG) correlate with word-by-word Entropy Reduction values derived from phrase structure grammars for those languages. In the anterior region, this correlation persists even in combination with surprisal co-predictors from PCFG and ngram models. The result confirms the idea that the brain’s temporal lobe houses a <a href="https://en.wikipedia.org/wiki/Parsing">parsing function</a>, one whose incremental processing difficulty profile reflects changes in <a href="https://en.wikipedia.org/wiki/Uncertainty_principle">grammatical uncertainty</a>.</abstract>
      <bibkey>nelson-etal-2017-entropy</bibkey>
    </paper>
    <paper id="3">
      <title>Grounding sound change in ideal observer models of perception</title>
      <author><first>Zachary</first><last>Burchill</last></author>
      <author><first>T. Florian</first><last>Jaeger</last></author>
      <pages>20–28</pages>
      <url hash="87b2c0a7">W17-0703</url>
      <doi>10.18653/v1/W17-0703</doi>
      <abstract>An important predictor of historical sound change, <a href="https://en.wikipedia.org/wiki/Functional_load">functional load</a>, fails to capture insights from <a href="https://en.wikipedia.org/wiki/Speech_perception">speech perception</a>. Building on ideal observer models of word recognition, we devise a new definition of <a href="https://en.wikipedia.org/wiki/Functional_load">functional load</a> that incorporates both a priori predictability and perceptual information. We explore this new <a href="https://en.wikipedia.org/wiki/Measure_(mathematics)">measure</a> with a simple <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> and find that <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> outperforms traditional <a href="https://en.wikipedia.org/wiki/Measure_(mathematics)">measures</a>.</abstract>
      <bibkey>burchill-jaeger-2017-grounding</bibkey>
    </paper>
    <paper id="4">
      <title>Oh, I’ve Heard That Before : Modelling Own-Dialect Bias After <a href="https://en.wikipedia.org/wiki/Perceptual_learning">Perceptual Learning</a> by Weighting Training Data<fixed-case>I</fixed-case>’ve Heard That Before”: Modelling Own-Dialect Bias After Perceptual Learning by Weighting Training Data</title>
      <author><first>Rachael</first><last>Tatman</last></author>
      <pages>29–34</pages>
      <url hash="32d9dc1e">W17-0704</url>
      <doi>10.18653/v1/W17-0704</doi>
      <abstract>Human listeners are able to quickly and robustly adapt to new accents and do so by using information about speaker’s identities. This paper will present experimental evidence that, even considering information about speaker’s identities, listeners retain a strong bias towards the acoustics of their own dialect after dialect learning. Participants’ behaviour was accurately mimicked by a <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> which was trained on more cases from the base dialect and fewer from the target dialect. This suggests that imbalanced training data may result in automatic speech recognition errors consistent with those of speakers from populations over-represented in the training data.</abstract>
      <bibkey>tatman-2017-oh</bibkey>
    </paper>
    <paper id="5">
      <title>Inherent Biases of <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">Recurrent Neural Networks</a> for Phonological Assimilation and Dissimilation</title>
      <author><first>Amanda</first><last>Doucette</last></author>
      <pages>35–40</pages>
      <url hash="fe6047e8">W17-0705</url>
      <doi>10.18653/v1/W17-0705</doi>
      <abstract>A <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network model</a> of phonological pattern learning is proposed. The model is a relatively simple <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> with one <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent layer</a>, and displays biases in learning that mimic observed biases in human learning. Single-feature patterns are learned faster than two-feature patterns, and vowel or consonant-only patterns are learned faster than <a href="https://en.wikipedia.org/wiki/Pattern">patterns</a> involving vowels and consonants, mimicking the results of laboratory learning experiments. In non-recurrent models, capturing these biases requires the use of alpha features or some other representation of repeated features, but with a <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network</a>, these elaborations are not necessary.</abstract>
      <bibkey>doucette-2017-inherent</bibkey>
    </paper>
    </volume>
  <volume id="8">
    <meta>
      <booktitle>Proceedings of the 11th Linguistic Annotation Workshop</booktitle>
      <url hash="1a78c0e8">W17-08</url>
      <editor><first>Nathan</first><last>Schneider</last></editor>
      <editor><first>Nianwen</first><last>Xue</last></editor>
      <doi>10.18653/v1/W17-08</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="1f1b53d0">W17-0800</url>
      <bibkey>ws-2017-linguistic</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Readers vs. Writers vs. Texts : Coping with Different Perspectives of Text Understanding in Emotion Annotation</title>
      <author><first>Sven</first><last>Buechel</last></author>
      <author><first>Udo</first><last>Hahn</last></author>
      <pages>1–12</pages>
      <url hash="d7bb1104">W17-0801</url>
      <doi>10.18653/v1/W17-0801</doi>
      <abstract>We here examine how different <a href="https://en.wikipedia.org/wiki/Point_of_view_(philosophy)">perspectives</a> of understanding <a href="https://en.wikipedia.org/wiki/Writing">written discourse</a>, like the reader’s, the writer’s or the text’s point of view, affect the quality of emotion annotations. We conducted a series of annotation experiments on two <a href="https://en.wikipedia.org/wiki/Text_corpus">corpora</a>, a popular movie review corpus and a genre- and domain-balanced corpus of standard English. We found statistical evidence that the writer’s perspective yields superior annotation quality overall. However, the quality one perspective yields compared to the other(s) seems to depend on the domain the utterance originates from. Our data further suggest that the popular movie review data set suffers from an atypical bimodal distribution which may decrease model performance when used as a training resource.</abstract>
      <bibkey>buechel-hahn-2017-readers</bibkey>
      <pwccode url="https://github.com/JULIELab/EmoBank" additional="false">JULIELab/EmoBank</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="2">
      <title>Finding Good Conversations Online : The Yahoo News Annotated Comments Corpus<fixed-case>Y</fixed-case>ahoo <fixed-case>N</fixed-case>ews Annotated Comments Corpus</title>
      <author><first>Courtney</first><last>Napoles</last></author>
      <author><first>Joel</first><last>Tetreault</last></author>
      <author><first>Aasish</first><last>Pappu</last></author>
      <author><first>Enrica</first><last>Rosato</last></author>
      <author><first>Brian</first><last>Provenzale</last></author>
      <pages>13–23</pages>
      <url hash="a54a3761">W17-0802</url>
      <doi>10.18653/v1/W17-0802</doi>
      <abstract>This work presents a dataset and annotation scheme for the new task of identifying good conversations that occur online, which we call ERICs : Engaging, Respectful, and/or Informative Conversations. We develop a <a href="https://en.wikipedia.org/wiki/Taxonomy_(general)">taxonomy</a> to reflect features of entire threads and individual comments which we believe contribute to identifying ERICs ; code a novel <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> of Yahoo News comment threads (2.4k threads and 10k comments) and 1k threads from the Internet Argument Corpus ; and analyze the features characteristic of ERICs. This is one of the largest annotated corpora of online human dialogues, with the most detailed set of annotations. It will be valuable for identifying ERICs and other aspects of <a href="https://en.wikipedia.org/wiki/Argumentation_theory">argumentation</a>, <a href="https://en.wikipedia.org/wiki/Dialogue">dialogue</a>, and <a href="https://en.wikipedia.org/wiki/Discourse">discourse</a>.</abstract>
      <bibkey>napoles-etal-2017-finding</bibkey>
      <pwccode url="https://github.com/cnap/ynacc" additional="false">cnap/ynacc</pwccode>
    </paper>
    <paper id="3">
      <title>Crowdsourcing discourse interpretations : On the influence of context and the reliability of a connective insertion task</title>
      <author><first>Merel</first><last>Scholman</last></author>
      <author><first>Vera</first><last>Demberg</last></author>
      <pages>24–33</pages>
      <url hash="2545d1a8">W17-0803</url>
      <doi>10.18653/v1/W17-0803</doi>
      <abstract>Traditional discourse annotation tasks are considered costly and time-consuming, and the <a href="https://en.wikipedia.org/wiki/Reliability_(statistics)">reliability</a> and <a href="https://en.wikipedia.org/wiki/Validity_(statistics)">validity</a> of these tasks is in question. In this paper, we investigate whether <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourcing</a> can be used to obtain reliable discourse relation annotations. We also examine the influence of <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context</a> on the <a href="https://en.wikipedia.org/wiki/Reliability_(statistics)">reliability</a> of the <a href="https://en.wikipedia.org/wiki/Data">data</a>. The results of a crowdsourced connective insertion task showed that the method can be used to obtain reliable annotations : The majority of the inserted connectives converged with the original label. Further, the <a href="https://en.wikipedia.org/wiki/Methodology">method</a> is sensitive to the fact that multiple senses can often be inferred for a single relation. Regarding the presence of <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context</a>, the results show no significant difference in distributions of insertions between conditions overall. However, a by-item comparison revealed several characteristics of segments that determine whether the presence of context makes a difference in annotations. The findings discussed in this paper can be taken as evidence that <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourcing</a> can be used as a valuable method to obtain insights into the sense(s) of relations.</abstract>
      <bibkey>scholman-demberg-2017-crowdsourcing</bibkey>
    </paper>
    <paper id="4">
      <title>A Code-Switching Corpus of Turkish-German Conversations<fixed-case>T</fixed-case>urkish-<fixed-case>G</fixed-case>erman Conversations</title>
      <author><first>Özlem</first><last>Çetinoğlu</last></author>
      <pages>34–40</pages>
      <url hash="f0963bd3">W17-0804</url>
      <doi>10.18653/v1/W17-0804</doi>
      <abstract>We present a code-switching corpus of <a href="https://en.wikipedia.org/wiki/Turks_in_Germany">Turkish-German</a> that is collected by recording conversations of bilinguals. The recordings are then transcribed in two layers following speech and orthography conventions, and annotated with <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentence boundaries</a> and intersentential, intrasentential, and intra-word switch points. The total amount of data is 5 hours of speech which corresponds to 3614 sentences. The <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> aims at serving as a resource for <a href="https://en.wikipedia.org/wiki/Speech_analysis">speech or text analysis</a>, as well as a collection for <a href="https://en.wikipedia.org/wiki/Linguistic_description">linguistic inquiries</a>.</abstract>
      <bibkey>cetinoglu-2017-code</bibkey>
    </paper>
    <paper id="5">
      <title>Annotating omission in statement pairs</title>
      <author><first>Héctor</first><last>Martínez Alonso</last></author>
      <author><first>Amaury</first><last>Delamaire</last></author>
      <author><first>Benoît</first><last>Sagot</last></author>
      <pages>41–45</pages>
      <url hash="e19a854b">W17-0805</url>
      <doi>10.18653/v1/W17-0805</doi>
      <abstract>We focus on the identification of omission in statement pairs. We compare three <a href="https://en.wikipedia.org/wiki/Crowdsourcing">annotation schemes</a>, namely two different <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourcing schemes</a> and <a href="https://en.wikipedia.org/wiki/Crowdsourcing">manual expert annotation</a>. We show that the simplest of the two crowdsourcing approaches yields a better annotation quality than the more complex one. We use a dedicated <a href="https://en.wikipedia.org/wiki/Classifier_(linguistics)">classifier</a> to assess whether the annotators’ behavior can be explained by straightforward <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">linguistic features</a>. The <a href="https://en.wikipedia.org/wiki/Classifier_(linguistics)">classifier</a> benefits from a <a href="https://en.wikipedia.org/wiki/Conceptual_model">modeling</a> that uses lexical information beyond length and overlap measures. However, for our task, we argue that expert and not crowdsourcing-based annotation is the best compromise between annotation cost and <a href="https://en.wikipedia.org/wiki/Quality_(business)">quality</a>.</abstract>
      <bibkey>martinez-alonso-etal-2017-annotating</bibkey>
      <pwccode url="https://github.com/hectormartinez/verdidata" additional="false">hectormartinez/verdidata</pwccode>
    </paper>
    <paper id="6">
      <title>Annotating <a href="https://en.wikipedia.org/wiki/Speech">Speech</a>, Attitude and Perception Reports</title>
      <author><first>Corien</first><last>Bary</last></author>
      <author><first>Leopold</first><last>Hess</last></author>
      <author><first>Kees</first><last>Thijs</last></author>
      <author><first>Peter</first><last>Berck</last></author>
      <author><first>Iris</first><last>Hendrickx</last></author>
      <pages>46–56</pages>
      <url hash="915b91e8">W17-0806</url>
      <doi>10.18653/v1/W17-0806</doi>
      <abstract>We present REPORTS, an annotation scheme for the annotation of speech, attitude and perception reports. Such a <a href="https://en.wikipedia.org/wiki/Scheme_(mathematics)">scheme</a> makes it possible to annotate the various <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">text elements</a> involved in such reports (e.g. embedding entity, <a href="https://en.wikipedia.org/wiki/Complement_(set_theory)">complement</a>, <a href="https://en.wikipedia.org/wiki/Complement_(set_theory)">complement head</a>) and their relations in a uniform way, which in turn facilitates the automatic extraction of information on, for example, <a href="https://en.wikipedia.org/wiki/Complement_(set_theory)">complementation</a> and vocabulary distribution. We also present the Ancient Greek corpus RAG (Thucydides’ History of the Peloponnesian War), to which we have applied this scheme using the annotation tool BRAT. We discuss some of the issues, both theoretical and practical, that we encountered, show how the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> helps in answering specific questions, and conclude that REPORTS fitted in well with our needs.</abstract>
      <bibkey>bary-etal-2017-annotating</bibkey>
    </paper>
    <paper id="8">
      <title>Representation and Interchange of Linguistic Annotation. An In-Depth, Side-by-Side Comparison of Three Designs</title>
      <author><first>Richard</first><last>Eckart de Castilho</last></author>
      <author><first>Nancy</first><last>Ide</last></author>
      <author><first>Emanuele</first><last>Lapponi</last></author>
      <author><first>Stephan</first><last>Oepen</last></author>
      <author><first>Keith</first><last>Suderman</last></author>
      <author><first>Erik</first><last>Velldal</last></author>
      <author><first>Marc</first><last>Verhagen</last></author>
      <pages>67–75</pages>
      <url hash="7c26d405">W17-0808</url>
      <doi>10.18653/v1/W17-0808</doi>
      <abstract>For decades, most self-respecting linguistic engineering initiatives have designed and implemented custom representations for various layers of, for example, morphological, syntactic, and semantic analysis. Despite occasional efforts at harmonization or even standardization, our field today is blessed with a multitude of ways of encoding and exchanging linguistic annotations of these types, both at the levels of ‘abstract syntax’, naming choices, and of course file formats. To a large degree, it is possible to work within and across design plurality by conversion, and often there may be good reasons for divergent design reflecting differences in use. However, it is likely that some abstract commonalities across choices of representation are obscured by more superficial differences, and conversely there is no obvious procedure to tease apart what actually constitute contentful vs. mere technical divergences. In this study, we seek to conceptually align three representations for common types of morpho-syntactic analysis, pinpoint what in our view constitute contentful differences, and reflect on the underlying principles and specific requirements that led to individual choices. We expect that a more in-depth understanding of these choices across designs may led to increased harmonization, or at least to more informed design of future representations.</abstract>
      <bibkey>eckart-de-castilho-etal-2017-representation</bibkey>
    </paper>
    <paper id="9">
      <title>TDB 1.1 : Extensions on Turkish Discourse Bank<fixed-case>TDB</fixed-case> 1.1: Extensions on <fixed-case>T</fixed-case>urkish Discourse Bank</title>
      <author><first>Deniz</first><last>Zeyrek</last></author>
      <author><first>Murathan</first><last>Kurfalı</last></author>
      <pages>76–81</pages>
      <url hash="7ff4ece2">W17-0809</url>
      <doi>10.18653/v1/W17-0809</doi>
      <abstract>This paper presents the recent developments on Turkish Discourse Bank (TDB). First, the resource is summarized and an evaluation is presented. Then, TDB 1.1, i.e. enrichments on 10 % of the corpus are described (namely, senses for explicit discourse connectives, and new annotations for three discourse relation types-implicit relations, entity relations and alternative lexicalizations). The method of <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a> is explained and the data are evaluated.</abstract>
      <bibkey>zeyrek-kurfali-2017-tdb</bibkey>
    </paper>
    <paper id="10">
      <title>Two Layers of Annotation for Representing Event Mentions in News Stories</title>
      <author><first>Maria Pia</first><last>di Buono</last></author>
      <author><first>Martin</first><last>Tutek</last></author>
      <author><first>Jan</first><last>Šnajder</last></author>
      <author><first>Goran</first><last>Glavaš</last></author>
      <author><first>Bojana</first><last>Dalbelo Bašić</last></author>
      <author><first>Nataša</first><last>Milić-Frayling</last></author>
      <pages>82–90</pages>
      <url hash="e0f4c074">W17-0810</url>
      <doi>10.18653/v1/W17-0810</doi>
      <abstract>In this paper, we describe our preliminary study on annotating event mention as a part of our research on high-precision news event extraction models. To this end, we propose a two-layer annotation scheme, designed to separately capture the functional and conceptual aspects of event mentions. We hypothesize that the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a> of <a href="https://en.wikipedia.org/wiki/Computer_simulation">models</a> can be improved by modeling and extracting separately the different aspects of news events, and then combining the extracted information by leveraging the complementarities of the <a href="https://en.wikipedia.org/wiki/Computer_simulation">models</a>. In addition, we carry out a preliminary <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a> using the proposed scheme and analyze the <a href="https://en.wikipedia.org/wiki/Annotation">annotation quality</a> in terms of <a href="https://en.wikipedia.org/wiki/Inter-annotator_agreement">inter-annotator agreement</a>.</abstract>
      <bibkey>di-buono-etal-2017-two</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/ecb">ECB+</pwcdataset>
    </paper>
    <paper id="11">
      <title>Word Similarity Datasets for <a href="https://en.wikipedia.org/wiki/Languages_of_India">Indian Languages</a> : Annotation and Baseline Systems<fixed-case>I</fixed-case>ndian Languages: Annotation and Baseline Systems</title>
      <author><first>Syed Sarfaraz</first><last>Akhtar</last></author>
      <author><first>Arihant</first><last>Gupta</last></author>
      <author><first>Avijit</first><last>Vajpayee</last></author>
      <author><first>Arjit</first><last>Srivastava</last></author>
      <author><first>Manish</first><last>Shrivastava</last></author>
      <pages>91–94</pages>
      <url hash="07f7a8a0">W17-0811</url>
      <doi>10.18653/v1/W17-0811</doi>
      <abstract>With the advent of <a href="https://en.wikipedia.org/wiki/Word_processor_(electronic_device)">word representations</a>, word similarity tasks are becoming increasing popular as an evaluation metric for the quality of the <a href="https://en.wikipedia.org/wiki/Word_processor_(electronic_device)">representations</a>. In this paper, we present manually annotated monolingual word similarity datasets of six Indian languages-Urdu, <a href="https://en.wikipedia.org/wiki/Telugu_language">Telugu</a>, <a href="https://en.wikipedia.org/wiki/Marathi_language">Marathi</a>, <a href="https://en.wikipedia.org/wiki/Punjabi_language">Punjabi</a>, <a href="https://en.wikipedia.org/wiki/Tamil_language">Tamil</a> and <a href="https://en.wikipedia.org/wiki/Gujarati_language">Gujarati</a>. These <a href="https://en.wikipedia.org/wiki/Language">languages</a> are most spoken Indian languages worldwide after <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a> and <a href="https://en.wikipedia.org/wiki/Bengali_language">Bengali</a>. For the construction of these <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a>, our approach relies on translation and re-annotation of word similarity datasets of English. We also present baseline scores for word representation models using state-of-the-art techniques for <a href="https://en.wikipedia.org/wiki/Urdu">Urdu</a>, <a href="https://en.wikipedia.org/wiki/Telugu_language">Telugu</a> and <a href="https://en.wikipedia.org/wiki/Marathi_language">Marathi</a> by evaluating them on newly created word similarity datasets.</abstract>
      <bibkey>akhtar-etal-2017-word</bibkey>
    </paper>
    <paper id="13">
      <title>Catching the Common Cause : Extraction and Annotation of Causal Relations and their Participants</title>
      <author><first>Ines</first><last>Rehbein</last></author>
      <author><first>Josef</first><last>Ruppenhofer</last></author>
      <pages>105–114</pages>
      <url hash="37869353">W17-0813</url>
      <doi>10.18653/v1/W17-0813</doi>
      <abstract>In this paper, we present a simple, yet effective method for the automatic identification and extraction of causal relations from <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">text</a>, based on a large English-German parallel corpus. The goal of this effort is to create a <a href="https://en.wikipedia.org/wiki/Lexical_resource">lexical resource</a> for German causal relations. The resource will consist of a lexicon that describes constructions that trigger causality as well as the participants of the causal event, and will be augmented by a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> with annotated instances for each entry, that can be used as training data to develop a system for automatic classification of causal relations. Focusing on verbs, our method harvested a set of 100 different lexical triggers of causality, including support verb constructions. At the moment, our <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> includes over 1,000 annotated instances. The <a href="https://en.wikipedia.org/wiki/Lexicon">lexicon</a> and the annotated data will be made available to the research community.</abstract>
      <bibkey>rehbein-ruppenhofer-2017-catching</bibkey>
    </paper>
    <paper id="14">
      <title>Assessing SRL Frameworks with Automatic Training Data Expansion<fixed-case>SRL</fixed-case> Frameworks with Automatic Training Data Expansion</title>
      <author><first>Silvana</first><last>Hartmann</last></author>
      <author><first>Éva</first><last>Mújdricza-Maydt</last></author>
      <author><first>Ilia</first><last>Kuznetsov</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <author><first>Anette</first><last>Frank</last></author>
      <pages>115–121</pages>
      <url hash="dcb48adb">W17-0814</url>
      <doi>10.18653/v1/W17-0814</doi>
      <abstract>We present the first experiment-based study that explicitly contrasts the three major semantic role labeling frameworks. As a prerequisite, we create a dataset labeled with parallel FrameNet-, PropBank-, and VerbNet-style labels for <a href="https://en.wikipedia.org/wiki/German_language">German</a>. We train a state-of-the-art SRL tool for <a href="https://en.wikipedia.org/wiki/German_language">German</a> for the different annotation styles and provide a comparative analysis across frameworks. We further explore the behavior of the <a href="https://en.wikipedia.org/wiki/Software_framework">frameworks</a> with automatic training data generation. VerbNet provides larger semantic expressivity than <a href="https://en.wikipedia.org/wiki/PropBank">PropBank</a>, and we find that its generalization capacity approaches <a href="https://en.wikipedia.org/wiki/PropBank">PropBank</a> in SRL training, but it benefits less from training data expansion than the sparse-data affected FrameNet.</abstract>
      <bibkey>hartmann-etal-2017-assessing</bibkey>
    </paper>
  </volume>
  <volume id="9">
    <meta>
      <booktitle>Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics</booktitle>
      <url hash="182a95b9">W17-09</url>
      <editor><first>Michael</first><last>Roth</last></editor>
      <editor><first>Nasrin</first><last>Mostafazadeh</last></editor>
      <editor><first>Nathanael</first><last>Chambers</last></editor>
      <editor><first>Annie</first><last>Louis</last></editor>
      <doi>10.18653/v1/W17-09</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="dd7bd8cb">W17-0900</url>
      <bibkey>ws-2017-linking</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Inducing Script Structure from Crowdsourced Event Descriptions via Semi-Supervised Clustering</title>
      <author><first>Lilian</first><last>Wanzare</last></author>
      <author><first>Alessandra</first><last>Zarcone</last></author>
      <author><first>Stefan</first><last>Thater</last></author>
      <author><first>Manfred</first><last>Pinkal</last></author>
      <pages>1–11</pages>
      <url hash="d86b457b">W17-0901</url>
      <doi>10.18653/v1/W17-0901</doi>
      <abstract>We present a semi-supervised clustering approach to induce script structure from crowdsourced descriptions of event sequences by grouping event descriptions into paraphrase sets (representing event types) and inducing their temporal order. Our approach exploits semantic and positional similarity and allows for flexible event order, thus overcoming the rigidity of previous approaches. We incorporate crowdsourced alignments as prior knowledge and show that exploiting a small number of <a href="https://en.wikipedia.org/wiki/Sequence_alignment">alignments</a> results in a substantial improvement in cluster quality over state-of-the-art models and provides an appropriate basis for the induction of temporal order. We also show a coverage study to demonstrate the scalability of our approach.</abstract>
      <bibkey>wanzare-etal-2017-inducing</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/omics">OMICS</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/rocstories">ROCStories</pwcdataset>
    </paper>
    <paper id="2">
      <title>A Consolidated Open Knowledge Representation for Multiple Texts</title>
      <author><first>Rachel</first><last>Wities</last></author>
      <author><first>Vered</first><last>Shwartz</last></author>
      <author><first>Gabriel</first><last>Stanovsky</last></author>
      <author><first>Meni</first><last>Adler</last></author>
      <author><first>Ori</first><last>Shapira</last></author>
      <author><first>Shyam</first><last>Upadhyay</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <author><first>Eugenio</first><last>Martinez Camara</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <author><first>Ido</first><last>Dagan</last></author>
      <pages>12–24</pages>
      <url hash="997418bc">W17-0902</url>
      <doi>10.18653/v1/W17-0902</doi>
      <abstract>We propose to move from Open Information Extraction (OIE) ahead to Open Knowledge Representation (OKR), aiming to represent information conveyed jointly in a set of texts in an open text-based manner. We do so by consolidating OIE extractions using entity and predicate coreference, while modeling information containment between coreferring elements via lexical entailment. We suggest that generating OKR structures can be a useful step in the NLP pipeline, to give semantic applications an easy handle on consolidated information across multiple texts.</abstract>
      <bibkey>wities-etal-2017-consolidated</bibkey>
      <pwccode url="https://github.com/vered1986/OKR" additional="false">vered1986/OKR</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/dbpedia">DBpedia</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ecb">ECB+</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/qa-srl">QA-SRL</pwcdataset>
    </paper>
    <paper id="3">
      <title>Event-Related Features in <a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">Feedforward Neural Networks</a> Contribute to Identifying Causal Relations in Discourse</title>
      <author><first>Edoardo Maria</first><last>Ponti</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <pages>25–30</pages>
      <url hash="2a183110">W17-0903</url>
      <doi>10.18653/v1/W17-0903</doi>
      <abstract>Causal relations play a key role in <a href="https://en.wikipedia.org/wiki/Information_extraction">information extraction</a> and <a href="https://en.wikipedia.org/wiki/Reason">reasoning</a>. Most of the times, their expression is ambiguous or implicit, i.e. without signals in the text. This makes their identification challenging. We aim to improve their identification by implementing a <a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">Feedforward Neural Network</a> with a novel set of <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> for this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. In particular, these are based on the position of event mentions and the semantics of events and participants. The resulting classifier outperforms strong baselines on two datasets (the Penn Discourse Treebank and the CSTNews corpus) annotated with different schemes and containing examples in two languages, <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a>. This result demonstrates the importance of <a href="https://en.wikipedia.org/wiki/Event_(philosophy)">events</a> for identifying <a href="https://en.wikipedia.org/wiki/Discourse_analysis">discourse relations</a>.</abstract>
      <bibkey>ponti-korhonen-2017-event</bibkey>
    </paper>
    <paper id="4">
      <title>Stance Detection in <a href="https://en.wikipedia.org/wiki/List_of_Facebook_features">Facebook Posts</a> of a German Right-wing Party<fixed-case>F</fixed-case>acebook Posts of a <fixed-case>G</fixed-case>erman Right-wing Party</title>
      <author><first>Manfred</first><last>Klenner</last></author>
      <author><first>Don</first><last>Tuggener</last></author>
      <author><first>Simon</first><last>Clematide</last></author>
      <pages>31–40</pages>
      <url hash="d66e7dde">W17-0904</url>
      <doi>10.18653/v1/W17-0904</doi>
      <abstract>We argue that in order to detect stance, not only the explicit attitudes of the stance holder towards the targets are crucial. It is the whole narrative the writer drafts that counts, including the way he hypostasizes the discourse referents : as benefactors or villains, as victims or beneficiaries. We exemplify the ability of our system to identify targets and detect the writer’s stance towards them on the basis of about 100 000 Facebook posts of a German right-wing party. A reader and writer model on top of our verb-based attitude extraction directly reveal stance conflicts.</abstract>
      <bibkey>klenner-etal-2017-stance</bibkey>
    </paper>
    <paper id="5">
      <title>Behind the Scenes of an Evolving Event Cloze Test</title>
      <author><first>Nathanael</first><last>Chambers</last></author>
      <pages>41–45</pages>
      <url hash="127ad69b">W17-0905</url>
      <doi>10.18653/v1/W17-0905</doi>
      <abstract>This paper analyzes the narrative event cloze test and its recent evolution. The <a href="https://en.wikipedia.org/wiki/Software_testing">test</a> removes one event from a document’s chain of events, and systems predict the missing event. Originally proposed to evaluate learned knowledge of <a href="https://en.wikipedia.org/wiki/Event_(computing)">event scenarios</a> (e.g., <a href="https://en.wikipedia.org/wiki/Scripting_language">scripts</a> and frames), most recent work now builds ngram-like language models (LM) to beat the test. This paper argues that the <a href="https://en.wikipedia.org/wiki/Test_(assessment)">test</a> has slowly / unknowingly been altered to accommodate LMs.5 Most notably, tests are auto-generated rather than by hand, and no effort is taken to include core script events. Recent work is not clear on evaluation goals and contains contradictory results. We implement several <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>, and show that the test’s bias to high-frequency events explains the inconsistencies. We conclude with recommendations on how to return to the test’s original intent, and offer brief suggestions on a path forward.</abstract>
      <bibkey>chambers-2017-behind</bibkey>
    </paper>
    <paper id="6">
      <title>LSDSem 2017 Shared Task : The Story Cloze Test<fixed-case>LSDS</fixed-case>em 2017 Shared Task: The Story Cloze Test</title>
      <author><first>Nasrin</first><last>Mostafazadeh</last></author>
      <author><first>Michael</first><last>Roth</last></author>
      <author><first>Annie</first><last>Louis</last></author>
      <author><first>Nathanael</first><last>Chambers</last></author>
      <author><first>James</first><last>Allen</last></author>
      <pages>46–51</pages>
      <url hash="452699ab">W17-0906</url>
      <doi>10.18653/v1/W17-0906</doi>
      <abstract>The LSDSem’17 shared task is the Story Cloze Test, a new evaluation for story understanding and script learning. This test provides a <a href="https://en.wikipedia.org/wiki/System">system</a> with a four-sentence story and two possible endings, and the system must choose the correct ending to the story. Successful narrative understanding (getting closer to human performance of 100 %) requires systems to link various levels of <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> to <a href="https://en.wikipedia.org/wiki/Commonsense_knowledge">commonsense knowledge</a>. A total of eight systems participated in the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">shared task</a>, with a variety of <a href="https://en.wikipedia.org/wiki/Software_development_process">approaches</a> including.</abstract>
      <bibkey>mostafazadeh-etal-2017-lsdsem</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/rocstories">ROCStories</pwcdataset>
    </paper>
    <paper id="9">
      <title>Sentiment Analysis and Lexical Cohesion for the Story Cloze Task</title>
      <author><first>Michael</first><last>Flor</last></author>
      <author><first>Swapna</first><last>Somasundaran</last></author>
      <pages>62–67</pages>
      <url hash="09180028">W17-0909</url>
      <doi>10.18653/v1/W17-0909</doi>
      <abstract>We present two NLP components for the Story Cloze Task   dictionary-based sentiment analysis and lexical cohesion. While previous research found no contribution from sentiment analysis to the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> on this task, we demonstrate that sentiment is an important aspect. We describe a new approach, using a <a href="https://en.wikipedia.org/wiki/Rule_of_inference">rule</a> that estimates sentiment congruence in a story. Our sentiment-based system achieves strong results on this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. Our lexical cohesion system achieves <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> comparable to previously published baseline results. A combination of the two <a href="https://en.wikipedia.org/wiki/System">systems</a> achieves better <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> than published baselines. We argue that <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> should be considered an integral part of narrative comprehension.</abstract>
      <bibkey>flor-somasundaran-2017-sentiment</bibkey>
    </paper>
    <paper id="10">
      <title>Resource-Lean Modeling of Coherence in Commonsense Stories</title>
      <author><first>Niko</first><last>Schenk</last></author>
      <author><first>Christian</first><last>Chiarcos</last></author>
      <pages>68–73</pages>
      <url hash="3fd386c5">W17-0910</url>
      <doi>10.18653/v1/W17-0910</doi>
      <abstract>We present a resource-lean neural recognizer for modeling coherence in commonsense stories. Our lightweight system is inspired by successful attempts to modeling discourse relations and stands out due to its simplicity and easy optimization compared to prior approaches to narrative script learning. We evaluate our <a href="https://en.wikipedia.org/wiki/Software_development_process">approach</a> in the Story Cloze Test demonstrating an absolute improvement in <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 4.7 % over state-of-the-art implementations.</abstract>
      <bibkey>schenk-chiarcos-2017-resource</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/rocstories">ROCStories</pwcdataset>
    </paper>
    <paper id="12">
      <title>IIT (BHU): System Description for LSDSem’17 Shared Task<fixed-case>IIT</fixed-case> (<fixed-case>BHU</fixed-case>): System Description for <fixed-case>LSDS</fixed-case>em’17 Shared Task</title>
      <author><first>Pranav</first><last>Goel</last></author>
      <author><first>Anil Kumar</first><last>Singh</last></author>
      <pages>81–86</pages>
      <url hash="99b1555f">W17-0912</url>
      <doi>10.18653/v1/W17-0912</doi>
      <abstract>This paper describes an ensemble system submitted as part of the LSDSem Shared Task 2017-the Story Cloze Test. The main conclusion from our results is that an approach based on <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a> alone may not be enough for this task. We test various approaches and compare them with two ensemble systems. One is based on <a href="https://en.wikipedia.org/wiki/Voting">voting</a> and the other on <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression based classifier</a>. Our final <a href="https://en.wikipedia.org/wiki/System">system</a> is able to outperform the previous <a href="https://en.wikipedia.org/wiki/State_(computer_science)">state</a> of the art for the Story Cloze test. Another very interesting observation is the performance of sentiment based approach which works almost as well on its own as our final ensemble system.</abstract>
      <bibkey>goel-singh-2017-iit</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/rocstories">ROCStories</pwcdataset>
    </paper>
    <paper id="13">
      <title>Story Cloze Ending Selection Baselines and Data Examination</title>
      <author><first>Todor</first><last>Mihaylov</last></author>
      <author><first>Anette</first><last>Frank</last></author>
      <pages>87–92</pages>
      <url hash="78c2020d">W17-0913</url>
      <doi>10.18653/v1/W17-0913</doi>
      <abstract>This paper describes two supervised baseline systems for the Story Cloze Test Shared Task (Mostafazadeh et al., 2016a). We first build a <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> using <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> based on <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> and <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity computation</a>. We further implement a neural LSTM system with different encoding strategies that try to model the relation between the story and the provided endings. Our experiments show that a model using representation features based on average word embedding vectors over the given story words and the candidate ending sentences words, joint with similarity features between the story and candidate ending representations performed better than the neural models. Our best <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> based on achieves an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 72.42, ranking 3rd in the official evaluation.</abstract>
      <bibkey>mihaylov-frank-2017-story</bibkey>
    </paper>
  </volume>
  <volume id="10">
    <meta>
      <booktitle>Proceedings of the <fixed-case>M</fixed-case>ulti<fixed-case>L</fixed-case>ing 2017 Workshop on Summarization and Summary Evaluation Across Source Types and Genres</booktitle>
      <url hash="3ab4057a">W17-10</url>
      <editor><first>George</first><last>Giannakopoulos</last></editor>
      <editor><first>Elena</first><last>Lloret</last></editor>
      <editor><first>John M.</first><last>Conroy</last></editor>
      <editor><first>Josef</first><last>Steinberger</last></editor>
      <editor><first>Marina</first><last>Litvak</last></editor>
      <editor><first>Peter</first><last>Rankel</last></editor>
      <editor><first>Benoit</first><last>Favre</last></editor>
      <doi>10.18653/v1/W17-10</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="a193f774">W17-1000</url>
      <bibkey>ws-2017-multiling</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Decoupling Encoder and Decoder Networks for Abstractive Document Summarization</title>
      <author><first>Ying</first><last>Xu</last></author>
      <author><first>Jey Han</first><last>Lau</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <pages>7–11</pages>
      <url hash="4d9fbb43">W17-1002</url>
      <doi>10.18653/v1/W17-1002</doi>
      <abstract>Abstractive document summarization seeks to automatically generate a summary for a document, based on some abstract understanding of the original document. State-of-the-art techniques traditionally use attentive encoderdecoder architectures. However, due to the large number of parameters in these <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a>, they require large training datasets and long training times. In this paper, we propose decoupling the encoder and decoder networks, and training them separately. We encode documents using an unsupervised document encoder, and then feed the document vector to a <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network decoder</a>. With this decoupled architecture, we decrease the number of parameters in the <a href="https://en.wikipedia.org/wiki/Codec">decoder</a> substantially, and shorten its <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training time</a>. Experiments show that the decoupled model achieves comparable performance with state-of-the-art models for in-domain documents, but less well for out-of-domain documents.</abstract>
      <bibkey>xu-etal-2017-decoupling</bibkey>
    </paper>
    <paper id="3">
      <title>Centroid-based Text Summarization through Compositionality of Word Embeddings</title>
      <author><first>Gaetano</first><last>Rossiello</last></author>
      <author><first>Pierpaolo</first><last>Basile</last></author>
      <author><first>Giovanni</first><last>Semeraro</last></author>
      <pages>12–21</pages>
      <url hash="e9738339">W17-1003</url>
      <doi>10.18653/v1/W17-1003</doi>
      <abstract>The textual similarity is a crucial aspect for many extractive text summarization methods. A bag-of-words representation does not allow to grasp the semantic relationships between concepts when comparing strongly related sentences with no words in common. To overcome this issue, in this paper we propose a centroid-based method for <a href="https://en.wikipedia.org/wiki/Automatic_summarization">text summarization</a> that exploits the compositional capabilities of <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>. The evaluations on multi-document and multilingual datasets prove the effectiveness of the continuous vector representation of words compared to the <a href="https://en.wikipedia.org/wiki/Bag-of-words_model">bag-of-words model</a>. Despite its simplicity, our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> achieves good performance even in comparison to more complex <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning models</a>. Our <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">method</a> is unsupervised and <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> can be adopted in other summarization tasks.</abstract>
      <bibkey>rossiello-etal-2017-centroid</bibkey>
      <pwccode url="https://github.com/gaetangate/text-summarizer" additional="true">gaetangate/text-summarizer</pwccode>
    </paper>
    <paper id="4">
      <title>Query-based summarization using MDL principle<fixed-case>MDL</fixed-case> principle</title>
      <author><first>Marina</first><last>Litvak</last></author>
      <author><first>Natalia</first><last>Vanetik</last></author>
      <pages>22–31</pages>
      <url hash="779b197c">W17-1004</url>
      <doi>10.18653/v1/W17-1004</doi>
      <abstract>Query-based text summarization is aimed at extracting essential information that answers the query from original text. The answer is presented in a minimal, often predefined, number of words. In this paper we introduce a new unsupervised approach for query-based extractive summarization, based on the minimum description length (MDL) principle that employs Krimp compression algorithm (Vreeken et al., 2011). The key idea of our approach is to select frequent word sets related to a given query that compress document sentences better and therefore describe the document better. A summary is extracted by selecting sentences that best cover query-related frequent word sets. The approach is evaluated based on the DUC 2005 and DUC 2006 datasets which are specifically designed for query-based summarization (DUC, 2005 2006). It competes with the best results.</abstract>
      <bibkey>litvak-vanetik-2017-query</bibkey>
    </paper>
    <paper id="5">
      <title>Word Embedding and Topic Modeling Enhanced Multiple Features for Content Linking and Argument / Sentiment Labeling in Online Forums</title>
      <author><first>Lei</first><last>Li</last></author>
      <author><first>Liyuan</first><last>Mao</last></author>
      <author><first>Moye</first><last>Chen</last></author>
      <pages>32–36</pages>
      <url hash="9656982e">W17-1005</url>
      <doi>10.18653/v1/W17-1005</doi>
      <abstract>Multiple grammatical and semantic features are adopted in content linking and argument / sentiment labeling for online forums in this paper. There are mainly two different <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> for content linking. First, we utilize the <a href="https://en.wikipedia.org/wiki/Deep_learning">deep feature</a> obtained from Word Embedding Model in <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> and compute sentence similarity. Second, we use multiple traditional features to locate candidate linking sentences, and then adopt a voting method to obtain the final result. LDA topic modeling is used to mine latent semantic feature and <a href="https://en.wikipedia.org/wiki/K-means_clustering">K-means clustering</a> is implemented for argument labeling, while features from sentiment dictionaries and rule-based sentiment analysis are integrated for sentiment labeling. Experimental results have shown that our <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> are valid.</abstract>
      <bibkey>li-etal-2017-word</bibkey>
    </paper>
    <paper id="6">
      <title>Ultra-Concise Multi-genre Summarisation of <a href="https://en.wikipedia.org/wiki/Web_2.0">Web2.0</a> : towards Intelligent Content Generation</title>
      <author><first>Elena</first><last>Lloret</last></author>
      <author><first>Ester</first><last>Boldrini</last></author>
      <author><first>Patricio</first><last>Martínez-Barco</last></author>
      <author><first>Manuel</first><last>Palomar</last></author>
      <pages>37–46</pages>
      <url hash="12b36eda">W17-1006</url>
      <doi>10.18653/v1/W17-1006</doi>
      <abstract>The electronic Word of Mouth has become the most powerful communication channel thanks to the wide usage of the <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a>. Our research proposes an approach towards the production of automatic ultra-concise summaries from multiple <a href="https://en.wikipedia.org/wiki/Web_2.0">Web 2.0 sources</a>. We exploit <a href="https://en.wikipedia.org/wiki/User-generated_content">user-generated content</a> from reviews and microblogs in different domains, and compile and analyse four types of ultra-concise summaries : a)positive information, b) negative information ; c) both or d) objective information. The appropriateness and usefulness of our <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> is demonstrated by its successful results and great potential in real-life applications, thus meaning a relevant advancement of the state-of-the-art approaches.</abstract>
      <bibkey>lloret-etal-2017-ultra</bibkey>
    </paper>
    <paper id="7">
      <title>Machine Learning Approach to Evaluate MultiLingual Summaries<fixed-case>M</fixed-case>ulti<fixed-case>L</fixed-case>ingual Summaries</title>
      <author><first>Samira</first><last>Ellouze</last></author>
      <author><first>Maher</first><last>Jaoua</last></author>
      <author><first>Lamia</first><last>Hadrich Belguith</last></author>
      <pages>47–54</pages>
      <url hash="809dc5ae">W17-1007</url>
      <doi>10.18653/v1/W17-1007</doi>
      <abstract>The present paper introduces a new MultiLing text summary evaluation method. This method relies on machine learning approach which operates by combining multiple <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> to build <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> that predict the human score (overall responsiveness) of a new summary. We have tried several single and ensemble learning classifiers to build the best <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>. We have experimented our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> in summary level evaluation where we evaluate each text summary separately. The correlation between built models and human score is better than the correlation between baselines and <a href="https://en.wikipedia.org/wiki/Score_(game)">manual score</a>.</abstract>
      <bibkey>ellouze-etal-2017-machine</bibkey>
    </paper>
  </volume>
  <volume id="11">
    <meta>
      <booktitle>Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media</booktitle>
      <url hash="9e1b82a9">W17-11</url>
      <editor><first>Lun-Wei</first><last>Ku</last></editor>
      <editor><first>Cheng-Te</first><last>Li</last></editor>
      <doi>10.18653/v1/W17-11</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="ca2d72c5">W17-1100</url>
      <bibkey>ws-2017-international</bibkey>
    </frontmatter>
    <paper id="1">
      <title>A Survey on Hate Speech Detection using <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a></title>
      <author><first>Anna</first><last>Schmidt</last></author>
      <author><first>Michael</first><last>Wiegand</last></author>
      <pages>1–10</pages>
      <url hash="5520a6a5">W17-1101</url>
      <doi>10.18653/v1/W17-1101</doi>
      <abstract>This paper presents a survey on hate speech detection. Given the steadily growing body of social media content, the amount of <a href="https://en.wikipedia.org/wiki/Online_hate_speech">online hate speech</a> is also increasing. Due to the massive scale of the <a href="https://en.wikipedia.org/wiki/World_Wide_Web">web</a>, methods that automatically detect <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a> are required. Our survey describes key areas that have been explored to automatically recognize these types of utterances using <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. We also discuss limits of those <a href="https://en.wikipedia.org/wiki/Theory_of_forms">approaches</a>.</abstract>
      <bibkey>schmidt-wiegand-2017-survey</bibkey>
    </paper>
    <paper id="2">
      <title>Facebook sentiment : Reactions and Emojis<fixed-case>F</fixed-case>acebook sentiment: Reactions and Emojis</title>
      <author><first>Ye</first><last>Tian</last></author>
      <author><first>Thiago</first><last>Galery</last></author>
      <author><first>Giulio</first><last>Dulcinati</last></author>
      <author><first>Emilia</first><last>Molimpakis</last></author>
      <author><first>Chao</first><last>Sun</last></author>
      <pages>11–16</pages>
      <url hash="7678883e">W17-1102</url>
      <doi>10.18653/v1/W17-1102</doi>
      <abstract>Emojis are used frequently in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. A widely assumed view is that <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a> express the emotional state of the user, which has led to research focusing on the expressiveness of <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a> independent from the <a href="https://en.wikipedia.org/wiki/Context_(language_use)">linguistic context</a>. We argue that <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a> and the <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">linguistic texts</a> can modify the meaning of each other. The overall communicated meaning is not a simple sum of the two channels. In order to study the meaning interplay, we need data indicating the overall sentiment of the entire message as well as the sentiment of the <a href="https://en.wikipedia.org/wiki/Emoji">emojis stand-alone</a>. We propose that Facebook Reactions are a good data source for such a purpose. FB reactions (e.g. Love and Angry) indicate the readers’ overall sentiment, against which we can investigate the types of <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a> used the comments under different reaction profiles. We present a <a href="https://en.wikipedia.org/wiki/Data_set">data set</a> of 21,000 FB posts (57 million reactions and 8 million comments) from public media pages across four countries.</abstract>
      <bibkey>tian-etal-2017-facebook</bibkey>
    </paper>
    <paper id="3">
      <title>Potential and Limitations of Cross-Domain Sentiment Classification</title>
      <author><first>Jan Milan</first><last>Deriu</last></author>
      <author><first>Martin</first><last>Weilenmann</last></author>
      <author><first>Dirk</first><last>Von Gruenigen</last></author>
      <author><first>Mark</first><last>Cieliebak</last></author>
      <pages>17–24</pages>
      <url hash="94b4693d">W17-1103</url>
      <doi>10.18653/v1/W17-1103</doi>
      <abstract>In this paper we investigate the cross-domain performance of a current state-of-the-art <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis systems</a>. For this purpose we train a convolutional neural network (CNN) on data from different domains and evaluate its performance on other domains. Furthermore, we evaluate the usefulness of combining a large amount of different smaller annotated corpora to a large corpus. Our results show that more sophisticated approaches are required to train a <a href="https://en.wikipedia.org/wiki/System">system</a> that works equally well on various domains.</abstract>
      <bibkey>deriu-etal-2017-potential</bibkey>
    </paper>
    <paper id="4">
      <title>Aligning Entity Names with Online Aliases on Twitter<fixed-case>T</fixed-case>witter</title>
      <author><first>Kevin</first><last>McKelvey</last></author>
      <author><first>Peter</first><last>Goutzounis</last></author>
      <author><first>Stephen</first><last>da Cruz</last></author>
      <author><first>Nathanael</first><last>Chambers</last></author>
      <pages>25–35</pages>
      <url hash="edc144db">W17-1104</url>
      <doi>10.18653/v1/W17-1104</doi>
      <abstract>This paper presents new <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> that automatically align <a href="https://en.wikipedia.org/wiki/Pseudonym">online aliases</a> with their real entity names. Many research applications rely on identifying entity names in text, but people often refer to entities with unexpected nicknames and <a href="https://en.wikipedia.org/wiki/Pseudonym">aliases</a>. For example, The King and King James are <a href="https://en.wikipedia.org/wiki/Pseudonym">aliases</a> for Lebron James, a professional basketball player. Recent work on <a href="https://en.wikipedia.org/wiki/Entity_linking">entity linking</a> attempts to resolve mentions to knowledge base entries, like a wikipedia page, but linking is unfortunately limited to well-known entities with pre-built pages. This paper asks a more basic question : can <a href="https://en.wikipedia.org/wiki/Pseudonym">aliases</a> be aligned without background knowledge of the entity? Further, can the <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> surrounding alias mentions be used to inform alignments? We describe <a href="https://en.wikipedia.org/wiki/Statistical_model">statistical models</a> that make decisions based on the lexicographic properties of the <a href="https://en.wikipedia.org/wiki/Pseudonym">aliases</a> with their semantic context in a large corpus of tweets. We experiment on a database of Twitter users and their <a href="https://en.wikipedia.org/wiki/User_(computing)">usernames</a>, and present the first human evaluation for this task. Alignment accuracy approaches human performance at 81 %, and we show that while lexicographic features are most important, the semantic context of an alias further improves classification accuracy.</abstract>
      <bibkey>mckelvey-etal-2017-aligning</bibkey>
    </paper>
    <paper id="5">
      <title>Character-based Neural Embeddings for Tweet Clustering</title>
      <author><first>Svitlana</first><last>Vakulenko</last></author>
      <author><first>Lyndon</first><last>Nixon</last></author>
      <author><first>Mihai</first><last>Lupu</last></author>
      <pages>36–44</pages>
      <url hash="f8dd03f6">W17-1105</url>
      <doi>10.18653/v1/W17-1105</doi>
      <abstract>In this paper we show how the performance of tweet clustering can be improved by leveraging character-based neural networks. The proposed approach overcomes the limitations related to the vocabulary explosion in the word-based models and allows for the seamless processing of the multilingual content. Our evaluation results and code are available on-line :.<url>https://github.com/vendi12/tweet2vec_clustering</url>.
    </abstract>
      <bibkey>vakulenko-etal-2017-character</bibkey>
      <pwccode url="https://github.com/vendi12/tweet2vec_clustering" additional="false">vendi12/tweet2vec_clustering</pwccode>
    </paper>
    <paper id="6">
      <title>A Twitter Corpus and Benchmark Resources for German Sentiment Analysis<fixed-case>T</fixed-case>witter Corpus and Benchmark Resources for <fixed-case>G</fixed-case>erman Sentiment Analysis</title>
      <author><first>Mark</first><last>Cieliebak</last></author>
      <author><first>Jan Milan</first><last>Deriu</last></author>
      <author><first>Dominic</first><last>Egger</last></author>
      <author><first>Fatih</first><last>Uzdilli</last></author>
      <pages>45–51</pages>
      <url hash="7971da70">W17-1106</url>
      <doi>10.18653/v1/W17-1106</doi>
      <abstract>In this paper we present SB10k, a new <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> with approx. 10,000 German tweets. We use this new corpus and two existing corpora to provide state-of-the-art benchmarks for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> in <a href="https://en.wikipedia.org/wiki/German_language">German</a> : we implemented a CNN (based on the winning system of SemEval-2016) and a feature-based SVM and compare their performance on all three corpora. For the <a href="https://en.wikipedia.org/wiki/CNN">CNN</a>, we also created German word embeddings trained on 300 M tweets. These <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> were then optimized for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> using distant-supervised learning. The new <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>, the German word embeddings (plain and optimized), and source code to re-run the <a href="https://en.wikipedia.org/wiki/Benchmark_(computing)">benchmarks</a> are publicly available.</abstract>
      <bibkey>cieliebak-etal-2017-twitter</bibkey>
    </paper>
  </volume>
  <volume id="12">
    <meta>
      <booktitle>Proceedings of the Fourth Workshop on <fixed-case>NLP</fixed-case> for Similar Languages, Varieties and Dialects (<fixed-case>V</fixed-case>ar<fixed-case>D</fixed-case>ial)</booktitle>
      <url hash="cb720080">W17-12</url>
      <editor><first>Preslav</first><last>Nakov</last></editor>
      <editor><first>Marcos</first><last>Zampieri</last></editor>
      <editor><first>Nikola</first><last>Ljubešić</last></editor>
      <editor><first>Jörg</first><last>Tiedemann</last></editor>
      <editor><first>Shevin</first><last>Malmasi</last></editor>
      <editor><first>Ahmed</first><last>Ali</last></editor>
      <doi>10.18653/v1/W17-12</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="7a635ed9">W17-1200</url>
      <bibkey>ws-2017-nlp</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Findings of the VarDial Evaluation Campaign 2017<fixed-case>V</fixed-case>ar<fixed-case>D</fixed-case>ial Evaluation Campaign 2017</title>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <author><first>Shervin</first><last>Malmasi</last></author>
      <author><first>Nikola</first><last>Ljubešić</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <author><first>Ahmed</first><last>Ali</last></author>
      <author><first>Jörg</first><last>Tiedemann</last></author>
      <author><first>Yves</first><last>Scherrer</last></author>
      <author><first>Noëmi</first><last>Aepli</last></author>
      <pages>1–15</pages>
      <url hash="7dcfe484">W17-1201</url>
      <doi>10.18653/v1/W17-1201</doi>
      <abstract>We present the results of the VarDial Evaluation Campaign on Natural Language Processing (NLP) for Similar Languages, Varieties and Dialects, which we organized as part of the fourth edition of the VarDial workshop at EACL’2017. This year, we included four shared tasks : Discriminating between Similar Languages (DSL), Arabic Dialect Identification (ADI), German Dialect Identification (GDI), and Cross-lingual Dependency Parsing (CLP). A total of 19 teams submitted runs across the four <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a>, and 15 of them wrote system description papers.</abstract>
      <bibkey>zampieri-etal-2017-findings</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="3">
      <title>Computational analysis of Gondi dialects<fixed-case>G</fixed-case>ondi dialects</title>
      <author><first>Taraka</first><last>Rama</last></author>
      <author><first>Çağrı</first><last>Çöltekin</last></author>
      <author><first>Pavel</first><last>Sofroniev</last></author>
      <pages>26–35</pages>
      <url hash="fb086fa4">W17-1203</url>
      <doi>10.18653/v1/W17-1203</doi>
      <abstract>This paper presents a <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational analysis</a> of <a href="https://en.wikipedia.org/wiki/Gondi_language">Gondi dialects</a> spoken in central India. We present a digitized data set of the dialect area, and analyze the <a href="https://en.wikipedia.org/wiki/Data">data</a> using different techniques from <a href="https://en.wikipedia.org/wiki/Dialectometry">dialectometry</a>, <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a>, and <a href="https://en.wikipedia.org/wiki/Computational_biology">computational biology</a>. We show that the <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> largely agree with each other and with the earlier non-computational analyses of the language group.</abstract>
      <bibkey>rama-etal-2017-computational</bibkey>
    </paper>
    <paper id="4">
      <title>Investigating Diatopic Variation in a Historical Corpus</title>
      <author><first>Stefanie</first><last>Dipper</last></author>
      <author><first>Sandra</first><last>Waldenberger</last></author>
      <pages>36–45</pages>
      <url hash="6624146b">W17-1204</url>
      <doi>10.18653/v1/W17-1204</doi>
      <abstract>This paper investigates diatopic variation in a historical corpus of German. Based on equivalent word forms from different language areas, replacement rules and <a href="https://en.wikipedia.org/wiki/Map_(mathematics)">mappings</a> are derived which describe the relations between these word forms. These rules and <a href="https://en.wikipedia.org/wiki/Map_(mathematics)">mappings</a> are then interpreted as reflections of morphological, phonological or graphemic variation. Based on sample rules and <a href="https://en.wikipedia.org/wiki/Map_(mathematics)">mappings</a>, we show that our approach can replicate results from <a href="https://en.wikipedia.org/wiki/Historical_linguistics">historical linguistics</a>. While previous studies were restricted to predefined word lists, or confined to single authors or texts, our approach uses a much wider range of data available in historical corpora.</abstract>
      <bibkey>dipper-waldenberger-2017-investigating</bibkey>
    </paper>
    <paper id="6">
      <title>The similarity and Mutual Intelligibility between Amharic and Tigrigna Varieties<fixed-case>A</fixed-case>mharic and <fixed-case>T</fixed-case>igrigna Varieties</title>
      <author><first>Tekabe Legesse</first><last>Feleke</last></author>
      <pages>47–54</pages>
      <url hash="37969a29">W17-1206</url>
      <doi>10.18653/v1/W17-1206</doi>
      <abstract>The present study has examined the similarity and the <a href="https://en.wikipedia.org/wiki/Mutual_intelligibility">mutual intelligibility</a> between <a href="https://en.wikipedia.org/wiki/Amharic">Amharic</a> and Tigrigna using three tools namely <a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein distance</a>, intelligibility test and questionnaires. The study has shown that both <a href="https://en.wikipedia.org/wiki/Tigrigna_language">Tigrigna varieties</a> have almost equal phonetic and lexical distances from Amharic. The study also indicated that <a href="https://en.wikipedia.org/wiki/Amharic">Amharic speakers</a> understand less than 50 % of the two varieties. Furthermore, the study showed that Amharic speakers are more positive about the Ethiopian Tigrigna variety than the Eritrean Variety. However, their attitude towards the two <a href="https://en.wikipedia.org/wiki/Variety_(linguistics)">varieties</a> does not have an impact on their intelligibility. The <a href="https://en.wikipedia.org/wiki/Amharic">Amharic speakers</a>’ familiarity to the <a href="https://en.wikipedia.org/wiki/Tigrinya_language">Tigrigna varieties</a> is largely dependent on the genealogical relation between <a href="https://en.wikipedia.org/wiki/Amharic">Amharic</a> and the two <a href="https://en.wikipedia.org/wiki/Tigrinya_language">Tigrigna varieties</a>.</abstract>
      <bibkey>feleke-2017-similarity</bibkey>
    </paper>
    <paper id="7">
      <title>Why Catalan-Spanish Neural Machine Translation? Analysis, comparison and combination with standard Rule and Phrase-based technologies<fixed-case>C</fixed-case>atalan-<fixed-case>S</fixed-case>panish Neural Machine Translation? Analysis, comparison and combination with standard Rule and Phrase-based technologies</title>
      <author><first>Marta R.</first><last>Costa-jussà</last></author>
      <pages>55–62</pages>
      <url hash="d67feecd">W17-1207</url>
      <doi>10.18653/v1/W17-1207</doi>
      <abstract>Catalan and <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a> are two related languages given that both derive from <a href="https://en.wikipedia.org/wiki/Latin">Latin</a>. They share similarities in several linguistic levels including <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphology</a>, <a href="https://en.wikipedia.org/wiki/Syntax">syntax</a> and <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a>. This makes them particularly interesting for the MT task. Given the recent appearance and popularity of neural MT, this paper analyzes the performance of this new approach compared to the well-established rule-based and phrase-based MT systems. Experiments are reported on a large database of 180 million words. Results, in terms of standard automatic measures, show that neural MT clearly outperforms the rule-based and phrase-based MT system on in-domain test set, but it is worst in the out-of-domain test set. A naive system combination specially works for the latter. In-domain manual analysis shows that neural MT tends to improve both adequacy and <a href="https://en.wikipedia.org/wiki/Fluency">fluency</a>, for example, by being able to generate more natural translations instead of literal ones, choosing to the adequate target word when the source word has several translations and improving gender agreement. However, out-of-domain manual analysis shows how neural MT is more affected by unknown words or contexts.</abstract>
      <bibkey>costa-jussa-2017-catalan</bibkey>
    </paper>
    <paper id="8">
      <title>Kurdish Interdialect Machine Translation<fixed-case>K</fixed-case>urdish Interdialect Machine Translation</title>
      <author><first>Hossein</first><last>Hassani</last></author>
      <pages>63–72</pages>
      <url hash="3e50c524">W17-1208</url>
      <doi>10.18653/v1/W17-1208</doi>
      <abstract>This research suggests a <a href="https://en.wikipedia.org/wiki/Methodology">method</a> for <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> among two <a href="https://en.wikipedia.org/wiki/Kurdish_languages">Kurdish dialects</a>. We chose the two widely spoken dialects, <a href="https://en.wikipedia.org/wiki/Kurmanji">Kurmanji</a> and <a href="https://en.wikipedia.org/wiki/Sorani">Sorani</a>, which are considered to be mutually unintelligible. Also, despite being spoken by about 30 million people in different countries, <a href="https://en.wikipedia.org/wiki/Kurdish_languages">Kurdish</a> is among less-resourced languages. The research used bi-dialectal dictionaries and showed that the lack of <a href="https://en.wikipedia.org/wiki/Parallel_text">parallel corpora</a> is not a major obstacle in <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> between the two dialects. The experiments showed that the machine translated texts are comprehensible to those who do not speak the dialect. The research is the first attempt for inter-dialect machine translation in <a href="https://en.wikipedia.org/wiki/Kurdish_languages">Kurdish</a> and particularly could help in making online texts in one dialect comprehensible to those who only speak the target dialect. The results showed that the translated texts are in 71 % and 79 % cases rated as understandable for <a href="https://en.wikipedia.org/wiki/Kurmanji">Kurmanji</a> and <a href="https://en.wikipedia.org/wiki/Sorani">Sorani</a> respectively. They are rated as slightly-understandable in 29 % cases for <a href="https://en.wikipedia.org/wiki/Kurmanji">Kurmanji</a> and 21 % for <a href="https://en.wikipedia.org/wiki/Sorani">Sorani</a>.</abstract>
      <bibkey>hassani-2017-kurdish</bibkey>
    </paper>
    <paper id="9">
      <title>Twitter Language Identification Of Similar Languages And Dialects Without Ground Truth<fixed-case>T</fixed-case>witter Language Identification Of Similar Languages And Dialects Without Ground Truth</title>
      <author><first>Jennifer</first><last>Williams</last></author>
      <author><first>Charlie</first><last>Dagli</last></author>
      <pages>73–83</pages>
      <url hash="1e4d4385">W17-1209</url>
      <doi>10.18653/v1/W17-1209</doi>
      <abstract>We present a new method to bootstrap filter Twitter language ID labels in our dataset for automatic language identification (LID). Our method combines geo-location, original Twitter LID labels, and <a href="https://en.wikipedia.org/wiki/Amazon_Mechanical_Turk">Amazon Mechanical Turk</a> to resolve missing and unreliable labels. We are the first to compare LID classification performance using the MIRA algorithm and langid.py. We show <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> performance on different versions of our <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> with high <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> using only Twitter data, without <a href="https://en.wikipedia.org/wiki/Ground_truth">ground truth</a>, and very few training examples. We also show how <a href="https://en.wikipedia.org/wiki/Platt_scaling">Platt Scaling</a> can be use to calibrate MIRA classifier output values into a <a href="https://en.wikipedia.org/wiki/Probability_distribution">probability distribution</a> over candidate classes, making the output more intuitive. Our method allows for fine-grained distinctions between similar languages and dialects and allows us to rediscover the language composition of our Twitter dataset.</abstract>
      <bibkey>williams-dagli-2017-twitter</bibkey>
    </paper>
    <paper id="10">
      <title>Multi-source morphosyntactic tagging for spoken Rusyn<fixed-case>R</fixed-case>usyn</title>
      <author><first>Yves</first><last>Scherrer</last></author>
      <author><first>Achim</first><last>Rabus</last></author>
      <pages>84–92</pages>
      <url hash="d6edf583">W17-1210</url>
      <doi>10.18653/v1/W17-1210</doi>
      <abstract>This paper deals with the development of <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphosyntactic taggers</a> for <a href="https://en.wikipedia.org/wiki/Variety_(linguistics)">spoken varieties</a> of the Slavic minority language Rusyn. As neither annotated corpora nor parallel corpora are electronically available for <a href="https://en.wikipedia.org/wiki/Rusyn_language">Rusyn</a>, we propose to combine existing resources from the etymologically close Slavic languages Russian, <a href="https://en.wikipedia.org/wiki/Ukrainian_language">Ukrainian</a>, <a href="https://en.wikipedia.org/wiki/Slovak_language">Slovak</a>, and <a href="https://en.wikipedia.org/wiki/Polish_language">Polish</a> and adapt them to <a href="https://en.wikipedia.org/wiki/Rusyn_language">Rusyn</a>. Using MarMoT as tagging toolkit, we show that a tagger trained on a balanced set of the four source languages outperforms single language taggers by about 9 %, and that additional automatically induced morphosyntactic lexicons lead to further improvements. The best observed accuracies for Rusyn are 82.4 % for <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech tagging</a> and 75.5 % for <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">full morphological tagging</a>.</abstract>
      <bibkey>scherrer-rabus-2017-multi</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/multext-east">MULTEXT-East</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="11">
      <title>Identifying dialects with textual and acoustic cues</title>
      <author><first>Abualsoud</first><last>Hanani</last></author>
      <author><first>Aziz</first><last>Qaroush</last></author>
      <author><first>Stephen</first><last>Taylor</last></author>
      <pages>93–101</pages>
      <url hash="7f60384c">W17-1211</url>
      <doi>10.18653/v1/W17-1211</doi>
      <abstract>We describe several systems for identifying short samples of Arabic or Swiss-German dialects, which were prepared for the shared task of the 2017 DSL Workshop (Zampieri et al., 2017). The Arabic data comprises both text and acoustic files, and our best run combined both. The Swiss-German data is text-only. Coincidently, our best runs achieved a <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of nearly 63 % on both the Swiss-German and Arabic dialects tasks.</abstract>
      <bibkey>hanani-etal-2017-identifying</bibkey>
    </paper>
    <paper id="12">
      <title>Evaluating HeLI with Non-Linear Mappings<fixed-case>H</fixed-case>e<fixed-case>LI</fixed-case> with Non-Linear Mappings</title>
      <author><first>Tommi</first><last>Jauhiainen</last></author>
      <author><first>Krister</first><last>Lindén</last></author>
      <author><first>Heidi</first><last>Jauhiainen</last></author>
      <pages>102–108</pages>
      <url hash="c41394f0">W17-1212</url>
      <doi>10.18653/v1/W17-1212</doi>
      <abstract>In this paper we describe the non-linear mappings we used with the Helsinki language identification method, HeLI, in the 4th edition of the Discriminating between Similar Languages (DSL) shared task, which was organized as part of the VarDial 2017 workshop. Our SUKI team participated on the closed track together with 10 other teams. Our <a href="https://en.wikipedia.org/wiki/System">system</a> reached the 7th position in the track. We describe the HeLI method and the non-linear mappings in <a href="https://en.wikipedia.org/wiki/Mathematical_notation">mathematical notation</a>. The HeLI method uses a <a href="https://en.wikipedia.org/wiki/Statistical_model">probabilistic model</a> with character n-grams and word-based backoff. We also describe our trials using the non-linear mappings instead of relative frequencies and we present statistics about the back-off function of the HeLI method.</abstract>
      <bibkey>jauhiainen-etal-2017-evaluating</bibkey>
    </paper>
    <paper id="13">
      <title>A Perplexity-Based Method for Similar Languages Discrimination</title>
      <author><first>Pablo</first><last>Gamallo</last></author>
      <author><first>Jose Ramom</first><last>Pichel</last></author>
      <author><first>Iñaki</first><last>Alegria</last></author>
      <pages>109–114</pages>
      <url hash="1bdd8bd4">W17-1213</url>
      <doi>10.18653/v1/W17-1213</doi>
      <abstract>This article describes the system submitted by the Citius_Ixa_Imaxin team to the VarDial 2017 (DSL and GDI tasks). The strategy underlying our <a href="https://en.wikipedia.org/wiki/System">system</a> is based on a <a href="https://en.wikipedia.org/wiki/Language_distance">language distance</a> computed by means of model perplexity. The best model configuration we have tested is a <a href="https://en.wikipedia.org/wiki/Electoral_system">voting system</a> making use of several n-grams models of both words and characters, even if word unigrams turned out to be a very competitive <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> with reasonable results in the tasks we have participated. An <a href="https://en.wikipedia.org/wiki/Error_analysis_(linguistics)">error analysis</a> has been performed in which we identified many test examples with no linguistic evidences to distinguish among the variants.<tex-math>n</tex-math>-grams models of both words and characters, even if word unigrams turned out to be a very competitive model with reasonable results in the tasks we have participated. An error analysis has been performed in which we identified many test examples with no linguistic evidences to distinguish among the variants. </abstract>
      <bibkey>gamallo-etal-2017-perplexity</bibkey>
    </paper>
    <paper id="14">
      <title>Improving the Character Ngram Model for the DSL Task with BM25 Weighting and Less Frequently Used Feature Sets<fixed-case>DSL</fixed-case> Task with <fixed-case>BM</fixed-case>25 Weighting and Less Frequently Used Feature Sets</title>
      <author><first>Yves</first><last>Bestgen</last></author>
      <pages>115–123</pages>
      <url hash="5a8040a1">W17-1214</url>
      <doi>10.18653/v1/W17-1214</doi>
      <abstract>This paper describes the system developed by the Centre for English Corpus Linguistics (CECL) to discriminating similar languages, <a href="https://en.wikipedia.org/wiki/Variety_(linguistics)">language varieties</a> and dialects. Based on a <a href="https://en.wikipedia.org/wiki/Symmetric_multiprocessing">SVM</a> with character and POStag n-grams as features and the BM25 weighting scheme, <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> achieved 92.7 % accuracy in the Discriminating between Similar Languages (DSL) task, ranking first among eleven systems but with a lead over the next three teams of only 0.2 %. A simpler version of the <a href="https://en.wikipedia.org/wiki/System">system</a> ranked second in the German Dialect Identification (GDI) task thanks to several ad hoc postprocessing steps. Complementary analyses carried out by a <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">cross-validation procedure</a> suggest that the BM25 weighting scheme could be competitive in this type of tasks, at least in comparison with the sublinear TF-IDF. POStag n-grams also improved the <a href="https://en.wikipedia.org/wiki/System">system</a> performance.</abstract>
      <bibkey>bestgen-2017-improving</bibkey>
    </paper>
    <paper id="15">
      <title>Discriminating between Similar Languages with Word-level Convolutional Neural Networks</title>
      <author><first>Marcelo</first><last>Criscuolo</last></author>
      <author><first>Sandra Maria</first><last>Aluísio</last></author>
      <pages>124–130</pages>
      <url hash="4b06a9ba">W17-1215</url>
      <doi>10.18653/v1/W17-1215</doi>
      <abstract>Discriminating between Similar Languages (DSL) is a challenging task addressed at the VarDial Workshop series. We report on our participation in the DSL shared task with a <a href="https://en.wikipedia.org/wiki/Multithreading_(computer_architecture)">two-stage system</a>. In the first stage, character n-grams are used to separate <a href="https://en.wikipedia.org/wiki/Variety_(linguistics)">language groups</a>, then specialized classifiers distinguish similar language varieties. We have conducted experiments with three system configurations and submitted one run for each. Our main approach is a word-level convolutional neural network (CNN) that learns task-specific vectors with minimal text preprocessing. We also experiment with multi-layer perceptron (MLP) networks and another hybrid configuration. Our best run achieved an accuracy of 90.76 %, ranking 8th among 11 participants and getting very close to the system that ranked first (less than 2 points). Even though the CNN model could not achieve the best results, it still makes a viable approach to discriminating between similar languages.</abstract>
      <bibkey>criscuolo-aluisio-2017-discriminating</bibkey>
    </paper>
    <paper id="16">
      <title>Cross-lingual dependency parsing for closely related languages-Helsinki’s submission to VarDial 2017<fixed-case>H</fixed-case>elsinki’s submission to <fixed-case>V</fixed-case>ar<fixed-case>D</fixed-case>ial 2017</title>
      <author><first>Jörg</first><last>Tiedemann</last></author>
      <pages>131–136</pages>
      <url hash="ea8fc5f3">W17-1216</url>
      <doi>10.18653/v1/W17-1216</doi>
      <abstract>This paper describes the submission from the University of Helsinki to the shared task on cross-lingual dependency parsing at VarDial 2017. We present work on annotation projection and treebank translation that gave good results for all three target languages in the test set. In particular, <a href="https://en.wikipedia.org/wiki/Slovak_language">Slovak</a> seems to work well with information coming from the Czech treebank, which is in line with related work. The attachment scores for cross-lingual models even surpass the <a href="https://en.wikipedia.org/wiki/Supervised_learning">fully supervised models</a> trained on the target language treebank. Croatian is the most difficult language in the test set and the improvements over the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a> are rather modest. Norwegian works best with information coming from <a href="https://en.wikipedia.org/wiki/Swedish_language">Swedish</a> whereas <a href="https://en.wikipedia.org/wiki/Danish_language">Danish</a> contributes surprisingly little.</abstract>
      <bibkey>tiedemann-2017-cross</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="17">
      <title>Discriminating between Similar Languages Using a Combination of Typed and Untyped Character N-grams and Words</title>
      <author><first>Helena</first><last>Gomez</last></author>
      <author><first>Ilia</first><last>Markov</last></author>
      <author><first>Jorge</first><last>Baptista</last></author>
      <author><first>Grigori</first><last>Sidorov</last></author>
      <author><first>David</first><last>Pinto</last></author>
      <pages>137–145</pages>
      <url hash="e2a90102">W17-1217</url>
      <doi>10.18653/v1/W17-1217</doi>
      <abstract>This paper presents the cic_ualg’s system that took part in the Discriminating between Similar Languages (DSL) shared task, held at the VarDial 2017 Workshop. This year’s task aims at identifying 14 languages across 6 language groups using a corpus of excerpts of journalistic texts. Two classification approaches were compared : a single-step (all languages) approach and a two-step (language group and then languages within the group) approach. Features exploited include lexical features (unigrams of words) and character n-grams. Besides traditional (untyped) character n-grams, we introduce typed character n-grams in the DSL task. Experiments were carried out with different feature representation methods (binary and raw term frequency), frequency threshold values, and machine-learning algorithms   Support Vector Machines (SVM) and Multinomial Naive Bayes (MNB). Our best run in the DSL task achieved 91.46 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>.</abstract>
      <bibkey>gomez-etal-2017-discriminating</bibkey>
    </paper>
    <paper id="18">
      <title>Tbingen system in VarDial 2017 shared task : experiments with <a href="https://en.wikipedia.org/wiki/Language_identification">language identification</a> and cross-lingual parsing<fixed-case>T</fixed-case>übingen system in <fixed-case>V</fixed-case>ar<fixed-case>D</fixed-case>ial 2017 shared task: experiments with language identification and cross-lingual parsing</title>
      <author><first>Çağrı</first><last>Çöltekin</last></author>
      <author><first>Taraka</first><last>Rama</last></author>
      <pages>146–155</pages>
      <url hash="a2511349">W17-1218</url>
      <doi>10.18653/v1/W17-1218</doi>
      <abstract>This paper describes our <a href="https://en.wikipedia.org/wiki/System">systems</a> and results on VarDial 2017 shared tasks. Besides three language / dialect discrimination tasks, we also participated in the cross-lingual dependency parsing (CLP) task using a simple methodology which we also briefly describe in this paper. For all the discrimination tasks, we used linear SVMs with character and word features. The <a href="https://en.wikipedia.org/wiki/System">system</a> achieves competitive results among other <a href="https://en.wikipedia.org/wiki/System">systems</a> in the shared <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. We also report additional experiments with neural network models. The performance of neural network models was close but always below the corresponding SVM classifiers in the discrimination tasks. For the cross-lingual parsing task, we experimented with an approach based on automatically translating the source treebank to the target language, and training a <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> on the translated treebank. We used off-the-shelf tools for both <a href="https://en.wikipedia.org/wiki/Translation">translation</a> and <a href="https://en.wikipedia.org/wiki/Parsing">parsing</a>. Despite achieving better-than-baseline results, our scores in CLP tasks were substantially lower than the scores of the other participants.</abstract>
      <bibkey>coltekin-rama-2017-tubingen</bibkey>
    </paper>
    <paper id="19">
      <title>When Sparse Traditional Models Outperform Dense Neural Networks : the Curious Case of Discriminating between Similar Languages</title>
      <author><first>Maria</first><last>Medvedeva</last></author>
      <author><first>Martin</first><last>Kroon</last></author>
      <author><first>Barbara</first><last>Plank</last></author>
      <pages>156–163</pages>
      <url hash="ed1a272a">W17-1219</url>
      <doi>10.18653/v1/W17-1219</doi>
      <abstract>We present the results of our participation in the VarDial 4 shared task on discriminating closely related languages. Our submission includes simple traditional models using linear support vector machines (SVMs) and a <a href="https://en.wikipedia.org/wiki/Neural_network">neural network (NN)</a>. The main idea was to leverage language group information. We did so with a two-layer approach in the traditional <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> and a multi-task objective in the <a href="https://en.wikipedia.org/wiki/Neural_network">neural network case</a>. Our results confirm earlier findings : simple traditional models outperform <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a> consistently for this task, at least given the amount of systems we could examine in the available time. Our two-layer linear SVM ranked 2nd in the <a href="https://en.wikipedia.org/wiki/Task_(computing)">shared task</a>.</abstract>
      <bibkey>medvedeva-etal-2017-sparse</bibkey>
    </paper>
    <paper id="20">
      <title>German Dialect Identification in Interview Transcriptions<fixed-case>G</fixed-case>erman Dialect Identification in Interview Transcriptions</title>
      <author><first>Shervin</first><last>Malmasi</last></author>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <pages>164–169</pages>
      <url hash="5fc76e2f">W17-1220</url>
      <doi>10.18653/v1/W17-1220</doi>
      <abstract>This paper presents three systems submitted to the German Dialect Identification (GDI) task at the VarDial Evaluation Campaign 2017. The task consists of training <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> to identify the dialect of Swiss-German speech transcripts. The dialects included in the GDI dataset are <a href="https://en.wikipedia.org/wiki/Canton_of_Basel-Stadt">Basel</a>, <a href="https://en.wikipedia.org/wiki/Canton_of_Bern">Bern</a>, Lucerne, and <a href="https://en.wikipedia.org/wiki/Canton_of_Zürich">Zurich</a>. The three systems we submitted are based on : a plurality ensemble, a mean probability ensemble, and a meta-classifier trained on character and word n-grams. The best results were obtained by the <a href="https://en.wikipedia.org/wiki/Meta-analysis">meta-classifier</a> achieving 68.1 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and 66.2 % <a href="https://en.wikipedia.org/wiki/F-number">F1-score</a>, ranking first among the 10 teams which participated in the GDI shared task.</abstract>
      <bibkey>malmasi-zampieri-2017-german</bibkey>
    </paper>
    <paper id="21">
      <title>CLUZH at VarDial GDI 2017 : Testing a Variety of Machine Learning Tools for the Classification of Swiss German Dialects<fixed-case>CLUZH</fixed-case> at <fixed-case>V</fixed-case>ar<fixed-case>D</fixed-case>ial <fixed-case>GDI</fixed-case> 2017: Testing a Variety of Machine Learning Tools for the Classification of <fixed-case>S</fixed-case>wiss <fixed-case>G</fixed-case>erman Dialects</title>
      <author><first>Simon</first><last>Clematide</last></author>
      <author><first>Peter</first><last>Makarov</last></author>
      <pages>170–177</pages>
      <url hash="41b5e8a9">W17-1221</url>
      <doi>10.18653/v1/W17-1221</doi>
      <abstract>Our submissions for the GDI 2017 Shared Task are the results from three different types of classifiers : Nave Bayes, Conditional Random Fields (CRF), and Support Vector Machine (SVM). Our CRF-based run achieves a weighted F1 score of 65 % (third rank) being beaten by the best system by 0.9 %. Measured by classification accuracy, our ensemble run (Nave Bayes, CRF, SVM) reaches 67 % (second rank) being 1 % lower than the best system. We also describe our experiments with Recurrent Neural Network (RNN) architectures. Since they performed worse than our non-neural approaches we did not include them in the submission.</abstract>
      <bibkey>clematide-makarov-2017-cluzh</bibkey>
    </paper>
    <paper id="22">
      <title>Arabic Dialect Identification Using iVectors and ASR Transcripts<fixed-case>A</fixed-case>rabic Dialect Identification Using i<fixed-case>V</fixed-case>ectors and <fixed-case>ASR</fixed-case> Transcripts</title>
      <author><first>Shervin</first><last>Malmasi</last></author>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <pages>178–183</pages>
      <url hash="17a7ba52">W17-1222</url>
      <doi>10.18653/v1/W17-1222</doi>
      <abstract>This paper presents the systems submitted by the MAZA team to the Arabic Dialect Identification (ADI) shared task at the VarDial Evaluation Campaign 2017. The goal of the task is to evaluate <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational models</a> to identify the <a href="https://en.wikipedia.org/wiki/Varieties_of_Arabic">dialect of Arabic utterances</a> using both <a href="https://en.wikipedia.org/wiki/Transcription_(linguistics)">audio and text transcriptions</a>. The ADI shared task dataset included Modern Standard Arabic (MSA) and four Arabic dialects : <a href="https://en.wikipedia.org/wiki/Egyptian_Arabic">Egyptian</a>, <a href="https://en.wikipedia.org/wiki/Gulf_Arabic">Gulf</a>, <a href="https://en.wikipedia.org/wiki/Levantine_Arabic">Levantine</a>, and <a href="https://en.wikipedia.org/wiki/North_African_Arabic">North-African</a>. The three systems submitted by MAZA are based on combinations of multiple machine learning classifiers arranged as (1) voting ensemble ; (2) mean probability ensemble ; (3) meta-classifier. The best results were obtained by the <a href="https://en.wikipedia.org/wiki/Meta-analysis">meta-classifier</a> achieving 71.7 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>, ranking second among the six teams which participated in the ADI shared task.</abstract>
      <bibkey>malmasi-zampieri-2017-arabic</bibkey>
    </paper>
    <paper id="24">
      <title>Exploring Lexical and Syntactic Features for Language Variety Identification</title>
      <author><first>Chris</first><last>van der Lee</last></author>
      <author><first>Antal</first><last>van den Bosch</last></author>
      <pages>190–199</pages>
      <url hash="62216166">W17-1224</url>
      <doi>10.18653/v1/W17-1224</doi>
      <abstract>We present a method to discriminate between texts written in either the Netherlandic or the Flemish variant of the <a href="https://en.wikipedia.org/wiki/Dutch_language">Dutch language</a>. The method draws on a feature bundle representing text statistics, <a href="https://en.wikipedia.org/wiki/Syntax">syntactic features</a>, and <a href="https://en.wikipedia.org/wiki/N-gram">word n-grams</a>. Text statistics include average word length and <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentence length</a>, while syntactic features include ratios of function words and part-of-speech n-grams. The effectiveness of the <a href="https://en.wikipedia.org/wiki/Classifier_(linguistics)">classifier</a> was measured by classifying <a href="https://en.wikipedia.org/wiki/Dutch_language">Dutch subtitles</a> developed for either <a href="https://en.wikipedia.org/wiki/Dutch_language">Dutch</a> or <a href="https://en.wikipedia.org/wiki/Vlaamse_Radio-_en_Televisieomroeporganisatie">Flemish television</a>. Several <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning algorithms</a> were compared as well as feature combination methods in order to find the optimal generalization performance. A machine-learning meta classifier based on <a href="https://en.wikipedia.org/wiki/AdaBoost">AdaBoost</a> attained the best <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> of 0.92.<tex-math>n</tex-math>-grams. Text statistics include average word length and sentence length, while syntactic features include ratios of function words and part-of-speech <tex-math>n</tex-math>-grams. The effectiveness of the classifier was measured by classifying Dutch subtitles developed for either Dutch or Flemish television. Several machine learning algorithms were compared as well as feature combination methods in order to find the optimal generalization performance. A machine-learning meta classifier based on AdaBoost attained the best F-score of 0.92. </abstract>
      <bibkey>van-der-lee-van-den-bosch-2017-exploring</bibkey>
    </paper>
    </volume>
  <volume id="13">
    <meta>
      <booktitle>Proceedings of the Third <fixed-case>A</fixed-case>rabic Natural Language Processing Workshop</booktitle>
      <url hash="33594ae5">W17-13</url>
      <editor><first>Nizar</first><last>Habash</last></editor>
      <editor><first>Mona</first><last>Diab</last></editor>
      <editor><first>Kareem</first><last>Darwish</last></editor>
      <editor><first>Wassim</first><last>El-Hajj</last></editor>
      <editor><first>Hend</first><last>Al-Khalifa</last></editor>
      <editor><first>Houda</first><last>Bouamor</last></editor>
      <editor><first>Nadi</first><last>Tomeh</last></editor>
      <editor><first>Mahmoud</first><last>El-Haj</last></editor>
      <editor><first>Wajdi</first><last>Zaghouani</last></editor>
      <doi>10.18653/v1/W17-13</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="36a70790">W17-1300</url>
      <bibkey>ws-2017-arabic</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Identification of Languages in Algerian Arabic Multilingual Documents<fixed-case>A</fixed-case>lgerian <fixed-case>A</fixed-case>rabic Multilingual Documents</title>
      <author><first>Wafia</first><last>Adouane</last></author>
      <author><first>Simon</first><last>Dobnik</last></author>
      <pages>1–8</pages>
      <url hash="2156ceda">W17-1301</url>
      <doi>10.18653/v1/W17-1301</doi>
      <abstract>This paper presents a language identification system designed to detect the language of each word, in its context, in a multilingual documents as generated in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> by bilingual / multilingual communities, in our case speakers of Algerian Arabic. We frame the task as a sequence tagging problem and use <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised machine learning</a> with standard methods like HMM and Ngram classification tagging. We also experiment with a lexicon-based method. Combining all the methods in a fall-back mechanism and introducing some <a href="https://en.wikipedia.org/wiki/Rule_of_inference">linguistic rules</a>, to deal with unseen tokens and <a href="https://en.wikipedia.org/wiki/Ambiguity">ambiguous words</a>, gives an overall <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 93.14 %. Finally, we introduced <a href="https://en.wikipedia.org/wiki/Rule_of_inference">rules</a> for language identification from sequences of recognised words.</abstract>
      <bibkey>adouane-dobnik-2017-identification</bibkey>
    </paper>
    <paper id="2">
      <title>Arabic Diacritization : <a href="https://en.wikipedia.org/wiki/Statistics">Stats</a>, <a href="https://en.wikipedia.org/wiki/Regulation">Rules</a>, and Hacks<fixed-case>A</fixed-case>rabic Diacritization: Stats, Rules, and Hacks</title>
      <author><first>Kareem</first><last>Darwish</last></author>
      <author><first>Hamdy</first><last>Mubarak</last></author>
      <author><first>Ahmed</first><last>Abdelali</last></author>
      <pages>9–17</pages>
      <url hash="9d081dd5">W17-1302</url>
      <doi>10.18653/v1/W17-1302</doi>
      <abstract>In this paper, we present a new and fast state-of-the-art Arabic diacritizer that guesses the diacritics of words and then their <a href="https://en.wikipedia.org/wiki/Grammatical_case">case endings</a>. We employ a <a href="https://en.wikipedia.org/wiki/Viterbi_decoder">Viterbi decoder</a> at word-level with back-off to stem, morphological patterns, and <a href="https://en.wikipedia.org/wiki/Transliteration">transliteration</a> and sequence labeling based diacritization of named entities. For case endings, we use Support Vector Machine (SVM) based ranking coupled with <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological patterns</a> and <a href="https://en.wikipedia.org/wiki/Rule_of_inference">linguistic rules</a> to properly guess case endings. We achieve a low word level diacritization error of 3.29 % and 12.77 % without and with case endings respectively on a new multi-genre free of copyright test set. We are making the diacritizer available for free for research purposes.</abstract>
      <bibkey>darwish-etal-2017-arabic</bibkey>
    </paper>
    <paper id="3">
      <title>Semantic Similarity of Arabic Sentences with Word Embeddings<fixed-case>A</fixed-case>rabic Sentences with Word Embeddings</title>
      <author><first>El Moatez Billah</first><last>Nagoudi</last></author>
      <author><first>Didier</first><last>Schwab</last></author>
      <pages>18–24</pages>
      <url hash="5338cfb5">W17-1303</url>
      <doi>10.18653/v1/W17-1303</doi>
      <abstract>Semantic textual similarity is the basis of countless applications and plays an important role in diverse areas, such as <a href="https://en.wikipedia.org/wiki/Information_retrieval">information retrieval</a>, <a href="https://en.wikipedia.org/wiki/Plagiarism_detection">plagiarism detection</a>, <a href="https://en.wikipedia.org/wiki/Information_extraction">information extraction</a> and <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>. This article proposes an innovative word embedding-based system devoted to calculate the <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a> in <a href="https://en.wikipedia.org/wiki/Arabic_grammar">Arabic sentences</a>. The main idea is to exploit <a href="https://en.wikipedia.org/wiki/Vector_space">vectors</a> as word representations in a <a href="https://en.wikipedia.org/wiki/Dimension_(vector_space)">multidimensional space</a> in order to capture the semantic and syntactic properties of words. IDF weighting and Part-of-Speech tagging are applied on the examined sentences to support the identification of words that are highly descriptive in each sentence. The performance of our proposed <a href="https://en.wikipedia.org/wiki/System">system</a> is confirmed through the <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson correlation</a> between our assigned semantic similarity scores and <a href="https://en.wikipedia.org/wiki/Judgement">human judgments</a>.</abstract>
      <bibkey>nagoudi-schwab-2017-semantic</bibkey>
    </paper>
    <paper id="4">
      <title>Morphological Analysis for the <a href="https://en.wikipedia.org/wiki/Maltese_language">Maltese Language</a> : The challenges of a <a href="https://en.wikipedia.org/wiki/Hybrid_system">hybrid system</a><fixed-case>M</fixed-case>altese Language: The challenges of a hybrid system</title>
      <author><first>Claudia</first><last>Borg</last></author>
      <author><first>Albert</first><last>Gatt</last></author>
      <pages>25–34</pages>
      <url hash="a32646ca">W17-1304</url>
      <doi>10.18653/v1/W17-1304</doi>
      <abstract>Maltese is a morphologically rich language with a hybrid morphological system which features both concatenative and non-concatenative processes. This paper analyses the impact of this <a href="https://en.wikipedia.org/wiki/Hybridity">hybridity</a> on the performance of machine learning techniques for <a href="https://en.wikipedia.org/wiki/Morphology_(biology)">morphological labelling</a> and <a href="https://en.wikipedia.org/wiki/Cluster_analysis">clustering</a>. In particular, we analyse a dataset of morphologically related word clusters to evaluate the difference in results for concatenative and non-concatenative clusters. We also describe research carried out in <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological labelling</a>, with a particular focus on the verb category. Two evaluations were carried out, one using an unseen dataset, and another one using a gold standard dataset which was manually labelled. The <a href="https://en.wikipedia.org/wiki/Gold_standard_(test)">gold standard dataset</a> was split into concatenative and non-concatenative to analyse the difference in results between the two <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological systems</a>.</abstract>
      <bibkey>borg-gatt-2017-morphological</bibkey>
    </paper>
    <paper id="5">
      <title>A <a href="https://en.wikipedia.org/wiki/Morphological_analysis">Morphological Analyzer</a> for Gulf Arabic Verbs<fixed-case>G</fixed-case>ulf <fixed-case>A</fixed-case>rabic Verbs</title>
      <author><first>Salam</first><last>Khalifa</last></author>
      <author><first>Sara</first><last>Hassan</last></author>
      <author><first>Nizar</first><last>Habash</last></author>
      <pages>35–45</pages>
      <url hash="853e3e91">W17-1305</url>
      <doi>10.18653/v1/W17-1305</doi>
      <abstract>We present CALIMAGLF, a Gulf Arabic morphological analyzer currently covering over 2,600 verbal lemmas. We describe in detail the process of building the analyzer starting from phonetic dictionary entries to fully inflected orthographic paradigms and associated lexicon and orthographic variants. We evaluate the coverage of CALIMA-GLF against Modern Standard Arabic and Egyptian Arabic analyzers on part of a Gulf Arabic novel. CALIMA-GLF verb analysis token recall for identifying correct POS tag outperforms both the Modern Standard Arabic and Egyptian Arabic analyzers by over 27.4 % and 16.9 % absolute, respectively.</abstract>
      <bibkey>khalifa-etal-2017-morphological</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/gumar-corpus">Gumar Corpus</pwcdataset>
    </paper>
    <paper id="6">
      <title>A Neural Architecture for Dialectal Arabic Segmentation<fixed-case>A</fixed-case>rabic Segmentation</title>
      <author><first>Younes</first><last>Samih</last></author>
      <author><first>Mohammed</first><last>Attia</last></author>
      <author><first>Mohamed</first><last>Eldesouki</last></author>
      <author><first>Ahmed</first><last>Abdelali</last></author>
      <author><first>Hamdy</first><last>Mubarak</last></author>
      <author><first>Laura</first><last>Kallmeyer</last></author>
      <author><first>Kareem</first><last>Darwish</last></author>
      <pages>46–54</pages>
      <url hash="f1f3b928">W17-1306</url>
      <doi>10.18653/v1/W17-1306</doi>
      <abstract>The automated processing of <a href="https://en.wikipedia.org/wiki/Arabic_dialects">Arabic Dialects</a> is challenging due to the lack of spelling standards and to the scarcity of annotated data and resources in general. Segmentation of words into its constituent parts is an important processing building block. In this paper, we show how a segmenter can be trained using only 350 annotated tweets using <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a> without any <a href="https://en.wikipedia.org/wiki/Normalization_(statistics)">normalization</a> or use of lexical features or lexical resources. We deal with segmentation as a sequence labeling problem at the <a href="https://en.wikipedia.org/wiki/Character_(computing)">character level</a>. We show experimentally that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> can rival state-of-the-art methods that rely on additional resources.</abstract>
      <bibkey>samih-etal-2017-neural</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/egyptian-arabic-segmentation-dataset">Egyptian Arabic Segmentation Dataset</pwcdataset>
    </paper>
    <paper id="7">
      <title>Sentiment Analysis of Tunisian Dialects : Linguistic Ressources and Experiments<fixed-case>T</fixed-case>unisian Dialects: Linguistic Ressources and Experiments</title>
      <author><first>Salima</first><last>Medhaffar</last></author>
      <author><first>Fethi</first><last>Bougares</last></author>
      <author><first>Yannick</first><last>Estève</last></author>
      <author><first>Lamia</first><last>Hadrich-Belguith</last></author>
      <pages>55–61</pages>
      <url hash="a33551d2">W17-1307</url>
      <doi>10.18653/v1/W17-1307</doi>
      <abstract>Dialectal Arabic (DA) is significantly different from the <a href="https://en.wikipedia.org/wiki/Arabic">Arabic language</a> taught in schools and used in <a href="https://en.wikipedia.org/wiki/Writing">written communication</a> and formal speech (broadcast news, <a href="https://en.wikipedia.org/wiki/Religion">religion</a>, <a href="https://en.wikipedia.org/wiki/Politics">politics</a>, etc.). There are many existing researches in the field of Arabic language Sentiment Analysis (SA) ; however, they are generally restricted to Modern Standard Arabic (MSA) or some dialects of economic or political interest. In this paper we are interested in the <a href="https://en.wikipedia.org/wiki/Arabic">SA</a> of the <a href="https://en.wikipedia.org/wiki/Tunisian_Arabic">Tunisian Dialect</a>. We utilize Machine Learning techniques to determine the <a href="https://en.wikipedia.org/wiki/Polarity_(linguistics)">polarity</a> of comments written in <a href="https://en.wikipedia.org/wiki/Tunisian_Arabic">Tunisian Dialect</a>. First, we evaluate the SA systems performances with <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> trained using freely available MSA and Multi-dialectal data sets. We then collect and annotate a Tunisian Dialect corpus of 17.000 comments from <a href="https://en.wikipedia.org/wiki/Facebook">Facebook</a>. This <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> allows us a significant accuracy improvement compared to the best <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> trained on other <a href="https://en.wikipedia.org/wiki/Varieties_of_Arabic">Arabic dialects</a> or MSA data. We believe that this first freely available corpus will be valuable to researchers working in the field of Tunisian Sentiment Analysis and similar areas.</abstract>
      <bibkey>medhaffar-etal-2017-sentiment</bibkey>
      <pwccode url="https://github.com/fbougares/TSAC" additional="false">fbougares/TSAC</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/tsac">TSAC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/labr">LABR</pwcdataset>
    </paper>
    <paper id="8">
      <title>CAT : Credibility Analysis of Arabic Content on Twitter<fixed-case>CAT</fixed-case>: Credibility Analysis of <fixed-case>A</fixed-case>rabic Content on <fixed-case>T</fixed-case>witter</title>
      <author><first>Rim</first><last>El Ballouli</last></author>
      <author><first>Wassim</first><last>El-Hajj</last></author>
      <author><first>Ahmad</first><last>Ghandour</last></author>
      <author><first>Shady</first><last>Elbassuoni</last></author>
      <author><first>Hazem</first><last>Hajj</last></author>
      <author><first>Khaled</first><last>Shaban</last></author>
      <pages>62–71</pages>
      <url hash="e637b36c">W17-1308</url>
      <doi>10.18653/v1/W17-1308</doi>
      <abstract>Data generated on <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> has become a rich source for various data mining tasks. Those data analysis tasks that are dependent on the tweet semantics, such as <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a>, emotion mining, and rumor detection among others, suffer considerably if the tweet is not credible, not real, or spam. In this paper, we perform an extensive analysis on credibility of Arabic content on <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>. We also build a classification model (CAT) to automatically predict the <a href="https://en.wikipedia.org/wiki/Credibility">credibility</a> of a given Arabic tweet. Of particular originality is the inclusion of <a href="https://en.wikipedia.org/wiki/Software_feature">features</a> extracted directly or indirectly from the author’s profile and timeline. To train and test CAT, we annotated for <a href="https://en.wikipedia.org/wiki/Credibility">credibility</a> a <a href="https://en.wikipedia.org/wiki/Data_set">data set</a> of 9,000 <a href="https://en.wikipedia.org/wiki/Twitter">Arabic tweets</a> that are topic independent. CAT achieved consistent improvements in predicting the credibility of the tweets when compared to several baselines and when compared to the state-of-the-art approach with an improvement of 21 % in weighted average F-measure. We also conducted experiments to highlight the importance of the user-based features as opposed to the content-based features. We conclude our work with a feature reduction experiment that highlights the best indicative features of credibility.</abstract>
      <bibkey>el-ballouli-etal-2017-cat</bibkey>
    </paper>
    <paper id="9">
      <title>A New <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">Error Annotation</a> for Dyslexic texts in Arabic<fixed-case>A</fixed-case>rabic</title>
      <author><first>Maha</first><last>Alamri</last></author>
      <author><first>William J</first><last>Teahan</last></author>
      <pages>72–78</pages>
      <url hash="ee381efe">W17-1309</url>
      <doi>10.18653/v1/W17-1309</doi>
      <abstract>This paper aims to develop a new classification of errors made in <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a> by those suffering from <a href="https://en.wikipedia.org/wiki/Dyslexia">dyslexia</a> to be used in the annotation of the Arabic dyslexia corpus (BDAC). The dyslexic error classification for Arabic texts (DECA) comprises a list of spelling errors extracted from previous studies and a collection of texts written by people with <a href="https://en.wikipedia.org/wiki/Dyslexia">dyslexia</a> that can provide a framework to help analyse specific errors committed by dyslexic writers. The <a href="https://en.wikipedia.org/wiki/Categorization">classification</a> comprises 37 types of errors, grouped into nine categories. The paper also discusses building a corpus of dyslexic Arabic texts that uses the error annotation scheme and provides an analysis of the errors that were found in the texts.</abstract>
      <bibkey>alamri-teahan-2017-new</bibkey>
    </paper>
    <paper id="11">
      <title>SHAKKIL : An Automatic Diacritization System for Modern Standard Arabic Texts<fixed-case>SHAKKIL</fixed-case>: An Automatic Diacritization System for <fixed-case>M</fixed-case>odern <fixed-case>S</fixed-case>tandard <fixed-case>A</fixed-case>rabic Texts</title>
      <author><first>Amany</first><last>Fashwan</last></author>
      <author><first>Sameh</first><last>Alansary</last></author>
      <pages>84–93</pages>
      <url hash="6278b3ba">W17-1311</url>
      <doi>10.18653/v1/W17-1311</doi>
      <abstract>This paper sheds light on a <a href="https://en.wikipedia.org/wiki/System">system</a> that would be able to diacritize Arabic texts automatically (SHAKKIL). In this system, the diacritization problem will be handled through two levels ; morphological and syntactic processing levels. The adopted morphological disambiguation algorithm depends on four layers ; Uni-morphological form layer, rule-based morphological disambiguation layer, statistical-based disambiguation layer and Out Of Vocabulary (OOV) layer. The adopted syntactic disambiguation algorithms is concerned with detecting the case ending diacritics depending on a rule based approach simulating the shallow parsing technique. This will be achieved using an annotated corpus for extracting the <a href="https://en.wikipedia.org/wiki/Arabic_grammar">Arabic linguistic rules</a>, building the <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> and testing the system output. This system is considered as a good trial of the interaction between rule-based approach and statistical approach, where the rules can help the statistics in detecting the right <a href="https://en.wikipedia.org/wiki/Diacritic">diacritization</a> and vice versa. At this point, the morphological Word Error Rate (WER) is 4.56 % while the morphological Diacritic Error Rate (DER) is 1.88 % and the syntactic WER is 9.36 %. The best WER is 14.78 % compared to the best-published results, of (Abandah, 2015) ; 11.68 %, (Rashwan, et al., 2015) ; 12.90 % and (Metwally, Rashwan, &amp; Atiya, 2016) ; 13.70 %.</abstract>
      <bibkey>fashwan-alansary-2017-shakkil</bibkey>
    </paper>
    <paper id="12">
      <title>Arabic Tweets Treebanking and Parsing : A Bootstrapping Approach<fixed-case>A</fixed-case>rabic Tweets Treebanking and Parsing: A Bootstrapping Approach</title>
      <author><first>Fahad</first><last>Albogamy</last></author>
      <author><first>Allan</first><last>Ramsay</last></author>
      <author><first>Hanady</first><last>Ahmed</last></author>
      <pages>94–99</pages>
      <url hash="c2b284df">W17-1312</url>
      <doi>10.18653/v1/W17-1312</doi>
      <abstract>In this paper, we propose using a bootstrapping method for constructing a dependency treebank of <a href="https://en.wikipedia.org/wiki/Twitter">Arabic tweets</a>. This method uses a rule-based parser to create a small treebank of one thousand Arabic tweets and a data-driven parser to create a larger <a href="https://en.wikipedia.org/wiki/Treebank">treebank</a> by using the small treebank as a seed training set. We are able to create a dependency treebank from unlabelled tweets without any manual intervention. Experiments results show that this method can improve the speed of training the <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> and the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of the resulting <a href="https://en.wikipedia.org/wiki/Parsing">parsers</a>.</abstract>
      <bibkey>albogamy-etal-2017-arabic</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="13">
      <title>Identifying Effective Translations for Cross-lingual Arabic-to-English User-generated Speech Search<fixed-case>A</fixed-case>rabic-to-<fixed-case>E</fixed-case>nglish User-generated Speech Search</title>
      <author><first>Ahmad</first><last>Khwileh</last></author>
      <author><first>Haithem</first><last>Afli</last></author>
      <author><first>Gareth</first><last>Jones</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <pages>100–109</pages>
      <url hash="7aa0d0fe">W17-1313</url>
      <doi>10.18653/v1/W17-1313</doi>
      <abstract>Cross Language Information Retrieval (CLIR) systems are a valuable tool to enable speakers of one language to search for content of interest expressed in a different language. A group for whom this is of particular interest is bilingual Arabic speakers who wish to search for English language content using information needs expressed in Arabic queries. A key challenge in <a href="https://en.wikipedia.org/wiki/CLIR">CLIR</a> is crossing the language barrier between the query and the documents. The most common approach to bridging this gap is automated query translation, which can be unreliable for vague or short queries. In this work, we examine the potential for improving CLIR effectiveness by predicting the translation effectiveness using Query Performance Prediction (QPP) techniques. We propose a novel QPP method to estimate the quality of translation for an Arabic-English Cross-lingual User-generated Speech Search (CLUGS) task. We present an empirical evaluation that demonstrates the quality of our method on alternative translation outputs extracted from an Arabic-to-English Machine Translation system developed for this task. Finally, we show how this <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> can be integrated in CLUGS to find relevant translations for improved retrieval performance.</abstract>
      <bibkey>khwileh-etal-2017-identifying</bibkey>
    </paper>
    <paper id="14">
      <title>A Characterization Study of Arabic Twitter Data with a Benchmarking for State-of-the-Art Opinion Mining Models<fixed-case>A</fixed-case>rabic <fixed-case>T</fixed-case>witter Data with a Benchmarking for State-of-the-Art Opinion Mining Models</title>
      <author><first>Ramy</first><last>Baly</last></author>
      <author><first>Gilbert</first><last>Badaro</last></author>
      <author><first>Georges</first><last>El-Khoury</last></author>
      <author><first>Rawan</first><last>Moukalled</last></author>
      <author><first>Rita</first><last>Aoun</last></author>
      <author><first>Hazem</first><last>Hajj</last></author>
      <author><first>Wassim</first><last>El-Hajj</last></author>
      <author><first>Nizar</first><last>Habash</last></author>
      <author><first>Khaled</first><last>Shaban</last></author>
      <pages>110–118</pages>
      <url hash="e6b443b3">W17-1314</url>
      <doi>10.18653/v1/W17-1314</doi>
      <abstract>Opinion mining in <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a> is a challenging task given the <a href="https://en.wikipedia.org/wiki/Varieties_of_Arabic">rich morphology of the language</a>. The task becomes more challenging when it is applied to Twitter data, which contains additional sources of noise, such as the use of unstandardized dialectal variations, the nonconformation to grammatical rules, the use of Arabizi and code-switching, and the use of non-text objects such as images and <a href="https://en.wikipedia.org/wiki/URL">URLs</a> to express opinion. In this paper, we perform an analytical study to observe how such linguistic phenomena vary across different <a href="https://en.wikipedia.org/wiki/Arab_world">Arab regions</a>. This study of Arabic Twitter characterization aims at providing better understanding of Arabic Tweets, and fostering advanced research on the topic. Furthermore, we explore the performance of the two schools of <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a> on Arabic Twitter, namely the <a href="https://en.wikipedia.org/wiki/Feature_engineering">feature engineering approach</a> and the <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning approach</a>. We consider <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> that have achieved state-of-the-art performance for opinion mining in English. Results highlight the advantages of using <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning-based models</a>, and confirm the importance of using <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological abstractions</a> to address <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">Arabic’s complex morphology</a>.</abstract>
      <bibkey>baly-etal-2017-characterization</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/astd">ASTD</pwcdataset>
    </paper>
    <paper id="15">
      <title>Robust Dictionary Lookup in Multiple Noisy Orthographies</title>
      <author><first>Lingliang</first><last>Zhang</last></author>
      <author><first>Nizar</first><last>Habash</last></author>
      <author><first>Godfried</first><last>Toussaint</last></author>
      <pages>119–129</pages>
      <url hash="fe47609e">W17-1315</url>
      <doi>10.18653/v1/W17-1315</doi>
      <abstract>We present the MultiScript Phonetic Search algorithm to address the problem of <a href="https://en.wikipedia.org/wiki/Language_acquisition">language learners</a> looking up unfamiliar words that they heard. We apply it to Arabic dictionary lookup with noisy queries done using both the <a href="https://en.wikipedia.org/wiki/Arabic_script">Arabic and Roman scripts</a>. Our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> is based on a computational phonetic distance metric that can be optionally machine learned. To benchmark our performance, we created the ArabScribe dataset, containing 10,000 noisy transcriptions of random Arabic dictionary words. Our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> outperforms Google Translate’s did you mean feature, as well as the Yamli smart Arabic keyboard.</abstract>
      <bibkey>zhang-etal-2017-robust</bibkey>
    </paper>
    <paper id="18">
      <title>Not All Segments are Created Equal : Syntactically Motivated Sentiment Analysis in Lexical Space</title>
      <author><first>Muhammad</first><last>Abdul-Mageed</last></author>
      <pages>147–156</pages>
      <url hash="905f871c">W17-1318</url>
      <doi>10.18653/v1/W17-1318</doi>
      <abstract>Although there is by now a considerable amount of research on subjectivity and sentiment analysis on morphologically-rich languages, it is still unclear how lexical information can best be modeled in these <a href="https://en.wikipedia.org/wiki/Language">languages</a>. To bridge this gap, we build effective models exploiting exclusively gold- and machine-segmented lexical input and successfully employ syntactically motivated feature selection to improve <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a>. Our best <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> achieve significantly above the baselines, with 67.93 % and 69.37 % accuracies for subjectivity and sentiment classification respectively.</abstract>
      <bibkey>abdul-mageed-2017-segments</bibkey>
    </paper>
    <paper id="19">
      <title>An enhanced automatic speech recognition system for Arabic<fixed-case>A</fixed-case>rabic</title>
      <author><first>Mohamed Amine</first><last>Menacer</last></author>
      <author><first>Odile</first><last>Mella</last></author>
      <author><first>Dominique</first><last>Fohr</last></author>
      <author><first>Denis</first><last>Jouvet</last></author>
      <author><first>David</first><last>Langlois</last></author>
      <author><first>Kamel</first><last>Smaili</last></author>
      <pages>157–165</pages>
      <url hash="9f686c75">W17-1319</url>
      <doi>10.18653/v1/W17-1319</doi>
      <abstract>Automatic speech recognition for <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a> is a very challenging task. Despite all the classical techniques for Automatic Speech Recognition (ASR), which can be efficiently applied to Arabic speech recognition, it is essential to take into consideration the language specificities to improve the system performance. In this article, we focus on Modern Standard Arabic (MSA) speech recognition. We introduce the challenges related to <a href="https://en.wikipedia.org/wiki/Arabic">Arabic language</a>, namely the complex morphology nature of the language and the absence of the short vowels in written text, which leads to several potential vowelization for each graphemes, which is often conflicting. We develop an ASR system for MSA by using <a href="https://en.wikipedia.org/wiki/Kaldi_(software)">Kaldi toolkit</a>. Several acoustic and language models are trained. We obtain a <a href="https://en.wikipedia.org/wiki/Word_error_rate">Word Error Rate (WER)</a> of 14.42 for the baseline system and 12.2 relative improvement by rescoring the <a href="https://en.wikipedia.org/wiki/Lattice_(group)">lattice</a> and by rewriting the output with the right Z hamoza above or below Alif.</abstract>
      <bibkey>menacer-etal-2017-enhanced</bibkey>
    </paper>
    <paper id="20">
      <title>Universal Dependencies for Arabic<fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies for <fixed-case>A</fixed-case>rabic</title>
      <author><first>Dima</first><last>Taji</last></author>
      <author><first>Nizar</first><last>Habash</last></author>
      <author><first>Daniel</first><last>Zeman</last></author>
      <pages>166–176</pages>
      <url hash="99bab123">W17-1320</url>
      <doi>10.18653/v1/W17-1320</doi>
      <abstract>We describe the process of creating NUDAR, a Universal Dependency treebank for <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a>. We present the conversion from the Penn Arabic Treebank to the Universal Dependency syntactic representation through an intermediate dependency representation. We discuss the challenges faced in the <a href="https://en.wikipedia.org/wiki/Data_conversion">conversion of the trees</a>, the decisions we made to solve them, and the validation of our <a href="https://en.wikipedia.org/wiki/Data_conversion">conversion</a>. We also present initial <a href="https://en.wikipedia.org/wiki/Parsing">parsing</a> results on NUDAR.</abstract>
      <bibkey>taji-etal-2017-universal</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="21">
      <title>A Layered Language Model based Hybrid Approach to Automatic Full Diacritization of Arabic<fixed-case>A</fixed-case>rabic</title>
      <author><first>Mohamed</first><last>Al-Badrashiny</last></author>
      <author><first>Abdelati</first><last>Hawwari</last></author>
      <author><first>Mona</first><last>Diab</last></author>
      <pages>177–184</pages>
      <url hash="3fa10662">W17-1321</url>
      <doi>10.18653/v1/W17-1321</doi>
      <abstract>In this paper we present a system for automatic Arabic text diacritization using three levels of analysis granularity in a layered back off manner. We build and exploit diacritized language models (LM) for each of three different levels of granularity : surface form, morphologically segmented into prefix / stem / suffix, and character level. For each of the passes, we use <a href="https://en.wikipedia.org/wiki/Viterbi_search">Viterbi search</a> to pick the most probable diacritization per word in the input. We start with the surface form LM, followed by the morphological level, then finally we leverage the character level LM. Our <a href="https://en.wikipedia.org/wiki/System">system</a> outperforms all of the published <a href="https://en.wikipedia.org/wiki/System">systems</a> evaluated against the same <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training and test data</a>. It achieves a 10.87 % <a href="https://en.wikipedia.org/wiki/Word_error_rate">WER</a> for complete full diacritization including lexical and syntactic diacritization, and 3.0 % <a href="https://en.wikipedia.org/wiki/Word_error_rate">WER</a> for lexical diacritization, ignoring syntactic diacritization.</abstract>
      <bibkey>al-badrashiny-etal-2017-layered</bibkey>
    </paper>
    <paper id="22">
      <title>Arabic Textual Entailment with Word Embeddings<fixed-case>A</fixed-case>rabic Textual Entailment with Word Embeddings</title>
      <author><first>Nada</first><last>Almarwani</last></author>
      <author><first>Mona</first><last>Diab</last></author>
      <pages>185–190</pages>
      <url hash="e3250d21">W17-1322</url>
      <doi>10.18653/v1/W17-1322</doi>
      <abstract>Determining the <a href="https://en.wikipedia.org/wiki/Textual_entailment">textual entailment</a> between texts is important in many NLP tasks, such as <a href="https://en.wikipedia.org/wiki/Automatic_summarization">summarization</a>, <a href="https://en.wikipedia.org/wiki/Question_answering">question answering</a>, and <a href="https://en.wikipedia.org/wiki/Information_retrieval">information extraction and retrieval</a>. Various methods have been suggested based on external knowledge sources ; however, such resources are not always available in all languages and their acquisition is typically laborious and very costly. Distributional word representations such as <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> learned over large corpora have been shown to capture syntactic and semantic word relationships. Such <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> have contributed to improving the performance of several <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP tasks</a>. In this paper, we address the problem of <a href="https://en.wikipedia.org/wiki/Textual_entailment">textual entailment</a> in <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a>. We employ both traditional <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> and distributional representations. Crucially, we do not depend on any external resources in the process. Our suggested approach yields state of the art performance on a standard data set, ArbTE, achieving an accuracy of 76.2 % compared to state of the art of 69.3 %.</abstract>
      <bibkey>almarwani-diab-2017-arabic</bibkey>
    </paper>
  </volume>
  <volume id="14">
    <meta>
      <booktitle>Proceedings of the 6th Workshop on <fixed-case>B</fixed-case>alto-<fixed-case>S</fixed-case>lavic Natural Language Processing</booktitle>
      <url hash="7ce7fb51">W17-14</url>
      <editor><first>Tomaž</first><last>Erjavec</last></editor>
      <editor><first>Jakub</first><last>Piskorski</last></editor>
      <editor><first>Lidia</first><last>Pivovarova</last></editor>
      <editor><first>Jan</first><last>Šnajder</last></editor>
      <editor><first>Josef</first><last>Steinberger</last></editor>
      <editor><first>Roman</first><last>Yangarber</last></editor>
      <doi>10.18653/v1/W17-14</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="25032938">W17-1400</url>
      <bibkey>ws-2017-balto</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Toward Pan-Slavic NLP : Some Experiments with Language Adaptation<fixed-case>S</fixed-case>lavic <fixed-case>NLP</fixed-case>: Some Experiments with Language Adaptation</title>
      <author><first>Serge</first><last>Sharoff</last></author>
      <pages>1–2</pages>
      <url hash="30fa5626">W17-1401</url>
      <doi>10.18653/v1/W17-1401</doi>
      <abstract>There is great variation in the amount of NLP resources available for <a href="https://en.wikipedia.org/wiki/Slavic_languages">Slavonic languages</a>. For example, the Universal Dependency treebank (Nivre et al., 2016) has about 2 MW of training resources for <a href="https://en.wikipedia.org/wiki/Czech_language">Czech</a>, more than 1 MW for <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a>, while only 950 words for <a href="https://en.wikipedia.org/wiki/Ukrainian_language">Ukrainian</a> and nothing for <a href="https://en.wikipedia.org/wiki/Belarusian_language">Belorussian</a>, <a href="https://en.wikipedia.org/wiki/Bosnian_language">Bosnian</a> or <a href="https://en.wikipedia.org/wiki/Macedonian_language">Macedonian</a>. Similarly, the Autodesk Machine Translation dataset only covers three <a href="https://en.wikipedia.org/wiki/Slavic_languages">Slavonic languages</a> (Czech, <a href="https://en.wikipedia.org/wiki/Polish_language">Polish</a> and Russian). In this talk I will discuss a general approach, which can be called Language Adaptation, similarly to <a href="https://en.wikipedia.org/wiki/Domain_adaptation">Domain Adaptation</a>. In this approach, a model for a particular language processing task is built by lexical transfer of cognate words and by learning a new <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">feature representation</a> for a lesser-resourced (recipient) language starting from a better-resourced (donor) language. More specifically, I will demonstrate how language adaptation works in such training scenarios as Translation Quality Estimation, Part-of-Speech tagging and <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">Named Entity Recognition</a>.</abstract>
      <bibkey>sharoff-2017-toward</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="2">
      <title>Clustering of Russian Adjective-Noun Constructions using Word Embeddings<fixed-case>R</fixed-case>ussian Adjective-Noun Constructions using Word Embeddings</title>
      <author><first>Andrey</first><last>Kutuzov</last></author>
      <author><first>Elizaveta</first><last>Kuzmenko</last></author>
      <author><first>Lidia</first><last>Pivovarova</last></author>
      <pages>3–13</pages>
      <url hash="f3c00c55">W17-1402</url>
      <doi>10.18653/v1/W17-1402</doi>
      <abstract>This paper presents a method of automatic construction extraction from a large corpus of Russian. The term ‘construction’ here means a multi-word expression in which a variable can be replaced with another word from the same <a href="https://en.wikipedia.org/wiki/Semantic_class">semantic class</a>, for example, ‘a glass of [ water / juice / milk ]’. We deal with <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">constructions</a> that consist of a <a href="https://en.wikipedia.org/wiki/Noun">noun</a> and its adjective modifier. We propose a method of grouping such constructions into <a href="https://en.wikipedia.org/wiki/Semantic_class">semantic classes</a> via 2-step clustering of word vectors in <a href="https://en.wikipedia.org/wiki/Distribution_(mathematics)">distributional models</a>. We compare it with other clustering techniques and evaluate it against A Russian-English Collocational Dictionary of the Human Body that contains manually annotated groups of constructions with nouns meaning human body parts. The best performing method is used to cluster all adjective-noun bigrams in the <a href="https://en.wikipedia.org/wiki/Russian_National_Corpus">Russian National Corpus</a>. Results of this procedure are publicly available and can be used for building Russian construction dictionary as well as to accelerate theoretical studies of constructions.</abstract>
      <bibkey>kutuzov-etal-2017-clustering</bibkey>
    </paper>
    <paper id="3">
      <title>A Preliminary Study of Croatian Lexical Substitution<fixed-case>C</fixed-case>roatian Lexical Substitution</title>
      <author><first>Domagoj</first><last>Alagić</last></author>
      <author><first>Jan</first><last>Šnajder</last></author>
      <pages>14–19</pages>
      <url hash="cb45d902">W17-1403</url>
      <doi>10.18653/v1/W17-1403</doi>
      <abstract>Lexical substitution is a task of determining a meaning-preserving replacement for a word in context. We report on a preliminary study of this task for the <a href="https://en.wikipedia.org/wiki/Croatian_language">Croatian language</a> on a small-scale lexical sample dataset, manually annotated using three different annotation schemes. We compare the <a href="https://en.wikipedia.org/wiki/Annotation">annotations</a>, analyze the inter-annotator agreement, and observe a number of interesting language specific details in the obtained lexical substitutes. Furthermore, we apply a recently-proposed, dependency-based lexical substitution model to our <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves a <a href="https://en.wikipedia.org/wiki/P-value">P@3 score</a> of 0.35, which indicates the difficulty of the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>.</abstract>
      <bibkey>alagic-snajder-2017-preliminary</bibkey>
    </paper>
    <paper id="4">
      <title>Projecting Multiword Expression Resources on a Polish Treebank<fixed-case>P</fixed-case>olish Treebank</title>
      <author><first>Agata</first><last>Savary</last></author>
      <author><first>Jakub</first><last>Waszczuk</last></author>
      <pages>20–26</pages>
      <url hash="2caf526f">W17-1404</url>
      <doi>10.18653/v1/W17-1404</doi>
      <abstract>Multiword expressions (MWEs) are <a href="https://en.wikipedia.org/wiki/Object_(philosophy)">linguistic objects</a> containing two or more words and showing <a href="https://en.wikipedia.org/wiki/Idiosyncrasy">idiosyncratic behavior</a> at different levels. Treebanks with annotated MWEs enable studies of such properties, as well as training and evaluation of MWE-aware parsers. However, few <a href="https://en.wikipedia.org/wiki/Treebank">treebanks</a> contain full-fledged MWE annotations. We show how this gap can be bridged in Polish by projecting 3 MWE resources on a constituency treebank.</abstract>
      <bibkey>savary-waszczuk-2017-projecting</bibkey>
    </paper>
    <paper id="5">
      <title>Lexicon Induction for Spoken Rusyn   Challenges and Results<fixed-case>R</fixed-case>usyn – Challenges and Results</title>
      <author><first>Achim</first><last>Rabus</last></author>
      <author><first>Yves</first><last>Scherrer</last></author>
      <pages>27–32</pages>
      <url hash="cdd12fd2">W17-1405</url>
      <doi>10.18653/v1/W17-1405</doi>
      <abstract>This paper reports on challenges and results in developing NLP resources for <a href="https://en.wikipedia.org/wiki/Rusyn_language">spoken Rusyn</a>. Being a <a href="https://en.wikipedia.org/wiki/Slavic_languages">Slavic minority language</a>, <a href="https://en.wikipedia.org/wiki/Rusyn_language">Rusyn</a> does not have any resources to make use of. We propose to build a morphosyntactic dictionary for <a href="https://en.wikipedia.org/wiki/Rusyn_language">Rusyn</a>, combining existing resources from the etymologically close Slavic languages Russian, <a href="https://en.wikipedia.org/wiki/Ukrainian_language">Ukrainian</a>, <a href="https://en.wikipedia.org/wiki/Slovak_language">Slovak</a>, and <a href="https://en.wikipedia.org/wiki/Polish_language">Polish</a>. We adapt these resources to <a href="https://en.wikipedia.org/wiki/Rusyn_language">Rusyn</a> by using vowel-sensitive Levenshtein distance, hand-written language-specific transformation rules, and combinations of the two. Compared to an exact match baseline, we increase the coverage of the resulting <a href="https://en.wikipedia.org/wiki/Morphological_dictionary">morphological dictionary</a> by up to 77.4 % relative (42.9 % absolute), which results in a tagging recall increased by 11.6 % relative (9.1 % absolute). Our research confirms and expands the results of previous studies showing the efficiency of using NLP resources from neighboring languages for low-resourced languages.</abstract>
      <bibkey>rabus-scherrer-2017-lexicon</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/multext-east">MULTEXT-East</pwcdataset>
    </paper>
    <paper id="7">
      <title>Universal Dependencies for <a href="https://en.wikipedia.org/wiki/Serbian_language">Serbian</a> in Comparison with Croatian and Other Slavic Languages<fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies for <fixed-case>S</fixed-case>erbian in Comparison with <fixed-case>C</fixed-case>roatian and Other <fixed-case>S</fixed-case>lavic Languages</title>
      <author><first>Tanja</first><last>Samardžić</last></author>
      <author><first>Mirjana</first><last>Starović</last></author>
      <author><first>Željko</first><last>Agić</last></author>
      <author><first>Nikola</first><last>Ljubešić</last></author>
      <pages>39–44</pages>
      <url hash="20f1b36b">W17-1407</url>
      <doi>10.18653/v1/W17-1407</doi>
      <abstract>The paper documents the procedure of building a new Universal Dependencies (UDv2) treebank for <a href="https://en.wikipedia.org/wiki/Serbian_language">Serbian</a> starting from an existing Croatian UDv1 treebank and taking into account the other Slavic UD annotation guidelines. We describe the automatic and manual annotation procedures, discuss the annotation of Slavic-specific categories (case governing quantifiers, reflexive pronouns, question particles) and propose an approach to handling deverbal nouns in <a href="https://en.wikipedia.org/wiki/Slavic_languages">Slavic languages</a>.</abstract>
      <bibkey>samardzic-etal-2017-universal</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="8">
      <title>Spelling Correction for Morphologically Rich Language : a Case Study of <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a><fixed-case>R</fixed-case>ussian</title>
      <author><first>Alexey</first><last>Sorokin</last></author>
      <pages>45–53</pages>
      <url hash="c8b02884">W17-1408</url>
      <doi>10.18653/v1/W17-1408</doi>
      <abstract>We present an <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> for automatic correction of spelling errors on the <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentence level</a>, which uses noisy channel model and feature-based reranking of hypotheses. Our <a href="https://en.wikipedia.org/wiki/System">system</a> is designed for <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a> and clearly outperforms the winner of SpellRuEval-2016 competition. We show that language model size has the greatest influence on spelling correction quality. We also experiment with different types of <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> and show that morphological and semantic information also improves the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of <a href="https://en.wikipedia.org/wiki/Spell_checker">spellchecking</a>.</abstract>
      <bibkey>sorokin-2017-spelling</bibkey>
    </paper>
    <paper id="9">
      <title>Debunking Sentiment Lexicons : A Case of Domain-Specific Sentiment Classification for Croatian<fixed-case>C</fixed-case>roatian</title>
      <author><first>Paula</first><last>Gombar</last></author>
      <author><first>Zoran</first><last>Medić</last></author>
      <author><first>Domagoj</first><last>Alagić</last></author>
      <author><first>Jan</first><last>Šnajder</last></author>
      <pages>54–59</pages>
      <url hash="9b549b75">W17-1409</url>
      <doi>10.18653/v1/W17-1409</doi>
      <abstract>Sentiment lexicons are widely used as an intuitive and inexpensive way of tackling sentiment classification, often within a simple lexicon word-counting approach or as part of a supervised model. However, it is an open question whether these approaches can compete with <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised models</a> that use only word-representation features. We address this question in the context of domain-specific sentiment classification for <a href="https://en.wikipedia.org/wiki/Croatian_language">Croatian</a>. We experiment with the graph-based acquisition of sentiment lexicons, analyze their quality, and investigate how effectively they can be used in sentiment classification. Our results indicate that, even with as few as 500 labeled instances, a <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised model</a> substantially outperforms a word-counting model. We also observe that adding lexicon-based features does not significantly improve supervised sentiment classification.</abstract>
      <bibkey>gombar-etal-2017-debunking</bibkey>
    </paper>
    <paper id="10">
      <title>Adapting a State-of-the-Art <a href="https://en.wikipedia.org/wiki/Tagger">Tagger</a> for <a href="https://en.wikipedia.org/wiki/South_Slavic_languages">South Slavic Languages</a> to Non-Standard Text<fixed-case>S</fixed-case>outh <fixed-case>S</fixed-case>lavic Languages to Non-Standard Text</title>
      <author><first>Nikola</first><last>Ljubešić</last></author>
      <author><first>Tomaž</first><last>Erjavec</last></author>
      <author><first>Darja</first><last>Fišer</last></author>
      <pages>60–68</pages>
      <url hash="2d1b00ca">W17-1410</url>
      <doi>10.18653/v1/W17-1410</doi>
      <abstract>In this paper we present the adaptations of a state-of-the-art <a href="https://en.wikipedia.org/wiki/Tagger">tagger</a> for <a href="https://en.wikipedia.org/wiki/South_Slavic_languages">South Slavic languages</a> to <a href="https://en.wikipedia.org/wiki/Nonstandard_dialect">non-standard texts</a> on the example of the <a href="https://en.wikipedia.org/wiki/Slovene_language">Slovene language</a>. We investigate the impact of introducing in-domain training data as well as additional supervision through external resources or tools like word clusters and <a href="https://en.wikipedia.org/wiki/Word_normalization">word normalization</a>. We remove more than half of the error of the standard tagger when applied to non-standard texts by training it on a combination of standard and non-standard training data, while enriching the data representation with external resources removes additional 11 percent of the error. The final <a href="https://en.wikipedia.org/wiki/Computer_configuration">configuration</a> achieves tagging accuracy of 87.41 % on the full <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphosyntactic description</a>, which is, nevertheless, still quite far from the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 94.27 % achieved on standard text.</abstract>
      <bibkey>ljubesic-etal-2017-adapting</bibkey>
    </paper>
    <paper id="14">
      <title>Language-Independent Named Entity Analysis Using <a href="https://en.wikipedia.org/wiki/Parallel_projection">Parallel Projection</a> and Rule-Based Disambiguation</title>
      <author><first>James</first><last>Mayfield</last></author>
      <author><first>Paul</first><last>McNamee</last></author>
      <author><first>Cash</first><last>Costello</last></author>
      <pages>92–96</pages>
      <url hash="d516fa1b">W17-1414</url>
      <doi>10.18653/v1/W17-1414</doi>
      <abstract>The 2017 shared task at the Balto-Slavic NLP workshop requires identifying coarse-grained named entities in seven languages, identifying each entity’s base form, and clustering name mentions across the multilingual set of documents. The fact that no training data is provided to systems for building <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised classifiers</a> further adds to the <a href="https://en.wikipedia.org/wiki/Complexity">complexity</a>. To complete the task we first use publicly available parallel texts to project <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a> capability from <a href="https://en.wikipedia.org/wiki/English_language">English</a> to each evaluation language. We ignore entirely the subtask of identifying non-inflected forms of names. Finally, we create cross-document entity identifiers by clustering named mentions using a procedure-based approach.</abstract>
      <bibkey>mayfield-etal-2017-language</bibkey>
    </paper>
    <paper id="16">
      <title>Stylometric Analysis of Parliamentary Speeches : Gender Dimension</title>
      <author><first>Justina</first><last>Mandravickaitė</last></author>
      <author><first>Tomas</first><last>Krilavičius</last></author>
      <pages>102–107</pages>
      <url hash="421ec654">W17-1416</url>
      <doi>10.18653/v1/W17-1416</doi>
      <abstract>Relation between <a href="https://en.wikipedia.org/wiki/Gender">gender</a> and language has been studied by many authors, however, there is still some uncertainty left regarding gender influence on <a href="https://en.wikipedia.org/wiki/Usage_(language)">language usage</a> in the professional environment. Often, the studied data sets are too small or texts of individual authors are too short in order to capture differences of language usage wrt gender successfully. This study draws from a larger corpus of speeches transcripts of the Lithuanian Parliament (1990-2013) to explore language differences of political debates by gender via stylometric analysis. Experimental set up consists of stylistic features that indicate lexical style and do not require external linguistic tools, namely the most frequent words, in combination with unsupervised machine learning algorithms. Results show that gender differences in the language use remain in professional environment not only in usage of <a href="https://en.wikipedia.org/wiki/Function_word">function words</a>, preferred <a href="https://en.wikipedia.org/wiki/Construct_(philosophy)">linguistic constructions</a>, but in the presented topics as well.</abstract>
      <bibkey>mandravickaite-krilavicius-2017-stylometric</bibkey>
    </paper>
    <paper id="18">
      <title>Gender Profiling for Slovene Twitter communication : the Influence of Gender Marking, Content and Style<fixed-case>S</fixed-case>lovene <fixed-case>T</fixed-case>witter communication: the Influence of Gender Marking, Content and Style</title>
      <author><first>Ben</first><last>Verhoeven</last></author>
      <author><first>Iza</first><last>Škrjanec</last></author>
      <author><first>Senja</first><last>Pollak</last></author>
      <pages>119–125</pages>
      <url hash="3988d5d0">W17-1418</url>
      <doi>10.18653/v1/W17-1418</doi>
      <abstract>We present results of the first <a href="https://en.wikipedia.org/wiki/Sex_and_gender_distinction">gender classification</a> experiments on <a href="https://en.wikipedia.org/wiki/Slovene_language">Slovene text</a> to our knowledge. Inspired by the TwiSty corpus and experiments (Verhoeven et al., 2016), we employed the Janes corpus (Erjavec et al., 2016) and its gender annotations to perform gender classification experiments on Twitter text comparing a token-based and a lemma-based approach. We find that the token-based approach (92.6 % accuracy), containing <a href="https://en.wikipedia.org/wiki/Gender">gender markings</a> related to the author, outperforms the lemma-based approach by about 5 %. Especially in the lemmatized version, we also observe stylistic and content-based differences in writing between men (e.g. more profane language, <a href="https://en.wikipedia.org/wiki/Numeral_(linguistics)">numerals</a> and beer mentions) and <a href="https://en.wikipedia.org/wiki/Woman">women</a> (e.g. more <a href="https://en.wikipedia.org/wiki/Pronoun">pronouns</a>, <a href="https://en.wikipedia.org/wiki/Emoticon">emoticons</a> and character flooding). Many of our findings corroborate previous research on other languages.</abstract>
      <bibkey>verhoeven-etal-2017-gender</bibkey>
    </paper>
  </volume>
  <volume id="15">
    <meta>
      <booktitle>Proceedings of the 2nd Workshop on Coreference Resolution Beyond <fixed-case>O</fixed-case>nto<fixed-case>N</fixed-case>otes (<fixed-case>CORBON</fixed-case> 2017)</booktitle>
      <url hash="42fcec85">W17-15</url>
      <editor><first>Maciej</first><last>Ogrodniczuk</last></editor>
      <editor><first>Vincent</first><last>Ng</last></editor>
      <doi>10.18653/v1/W17-15</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="f40a691c">W17-1500</url>
      <bibkey>ws-2017-coreference</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Use Generalized Representations, But Do Not Forget Surface Features</title>
      <author><first>Nafise Sadat</first><last>Moosavi</last></author>
      <author><first>Michael</first><last>Strube</last></author>
      <pages>1–7</pages>
      <url hash="7697b515">W17-1501</url>
      <doi>10.18653/v1/W17-1501</doi>
      <abstract>Only a year ago, all state-of-the-art coreference resolvers were using an extensive amount of surface features. Recently, there was a paradigm shift towards using <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> and <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural networks</a>, where the use of surface features is very limited. In this paper, we show that a simple SVM model with <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">surface features</a> outperforms more complex neural models for detecting anaphoric mentions. Our analysis suggests that using generalized representations and surface features have different strength that should be both taken into account for improving <a href="https://en.wikipedia.org/wiki/Coreference_resolution">coreference resolution</a>.</abstract>
      <bibkey>moosavi-strube-2017-use</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wikicoref">WikiCoref</pwcdataset>
    </paper>
    <paper id="2">
      <title>Enriching Basque Coreference Resolution System using Semantic Knowledge sources<fixed-case>B</fixed-case>asque Coreference Resolution System using Semantic Knowledge sources</title>
      <author><first>Ander</first><last>Soraluze</last></author>
      <author><first>Olatz</first><last>Arregi</last></author>
      <author><first>Xabier</first><last>Arregi</last></author>
      <author><first>Arantza</first><last>Díaz de Ilarraza</last></author>
      <pages>8–16</pages>
      <url hash="6783baa1">W17-1502</url>
      <doi>10.18653/v1/W17-1502</doi>
      <abstract>In this paper we present a Basque coreference resolution system enriched with semantic knowledge. An <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error analysis</a> carried out revealed the deficiencies that the <a href="https://en.wikipedia.org/wiki/System">system</a> had in resolving coreference cases in which semantic or world knowledge is needed. We attempt to improve the deficiencies using two semantic knowledge sources, specifically <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a> and <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a>.</abstract>
      <bibkey>soraluze-etal-2017-enriching</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/yago">YAGO</pwcdataset>
    </paper>
    <paper id="3">
      <title>Improving Polish Mention Detection with Valency Dictionary<fixed-case>P</fixed-case>olish Mention Detection with Valency Dictionary</title>
      <author><first>Maciej</first><last>Ogrodniczuk</last></author>
      <author><first>Bartłomiej</first><last>Nitoń</last></author>
      <pages>17–23</pages>
      <url hash="9f053269">W17-1503</url>
      <doi>10.18653/v1/W17-1503</doi>
      <abstract>This paper presents results of an experiment integrating information from valency dictionary of Polish into a mention detection system. Two types of information is acquired : positions of syntactic schemata for nominal and verbal constructs and secondary prepositions present in schemata. The syntactic schemata are used to prevent (for verbal realizations) or encourage (for nominal groups) constructing mentions from phrases filling multiple schema positions, the secondary prepositions   to filter out artificial mentions created from their nominal components. Mention detection is evaluated against the manual annotation of the Polish Coreference Corpus in two settings : taking into account only mention heads or exact borders.</abstract>
      <bibkey>ogrodniczuk-niton-2017-improving</bibkey>
    </paper>
    <paper id="4">
      <title>A Google-Proof Collection of French Winograd Schemas<fixed-case>G</fixed-case>oogle-Proof Collection of <fixed-case>F</fixed-case>rench <fixed-case>W</fixed-case>inograd Schemas</title>
      <author><first>Pascal</first><last>Amsili</last></author>
      <author><first>Olga</first><last>Seminck</last></author>
      <pages>24–29</pages>
      <url hash="69f9bf0c">W17-1504</url>
      <doi>10.18653/v1/W17-1504</doi>
      <abstract>This article presents the first collection of French Winograd Schemas. Winograd Schemas form anaphora resolution problems that can only be resolved with extensive <a href="https://en.wikipedia.org/wiki/World_knowledge">world knowledge</a>. For this reason the <a href="https://en.wikipedia.org/wiki/Winograd_Schema_Challenge">Winograd Schema Challenge</a> has been proposed as an alternative to the <a href="https://en.wikipedia.org/wiki/Turing_test">Turing Test</a>. A very important feature of Winograd Schemas is that it should be impossible to resolve them with statistical information about word co-occurrences : they should be Google-proof. We propose a measure of Google-proofness based on <a href="https://en.wikipedia.org/wiki/Mutual_information">Mutual Information</a>, and demonstrate the method on our collection of French Winograd Schemas.</abstract>
      <bibkey>amsili-seminck-2017-google</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wsc">WSC</pwcdataset>
    </paper>
    <paper id="6">
      <title>Multi-source annotation projection of coreference chains : assessing strategies and testing opportunities</title>
      <author><first>Yulia</first><last>Grishina</last></author>
      <author><first>Manfred</first><last>Stede</last></author>
      <pages>41–50</pages>
      <url hash="09e06672">W17-1506</url>
      <doi>10.18653/v1/W17-1506</doi>
      <abstract>In this paper, we examine the possibility of using annotation projection from multiple sources for automatically obtaining coreference annotations in the target language. We implement a multi-source annotation projection algorithm and apply it on an English-German-Russian parallel corpus in order to transfer coreference chains from two sources to the target side. Operating in two settings   a low-resource and a more linguistically-informed one   we show that automatic coreference transfer could benefit from combining information from multiple languages, and assess the quality of both the extraction and the linking of target coreference mentions.</abstract>
      <bibkey>grishina-stede-2017-multi</bibkey>
    </paper>
    <paper id="7">
      <title>CORBON 2017 Shared Task : Projection-Based Coreference Resolution<fixed-case>CORBON</fixed-case> 2017 Shared Task: Projection-Based Coreference Resolution</title>
      <author><first>Yulia</first><last>Grishina</last></author>
      <pages>51–55</pages>
      <url hash="0d97168b">W17-1507</url>
      <doi>10.18653/v1/W17-1507</doi>
      <abstract>The CORBON 2017 Shared Task, organised as part of the Coreference Resolution Beyond OntoNotes workshop at EACL 2017, presented a new challenge for multilingual coreference resolution : we offer a projection-based setting in which one is supposed to build a coreference resolver for a new language exploiting little or even no knowledge of it, with our languages of interest being <a href="https://en.wikipedia.org/wiki/German_language">German</a> and <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a>. We additionally offer a more traditional setting, targeting the development of a multilingual coreference resolver without any restrictions on the resources and methods used. In this paper, we describe the task setting and provide the results of one participant who successfully completed the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, comparing their results to the closely related previous research. Analysing the task setting and the results, we discuss the major challenges and make suggestions on the future directions of coreference evaluation.</abstract>
      <bibkey>grishina-2017-corbon</bibkey>
    </paper>
    <paper id="8">
      <title>Projection-based Coreference Resolution Using Deep Syntax</title>
      <author><first>Michal</first><last>Novák</last></author>
      <author><first>Anna</first><last>Nedoluzhko</last></author>
      <author><first>Zdeněk</first><last>Žabokrtský</last></author>
      <pages>56–64</pages>
      <url hash="4b0c7035">W17-1508</url>
      <doi>10.18653/v1/W17-1508</doi>
      <abstract>The paper describes the system for <a href="https://en.wikipedia.org/wiki/Coreference_resolution">coreference resolution</a> in <a href="https://en.wikipedia.org/wiki/German_language">German</a> and <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a>, trained exclusively on coreference relations project ed through a parallel corpus from <a href="https://en.wikipedia.org/wiki/English_language">English</a>. The <a href="https://en.wikipedia.org/wiki/Resolver">resolver</a> operates on the level of deep syntax and makes use of multiple specialized models. It achieves 32 and 22 points in terms of CoNLL score for <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a> and <a href="https://en.wikipedia.org/wiki/German_language">German</a>, respectively. Analysis of the evaluation results show that the <a href="https://en.wikipedia.org/wiki/Resolver">resolver</a> for <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a> is able to preserve 66 % of the English resolver’s quality in terms of CoNLL score. The <a href="https://en.wikipedia.org/wiki/System">system</a> was submitted to the Closed track of the CORBON 2017 Shared task.</abstract>
      <bibkey>novak-etal-2017-projection</bibkey>
    </paper>
  </volume>
  <volume id="16">
    <meta>
      <booktitle>Proceedings of the First <fixed-case>ACL</fixed-case> Workshop on Ethics in Natural Language Processing</booktitle>
      <url hash="5b5ad02e">W17-16</url>
      <editor><first>Dirk</first><last>Hovy</last></editor>
      <editor><first>Shannon</first><last>Spruit</last></editor>
      <editor><first>Margaret</first><last>Mitchell</last></editor>
      <editor><first>Emily M.</first><last>Bender</last></editor>
      <editor><first>Michael</first><last>Strube</last></editor>
      <editor><first>Hanna</first><last>Wallach</last></editor>
      <doi>10.18653/v1/W17-16</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="5dc62836">W17-1600</url>
      <bibkey>ws-2017-acl</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Gender as a Variable in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural-Language Processing</a> : Ethical Considerations</title>
      <author><first>Brian</first><last>Larson</last></author>
      <pages>1–11</pages>
      <url hash="97117781">W17-1601</url>
      <doi>10.18653/v1/W17-1601</doi>
      <abstract>Researchers and practitioners in natural-language processing (NLP) and related fields should attend to ethical principles in study design, ascription of categories / variables to study participants, and reporting of findings or results. This paper discusses theoretical and ethical frameworks for using <a href="https://en.wikipedia.org/wiki/Gender">gender</a> as a variable in NLP studies and proposes four guidelines for researchers and practitioners. The principles outlined here should guide practitioners, researchers, and peer reviewers, and they may be applicable to other <a href="https://en.wikipedia.org/wiki/Social_class">social categories</a>, such as <a href="https://en.wikipedia.org/wiki/Race_(human_categorization)">race</a>, applied to human beings connected to <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP research</a>.</abstract>
      <bibkey>larson-2017-gender</bibkey>
    </paper>
    <paper id="2">
      <title>These are not the Stereotypes You are Looking For : Bias and Fairness in Authorial Gender Attribution</title>
      <author><first>Corina</first><last>Koolen</last></author>
      <author><first>Andreas</first><last>van Cranenburgh</last></author>
      <pages>12–22</pages>
      <url hash="c4d77077">W17-1602</url>
      <doi>10.18653/v1/W17-1602</doi>
      <abstract>Stylometric and text categorization results show that author gender can be discerned in texts with relatively high <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>. However, it is difficult to explain what gives rise to these results and there are many possible <a href="https://en.wikipedia.org/wiki/Confounding">confounding factors</a>, such as the domain, genre, and target audience of a text. More fundamentally, such classification efforts risk invoking <a href="https://en.wikipedia.org/wiki/Stereotype">stereotyping</a> and <a href="https://en.wikipedia.org/wiki/Essentialism">essentialism</a>. We explore this issue in two datasets of Dutch literary novels, using commonly used descriptive (LIWC, topic modeling) and predictive (machine learning) methods. Our results show the importance of controlling for variables in the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> and we argue for taking care not to overgeneralize from the results.</abstract>
      <bibkey>koolen-van-cranenburgh-2017-stereotypes</bibkey>
    </paper>
    <paper id="3">
      <title>A Quantitative Study of Data in the NLP community<fixed-case>NLP</fixed-case> community</title>
      <author><first>Margot</first><last>Mieskes</last></author>
      <pages>23–29</pages>
      <url hash="ec488f0b">W17-1603</url>
      <doi>10.18653/v1/W17-1603</doi>
      <abstract>We present results on a quantitative analysis of publications in the NLP domain on collecting, publishing and availability of research data. We find that a wide range of publications rely on data crawled from the <a href="https://en.wikipedia.org/wiki/World_Wide_Web">web</a>, but few give details on how potentially sensitive data was treated. Additionally, we find that while links to repositories of data are given, they often do not work even a short time after publication. We put together several suggestions on how to improve this situation based on publications from the <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP domain</a>, but also other research areas.</abstract>
      <bibkey>mieskes-2017-quantitative</bibkey>
    </paper>
    <paper id="4">
      <title>Ethical by Design : Ethics Best Practices for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a></title>
      <author><first>Jochen L.</first><last>Leidner</last></author>
      <author><first>Vassilis</first><last>Plachouras</last></author>
      <pages>30–40</pages>
      <url hash="ad5dbabe">W17-1604</url>
      <doi>10.18653/v1/W17-1604</doi>
      <abstract>Natural language processing (NLP) systems analyze and/or generate <a href="https://en.wikipedia.org/wiki/Human_language">human language</a>, typically on users’ behalf. One natural and necessary question that needs to be addressed in this context, both in research projects and in production settings, is the question how ethical the work is, both regarding the process and its outcome. Towards this end, we articulate a set of issues, propose a set of best practices, notably a process featuring an ethics review board, and sketch and how they could be meaningfully applied. Our main argument is that ethical outcomes ought to be achieved by design, i.e. by following a process aligned by <a href="https://en.wikipedia.org/wiki/Value_(ethics)">ethical values</a>. We also offer some response options for those facing <a href="https://en.wikipedia.org/wiki/Ethics">ethics issues</a>. While a number of previous works exist that discuss ethical issues, in particular around <a href="https://en.wikipedia.org/wiki/Big_data">big data</a> and <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a>, to the authors’ knowledge this is the first account of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> and <a href="https://en.wikipedia.org/wiki/Ethics">ethics</a> from the perspective of a principled process.</abstract>
      <bibkey>leidner-plachouras-2017-ethical</bibkey>
    </paper>
    <paper id="6">
      <title>Gender and Dialect Bias in YouTube’s Automatic Captions<fixed-case>Y</fixed-case>ou<fixed-case>T</fixed-case>ube’s Automatic Captions</title>
      <author><first>Rachael</first><last>Tatman</last></author>
      <pages>53–59</pages>
      <url hash="300ce7fd">W17-1606</url>
      <doi>10.18653/v1/W17-1606</doi>
      <abstract>This project evaluates the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of YouTube’s automatically-generated captions across two genders and five dialect groups. Speakers’ dialect and gender was controlled for by using videos uploaded as part of the accent tag challenge, where speakers explicitly identify their language background. The results show robust differences in <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> across both gender and dialect, with lower <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> for 1) women and 2) speakers from Scotland. This finding builds on earlier research finding that speaker’s sociolinguistic identity may negatively impact their ability to use automatic speech recognition, and demonstrates the need for sociolinguistically-stratified validation of systems.</abstract>
      <bibkey>tatman-2017-gender</bibkey>
    </paper>
    <paper id="7">
      <title>Integrating the Management of Personal Data Protection and <a href="https://en.wikipedia.org/wiki/Open_science">Open Science</a> with Research Ethics</title>
      <author><first>Dave</first><last>Lewis</last></author>
      <author><first>Joss</first><last>Moorkens</last></author>
      <author><first>Kaniz</first><last>Fatema</last></author>
      <pages>60–65</pages>
      <url hash="2136a977">W17-1607</url>
      <doi>10.18653/v1/W17-1607</doi>
      <abstract>We examine the impact of the <a href="https://en.wikipedia.org/wiki/General_Data_Protection_Regulation">EU General Data Protection Regulation</a> and the push from research funders to provide open access research data on the current practices in Language Technology Research. We analyse the challenges that arise and the opportunities to address many of them through the use of existing open data practices. We discuss the impact of this also on current practice in <a href="https://en.wikipedia.org/wiki/Research_ethics">research ethics</a>.</abstract>
      <bibkey>lewis-etal-2017-integrating</bibkey>
    </paper>
    <paper id="8">
      <title>Ethical Considerations in NLP Shared Tasks<fixed-case>NLP</fixed-case> Shared Tasks</title>
      <author><first>Carla</first><last>Parra Escartín</last></author>
      <author><first>Wessel</first><last>Reijers</last></author>
      <author><first>Teresa</first><last>Lynn</last></author>
      <author><first>Joss</first><last>Moorkens</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <author><first>Chao-Hong</first><last>Liu</last></author>
      <pages>66–73</pages>
      <url hash="ad0f2fa1">W17-1608</url>
      <doi>10.18653/v1/W17-1608</doi>
      <abstract>Shared tasks are increasingly common in our field, and new challenges are suggested at almost every conference and workshop. However, as this has become an established way of pushing research forward, it is important to discuss how we researchers organise and participate in shared tasks, and make that information available to the community to allow further research improvements. In this paper, we present a number of <a href="https://en.wikipedia.org/wiki/Ethics">ethical issues</a> along with other areas of concern that are related to the competitive nature of shared tasks. As such issues could potentially impact on research ethics in the Natural Language Processing community, we also propose the development of a framework for the organisation of and participation in shared tasks that can help mitigate against these issues arising.</abstract>
      <bibkey>parra-escartin-etal-2017-ethical</bibkey>
    </paper>
    <paper id="9">
      <title>Social Bias in Elicited Natural Language Inferences</title>
      <author><first>Rachel</first><last>Rudinger</last></author>
      <author><first>Chandler</first><last>May</last></author>
      <author><first>Benjamin</first><last>Van Durme</last></author>
      <pages>74–79</pages>
      <url hash="8b788f2d">W17-1609</url>
      <doi>10.18653/v1/W17-1609</doi>
      <abstract>We analyze the Stanford Natural Language Inference (SNLI) corpus in an investigation of bias and stereotyping in NLP data. The SNLI human-elicitation protocol makes it prone to amplifying bias and stereotypical associations, which we demonstrate statistically (using pointwise mutual information) and with qualitative examples.</abstract>
      <bibkey>rudinger-etal-2017-social</bibkey>
      <pwccode url="https://github.com/cjmay/snli-ethics" additional="false">cjmay/snli-ethics</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="10">
      <title>A Short Review of Ethical Challenges in Clinical Natural Language Processing</title>
      <author><first>Simon</first><last>Šuster</last></author>
      <author><first>Stéphan</first><last>Tulkens</last></author>
      <author><first>Walter</first><last>Daelemans</last></author>
      <pages>80–87</pages>
      <url hash="586abf15">W17-1610</url>
      <doi>10.18653/v1/W17-1610</doi>
      <abstract>Clinical NLP has an immense potential in contributing to how clinical practice will be revolutionized by the advent of large scale processing of clinical records. However, this potential has remained largely untapped due to slow progress primarily caused by strict data access policies for researchers. In this paper, we discuss the concern for <a href="https://en.wikipedia.org/wiki/Privacy">privacy</a> and the measures it entails. We also suggest sources of less sensitive data. Finally, we draw attention to biases that can compromise the validity of empirical research and lead to socially harmful applications.</abstract>
      <bibkey>suster-etal-2017-short</bibkey>
    </paper>
    <paper id="11">
      <title>Goal-Oriented Design for Ethical Machine Learning and NLP<fixed-case>NLP</fixed-case></title>
      <author><first>Tyler</first><last>Schnoebelen</last></author>
      <pages>88–93</pages>
      <url hash="ae06eadb">W17-1611</url>
      <doi>10.18653/v1/W17-1611</doi>
      <abstract>The argument made in this paper is that to act ethically in <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a> and <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> requires focusing on goals. NLP projects are often classificatory systems that deal with <a href="https://en.wikipedia.org/wiki/Human_subject_research">human subjects</a>, which means that goals from people affected by the <a href="https://en.wikipedia.org/wiki/System">systems</a> should be included. The paper takes as its core example a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> that detects <a href="https://en.wikipedia.org/wiki/Crime">criminality</a>, showing the problems of training data, categories, and outcomes. The paper is oriented to the kinds of critiques on <a href="https://en.wikipedia.org/wiki/Power_(social_and_political)">power</a> and the reproduction of inequality that are found in <a href="https://en.wikipedia.org/wiki/Social_theory">social theory</a>, but it also includes concrete suggestions on how to put goal-oriented design into practice.</abstract>
      <bibkey>schnoebelen-2017-goal</bibkey>
    </paper>
    <paper id="12">
      <title>Ethical Research Protocols for Social Media Health Research</title>
      <author><first>Adrian</first><last>Benton</last></author>
      <author><first>Glen</first><last>Coppersmith</last></author>
      <author><first>Mark</first><last>Dredze</last></author>
      <pages>94–102</pages>
      <url hash="f126542f">W17-1612</url>
      <doi>10.18653/v1/W17-1612</doi>
      <abstract>Social media have transformed data-driven research in <a href="https://en.wikipedia.org/wiki/Political_science">political science</a>, the <a href="https://en.wikipedia.org/wiki/Social_science">social sciences</a>, <a href="https://en.wikipedia.org/wiki/Health">health</a>, and <a href="https://en.wikipedia.org/wiki/Medicine">medicine</a>. Since <a href="https://en.wikipedia.org/wiki/Medical_research">health research</a> often touches on sensitive topics that relate to ethics of treatment and patient privacy, similar ethical considerations should be acknowledged when using social media data in <a href="https://en.wikipedia.org/wiki/Medical_research">health research</a>. While much has been said regarding the ethical considerations of social media research, <a href="https://en.wikipedia.org/wiki/Medical_research">health research</a> leads to an additional set of concerns. We provide practical suggestions in the form of guidelines for researchers working with social media data in <a href="https://en.wikipedia.org/wiki/Medical_research">health research</a>. These guidelines can inform an IRB proposal for researchers new to social media health research.</abstract>
      <bibkey>benton-etal-2017-ethical</bibkey>
    </paper>
    <paper id="13">
      <title>Say the Right Thing Right : Ethics Issues in Natural Language Generation Systems</title>
      <author><first>Charese</first><last>Smiley</last></author>
      <author><first>Frank</first><last>Schilder</last></author>
      <author><first>Vassilis</first><last>Plachouras</last></author>
      <author><first>Jochen L.</first><last>Leidner</last></author>
      <pages>103–108</pages>
      <url hash="ec8f9af3">W17-1613</url>
      <doi>10.18653/v1/W17-1613</doi>
      <abstract>We discuss the ethical implications of <a href="https://en.wikipedia.org/wiki/Natural-language_generation">Natural Language Generation systems</a>. We use one particular <a href="https://en.wikipedia.org/wiki/System">system</a> as a case study to identify and classify issues, and we provide an ethics checklist, in the hope that future system designers may benefit from conducting their own ethics reviews based on our checklist.</abstract>
      <bibkey>smiley-etal-2017-say</bibkey>
    </paper>
  </volume>
  <volume id="17">
    <meta>
      <booktitle>Proceedings of the 13th Workshop on Multiword Expressions (<fixed-case>MWE</fixed-case> 2017)</booktitle>
      <url hash="af17a21d">W17-17</url>
      <editor><first>Stella</first><last>Markantonatou</last></editor>
      <editor><first>Carlos</first><last>Ramisch</last></editor>
      <editor><first>Agata</first><last>Savary</last></editor>
      <editor><first>Veronika</first><last>Vincze</last></editor>
      <doi>10.18653/v1/W17-17</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="4b7b3dad">W17-1700</url>
      <bibkey>ws-2017-multiword</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Multi-word Entity Classification in a Highly Multilingual Environment</title>
      <author><first>Sophie</first><last>Chesney</last></author>
      <author><first>Guillaume</first><last>Jacquet</last></author>
      <author><first>Ralf</first><last>Steinberger</last></author>
      <author><first>Jakub</first><last>Piskorski</last></author>
      <pages>11–20</pages>
      <url hash="26be3800">W17-1702</url>
      <doi>10.18653/v1/W17-1702</doi>
      <abstract>This paper describes an approach for the classification of millions of existing multi-word entities (MWEntities), such as organisation or event names, into thirteen category types, based only on the tokens they contain. In order to classify our very large in-house collection of multilingual MWEntities into an application-oriented set of entity categories, we trained and tested distantly-supervised classifiers in 43 languages based on MWEntities extracted from <a href="https://en.wikipedia.org/wiki/BabelNet">BabelNet</a>. The best-performing <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> was the multi-class SVM using a TF.IDF-weighted data representation. Interestingly, one unique <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> trained on a mix of all languages consistently performed better than <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> trained for individual languages, reaching an averaged F1-value of 88.8 %. In this paper, we present the <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training and test data</a>, including a human evaluation of its <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>, describe the methods used to train the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a>, and discuss the results.</abstract>
      <bibkey>chesney-etal-2017-multi</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/dbpedia">DBpedia</pwcdataset>
    </paper>
    <paper id="3">
      <title>Using bilingual word-embeddings for multilingual collocation extraction</title>
      <author><first>Marcos</first><last>Garcia</last></author>
      <author><first>Marcos</first><last>García-Salido</last></author>
      <author><first>Margarita</first><last>Alonso-Ramos</last></author>
      <pages>21–30</pages>
      <url hash="43da10d3">W17-1703</url>
      <doi>10.18653/v1/W17-1703</doi>
      <abstract>This paper presents a new strategy for multilingual collocation extraction which takes advantage of parallel corpora to learn bilingual word-embeddings. Monolingual collocation candidates are retrieved using Universal Dependencies, while the distributional models are then applied to search for equivalents of the elements of each collocation in the target languages. The proposed method extracts not only collocation equivalents with direct translation between languages, but also other cases where the <a href="https://en.wikipedia.org/wiki/Collocation">collocations</a> in the two languages are not literal translations of each other. Several experiments -evaluating collocations with three syntactic patterns- in <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, and <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a> show that our approach can effectively extract large pairs of bilingual equivalents with an average precision of about 90 %. Moreover, preliminary results on comparable corpora suggest that the distributional models can be applied for identifying new bilingual collocations in different domains.</abstract>
      <bibkey>garcia-etal-2017-using</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/opensubtitles">OpenSubtitles</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="4">
      <title>The PARSEME Shared Task on Automatic Identification of Verbal Multiword Expressions<fixed-case>PARSEME</fixed-case> Shared Task on Automatic Identification of Verbal Multiword Expressions</title>
      <author><first>Agata</first><last>Savary</last></author>
      <author><first>Carlos</first><last>Ramisch</last></author>
      <author><first>Silvio</first><last>Cordeiro</last></author>
      <author><first>Federico</first><last>Sangati</last></author>
      <author><first>Veronika</first><last>Vincze</last></author>
      <author><first>Behrang</first><last>QasemiZadeh</last></author>
      <author><first>Marie</first><last>Candito</last></author>
      <author><first>Fabienne</first><last>Cap</last></author>
      <author><first>Voula</first><last>Giouli</last></author>
      <author><first>Ivelina</first><last>Stoyanova</last></author>
      <author><first>Antoine</first><last>Doucet</last></author>
      <pages>31–47</pages>
      <url hash="7fa7b0f5">W17-1704</url>
      <doi>10.18653/v1/W17-1704</doi>
      <abstract>Multiword expressions (MWEs) are known as a pain in the neck for <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP</a> due to their idiosyncratic behaviour. While some categories of MWEs have been addressed by many studies, verbal MWEs (VMWEs), such as to take a decision, to break one’s heart or to turn off, have been rarely modelled. This is notably due to their syntactic variability, which hinders treating them as words with spaces. We describe an initiative meant to bring about substantial progress in understanding, modelling and processing VMWEs. It is a joint effort, carried out within a European research network, to elaborate universal terminologies and annotation guidelines for 18 languages. Its main outcome is a multilingual 5-million-word annotated corpus which underlies a shared task on automatic identification of VMWEs. This paper presents the corpus annotation methodology and outcome, the shared task organisation and the results of the participating systems.</abstract>
      <bibkey>savary-etal-2017-parseme</bibkey>
    </paper>
    <paper id="7">
      <title>Neural Networks for Multi-Word Expression Detection</title>
      <author><first>Natalia</first><last>Klyueva</last></author>
      <author><first>Antoine</first><last>Doucet</last></author>
      <author><first>Milan</first><last>Straka</last></author>
      <pages>60–65</pages>
      <url hash="411ea760">W17-1707</url>
      <doi>10.18653/v1/W17-1707</doi>
      <abstract>In this paper we describe the MUMULS system that participated to the 2017 shared task on automatic identification of verbal multiword expressions (VMWEs). The MUMULS system was implemented using a <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised approach</a> based on <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural networks</a> using the open source library <a href="https://en.wikipedia.org/wiki/TensorFlow">TensorFlow</a>. The <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> was trained on a <a href="https://en.wikipedia.org/wiki/Data_set">data set</a> containing annotated VMWEs as well as <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological and syntactic information</a>. The MUMULS system performed the identification of VMWEs in 15 languages, it was one of few systems that could categorize VMWEs type in nearly all languages.</abstract>
      <bibkey>klyueva-etal-2017-neural</bibkey>
    </paper>
    <paper id="8">
      <title>Factoring Ambiguity out of the Prediction of Compositionality for German Multi-Word Expressions<fixed-case>G</fixed-case>erman Multi-Word Expressions</title>
      <author><first>Stefan</first><last>Bott</last></author>
      <author><first>Sabine</first><last>Schulte im Walde</last></author>
      <pages>66–72</pages>
      <url hash="fd546d6b">W17-1708</url>
      <doi>10.18653/v1/W17-1708</doi>
      <abstract>Ambiguity represents an obstacle for distributional semantic models(DSMs), which typically subsume the contexts of all word senses within one vector. While individual vector space approaches have been concerned with sense discrimination (e.g., Schtze 1998, Erk 2009, Erk and Pado 2010), such <a href="https://en.wikipedia.org/wiki/Discrimination">discrimination</a> has rarely been integrated into DSMs across <a href="https://en.wikipedia.org/wiki/Semantic_analysis_(linguistics)">semantic tasks</a>. This paper presents a soft-clustering approach to sense discrimination that filters sense-irrelevant features when predicting the degrees of compositionality for German noun-noun compounds and German particle verbs.</abstract>
      <bibkey>bott-schulte-im-walde-2017-factoring</bibkey>
    </paper>
    <paper id="9">
      <title>Multiword expressions and lexicalism : the view from LFG<fixed-case>LFG</fixed-case></title>
      <author><first>Jamie Y.</first><last>Findlay</last></author>
      <pages>73–79</pages>
      <url hash="2ad5af34">W17-1709</url>
      <doi>10.18653/v1/W17-1709</doi>
      <abstract>Multiword expressions (MWEs) pose a problem for lexicalist theories like Lexical Functional Grammar (LFG), since they are prima facie counterexamples to a strong form of the lexical integrity principle, which entails that a lexical item can only be realised as a single, syntactically atomic word. In this paper, I demonstrate some of the problems facing any strongly lexicalist account of MWEs, and argue that the lexical integrity principle must be weakened. I conclude by sketching a <a href="https://en.wikipedia.org/wiki/Formalism_(philosophy_of_mathematics)">formalism</a> which integrates a Tree Adjoining Grammar into the LFG architecture, taking advantage of this relaxation.</abstract>
      <bibkey>findlay-2017-multiword</bibkey>
    </paper>
    <paper id="10">
      <title>Understanding Idiomatic Variation</title>
      <author><first>Kristina</first><last>Geeraert</last></author>
      <author><first>R. Harald</first><last>Baayen</last></author>
      <author><first>John</first><last>Newman</last></author>
      <pages>80–90</pages>
      <url hash="b6e1657f">W17-1710</url>
      <doi>10.18653/v1/W17-1710</doi>
      <abstract>This study investigates the processing of <a href="https://en.wikipedia.org/wiki/Idiom_(language_structure)">idiomatic variants</a> through an eye-tracking experiment. Four types of idiom variants were included, in addition to the <a href="https://en.wikipedia.org/wiki/Canonical_form">canonical form</a> and the <a href="https://en.wikipedia.org/wiki/Literal_and_figurative_language">literal meaning</a>. Results suggest that modifications to <a href="https://en.wikipedia.org/wiki/Idiom_(language_structure)">idioms</a>, modulo obvious effects of length differences, are not more difficult to process than the canonical forms themselves. This fits with recent corpus findings.</abstract>
      <bibkey>geeraert-etal-2017-understanding</bibkey>
    </paper>
    <paper id="11">
      <title>Discovering Light Verb Constructions and their Translations from Parallel Corpora without Word Alignment</title>
      <author><first>Natalie</first><last>Vargas</last></author>
      <author><first>Carlos</first><last>Ramisch</last></author>
      <author><first>Helena</first><last>Caseli</last></author>
      <pages>91–96</pages>
      <url hash="79212021">W17-1711</url>
      <doi>10.18653/v1/W17-1711</doi>
      <abstract>We propose a method for joint unsupervised discovery of multiword expressions (MWEs) and their translations from parallel corpora. First, we apply independent monolingual MWE extraction in source and target languages simultaneously. Then, we calculate translation probability, association score and distributional similarity of co-occurring pairs. Finally, we rank all <a href="https://en.wikipedia.org/wiki/Translation_(geometry)">translations</a> of a given MWE using a linear combination of these features. Preliminary experiments on light verb constructions show promising results.</abstract>
      <bibkey>vargas-etal-2017-discovering</bibkey>
    </paper>
    <paper id="13">
      <title>Show Me Your Variance and I Tell You Who You Are-Deriving Compound Compositionality from Word Alignments<fixed-case>I</fixed-case> Tell You Who You Are - Deriving Compound Compositionality from Word Alignments</title>
      <author><first>Fabienne</first><last>Cap</last></author>
      <pages>102–107</pages>
      <url hash="3e25b4f8">W17-1713</url>
      <doi>10.18653/v1/W17-1713</doi>
      <abstract>We use word alignment variance as an indicator for the <a href="https://en.wikipedia.org/wiki/Compound_(linguistics)">non-compositionality</a> of German and English noun compounds. Our work-in-progress results are on their own not competitive with state-of-the art approaches, but they show that alignment variance is correlated with <a href="https://en.wikipedia.org/wiki/Compositionality">compositionality</a> and thus worth a closer look in the future.</abstract>
      <bibkey>cap-2017-show</bibkey>
    </paper>
    <paper id="14">
      <title>Semantic annotation to characterize contextual variation in terminological noun compounds : a pilot study</title>
      <author><first>Melania</first><last>Cabezas-García</last></author>
      <author><first>Antonio</first><last>San Martín</last></author>
      <pages>108–113</pages>
      <url hash="cdaede6d">W17-1714</url>
      <doi>10.18653/v1/W17-1714</doi>
      <abstract>Noun compounds (NCs) are semantically complex and not fully compositional, as is often assumed. This paper presents a pilot study regarding the semantic annotation of environmental NCs with a view to accessing their <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> and exploring their domain-based contextual variation. Our results showed that the semantic annotation of NCs afforded important insights into how context impacts their conceptualization.</abstract>
      <bibkey>cabezas-garcia-san-martin-2017-semantic</bibkey>
    </paper>
    <paper id="16">
      <title>A data-driven approach to verbal multiword expression detection. PARSEME Shared Task system description paper<fixed-case>PARSEME</fixed-case> Shared Task system description paper</title>
      <author><first>Tiberiu</first><last>Boros</last></author>
      <author><first>Sonia</first><last>Pipa</last></author>
      <author><first>Verginica</first><last>Barbu Mititelu</last></author>
      <author><first>Dan</first><last>Tufis</last></author>
      <pages>121–126</pages>
      <url hash="d46a3c6d">W17-1716</url>
      <doi>10.18653/v1/W17-1716</doi>
      <abstract>Multiword expressions are groups of words acting as a morphologic, syntactic and semantic unit in <a href="https://en.wikipedia.org/wiki/Linguistic_description">linguistic analysis</a>. Verbal multiword expressions represent the subgroup of <a href="https://en.wikipedia.org/wiki/Multiword_expression">multiword expressions</a>, namely that in which a verb is the syntactic head of the group considered in its canonical (or dictionary) form. All multiword expressions are a great challenge for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>, but the verbal ones are particularly interesting for tasks such as <a href="https://en.wikipedia.org/wiki/Parsing">parsing</a>, as the verb is the central element in the syntactic organization of a sentence. In this paper we introduce our data-driven approach to verbal multiword expressions which was objectively validated during the PARSEME shared task on verbal multiword expressions identification. We tested our approach on 12 languages, and we provide detailed information about corpora composition, feature selection process, validation procedure and performance on all languages.</abstract>
      <bibkey>boros-etal-2017-data</bibkey>
    </paper>
    <paper id="17">
      <title>The ATILF-LLF System for Parseme Shared Task : a Transition-based Verbal Multiword Expression Tagger<fixed-case>ATILF</fixed-case>-<fixed-case>LLF</fixed-case> System for Parseme Shared Task: a Transition-based Verbal Multiword Expression Tagger</title>
      <author><first>Hazem</first><last>Al Saied</last></author>
      <author><first>Matthieu</first><last>Constant</last></author>
      <author><first>Marie</first><last>Candito</last></author>
      <pages>127–132</pages>
      <url hash="3cf2c787">W17-1717</url>
      <doi>10.18653/v1/W17-1717</doi>
      <abstract>We describe the ATILF-LLF system built for the MWE 2017 Shared Task on automatic identification of verbal multiword expressions. We participated in the closed track only, for all the 18 available languages. Our <a href="https://en.wikipedia.org/wiki/System">system</a> is a robust greedy transition-based system, in which MWE are identified through a MERGE transition. The system was meant to accommodate the variety of linguistic resources provided for each language, in terms of accompanying <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological and syntactic information</a>. Using per-MWE Fscore, the <a href="https://en.wikipedia.org/wiki/System">system</a> was ranked first for all but two languages (Hungarian and Romanian).</abstract>
      <bibkey>al-saied-etal-2017-atilf</bibkey>
    </paper>
    <paper id="19">
      <title>Compositionality in Verb-Particle Constructions</title>
      <author><first>Archna</first><last>Bhatia</last></author>
      <author><first>Choh Man</first><last>Teng</last></author>
      <author><first>James</first><last>Allen</last></author>
      <pages>139–148</pages>
      <url hash="ecf962d2">W17-1719</url>
      <doi>10.18653/v1/W17-1719</doi>
      <abstract>We are developing a broad-coverage deep semantic lexicon for a system that parses sentences into a logical form expressed in a rich ontology that supports <a href="https://en.wikipedia.org/wiki/Reason">reasoning</a>. In this paper we look at verb-particle constructions (VPCs), and the extent to which they can be treated compositionally vs idiomatically. First we distinguish between the different types of VPCs based on their compositionality and then present a set of <a href="https://en.wikipedia.org/wiki/Heuristic">heuristics</a> for classifying specific instances as compositional or not. We then identify a small set of general sense classes for <a href="https://en.wikipedia.org/wiki/Grammatical_particle">particles</a> when used compositionally and discuss the resulting lexical representations that are being added to the lexicon. By treating VPCs as compositional whenever possible, we attain broad coverage in a compact way, and also enable interpretations of novel VPC usages not explicitly present in the lexicon.</abstract>
      <bibkey>bhatia-etal-2017-compositionality</bibkey>
    </paper>
    <paper id="20">
      <title>Rule-Based Translation of Spanish Verb-Noun Combinations into <a href="https://en.wikipedia.org/wiki/Basque_language">Basque</a><fixed-case>S</fixed-case>panish Verb-Noun Combinations into <fixed-case>B</fixed-case>asque</title>
      <author><first>Uxoa</first><last>Iñurrieta</last></author>
      <author><first>Itziar</first><last>Aduriz</last></author>
      <author><first>Arantza</first><last>Díaz de Ilarraza</last></author>
      <author><first>Gorka</first><last>Labaka</last></author>
      <author><first>Kepa</first><last>Sarasola</last></author>
      <pages>149–154</pages>
      <url hash="a6fe4b99">W17-1720</url>
      <doi>10.18653/v1/W17-1720</doi>
      <abstract>This paper presents a method to improve the translation of Verb-Noun Combinations (VNCs) in a rule-based Machine Translation (MT) system for Spanish-Basque. Linguistic information about a set of <a href="https://en.wikipedia.org/wiki/Virtual_Network_Computing">VNCs</a> is gathered from the public database Konbitzul, and it is integrated into the MT system, leading to an improvement in <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a>, NIST and TER scores, as well as the results being evidently better according to human evaluators.</abstract>
      <bibkey>inurrieta-etal-2017-rule</bibkey>
    </paper>
    <paper id="21">
      <title>Verb-Particle Constructions in Questions</title>
      <author><first>Veronika</first><last>Vincze</last></author>
      <pages>155–160</pages>
      <url hash="936bfebe">W17-1721</url>
      <doi>10.18653/v1/W17-1721</doi>
      <abstract>In this paper, we investigate the behavior of <a href="https://en.wikipedia.org/wiki/Grammatical_conjugation">verb-particle constructions</a> in English questions. We present a small dataset that contains <a href="https://en.wikipedia.org/wiki/Questionnaire_construction">questions</a> and verb-particle construction candidates. We demonstrate that there are significant differences in the distribution of WH-words, verbs and prepositions / particles in sentences that contain VPCs and sentences that contain only verb + prepositional phrase combinations both by statistical means and in <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a> experiments. Hence, VPCs and non-VPCs can be effectively separated from each other by using a rich feature set, containing several novel features.</abstract>
      <bibkey>vincze-2017-verb</bibkey>
    </paper>
    <paper id="22">
      <title>Simple Compound Splitting for German<fixed-case>G</fixed-case>erman</title>
      <author><first>Marion</first><last>Weller-Di Marco</last></author>
      <pages>161–166</pages>
      <url hash="9a8581c5">W17-1722</url>
      <doi>10.18653/v1/W17-1722</doi>
      <abstract>This paper presents a simple method for German compound splitting that combines a basic frequency-based approach with a form-to-lemma mapping to approximate morphological operations. With the exception of a small set of hand-crafted rules for modeling transitional elements, this approach is resource-poor. In our evaluation, the simple splitter outperforms a splitter relying on rich morphological resources.</abstract>
      <bibkey>weller-di-marco-2017-simple</bibkey>
    </paper>
    <paper id="23">
      <title>Identification of Ambiguous Multiword Expressions Using Sequence Models and Lexical Resources</title>
      <author><first>Manon</first><last>Scholivet</last></author>
      <author><first>Carlos</first><last>Ramisch</last></author>
      <pages>167–175</pages>
      <url hash="0b03a715">W17-1723</url>
      <doi>10.18653/v1/W17-1723</doi>
      <abstract>We present a simple and efficient <a href="https://en.wikipedia.org/wiki/Tagger">tagger</a> capable of identifying highly ambiguous multiword expressions (MWEs) in French texts. It is based on conditional random fields (CRF), using local context information as <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>. We show that this approach can obtain results that, in some cases, approach more sophisticated parser-based MWE identification methods without requiring syntactic trees from a <a href="https://en.wikipedia.org/wiki/Treebank">treebank</a>. Moreover, we study how well the CRF can take into account external information coming from a lexicon.</abstract>
      <bibkey>scholivet-ramisch-2017-identification</bibkey>
    </paper>
    <paper id="24">
      <title>Comparing Recurring Lexico-Syntactic Trees (RLTs) and Ngram Techniques for Extended Phraseology Extraction<fixed-case>RLT</fixed-case>s) and Ngram Techniques for Extended Phraseology Extraction</title>
      <author><first>Agnès</first><last>Tutin</last></author>
      <author><first>Olivier</first><last>Kraif</last></author>
      <pages>176–180</pages>
      <url hash="5c3bf995">W17-1724</url>
      <doi>10.18653/v1/W17-1724</doi>
      <abstract>This paper aims at assessing to what extent a syntax-based method (Recurring Lexico-syntactic Trees (RLT) extraction) allows us to extract large phraseological units such as prefabricated routines, e.g. as previously said or as far as we / I know in <a href="https://en.wikipedia.org/wiki/Scientific_literature">scientific writing</a>. In order to evaluate this method, we compare it to the classical ngram extraction technique, on a subset of recurring segments including speech verbs in a French corpus of scientific writing. Results show that the LRT extraction technique is far more efficient for extended MWEs such as <a href="https://en.wikipedia.org/wiki/Subroutine">routines</a> or <a href="https://en.wikipedia.org/wiki/Collocation">collocations</a> but performs more poorly for surface phenomena such as syntactic constructions or fully frozen expressions.</abstract>
      <bibkey>tutin-kraif-2017-comparing</bibkey>
    </paper>
    <paper id="25">
      <title>Benchmarking Joint Lexical and Syntactic Analysis on Multiword-Rich Data</title>
      <author><first>Matthieu</first><last>Constant</last></author>
      <author><first>Héctor</first><last>Martinez Alonso</last></author>
      <pages>181–186</pages>
      <url hash="c2e13338">W17-1725</url>
      <doi>10.18653/v1/W17-1725</doi>
      <abstract>This article evaluates the extension of a <a href="https://en.wikipedia.org/wiki/Dependency_grammar">dependency parser</a> that performs joint syntactic analysis and multiword expression identification. We show that, given sufficient training data, the <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> benefits from explicit multiword information and improves overall labeled accuracy score in eight of the ten evaluation cases.</abstract>
      <bibkey>constant-martinez-alonso-2017-benchmarking</bibkey>
    </paper>
    <paper id="26">
      <title>Semi-Automated Resolution of Inconsistency for a Harmonized Multiword Expression and Dependency Parse Annotation</title>
      <author><first>King</first><last>Chan</last></author>
      <author><first>Julian</first><last>Brooke</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <pages>187–193</pages>
      <url hash="e398df73">W17-1726</url>
      <doi>10.18653/v1/W17-1726</doi>
      <abstract>This paper presents a methodology for identifying and resolving various kinds of inconsistency in the context of merging dependency and multiword expression (MWE) annotations, to generate a dependency treebank with comprehensive MWE annotations. Candidates for correction are identified using a variety of <a href="https://en.wikipedia.org/wiki/Heuristic">heuristics</a>, including an entirely novel one which identifies violations of MWE constituency in the dependency tree, and resolved by <a href="https://en.wikipedia.org/wiki/Arbitration">arbitration</a> with minimal human intervention. Using this technique, we identified and corrected several hundred errors across both parse and MWE annotations, representing changes to a significant percentage (well over 10 %) of the MWE instances in the joint corpus.</abstract>
      <bibkey>chan-etal-2017-semi</bibkey>
      <pwccode url="https://github.com/eltimster/HAMSTER" additional="false">eltimster/HAMSTER</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/english-web-treebank">English Web Treebank</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="27">
      <title>Combining <a href="https://en.wikipedia.org/wiki/Linguistic_feature">Linguistic Features</a> for the Detection of Croatian Multiword Expressions<fixed-case>C</fixed-case>roatian Multiword Expressions</title>
      <author><first>Maja</first><last>Buljan</last></author>
      <author><first>Jan</first><last>Šnajder</last></author>
      <pages>194–199</pages>
      <url hash="15de7fb3">W17-1727</url>
      <doi>10.18653/v1/W17-1727</doi>
      <abstract>As multiword expressions (MWEs) exhibit a range of <a href="https://en.wikipedia.org/wiki/Idiosyncrasy">idiosyncrasies</a>, their automatic detection warrants the use of many different features. Tsvetkov and Wintner (2014) proposed a Bayesian network model that combines linguistically motivated features and also models their interactions. In this paper, we extend their model with new <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">features</a> and apply it to <a href="https://en.wikipedia.org/wiki/Croatian_language">Croatian</a>, a <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphologically complex</a> and a relatively free word order language, achieving a satisfactory performance of 0.823 F1-score. Furthermore, by comparing against (semi)naive Bayes models, we demonstrate that manually modeling feature interactions is indeed important. We make our annotated dataset of Croatian MWEs freely available.</abstract>
      <bibkey>buljan-snajder-2017-combining</bibkey>
    </paper>
    <paper id="28">
      <title>Complex Verbs are Different : Exploring the Visual Modality in Multi-Modal Models to Predict Compositionality</title>
      <author><first>Maximilian</first><last>Köper</last></author>
      <author><first>Sabine</first><last>Schulte im Walde</last></author>
      <pages>200–206</pages>
      <url hash="23b250f5">W17-1728</url>
      <doi>10.18653/v1/W17-1728</doi>
      <abstract>This paper compares a neural network DSM relying on textual co-occurrences with a multi-modal model integrating visual information. We focus on <a href="https://en.wikipedia.org/wiki/Compound_(linguistics)">nominal vs. verbal compounds</a>, and zoom into lexical, empirical and perceptual target properties to explore the contribution of the <a href="https://en.wikipedia.org/wiki/Visual_system">visual modality</a>. Our experiments show that (i) visual features contribute differently for verbs than for nouns, and (ii) <a href="https://en.wikipedia.org/wiki/Image">images</a> complement textual information, if (a) the textual modality by itself is poor and appropriate image subsets are used, or (b) the textual modality by itself is rich and large (potentially noisy) images are added.</abstract>
      <bibkey>koper-schulte-im-walde-2017-complex</bibkey>
    </paper>
  </volume>
  <volume id="18">
    <meta>
      <booktitle>Proceedings of the Workshop Computational Semantics Beyond Events and Roles</booktitle>
      <url hash="18715fbe">W17-18</url>
      <editor><first>Eduardo</first><last>Blanco</last></editor>
      <editor><first>Roser</first><last>Morante</last></editor>
      <editor><first>Roser</first><last>Saurí</last></editor>
      <doi>10.18653/v1/W17-18</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="6c43f455">W17-1800</url>
      <bibkey>ws-2017-semantics</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Understanding the Semantics of Narratives of Interpersonal Violence through Reader Annotations and Physiological Reactions</title>
      <author><first>Alexander</first><last>Calderwood</last></author>
      <author><first>Elizabeth A.</first><last>Pruett</last></author>
      <author><first>Raymond</first><last>Ptucha</last></author>
      <author><first>Christopher</first><last>Homan</last></author>
      <author><first>Cecilia</first><last>Ovesdotter Alm</last></author>
      <pages>1–9</pages>
      <url hash="760998b5">W17-1801</url>
      <doi>10.18653/v1/W17-1801</doi>
      <abstract>Interpersonal violence (IPV) is a prominent sociological problem that affects people of all demographic backgrounds. By analyzing how readers interpret, perceive, and react to experiences narrated in social media posts, we explore an understudied source for <a href="https://en.wikipedia.org/wiki/Discourse">discourse</a> about abuse. We asked readers to annotate Reddit posts about relationships with vs. without IPV for stakeholder roles and emotion, while measuring their <a href="https://en.wikipedia.org/wiki/Electrodermal_activity">galvanic skin response (GSR)</a>, <a href="https://en.wikipedia.org/wiki/Pulse">pulse</a>, and <a href="https://en.wikipedia.org/wiki/Facial_expression">facial expression</a>. We map annotations to coreference resolution output to obtain a labeled coreference chain for stakeholders in texts, and apply automated semantic role labeling for analyzing IPV discourse. Findings provide insights into how readers process roles and emotion in narratives. For example, abusers tend to be linked with <a href="https://en.wikipedia.org/wiki/Violence">violent actions</a> and certain <a href="https://en.wikipedia.org/wiki/Affect_(psychology)">affect states</a>. We train classifiers to predict stakeholder categories of coreference chains. We also find that subjects’ GSR noticeably changed for IPV texts, suggesting that co-collected measurement-based data about annotators can be used to support text annotation.</abstract>
      <bibkey>calderwood-etal-2017-understanding</bibkey>
    </paper>
    <paper id="2">
      <title>Intension, <a href="https://en.wikipedia.org/wiki/Attitude_(psychology)">Attitude</a>, and <a href="https://en.wikipedia.org/wiki/Tense–aspect–mood">Tense Annotation</a> in a High-Fidelity Semantic Representation</title>
      <author><first>Gene</first><last>Kim</last></author>
      <author><first>Lenhart</first><last>Schubert</last></author>
      <pages>10–15</pages>
      <url hash="2949b843">W17-1802</url>
      <doi>10.18653/v1/W17-1802</doi>
      <abstract>This paper describes current efforts in developing an annotation schema and guidelines for sentences in Episodic Logic (EL). We focus on important distinctions for representing <a href="https://en.wikipedia.org/wiki/Modal_logic">modality</a>, <a href="https://en.wikipedia.org/wiki/Attitude_(psychology)">attitudes</a>, and <a href="https://en.wikipedia.org/wiki/Grammatical_tense">tense</a> and present an annotation schema that makes these distinctions. EL has proved competitive with other logical formulations in speed and inference-enablement, while expressing a wider array of natural language phenomena including intensional modification of predicates and sentences, propositional attitudes, and <a href="https://en.wikipedia.org/wiki/Grammatical_tense">tense</a> and <a href="https://en.wikipedia.org/wiki/Grammatical_aspect">aspect</a>.</abstract>
      <bibkey>kim-schubert-2017-intension</bibkey>
    </paper>
    <paper id="3">
      <title>Towards a lexicon of event-selecting predicates for a French FactBank<fixed-case>F</fixed-case>rench <fixed-case>F</fixed-case>act<fixed-case>B</fixed-case>ank</title>
      <author><first>Ingrid</first><last>Falk</last></author>
      <author><first>Fabienne</first><last>Martin</last></author>
      <pages>16–21</pages>
      <url hash="1725e5e1">W17-1803</url>
      <doi>10.18653/v1/W17-1803</doi>
      <abstract>This paper presents ongoing work for the construction of a French FactBank and a lexicon of French event-selecting predicates (ESPs), by applying the factuality detection algorithm introduced in (Saur and Pustejovsky, 2012). This algorithm relies on a lexicon of ESPs, specifying how these predicates influence the polarity of their embedded events. For this pilot study, we focused on French factive and implicative verbs, and capitalised on a lexical resource for the English counterparts of these verbs provided by the CLSI Group (Nairn et al., 2006 ; Karttunen, 2012).</abstract>
      <bibkey>falk-martin-2017-towards</bibkey>
    </paper>
    <paper id="4">
      <title>Universal Dependencies to <a href="https://en.wikipedia.org/wiki/Logical_form">Logical Form</a> with Negation Scope<fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies to Logical Form with Negation Scope</title>
      <author><first>Federico</first><last>Fancellu</last></author>
      <author><first>Siva</first><last>Reddy</last></author>
      <author><first>Adam</first><last>Lopez</last></author>
      <author><first>Bonnie</first><last>Webber</last></author>
      <pages>22–32</pages>
      <url hash="22ec7b1d">W17-1804</url>
      <doi>10.18653/v1/W17-1804</doi>
      <abstract>Many language technology applications would benefit from the ability to represent <a href="https://en.wikipedia.org/wiki/Affirmation_and_negation">negation</a> and its scope on top of widely-used linguistic resources. In this paper, we investigate the possibility of obtaining a <a href="https://en.wikipedia.org/wiki/First-order_logic">first-order logic representation</a> with <a href="https://en.wikipedia.org/wiki/Scope_(computer_science)">negation scope</a> marked using Universal Dependencies. To do so, we enhance UDepLambda, a <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> that converts <a href="https://en.wikipedia.org/wiki/Dependency_graph">dependency graphs</a> to <a href="https://en.wikipedia.org/wiki/Logical_form">logical forms</a>. The resulting UDepLambda is able to handle phenomena related to scope by means of an higher-order type theory, relevant not only to <a href="https://en.wikipedia.org/wiki/Negation">negation</a> but also to <a href="https://en.wikipedia.org/wiki/Universal_quantification">universal quantification</a> and other complex semantic phenomena. The initial conversion we did for <a href="https://en.wikipedia.org/wiki/English_language">English</a> is promising, in that one can represent the scope of negation also in the presence of more complex phenomena such as <a href="https://en.wikipedia.org/wiki/Universal_quantification">universal quantifiers</a>.<i>Universal Dependencies</i>. To do so, we enhance <i>UDepLambda</i>, a framework that converts dependency graphs to logical forms. The resulting <i>UDepLambda<tex-math>\lnot</tex-math>
        </i>

is able to handle phenomena related to scope by means of an higher-order type theory, relevant not only to negation but also to universal quantification and other complex semantic phenomena. The initial conversion we did for English is promising, in that one can represent the scope of negation also in the presence of more complex phenomena such as universal quantifiers. </abstract>
      <bibkey>fancellu-etal-2017-universal</bibkey>
    </paper>
    <paper id="5">
      <title>Meaning Banking beyond Events and Roles</title>
      <author><first>Johan</first><last>Bos</last></author>
      <pages>33</pages>
      <url hash="1bcffa04">W17-1805</url>
      <doi>10.18653/v1/W17-1805</doi>
      <abstract>In this talk I will discuss the analysis of several semantic phenomena that need meaning representations that can describe <a href="https://en.wikipedia.org/wiki/Context_(language_use)">attributes of propositional contexts</a>. I will do this in a version of <a href="https://en.wikipedia.org/wiki/Discourse_representation_theory">Discourse Representation Theory</a>, using a universal semantic tagset developed as part of a project that aims to produce a large meaning bank (a semantically-annotated corpus) for four languages (English, Dutch, German and Italian).</abstract>
      <bibkey>bos-2017-meaning</bibkey>
    </paper>
    <paper id="6">
      <title>The Scope and Focus of Negation : A Complete Annotation Framework for <a href="https://en.wikipedia.org/wiki/Italian_language">Italian</a><fixed-case>I</fixed-case>talian</title>
      <author><first>Begoña</first><last>Altuna</last></author>
      <author><first>Anne-Lyse</first><last>Minard</last></author>
      <author><first>Manuela</first><last>Speranza</last></author>
      <pages>34–42</pages>
      <url hash="ce92b783">W17-1806</url>
      <doi>10.18653/v1/W17-1806</doi>
      <abstract>In this paper we present a complete framework for the annotation of negation in <a href="https://en.wikipedia.org/wiki/Italian_language">Italian</a>, which accounts for both negation scope and negation focus, and also for language-specific phenomena such as negative concord. In our view, the annotation of negation complements more comprehensive Natural Language Processing tasks, such as temporal information processing and <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a>. We applied the proposed framework and the guidelines built on top of it to the annotation of written texts, namely news articles and <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a>, thus producing annotated data for a total of over 36,000 tokens.</abstract>
      <bibkey>altuna-etal-2017-scope</bibkey>
    </paper>
    <paper id="8">
      <title>Annotating Negation in Spanish Clinical Texts<fixed-case>S</fixed-case>panish Clinical Texts</title>
      <author><first>Noa</first><last>Cruz</last></author>
      <author><first>Roser</first><last>Morante</last></author>
      <author><first>Manuel J.</first><last>Maña López</last></author>
      <author><first>Jacinto</first><last>Mata Vázquez</last></author>
      <author><first>Carlos L.</first><last>Parra Calderón</last></author>
      <pages>53–58</pages>
      <url hash="b2655da7">W17-1808</url>
      <doi>10.18653/v1/W17-1808</doi>
      <abstract>In this paper we present on-going work on annotating <a href="https://en.wikipedia.org/wiki/Affirmation_and_negation">negation</a> in Spanish clinical documents. A corpus of anamnesis and radiology reports has been annotated by two domain expert annotators with negation markers and negated events. The <a href="https://en.wikipedia.org/wiki/Dice_coefficient">Dice coefficient</a> for <a href="https://en.wikipedia.org/wiki/Inter-annotator_agreement">inter-annotator agreement</a> is higher than 0.94 for negation markers and higher than 0.72 for negated events. The <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> will be publicly released when the annotation process is finished, constituting the first <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> annotated with <a href="https://en.wikipedia.org/wiki/Affirmation_and_negation">negation</a> for Spanish clinical reports available for the NLP community.</abstract>
      <bibkey>cruz-etal-2017-annotating</bibkey>
    </paper>
    <paper id="10">
      <title>An open-source tool for negation detection : a maximum-margin approach</title>
      <author><first>Martine</first><last>Enger</last></author>
      <author><first>Erik</first><last>Velldal</last></author>
      <author><first>Lilja</first><last>Øvrelid</last></author>
      <pages>64–69</pages>
      <url hash="eb93751b">W17-1810</url>
      <doi>10.18653/v1/W17-1810</doi>
      <abstract>This paper presents an <a href="https://en.wikipedia.org/wiki/Open-source_software">open-source toolkit</a> for negation detection. It identifies negation cues and their corresponding scope in either raw or parsed text using maximum-margin classification. The <a href="https://en.wikipedia.org/wiki/System">system</a> design draws on best practice from the existing literature on negation detection, aiming for a simple and portable system that still achieves competitive performance. Pre-trained models and experimental results are provided for <a href="https://en.wikipedia.org/wiki/English_language">English</a>.</abstract>
      <bibkey>enger-etal-2017-open</bibkey>
      <pwccode url="https://github.com/marenger/negtool" additional="false">marenger/negtool</pwccode>
    </paper>
  </volume>
  <volume id="19">
    <meta>
      <booktitle>Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications</booktitle>
      <url hash="041c8e2a">W17-19</url>
      <editor><first>Jose</first><last>Camacho-Collados</last></editor>
      <editor><first>Mohammad Taher</first><last>Pilehvar</last></editor>
      <doi>10.18653/v1/W17-19</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="e7ca86f5">W17-1900</url>
      <bibkey>ws-2017-sense</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Compositional Semantics using Feature-Based Models from <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a><fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et</title>
      <author><first>Pablo</first><last>Gamallo</last></author>
      <author><first>Martín</first><last>Pereira-Fariña</last></author>
      <pages>1–11</pages>
      <url hash="ff3228a7">W17-1901</url>
      <doi>10.18653/v1/W17-1901</doi>
      <abstract>This article describes a method to build semantic representations of composite expressions in a compositional way by using WordNet relations to represent the meaning of words. The meaning of a target word is modelled as a vector in which its semantically related words are assigned weights according to both the type of the relationship and the distance to the target word. Word vectors are compositionally combined by syntactic dependencies. Each syntactic dependency triggers two complementary compositional functions : the named head function and dependent function. The experiments show that the proposed compositional method outperforms the state-of-the-art for both intransitive subject-verb and transitive subject-verb-object constructions.</abstract>
      <bibkey>gamallo-pereira-farina-2017-compositional</bibkey>
    </paper>
    <paper id="2">
      <title>Automated WordNet Construction Using Word Embeddings<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et Construction Using Word Embeddings</title>
      <author><first>Mikhail</first><last>Khodak</last></author>
      <author><first>Andrej</first><last>Risteski</last></author>
      <author><first>Christiane</first><last>Fellbaum</last></author>
      <author><first>Sanjeev</first><last>Arora</last></author>
      <pages>12–23</pages>
      <url hash="274cc511">W17-1902</url>
      <doi>10.18653/v1/W17-1902</doi>
      <abstract>We present a fully unsupervised method for automated construction of WordNets based upon recent advances in distributional representations of sentences and word-senses combined with readily available machine translation tools. The approach requires very few linguistic resources and is thus extensible to multiple target languages. To evaluate our method we construct two 600-word testsets for word-to-synset matching in <a href="https://en.wikipedia.org/wiki/French_language">French</a> and <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a> using native speakers and evaluate the performance of our method along with several other recent approaches. Our method exceeds the best language-specific and multi-lingual automated WordNets in <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> for both languages. The databases we construct for <a href="https://en.wikipedia.org/wiki/French_language">French</a> and <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a>, both languages without large publicly available manually constructed WordNets, will be publicly released along with the testsets.</abstract>
      <bibkey>khodak-etal-2017-automated</bibkey>
      <pwccode url="https://github.com/mkhodak/pawn" additional="false">mkhodak/pawn</pwccode>
    </paper>
    <paper id="3">
      <title>Improving Verb Metaphor Detection by Propagating Abstractness to Words, Phrases and Individual Senses</title>
      <author><first>Maximilian</first><last>Köper</last></author>
      <author><first>Sabine</first><last>Schulte im Walde</last></author>
      <pages>24–30</pages>
      <url hash="a5a18345">W17-1903</url>
      <doi>10.18653/v1/W17-1903</doi>
      <abstract>Abstract words refer to things that can not be seen, heard, felt, smelled, or tasted as opposed to concrete words. Among other <a href="https://en.wikipedia.org/wiki/Application_software">applications</a>, the degree of <a href="https://en.wikipedia.org/wiki/Abstraction">abstractness</a> has been shown to be a useful information for metaphor detection. Our contribution to this topic are as follows : i) we compare supervised techniques to learn and extend <a href="https://en.wikipedia.org/wiki/Abstraction">abstractness ratings</a> for huge vocabularies ii) we learn and investigate norms for larger units by propagating <a href="https://en.wikipedia.org/wiki/Abstraction">abstractness</a> to verb-noun pairs which lead to better metaphor detection iii) we overcome the limitation of learning a single rating per word and show that multi-sense abstractness ratings are potentially useful for metaphor detection. Finally, with this paper we publish automatically created abstractness norms for 3million English words and multi-words as well as automatically created sense specific abstractness ratings</abstract>
      <bibkey>koper-schulte-im-walde-2017-improving</bibkey>
    </paper>
    <paper id="4">
      <title>Improving Clinical Diagnosis Inference through Integration of Structured and Unstructured Knowledge</title>
      <author><first>Yuan</first><last>Ling</last></author>
      <author><first>Yuan</first><last>An</last></author>
      <author><first>Sadid</first><last>Hasan</last></author>
      <pages>31–36</pages>
      <url hash="9e125ef9">W17-1904</url>
      <doi>10.18653/v1/W17-1904</doi>
      <abstract>This paper presents a novel approach to the task of automatically inferring the most probable diagnosis from a given clinical narrative. Structured Knowledge Bases (KBs) can be useful for such complex <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> but not sufficient. Hence, we leverage a vast amount of unstructured free text to integrate with structured KBs. The key innovative ideas include building a concept graph from both structured and unstructured knowledge sources and ranking the diagnosis concepts using the enhanced word embedding vectors learned from integrated sources. Experiments on the TREC CDS and HumanDx datasets showed that our methods improved the results of clinical diagnosis inference.</abstract>
      <bibkey>ling-etal-2017-improving</bibkey>
    </paper>
    <paper id="5">
      <title>Classifying Lexical-semantic Relationships by Exploiting Sense / Concept Representations</title>
      <author><first>Kentaro</first><last>Kanada</last></author>
      <author><first>Tetsunori</first><last>Kobayashi</last></author>
      <author><first>Yoshihiko</first><last>Hayashi</last></author>
      <pages>37–46</pages>
      <url hash="4bbdb6d6">W17-1905</url>
      <doi>10.18653/v1/W17-1905</doi>
      <abstract>This paper proposes a method for classifying the type of lexical-semantic relation between a given pair of words. Given an inventory of target relationships, this <a href="https://en.wikipedia.org/wiki/Task_(computing)">task</a> can be seen as a multi-class classification problem. We train a supervised classifier by assuming : (1) a specific type of lexical-semantic relation between a pair of words would be indicated by a carefully designed set of relation-specific similarities associated with the words ; and (2) the similarities could be effectively computed by sense representations (sense / concept embeddings). The experimental results show that the proposed <a href="https://en.wikipedia.org/wiki/Methodology">method</a> clearly outperforms an existing state-of-the-art method that does not utilize sense / concept embeddings, thereby demonstrating the effectiveness of the sense representations.</abstract>
      <bibkey>kanada-etal-2017-classifying</bibkey>
    </paper>
    <paper id="6">
      <title>Supervised and unsupervised approaches to measuring usage similarity</title>
      <author><first>Milton</first><last>King</last></author>
      <author><first>Paul</first><last>Cook</last></author>
      <pages>47–52</pages>
      <url hash="ff8d9bac">W17-1906</url>
      <doi>10.18653/v1/W17-1906</doi>
      <abstract>Usage similarity (USim) is an approach to determining word meaning in context that does not rely on a sense inventory. Instead, pairs of usages of a target lemma are rated on a scale. In this paper we propose unsupervised approaches to USim based on embeddings for words, contexts, and sentences, and achieve state-of-the-art results over two USim datasets. We further consider supervised approaches to USim, and find that although they outperform unsupervised approaches, they are unable to generalize to lemmas that are unseen in the training data.</abstract>
      <bibkey>king-cook-2017-supervised</bibkey>
    </paper>
    <paper id="8">
      <title>Creating and Validating Multilingual Semantic Representations for Six Languages : Expert versus Non-Expert Crowds</title>
      <author><first>Mahmoud</first><last>El-Haj</last></author>
      <author><first>Paul</first><last>Rayson</last></author>
      <author><first>Scott</first><last>Piao</last></author>
      <author><first>Stephen</first><last>Wattam</last></author>
      <pages>61–71</pages>
      <url hash="08d23698">W17-1908</url>
      <doi>10.18653/v1/W17-1908</doi>
      <abstract>Creating high-quality wide-coverage multilingual semantic lexicons to support knowledge-based approaches is a challenging time-consuming manual task. This has traditionally been performed by <a href="https://en.wikipedia.org/wiki/Linguistic_description">linguistic experts</a> : a slow and expensive process. We present an experiment in which we adapt and evaluate crowdsourcing methods employing native speakers to generate a list of coarse-grained senses under a common multilingual semantic taxonomy for sets of words in six languages. 451 non-experts (including 427 Mechanical Turk workers) and 15 expert participants semantically annotated 250 words manually for <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a>, <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a>, <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Italian_language">Italian</a>, Portuguese and Urdu lexicons. In order to avoid erroneous (spam) crowdsourced results, we used a novel task-specific two-phase filtering process where users were asked to identify synonyms in the target language, and remove erroneous senses.</abstract>
      <bibkey>el-haj-etal-2017-creating</bibkey>
    </paper>
    <paper id="10">
      <title>One Representation per Word-Does it make Sense for Composition?</title>
      <author><first>Thomas</first><last>Kober</last></author>
      <author><first>Julie</first><last>Weeds</last></author>
      <author><first>John</first><last>Wilkie</last></author>
      <author><first>Jeremy</first><last>Reffin</last></author>
      <author><first>David</first><last>Weir</last></author>
      <pages>79–90</pages>
      <url hash="65dea86b">W17-1910</url>
      <doi>10.18653/v1/W17-1910</doi>
      <abstract>In this paper, we investigate whether an a priori disambiguation of word senses is strictly necessary or whether the meaning of a word in context can be disambiguated through <a href="https://en.wikipedia.org/wiki/Composition_(language)">composition</a> alone. We evaluate the performance of off-the-shelf single-vector and multi-sense vector models on a benchmark phrase similarity task and a novel task for word-sense discrimination. We find that single-sense vector models perform as well or better than multi-sense vector models despite arguably less clean elementary representations. Our findings furthermore show that simple composition functions such as <a href="https://en.wikipedia.org/wiki/Pointwise_addition">pointwise addition</a> are able to recover sense specific information from a single-sense vector model remarkably well.</abstract>
      <bibkey>kober-etal-2017-one</bibkey>
      <pwccode url="https://github.com/tttthomasssss/sense2017" additional="false">tttthomasssss/sense2017</pwccode>
    </paper>
    <paper id="11">
      <title>Elucidating Conceptual Properties from Word Embeddings</title>
      <author><first>Kyoung-Rok</first><last>Jang</last></author>
      <author><first>Sung-Hyon</first><last>Myaeng</last></author>
      <pages>91–95</pages>
      <url hash="e7de8596">W17-1911</url>
      <doi>10.18653/v1/W17-1911</doi>
      <abstract>In this paper, we introduce a <a href="https://en.wikipedia.org/wiki/Scientific_method">method</a> of identifying the components (i.e. dimensions) of word embeddings that strongly signifies properties of a word. By elucidating such properties hidden in <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>, we could make <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> more interpretable, and also could perform property-based meaning comparison. With the capability, we can answer questions like To what degree a given word has the property cuteness? or In what perspective two words are similar?. We verify our method by examining how the strength of property-signifying components correlates with the degree of prototypicality of a target word.</abstract>
      <bibkey>jang-myaeng-2017-elucidating</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hyperlex">HyperLex</pwcdataset>
    </paper>
    <paper id="12">
      <title>TTCS^ : a Vectorial Resource for Computing Conceptual Similarity<fixed-case>TTCS</fixed-case><tex-math>^{\mathcal{E}}</tex-math>: a Vectorial Resource for Computing Conceptual Similarity</title>
      <author><first>Enrico</first><last>Mensa</last></author>
      <author><first>Daniele P.</first><last>Radicioni</last></author>
      <author><first>Antonio</first><last>Lieto</last></author>
      <pages>96–101</pages>
      <url hash="75e6b11a">W17-1912</url>
      <doi>10.18653/v1/W17-1912</doi>
      <abstract>In this paper we introduce the TTCS^, a linguistic resource that relies on <a href="https://en.wikipedia.org/wiki/BabelNet">BabelNet</a>, NASARI and <a href="https://en.wikipedia.org/wiki/ConceptNet">ConceptNet</a>, that has now been used to compute the conceptual similarity between concept pairs. The conceptual representation herein provides uniform access to concepts based on BabelNet synset IDs, and consists of a vector-based semantic representation which is compliant with the Conceptual Spaces, a geometric framework for common-sense knowledge representation and reasoning. The TTCS^ has been evaluated in a preliminary experimentation on a conceptual similarity task.<tex-math>^{\mathcal{E}}</tex-math>, a linguistic resource that relies on BabelNet, NASARI and ConceptNet, that has now been used to compute the conceptual similarity between concept pairs. The conceptual representation herein provides uniform access to concepts based on BabelNet synset IDs, and consists of a vector-based semantic representation which is compliant with the Conceptual Spaces, a geometric framework for common-sense knowledge representation and reasoning. The TTCS<tex-math>^{\mathcal{E}}</tex-math> has been evaluated in a preliminary experimentation on a conceptual similarity task. </abstract>
      <bibkey>mensa-etal-2017-ttcs</bibkey>
    </paper>
    <paper id="13">
      <title>Measuring the Italian-English lexical gap for <a href="https://en.wikipedia.org/wiki/Action_verb">action verbs</a> and its impact on translation<fixed-case>I</fixed-case>talian-<fixed-case>E</fixed-case>nglish lexical gap for action verbs and its impact on translation</title>
      <author><first>Lorenzo</first><last>Gregori</last></author>
      <author><first>Alessandro</first><last>Panunzi</last></author>
      <pages>102–109</pages>
      <url hash="80934a8f">W17-1913</url>
      <doi>10.18653/v1/W17-1913</doi>
      <abstract>This paper describes a method to measure the lexical gap of action verbs in <a href="https://en.wikipedia.org/wiki/Italian_language">Italian</a> and <a href="https://en.wikipedia.org/wiki/English_language">English</a> by using the IMAGACT ontology of action. The fine-grained categorization of action concepts of the data source allowed to have wide overview of the relation between concepts in the two languages. The calculated <a href="https://en.wikipedia.org/wiki/Lexical_gap">lexical gap</a> for both <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/Italian_language">Italian</a> is about 30 % of the action concepts, much higher than previous results. Beyond this general numbers a deeper analysis has been performed in order to evaluate the impact that <a href="https://en.wikipedia.org/wiki/Lexical_gap">lexical gaps</a> can have on <a href="https://en.wikipedia.org/wiki/Translation">translation</a>. In particular a distinction has been made between the cases in which the presence of a <a href="https://en.wikipedia.org/wiki/Lexical_gap">lexical gap</a> affects translation correctness and <a href="https://en.wikipedia.org/wiki/Completeness_(logic)">completeness</a> at a <a href="https://en.wikipedia.org/wiki/Semantics">semantic level</a>. The results highlight a high percentage of concepts that can be considered hard to translate (about 18 % from English to <a href="https://en.wikipedia.org/wiki/Italian_language">Italian</a> and 20 % from <a href="https://en.wikipedia.org/wiki/Italian_language">Italian</a> to English) and confirms that <a href="https://en.wikipedia.org/wiki/Action_verb">action verbs</a> are a critical lexical class for translation tasks.</abstract>
      <bibkey>gregori-panunzi-2017-measuring</bibkey>
    </paper>
    <paper id="14">
      <title>Word Sense Filtering Improves Embedding-Based Lexical Substitution</title>
      <author><first>Anne</first><last>Cocos</last></author>
      <author><first>Marianna</first><last>Apidianaki</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <pages>110–119</pages>
      <url hash="5d5e4ef9">W17-1914</url>
      <doi>10.18653/v1/W17-1914</doi>
      <abstract>The role of <a href="https://en.wikipedia.org/wiki/Word_sense_disambiguation">word sense disambiguation</a> in <a href="https://en.wikipedia.org/wiki/Lexical_substitution">lexical substitution</a> has been questioned due to the high performance of vector space models which propose good substitutes without explicitly accounting for <a href="https://en.wikipedia.org/wiki/Word_sense">sense</a>. We show that a filtering mechanism based on a sense inventory optimized for <a href="https://en.wikipedia.org/wiki/Substituent">substitutability</a> can improve the results of these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>. Our sense inventory is constructed using a clustering method which generates paraphrase clusters that are congruent with lexical substitution annotations in a development set. The results show that <a href="https://en.wikipedia.org/wiki/Lexical_substitution">lexical substitution</a> can still benefit from <a href="https://en.wikipedia.org/wiki/Word_sense">senses</a> which can improve the output of vector space paraphrase ranking models.</abstract>
      <bibkey>cocos-etal-2017-word</bibkey>
    </paper>
    <paper id="15">
      <title>Supervised and Unsupervised Word Sense Disambiguation on Word Embedding Vectors of Unambigous Synonyms</title>
      <author><first>Aleksander</first><last>Wawer</last></author>
      <author><first>Agnieszka</first><last>Mykowiecka</last></author>
      <pages>120–125</pages>
      <url hash="715ded8d">W17-1915</url>
      <doi>10.18653/v1/W17-1915</doi>
      <abstract>This paper compares two approaches to <a href="https://en.wikipedia.org/wiki/Word-sense_disambiguation">word sense disambiguation</a> using <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> trained on unambiguous synonyms. The first is <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised method</a> based on computing log probability from sequences of word embedding vectors, taking into account ambiguous word senses and guessing correct sense from context. The second method is supervised. We use a multilayer neural network model to learn a context-sensitive transformation that maps an input vector of ambiguous word into an output vector representing its sense. We evaluate both methods on corpora with manual annotations of word senses from the Polish wordnet (plWordnet).</abstract>
      <bibkey>wawer-mykowiecka-2017-supervised</bibkey>
    </paper>
  </volume>
  <volume id="20">
    <meta>
      <booktitle>Proceedings of the Sixth Workshop on Vision and Language</booktitle>
      <url hash="8a974f2d">W17-20</url>
      <editor><first>Anya</first><last>Belz</last></editor>
      <editor><first>Erkut</first><last>Erdem</last></editor>
      <editor><first>Katerina</first><last>Pastra</last></editor>
      <editor><first>Krystian</first><last>Mikolajczyk</last></editor>
      <doi>10.18653/v1/W17-20</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="96ebf2e2">W17-2000</url>
      <bibkey>ws-2017-vision</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Learning to Recognize Animals by Watching Documentaries : Using <a href="https://en.wikipedia.org/wiki/Subtitle_(titling)">Subtitles</a> as Weak Supervision</title>
      <author><first>Aparna</first><last>Nurani Venkitasubramanian</last></author>
      <author><first>Tinne</first><last>Tuytelaars</last></author>
      <author><first>Marie-Francine</first><last>Moens</last></author>
      <pages>21–30</pages>
      <url hash="17837cc5">W17-2003</url>
      <doi>10.18653/v1/W17-2003</doi>
      <abstract>We investigate animal recognition models learned from wildlife video documentaries by using the weak supervision of the textual subtitles. This is a particularly challenging setting, since i) the animals occur in their natural habitat and are often largely occluded and ii) subtitles are to a large degree complementary to the visual content, providing a very weak supervisory signal. This is in contrast to most work on integrated vision and language in the literature, where textual descriptions are tightly linked to the image content, and often generated in a curated fashion for the task at hand. In particular, we investigate different image representations and models, including a support vector machine on top of activations of a pretrained convolutional neural network, as well as a Naive Bayes framework on a ‘bag-of-activations’ image representation, where each element of the bag is considered separately. This representation allows key components in the image to be isolated, in spite of largely varying backgrounds and image clutter, without an <a href="https://en.wikipedia.org/wiki/Object_detection">object detection</a> or image segmentation step. The methods are evaluated based on how well they transfer to unseen camera-trap images captured across diverse topographical regions under different environmental conditions and illumination settings, involving a large domain shift.</abstract>
      <bibkey>nurani-venkitasubramanian-etal-2017-learning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imagenet">ImageNet</pwcdataset>
    </paper>
    <paper id="4">
      <title>Human Evaluation of Multi-modal Neural Machine Translation : A Case-Study on E-Commerce Listing Titles<fixed-case>E</fixed-case>-Commerce Listing Titles</title>
      <author><first>Iacer</first><last>Calixto</last></author>
      <author><first>Daniel</first><last>Stein</last></author>
      <author><first>Evgeny</first><last>Matusov</last></author>
      <author><first>Sheila</first><last>Castilho</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <pages>31–37</pages>
      <url hash="3bff9b8f">W17-2004</url>
      <doi>10.18653/v1/W17-2004</doi>
      <abstract>In this paper, we study how humans perceive the use of <a href="https://en.wikipedia.org/wiki/Digital_image">images</a> as an additional knowledge source to machine-translate <a href="https://en.wikipedia.org/wiki/User-generated_content">user-generated product listings</a> in an <a href="https://en.wikipedia.org/wiki/E-commerce">e-commerce company</a>. We conduct a human evaluation where we assess how a multi-modal neural machine translation (NMT) model compares to two text-only approaches : a conventional state-of-the-art attention-based NMT and a phrase-based statistical machine translation (PBSMT) model. We evaluate translations obtained with different systems and also discuss the data set of user-generated product listings, which in our case comprises both product listings and associated images. We found that humans preferred translations obtained with a PBSMT system to both text-only and multi-modal NMT over 56 % of the time. Nonetheless, human evaluators ranked translations from a multi-modal NMT model as better than those of a text-only NMT over 88 % of the time, which suggests that <a href="https://en.wikipedia.org/wiki/Digital_image">images</a> do help <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NMT</a> in this use-case.</abstract>
      <bibkey>calixto-etal-2017-human</bibkey>
    </paper>
    <paper id="5">
      <title>The BreakingNews Dataset<fixed-case>B</fixed-case>reaking<fixed-case>N</fixed-case>ews Dataset</title>
      <author><first>Arnau</first><last>Ramisa</last></author>
      <author><first>Fei</first><last>Yan</last></author>
      <author><first>Francesc</first><last>Moreno-Noguer</last></author>
      <author><first>Krystian</first><last>Mikolajczyk</last></author>
      <pages>38–39</pages>
      <url hash="a3159153">W17-2005</url>
      <doi>10.18653/v1/W17-2005</doi>
      <abstract>We present BreakingNews, a novel <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> with approximately 100 K news articles including images, text and captions, and enriched with heterogeneous meta-data (e.g. GPS coordinates and popularity metrics). The tenuous connection between the images and text in news data is appropriate to take work at the intersection of <a href="https://en.wikipedia.org/wiki/Computer_vision">Computer Vision</a> and <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a> to the next step, hence we hope this dataset will help spur progress in the field.</abstract>
      <bibkey>ramisa-etal-2017-breakingnews</bibkey>
    </paper>
    <paper id="7">
      <title>Multi-Modal Fashion Product Retrieval</title>
      <author><first>Antonio</first><last>Rubio Romano</last></author>
      <author><first>LongLong</first><last>Yu</last></author>
      <author><first>Edgar</first><last>Simo-Serra</last></author>
      <author><first>Francesc</first><last>Moreno-Noguer</last></author>
      <pages>43–45</pages>
      <url hash="c6519f93">W17-2007</url>
      <doi>10.18653/v1/W17-2007</doi>
      <abstract>Finding a product in the <a href="https://en.wikipedia.org/wiki/Fashion">fashion world</a> can be a daunting task. Everyday, e-commerce sites are updating with thousands of <a href="https://en.wikipedia.org/wiki/Digital_image">images</a> and their associated metadata (textual information), deepening the problem. In this paper, we leverage both the images and textual metadata and propose a joint multi-modal embedding that maps both the <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">text</a> and images into a common latent space. Distances in the latent space correspond to similarity between products, allowing us to effectively perform retrieval in this latent space. We compare against existing approaches and show significant improvements in retrieval tasks on a large-scale e-commerce dataset.</abstract>
      <bibkey>rubio-romano-etal-2017-multi</bibkey>
    </paper>
  </volume>
  <volume id="22">
    <meta>
      <booktitle>Proceedings of the Joint <fixed-case>SIGHUM</fixed-case> Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature</booktitle>
      <url hash="d35497b9">W17-22</url>
      <editor><first>Beatrice</first><last>Alex</last></editor>
      <editor><first>Stefania</first><last>Degaetano-Ortlieb</last></editor>
      <editor><first>Anna</first><last>Feldman</last></editor>
      <editor><first>Anna</first><last>Kazantseva</last></editor>
      <editor><first>Nils</first><last>Reiter</last></editor>
      <editor><first>Stan</first><last>Szpakowicz</last></editor>
      <doi>10.18653/v1/W17-22</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Vancouver, Canada</address>
      <month>August</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="2babe095">W17-2200</url>
      <bibkey>ws-2017-joint-sighum</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Metaphor Detection in a Poetry Corpus</title>
      <author><first>Vaibhav</first><last>Kesarwani</last></author>
      <author><first>Diana</first><last>Inkpen</last></author>
      <author><first>Stan</first><last>Szpakowicz</last></author>
      <author><first>Chris</first><last>Tanasescu</last></author>
      <pages>1–9</pages>
      <url hash="d3901b70">W17-2201</url>
      <doi>10.18653/v1/W17-2201</doi>
      <abstract>Metaphor is indispensable in <a href="https://en.wikipedia.org/wiki/Poetry">poetry</a>. It showcases the poet’s creativity, and contributes to the overall emotional pertinence of the poem while honing its specific rhetorical impact. Previous work on metaphor detection relies on either rule-based or statistical models, none of them applied to <a href="https://en.wikipedia.org/wiki/Poetry">poetry</a>. Our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> focuses on metaphor detection in a <a href="https://en.wikipedia.org/wiki/Text_corpus">poetry corpus</a>. It combines rule-based and statistical models (word embeddings) to develop a new classification system. Our <a href="https://en.wikipedia.org/wiki/System">system</a> has achieved a <a href="https://en.wikipedia.org/wiki/Precision_(statistics)">precision</a> of 0.759 and a <a href="https://en.wikipedia.org/wiki/Precision_(statistics)">recall</a> of 0.804 in identifying one type of <a href="https://en.wikipedia.org/wiki/Metaphor">metaphor</a> in <a href="https://en.wikipedia.org/wiki/Poetry">poetry</a>.</abstract>
      <bibkey>kesarwani-etal-2017-metaphor</bibkey>
    </paper>
    <paper id="2">
      <title>Machine Translation and Automated Analysis of the Sumerian Language<fixed-case>S</fixed-case>umerian Language</title>
      <author><first>Émilie</first><last>Pagé-Perron</last></author>
      <author><first>Maria</first><last>Sukhareva</last></author>
      <author><first>Ilya</first><last>Khait</last></author>
      <author><first>Christian</first><last>Chiarcos</last></author>
      <pages>10–16</pages>
      <url hash="3e3c642a">W17-2202</url>
      <doi>10.18653/v1/W17-2202</doi>
      <abstract>This paper presents a newly funded international project for <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> and automated analysis of ancient cuneiform languages where NLP specialists and Assyriologists collaborate to create an information retrieval system for <a href="https://en.wikipedia.org/wiki/Sumerian_language">Sumerian</a>. This research is conceived in response to the need to translate large numbers of administrative texts that are only available in transcription, in order to make them accessible to a wider audience. The <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> includes creation of a specialized NLP pipeline and also the use of linguistic linked open data to increase access to the results.</abstract>
      <bibkey>page-perron-etal-2017-machine</bibkey>
    </paper>
    <paper id="3">
      <title>Investigating the Relationship between <a href="https://en.wikipedia.org/wiki/Literary_genre">Literary Genres</a> and Emotional Plot Development</title>
      <author><first>Evgeny</first><last>Kim</last></author>
      <author><first>Sebastian</first><last>Padó</last></author>
      <author><first>Roman</first><last>Klinger</last></author>
      <pages>17–26</pages>
      <url hash="fcd861aa">W17-2203</url>
      <doi>10.18653/v1/W17-2203</doi>
      <abstract>Literary genres are commonly viewed as being defined in terms of content and <a href="https://en.wikipedia.org/wiki/Style_(visual_arts)">stylistic features</a>. In this paper, we focus on one particular class of <a href="https://en.wikipedia.org/wiki/Lexicon">lexical features</a>, namely <a href="https://en.wikipedia.org/wiki/Emotion">emotion information</a>, and investigate the hypothesis that <a href="https://en.wikipedia.org/wiki/Emotion">emotion-related information</a> correlates with particular <a href="https://en.wikipedia.org/wiki/Genre">genres</a>. Using genre classification as a testbed, we compare a model that computes lexicon-based emotion scores globally for complete stories with a model that tracks emotion arcs through stories on a subset of Project Gutenberg with five genres. Our main findings are : (a), the global emotion model is competitive with a large-vocabulary bag-of-words genre classifier (80%F1) ; (b), the emotion arc model shows a lower performance (59 % F1) but shows complementary behavior to the global model, as indicated by a very good performance of an oracle model (94 % F1) and an improved performance of an ensemble model (84 % F1) ; (c), genres differ in the extent to which stories follow the same emotional arcs, with particularly uniform behavior for anger (mystery) and fear (adventures, romance, humor, science fiction).</abstract>
      <bibkey>kim-etal-2017-investigating</bibkey>
    </paper>
    <paper id="4">
      <title>Enjambment Detection in a Large Diachronic Corpus of Spanish Sonnets<fixed-case>S</fixed-case>panish Sonnets</title>
      <author><first>Pablo</first><last>Ruiz</last></author>
      <author><first>Clara</first><last>Martínez Cantón</last></author>
      <author><first>Thierry</first><last>Poibeau</last></author>
      <author><first>Elena</first><last>González-Blanco</last></author>
      <pages>27–32</pages>
      <url hash="ecfe1b31">W17-2204</url>
      <doi>10.18653/v1/W17-2204</doi>
      <abstract>Enjambment takes place when a <a href="https://en.wikipedia.org/wiki/Syntax">syntactic unit</a> is broken up across two lines of <a href="https://en.wikipedia.org/wiki/Poetry">poetry</a>, giving rise to different <a href="https://en.wikipedia.org/wiki/Style_(visual_arts)">stylistic effects</a>. In <a href="https://en.wikipedia.org/wiki/Spanish_literature">Spanish literary studies</a>, there are unclear points about the types of stylistic effects that can arise, and under which linguistic conditions. To systematically gather evidence about this, we developed a system to automatically identify <a href="https://en.wikipedia.org/wiki/Enjambment">enjambment</a> (and its type) in <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>. For evaluation, we manually annotated a <a href="https://en.wikipedia.org/wiki/Text_corpus">reference corpus</a> covering different periods. As a scholarly corpus to apply the tool, from public HTML sources we created a diachronic corpus covering four centuries of <a href="https://en.wikipedia.org/wiki/Sonnet">sonnets</a> (3750 poems), and we analyzed the occurrence of <a href="https://en.wikipedia.org/wiki/Enjambment">enjambment</a> across stanzaic boundaries in different periods. Besides, we found examples that highlight limitations in current definitions of <a href="https://en.wikipedia.org/wiki/Enjambment">enjambment</a>.</abstract>
      <bibkey>ruiz-etal-2017-enjambment</bibkey>
    </paper>
    <paper id="5">
      <title>Plotting Markson’s Mistress<fixed-case>M</fixed-case>arkson’s “Mistress”</title>
      <author><first>Conor</first><last>Kelleher</last></author>
      <author><first>Mark</first><last>Keane</last></author>
      <pages>33–39</pages>
      <url hash="5a3223e9">W17-2205</url>
      <doi>10.18653/v1/W17-2205</doi>
      <abstract>The post-modern novel Wittgenstein’s Mistress by David Markson (1988) presents the reader with a very challenging <a href="https://en.wikipedia.org/wiki/Nonlinear_narrative">non-linear narrative</a>, that itself appears to one of the novel’s themes. We present a distant reading of this work designed to complement a close reading of it by David Foster Wallace (1990). Using a combination of text analysis, entity recognition and networks, we plot repetitive structures in the novel’s narrative relating them to its critical analysis.</abstract>
      <bibkey>kelleher-keane-2017-plotting</bibkey>
    </paper>
    <paper id="6">
      <title>Annotation Challenges for Reconstructing the Structural Elaboration of Middle Low German<fixed-case>M</fixed-case>iddle <fixed-case>L</fixed-case>ow <fixed-case>G</fixed-case>erman</title>
      <author><first>Nina</first><last>Seemann</last></author>
      <author><first>Marie-Luis</first><last>Merten</last></author>
      <author><first>Michaela</first><last>Geierhos</last></author>
      <author><first>Doris</first><last>Tophinke</last></author>
      <author><first>Eyke</first><last>Hüllermeier</last></author>
      <pages>40–45</pages>
      <url hash="df8ac10b">W17-2206</url>
      <doi>10.18653/v1/W17-2206</doi>
      <abstract>In this paper, we present the annotation challenges we have encountered when working on a <a href="https://en.wikipedia.org/wiki/Historical_language">historical language</a> that was undergoing elaboration processes. We especially focus on <a href="https://en.wikipedia.org/wiki/Syntactic_ambiguity">syntactic ambiguity</a> and <a href="https://en.wikipedia.org/wiki/Gradience">gradience</a> in <a href="https://en.wikipedia.org/wiki/Middle_Low_German">Middle Low German</a>, which causes uncertainty to some extent. Since current annotation tools consider construction contexts and the dynamics of the grammaticalization only partially, we plan to extend CorA-a web-based annotation tool for historical and other non-standard language data-to capture elaboration phenomena and annotator unsureness. Moreover, we seek to interactively learn morphological as well as syntactic annotations.</abstract>
      <bibkey>seemann-etal-2017-annotation</bibkey>
    </paper>
    <paper id="7">
      <title>Phonological Soundscapes in Medieval Poetry</title>
      <author><first>Christopher</first><last>Hench</last></author>
      <pages>46–56</pages>
      <url hash="a3ec5e13">W17-2207</url>
      <doi>10.18653/v1/W17-2207</doi>
      <abstract>The oral component of <a href="https://en.wikipedia.org/wiki/Medieval_poetry">medieval poetry</a> was integral to its performance and reception. Yet many believe that the medieval voice has been forever lost, and any attempts at rediscovering it are doomed to failure due to <a href="https://en.wikipedia.org/wiki/Scribe">scribal practices</a>, manuscript mouvance, and linguistic normalization in editing practices. This paper offers a method to abstract from this noise and better understand relative differences in phonological soundscapes by considering syllable qualities. The presented <a href="https://en.wikipedia.org/wiki/Syllabification">syllabification method</a> and soundscape analysis offer themselves as cross-disciplinary tools for low-resource languages. As a case study, we examine medieval German lyric and argue that the heavily debated lyrical ‘I’ follows a unique trajectory through soundscapes, shedding light on the performance and practice of these poets.</abstract>
      <bibkey>hench-2017-phonological</bibkey>
    </paper>
    <paper id="9">
      <title>Modeling intra-textual variation with <a href="https://en.wikipedia.org/wiki/Entropy">entropy</a> and surprisal : topical vs. stylistic patterns</title>
      <author><first>Stefania</first><last>Degaetano-Ortlieb</last></author>
      <author><first>Elke</first><last>Teich</last></author>
      <pages>68–77</pages>
      <url hash="2c7ca11d">W17-2209</url>
      <doi>10.18653/v1/W17-2209</doi>
      <abstract>We present a data-driven approach to investigate intra-textual variation by combining <a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)">entropy</a> and surprisal. With this approach we detect <a href="https://en.wikipedia.org/wiki/Variation_(linguistics)">linguistic variation</a> based on phrasal lexico-grammatical patterns across sections of research articles. Entropy is used to detect patterns typical of specific sections. Surprisal is used to differentiate between more and less informationally-loaded patterns as well as type of information (topical vs. stylistic). While we here focus on <a href="https://en.wikipedia.org/wiki/Article_(publishing)">research articles</a> in biology / genetics, the <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> is especially interesting for <a href="https://en.wikipedia.org/wiki/Digital_humanities">digital humanities scholars</a>, as it can be applied to any text type or domain and combined with additional variables (e.g. time, author or social group).</abstract>
      <bibkey>degaetano-ortlieb-teich-2017-modeling</bibkey>
    </paper>
    <paper id="12">
      <title>Speeding up corpus development for linguistic research : <a href="https://en.wikipedia.org/wiki/Language_documentation">language documentation</a> and acquisition in Romansh Tuatschin<fixed-case>R</fixed-case>omansh Tuatschin</title>
      <author><first>Géraldine</first><last>Walther</last></author>
      <author><first>Benoît</first><last>Sagot</last></author>
      <pages>89–94</pages>
      <url hash="936b5e5f">W17-2212</url>
      <doi>10.18653/v1/W17-2212</doi>
      <abstract>In this paper, we present ongoing work for developing language resources and basic NLP tools for an undocumented variety of Romansh, in the context of a language documentation and language acquisition project. Our tools are meant to improve the speed and reliability of corpus annotations for noisy data involving large amounts of <a href="https://en.wikipedia.org/wiki/Code-switching">code-switching</a>, occurrences of child-speech and orthographic noise. Being able to increase the efficiency of language resource development for language documentation and acquisition research also constitutes a step towards solving the data sparsity issues with which researchers have been struggling.</abstract>
      <bibkey>walther-sagot-2017-speeding</bibkey>
    </paper>
    <paper id="14">
      <title>A Dataset for Sanskrit Word Segmentation<fixed-case>S</fixed-case>anskrit Word Segmentation</title>
      <author><first>Amrith</first><last>Krishna</last></author>
      <author><first>Pavan Kumar</first><last>Satuluri</last></author>
      <author><first>Pawan</first><last>Goyal</last></author>
      <pages>105–114</pages>
      <url hash="6a19f3e8">W17-2214</url>
      <doi>10.18653/v1/W17-2214</doi>
      <abstract>The last decade saw a surge in digitisation efforts for ancient manuscripts in <a href="https://en.wikipedia.org/wiki/Sanskrit">Sanskrit</a>. Due to various linguistic peculiarities inherent to the language, even the preliminary tasks such as <a href="https://en.wikipedia.org/wiki/Word_segmentation">word segmentation</a> are non-trivial in <a href="https://en.wikipedia.org/wiki/Sanskrit">Sanskrit</a>. Elegant models for <a href="https://en.wikipedia.org/wiki/Word_segmentation">Word Segmentation</a> in <a href="https://en.wikipedia.org/wiki/Sanskrit">Sanskrit</a> are indispensable for further syntactic and semantic processing of the manuscripts. Current works in <a href="https://en.wikipedia.org/wiki/Word_segmentation">word segmentation</a> for <a href="https://en.wikipedia.org/wiki/Sanskrit">Sanskrit</a>, though commendable in their novelty, often have variations in their objective and evaluation criteria. In this work, we set the record straight. We formally define the objectives and the requirements for the word segmentation task. In order to encourage research in the field and to alleviate the time and effort required in pre-processing, we release a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> of 115,000 sentences for <a href="https://en.wikipedia.org/wiki/Word_segmentation">word segmentation</a>. For each sentence in the dataset we include the input character sequence, ground truth segmentation, and additionally lexical and morphological information about all the phonetically possible segments for the given sentence. In this work, we also discuss the linguistic considerations made while generating the candidate space of the possible segments.</abstract>
      <bibkey>krishna-etal-2017-dataset</bibkey>
    </paper>
    <paper id="15">
      <title>Lexical Correction of Polish Twitter Political Data<fixed-case>P</fixed-case>olish <fixed-case>T</fixed-case>witter Political Data</title>
      <author><first>Maciej</first><last>Ogrodniczuk</last></author>
      <author><first>Mateusz</first><last>Kopeć</last></author>
      <pages>115–125</pages>
      <url hash="8da3615c">W17-2215</url>
      <doi>10.18653/v1/W17-2215</doi>
      <abstract>Language processing architectures are often evaluated in near-to-perfect conditions with respect to processed content. The tools which perform sufficiently well on <a href="https://en.wikipedia.org/wiki/Electronic_publishing">electronic press</a>, <a href="https://en.wikipedia.org/wiki/Book">books</a> and other type of non-interactive content may poorly handle littered, colloquial and multilingual textual data which make the majority of communication today. This paper aims at investigating how <a href="https://en.wikipedia.org/wiki/Polish_language">Polish Twitter data</a> (in a slightly controlled ‘political’ flavour) differs from expectation of linguistic tools and how they could be corrected to be ready for processing by standard language processing chains available for <a href="https://en.wikipedia.org/wiki/Polish_language">Polish</a>. The setting includes specialised components for spelling correction of tweets as well as hashtag and username decoding.</abstract>
      <bibkey>ogrodniczuk-kopec-2017-lexical</bibkey>
    </paper>
  </volume>
  <volume id="23">
    <meta>
      <booktitle><fixed-case>B</fixed-case>io<fixed-case>NLP</fixed-case> 2017</booktitle>
      <url hash="7b6d839b">W17-23</url>
      <editor><first>Kevin Bretonnel</first><last>Cohen</last></editor>
      <editor><first>Dina</first><last>Demner-Fushman</last></editor>
      <editor><first>Sophia</first><last>Ananiadou</last></editor>
      <editor><first>Junichi</first><last>Tsujii</last></editor>
      <doi>10.18653/v1/W17-23</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Vancouver, Canada,</address>
      <month>August</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="67a7ccd6">W17-2300</url>
      <bibkey>ws-2017-bionlp</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Target word prediction and paraphasia classification in spoken discourse</title>
      <author><first>Joel</first><last>Adams</last></author>
      <author><first>Steven</first><last>Bedrick</last></author>
      <author><first>Gerasimos</first><last>Fergadiotis</last></author>
      <author><first>Kyle</first><last>Gorman</last></author>
      <author><first>Jan</first><last>van Santen</last></author>
      <pages>1–8</pages>
      <url hash="76bc6f8e">W17-2301</url>
      <doi>10.18653/v1/W17-2301</doi>
      <abstract>We present a system for automatically detecting and classifying phonologically anomalous productions in the <a href="https://en.wikipedia.org/wiki/Speech">speech</a> of individuals with <a href="https://en.wikipedia.org/wiki/Aphasia">aphasia</a>. Working from transcribed discourse samples, our system identifies <a href="https://en.wikipedia.org/wiki/Neologism">neologisms</a>, and uses a combination of string alignment and <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> to produce a lattice of plausible words that the speaker may have intended to produce. We then score this <a href="https://en.wikipedia.org/wiki/Lattice_(order)">lattice</a> according to various features, and attempt to determine whether the anomalous production represented a phonemic error or a genuine <a href="https://en.wikipedia.org/wiki/Neologism">neologism</a>. This approach has the potential to be expanded to consider other types of paraphasic errors, and could be applied to a wide variety of screening and therapeutic applications.</abstract>
      <bibkey>adams-etal-2017-target</bibkey>
    </paper>
    <paper id="2">
      <title>Extracting Drug-Drug Interactions with Attention CNNs<fixed-case>CNN</fixed-case>s</title>
      <author><first>Masaki</first><last>Asada</last></author>
      <author><first>Makoto</first><last>Miwa</last></author>
      <author><first>Yutaka</first><last>Sasaki</last></author>
      <pages>9–18</pages>
      <url hash="3e2b3e7e">W17-2302</url>
      <doi>10.18653/v1/W17-2302</doi>
      <abstract>We propose a novel attention mechanism for a Convolutional Neural Network (CNN)-based Drug-Drug Interaction (DDI) extraction model. CNNs have been shown to have a great potential on DDI extraction tasks ; however, <a href="https://en.wikipedia.org/wiki/Attentional_control">attention mechanisms</a>, which emphasize important words in the sentence of a target-entity pair, have not been investigated with the CNNs despite the fact that <a href="https://en.wikipedia.org/wiki/Attentional_control">attention mechanisms</a> are shown to be effective for a general domain relation classification task. We evaluated our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> on the Task 9.2 of the DDIExtraction-2013 shared task. As a result, our attention mechanism improved the performance of our base CNN-based DDI model, and the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieved an F-score of 69.12 %, which is competitive with the state-of-the-art models.</abstract>
      <bibkey>asada-etal-2017-extracting</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/ddi">DDI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2010-task-8">SemEval-2010 Task 8</pwcdataset>
    </paper>
    <paper id="3">
      <title>Insights into Analogy Completion from the Biomedical Domain</title>
      <author><first>Denis</first><last>Newman-Griffis</last></author>
      <author><first>Albert</first><last>Lai</last></author>
      <author><first>Eric</first><last>Fosler-Lussier</last></author>
      <pages>19–28</pages>
      <url hash="2778818f">W17-2303</url>
      <doi>10.18653/v1/W17-2303</doi>
      <abstract>Analogy completion has been a popular task in recent years for evaluating the semantic properties of word embeddings, but the standard methodology makes a number of assumptions about <a href="https://en.wikipedia.org/wiki/Analogy">analogies</a> that do not always hold, either in recent benchmark datasets or when expanding into other domains. Through an analysis of analogies in the biomedical domain, we identify three assumptions : that of a Single Answer for any given <a href="https://en.wikipedia.org/wiki/Analogy">analogy</a>, that the pairs involved describe the Same Relationship, and that each pair is Informative with respect to the other. We propose modifying the standard <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> to relax these assumptions by allowing for multiple correct answers, reporting MAP and MRR in addition to <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>, and using multiple example pairs. We further present BMASS, a novel dataset for evaluating linguistic regularities in biomedical embeddings, and demonstrate that the relationships described in the dataset pose significant semantic challenges to current word embedding methods.</abstract>
      <bibkey>newman-griffis-etal-2017-insights</bibkey>
      <pwccode url="https://github.com/OSU-slatelab/BMASS" additional="false">OSU-slatelab/BMASS</pwccode>
    </paper>
    <paper id="4">
      <title>Deep learning for extracting protein-protein interactions from biomedical literature</title>
      <author><first>Yifan</first><last>Peng</last></author>
      <author><first>Zhiyong</first><last>Lu</last></author>
      <pages>29–38</pages>
      <url hash="00759987">W17-2304</url>
      <doi>10.18653/v1/W17-2304</doi>
      <abstract>State-of-the-art methods for protein-protein interaction (PPI) extraction are primarily feature-based or kernel-based by leveraging lexical and syntactic information. But how to incorporate such knowledge in the recent <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning methods</a> remains an open question. In this paper, we propose a multichannel dependency-based convolutional neural network model (McDepCNN). It applies one channel to the <a href="https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms">embedding vector</a> of each word in the sentence, and another channel to the <a href="https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms">embedding vector</a> of the head of the corresponding word. Therefore, the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> can use richer information obtained from different channels. Experiments on two public benchmarking datasets, AIMed and BioInfer, demonstrate that McDepCNN provides up to 6 % F1-score improvement over rich feature-based methods and single-kernel methods. In addition, McDepCNN achieves 24.4 % relative improvement in <a href="https://en.wikipedia.org/wiki/F-number">F1-score</a> over the state-of-the-art methods on cross-corpus evaluation and 12 % improvement in <a href="https://en.wikipedia.org/wiki/F-number">F1-score</a> over kernel-based methods on difficult instances. These results suggest that McDepCNN generalizes more easily over different corpora, and is capable of capturing long distance features in the sentences.</abstract>
      <bibkey>peng-lu-2017-deep</bibkey>
    </paper>
    <paper id="5">
      <title>Stacking With Auxiliary Features for Entity Linking in the Medical Domain</title>
      <author><first>Nazneen Fatema</first><last>Rajani</last></author>
      <author><first>Mihaela</first><last>Bornea</last></author>
      <author><first>Ken</first><last>Barker</last></author>
      <pages>39–47</pages>
      <url hash="4dfdbfb3">W17-2305</url>
      <doi>10.18653/v1/W17-2305</doi>
      <abstract>Linking spans of natural language text to concepts in a structured source is an important task for many problems. It allows intelligent systems to leverage rich knowledge available in those sources (such as concept properties and relations) to enhance the <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> of the mentions of these concepts in text. In the medical domain, it is common to link text spans to medical concepts in large, curated knowledge repositories such as the <a href="https://en.wikipedia.org/wiki/Unified_Medical_Language_System">Unified Medical Language System</a>. Different approaches have different strengths : some are precision-oriented, some recall-oriented ; some better at considering context but more prone to <a href="https://en.wikipedia.org/wiki/Hallucination">hallucination</a>. The variety of techniques suggests that <a href="https://en.wikipedia.org/wiki/Assembly_language">ensembling</a> could outperform component technologies at this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. In this paper, we describe our process for building a Stacking ensemble using additional, auxiliary features for Entity Linking in the medical domain. We report experiments that show that naive ensembling does not always outperform component Entity Linking systems, that stacking usually outperforms naive ensembling, and that auxiliary features added to the stacker further improve its performance on three distinct datasets. Our best <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> produces state-of-the-art results on several <a href="https://en.wikipedia.org/wiki/Data_set">medical datasets</a>.</abstract>
      <bibkey>rajani-etal-2017-stacking</bibkey>
    </paper>
    <paper id="7">
      <title>Tackling Biomedical Text Summarization : OAQA at BioASQ 5B<fixed-case>OAQA</fixed-case> at <fixed-case>B</fixed-case>io<fixed-case>ASQ</fixed-case> 5<fixed-case>B</fixed-case></title>
      <author><first>Khyathi</first><last>Chandu</last></author>
      <author><first>Aakanksha</first><last>Naik</last></author>
      <author><first>Aditya</first><last>Chandrasekar</last></author>
      <author><first>Zi</first><last>Yang</last></author>
      <author><first>Niloy</first><last>Gupta</last></author>
      <author><first>Eric</first><last>Nyberg</last></author>
      <pages>58–66</pages>
      <url hash="3ec8bb7b">W17-2307</url>
      <doi>10.18653/v1/W17-2307</doi>
      <abstract>In this paper, we describe our participation in phase B of task 5b of the fifth edition of the annual BioASQ challenge, which includes answering factoid, list, yes-no and summary questions from biomedical data. We describe our techniques with an emphasis on ideal answer generation, where the goal is to produce a relevant, precise, non-redundant, query-oriented summary from multiple relevant documents. We make use of extractive summarization techniques to address this task and experiment with different biomedical ontologies and various algorithms including <a href="https://en.wikipedia.org/wiki/Agglomerative_clustering">agglomerative clustering</a>, Maximum Marginal Relevance (MMR) and sentence compression. We propose a novel word embedding based tf-idf similarity metric and a soft positional constraint which improve our system performance. We evaluate our <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">techniques</a> on test batch 4 from the fourth edition of the challenge. Our best system achieves a ROUGE-2 score of 0.6534 and ROUGE-SU4 score of 0.6536.</abstract>
      <bibkey>chandu-etal-2017-tackling</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/bioasq">BioASQ</pwcdataset>
    </paper>
    <paper id="8">
      <title>Macquarie University at BioASQ 5b   Query-based Summarisation Techniques for Selecting the Ideal Answers<fixed-case>M</fixed-case>acquarie <fixed-case>U</fixed-case>niversity at <fixed-case>B</fixed-case>io<fixed-case>ASQ</fixed-case> 5b – Query-based Summarisation Techniques for Selecting the Ideal Answers</title>
      <author><first>Diego</first><last>Mollá</last></author>
      <pages>67–75</pages>
      <url hash="bd71a0d2">W17-2308</url>
      <doi>10.18653/v1/W17-2308</doi>
      <abstract>Macquarie University’s contribution to the BioASQ challenge (Task 5b Phase B) focused on the use of query-based extractive summarisation techniques for the generation of the ideal answers. Four runs were submitted, with approaches ranging from a <a href="https://en.wikipedia.org/wiki/Triviality_(mathematics)">trivial system</a> that selected the first n snippets, to the use of <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning approaches</a> under a <a href="https://en.wikipedia.org/wiki/Regression_analysis">regression framework</a>. Our experiments and the ROUGE results of the five test batches of BioASQ indicate surprisingly good results for the trivial approach. Overall, most of our runs on the first three test batches achieved the best ROUGE-SU4 results in the challenge.<tex-math>n</tex-math> snippets, to the use of deep learning approaches under a regression framework. Our experiments and the ROUGE results of the five test batches of BioASQ indicate surprisingly good results for the trivial approach. Overall, most of our runs on the first three test batches achieved the best ROUGE-SU4 results in the challenge. </abstract>
      <bibkey>molla-2017-macquarie</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/bioasq">BioASQ</pwcdataset>
    </paper>
    <paper id="9">
      <title>Neural Question Answering at BioASQ 5B<fixed-case>B</fixed-case>io<fixed-case>ASQ</fixed-case> 5<fixed-case>B</fixed-case></title>
      <author><first>Georg</first><last>Wiese</last></author>
      <author><first>Dirk</first><last>Weissenborn</last></author>
      <author><first>Mariana</first><last>Neves</last></author>
      <pages>76–79</pages>
      <url hash="863b7850">W17-2309</url>
      <doi>10.18653/v1/W17-2309</doi>
      <attachment type="presentation" hash="02bdbb00">W17-2309.Presentation.pdf</attachment>
      <abstract>This paper describes our submission to the 2017 BioASQ challenge. We participated in Task B, Phase B which is concerned with biomedical question answering (QA). We focus on factoid and list question, using an extractive QA model, that is, we restrict our system to output substrings of the provided text snippets. At the core of our <a href="https://en.wikipedia.org/wiki/System">system</a>, we use FastQA, a state-of-the-art neural QA system. We extended it with biomedical word embeddings and changed its answer layer to be able to answer list questions in addition to factoid questions. We pre-trained the model on a large-scale open-domain QA dataset, SQuAD, and then fine-tuned the parameters on the BioASQ training set. With our approach, we achieve state-of-the-art results on factoid questions and competitive results on list questions.</abstract>
      <bibkey>wiese-etal-2017-neural-question</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="10">
      <title>End-to-End System for Bacteria Habitat Extraction</title>
      <author><first>Farrokh</first><last>Mehryary</last></author>
      <author><first>Kai</first><last>Hakala</last></author>
      <author><first>Suwisa</first><last>Kaewphan</last></author>
      <author><first>Jari</first><last>Björne</last></author>
      <author><first>Tapio</first><last>Salakoski</last></author>
      <author><first>Filip</first><last>Ginter</last></author>
      <pages>80–90</pages>
      <url hash="a8719fff">W17-2310</url>
      <doi>10.18653/v1/W17-2310</doi>
      <abstract>We introduce an end-to-end system capable of <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named-entity detection</a>, <a href="https://en.wikipedia.org/wiki/Normalization_(statistics)">normalization</a> and relation extraction for extracting information about bacteria and their habitats from <a href="https://en.wikipedia.org/wiki/Medical_literature">biomedical literature</a>. Our system is based on <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a>, CRF classifiers and <a href="https://en.wikipedia.org/wiki/Vector_space_model">vector space models</a>. We train and evaluate the <a href="https://en.wikipedia.org/wiki/System">system</a> on the BioNLP 2016 Shared Task Bacteria Biotope data. The official evaluation shows that the joint performance of our entity detection and relation extraction models outperforms the winning team of the Shared Task by 19pp on F1-score, establishing a new top score for the task. We also achieve state-of-the-art results in the <a href="https://en.wikipedia.org/wiki/Normalization_(statistics)">normalization task</a>. Our <a href="https://en.wikipedia.org/wiki/System">system</a> is open source and freely available at.<url>https://github.com/TurkuNLP/BHE</url>.
    </abstract>
      <bibkey>mehryary-etal-2017-end</bibkey>
      <pwccode url="https://github.com/TurkuNLP/BHE" additional="false">TurkuNLP/BHE</pwccode>
    </paper>
    <paper id="12">
      <title>Representation of complex terms in a <a href="https://en.wikipedia.org/wiki/Vector_space">vector space</a> structured by an <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontology</a> for a normalization task</title>
      <author><first>Arnaud</first><last>Ferré</last></author>
      <author><first>Pierre</first><last>Zweigenbaum</last></author>
      <author><first>Claire</first><last>Nédellec</last></author>
      <pages>99–106</pages>
      <url hash="1b04892a">W17-2312</url>
      <doi>10.18653/v1/W17-2312</doi>
      <abstract>We propose in this paper a <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning">semi-supervised method</a> for labeling terms of texts with concepts of a <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">domain ontology</a>. The method generates continuous vector representations of complex terms in a <a href="https://en.wikipedia.org/wiki/Semantic_space">semantic space</a> structured by the <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontology</a>. The proposed method relies on a distributional semantics approach, which generates initial vectors for each of the extracted terms. Then these <a href="https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics)">vectors</a> are embedded in the <a href="https://en.wikipedia.org/wiki/Vector_space">vector space</a> constructed from the structure of the ontology. This embedding is carried out by training a <a href="https://en.wikipedia.org/wiki/Linear_model">linear model</a>. Finally, we apply a distance calculation to determine the proximity between vectors of terms and vectors of concepts and thus to assign <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontology labels</a> to terms. We have evaluated the quality of these representations for a normalization task by using the concepts of an <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontology</a> as semantic labels. Normalization of terms is an important step to extract a part of the information containing in texts, but the <a href="https://en.wikipedia.org/wiki/Vector_space">vector space</a> generated might find other applications. The performance of this <a href="https://en.wikipedia.org/wiki/Methodology">method</a> is comparable to that of the state of the art for this task of standardization, opening up encouraging prospects.</abstract>
      <bibkey>ferre-etal-2017-representation</bibkey>
    </paper>
    <paper id="13">
      <title>Improving Correlation with Human Judgments by Integrating Semantic Similarity with SecondOrder Vectors</title>
      <author><first>Bridget</first><last>McInnes</last></author>
      <author><first>Ted</first><last>Pedersen</last></author>
      <pages>107–116</pages>
      <url hash="be423f65">W17-2313</url>
      <doi>10.18653/v1/W17-2313</doi>
      <abstract>Vector space methods that measure semantic similarity and relatedness often rely on distributional information such as cooccurrence frequencies or <a href="https://en.wikipedia.org/wiki/Correlation_and_dependence">statistical measures of association</a> to weight the importance of particular cooccurrences. In this paper, we extend these methods by incorporating a measure of <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a> based on a human curated taxonomy into a secondorder vector representation. This results in a measure of <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic relatedness</a> that combines both the <a href="https://en.wikipedia.org/wiki/Context_(language_use)">contextual information</a> available in a corpusbased vector space representation with the semantic knowledge found in a biomedical ontology. Our results show that incorporating <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a> into a second order co-occurrence matrices improves correlation with human judgments for both similarity and relatedness, and that our method compares favorably to various different word embedding methods that have recently been evaluated on the same reference standards we have used.</abstract>
      <bibkey>mcinnes-pedersen-2017-improving</bibkey>
    </paper>
    <paper id="14">
      <title>Proactive Learning for Named Entity Recognition</title>
      <author><first>Maolin</first><last>Li</last></author>
      <author><first>Nhung</first><last>Nguyen</last></author>
      <author><first>Sophia</first><last>Ananiadou</last></author>
      <pages>117–125</pages>
      <url hash="3781ffaf">W17-2314</url>
      <doi>10.18653/v1/W17-2314</doi>
      <abstract>The goal of <a href="https://en.wikipedia.org/wiki/Active_learning">active learning</a> is to minimise the cost of producing an <a href="https://en.wikipedia.org/wiki/Annotation">annotated dataset</a>, in which annotators are assumed to be perfect, i.e., they always choose the correct labels. However, in practice, annotators are not infallible, and they are likely to assign incorrect labels to some instances. Proactive learning is a generalisation of active learning that can model different kinds of <a href="https://en.wikipedia.org/wiki/Annotation">annotators</a>. Although <a href="https://en.wikipedia.org/wiki/Proactive_learning">proactive learning</a> has been applied to certain labelling tasks, such as text classification, there is little work on its application to named entity (NE) tagging. In this paper, we propose a proactive learning method for producing NE annotated corpora, using two annotators with different levels of expertise, and who charge different amounts based on their levels of experience. To optimise both cost and annotation quality, we also propose a mechanism to present multiple sentences to annotators at each iteration. Experimental results for several corpora show that our method facilitates the construction of high-quality NE labelled datasets at minimal cost.</abstract>
      <bibkey>li-etal-2017-proactive</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/genia">GENIA</pwcdataset>
    </paper>
    <paper id="15">
      <title>Biomedical Event Extraction using Abstract Meaning Representation<fixed-case>A</fixed-case>bstract <fixed-case>M</fixed-case>eaning <fixed-case>R</fixed-case>epresentation</title>
      <author><first>Sudha</first><last>Rao</last></author>
      <author><first>Daniel</first><last>Marcu</last></author>
      <author><first>Kevin</first><last>Knight</last></author>
      <author><first>Hal</first><last>Daumé III</last></author>
      <pages>126–135</pages>
      <url hash="a166611d">W17-2315</url>
      <doi>10.18653/v1/W17-2315</doi>
      <abstract>We propose a novel, Abstract Meaning Representation (AMR) based approach to identifying molecular events / interactions in biomedical text. Our key contributions are : (1) an empirical validation of our hypothesis that an event is a subgraph of the AMR graph, (2) a neural network-based model that identifies such an event subgraph given an AMR, and (3) a distant supervision based approach to gather additional training data. We evaluate our approach on the 2013 Genia Event Extraction dataset and show promising results.</abstract>
      <bibkey>rao-etal-2017-biomedical</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/bio">Bio</pwcdataset>
    </paper>
    <paper id="16">
      <title>Detecting Personal Medication Intake in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> : An Annotated Corpus and Baseline Classification System<fixed-case>T</fixed-case>witter: An Annotated Corpus and Baseline Classification System</title>
      <author><first>Ari</first><last>Klein</last></author>
      <author><first>Abeed</first><last>Sarker</last></author>
      <author><first>Masoud</first><last>Rouhizadeh</last></author>
      <author><first>Karen</first><last>O’Connor</last></author>
      <author><first>Graciela</first><last>Gonzalez</last></author>
      <pages>136–142</pages>
      <url hash="2cf000df">W17-2316</url>
      <doi>10.18653/v1/W17-2316</doi>
      <abstract>Social media sites (e.g., <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>) have been used for surveillance of drug safety at the population level, but studies that focus on the effects of medications on specific sets of individuals have had to rely on other sources of data. Mining social media data for this in-formation would require the ability to distinguish indications of personal medication in-take in this <a href="https://en.wikipedia.org/wiki/Media_(communication)">media</a>. Towards that end, this paper presents an annotated corpus that can be used to train <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning systems</a> to determine whether a tweet that mentions a medication indicates that the individual posting has taken that medication at a specific time. To demonstrate the utility of the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> as a training set, we present baseline results of <a href="https://en.wikipedia.org/wiki/Supervised_classification">supervised classification</a>.</abstract>
      <bibkey>klein-etal-2017-detecting</bibkey>
    </paper>
    <paper id="17">
      <title>Unsupervised Context-Sensitive Spelling Correction of Clinical Free-Text with Word and Character N-Gram Embeddings</title>
      <author><first>Pieter</first><last>Fivez</last></author>
      <author><first>Simon</first><last>Šuster</last></author>
      <author><first>Walter</first><last>Daelemans</last></author>
      <pages>143–148</pages>
      <url hash="5321a5f0">W17-2317</url>
      <doi>10.18653/v1/W17-2317</doi>
      <abstract>We present an unsupervised context-sensitive spelling correction method for clinical free-text that uses word and character n-gram embeddings. Our method generates misspelling replacement candidates and ranks them according to their semantic fit, by calculating a weighted cosine similarity between the vectorized representation of a candidate and the misspelling context. We greatly outperform two baseline off-the-shelf spelling correction tools on a manually annotated MIMIC-III test set, and counter the frequency bias of an optimized noisy channel model, showing that neural embeddings can be successfully exploited to include context-awareness in a spelling correction model.</abstract>
      <bibkey>fivez-etal-2017-unsupervised</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/mimic-iii">MIMIC-III</pwcdataset>
    </paper>
    <paper id="18">
      <title>Characterization of Divergence in Impaired Speech of ALS Patients<fixed-case>ALS</fixed-case> Patients</title>
      <author><first>Archna</first><last>Bhatia</last></author>
      <author><first>Bonnie</first><last>Dorr</last></author>
      <author><first>Kristy</first><last>Hollingshead</last></author>
      <author><first>Samuel L.</first><last>Phillips</last></author>
      <author><first>Barbara</first><last>McKenzie</last></author>
      <pages>149–158</pages>
      <url hash="92cefb6c">W17-2318</url>
      <doi>10.18653/v1/W17-2318</doi>
      <abstract>Approximately 80 % to 95 % of patients with Amyotrophic Lateral Sclerosis (ALS) eventually develop speech impairments, such as defective articulation, slow laborious speech and <a href="https://en.wikipedia.org/wiki/Hypernasal_speech">hypernasality</a>. The relationship between <a href="https://en.wikipedia.org/wiki/Speech_disorder">impaired speech</a> and asymptomatic speech may be seen as a divergence from a baseline. This relationship can be characterized in terms of measurable combinations of <a href="https://en.wikipedia.org/wiki/Phonology">phonological characteristics</a> that are indicative of the degree to which the two diverge. We demonstrate that divergence measurements based on <a href="https://en.wikipedia.org/wiki/Phonology">phonological characteristics of speech</a> correlate with <a href="https://en.wikipedia.org/wiki/Physiology">physiological assessments of ALS</a>. Speech-based assessments offer benefits over commonly-used physiological assessments in that they are inexpensive, non-intrusive, and do not require trained clinical personnel for administering and interpreting the results.</abstract>
      <bibkey>bhatia-etal-2017-characterization</bibkey>
    </paper>
    <paper id="19">
      <title>Deep Learning for Punctuation Restoration in Medical Reports</title>
      <author><first>Wael</first><last>Salloum</last></author>
      <author><first>Greg</first><last>Finley</last></author>
      <author><first>Erik</first><last>Edwards</last></author>
      <author><first>Mark</first><last>Miller</last></author>
      <author><first>David</first><last>Suendermann-Oeft</last></author>
      <pages>159–164</pages>
      <url hash="71190cfb">W17-2319</url>
      <doi>10.18653/v1/W17-2319</doi>
      <abstract>In clinical dictation, speakers try to be as concise as possible to save time, often resulting in utterances without explicit punctuation commands. Since the end product of a dictated report, e.g. an out-patient letter, does require correct <a href="https://en.wikipedia.org/wiki/Orthography">orthography</a>, including exact <a href="https://en.wikipedia.org/wiki/Punctuation">punctuation</a>, the latter need to be restored, preferably by automated means. This paper describes a method for punctuation restoration based on a state-of-the-art stack of NLP and machine learning techniques including B-RNNs with an attention mechanism and late fusion, as well as a feature extraction technique tailored to the processing of medical terminology using a novel vocabulary reduction model. To the best of our knowledge, the resulting performance is superior to that reported in prior art on similar <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a>.</abstract>
      <bibkey>salloum-etal-2017-deep</bibkey>
    </paper>
    <paper id="20">
      <title>Unsupervised Domain Adaptation for Clinical Negation Detection</title>
      <author><first>Timothy</first><last>Miller</last></author>
      <author><first>Steven</first><last>Bethard</last></author>
      <author><first>Hadi</first><last>Amiri</last></author>
      <author><first>Guergana</first><last>Savova</last></author>
      <pages>165–170</pages>
      <url hash="78b2ba71">W17-2320</url>
      <doi>10.18653/v1/W17-2320</doi>
      <abstract>Detecting negated concepts in clinical texts is an important part of NLP information extraction systems. However, generalizability of negation systems is lacking, as cross-domain experiments suffer dramatic performance losses. We examine the performance of multiple unsupervised domain adaptation algorithms on clinical negation detection, finding only modest gains that fall well short of in-domain performance.</abstract>
      <bibkey>miller-etal-2017-unsupervised</bibkey>
    </paper>
    <paper id="21">
      <title>BioCreative VI Precision Medicine Track : creating a training corpus for mining protein-protein interactions affected by mutations<fixed-case>B</fixed-case>io<fixed-case>C</fixed-case>reative <fixed-case>VI</fixed-case> Precision Medicine Track: creating a training corpus for mining protein-protein interactions affected by mutations</title>
      <author><first>Rezarta</first><last>Islamaj Doğan</last></author>
      <author><first>Andrew</first><last>Chatr-aryamontri</last></author>
      <author><first>Sun</first><last>Kim</last></author>
      <author><first>Chih-Hsuan</first><last>Wei</last></author>
      <author><first>Yifan</first><last>Peng</last></author>
      <author><first>Donald</first><last>Comeau</last></author>
      <author><first>Zhiyong</first><last>Lu</last></author>
      <pages>171–175</pages>
      <url hash="3d101687">W17-2321</url>
      <doi>10.18653/v1/W17-2321</doi>
      <abstract>The Precision Medicine Track in BioCre-ative VI aims to bring together the Bi-oNLP community for a novel challenge focused on mining the biomedical litera-ture in search of mutations and protein-protein interactions (PPI). In order to support this track with an effective train-ing dataset with limited curator time, the track organizers carefully reviewed Pub-Med articles from two different sources : curated public PPI databases, and the re-sults of state-of-the-art public text mining tools. We detail here the <a href="https://en.wikipedia.org/wiki/Data_collection">data collection</a>, manual review and annotation process and describe this training corpus charac-teristics. We also describe a corpus per-formance baseline. This analysis will provide useful information to developers and researchers for comparing and devel-oping innovative text mining approaches for the BioCreative VI challenge and other Precision Medicine related applica-tions.</abstract>
      <bibkey>islamaj-dogan-etal-2017-biocreative</bibkey>
    </paper>
    <paper id="22">
      <title>Painless Relation Extraction with Kindred</title>
      <author><first>Jake</first><last>Lever</last></author>
      <author><first>Steven</first><last>Jones</last></author>
      <pages>176–183</pages>
      <url hash="37da6480">W17-2322</url>
      <doi>10.18653/v1/W17-2322</doi>
      <abstract>Relation extraction methods are essential for creating robust text mining tools to help researchers find useful knowledge in the vast published literature. Easy-to-use and generalizable methods are needed to encourage an ecosystem in which researchers can easily use shared resources and build upon each others’ methods. We present the Kindred Python package for <a href="https://en.wikipedia.org/wiki/Relation_extraction">relation extraction</a>. It builds upon methods from the most successful tools in the recent BioNLP Shared Task to predict high-quality predictions with low computational cost. It also integrates with PubAnnotation, PubTator, and BioNLP Shared Task data in order to allow easy development and application of relation extraction models.</abstract>
      <bibkey>lever-jones-2017-painless</bibkey>
    </paper>
    <paper id="23">
      <title>Noise Reduction Methods for Distantly Supervised Biomedical Relation Extraction</title>
      <author><first>Gang</first><last>Li</last></author>
      <author><first>Cathy</first><last>Wu</last></author>
      <author><first>K.</first><last>Vijay-Shanker</last></author>
      <pages>184–193</pages>
      <url hash="d16de010">W17-2323</url>
      <doi>10.18653/v1/W17-2323</doi>
      <abstract>Distant supervision has been applied to automatically generate labeled data for biomedical relation extraction. Noise exists in both positively and negatively-labeled data and affects the performance of supervised machine learning methods. In this paper, we propose three novel <a href="https://en.wikipedia.org/wiki/Heuristic">heuristics</a> based on the notion of proximity, trigger word and confidence of patterns to leverage lexical and syntactic information to reduce the level of noise in the distantly labeled data. Experiments on three different tasks, extraction of protein-protein-interaction, miRNA-gene regulation relation and protein-localization event, show that the proposed methods can improve the <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> over the baseline by 6, 10 and 14 points for the three tasks, respectively. We also show that when the <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> are configured to output high-confidence results, high precisions can be obtained using the proposed methods, making them promising for facilitating manual curation for <a href="https://en.wikipedia.org/wiki/Database">databases</a>.</abstract>
      <bibkey>li-etal-2017-noise</bibkey>
    </paper>
    <paper id="24">
      <title>Role-Preserving Redaction of Medical Records to Enable Ontology-Driven Processing</title>
      <author><first>Seth</first><last>Polsley</last></author>
      <author><first>Atif</first><last>Tahir</last></author>
      <author><first>Muppala</first><last>Raju</last></author>
      <author><first>Akintayo</first><last>Akinleye</last></author>
      <author><first>Duane</first><last>Steward</last></author>
      <pages>194–199</pages>
      <url hash="6db6c684">W17-2324</url>
      <doi>10.18653/v1/W17-2324</doi>
      <abstract>Electronic medical records (EMR) have largely replaced hand-written patient files in healthcare. The growing pool of <a href="https://en.wikipedia.org/wiki/Electronic_health_record">EMR data</a> presents a significant resource in <a href="https://en.wikipedia.org/wiki/Medical_research">medical research</a>, but the U.S. Health Insurance Portability and Accountability Act (HIPAA) mandates redacting <a href="https://en.wikipedia.org/wiki/Medical_record">medical records</a> before performing any analysis on the same. This process complicates obtaining <a href="https://en.wikipedia.org/wiki/Medical_record">medical data</a> and can remove much useful information from the record. As part of a larger project involving ontology-driven medical processing, we employ a method of recognizing protected health information (PHI) that maps to <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontological terms</a>. We then use the relationships defined in the <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontology</a> to redact medical texts so that roles and semantics of terms are retained without compromising <a href="https://en.wikipedia.org/wiki/Anonymity">anonymity</a>. The method is evaluated by clinical experts on several hundred <a href="https://en.wikipedia.org/wiki/Medical_record">medical documents</a>, achieving up to a 98.8 % <a href="https://en.wikipedia.org/wiki/F-score">f-score</a>, and has already shown promise for retaining semantic information in later processing.</abstract>
      <bibkey>polsley-etal-2017-role</bibkey>
    </paper>
    <paper id="25">
      <title>Annotation of pain and anesthesia events for surgery-related processes and outcomes extraction</title>
      <author><first>Wen-wai</first><last>Yim</last></author>
      <author><first>Dario</first><last>Tedesco</last></author>
      <author><first>Catherine</first><last>Curtin</last></author>
      <author><first>Tina</first><last>Hernandez-Boussard</last></author>
      <pages>200–205</pages>
      <url hash="71f8a200">W17-2325</url>
      <doi>10.18653/v1/W17-2325</doi>
      <abstract>Pain and anesthesia information are crucial elements to identifying surgery-related processes and outcomes. However <a href="https://en.wikipedia.org/wiki/Pain">pain</a> is not consistently recorded in the <a href="https://en.wikipedia.org/wiki/Electronic_health_record">electronic medical record</a>. Even when recorded, the rich complex granularity of the pain experience may be lost. Similarly, anesthesia information is recorded using local electronic collection systems ; though the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and completeness of the information is unknown. We propose an annotation schema to capture <a href="https://en.wikipedia.org/wiki/Pain">pain</a>, <a href="https://en.wikipedia.org/wiki/Pain_management">pain management</a>, and anesthesia event information.</abstract>
      <bibkey>yim-etal-2017-annotation</bibkey>
    </paper>
    <paper id="26">
      <title>Identifying Comparative Structures in Biomedical Text</title>
      <author><first>Samir</first><last>Gupta</last></author>
      <author><first>A.S.M. Ashique</first><last>Mahmood</last></author>
      <author><first>Karen</first><last>Ross</last></author>
      <author><first>Cathy</first><last>Wu</last></author>
      <author><first>K.</first><last>Vijay-Shanker</last></author>
      <pages>206–215</pages>
      <url hash="ae45d653">W17-2326</url>
      <doi>10.18653/v1/W17-2326</doi>
      <abstract>Comparison sentences are very commonly used by authors in <a href="https://en.wikipedia.org/wiki/Medical_literature">biomedical literature</a> to report results of experiments. In such comparisons, authors typically make observations under two different scenarios. In this paper, we present a <a href="https://en.wikipedia.org/wiki/System">system</a> to automatically identify such comparative sentences and their components i.e. the compared entities, the scale of the comparison and the aspect on which the entities are being compared. Our <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> is based on <a href="https://en.wikipedia.org/wiki/Coupling_(computer_programming)">dependencies</a> obtained by applying a <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> to extract a wide range of comparison structures. We evaluated our <a href="https://en.wikipedia.org/wiki/System">system</a> for its effectiveness in identifying comparisons and their components. The <a href="https://en.wikipedia.org/wiki/System">system</a> achieved a F-score of 0.87 for comparison sentence identification and 0.77-0.81 for identifying its components.</abstract>
      <bibkey>gupta-etal-2017-identifying</bibkey>
    </paper>
    <paper id="27">
      <title>Tagging Funding Agencies and Grants in Scientific Articles using Sequential Learning Models</title>
      <author><first>Subhradeep</first><last>Kayal</last></author>
      <author><first>Zubair</first><last>Afzal</last></author>
      <author><first>George</first><last>Tsatsaronis</last></author>
      <author><first>Sophia</first><last>Katrenko</last></author>
      <author><first>Pascal</first><last>Coupet</last></author>
      <author><first>Marius</first><last>Doornenbal</last></author>
      <author><first>Michelle</first><last>Gregory</last></author>
      <pages>216–221</pages>
      <url hash="6656f415">W17-2327</url>
      <doi>10.18653/v1/W17-2327</doi>
      <abstract>In this paper we present a solution for tagging funding bodies and grants in scientific articles using a combination of trained sequential learning models, namely conditional random fields (CRF), hidden markov models (HMM) and maximum entropy models (MaxEnt), on a benchmark set created in-house. We apply the trained models to address the BioASQ challenge 5c, which is a newly introduced task that aims to solve the problem of funding information extraction from scientific articles. Results in the dry-run data set of BioASQ task 5c show that the suggested approach can achieve a micro-recall of more than 85 % in tagging both funding bodies and grants.</abstract>
      <bibkey>kayal-etal-2017-tagging</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/bioasq">BioASQ</pwcdataset>
    </paper>
    <paper id="28">
      <title>Deep Learning for Biomedical Information Retrieval : Learning Textual Relevance from Click Logs</title>
      <author><first>Sunil</first><last>Mohan</last></author>
      <author><first>Nicolas</first><last>Fiorini</last></author>
      <author><first>Sun</first><last>Kim</last></author>
      <author><first>Zhiyong</first><last>Lu</last></author>
      <pages>222–231</pages>
      <url hash="a2eaff4d">W17-2328</url>
      <doi>10.18653/v1/W17-2328</doi>
      <abstract>We describe a Deep Learning approach to modeling the relevance of a document’s text to a query, applied to biomedical literature. Instead of mapping each document and query to a common semantic space, we compute a variable-length difference vector between the query and document which is then passed through a deep convolution stage followed by a deep regression network to produce the estimated probability of the document’s relevance to the query. Despite the small amount of training data, this approach produces a more robust predictor than computing similarities between semantic vector representations of the query and document, and also results in significant improvements over traditional IR text factors. In the future, we plan to explore its application in improving <a href="https://en.wikipedia.org/wiki/PubMed">PubMed search</a>.</abstract>
      <bibkey>mohan-etal-2017-deep</bibkey>
    </paper>
    <paper id="29">
      <title>Detecting Dementia through Retrospective Analysis of Routine Blog Posts by Bloggers with Dementia</title>
      <author><first>Vaden</first><last>Masrani</last></author>
      <author><first>Gabriel</first><last>Murray</last></author>
      <author><first>Thalia</first><last>Field</last></author>
      <author><first>Giuseppe</first><last>Carenini</last></author>
      <pages>232–237</pages>
      <url hash="9ed50b5d">W17-2329</url>
      <doi>10.18653/v1/W17-2329</doi>
      <abstract>We investigate if writers with dementia can be automatically distinguished from those without by analyzing <a href="https://en.wikipedia.org/wiki/Marker_(linguistics)">linguistic markers</a> in <a href="https://en.wikipedia.org/wiki/Writing">written text</a>, in the form of <a href="https://en.wikipedia.org/wiki/Blog">blog posts</a>. We have built a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> of several thousand <a href="https://en.wikipedia.org/wiki/Blog">blog posts</a>, some by people with dementia and others by people with loved ones with dementia. We use this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> to train and test several <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning methods</a>, and achieve <a href="https://en.wikipedia.org/wiki/Prediction">prediction</a> performance at a level far above the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a>.</abstract>
      <bibkey>masrani-etal-2017-detecting</bibkey>
      <pwccode url="https://github.com/vadmas/blog_corpus" additional="false">vadmas/blog_corpus</pwccode>
    </paper>
    <paper id="30">
      <title>Protein Word Detection using Text Segmentation Techniques</title>
      <author><first>Devi</first><last>Ganesan</last></author>
      <author><first>Ashish V.</first><last>Tendulkar</last></author>
      <author><first>Sutanu</first><last>Chakraborti</last></author>
      <pages>238–246</pages>
      <url hash="b36be337">W17-2330</url>
      <doi>10.18653/v1/W17-2330</doi>
      <abstract>Literature in <a href="https://en.wikipedia.org/wiki/Molecular_biology">Molecular Biology</a> is abundant with linguistic metaphors. There have been works in the past that attempt to draw parallels between <a href="https://en.wikipedia.org/wiki/Linguistics">linguistics</a> and <a href="https://en.wikipedia.org/wiki/Biology">biology</a>, driven by the fundamental premise that <a href="https://en.wikipedia.org/wiki/Protein">proteins</a> have a language of their own. Since word detection is crucial to the decipherment of any unknown language, we attempt to establish a problem mapping from <a href="https://en.wikipedia.org/wiki/Natural_language">natural language text</a> to <a href="https://en.wikipedia.org/wiki/Protein_primary_structure">protein sequences</a> at the level of words. Towards this end, we explore the use of an unsupervised text segmentation algorithm to the task of extracting biological words from <a href="https://en.wikipedia.org/wiki/Protein_primary_structure">protein sequences</a>. In particular, we demonstrate the effectiveness of using <a href="https://en.wikipedia.org/wiki/Domain_knowledge">domain knowledge</a> to complement data driven approaches in the text segmentation task, as well as in its biological counterpart. We also propose a novel extrinsic evaluation measure for protein words through protein family classification.</abstract>
      <bibkey>ganesan-etal-2017-protein</bibkey>
    </paper>
    <paper id="31">
      <title>External Evaluation of Event Extraction Classifiers for Automatic Pathway Curation : An extended study of the <a href="https://en.wikipedia.org/wiki/MTOR_pathway">mTOR pathway</a><fixed-case>TOR</fixed-case> pathway</title>
      <author><first>Wojciech</first><last>Kusa</last></author>
      <author><first>Michael</first><last>Spranger</last></author>
      <pages>247–256</pages>
      <url hash="ec770904">W17-2331</url>
      <doi>10.18653/v1/W17-2331</doi>
      <abstract>This paper evaluates the impact of various event extraction systems on automatic pathway curation using the popular <a href="https://en.wikipedia.org/wiki/MTOR_pathway">mTOR pathway</a>. We quantify the impact of <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training data sets</a> as well as different <a href="https://en.wikipedia.org/wiki/Statistical_classification">machine learning classifiers</a> and show that some improve the quality of automatically extracted pathways.</abstract>
      <bibkey>kusa-spranger-2017-external</bibkey>
      <pwccode url="https://github.com/sbnlp/2017BioNLPEvaluation" additional="false">sbnlp/2017BioNLPEvaluation</pwccode>
    </paper>
    <paper id="32">
      <title>Toward Automated Early Sepsis Alerting : Identifying Infection Patients from Nursing Notes</title>
      <author><first>Emilia</first><last>Apostolova</last></author>
      <author><first>Tom</first><last>Velez</last></author>
      <pages>257–262</pages>
      <url hash="aea3cc4a">W17-2332</url>
      <doi>10.18653/v1/W17-2332</doi>
      <abstract>Severe sepsis and <a href="https://en.wikipedia.org/wiki/Septic_shock">septic shock</a> are conditions that affect millions of patients and have close to 50 % <a href="https://en.wikipedia.org/wiki/Mortality_rate">mortality rate</a>. Early identification of at-risk patients significantly improves outcomes. Electronic surveillance tools have been developed to monitor structured Electronic Medical Records and automatically recognize early signs of sepsis. However, many sepsis risk factors (e.g. symptoms and signs of infection) are often captured only in free text clinical notes. In this study, we developed a method for automatic monitoring of nursing notes for signs and symptoms of infection. We utilized a creative approach to automatically generate an annotated dataset. The <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> was used to create a <a href="https://en.wikipedia.org/wiki/Machine_learning">Machine Learning model</a> that achieved an <a href="https://en.wikipedia.org/wiki/F-number">F1-score</a> ranging from 79 to 96 %.</abstract>
      <bibkey>apostolova-velez-2017-toward</bibkey>
      <pwccode url="https://github.com/ema-/antibiotic-dictionary" additional="false">ema-/antibiotic-dictionary</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/mimic-iii">MIMIC-III</pwcdataset>
    </paper>
    <paper id="33">
      <title>Enhancing Automatic ICD-9-CM Code Assignment for Medical Texts with PubMed<fixed-case>ICD</fixed-case>-9-<fixed-case>CM</fixed-case> Code Assignment for Medical Texts with <fixed-case>P</fixed-case>ub<fixed-case>M</fixed-case>ed</title>
      <author><first>Danchen</first><last>Zhang</last></author>
      <author><first>Daqing</first><last>He</last></author>
      <author><first>Sanqiang</first><last>Zhao</last></author>
      <author><first>Lei</first><last>Li</last></author>
      <pages>263–271</pages>
      <url hash="91659678">W17-2333</url>
      <doi>10.18653/v1/W17-2333</doi>
      <abstract>Assigning a standard ICD-9-CM code to <a href="https://en.wikipedia.org/wiki/Symptom">disease symptoms</a> in <a href="https://en.wikipedia.org/wiki/Medical_literature">medical texts</a> is an important task in the <a href="https://en.wikipedia.org/wiki/Medicine">medical domain</a>. Automating this <a href="https://en.wikipedia.org/wiki/Process_(engineering)">process</a> could greatly reduce the costs. However, the effectiveness of an automatic ICD-9-CM code classifier faces a serious problem, which can be triggered by <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">unbalanced training data</a>. Frequent diseases often have more <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training data</a>, which helps its <a href="https://en.wikipedia.org/wiki/Medical_classification">classification</a> to perform better than that of an infrequent disease. However, a <a href="https://en.wikipedia.org/wiki/Incidence_(epidemiology)">disease’s frequency</a> does not necessarily reflect its importance. To resolve this training data shortage problem, we propose to strategically draw data from <a href="https://en.wikipedia.org/wiki/PubMed">PubMed</a> to enrich the training data when there is such need. We validate our method on the CMC dataset, and the evaluation results indicate that our method can significantly improve the code assignment classifiers’ performance at the macro-averaging level.</abstract>
      <bibkey>zhang-etal-2017-enhancing</bibkey>
    </paper>
    <paper id="34">
      <title>Evaluating Feature Extraction Methods for Knowledge-based Biomedical Word Sense Disambiguation</title>
      <author><first>Sam</first><last>Henry</last></author>
      <author><first>Clint</first><last>Cuffy</last></author>
      <author><first>Bridget</first><last>McInnes</last></author>
      <pages>272–281</pages>
      <url hash="d696999e">W17-2334</url>
      <doi>10.18653/v1/W17-2334</doi>
      <abstract>In this paper, we present an analysis of <a href="https://en.wikipedia.org/wiki/Feature_extraction">feature extraction methods</a> via <a href="https://en.wikipedia.org/wiki/Dimensionality_reduction">dimensionality reduction</a> for the task of biomedical Word Sense Disambiguation (WSD). We modify the vector representations in the 2-MRD WSD algorithm, and evaluate four dimensionality reduction methods : Word Embeddings using Continuous Bag of Words and Skip Gram, Singular Value Decomposition (SVD), and Principal Component Analysis (PCA). We also evaluate the effects of <a href="https://en.wikipedia.org/wiki/Vector_space">vector size</a> on the performance of each of these <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">methods</a>. Results are evaluated on five standard evaluation datasets (Abbrev.100, Abbrev.200, Abbrev.300, NLM-WSD, and MSH-WSD). We find that <a href="https://en.wikipedia.org/wiki/Norm_(mathematics)">vector sizes</a> of 100 are sufficient for all techniques except <a href="https://en.wikipedia.org/wiki/Singular_value_decomposition">SVD</a>, for which a <a href="https://en.wikipedia.org/wiki/Vector_space">vector size</a> of 1500 is referred. We also show that <a href="https://en.wikipedia.org/wiki/Word_embedding">SVD</a> performs on par with <a href="https://en.wikipedia.org/wiki/Word_embedding">Word Embeddings</a> for all but one <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>.</abstract>
      <bibkey>henry-etal-2017-evaluating</bibkey>
    </paper>
    <paper id="36">
      <title>Automated Preamble Detection in Dictated Medical Reports</title>
      <author><first>Wael</first><last>Salloum</last></author>
      <author><first>Greg</first><last>Finley</last></author>
      <author><first>Erik</first><last>Edwards</last></author>
      <author><first>Mark</first><last>Miller</last></author>
      <author><first>David</first><last>Suendermann-Oeft</last></author>
      <pages>287–295</pages>
      <url hash="f97dead9">W17-2336</url>
      <doi>10.18653/v1/W17-2336</doi>
      <abstract>Dictated medical reports very often feature a <a href="https://en.wikipedia.org/wiki/Preamble">preamble</a> containing <a href="https://en.wikipedia.org/wiki/Metainformation">metainformation</a> about the report such as patient and physician names, location and name of the clinic, date of procedure, and so on. In the medical transcription process, the <a href="https://en.wikipedia.org/wiki/Preamble">preamble</a> is usually omitted from the final report, as it contains information already available in the <a href="https://en.wikipedia.org/wiki/Electronic_health_record">electronic medical record</a>. We present a <a href="https://en.wikipedia.org/wiki/Scientific_method">method</a> which is able to automatically identify <a href="https://en.wikipedia.org/wiki/Preamble">preambles</a> in <a href="https://en.wikipedia.org/wiki/Dictation_(exercise)">medical dictations</a>. The method makes use of state-of-the-art NLP techniques including <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> and Bi-LSTMs and achieves preamble detection performance superior to humans.</abstract>
      <bibkey>salloum-etal-2017-automated</bibkey>
    </paper>
    <paper id="37">
      <title>A Biomedical Question Answering System in BioASQ 2017<fixed-case>B</fixed-case>io<fixed-case>ASQ</fixed-case> 2017</title>
      <author><first>Mourad</first><last>Sarrouti</last></author>
      <author><first>Said</first><last>Ouatik El Alaoui</last></author>
      <pages>296–301</pages>
      <url hash="26016268">W17-2337</url>
      <doi>10.18653/v1/W17-2337</doi>
      <abstract>Question answering, the identification of short accurate answers to users questions, is a longstanding challenge widely studied over the last decades in the <a href="https://en.wikipedia.org/wiki/Open_domain">open domain</a>. However, <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> still requires further efforts in the <a href="https://en.wikipedia.org/wiki/Biomedicine">biomedical domain</a>. In this paper, we describe our participation in phase B of task 5b in the 2017 BioASQ challenge using our biomedical question answering system. Our <a href="https://en.wikipedia.org/wiki/System">system</a>, dealing with four types of <a href="https://en.wikipedia.org/wiki/Question">questions</a> (i.e., yes / no, <a href="https://en.wikipedia.org/wiki/Factoid">factoid</a>, list, and summary), is based on (1) a dictionary-based approach for generating the exact answers of yes / no questions, (2) UMLS metathesaurus and term frequency metric for extracting the exact answers of <a href="https://en.wikipedia.org/wiki/Factoid">factoid and list questions</a>, and (3) the BM25 model and <a href="https://en.wikipedia.org/wiki/Unified_Modeling_Language">UMLS concepts</a> for retrieving the ideal answers (i.e., paragraph-sized summaries). Preliminary results show that our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves good and competitive results in both exact and ideal answers extraction tasks as compared with the participating systems.</abstract>
      <bibkey>sarrouti-ouatik-el-alaoui-2017-biomedical</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/bioasq">BioASQ</pwcdataset>
    </paper>
    <paper id="38">
      <title>Adapting Pre-trained Word Embeddings For Use In Medical Coding</title>
      <author><first>Kevin</first><last>Patel</last></author>
      <author><first>Divya</first><last>Patel</last></author>
      <author><first>Mansi</first><last>Golakiya</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <author><first>Nilesh</first><last>Birari</last></author>
      <pages>302–306</pages>
      <url hash="a791fd02">W17-2338</url>
      <doi>10.18653/v1/W17-2338</doi>
      <abstract>Word embeddings are a crucial component in modern <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>. Pre-trained embeddings released by different groups have been a major reason for their popularity. However, they are trained on generic corpora, which limits their direct use for domain specific tasks. In this paper, we propose a method to add task specific information to pre-trained word embeddings. Such <a href="https://en.wikipedia.org/wiki/Information">information</a> can improve their utility. We add information from medical coding data, as well as the first level from the hierarchy of ICD-10 medical code set to different pre-trained word embeddings. We adapt CBOW algorithm from the <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec package</a> for our purpose. We evaluated our approach on five different pre-trained word embeddings. Both the original word embeddings, and their modified versions (the ones with added information) were used for automated review of medical coding. The modified <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> give an improvement in <a href="https://en.wikipedia.org/wiki/F-score">f-score</a> by 1 % on the 5-fold evaluation on a private medical claims dataset. Our results show that adding extra information is possible and beneficial for the task at hand.</abstract>
      <bibkey>patel-etal-2017-adapting</bibkey>
    </paper>
    <paper id="40">
      <title>Biomedical Event Trigger Identification Using Bidirectional Recurrent Neural Network Based Models</title>
      <author><first>Rahul</first><last>V S S Patchigolla</last></author>
      <author><first>Sunil</first><last>Sahu</last></author>
      <author><first>Ashish</first><last>Anand</last></author>
      <pages>316–321</pages>
      <url hash="debbedb2">W17-2340</url>
      <doi>10.18653/v1/W17-2340</doi>
      <abstract>Biomedical events describe complex interactions between various biomedical entities. Event trigger is a word or a phrase which typically signifies the occurrence of an event. Event trigger identification is an important first step in all event extraction methods. However many of the current approaches either rely on complex hand-crafted features or consider features only within a window. In this paper we propose a method that takes the advantage of <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network (RNN)</a> to extract higher level features present across the sentence. Thus hidden state representation of RNN along with word and entity type embedding as <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> avoid relying on the complex hand-crafted features generated using various NLP toolkits. Our experiments have shown to achieve state-of-art F1-score on Multi Level Event Extraction (MLEE) corpus. We have also performed category-wise analysis of the result and discussed the importance of various <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> in trigger identification task.</abstract>
      <bibkey>v-s-s-patchigolla-etal-2017-biomedical</bibkey>
      <pwccode url="https://github.com/rahulpatchigolla/EventTriggerDetection" additional="false">rahulpatchigolla/EventTriggerDetection</pwccode>
    </paper>
    <paper id="41">
      <title>Representations of Time Expressions for Temporal Relation Extraction with <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Networks</a></title>
      <author><first>Chen</first><last>Lin</last></author>
      <author><first>Timothy</first><last>Miller</last></author>
      <author><first>Dmitriy</first><last>Dligach</last></author>
      <author><first>Steven</first><last>Bethard</last></author>
      <author><first>Guergana</first><last>Savova</last></author>
      <pages>322–327</pages>
      <url hash="0b94962f">W17-2341</url>
      <doi>10.18653/v1/W17-2341</doi>
      <abstract>Token sequences are often used as the input for Convolutional Neural Networks (CNNs) in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. However, they might not be an ideal representation for time expressions, which are long, highly varied, and semantically complex. We describe a <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">method</a> for representing time expressions with single pseudo-tokens for CNNs. With this <a href="https://en.wikipedia.org/wiki/Methodology">method</a>, we establish a new state-of-the-art result for a clinical temporal relation extraction task.</abstract>
      <bibkey>lin-etal-2017-representations</bibkey>
    </paper>
    <paper id="42">
      <title>Automatic Diagnosis Coding of Radiology Reports : A Comparison of <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a> and Conventional Classification Methods</title>
      <author><first>Sarvnaz</first><last>Karimi</last></author>
      <author><first>Xiang</first><last>Dai</last></author>
      <author><first>Hamed</first><last>Hassanzadeh</last></author>
      <author><first>Anthony</first><last>Nguyen</last></author>
      <pages>328–332</pages>
      <url hash="a4862912">W17-2342</url>
      <doi>10.18653/v1/W17-2342</doi>
      <abstract>Diagnosis autocoding services and research intend to both improve the productivity of clinical coders and the accuracy of the coding. It is an important step in <a href="https://en.wikipedia.org/wiki/Data_analysis">data analysis</a> for funding and reimbursement, as well as health services planning and <a href="https://en.wikipedia.org/wiki/Resource_allocation">resource allocation</a>. We investigate the applicability of <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> at autocoding of radiology reports using International Classification of Diseases (ICD). Deep learning methods are known to require <a href="https://en.wikipedia.org/wiki/Big_data">large training data</a>. Our goal is to explore how to use these <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> when the training data is sparse, skewed and relatively small, and how their effectiveness compares to conventional methods. We identify optimal parameters that could be used in setting up a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a> for <a href="https://en.wikipedia.org/wiki/Autocoding">autocoding</a> with comparable results to that of conventional methods.</abstract>
      <bibkey>karimi-etal-2017-automatic</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
    </paper>
    <paper id="43">
      <title>Automatic classification of doctor-patient questions for a virtual patient record query task</title>
      <author><first>Leonardo</first><last>Campillos Llanos</last></author>
      <author><first>Sophie</first><last>Rosset</last></author>
      <author><first>Pierre</first><last>Zweigenbaum</last></author>
      <pages>333–341</pages>
      <url hash="4b1bae3e">W17-2343</url>
      <doi>10.18653/v1/W17-2343</doi>
      <abstract>We present the work-in-progress of automating the classification of doctor-patient questions in the context of a simulated consultation with a virtual patient. We classify questions according to the computational strategy (rule-based or other) needed for looking up data in the <a href="https://en.wikipedia.org/wiki/Medical_record">clinical record</a>. We compare ‘traditional’ machine learning methods (Gaussian and Multinomial Naive Bayes, and Support Vector Machines) and a neural network classifier (FastText). We obtained the best results with the SVM using <a href="https://en.wikipedia.org/wiki/Semantic_annotation">semantic annotations</a>, whereas the neural classifier achieved promising results without it.</abstract>
      <bibkey>campillos-llanos-etal-2017-automatic</bibkey>
    </paper>
    <paper id="45">
      <title>Clinical Event Detection with Hybrid Neural Architecture</title>
      <author><first>Adyasha</first><last>Maharana</last></author>
      <author><first>Meliha</first><last>Yetisgen</last></author>
      <pages>351–355</pages>
      <url hash="214f9c11">W17-2345</url>
      <doi>10.18653/v1/W17-2345</doi>
      <abstract>Event detection from clinical notes has been traditionally solved with rule based and statistical natural language processing (NLP) approaches that require extensive domain knowledge and feature engineering. In this paper, we have explored the feasibility of approaching this task with <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural networks</a>, clinical word embeddings and introduced a hybrid architecture to improve detection for entities with smaller representation in the dataset. A comparative analysis is also done which reveals the complementary behavior of <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a> and <a href="https://en.wikipedia.org/wiki/Conditional_random_field">conditional random fields</a> in clinical entity detection.</abstract>
      <bibkey>maharana-yetisgen-2017-clinical</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/mimic-iii">MIMIC-III</pwcdataset>
    </paper>
    <paper id="46">
      <title>Extracting Personal Medical Events for User Timeline Construction using Minimal Supervision</title>
      <author><first>Aakanksha</first><last>Naik</last></author>
      <author><first>Chris</first><last>Bogart</last></author>
      <author><first>Carolyn</first><last>Rose</last></author>
      <pages>356–364</pages>
      <url hash="2b08a3fd">W17-2346</url>
      <doi>10.18653/v1/W17-2346</doi>
      <abstract>In this paper, we describe a <a href="https://en.wikipedia.org/wiki/System">system</a> for automatic construction of user disease progression timelines from their posts in online support groups using minimal supervision. In recent years, several online support groups have been established which has led to a huge increase in the amount of patient-authored text available. Creating systems which can automatically extract important medical events and create disease progression timelines for users from such text can help in patient health monitoring as well as studying links between <a href="https://en.wikipedia.org/wiki/Disease">medical events</a> and users’ participation in <a href="https://en.wikipedia.org/wiki/Support_group">support groups</a>. Prior work in this domain has used manually constructed keyword sets to detect medical events. In this work, our aim is to perform medical event detection using minimal supervision in order to develop a more general timeline construction system. Our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 55.17 %, which is 92 % of the performance achieved by a supervised baseline system.</abstract>
      <bibkey>naik-etal-2017-extracting</bibkey>
    </paper>
    <paper id="48">
      <title>A Multi-strategy Query Processing Approach for Biomedical Question Answering : USTB_PRIR at BioASQ 2017 Task 5B<fixed-case>USTB</fixed-case>_<fixed-case>PRIR</fixed-case> at <fixed-case>B</fixed-case>io<fixed-case>ASQ</fixed-case> 2017 Task 5<fixed-case>B</fixed-case></title>
      <author><first>Zan-Xia</first><last>Jin</last></author>
      <author><first>Bo-Wen</first><last>Zhang</last></author>
      <author><first>Fan</first><last>Fang</last></author>
      <author><first>Le-Le</first><last>Zhang</last></author>
      <author><first>Xu-Cheng</first><last>Yin</last></author>
      <pages>373–380</pages>
      <url hash="9b861774">W17-2348</url>
      <doi>10.18653/v1/W17-2348</doi>
      <abstract>This paper describes the participation of USTB_PRIR team in the 2017 BioASQ 5B on <a href="https://en.wikipedia.org/wiki/Question_answering">question answering</a>, including <a href="https://en.wikipedia.org/wiki/Document_retrieval">document retrieval</a>, snippet retrieval, and concept retrieval task. We introduce different multimodal query processing strategies to enrich query terms and assign different weights to them. Specifically, sequential dependence model (SDM), pseudo-relevance feedback (PRF), fielded sequential dependence model (FSDM) and Divergence from Randomness model (DFRM) are respectively performed on different fields of PubMed articles, sentences extracted from relevant articles, the five terminologies or ontologies (MeSH, GO, Jochem, Uniprot and DO) to achieve better search performances. Preliminary results show that our <a href="https://en.wikipedia.org/wiki/System">systems</a> outperform others in the document and snippet retrieval task in the first two batches.</abstract>
      <bibkey>jin-etal-2017-multi</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/bioasq">BioASQ</pwcdataset>
    </paper>
  </volume>
  <volume id="24">
    <meta>
      <booktitle>Proceedings of <fixed-case>T</fixed-case>ext<fixed-case>G</fixed-case>raphs-11: the Workshop on Graph-based Methods for Natural Language Processing</booktitle>
      <url hash="5d12bae9">W17-24</url>
      <editor><first>Martin</first><last>Riedl</last></editor>
      <editor><first>Swapna</first><last>Somasundaran</last></editor>
      <editor><first>Goran</first><last>Glavaš</last></editor>
      <editor><first>Eduard</first><last>Hovy</last></editor>
      <doi>10.18653/v1/W17-24</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Vancouver, Canada</address>
      <month>August</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="bc652322">W17-2400</url>
      <bibkey>ws-2017-textgraphs</bibkey>
    </frontmatter>
    <paper id="1">
      <title>On the Calligraphy of Books</title>
      <author><first>Vanessa Queiroz</first><last>Marinho</last></author>
      <author><first>Henrique Ferraz</first><last>de Arruda</last></author>
      <author><first>Thales</first><last>Sinelli</last></author>
      <author><first>Luciano da Fontoura</first><last>Costa</last></author>
      <author><first>Diego Raphael</first><last>Amancio</last></author>
      <pages>1–10</pages>
      <url hash="dc12c4fb">W17-2401</url>
      <doi>10.18653/v1/W17-2401</doi>
      <abstract>Authorship attribution is a natural language processing task that has been widely studied, often by considering small order statistics. In this paper, we explore a complex network approach to assign the authorship of texts based on their mesoscopic representation, in an attempt to capture the flow of the narrative. Indeed, as reported in this work, such an approach allowed the identification of the dominant narrative structure of the studied authors. This has been achieved due to the ability of the mesoscopic approach to take into account relationships between different, not necessarily adjacent, parts of the text, which is able to capture the story flow. The potential of the proposed approach has been illustrated through <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">principal component analysis</a>, a comparison with the chance baseline method, and <a href="https://en.wikipedia.org/wiki/Network_visualization">network visualization</a>. Such <a href="https://en.wikipedia.org/wiki/Visualization_(graphics)">visualizations</a> reveal individual characteristics of the authors, which can be understood as a kind of <a href="https://en.wikipedia.org/wiki/Calligraphy">calligraphy</a>.</abstract>
      <bibkey>marinho-etal-2017-calligraphy</bibkey>
    </paper>
    <paper id="2">
      <title>Adapting predominant and novel sense discovery algorithms for identifying corpus-specific sense differences</title>
      <author><first>Binny</first><last>Mathew</last></author>
      <author><first>Suman Kalyan</first><last>Maity</last></author>
      <author><first>Pratip</first><last>Sarkar</last></author>
      <author><first>Animesh</first><last>Mukherjee</last></author>
      <author><first>Pawan</first><last>Goyal</last></author>
      <pages>11–20</pages>
      <url hash="ad221ce4">W17-2402</url>
      <doi>10.18653/v1/W17-2402</doi>
      <abstract>Word senses are not static and may have temporal, spatial or corpus-specific scopes. Identifying such <a href="https://en.wikipedia.org/wiki/Scope_(computer_science)">scopes</a> might benefit the existing WSD systems largely. In this paper, while studying corpus specific word senses, we adapt three existing predominant and novel-sense discovery algorithms to identify these corpus-specific senses. We make use of text data available in the form of millions of digitized books and newspaper archives as two different sources of corpora and propose automated methods to identify corpus-specific word senses at various time points. We conduct an extensive and thorough human judgement experiment to rigorously evaluate and compare the performance of these approaches. Post adaptation, the output of the three <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> are in the same format and the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> results are also comparable, with roughly 45-60 % of the reported corpus-specific senses being judged as genuine.</abstract>
      <bibkey>mathew-etal-2017-adapting</bibkey>
    </paper>
    <paper id="3">
      <title>Merging knowledge bases in different languages</title>
      <author><first>Jerónimo</first><last>Hernández-González</last></author>
      <author><first>Estevam R.</first><last>Hruschka Jr.</last></author>
      <author><first>Tom M.</first><last>Mitchell</last></author>
      <pages>21–29</pages>
      <url hash="29ea1747">W17-2403</url>
      <doi>10.18653/v1/W17-2403</doi>
      <abstract>Recently, different systems which learn to populate and extend a knowledge base (KB) from the <a href="https://en.wikipedia.org/wiki/World_Wide_Web">web</a> in different languages have been presented. Although a large set of concepts should be learnt independently from the language used to read, there are facts which are expected to be more easily gathered in <a href="https://en.wikipedia.org/wiki/Local_language">local language</a> (e.g., culture or geography). A system that merges KBs learnt in different languages will benefit from the complementary information as long as common beliefs are identified, as well as from <a href="https://en.wikipedia.org/wiki/Redundancy_(information_theory)">redundancy</a> present in web pages written in different languages. In this paper, we deal with the problem of identifying equivalent beliefs (or concepts) across language specific KBs, assuming that they share the same ontology of categories and relations. In a case study with two KBs independently learnt from different inputs, namely <a href="https://en.wikipedia.org/wiki/Web_page">web pages</a> written in <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/Web_page">web pages</a> written in <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a> respectively, we report on the results of two methodologies : an approach based on personalized PageRank and an inference technique to find out common relevant paths through the KBs. The proposed inference technique efficiently identifies relevant paths, outperforming the baseline (a dictionary-based classifier) in the vast majority of tested categories.</abstract>
      <bibkey>hernandez-gonzalez-etal-2017-merging</bibkey>
    </paper>
    <paper id="4">
      <title>Parameter Free Hierarchical Graph-Based Clustering for Analyzing Continuous Word Embeddings</title>
      <author><first>Thomas Alexander</first><last>Trost</last></author>
      <author><first>Dietrich</first><last>Klakow</last></author>
      <pages>30–38</pages>
      <url hash="65558f5c">W17-2404</url>
      <doi>10.18653/v1/W17-2404</doi>
      <abstract>Word embeddings are high-dimensional vector representations of words and are thus difficult to interpret. In order to deal with this, we introduce an unsupervised parameter free method for creating a hierarchical graphical clustering of the full ensemble of word vectors and show that this structure is a geometrically meaningful representation of the original relations between the words. This newly obtained representation can be used for better understanding and thus improving the <a href="https://en.wikipedia.org/wiki/Embedding">embedding algorithm</a> and exhibits <a href="https://en.wikipedia.org/wiki/Semantics">semantic meaning</a>, so it can also be utilized in a variety of language processing tasks like <a href="https://en.wikipedia.org/wiki/Categorization">categorization</a> or <a href="https://en.wikipedia.org/wiki/Similarity_measure">measuring similarity</a>.</abstract>
      <bibkey>trost-klakow-2017-parameter</bibkey>
    </paper>
    <paper id="5">
      <title>Spectral Graph-Based Method of Multimodal Word Embedding</title>
      <author><first>Kazuki</first><last>Fukui</last></author>
      <author><first>Takamasa</first><last>Oshikiri</last></author>
      <author><first>Hidetoshi</first><last>Shimodaira</last></author>
      <pages>39–44</pages>
      <url hash="b9cdd89e">W17-2405</url>
      <doi>10.18653/v1/W17-2405</doi>
      <abstract>In this paper, we propose a novel method for multimodal word embedding, which exploit a generalized framework of multi-view spectral graph embedding to take into account visual appearances or scenes denoted by words in a corpus. We evaluated our method through word similarity tasks and a concept-to-image search task, having found that it provides word representations that reflect visual information, while somewhat trading-off the performance on the word similarity tasks. Moreover, we demonstrate that our method captures multimodal linguistic regularities, which enable recovering relational similarities between words and images by vector arithmetics.</abstract>
      <bibkey>fukui-etal-2017-spectral</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/nus-wide">NUS-WIDE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-question-answering">Visual Question Answering</pwcdataset>
    </paper>
    <paper id="7">
      <title>Extract with Order for Coherent Multi-Document Summarization</title>
      <author><first>Mir Tafseer</first><last>Nayeem</last></author>
      <author><first>Yllias</first><last>Chali</last></author>
      <pages>51–56</pages>
      <url hash="f4c46e6c">W17-2407</url>
      <doi>10.18653/v1/W17-2407</doi>
      <abstract>In this work, we aim at developing an extractive summarizer in the multi-document setting. We implement a rank based sentence selection using continuous vector representations along with key-phrases. Furthermore, we propose a <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> to tackle summary coherence for increasing <a href="https://en.wikipedia.org/wiki/Readability">readability</a>. We conduct experiments on the Document Understanding Conference (DUC) 2004 datasets using ROUGE toolkit. Our experiments demonstrate that the <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> bring significant improvements over the state of the art <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> in terms of <a href="https://en.wikipedia.org/wiki/Informatics">informativity</a> and <a href="https://en.wikipedia.org/wiki/Coherence_(physics)">coherence</a>.</abstract>
      <bibkey>nayeem-chali-2017-extract</bibkey>
    </paper>
    <paper id="10">
      <title>Evaluating text coherence based on semantic similarity graph</title>
      <author><first>Jan Wira Gotama</first><last>Putra</last></author>
      <author><first>Takenobu</first><last>Tokunaga</last></author>
      <pages>76–85</pages>
      <url hash="eac6900a">W17-2410</url>
      <doi>10.18653/v1/W17-2410</doi>
      <attachment type="presentation" hash="b93c9732">W17-2410.Presentation.pdf</attachment>
      <abstract>Coherence is a crucial feature of text because it is indispensable for conveying its communication purpose and meaning to its readers. In this paper, we propose an unsupervised text coherence scoring based on <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph construction</a> in which <a href="https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms">edges</a> are established between semantically similar sentences represented by vertices. The sentence similarity is calculated based on the cosine similarity of semantic vectors representing sentences. We provide three graph construction methods establishing an <a href="https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms">edge</a> from a given <a href="https://en.wikipedia.org/wiki/Vertex_(graph_theory)">vertex</a> to a preceding adjacent vertex, to a single similar vertex, or to multiple similar vertices. We evaluated our <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">methods</a> in the document discrimination task and the insertion task by comparing our proposed <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">methods</a> to the supervised (Entity Grid) and unsupervised (Entity Graph) baselines. In the document discrimination task, our method outperformed the unsupervised baseline but could not do the supervised baseline, while in the insertion task, our method outperformed both baselines.</abstract>
      <bibkey>putra-tokunaga-2017-evaluating</bibkey>
    </paper>
  </volume>
  <volume id="25">
    <meta>
      <booktitle>Proceedings of the 10th Workshop on Building and Using Comparable Corpora</booktitle>
      <url hash="3f27b743">W17-25</url>
      <editor><first>Serge</first><last>Sharoff</last></editor>
      <editor><first>Pierre</first><last>Zweigenbaum</last></editor>
      <editor><first>Reinhard</first><last>Rapp</last></editor>
      <doi>10.18653/v1/W17-25</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Vancouver, Canada</address>
      <month>August</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="fe51a2e2">W17-2500</url>
      <bibkey>ws-2017-building</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Users and Data : The Two Neglected Children of Bilingual Natural Language Processing Research</title>
      <author><first>Phillippe</first><last>Langlais</last></author>
      <pages>1–5</pages>
      <url hash="dad4c61f">W17-2501</url>
      <doi>10.18653/v1/W17-2501</doi>
      <abstract>Despite numerous studies devoted to mining parallel material from bilingual data, we have yet to see the resulting <a href="https://en.wikipedia.org/wiki/Technology">technologies</a> wholeheartedly adopted by professional translators and terminologists alike. I argue that this state of affairs is mainly due to two factors : the emphasis published authors put on <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> (even though data is as important), and the conspicuous lack of concern for actual end-users.</abstract>
      <bibkey>langlais-2017-users</bibkey>
    </paper>
    <paper id="2">
      <title>Deep Investigation of Cross-Language Plagiarism Detection Methods</title>
      <author><first>Jérémy</first><last>Ferrero</last></author>
      <author><first>Laurent</first><last>Besacier</last></author>
      <author><first>Didier</first><last>Schwab</last></author>
      <author><first>Frédéric</first><last>Agnès</last></author>
      <pages>6–15</pages>
      <url hash="a4352ba5">W17-2502</url>
      <doi>10.18653/v1/W17-2502</doi>
      <attachment type="presentation" hash="6fb91ef4">W17-2502.Presentation.pdf</attachment>
      <abstract>This paper is a deep investigation of cross-language plagiarism detection methods on a new recently introduced <a href="https://en.wikipedia.org/wiki/Open_data">open dataset</a>, which contains parallel and comparable collections of documents with multiple characteristics (different genres, languages and sizes of texts). We investigate cross-language plagiarism detection methods for 6 language pairs on 2 granularities of text units in order to draw robust conclusions on the best methods while deeply analyzing correlations across document styles and languages.</abstract>
      <bibkey>ferrero-etal-2017-deep</bibkey>
      <pwccode url="https://github.com/FerreroJeremy/Cross-Language-Dataset" additional="false">FerreroJeremy/Cross-Language-Dataset</pwccode>
    </paper>
    <paper id="3">
      <title>Sentence Alignment using Unfolding Recursive Autoencoders</title>
      <author><first>Jeenu</first><last>Grover</last></author>
      <author><first>Pabitra</first><last>Mitra</last></author>
      <pages>16–20</pages>
      <url hash="d144dcb5">W17-2503</url>
      <doi>10.18653/v1/W17-2503</doi>
      <abstract>In this paper, we propose a novel two step algorithm for sentence alignment in <a href="https://en.wikipedia.org/wiki/Text_corpus">monolingual corpora</a> using Unfolding Recursive Autoencoders. First, we use unfolding recursive auto-encoders (RAE) to learn feature vectors for phrases in syntactical tree of the sentence. To compare two sentences we use a <a href="https://en.wikipedia.org/wiki/Similarity_matrix">similarity matrix</a> which has dimensions proportional to the size of the two sentences. Since the <a href="https://en.wikipedia.org/wiki/Similarity_matrix">similarity matrix</a> generated to compare two sentences has varying dimension due to different sentence lengths, a dynamic pooling layer is used to map it to a matrix of fixed dimension. The resulting <a href="https://en.wikipedia.org/wiki/Matrix_(mathematics)">matrix</a> is used to calculate the similarity scores between the two sentences. The second step of the <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> captures the contexts in which the sentences occur in the document by using a dynamic programming algorithm for global alignment.</abstract>
      <bibkey>grover-mitra-2017-sentence</bibkey>
    </paper>
    <paper id="4">
      <title>Acquisition of Translation Lexicons for Historically Unwritten Languages via Bridging Loanwords</title>
      <author><first>Michael</first><last>Bloodgood</last></author>
      <author><first>Benjamin</first><last>Strauss</last></author>
      <pages>21–25</pages>
      <url hash="57640da2">W17-2504</url>
      <doi>10.18653/v1/W17-2504</doi>
      <attachment type="presentation" hash="ee72f517">W17-2504.Presentation.pdf</attachment>
      <abstract>With the advent of informal electronic communications such as <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>, <a href="https://en.wikipedia.org/wiki/Colloquialism">colloquial languages</a> that were historically unwritten are being written for the first time in heavily <a href="https://en.wikipedia.org/wiki/Code-switching">code-switched environments</a>. We present a method for inducing portions of translation lexicons through the use of expert knowledge in these settings where there are approximately zero resources available other than a language informant, potentially not even large amounts of monolingual data. We investigate inducing a Moroccan Darija-English translation lexicon via French loanwords bridging into English and find that a useful lexicon is induced for human-assisted translation and <a href="https://en.wikipedia.org/wiki/Statistical_machine_translation">statistical machine translation</a>.</abstract>
      <bibkey>bloodgood-strauss-2017-acquisition</bibkey>
    </paper>
    <paper id="5">
      <title>Toward a Comparable Corpus of Latvian, Russian and English Tweets<fixed-case>L</fixed-case>atvian, <fixed-case>R</fixed-case>ussian and <fixed-case>E</fixed-case>nglish Tweets</title>
      <author><first>Dmitrijs</first><last>Milajevs</last></author>
      <pages>26–30</pages>
      <url hash="bbc13abd">W17-2505</url>
      <doi>10.18653/v1/W17-2505</doi>
      <abstract>Twitter has become a rich source for linguistic data. Here, a possibility of building a trilingual Latvian-Russian-English corpus of tweets from Riga, Latvia is investigated. Such a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>, once constructed, might be of great use for multiple purposes including training <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation models</a>, examining cross-lingual phenomena and studying the population of Riga. This pilot study shows that it is feasible to build such a resource by collecting and analysing a pilot corpus, which is made publicly available and can be used to construct a large comparable corpus.</abstract>
      <bibkey>milajevs-2017-toward</bibkey>
    </paper>
    <paper id="6">
      <title>Automatic Extraction of Parallel Speech Corpora from Dubbed Movies</title>
      <author><first>Alp</first><last>Öktem</last></author>
      <author><first>Mireia</first><last>Farrús</last></author>
      <author><first>Leo</first><last>Wanner</last></author>
      <pages>31–35</pages>
      <url hash="a935dc9e">W17-2506</url>
      <doi>10.18653/v1/W17-2506</doi>
      <attachment type="presentation" hash="1de64b9e">W17-2506.Presentation.pdf</attachment>
      <abstract>This paper presents a methodology to extract parallel speech corpora based on any language pair from dubbed movies, together with an application framework in which some corresponding prosodic parameters are extracted. The obtained <a href="https://en.wikipedia.org/wiki/Parallel_text">parallel corpora</a> are especially suitable for speech-to-speech translation applications when a <a href="https://en.wikipedia.org/wiki/Prosody_(linguistics)">prosody transfer</a> between source and target languages is desired.</abstract>
      <bibkey>oktem-etal-2017-automatic</bibkey>
    </paper>
    <paper id="7">
      <title>A parallel collection of clinical trials in <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a> and English<fixed-case>P</fixed-case>ortuguese and <fixed-case>E</fixed-case>nglish</title>
      <author><first>Mariana</first><last>Neves</last></author>
      <pages>36–40</pages>
      <url hash="c0c871fd">W17-2507</url>
      <doi>10.18653/v1/W17-2507</doi>
      <attachment type="presentation" hash="5af8fa51">W17-2507.Presentation.pdf</attachment>
      <abstract>Parallel collections of documents are crucial resources for training and evaluating machine translation (MT) systems. Even though large collections are available for certain domains and language pairs, these are still scarce in the biomedical domain. We developed a parallel corpus of clinical trials in <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a> and <a href="https://en.wikipedia.org/wiki/English_language">English</a>. The documents are derived from the Brazilian Clinical Trials Registry and the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> currently contains a total of 1188 documents. In this paper, we describe the corpus construction and discuss the quality of the <a href="https://en.wikipedia.org/wiki/Translation">translation</a> and the sentence alignment that we obtained.</abstract>
      <bibkey>neves-2017-parallel</bibkey>
    </paper>
    <paper id="8">
      <title>Weighted Set-Theoretic Alignment of Comparable Sentences</title>
      <author><first>Andoni</first><last>Azpeitia</last></author>
      <author><first>Thierry</first><last>Etchegoyhen</last></author>
      <author><first>Eva</first><last>Martínez Garcia</last></author>
      <pages>41–45</pages>
      <url hash="14ee631d">W17-2508</url>
      <doi>10.18653/v1/W17-2508</doi>
      <abstract>This article presents the STACCw system for the BUCC 2017 shared task on parallel sentence extraction from comparable corpora. The original STACC approach, based on set-theoretic operations over bags of words, had been previously shown to be efficient and portable across domains and alignment scenarios. Wedescribe an extension of this approach with a new weighting scheme and show that it provides significant improvements on the datasets provided for the shared task.</abstract>
      <bibkey>azpeitia-etal-2017-weighted</bibkey>
    </paper>
    <paper id="9">
      <title>BUCC 2017 Shared Task : a First Attempt Toward a Deep Learning Framework for Identifying Parallel Sentences in Comparable Corpora<fixed-case>BUCC</fixed-case> 2017 Shared Task: a First Attempt Toward a Deep Learning Framework for Identifying Parallel Sentences in Comparable Corpora</title>
      <author><first>Francis</first><last>Grégoire</last></author>
      <author><first>Philippe</first><last>Langlais</last></author>
      <pages>46–50</pages>
      <url hash="14c2e3a1">W17-2509</url>
      <doi>10.18653/v1/W17-2509</doi>
      <abstract>This paper describes our participation in BUCC 2017 shared task : identifying parallel sentences in comparable corpora. Our goal is to leverage continuous vector representations and <a href="https://en.wikipedia.org/wiki/Distributional_semantics">distributional semantics</a> with a minimal use of external preprocessing and postprocessing tools. We report experiments that were conducted after transmitting our results.</abstract>
      <bibkey>gregoire-langlais-2017-bucc</bibkey>
    </paper>
    <paper id="10">
      <title>zNLP : Identifying Parallel Sentences in Chinese-English Comparable Corpora<fixed-case>NLP</fixed-case>: Identifying Parallel Sentences in <fixed-case>C</fixed-case>hinese-<fixed-case>E</fixed-case>nglish Comparable Corpora</title>
      <author><first>Zheng</first><last>Zhang</last></author>
      <author><first>Pierre</first><last>Zweigenbaum</last></author>
      <pages>51–55</pages>
      <url hash="64d1fcf9">W17-2510</url>
      <doi>10.18653/v1/W17-2510</doi>
      <abstract>This paper describes the zNLP system for the BUCC 2017 shared task. Our system identifies parallel sentence pairs in Chinese-English comparable corpora by translating word-by-word Chinese sentences into English, using the search engine Solr to select near-parallel sentences and then by using an SVM classifier to identify true parallel sentences from the previous results. It obtains an F1-score of 45 % (resp. 32 %) on the test (training) set.</abstract>
      <bibkey>zhang-zweigenbaum-2017-znlp</bibkey>
    </paper>
    <paper id="11">
      <title>BUCC2017 : A Hybrid Approach for Identifying Parallel Sentences in Comparable Corpora<fixed-case>BUCC</fixed-case>2017: A Hybrid Approach for Identifying Parallel Sentences in Comparable Corpora</title>
      <author><first>Sainik</first><last>Mahata</last></author>
      <author><first>Dipankar</first><last>Das</last></author>
      <author><first>Sivaji</first><last>Bandyopadhyay</last></author>
      <pages>56–59</pages>
      <url hash="62126c99">W17-2511</url>
      <doi>10.18653/v1/W17-2511</doi>
      <abstract>A Statistical Machine Translation (SMT) system is always trained using large parallel corpus to produce effective <a href="https://en.wikipedia.org/wiki/Translation">translation</a>. Not only is the corpus scarce, it also involves a lot of manual labor and cost. Parallel corpus can be prepared by employing comparable corpora where a pair of corpora is in two different languages pointing to the same domain. In the present work, we try to build a <a href="https://en.wikipedia.org/wiki/Parallel_corpus">parallel corpus</a> for French-English language pair from a given comparable corpus. The data and the problem set are provided as part of the shared task organized by BUCC 2017. We have proposed a system that first translates the sentences by heavily relying on <a href="https://en.wikipedia.org/wiki/Moses">Moses</a> and then group the sentences based on sentence length similarity. Finally, the one to one sentence selection was done based on Cosine Similarity algorithm.</abstract>
      <bibkey>mahata-etal-2017-bucc2017</bibkey>
    </paper>
    </volume>
  <volume id="26">
    <meta>
      <booktitle>Proceedings of the 2nd Workshop on Representation Learning for <fixed-case>NLP</fixed-case></booktitle>
      <url hash="b5b4ad67">W17-26</url>
      <editor><first>Phil</first><last>Blunsom</last></editor>
      <editor><first>Antoine</first><last>Bordes</last></editor>
      <editor><first>Kyunghyun</first><last>Cho</last></editor>
      <editor><first>Shay</first><last>Cohen</last></editor>
      <editor><first>Chris</first><last>Dyer</last></editor>
      <editor><first>Edward</first><last>Grefenstette</last></editor>
      <editor><first>Karl Moritz</first><last>Hermann</last></editor>
      <editor><first>Laura</first><last>Rimell</last></editor>
      <editor><first>Jason</first><last>Weston</last></editor>
      <editor><first>Scott</first><last>Yih</last></editor>
      <doi>10.18653/v1/W17-26</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Vancouver, Canada</address>
      <month>August</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="d7bed64b">W17-2600</url>
      <bibkey>ws-2017-representation</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Sense Contextualization in a Dependency-Based Compositional Distributional Model</title>
      <author><first>Pablo</first><last>Gamallo</last></author>
      <pages>1–9</pages>
      <url hash="6ccc500b">W17-2601</url>
      <doi>10.18653/v1/W17-2601</doi>
      <abstract>Little attention has been paid to distributional compositional methods which employ syntactically structured vector models. As word vectors belonging to different <a href="https://en.wikipedia.org/wiki/Syntactic_category">syntactic categories</a> have incompatible syntactic distributions, no trivial compositional operation can be applied to combine them into a new compositional vector. In this article, we generalize the method described by Erk and Pad (2009) by proposing a dependency-base framework that contextualize not only lemmas but also selectional preferences. The main contribution of the article is to expand their <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> to a fully compositional framework in which syntactic dependencies are put at the core of semantic composition. We claim that semantic composition is mainly driven by syntactic dependencies. Each syntactic dependency generates two new compositional vectors representing the contextualized sense of the two related lemmas. The sequential application of the compositional operations associated to the dependencies results in as many contextualized vectors as lemmas the composite expression contains. At the end of the semantic process, we do not obtain a single compositional vector representing the semantic denotation of the whole composite expression, but one contextualized vector for each lemma of the whole expression. Our method avoids the troublesome high-order tensor representations by defining lemmas and selectional restrictions as <a href="https://en.wikipedia.org/wiki/Tensor_(intrinsic_definition)">first-order tensors</a> (i.e. standard vectors). A corpus-based experiment is performed to both evaluate the quality of the compositional vectors built with our strategy, and to compare them to other approaches on distributional compositional semantics. The experiments show that our dependency-based compositional method performs as (or even better than) the <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a>.</abstract>
      <bibkey>gamallo-2017-sense</bibkey>
    </paper>
    <paper id="2">
      <title>Context encoders as a simple but powerful extension of <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a></title>
      <author><first>Franziska</first><last>Horn</last></author>
      <pages>10–14</pages>
      <url hash="19007b23">W17-2602</url>
      <doi>10.18653/v1/W17-2602</doi>
      <abstract>With a strikingly simple architecture and the ability to learn meaningful <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> efficiently from texts containing billions of words, <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> remains one of the most popular neural language models used today. However, as only a single <a href="https://en.wikipedia.org/wiki/Embedding">embedding</a> is learned for every word in the vocabulary, the model fails to optimally represent words with multiple meanings and, additionally, it is not possible to create embeddings for new (out-of-vocabulary) words on the spot. Based on an intuitive interpretation of the continuous bag-of-words (CBOW) word2vec model’s negative sampling training objective in terms of predicting context based similarities, we motivate an extension of the model we call context encoders (ConEc). By multiplying the matrix of trained word2vec embeddings with a word’s average context vector, out-of-vocabulary (OOV) embeddings and representations for words with multiple meanings can be created based on the words’ local contexts. The benefits of this approach are illustrated by using these <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> as <a href="https://en.wikipedia.org/wiki/Feature_(computer_vision)">features</a> in the CoNLL 2003 named entity recognition (NER) task.</abstract>
      <bibkey>horn-2017-context</bibkey>
      <pwccode url="https://github.com/cod3licious/conec" additional="false">cod3licious/conec</pwccode>
    </paper>
    <paper id="3">
      <title>Machine Comprehension by Text-to-Text Neural Question Generation</title>
      <author><first>Xingdi</first><last>Yuan</last></author>
      <author><first>Tong</first><last>Wang</last></author>
      <author><first>Caglar</first><last>Gulcehre</last></author>
      <author><first>Alessandro</first><last>Sordoni</last></author>
      <author><first>Philip</first><last>Bachman</last></author>
      <author><first>Saizheng</first><last>Zhang</last></author>
      <author><first>Sandeep</first><last>Subramanian</last></author>
      <author><first>Adam</first><last>Trischler</last></author>
      <pages>15–25</pages>
      <url hash="802382c0">W17-2603</url>
      <doi>10.18653/v1/W17-2603</doi>
      <abstract>We propose a recurrent neural model that generates natural-language questions from documents, conditioned on answers. We show how to train the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> using a combination of supervised and reinforcement learning. After teacher forcing for standard <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">maximum likelihood training</a>, we fine-tune the model using policy gradient techniques to maximize several rewards that measure question quality. Most notably, one of these rewards is the performance of a <a href="https://en.wikipedia.org/wiki/Question_answering">question-answering system</a>. We motivate question generation as a means to improve the performance of <a href="https://en.wikipedia.org/wiki/Question_answering">question answering systems</a>. Our <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> is trained and evaluated on the recent question-answering dataset SQuAD.</abstract>
      <bibkey>yuan-etal-2017-machine</bibkey>
      <pwccode url="" additional="true" />
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="4">
      <title>Emergent Predication Structure in Hidden State Vectors of Neural Readers</title>
      <author><first>Hai</first><last>Wang</last></author>
      <author><first>Takeshi</first><last>Onishi</last></author>
      <author><first>Kevin</first><last>Gimpel</last></author>
      <author><first>David</first><last>McAllester</last></author>
      <pages>26–36</pages>
      <url hash="d8bfea6d">W17-2604</url>
      <doi>10.18653/v1/W17-2604</doi>
      <abstract>A significant number of neural architectures for <a href="https://en.wikipedia.org/wiki/Reading_comprehension">reading comprehension</a> have recently been developed and evaluated on large cloze-style datasets. We present experiments supporting the emergence of <a href="https://en.wikipedia.org/wiki/Predicate_(mathematical_logic)">predication structure</a> in the hidden state vectors of these readers. More specifically, we provide evidence that the hidden state vectors represent atomic formulas [ c ] where   is a semantic property (predicate) and c is a constant symbol entity identifier.<tex-math>\Phi[c]</tex-math> where <tex-math>\Phi</tex-math> is a semantic property (predicate) and <tex-math>c</tex-math> is a constant symbol entity identifier. </abstract>
      <bibkey>wang-etal-2017-emergent</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cbt">CBT</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/who-did-what">Who-did-What</pwcdataset>
    </paper>
    <paper id="6">
      <title>Combining Word-Level and Character-Level Representations for Relation Classification of Informal Text</title>
      <author><first>Dongyun</first><last>Liang</last></author>
      <author><first>Weiran</first><last>Xu</last></author>
      <author><first>Yinge</first><last>Zhao</last></author>
      <pages>43–47</pages>
      <url hash="39001b4a">W17-2606</url>
      <doi>10.18653/v1/W17-2606</doi>
      <abstract>Word representation models have achieved great success in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing tasks</a>, such as <a href="https://en.wikipedia.org/wiki/Binary_relation">relation classification</a>. However, it does not always work on informal text, and the morphemes of some misspelling words may carry important short-distance semantic information. We propose a hybrid model, combining the merits of word-level and character-level representations to learn better <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">representations</a> on informal text. Experiments on two dataset of relation classification, SemEval-2010 Task8 and a large-scale one we compile from informal text, show that our model achieves a competitive result in the former and state-of-the-art with the other.</abstract>
      <bibkey>liang-etal-2017-combining</bibkey>
    </paper>
    <paper id="7">
      <title>Transfer Learning for Neural Semantic Parsing</title>
      <author><first>Xing</first><last>Fan</last></author>
      <author><first>Emilio</first><last>Monti</last></author>
      <author><first>Lambert</first><last>Mathias</last></author>
      <author><first>Markus</first><last>Dreyer</last></author>
      <pages>48–56</pages>
      <url hash="09e58272">W17-2607</url>
      <doi>10.18653/v1/W17-2607</doi>
      <abstract>The goal of <a href="https://en.wikipedia.org/wiki/Semantic_parsing">semantic parsing</a> is to map <a href="https://en.wikipedia.org/wiki/Natural_language">natural language</a> to a machine interpretable meaning representation language (MRL). One of the constraints that limits full exploration of <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning technologies</a> for <a href="https://en.wikipedia.org/wiki/Semantic_parsing">semantic parsing</a> is the lack of sufficient <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">annotation training data</a>. In this paper, we propose using sequence-to-sequence in a multi-task setup for <a href="https://en.wikipedia.org/wiki/Semantic_parsing">semantic parsing</a> with focus on <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a>. We explore three multi-task architectures for sequence-to-sequence model and compare their performance with the independently trained <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>. Our experiments show that the multi-task setup aids <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> from an auxiliary task with large labeled data to the target <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> with smaller labeled data. We see an absolute accuracy gain ranging from 1.0 % to 4.4 % in in our in-house data set and we also see good gains ranging from 2.5 % to 7.0 % on the ATIS semantic parsing tasks with syntactic and semantic auxiliary tasks.</abstract>
      <bibkey>fan-etal-2017-transfer</bibkey>
    </paper>
    <paper id="8">
      <title>Modeling Large-Scale Structured Relationships with <a href="https://en.wikipedia.org/wiki/Shared_memory">Shared Memory</a> for Knowledge Base Completion</title>
      <author><first>Yelong</first><last>Shen</last></author>
      <author><first>Po-Sen</first><last>Huang</last></author>
      <author><first>Ming-Wei</first><last>Chang</last></author>
      <author><first>Jianfeng</first><last>Gao</last></author>
      <pages>57–68</pages>
      <url hash="c488df2e">W17-2608</url>
      <doi>10.18653/v1/W17-2608</doi>
      <abstract>Recent studies on knowledge base completion, the task of recovering missing relationships based on recorded relations, demonstrate the importance of learning embeddings from multi-step relations. However, due to the size of <a href="https://en.wikipedia.org/wiki/Knowledge_base">knowledge bases</a>, learning multi-step relations directly on top of observed triplets could be costly. Hence, a manually designed procedure is often used when training the <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>. In this paper, we propose Implicit ReasoNets (IRNs), which is designed to perform multi-step inference implicitly through a <a href="https://en.wikipedia.org/wiki/Controller_(computing)">controller</a> and <a href="https://en.wikipedia.org/wiki/Shared_memory">shared memory</a>. Without a human-designed inference procedure, IRNs use training data to learn to perform multi-step inference in an embedding neural space through the <a href="https://en.wikipedia.org/wiki/Shared_memory">shared memory</a> and controller. While the <a href="https://en.wikipedia.org/wiki/Statistical_inference">inference procedure</a> does not explicitly operate on top of observed triplets, our proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms all previous <a href="https://en.wikipedia.org/wiki/Statistical_inference">approaches</a> on the popular FB15k benchmark by more than 5.7 %.</abstract>
      <bibkey>shen-etal-2017-modeling</bibkey>
    </paper>
    <paper id="10">
      <title>Sequential Attention : A Context-Aware Alignment Function for <a href="https://en.wikipedia.org/wiki/Machine_reading">Machine Reading</a></title>
      <author><first>Sebastian</first><last>Brarda</last></author>
      <author><first>Philip</first><last>Yeres</last></author>
      <author><first>Samuel</first><last>Bowman</last></author>
      <pages>75–80</pages>
      <url hash="b398e727">W17-2610</url>
      <doi>10.18653/v1/W17-2610</doi>
      <abstract>In this paper we propose a neural network model with a novel Sequential Attention layer that extends soft attention by assigning weights to words in an input sequence in a way that takes into account not just how well that word matches a query, but how well surrounding words match. We evaluate this approach on the task of <a href="https://en.wikipedia.org/wiki/Reading_comprehension">reading comprehension</a> (on the Who did What and CNN datasets) and show that it dramatically improves a strong baselinethe Stanford Readerand is competitive with the state of the art.</abstract>
      <bibkey>brarda-etal-2017-sequential</bibkey>
    </paper>
    <paper id="11">
      <title>Semantic Vector Encoding and <a href="https://en.wikipedia.org/wiki/Similarity_search">Similarity Search</a> Using Fulltext Search Engines</title>
      <author><first>Jan</first><last>Rygl</last></author>
      <author><first>Jan</first><last>Pomikálek</last></author>
      <author><first>Radim</first><last>Řehůřek</last></author>
      <author><first>Michal</first><last>Růžička</last></author>
      <author><first>Vít</first><last>Novotný</last></author>
      <author><first>Petr</first><last>Sojka</last></author>
      <pages>81–90</pages>
      <url hash="a6f87546">W17-2611</url>
      <doi>10.18653/v1/W17-2611</doi>
      <abstract>Vector representations and vector space modeling (VSM) play a central role in modern <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a>. We propose a novel approach to ‘vector similarity searching’ over dense semantic representations of words and documents that can be deployed on top of traditional inverted-index-based fulltext engines, taking advantage of their robustness, stability, scalability and ubiquity. We show that this approach allows the indexing and querying of dense vectors in text domains. This opens up exciting avenues for major efficiency gains, along with simpler deployment, scaling and monitoring. The end result is a fast and scalable vector database with a tunable trade-off between vector search performance and quality, backed by a standard <a href="https://en.wikipedia.org/wiki/Full-text_search">fulltext engine</a> such as <a href="https://en.wikipedia.org/wiki/Elasticsearch">Elasticsearch</a>. We empirically demonstrate its querying performance and quality by applying this solution to the task of semantic searching over a dense vector representation of the entire <a href="https://en.wikipedia.org/wiki/English_Wikipedia">English Wikipedia</a>.</abstract>
      <bibkey>rygl-etal-2017-semantic</bibkey>
    </paper>
    <paper id="12">
      <title>Multi-task Domain Adaptation for Sequence Tagging</title>
      <author><first>Nanyun</first><last>Peng</last></author>
      <author><first>Mark</first><last>Dredze</last></author>
      <pages>91–100</pages>
      <url hash="41a79c6d">W17-2612</url>
      <doi>10.18653/v1/W17-2612</doi>
      <abstract>Many domain adaptation approaches rely on learning cross domain shared representations to transfer the knowledge learned in one domain to other domains. Traditional <a href="https://en.wikipedia.org/wiki/Domain_adaptation">domain adaptation</a> only considers adapting for one task. In this paper, we explore multi-task representation learning under the domain adaptation scenario. We propose a neural network framework that supports <a href="https://en.wikipedia.org/wiki/Domain_adaptation">domain adaptation</a> for multiple tasks simultaneously, and learns shared representations that better generalize for <a href="https://en.wikipedia.org/wiki/Domain_adaptation">domain adaptation</a>. We apply the proposed framework to <a href="https://en.wikipedia.org/wiki/Domain_adaptation">domain adaptation</a> for sequence tagging problems considering two tasks : <a href="https://en.wikipedia.org/wiki/Chinese_word_segmentation">Chinese word segmentation</a> and <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>. Experiments show that multi-task domain adaptation works better than disjoint domain adaptation for each task, and achieves the state-of-the-art results for both tasks in the <a href="https://en.wikipedia.org/wiki/Social_media">social media domain</a>.</abstract>
      <bibkey>peng-dredze-2017-multi</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/weibo-ner">Weibo NER</pwcdataset>
    </paper>
    <paper id="13">
      <title>Beyond Bilingual : Multi-sense Word Embeddings using Multilingual Context</title>
      <author><first>Shyam</first><last>Upadhyay</last></author>
      <author><first>Kai-Wei</first><last>Chang</last></author>
      <author><first>Matt</first><last>Taddy</last></author>
      <author><first>Adam</first><last>Kalai</last></author>
      <author><first>James</first><last>Zou</last></author>
      <pages>101–110</pages>
      <url hash="fb01b767">W17-2613</url>
      <doi>10.18653/v1/W17-2613</doi>
      <abstract>Word embeddings, which represent a word as a point in a <a href="https://en.wikipedia.org/wiki/Vector_space">vector space</a>, have become ubiquitous to several NLP tasks. A recent line of work uses bilingual (two languages) corpora to learn a different vector for each sense of a word, by exploiting crosslingual signals to aid sense identification. We present a multi-view Bayesian non-parametric algorithm which improves multi-sense wor d embeddings by (a) using multilingual (i.e., more than two languages) corpora to significantly improve sense embeddings beyond what one achieves with bilingual information, and (b) uses a principled approach to learn a variable number of senses per word, in a data-driven manner. Ours is the first approach with the ability to leverage multilingual corpora efficiently for multi-sense representation learning. Experiments show that multilingual training significantly improves performance over monolingual and bilingual training, by allowing us to combine different parallel corpora to leverage multilingual context. Multilingual training yields comparable performance to a state of the art <a href="https://en.wikipedia.org/wiki/Monolingualism">monolingual model</a> trained on five times more training data.</abstract>
      <bibkey>upadhyay-etal-2017-beyond</bibkey>
    </paper>
    <paper id="17">
      <title>Learning Bilingual Projections of Embeddings for Vocabulary Expansion in <a href="https://en.wikipedia.org/wiki/Machine_translation">Machine Translation</a></title>
      <author><first>Pranava Swaroop</first><last>Madhyastha</last></author>
      <author><first>Cristina</first><last>España-Bonet</last></author>
      <pages>139–145</pages>
      <url hash="d1879d52">W17-2617</url>
      <doi>10.18653/v1/W17-2617</doi>
      <abstract>We propose a simple log-bilinear softmax-based model to deal with vocabulary expansion in <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>. Our model uses word embeddings trained on significantly large unlabelled monolingual corpora and learns over a fairly small, word-to-word bilingual dictionary. Given an out-of-vocabulary source word, the model generates a probabilistic list of possible translations in the target language using the trained bilingual embeddings. We integrate these translation options into a standard phrase-based statistical machine translation system and obtain consistent improvements in translation quality on the EnglishSpanish language pair. When tested over an out-of-domain testset, we get a significant improvement of 3.9 <a href="https://en.wikipedia.org/wiki/Point_(typography)">BLEU points</a>.</abstract>
      <bibkey>madhyastha-espana-bonet-2017-learning</bibkey>
    </paper>
    <paper id="18">
      <title>Prediction of Frame-to-Frame Relations in the FrameNet Hierarchy with Frame Embeddings<fixed-case>F</fixed-case>rame<fixed-case>N</fixed-case>et Hierarchy with Frame Embeddings</title>
      <author><first>Teresa</first><last>Botschen</last></author>
      <author><first>Hatem</first><last>Mousselly-Sergieh</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>146–156</pages>
      <url hash="cd50d2cf">W17-2618</url>
      <doi>10.18653/v1/W17-2618</doi>
      <abstract>Automatic completion of frame-to-frame (F2F) relations in the FrameNet (FN) hierarchy has received little attention, although they incorporate meta-level commonsense knowledge and are used in downstream approaches. We address the problem of sparsely annotated F2F relations. First, we examine whether the manually defined F2F relations emerge from text by learning text-based frame embeddings. Our analysis reveals insights about the difficulty of reconstructing F2F relations purely from <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">text</a>. Second, we present different systems for predicting F2F relations ; our best-performing one uses the FN hierarchy to train on and to ground embeddings in. A comparison of systems and <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> exposes the crucial influence of knowledge-based embeddings to a <a href="https://en.wikipedia.org/wiki/System">system</a>’s performance in predicting F2F relations.</abstract>
      <bibkey>botschen-etal-2017-prediction</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
    </paper>
    <paper id="19">
      <title>Learning Joint Multilingual Sentence Representations with <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a></title>
      <author><first>Holger</first><last>Schwenk</last></author>
      <author><first>Matthijs</first><last>Douze</last></author>
      <pages>157–167</pages>
      <url hash="64232a52">W17-2619</url>
      <doi>10.18653/v1/W17-2619</doi>
      <abstract>In this paper, we use the framework of <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> to learn joint sentence representations across six very different languages. Our aim is that a <a href="https://en.wikipedia.org/wiki/Representation_(mathematics)">representation</a> which is independent of the language, is likely to capture the underlying <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a>. We define a new cross-lingual similarity measure, compare up to 1.4 M <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentence representations</a> and study the characteristics of close sentences. We provide experimental evidence that sentences that are close in embedding space are indeed semantically highly related, but often have quite different structure and syntax. These relations also hold when comparing sentences in different languages.</abstract>
      <bibkey>schwenk-douze-2017-learning</bibkey>
    </paper>
    <paper id="21">
      <title>Gradual Learning of Matrix-Space Models of Language for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a></title>
      <author><first>Shima</first><last>Asaadi</last></author>
      <author><first>Sebastian</first><last>Rudolph</last></author>
      <pages>178–185</pages>
      <url hash="984151c7">W17-2621</url>
      <doi>10.18653/v1/W17-2621</doi>
      <abstract>Learning word representations to capture the <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> and compositionality of language has received much research interest in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. Beyond the popular vector space models, matrix representations for words have been proposed, since then, <a href="https://en.wikipedia.org/wiki/Matrix_multiplication">matrix multiplication</a> can serve as natural composition operation. In this work, we investigate the problem of learning <a href="https://en.wikipedia.org/wiki/Matrix_(mathematics)">matrix representations of words</a>. We present a learning approach for compositional matrix-space models for the task of <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a>. We show that our approach, which learns the matrices gradually in two steps, outperforms other approaches and a gradient-descent baseline in terms of <a href="https://en.wikipedia.org/wiki/Quality_(business)">quality</a> and <a href="https://en.wikipedia.org/wiki/Computational_cost">computational cost</a>.</abstract>
      <bibkey>asaadi-rudolph-2017-gradual</bibkey>
    </paper>
    <paper id="22">
      <title>Improving <a href="https://en.wikipedia.org/wiki/Language_model">Language Modeling</a> using Densely Connected Recurrent Neural Networks</title>
      <author><first>Fréderic</first><last>Godin</last></author>
      <author><first>Joni</first><last>Dambre</last></author>
      <author><first>Wesley</first><last>De Neve</last></author>
      <pages>186–190</pages>
      <url hash="8bfb016c">W17-2622</url>
      <doi>10.18653/v1/W17-2622</doi>
      <abstract>In this paper, we introduce the novel concept of densely connected layers into <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural networks</a>. We evaluate our proposed <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> on the Penn Treebank language modeling task. We show that we can obtain similar perplexity scores with six times fewer parameters compared to a standard stacked 2-layer LSTM model trained with dropout (Zaremba et al., 2014). In contrast with the current usage of skip connections, we show that densely connecting only a few stacked layers with skip connections already yields significant perplexity reductions.</abstract>
      <bibkey>godin-etal-2017-improving</bibkey>
    </paper>
    <paper id="23">
      <title>NewsQA : A Machine Comprehension Dataset<fixed-case>N</fixed-case>ews<fixed-case>QA</fixed-case>: A Machine Comprehension Dataset</title>
      <author><first>Adam</first><last>Trischler</last></author>
      <author><first>Tong</first><last>Wang</last></author>
      <author><first>Xingdi</first><last>Yuan</last></author>
      <author><first>Justin</first><last>Harris</last></author>
      <author><first>Alessandro</first><last>Sordoni</last></author>
      <author><first>Philip</first><last>Bachman</last></author>
      <author><first>Kaheer</first><last>Suleman</last></author>
      <pages>191–200</pages>
      <url hash="0c1e00c5">W17-2623</url>
      <doi>10.18653/v1/W17-2623</doi>
      <abstract>We present NewsQA, a challenging machine comprehension dataset of over 100,000 human-generated question-answer pairs. Crowdworkers supply questions and answers based on a set of over 10,000 <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a> from <a href="https://en.wikipedia.org/wiki/CNN">CNN</a>, with answers consisting of spans of text in the articles. We collect this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> through a four-stage process designed to solicit exploratory questions that require <a href="https://en.wikipedia.org/wiki/Reason">reasoning</a>. Analysis confirms that NewsQA demands abilities beyond simple word matching and recognizing textual entailment. We measure <a href="https://en.wikipedia.org/wiki/Human">human</a> performance on the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and compare it to several strong neural models. The performance gap between <a href="https://en.wikipedia.org/wiki/Human">humans</a> and <a href="https://en.wikipedia.org/wiki/Machine">machines</a> (13.3 % F1) indicates that significant progress can be made on NewsQA through future research. The <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> is freely available online.</abstract>
      <bibkey>trischler-etal-2017-newsqa</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/newsqa">NewsQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/booktest">BookTest</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/cbt">CBT</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mctest">MCTest</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="24">
      <title>Intrinsic and Extrinsic Evaluation of Spatiotemporal Text Representations in Twitter Streams<fixed-case>T</fixed-case>witter Streams</title>
      <author><first>Lawrence</first><last>Phillips</last></author>
      <author><first>Kyle</first><last>Shaffer</last></author>
      <author><first>Dustin</first><last>Arendt</last></author>
      <author><first>Nathan</first><last>Hodas</last></author>
      <author><first>Svitlana</first><last>Volkova</last></author>
      <pages>201–210</pages>
      <url hash="1eb738ec">W17-2624</url>
      <doi>10.18653/v1/W17-2624</doi>
      <abstract>Language in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> is a dynamic system, constantly evolving and adapting, with words and concepts rapidly emerging, disappearing, and changing their meaning. These changes can be estimated using word representations in context, over time and across locations. A number of methods have been proposed to track these spatiotemporal changes but no general method exists to evaluate the quality of these representations. Previous work largely focused on qualitative evaluation, which we improve by proposing a set of <a href="https://en.wikipedia.org/wiki/Visualization_(graphics)">visualizations</a> that highlight changes in text representation over both space and time. We demonstrate usefulness of novel spatiotemporal representations to explore and characterize specific aspects of the <a href="https://en.wikipedia.org/wiki/Twitter">corpus of tweets</a> collected from European countries over a two-week period centered around the <a href="https://en.wikipedia.org/wiki/2016_Brussels_bombings">terrorist attacks</a> in Brussels in March 2016. In addition, we quantitatively evaluate spatiotemporal representations by feeding them into a downstream classification task   event type prediction. Thus, our work is the first to provide both intrinsic (qualitative) and extrinsic (quantitative) evaluation of text representations for spatiotemporal trends.</abstract>
      <bibkey>phillips-etal-2017-intrinsic</bibkey>
    </paper>
    <paper id="25">
      <title>Rethinking Skip-thought : A Neighborhood based Approach</title>
      <author><first>Shuai</first><last>Tang</last></author>
      <author><first>Hailin</first><last>Jin</last></author>
      <author><first>Chen</first><last>Fang</last></author>
      <author><first>Zhaowen</first><last>Wang</last></author>
      <author><first>Virginia</first><last>de Sa</last></author>
      <pages>211–218</pages>
      <url hash="8ea15121">W17-2625</url>
      <doi>10.18653/v1/W17-2625</doi>
      <attachment type="poster" hash="958cf6e9">W17-2625.Poster.pdf</attachment>
      <abstract>We study the skip-thought model with neighborhood information as weak supervision. More specifically, we propose a skip-thought neighbor model to consider the adjacent sentences as a neighborhood. We train our skip-thought neighbor model on a large corpus with continuous sentences, and then evaluate the trained model on 7 tasks, which include <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic relatedness</a>, <a href="https://en.wikipedia.org/wiki/Paraphrase_detection">paraphrase detection</a>, and <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification benchmarks</a>. Both quantitative comparison and qualitative investigation are conducted. We empirically show that, our skip-thought neighbor model performs as well as the skip-thought model on evaluation tasks. In addition, we found that, incorporating an autoencoder path in our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> did n’t aid our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> to perform better, while it hurts the performance of the skip-thought model.</abstract>
      <bibkey>tang-etal-2017-rethinking</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/bookcorpus">BookCorpus</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mpqa-opinion-corpus">MPQA Opinion Corpus</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sick">SICK</pwcdataset>
    </paper>
    <paper id="29">
      <title>Adversarial Generation of Natural Language</title>
      <author><first>Sandeep</first><last>Subramanian</last></author>
      <author><first>Sai</first><last>Rajeswar</last></author>
      <author><first>Francis</first><last>Dutil</last></author>
      <author><first>Chris</first><last>Pal</last></author>
      <author><first>Aaron</first><last>Courville</last></author>
      <pages>241–251</pages>
      <url hash="a32933de">W17-2629</url>
      <doi>10.18653/v1/W17-2629</doi>
      <abstract>Generative Adversarial Networks (GANs) have gathered a lot of attention from the computer vision community, yielding impressive results for image generation. Advances in the adversarial generation of natural language from noise however are not commensurate with the progress made in generating images, and still lag far behind likelihood based methods. In this paper, we take a step towards generating <a href="https://en.wikipedia.org/wiki/Natural_language">natural language</a> with a GAN objective alone. We introduce a simple baseline that addresses the discrete output space problem without relying on gradient estimators and show that it is able to achieve state-of-the-art results on a Chinese poem generation dataset. We present quantitative results on generating sentences from context-free and probabilistic context-free grammars, and qualitative language modeling results. A conditional version is also described that can generate sequences conditioned on sentence characteristics.</abstract>
      <bibkey>subramanian-etal-2017-adversarial</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="30">
      <title>Deep Active Learning for Named Entity Recognition</title>
      <author><first>Yanyao</first><last>Shen</last></author>
      <author><first>Hyokun</first><last>Yun</last></author>
      <author><first>Zachary</first><last>Lipton</last></author>
      <author><first>Yakov</first><last>Kronrod</last></author>
      <author><first>Animashree</first><last>Anandkumar</last></author>
      <pages>252–256</pages>
      <url hash="14804132">W17-2630</url>
      <doi>10.18653/v1/W17-2630</doi>
      <abstract>Deep neural networks have advanced the state of the art in <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>. However, under typical <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training procedures</a>, advantages over <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">classical methods</a> emerge only with <a href="https://en.wikipedia.org/wiki/Data_set">large datasets</a>. As a result, <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> is employed only when large public datasets or a large budget for manually labeling data is available. In this work, we show otherwise : by combining <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> with active learning, we can outperform classical methods even with a significantly smaller amount of training data.</abstract>
      <bibkey>shen-etal-2017-deep</bibkey>
      <pwccode url="" additional="true" />
    </paper>
    <paper id="31">
      <title>Learning when to skim and when to read</title>
      <author><first>Alexander</first><last>Johansen</last></author>
      <author><first>Richard</first><last>Socher</last></author>
      <pages>257–264</pages>
      <url hash="5f7878fe">W17-2631</url>
      <doi>10.18653/v1/W17-2631</doi>
      <abstract>Many recent advances in <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> have come at increasing <a href="https://en.wikipedia.org/wiki/Computational_cost">computational cost</a>, but the power of these state-of-the-art <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> is not needed for every example in a dataset. We demonstrate two approaches to reducing unnecessary computation in cases where a fast but weak baseline classier and a stronger, slower model are both available. Applying an AUC-based metric to the task of sentiment classification, we find significant efficiency gains with both a probability-threshold method for reducing computational cost and one that uses a secondary decision network.</abstract>
      <bibkey>johansen-socher-2017-learning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="32">
      <title>Learning to Embed Words in Context for Syntactic Tasks</title>
      <author><first>Lifu</first><last>Tu</last></author>
      <author><first>Kevin</first><last>Gimpel</last></author>
      <author><first>Karen</first><last>Livescu</last></author>
      <pages>265–275</pages>
      <url hash="5a081e45">W17-2632</url>
      <doi>10.18653/v1/W17-2632</doi>
      <abstract>We present <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> for embedding words in the context of surrounding words. Such models, which we refer to as token embeddings, represent the characteristics of a word that are specific to a given context, such as <a href="https://en.wikipedia.org/wiki/Word_sense">word sense</a>, <a href="https://en.wikipedia.org/wiki/Syntactic_category">syntactic category</a>, and <a href="https://en.wikipedia.org/wiki/Semantic_role">semantic role</a>. We explore simple, efficient token embedding models based on standard neural network architectures. We learn token embeddings on a large amount of unannotated text and evaluate them as features for <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech taggers</a> and dependency parsers trained on much smaller amounts of annotated data. We find that <a href="https://en.wikipedia.org/wiki/Dependent_and_independent_variables">predictors</a> endowed with token embeddings consistently outperform baseline predictors across a range of context window and training set sizes.</abstract>
      <bibkey>tu-etal-2017-learning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
  </volume>
  <volume id="27">
    <meta>
      <booktitle>Proceedings of the Events and Stories in the News Workshop</booktitle>
      <url hash="3f1732f1">W17-27</url>
      <editor><first>Tommaso</first><last>Caselli</last></editor>
      <editor><first>Ben</first><last>Miller</last></editor>
      <editor><first>Marieke</first><last>van Erp</last></editor>
      <editor><first>Piek</first><last>Vossen</last></editor>
      <editor><first>Martha</first><last>Palmer</last></editor>
      <editor><first>Eduard</first><last>Hovy</last></editor>
      <editor><first>Teruko</first><last>Mitamura</last></editor>
      <editor><first>David</first><last>Caswell</last></editor>
      <doi>10.18653/v1/W17-27</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Vancouver, Canada</address>
      <month>August</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="ae5e16b0">W17-2700</url>
      <bibkey>ws-2017-events</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Detecting Changes in Twitter Streams using Temporal Clusters of Hashtags<fixed-case>T</fixed-case>witter Streams using Temporal Clusters of Hashtags</title>
      <author><first>Yunli</first><last>Wang</last></author>
      <author><first>Cyril</first><last>Goutte</last></author>
      <pages>10–14</pages>
      <url hash="8bdec457">W17-2702</url>
      <doi>10.18653/v1/W17-2702</doi>
      <abstract>Detecting events from social media data has important applications in <a href="https://en.wikipedia.org/wiki/Public_security">public security</a>, <a href="https://en.wikipedia.org/wiki/Politics">political issues</a>, and <a href="https://en.wikipedia.org/wiki/Public_health">public health</a>. Many studies have focused on detecting specific or unspecific events from <a href="https://en.wikipedia.org/wiki/Twitter">Twitter streams</a>. However, not much attention has been paid to detecting changes, and their impact, in online conversations related to an event. We propose methods for detecting such changes, using clustering of temporal profiles of hashtags, and three change point detection algorithms. The methods were tested on two Twitter datasets : one covering the 2014 Ottawa shooting event, and one covering the <a href="https://en.wikipedia.org/wiki/2014_Winter_Olympics">Sochi winter Olympics</a>. We compare our approach to a <a href="https://en.wikipedia.org/wiki/Baseline_(medicine)">baseline</a> consisting of detecting change from raw counts in the conversation. We show that our method produces large gains in change detection accuracy on both <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a>.</abstract>
      <bibkey>wang-goutte-2017-detecting</bibkey>
    </paper>
    <paper id="3">
      <title>Event Detection Using Frame-Semantic Parser</title>
      <author><first>Evangelia</first><last>Spiliopoulou</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <author><first>Teruko</first><last>Mitamura</last></author>
      <pages>15–20</pages>
      <url hash="11271331">W17-2703</url>
      <doi>10.18653/v1/W17-2703</doi>
      <abstract>Recent methods for Event Detection focus on <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a> for automatic feature generation and feature ranking. However, most of those approaches fail to exploit rich semantic information, which results in relatively poor <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall</a>. This paper is a small &amp; focused contribution, where we introduce an Event Detection and classification system, based on deep semantic information retrieved from a frame-semantic parser. Our experiments show that our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves higher <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall</a> than state-of-the-art systems. Further, we claim that enhancing our <a href="https://en.wikipedia.org/wiki/System">system</a> with deep learning techniques like feature ranking can achieve even better results, as it can benefit from both approaches.</abstract>
      <bibkey>spiliopoulou-etal-2017-event</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
    </paper>
    <paper id="8">
      <title>Inference of Fine-Grained Event Causality from Blogs and Films</title>
      <author><first>Zhichao</first><last>Hu</last></author>
      <author><first>Elahe</first><last>Rahimtoroghi</last></author>
      <author><first>Marilyn</first><last>Walker</last></author>
      <pages>52–58</pages>
      <url hash="c9465f6f">W17-2708</url>
      <doi>10.18653/v1/W17-2708</doi>
      <abstract>Human understanding of narrative is mainly driven by reasoning about <a href="https://en.wikipedia.org/wiki/Causality">causal relations</a> between events and thus recognizing them is a key capability for computational models of language understanding. Computational work in this area has approached this via two different routes : by focusing on acquiring a knowledge base of common causal relations between events, or by attempting to understand a particular story or macro-event, along with its storyline. In this position paper, we focus on knowledge acquisition approach and claim that <a href="https://en.wikipedia.org/wiki/News_agency">newswire</a> is a relatively poor source for learning fine-grained causal relations between everyday events. We describe experiments using an <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised method</a> to learn <a href="https://en.wikipedia.org/wiki/Causality">causal relations</a> between events in the narrative genres of <a href="https://en.wikipedia.org/wiki/First-person_narrative">first-person narratives</a> and film scene descriptions. We show that our method learns fine-grained causal relations, judged by humans as likely to be causal over 80 % of the time. We also demonstrate that the learned event pairs do not exist in publicly available event-pair datasets extracted from <a href="https://en.wikipedia.org/wiki/News_agency">newswire</a>.</abstract>
      <bibkey>hu-etal-2017-inference</bibkey>
    </paper>
    <paper id="9">
      <title>On the Creation of a Security-Related Event Corpus</title>
      <author><first>Martin</first><last>Atkinson</last></author>
      <author><first>Jakub</first><last>Piskorski</last></author>
      <author><first>Hristo</first><last>Tanev</last></author>
      <author><first>Vanni</first><last>Zavarella</last></author>
      <pages>59–65</pages>
      <url hash="e02462cf">W17-2709</url>
      <doi>10.18653/v1/W17-2709</doi>
      <abstract>This paper reports on an effort of creating a corpus of structured information on security-related events automatically extracted from <a href="https://en.wikipedia.org/wiki/Online_newspaper">on-line news</a>, part of which has been manually curated. The main motivation behind this effort is to provide material to the NLP community working on <a href="https://en.wikipedia.org/wiki/Event_extraction">event extraction</a> that could be used both for training and evaluation purposes.</abstract>
      <bibkey>atkinson-etal-2017-creation</bibkey>
    </paper>
    <paper id="10">
      <title>Inducing Event Types and Roles in Reverse : Using <a href="https://en.wikipedia.org/wiki/Function_(mathematics)">Function</a> to Discover Theme</title>
      <author><first>Natalie</first><last>Ahn</last></author>
      <pages>66–76</pages>
      <url hash="d4c19d89">W17-2710</url>
      <doi>10.18653/v1/W17-2710</doi>
      <abstract>With growing interest in automated event extraction, there is an increasing need to overcome the labor costs of hand-written event templates, entity lists, and annotated corpora. In the last few years, more inductive approaches have emerged, seeking to discover unknown event types and roles in <a href="https://en.wikipedia.org/wiki/Text_corpus">raw text</a>. The main recent efforts use probabilistic generative models, as in <a href="https://en.wikipedia.org/wiki/Topic_modeling">topic modeling</a>, which are formally concise but do not always yield stable or easily interpretable results. We argue that event schema induction can benefit from greater structure in the process and in linguistic features that distinguish words’ functions and <a href="https://en.wikipedia.org/wiki/Theme_(narrative)">themes</a>. To maximize our use of limited data, we reverse the typical schema induction steps and introduce new similarity measures, building an intuitive process for inducing the structure of unknown events.</abstract>
      <bibkey>ahn-2017-inducing</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/word-sense-disambiguation-a-unified">Word Sense Disambiguation: a Unified Evaluation Framework and Empirical Comparison</pwcdataset>
    </paper>
    <paper id="11">
      <title>The Event StoryLine Corpus : A New Benchmark for Causal and Temporal Relation Extraction<fixed-case>S</fixed-case>tory<fixed-case>L</fixed-case>ine Corpus: A New Benchmark for Causal and Temporal Relation Extraction</title>
      <author><first>Tommaso</first><last>Caselli</last></author>
      <author><first>Piek</first><last>Vossen</last></author>
      <pages>77–86</pages>
      <url hash="2ea64c04">W17-2711</url>
      <doi>10.18653/v1/W17-2711</doi>
      <abstract>This paper reports on the Event StoryLine Corpus (ESC) v1.0, a new benchmark dataset for the temporal and causal relation detection. By developing this dataset, we also introduce a new task, the StoryLine Extraction from news data, which aims at extracting and classifying events relevant for stories, from across news documents spread in time and clustered around a single seminal event or topic. In addition to describing the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>, we also report on three baselines systems whose results show the <a href="https://en.wikipedia.org/wiki/Complexity">complexity</a> of the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> and suggest directions for the development of more robust systems.</abstract>
      <bibkey>caselli-vossen-2017-event</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/ecb">ECB+</pwcdataset>
    </paper>
    <paper id="12">
      <title>The Rich Event Ontology</title>
      <author><first>Susan</first><last>Brown</last></author>
      <author><first>Claire</first><last>Bonial</last></author>
      <author><first>Leo</first><last>Obrst</last></author>
      <author><first>Martha</first><last>Palmer</last></author>
      <pages>87–97</pages>
      <url hash="2f41d80a">W17-2712</url>
      <doi>10.18653/v1/W17-2712</doi>
      <abstract>In this paper we describe a new lexical semantic resource, The Rich Event On-tology, which provides an independent conceptual backbone to unify existing semantic role labeling (SRL) schemas and augment them with event-to-event causal and temporal relations. By unifying the FrameNet, VerbNet, Automatic Content Extraction, and Rich Entities, Relations and Events resources, the ontology serves as a shared hub for the disparate annotation schemas and therefore enables the combination of SRL training data into a larger, more diverse corpus. By adding temporal and causal relational information not found in any of the independent resources, the <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontology</a> facilitates reasoning on and across documents, revealing relationships between events that come together in temporal and causal chains to build more complex scenarios. We envision the open resource serving as a valuable tool for both moving from the <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontology</a> to text to query for event types and scenarios of interest, and for moving from text to the <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontology</a> to access interpretations of events using the combined semantic information housed there.</abstract>
      <bibkey>brown-etal-2017-rich</bibkey>
    </paper>
    <paper id="13">
      <title>Integrating Decompositional Event Structures into Storylines</title>
      <author><first>William</first><last>Croft</last></author>
      <author><first>Pavlína</first><last>Pešková</last></author>
      <author><first>Michael</first><last>Regan</last></author>
      <pages>98–109</pages>
      <url hash="2c9f9186">W17-2713</url>
      <doi>10.18653/v1/W17-2713</doi>
      <abstract>Storyline research links together events in stories and specifies shared participants in those stories. In these analyses, an <a href="https://en.wikipedia.org/wiki/Atomic_event">atomic event</a> is assumed to be a single clause headed by a single verb. However, many analyses of verbal semantics assume a decompositional analysis of events expressed in single clauses. We present a formalization of a decompositional analysis of events in which each participant in a clausal event has their own temporally extended subevent, and the subevents are related through causal and other interactions. This decomposition allows us to represent <a href="https://en.wikipedia.org/wiki/Plot_(narrative)">storylines</a> as an evolving set of interactions between participants over time.</abstract>
      <bibkey>croft-etal-2017-integrating</bibkey>
    </paper>
  </volume>
  <volume id="28">
    <meta>
      <booktitle>Proceedings of the First Workshop on Language Grounding for Robotics</booktitle>
      <url hash="2c62b145">W17-28</url>
      <editor><first>Mohit</first><last>Bansal</last></editor>
      <editor><first>Cynthia</first><last>Matuszek</last></editor>
      <editor><first>Jacob</first><last>Andreas</last></editor>
      <editor><first>Yoav</first><last>Artzi</last></editor>
      <editor><first>Yonatan</first><last>Bisk</last></editor>
      <doi>10.18653/v1/W17-28</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Vancouver, Canada</address>
      <month>August</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="0800bc33">W17-2800</url>
      <bibkey>ws-2017-language</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Grounding Language for Interactive Task Learning</title>
      <author><first>Peter</first><last>Lindes</last></author>
      <author><first>Aaron</first><last>Mininger</last></author>
      <author><first>James R.</first><last>Kirk</last></author>
      <author><first>John E.</first><last>Laird</last></author>
      <pages>1–9</pages>
      <url hash="df692123">W17-2801</url>
      <doi>10.18653/v1/W17-2801</doi>
      <attachment type="dataset" hash="73e1c04d">W17-2801.Datasets.zip</attachment>
      <attachment type="poster" hash="29a9ff20">W17-2801.Poster.pdf</attachment>
      <abstract>This paper describes how <a href="https://en.wikipedia.org/wiki/Language">language</a> is grounded by a comprehension system called Lucia within a robotic agent called Rosie that can manipulate objects and navigate indoors. The whole system is built within the Soar cognitive architecture and uses Embodied Construction Grammar (ECG) as a formalism for describing linguistic knowledge. Grounding is performed using knowledge from the <a href="https://en.wikipedia.org/wiki/Grammar">grammar</a> itself, from the linguistic context, from the agents perception, and from an ontology of long-term knowledge about object categories and properties and actions the agent can perform. The paper also describes a benchmark corpus of 200 sentences in this domain along with test versions of the <a href="https://en.wikipedia.org/wiki/World_model">world model</a> and <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontology</a> and gold-standard meanings for each of the sentences. The benchmark is contained in the supplemental materials.</abstract>
      <bibkey>lindes-etal-2017-grounding</bibkey>
    </paper>
    <paper id="2">
      <title>Learning how to Learn : An Adaptive Dialogue Agent for Incrementally Learning Visually Grounded Word Meanings</title>
      <author><first>Yanchao</first><last>Yu</last></author>
      <author><first>Arash</first><last>Eshghi</last></author>
      <author><first>Oliver</first><last>Lemon</last></author>
      <pages>10–19</pages>
      <url hash="bf5049bf">W17-2802</url>
      <doi>10.18653/v1/W17-2802</doi>
      <abstract>We present an optimised multi-modal dialogue agent for interactive learning of visually grounded word meanings from a human tutor, trained on real human-human tutoring data. Within a life-long interactive learning period, the <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agent</a>, trained using Reinforcement Learning (RL), must be able to handle natural conversations with human users, and achieve good learning performance (i.e. accuracy) while minimising human effort in the <a href="https://en.wikipedia.org/wiki/Learning">learning process</a>. We train and evaluate this system in interaction with a simulated human tutor, which is built on the BURCHAK corpus   a Human-Human Dialogue dataset for the visual learning task. The results show that : 1) The learned <a href="https://en.wikipedia.org/wiki/Policy">policy</a> can coherently interact with the simulated user to achieve the goal of the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> (i.e. learning visual attributes of objects, e.g. colour and shape) ; and 2) it finds a better trade-off between classifier accuracy and tutoring costs than hand-crafted rule-based policies, including ones with dynamic policies.</abstract>
      <bibkey>yu-etal-2017-learning-learn</bibkey>
    </paper>
    <paper id="3">
      <title>Guiding Interaction Behaviors for Multi-modal Grounded Language Learning</title>
      <author><first>Jesse</first><last>Thomason</last></author>
      <author><first>Jivko</first><last>Sinapov</last></author>
      <author><first>Raymond</first><last>Mooney</last></author>
      <pages>20–24</pages>
      <url hash="5c6dfec4">W17-2803</url>
      <doi>10.18653/v1/W17-2803</doi>
      <abstract>Multi-modal grounded language learning connects language predicates to physical properties of objects in the world. Sensing with multiple modalities, such as audio, <a href="https://en.wikipedia.org/wiki/Haptic_perception">haptics</a>, and visual colors and shapes while performing interaction behaviors like lifting, dropping, and looking on objects enables a robot to ground non-visual predicates like empty as well as visual predicates like red. Previous work has established that grounding in <a href="https://en.wikipedia.org/wiki/Multimodal_interaction">multi-modal space</a> improves performance on object retrieval from <a href="https://en.wikipedia.org/wiki/Description">human descriptions</a>. In this work, we gather behavior annotations from humans and demonstrate that these improve language grounding performance by allowing a system to focus on relevant behaviors for words like white or half-full that can be understood by looking or lifting, respectively. We also explore adding modality annotations (whether to focus on audio or haptics when performing a behavior), which improves performance, and sharing information between linguistically related predicates (if green is a color, white is a color), which improves grounding recall but at the cost of precision.</abstract>
      <bibkey>thomason-etal-2017-guiding</bibkey>
    </paper>
    <paper id="5">
      <title>Natural Language Grounding and Grammar Induction for Robotic Manipulation Commands</title>
      <author><first>Muhannad</first><last>Alomari</last></author>
      <author><first>Paul</first><last>Duckworth</last></author>
      <author><first>Majd</first><last>Hawasly</last></author>
      <author><first>David C.</first><last>Hogg</last></author>
      <author><first>Anthony G.</first><last>Cohn</last></author>
      <pages>35–43</pages>
      <url hash="90c9b33f">W17-2805</url>
      <doi>10.18653/v1/W17-2805</doi>
      <abstract>We present a cognitively plausible system capable of acquiring knowledge in language and vision from pairs of short video clips and <a href="https://en.wikipedia.org/wiki/Linguistic_description">linguistic descriptions</a>. The aim of this work is to teach a robot manipulator how to execute <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language commands</a> by demonstration. This is achieved by first learning a set of visual ‘concepts’ that abstract the visual feature spaces into concepts that have human-level meaning. Second, learning the mapping / grounding between words and the extracted visual concepts. Third, inducing <a href="https://en.wikipedia.org/wiki/Grammar">grammar rules</a> via a semantic representation known as Robot Control Language (RCL). We evaluate our approach against state-of-the-art supervised and unsupervised grounding and grammar induction systems, and show that a robot can learn to execute never seen-before commands from pairs of unlabelled linguistic and visual inputs.</abstract>
      <bibkey>alomari-etal-2017-natural</bibkey>
    </paper>
    <paper id="7">
      <title>Grounding Symbols in Multi-Modal Instructions</title>
      <author><first>Yordan</first><last>Hristov</last></author>
      <author><first>Svetlin</first><last>Penkov</last></author>
      <author><first>Alex</first><last>Lascarides</last></author>
      <author><first>Subramanian</first><last>Ramamoorthy</last></author>
      <pages>49–57</pages>
      <url hash="915273aa">W17-2807</url>
      <doi>10.18653/v1/W17-2807</doi>
      <abstract>As robots begin to cohabit with humans in semi-structured environments, the need arises to understand instructions involving rich variabilityfor instance, learning to ground symbols in the physical world. Realistically, this task must cope with small datasets consisting of a particular users’ contextual assignment of meaning to terms. We present a method for processing a raw stream of cross-modal inputi.e., <a href="https://en.wikipedia.org/wiki/Natural_language_processing">linguistic instructions</a>, visual perception of a scene and a concurrent trace of 3D eye tracking fixationsto produce the segmentation of objects with a correspondent association to <a href="https://en.wikipedia.org/wiki/High-_and_low-level">high-level concepts</a>. To test our <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> we present experiments in a table-top object manipulation scenario. Our results show our model learns the user’s notion of colour and shape from a small number of physical demonstrations, generalising to identifying physical referents for novel combinations of the words.</abstract>
      <bibkey>hristov-etal-2017-grounding</bibkey>
    </paper>
    <paper id="9">
      <title>A Tale of Two DRAGGNs : A Hybrid Approach for Interpreting Action-Oriented and Goal-Oriented Instructions<fixed-case>DRAGGN</fixed-case>s: A Hybrid Approach for Interpreting Action-Oriented and Goal-Oriented Instructions</title>
      <author><first>Siddharth</first><last>Karamcheti</last></author>
      <author><first>Edward Clem</first><last>Williams</last></author>
      <author><first>Dilip</first><last>Arumugam</last></author>
      <author><first>Mina</first><last>Rhee</last></author>
      <author><first>Nakul</first><last>Gopalan</last></author>
      <author><first>Lawson L.S.</first><last>Wong</last></author>
      <author><first>Stefanie</first><last>Tellex</last></author>
      <pages>67–75</pages>
      <url hash="b7a23f76">W17-2809</url>
      <doi>10.18653/v1/W17-2809</doi>
      <abstract>Robots operating alongside humans in diverse, <a href="https://en.wikipedia.org/wiki/Stochastic_process">stochastic environments</a> must be able to accurately interpret <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language commands</a>. These instructions often fall into one of two categories : those that specify a goal condition or target state, and those that specify explicit actions, or how to perform a given task. Recent approaches have used reward functions as a semantic representation of goal-based commands, which allows for the use of a state-of-the-art planner to find a <a href="https://en.wikipedia.org/wiki/Policy">policy</a> for the given <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. However, these reward functions can not be directly used to represent action-oriented commands. We introduce a new hybrid approach, the Deep Recurrent Action-Goal Grounding Network (DRAGGN), for task grounding and execution that handles <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language</a> from either category as input, and generalizes to unseen environments. Our robot-simulation results demonstrate that a system successfully interpreting both goal-oriented and action-oriented task specifications brings us closer to robust <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language understanding</a> for <a href="https://en.wikipedia.org/wiki/Human–robot_interaction">human-robot interaction</a>.</abstract>
      <bibkey>karamcheti-etal-2017-tale</bibkey>
      <pwccode url="https://github.com/siddk/glamdp" additional="false">siddk/glamdp</pwccode>
    </paper>
    </volume>
  <volume id="29">
    <meta>
      <booktitle>Proceedings of the Second Workshop on <fixed-case>NLP</fixed-case> and Computational Social Science</booktitle>
      <url hash="f4ecef2f">W17-29</url>
      <editor><first>Dirk</first><last>Hovy</last></editor>
      <editor><first>Svitlana</first><last>Volkova</last></editor>
      <editor><first>David</first><last>Bamman</last></editor>
      <editor><first>David</first><last>Jurgens</last></editor>
      <editor><first>Brendan</first><last>O’Connor</last></editor>
      <editor><first>Oren</first><last>Tsur</last></editor>
      <editor><first>A. Seza</first><last>Doğruöz</last></editor>
      <doi>10.18653/v1/W17-29</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Vancouver, Canada</address>
      <month>August</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="bb28b79b">W17-2900</url>
      <bibkey>ws-2017-nlp-social</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Language-independent Gender Prediction on Twitter<fixed-case>T</fixed-case>witter</title>
      <author><first>Nikola</first><last>Ljubešić</last></author>
      <author><first>Darja</first><last>Fišer</last></author>
      <author><first>Tomaž</first><last>Erjavec</last></author>
      <pages>1–6</pages>
      <url hash="855a53c8">W17-2901</url>
      <doi>10.18653/v1/W17-2901</doi>
      <abstract>In this paper we present a set of experiments and analyses on predicting the gender of Twitter users based on language-independent features extracted either from the text or the metadata of users’ tweets. We perform our experiments on the TwiSty dataset containing manual gender annotations for users speaking six different languages. Our classification results show that, while the prediction model based on language-independent features performs worse than the <a href="https://en.wikipedia.org/wiki/Bag-of-words_model">bag-of-words model</a> when training and testing on the same language, it regularly outperforms the <a href="https://en.wikipedia.org/wiki/Bag-of-words_model">bag-of-words model</a> when applied to different languages, showing very stable results across various languages. Finally we perform a comparative analysis of feature effect sizes across the six languages and show that differences in our <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">features</a> correspond to cultural distances.</abstract>
      <bibkey>ljubesic-etal-2017-language</bibkey>
    </paper>
    <paper id="2">
      <title>When does a compliment become sexist? Analysis and classification of ambivalent sexism using twitter data</title>
      <author><first>Akshita</first><last>Jha</last></author>
      <author><first>Radhika</first><last>Mamidi</last></author>
      <pages>7–16</pages>
      <url hash="7b646a82">W17-2902</url>
      <doi>10.18653/v1/W17-2902</doi>
      <abstract>Sexism is prevalent in today’s society, both offline and online, and poses a credible threat to <a href="https://en.wikipedia.org/wiki/Social_equality">social equality</a> with respect to gender. According to ambivalent sexism theory (Glick and Fiske, 1996), it comes in two forms : Hostile and Benevolent. While <a href="https://en.wikipedia.org/wiki/Hostile_sexism">hostile sexism</a> is characterized by an explicitly negative attitude, <a href="https://en.wikipedia.org/wiki/Benevolent_sexism">benevolent sexism</a> is more subtle. Previous works on computationally detecting sexism present online are restricted to identifying the hostile form. Our objective is to investigate the less pronounced form of <a href="https://en.wikipedia.org/wiki/Sexism">sexism</a> demonstrated online. We achieve this by creating and analyzing a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> of <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> that exhibit <a href="https://en.wikipedia.org/wiki/Benevolent_sexism">benevolent sexism</a>. By using Support Vector Machines (SVM), sequence-to-sequence models and FastText classifier, we classify tweets into ‘Hostile’, ‘Benevolent’ or ‘Others’ class depending on the kind of sexism they exhibit. We have been able to achieve an <a href="https://en.wikipedia.org/wiki/F-score">F1-score</a> of 87.22 % using FastText classifier. Our work helps analyze and understand the much prevalent ambivalent sexism in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>.</abstract>
      <bibkey>jha-mamidi-2017-compliment</bibkey>
      <pwccode url="https://github.com/AkshitaJha/NLP_CSS_2017" additional="false">AkshitaJha/NLP_CSS_2017</pwccode>
    </paper>
    <paper id="3">
      <title>Personality Driven Differences in Paraphrase Preference</title>
      <author><first>Daniel</first><last>Preoţiuc-Pietro</last></author>
      <author><first>Jordan</first><last>Carpenter</last></author>
      <author><first>Lyle</first><last>Ungar</last></author>
      <pages>17–26</pages>
      <url hash="8b557f22">W17-2903</url>
      <doi>10.18653/v1/W17-2903</doi>
      <attachment type="presentation" hash="348f0052">W17-2903.Presentation.pdf</attachment>
      <abstract>Personality plays a decisive role in how people behave in different <a href="https://en.wikipedia.org/wiki/Scenario_analysis">scenarios</a>, including <a href="https://en.wikipedia.org/wiki/Social_media">online social media</a>. Researchers have used such <a href="https://en.wikipedia.org/wiki/Data">data</a> to study how <a href="https://en.wikipedia.org/wiki/Personality">personality</a> can be predicted from <a href="https://en.wikipedia.org/wiki/Usage_(language)">language use</a>. In this paper, we study phrase choice as a particular stylistic linguistic difference, as opposed to the mostly topical differences identified previously. Building on previous work on demographic preferences, we quantify differences in paraphrase choice from a massive Facebook data set with posts from over 115,000 users. We quantify the predictive power of phrase choice in user profiling and use phrase choice to study psycholinguistic hypotheses. This work is relevant to future applications that aim to personalize <a href="https://en.wikipedia.org/wiki/Text_generator">text generation</a> to specific personality types.</abstract>
      <bibkey>preotiuc-pietro-etal-2017-personality</bibkey>
    </paper>
    <paper id="4">
      <title>community2vec : Vector representations of online communities encode semantic relationships</title>
      <author><first>Trevor</first><last>Martin</last></author>
      <pages>27–31</pages>
      <url hash="fee11829">W17-2904</url>
      <doi>10.18653/v1/W17-2904</doi>
      <abstract>Vector embeddings of words have been shown to encode meaningful semantic relationships that enable solving of complex analogies. This vector embedding concept has been extended successfully to many different domains and in this paper we both create and visualize vector representations of an unstructured collection of online communities based on user participation. Further, we quantitatively and qualitatively show that these representations allow solving of semantically meaningful community analogies and also other more general types of relationships. These results could help improve community recommendation engines and also serve as a tool for sociological studies of community relatedness.</abstract>
      <bibkey>martin-2017-community2vec</bibkey>
    </paper>
    <paper id="5">
      <title>Telling Apart Tweets Associated with Controversial versus Non-Controversial Topics</title>
      <author><first>Aseel</first><last>Addawood</last></author>
      <author><first>Rezvaneh</first><last>Rezapour</last></author>
      <author><first>Omid</first><last>Abdar</last></author>
      <author><first>Jana</first><last>Diesner</last></author>
      <pages>32–41</pages>
      <url hash="442cf623">W17-2905</url>
      <doi>10.18653/v1/W17-2905</doi>
      <abstract>In this paper, we evaluate the <a href="https://en.wikipedia.org/wiki/Predictability">predictability of tweets</a> associated with controversial versus non-controversial topics. As a first step, we crowd-sourced the scoring of a predefined set of topics on a <a href="https://en.wikipedia.org/wiki/Likert_scale">Likert scale</a> from non-controversial to controversial. Our <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">feature set</a> entails and goes beyond <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment features</a>, e.g., by leveraging empathic language and other <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> that have been previously used but are new for this particular study. We find focusing on the structural characteristics of <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> to be beneficial for this task. Using a combination of emphatic, language-specific, and Twitter-specific features for <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a> resulted in 87 % accuracy (F1) for <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">cross-validation</a> of the training set and 63.4 % accuracy when using the test set. Our analysis shows that features specific to <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> or <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>, in general, are more prevalent in <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> on controversial topics than in non-controversial ones. To test the premise of the paper, we conducted two additional sets of experiments, which led to mixed results. This finding will inform our future investigations into the relationship between language use on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> and the perceived controversiality of topics.</abstract>
      <bibkey>addawood-etal-2017-telling</bibkey>
    </paper>
    <paper id="6">
      <title>Cross-Lingual Classification of Topics in Political Texts</title>
      <author><first>Goran</first><last>Glavaš</last></author>
      <author><first>Federico</first><last>Nanni</last></author>
      <author><first>Simone Paolo</first><last>Ponzetto</last></author>
      <pages>42–46</pages>
      <url hash="eb91636f">W17-2906</url>
      <doi>10.18653/v1/W17-2906</doi>
      <abstract>In this paper, we propose an approach for cross-lingual topical coding of sentences from electoral manifestos of political parties in different languages. To this end, we exploit continuous semantic text representations and induce a joint multilingual semantic vector spaces to enable <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a> using manually-coded sentences across different languages. Our experimental results show that <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> trained on multilingual data yield performance boosts over monolingual topic classification.</abstract>
      <bibkey>glavas-etal-2017-cross</bibkey>
    </paper>
    <paper id="7">
      <title>Mining Social Science Publications for Survey Variables</title>
      <author><first>Andrea</first><last>Zielinski</last></author>
      <author><first>Peter</first><last>Mutschke</last></author>
      <pages>47–52</pages>
      <url hash="c35079e1">W17-2907</url>
      <doi>10.18653/v1/W17-2907</doi>
      <abstract>Research in <a href="https://en.wikipedia.org/wiki/Social_science">Social Science</a> is usually based on <a href="https://en.wikipedia.org/wiki/Survey_methodology">survey data</a> where individual research questions relate to observable concepts (variables). However, due to a lack of standards for data citations a reliable identification of the variables used is often difficult. In this paper, we present a work-in-progress study that seeks to provide a solution to the variable detection task based on supervised machine learning algorithms, using a linguistic analysis pipeline to extract a rich feature set, including terminological concepts and similarity metric scores. Further, we present preliminary results on a small dataset that has been specifically designed for this task, yielding a significant increase in performance over the random baseline.</abstract>
      <bibkey>zielinski-mutschke-2017-mining</bibkey>
    </paper>
    <paper id="8">
      <title>Linguistic Markers of Influence in Informal Interactions</title>
      <author><first>Shrimai</first><last>Prabhumoye</last></author>
      <author><first>Samridhi</first><last>Choudhary</last></author>
      <author><first>Evangelia</first><last>Spiliopoulou</last></author>
      <author><first>Christopher</first><last>Bogart</last></author>
      <author><first>Carolyn</first><last>Rose</last></author>
      <author><first>Alan W</first><last>Black</last></author>
      <pages>53–62</pages>
      <url hash="7caed713">W17-2908</url>
      <doi>10.18653/v1/W17-2908</doi>
      <abstract>There has been a long standing interest in understanding ‘<a href="https://en.wikipedia.org/wiki/Social_influence">Social Influence</a>’ both in <a href="https://en.wikipedia.org/wiki/Social_science">Social Sciences</a> and in <a href="https://en.wikipedia.org/wiki/Computational_linguistics">Computational Linguistics</a>. In this paper, we present a novel approach to study and measure <a href="https://en.wikipedia.org/wiki/Interpersonal_influence">interpersonal influence</a> in <a href="https://en.wikipedia.org/wiki/Interpersonal_relationship">daily interactions</a>. Motivated by the basic principles of <a href="https://en.wikipedia.org/wiki/Social_influence">influence</a>, we attempt to identify indicative linguistic features of the posts in an online knitting community. We present the <a href="https://en.wikipedia.org/wiki/Scheme_(mathematics)">scheme</a> used to operationalize and label the posts as influential or non-influential. Experiments with the identified <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> show an improvement in the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification accuracy</a> of <a href="https://en.wikipedia.org/wiki/Social_influence">influence</a> by 3.15 %. Our results illustrate the important correlation between the structure of the language and its potential to influence others.</abstract>
      <bibkey>prabhumoye-etal-2017-linguistic</bibkey>
    </paper>
    <paper id="9">
      <title>Non-lexical Features Encode Political Affiliation on Twitter<fixed-case>T</fixed-case>witter</title>
      <author><first>Rachael</first><last>Tatman</last></author>
      <author><first>Leo</first><last>Stewart</last></author>
      <author><first>Amandalynne</first><last>Paullada</last></author>
      <author><first>Emma</first><last>Spiro</last></author>
      <pages>63–67</pages>
      <url hash="4fe56ce8">W17-2909</url>
      <doi>10.18653/v1/W17-2909</doi>
      <abstract>Previous work on classifying Twitter users’ political alignment has mainly focused on lexical and social network features. This study provides evidence that political affiliation is also reflected in features which have been previously overlooked : users’ discourse patterns (proportion of Tweets that are retweets or replies) and their rate of use of <a href="https://en.wikipedia.org/wiki/Capitalization">capitalization</a> and <a href="https://en.wikipedia.org/wiki/Punctuation">punctuation</a>. We find robust differences between politically left- and right-leaning communities with respect to these discourse and sub-lexical features, although they are not enough to train a high-accuracy classifier.</abstract>
      <bibkey>tatman-etal-2017-non</bibkey>
    </paper>
    <paper id="12">
      <title>How Does Twitter User Behavior Vary Across Demographic Groups?<fixed-case>T</fixed-case>witter User Behavior Vary Across Demographic Groups?</title>
      <author><first>Zach</first><last>Wood-Doughty</last></author>
      <author><first>Michael</first><last>Smith</last></author>
      <author><first>David</first><last>Broniatowski</last></author>
      <author><first>Mark</first><last>Dredze</last></author>
      <pages>83–89</pages>
      <url hash="297f0d39">W17-2912</url>
      <doi>10.18653/v1/W17-2912</doi>
      <abstract>Demographically-tagged social media messages are a common source of data for <a href="https://en.wikipedia.org/wiki/Computational_social_science">computational social science</a>. While these messages can indicate differences in beliefs and behaviors between demographic groups, we do not have a clear understanding of how different demographic groups use platforms such as <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>. This paper presents a preliminary analysis of how groups’ differing behaviors may confound analyses of the groups themselves. We analyzed one million <a href="https://en.wikipedia.org/wiki/Twitter">Twitter users</a> by first inferring <a href="https://en.wikipedia.org/wiki/Demography">demographic attributes</a>, and then measuring several <a href="https://en.wikipedia.org/wiki/Indicator_(statistics)">indicators</a> of <a href="https://en.wikipedia.org/wiki/Twitter">Twitter behavior</a>. We find differences in these indicators across demographic groups, suggesting that there may be underlying differences in how different demographic groups use <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>.</abstract>
      <bibkey>wood-doughty-etal-2017-twitter</bibkey>
    </paper>
    <paper id="13">
      <title>Ideological Phrase Indicators for Classification of Political Discourse Framing on Twitter<fixed-case>T</fixed-case>witter</title>
      <author><first>Kristen</first><last>Johnson</last></author>
      <author><first>I-Ta</first><last>Lee</last></author>
      <author><first>Dan</first><last>Goldwasser</last></author>
      <pages>90–99</pages>
      <url hash="d4b1785c">W17-2913</url>
      <doi>10.18653/v1/W17-2913</doi>
      <abstract>Politicians carefully word their statements in order to influence how others view an issue, a <a href="https://en.wikipedia.org/wiki/Political_strategy">political strategy</a> called <a href="https://en.wikipedia.org/wiki/Framing_(social_sciences)">framing</a>. Simultaneously, these <a href="https://en.wikipedia.org/wiki/Framing_(social_sciences)">frames</a> may also reveal the beliefs or positions on an issue of the politician. Simple language features such as <a href="https://en.wikipedia.org/wiki/Unigram">unigrams</a>, <a href="https://en.wikipedia.org/wiki/Bigram">bigrams</a>, and <a href="https://en.wikipedia.org/wiki/Trigram">trigrams</a> are important indicators for identifying the general frame of a text, for both longer congressional speeches and shorter tweets of politicians. However, <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> may contain multiple <a href="https://en.wikipedia.org/wiki/Unigram">unigrams</a> across different frames which limits the effectiveness of this approach. In this paper, we present a joint model which uses both linguistic features of tweets and ideological phrase indicators extracted from a state-of-the-art embedding-based model to predict the general frame of political tweets.</abstract>
      <bibkey>johnson-etal-2017-ideological</bibkey>
    </paper>
  </volume>
  <volume id="30">
    <meta>
      <booktitle>Proceedings of the First Workshop on Abusive Language Online</booktitle>
      <url hash="9976b544">W17-30</url>
      <editor><first>Zeerak</first><last>Waseem</last></editor>
      <editor><first>Wendy Hui Kyong</first><last>Chung</last></editor>
      <editor><first>Dirk</first><last>Hovy</last></editor>
      <editor><first>Joel</first><last>Tetreault</last></editor>
      <doi>10.18653/v1/W17-30</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Vancouver, BC, Canada</address>
      <month>August</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="84680cfb">W17-3000</url>
      <bibkey>ws-2017-abusive</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Dimensions of Abusive Language on Twitter<fixed-case>T</fixed-case>witter</title>
      <author><first>Isobelle</first><last>Clarke</last></author>
      <author><first>Jack</first><last>Grieve</last></author>
      <pages>1–10</pages>
      <url hash="c55878a3">W17-3001</url>
      <doi>10.18653/v1/W17-3001</doi>
      <abstract>In this paper, we use a new categorical form of multidimensional register analysis to identify the main dimensions of functional linguistic variation in a corpus of abusive language, consisting of racist and sexist Tweets. By analysing the use of a wide variety of parts-of-speech and grammatical constructions, as well as various features related to <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> and <a href="https://en.wikipedia.org/wiki/Computer-mediated_communication">computer-mediated communication</a>, we discover three dimensions of linguistic variation in this <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>, which we interpret as being related to the degree of interactive, antagonistic and attitudinal language exhibited by individual Tweets. We then demonstrate that there is a significant functional difference between racist and sexist Tweets, with sexists Tweets tending to be more interactive and attitudinal than racist Tweets.</abstract>
      <bibkey>clarke-grieve-2017-dimensions</bibkey>
    </paper>
    <paper id="2">
      <title>Constructive Language in News Comments</title>
      <author><first>Varada</first><last>Kolhatkar</last></author>
      <author><first>Maite</first><last>Taboada</last></author>
      <pages>11–17</pages>
      <url hash="161b45ed">W17-3002</url>
      <doi>10.18653/v1/W17-3002</doi>
      <abstract>We discuss the characteristics of constructive news comments, and present methods to identify them. First, we define the notion of constructiveness. Second, we annotate a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> for <a href="https://en.wikipedia.org/wiki/Constructivism_(philosophy_of_education)">constructiveness</a>. Third, we explore whether available argumentation corpora can be useful to identify constructiveness in news comments. Our <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> trained on <a href="https://en.wikipedia.org/wiki/Argumentation_theory">argumentation corpora</a> achieves a top <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 72.59 % (baseline=49.44 %) on our crowd-annotated test data. Finally, we examine the relation between constructiveness and <a href="https://en.wikipedia.org/wiki/Toxicity">toxicity</a>. In our crowd-annotated data, 21.42 % of the non-constructive comments and 17.89 % of the constructive comments are toxic, suggesting that non-constructive comments are not much more toxic than constructive comments.</abstract>
      <bibkey>kolhatkar-taboada-2017-constructive</bibkey>
    </paper>
    <paper id="3">
      <title>Rephrasing Profanity in Chinese Text<fixed-case>C</fixed-case>hinese Text</title>
      <author><first>Hui-Po</first><last>Su</last></author>
      <author><first>Zhen-Jie</first><last>Huang</last></author>
      <author><first>Hao-Tsung</first><last>Chang</last></author>
      <author><first>Chuan-Jie</first><last>Lin</last></author>
      <pages>18–24</pages>
      <url hash="23131f3d">W17-3003</url>
      <doi>10.18653/v1/W17-3003</doi>
      <abstract>This paper proposes a <a href="https://en.wikipedia.org/wiki/System">system</a> that can detect and rephrase profanity in <a href="https://en.wikipedia.org/wiki/Written_Chinese">Chinese text</a>. Rather than just masking detected profanity, we want to revise the input sentence by using inoffensive words while keeping their original meanings. 29 of such rephrasing rules were invented after observing sentences on real-word social websites. The overall <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of the proposed <a href="https://en.wikipedia.org/wiki/System">system</a> is 85.56 %</abstract>
      <bibkey>su-etal-2017-rephrasing</bibkey>
    </paper>
    <paper id="4">
      <title>Deep Learning for User Comment Moderation</title>
      <author><first>John</first><last>Pavlopoulos</last></author>
      <author><first>Prodromos</first><last>Malakasiotis</last></author>
      <author><first>Ion</first><last>Androutsopoulos</last></author>
      <pages>25–35</pages>
      <url hash="ec3e61dd">W17-3004</url>
      <doi>10.18653/v1/W17-3004</doi>
      <abstract>Experimenting with a new dataset of 1.6 M user comments from a Greek news portal and existing datasets of EnglishWikipedia comments, we show that an <a href="https://en.wikipedia.org/wiki/Random-access_memory">RNN</a> outperforms the previous state of the art in <a href="https://en.wikipedia.org/wiki/Moderation_system">moderation</a>. A deep, classification-specific attention mechanism improves further the overall performance of the <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">RNN</a>. We also compare against a <a href="https://en.wikipedia.org/wiki/CNN">CNN</a> and a word-list baseline, considering both fully automatic and semi-automatic moderation.</abstract>
      <bibkey>pavlopoulos-etal-2017-deep</bibkey>
    </paper>
    <paper id="5">
      <title>Class-based Prediction Errors to Detect Hate Speech with Out-of-vocabulary Words</title>
      <author><first>Joan</first><last>Serrà</last></author>
      <author><first>Ilias</first><last>Leontiadis</last></author>
      <author><first>Dimitris</first><last>Spathis</last></author>
      <author><first>Gianluca</first><last>Stringhini</last></author>
      <author><first>Jeremy</first><last>Blackburn</last></author>
      <author><first>Athena</first><last>Vakali</last></author>
      <pages>36–40</pages>
      <url hash="ec2f7b5e">W17-3005</url>
      <doi>10.18653/v1/W17-3005</doi>
      <abstract>Common approaches to <a href="https://en.wikipedia.org/wiki/Categorization">text categorization</a> essentially rely either on <a href="https://en.wikipedia.org/wiki/N-gram">n-gram counts</a> or on <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>. This presents important difficulties in highly dynamic or quickly-interacting environments, where the appearance of new words and/or varied misspellings is the norm. A paradigmatic example of this situation is abusive online behavior, with <a href="https://en.wikipedia.org/wiki/List_of_social_networking_websites">social networks</a> and <a href="https://en.wikipedia.org/wiki/Mass_media">media platforms</a> struggling to effectively combat uncommon or non-blacklisted hate words. To better deal with these issues in those fast-paced environments, we propose using the <a href="https://en.wikipedia.org/wiki/Error_signal">error signal</a> of class-based language models as input to text classification algorithms. In particular, we train a next-character prediction model for any given class and then exploit the error of such class-based models to inform a neural network classifier. This way, we shift from the ‘ability to describe’ seen documents to the ‘ability to predict’ unseen content. Preliminary studies using out-of-vocabulary splits from abusive tweet data show promising results, outperforming competitive text categorization strategies by 4-11 %.</abstract>
      <bibkey>serra-etal-2017-class</bibkey>
    </paper>
    <paper id="6">
      <title>One-step and Two-step Classification for Abusive Language Detection on Twitter<fixed-case>T</fixed-case>witter</title>
      <author><first>Ji Ho</first><last>Park</last></author>
      <author><first>Pascale</first><last>Fung</last></author>
      <pages>41–45</pages>
      <url hash="13cb9bf5">W17-3006</url>
      <doi>10.18653/v1/W17-3006</doi>
      <abstract>Automatic abusive language detection is a difficult but important task for <a href="https://en.wikipedia.org/wiki/Social_media">online social media</a>. Our research explores a two-step approach of performing classification on abusive language and then classifying into specific types and compares it with one-step approach of doing one multi-class classification for detecting sexist and racist languages. With a public English Twitter corpus of 20 thousand tweets in the type of <a href="https://en.wikipedia.org/wiki/Sexism">sexism</a> and <a href="https://en.wikipedia.org/wiki/Racism">racism</a>, our approach shows a promising performance of 0.827 <a href="https://en.wikipedia.org/wiki/F-measure">F-measure</a> by using HybridCNN in one-step and 0.824 <a href="https://en.wikipedia.org/wiki/F-measure">F-measure</a> by using <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a> in two-steps.</abstract>
      <bibkey>park-fung-2017-one</bibkey>
    </paper>
    <paper id="8">
      <title>Abusive Language Detection on Arabic Social Media<fixed-case>A</fixed-case>rabic Social Media</title>
      <author><first>Hamdy</first><last>Mubarak</last></author>
      <author><first>Kareem</first><last>Darwish</last></author>
      <author><first>Walid</first><last>Magdy</last></author>
      <pages>52–56</pages>
      <url hash="772200a9">W17-3008</url>
      <doi>10.18653/v1/W17-3008</doi>
      <abstract>In this paper, we present our work on detecting abusive language on Arabic social media. We extract a list of <a href="https://en.wikipedia.org/wiki/Obscenity">obscene words</a> and <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a> using common patterns used in offensive and rude communications. We also classify Twitter users according to whether they use any of these <a href="https://en.wikipedia.org/wiki/Word">words</a> or not in their tweets. We expand the list of obscene words using this classification, and we report results on a newly created dataset of classified Arabic tweets (obscene, offensive, and clean). We make this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> freely available for research, in addition to the list of obscene words and <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a>. We are also publicly releasing a large corpus of classified user comments that were deleted from a popular Arabic news site due to violations the site’s rules and guidelines.</abstract>
      <bibkey>mubarak-etal-2017-abusive</bibkey>
    </paper>
    <paper id="9">
      <title>Vectors for Counterspeech on Twitter<fixed-case>T</fixed-case>witter</title>
      <author><first>Lucas</first><last>Wright</last></author>
      <author><first>Derek</first><last>Ruths</last></author>
      <author><first>Kelly P</first><last>Dillon</last></author>
      <author><first>Haji Mohammad</first><last>Saleem</last></author>
      <author><first>Susan</first><last>Benesch</last></author>
      <pages>57–62</pages>
      <url hash="b0804056">W17-3009</url>
      <doi>10.18653/v1/W17-3009</doi>
      <abstract>A study of conversations on <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> found that some arguments between strangers led to favorable change in discourse and even in <a href="https://en.wikipedia.org/wiki/Attitude_(psychology)">attitudes</a>. The authors propose that such exchanges can be usefully distinguished according to whether individuals or groups take part on each side, since the opportunity for a constructive exchange of views seems to vary accordingly.</abstract>
      <bibkey>wright-etal-2017-vectors</bibkey>
    </paper>
    <paper id="10">
      <title>Detecting Nastiness in <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a></title>
      <author><first>Niloofar</first><last>Safi Samghabadi</last></author>
      <author><first>Suraj</first><last>Maharjan</last></author>
      <author><first>Alan</first><last>Sprague</last></author>
      <author><first>Raquel</first><last>Diaz-Sprague</last></author>
      <author><first>Thamar</first><last>Solorio</last></author>
      <pages>63–72</pages>
      <url hash="f55e5e79">W17-3010</url>
      <doi>10.18653/v1/W17-3010</doi>
      <abstract>Although <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> has made it easy for people to connect on a virtually unlimited basis, <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> has also opened doors to people who misuse it to undermine, harass, humiliate, threaten and bully others. There is a lack of adequate resources to detect and hinder its occurrence. In this paper, we present our initial NLP approach to detect invective posts as a first step to eventually detect and deter <a href="https://en.wikipedia.org/wiki/Cyberbullying">cyberbullying</a>. We crawl data containing <a href="https://en.wikipedia.org/wiki/Profanity">profanities</a> and then determine whether or not it contains invective. Annotations on this <a href="https://en.wikipedia.org/wiki/Data">data</a> are improved iteratively by in-lab annotations and <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourcing</a>. We pursue different NLP approaches containing various typical and some newer techniques to distinguish the use of <a href="https://en.wikipedia.org/wiki/Profanity">swear words</a> in a neutral way from those instances in which they are used in an insulting way. We also show that this <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> not only works for our <a href="https://en.wikipedia.org/wiki/Data_set">data set</a>, but also can be successfully applied to different <a href="https://en.wikipedia.org/wiki/Data_set">data sets</a>.</abstract>
      <bibkey>safi-samghabadi-etal-2017-detecting</bibkey>
    </paper>
    <paper id="12">
      <title>Understanding Abuse : A Typology of Abusive Language Detection Subtasks</title>
      <author><first>Zeerak</first><last>Waseem</last></author>
      <author><first>Thomas</first><last>Davidson</last></author>
      <author><first>Dana</first><last>Warmsley</last></author>
      <author><first>Ingmar</first><last>Weber</last></author>
      <pages>78–84</pages>
      <url hash="79761f34">W17-3012</url>
      <doi>10.18653/v1/W17-3012</doi>
      <abstract>As the body of research on abusive language detection and analysis grows, there is a need for critical consideration of the relationships between different subtasks that have been grouped under this label. Based on work on <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a>, <a href="https://en.wikipedia.org/wiki/Cyberbullying">cyberbullying</a>, and <a href="https://en.wikipedia.org/wiki/Online_abuse">online abuse</a> we propose a typology that captures central similarities and differences between subtasks and discuss the implications of this for data annotation and feature construction. We emphasize the practical actions that can be taken by researchers to best approach their abusive language detection subtask of interest.</abstract>
      <bibkey>waseem-etal-2017-understanding</bibkey>
    </paper>
    <paper id="14">
      <title>Illegal is not a Noun : Linguistic Form for Detection of Pejorative Nominalizations</title>
      <author><first>Alexis</first><last>Palmer</last></author>
      <author><first>Melissa</first><last>Robinson</last></author>
      <author><first>Kristy K.</first><last>Phillips</last></author>
      <pages>91–100</pages>
      <url hash="57fbb02c">W17-3014</url>
      <doi>10.18653/v1/W17-3014</doi>
      <abstract>This paper focuses on a particular type of abusive language, targeting expressions in which typically neutral adjectives take on pejorative meaning when used as nouns-compare ‘gay people’ to ‘the gays’. We first collect and analyze a corpus of hand-curated, expert-annotated pejorative nominalizations for four target adjectives : female, gay, illegal, and poor. We then collect a second corpus of automatically-extracted and POS-tagged, crowd-annotated tweets. For both corpora, we find support for the hypothesis that some <a href="https://en.wikipedia.org/wiki/Adjective">adjectives</a>, when nominalized, take on negative meaning. The targeted constructions are non-standard yet widely-used, and <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech taggers</a> mistag some nominal forms as <a href="https://en.wikipedia.org/wiki/Adjective">adjectives</a>. We implement a tool called NomCatcher to correct these mistaggings, and find that the same tool is effective for identifying new adjectives subject to transformation via <a href="https://en.wikipedia.org/wiki/Nominalization">nominalization</a> into abusive language.</abstract>
      <bibkey>palmer-etal-2017-illegal</bibkey>
    </paper>
  </volume>
  <volume id="31">
    <meta>
      <booktitle>Proceedings of the Fourth Workshop on Computational Linguistics and Clinical Psychology — From Linguistic Signal to Clinical Reality</booktitle>
      <url hash="e6575b05">W17-31</url>
      <editor><first>Kristy</first><last>Hollingshead</last></editor>
      <editor><first>Molly E.</first><last>Ireland</last></editor>
      <editor><first>Kate</first><last>Loveys</last></editor>
      <doi>10.18653/v1/W17-31</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Vancouver, BC</address>
      <month>August</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="a9d9237c">W17-3100</url>
      <bibkey>ws-2017-linguistics-clinical</bibkey>
    </frontmatter>
    <paper id="1">
      <title>A Cross-modal Review of Indicators for Depression Detection Systems</title>
      <author><first>Michelle</first><last>Morales</last></author>
      <author><first>Stefan</first><last>Scherer</last></author>
      <author><first>Rivka</first><last>Levitan</last></author>
      <pages>1–12</pages>
      <url hash="1a28c67b">W17-3101</url>
      <doi>10.18653/v1/W17-3101</doi>
      <abstract>Automatic detection of depression has attracted increasing attention from researchers in <a href="https://en.wikipedia.org/wiki/Psychology">psychology</a>, <a href="https://en.wikipedia.org/wiki/Computer_science">computer science</a>, <a href="https://en.wikipedia.org/wiki/Linguistics">linguistics</a>, and related disciplines. As a result, promising <a href="https://en.wikipedia.org/wiki/Depression_(mood)">depression detection systems</a> have been reported. This paper surveys these efforts by presenting the first cross-modal review of depression detection systems and discusses best practices and most promising approaches to this task.</abstract>
      <bibkey>morales-etal-2017-cross</bibkey>
    </paper>
    <paper id="2">
      <title>In your wildest dreams : the language and psychological features of dreams</title>
      <author><first>Kate</first><last>Niederhoffer</last></author>
      <author><first>Jonathan</first><last>Schler</last></author>
      <author><first>Patrick</first><last>Crutchley</last></author>
      <author><first>Kate</first><last>Loveys</last></author>
      <author><first>Glen</first><last>Coppersmith</last></author>
      <pages>13–25</pages>
      <url hash="6af9711f">W17-3102</url>
      <doi>10.18653/v1/W17-3102</doi>
      <abstract>In this paper, we provide the first quantified exploration of the structure of the language of dreams, their linguistic style and <a href="https://en.wikipedia.org/wiki/Emotion">emotional content</a>. We present a collection of digital dream logs as a viable corpus for the growing study of <a href="https://en.wikipedia.org/wiki/Mental_health">mental health</a> through the lens of language, complementary to the work done examining more traditional <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. This paper is largely exploratory in nature to lay the groundwork for subsequent research in <a href="https://en.wikipedia.org/wiki/Mental_health">mental health</a>, rather than optimizing a particular text classification task.</abstract>
      <bibkey>niederhoffer-etal-2017-wildest</bibkey>
    </paper>
    <paper id="3">
      <title>A Corpus Analysis of Social Connections and <a href="https://en.wikipedia.org/wiki/Social_isolation">Social Isolation</a> in Adolescents Suffering from Depressive Disorders</title>
      <author><first>Jia-Wen</first><last>Guo</last></author>
      <author><first>Danielle L</first><last>Mowery</last></author>
      <author><first>Djin</first><last>Lai</last></author>
      <author><first>Katherine</first><last>Sward</last></author>
      <author><first>Mike</first><last>Conway</last></author>
      <pages>26–31</pages>
      <url hash="fc1188c6">W17-3103</url>
      <doi>10.18653/v1/W17-3103</doi>
      <abstract>Social connection and <a href="https://en.wikipedia.org/wiki/Social_isolation">social isolation</a> are associated with <a href="https://en.wikipedia.org/wiki/Major_depressive_disorder">depressive symptoms</a>, particularly in adolescents and young adults, but how these concepts are documented in <a href="https://en.wikipedia.org/wiki/Medical_record">clinical notes</a> is unknown. This pilot study aimed to identify the topics relevant to <a href="https://en.wikipedia.org/wiki/Interpersonal_relationship">social connection</a> and <a href="https://en.wikipedia.org/wiki/Social_isolation">isolation</a> by analyzing 145 clinical notes from patients with <a href="https://en.wikipedia.org/wiki/Major_depressive_disorder">depression diagnosis</a>. We found that providers, including <a href="https://en.wikipedia.org/wiki/Physician">physicians</a>, <a href="https://en.wikipedia.org/wiki/Nursing">nurses</a>, social workers, and psychologists, document descriptions of both <a href="https://en.wikipedia.org/wiki/Social_connection">social connection</a> and <a href="https://en.wikipedia.org/wiki/Social_isolation">social isolation</a>.</abstract>
      <bibkey>guo-etal-2017-corpus</bibkey>
    </paper>
    <paper id="5">
      <title>Investigating Patient Attitudes Towards the use of Social Media Data to Augment Depression Diagnosis and Treatment : a Qualitative Study</title>
      <author><first>Jude</first><last>Mikal</last></author>
      <author><first>Samantha</first><last>Hurst</last></author>
      <author><first>Mike</first><last>Conway</last></author>
      <pages>41–47</pages>
      <url hash="cf22cb8b">W17-3105</url>
      <doi>10.18653/v1/W17-3105</doi>
      <abstract>In this paper, we use <a href="https://en.wikipedia.org/wiki/Qualitative_research">qualitative research methods</a> to investigate the attitudes of <a href="https://en.wikipedia.org/wiki/Social_media">social media users</a> towards the (opt-in) integration of social media data with routine mental health care and diagnosis. Our investigation was based on secondary analysis of a series of five focus groups with Twitter users, including three groups consisting of participants with a self-reported history of depression, and two groups consisting of participants without a self reported history of depression. Our results indicate that, overall, research participants were enthusiastic about the possibility of using <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> (in conjunction with automated Natural Language Processing algorithms) for mood tracking under the supervision of a mental health practitioner. However, for at least some participants, there was skepticism related to how well <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> represents the mental health of users, and hence its usefulness in the clinical context.</abstract>
      <bibkey>mikal-etal-2017-investigating</bibkey>
    </paper>
    <paper id="6">
      <title>Natural-language Interactive Narratives in Imaginal Exposure Therapy for Obsessive-Compulsive Disorder</title>
      <author><first>Melissa</first><last>Roemmele</last></author>
      <author><first>Paola</first><last>Mardo</last></author>
      <author><first>Andrew</first><last>Gordon</last></author>
      <pages>48–57</pages>
      <url hash="c906de43">W17-3106</url>
      <doi>10.18653/v1/W17-3106</doi>
      <abstract>Obsessive-compulsive disorder (OCD) is an <a href="https://en.wikipedia.org/wiki/Anxiety_disorder">anxiety-based disorder</a> that affects around 2.5 % of the population. A common treatment for <a href="https://en.wikipedia.org/wiki/Obsessive–compulsive_disorder">OCD</a> is <a href="https://en.wikipedia.org/wiki/Exposure_therapy">exposure therapy</a>, where the patient repeatedly confronts a feared experience, which has the long-term effect of decreasing their anxiety. Some exposures consist of reading and writing stories about an imagined anxiety-provoking scenario. In this paper, we present a technology that enables patients to interactively contribute to exposure stories by supplying natural language input (typed or spoken) that advances a scenario. This <a href="https://en.wikipedia.org/wiki/Interactivity">interactivity</a> could potentially increase the patient’s sense of immersion in an exposure and contribute to its success. We introduce the NLP task behind processing inputs to predict new events in the <a href="https://en.wikipedia.org/wiki/Scenario">scenario</a>, and describe our initial approach. We then illustrate the future possibility of this work with an example of an exposure scenario authored with our <a href="https://en.wikipedia.org/wiki/Application_software">application</a>.</abstract>
      <bibkey>roemmele-etal-2017-natural</bibkey>
    </paper>
    <paper id="7">
      <title>Detecting Anxiety through Reddit<fixed-case>R</fixed-case>eddit</title>
      <author><first>Judy Hanwen</first><last>Shen</last></author>
      <author><first>Frank</first><last>Rudzicz</last></author>
      <pages>58–65</pages>
      <url hash="5e7a652f">W17-3107</url>
      <doi>10.18653/v1/W17-3107</doi>
      <abstract>Previous investigations into detecting mental illnesses through <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> have predominately focused on detecting depression through Twitter corpora. In this paper, we study <a href="https://en.wikipedia.org/wiki/Anxiety_disorder">anxiety disorders</a> through personal narratives collected through the popular social media website, <a href="https://en.wikipedia.org/wiki/Reddit">Reddit</a>. We build a substantial data set of typical and anxiety-related posts, and we apply N-gram language modeling, vector embeddings, topic analysis, and emotional norms to generate features that accurately classify posts related to binary levels of anxiety. We achieve an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 91 % with vector-space word embeddings, and an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 98 % when combined with lexicon-based features.</abstract>
      <bibkey>shen-rudzicz-2017-detecting</bibkey>
    </paper>
    <paper id="9">
      <title>A Dictionary-Based Comparison of <a href="https://en.wikipedia.org/wiki/Autobiography">Autobiographies</a> by People and Murderous Monsters</title>
      <author><first>Micah</first><last>Iserman</last></author>
      <author><first>Molly</first><last>Ireland</last></author>
      <pages>74–84</pages>
      <url hash="0e5dceb3">W17-3109</url>
      <doi>10.18653/v1/W17-3109</doi>
      <abstract>People typically assume that killers are mentally ill or fundamentally different from the rest of humanity. Similarly, people often associate <a href="https://en.wikipedia.org/wiki/Mental_disorder">mental health conditions</a> (such as <a href="https://en.wikipedia.org/wiki/Schizophrenia">schizophrenia</a> or autism) with <a href="https://en.wikipedia.org/wiki/Violence">violence</a> and otherness-treatable perhaps, but not empathically understandable. We take a dictionary approach to explore word use in a set of <a href="https://en.wikipedia.org/wiki/Autobiography">autobiographies</a>, comparing the narratives of 2 killers (Adolf Hitler and Elliot Rodger) and 39 non-killers. Although results suggest several dimensions that differentiate these autobiographies-such as <a href="https://en.wikipedia.org/wiki/Sentimentality">sentiment</a>, temporal orientation, and references to death-they appear to reflect subject matter rather than psychology per se. Additionally, the Rodger text shows roughly typical developmental arcs in its use of words relating to <a href="https://en.wikipedia.org/wiki/Friendship">friends</a>, <a href="https://en.wikipedia.org/wiki/Family">family</a>, <a href="https://en.wikipedia.org/wiki/Sex">sex</a>, and <a href="https://en.wikipedia.org/wiki/Affect_(psychology)">affect</a>. From these data, we discuss the challenges of understanding <a href="https://en.wikipedia.org/wiki/Murder">killers</a> and people in general.</abstract>
      <bibkey>iserman-ireland-2017-dictionary</bibkey>
    </paper>
    <paper id="10">
      <title>Small but Mighty : Affective Micropatterns for Quantifying Mental Health from Social Media Language</title>
      <author><first>Kate</first><last>Loveys</last></author>
      <author><first>Patrick</first><last>Crutchley</last></author>
      <author><first>Emily</first><last>Wyatt</last></author>
      <author><first>Glen</first><last>Coppersmith</last></author>
      <pages>85–95</pages>
      <url hash="676f2693">W17-3110</url>
      <doi>10.18653/v1/W17-3110</doi>
      <abstract>Many <a href="https://en.wikipedia.org/wiki/Phenomenon">psychological phenomena</a> occur in small time windows, measured in minutes or hours. However, most <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational linguistic techniques</a> look at data on the order of weeks, months, or years. We explore micropatterns in sequences of messages occurring over a short time window for their prevalence and power for quantifying psychological phenomena, specifically, patterns in affect. We examine affective micropatterns in social media posts from users with anxiety, <a href="https://en.wikipedia.org/wiki/Eating_disorder">eating disorders</a>, <a href="https://en.wikipedia.org/wiki/Panic_attack">panic attacks</a>, <a href="https://en.wikipedia.org/wiki/Schizophrenia">schizophrenia</a>, <a href="https://en.wikipedia.org/wiki/Suicidality">suicidality</a>, and matched controls.</abstract>
      <bibkey>loveys-etal-2017-small</bibkey>
    </paper>
  </volume>
  <volume id="32">
    <meta>
      <booktitle>Proceedings of the First Workshop on Neural Machine Translation</booktitle>
      <url hash="1ca21456">W17-32</url>
      <editor><first>Thang</first><last>Luong</last></editor>
      <editor><first>Alexandra</first><last>Birch</last></editor>
      <editor><first>Graham</first><last>Neubig</last></editor>
      <editor><first>Andrew</first><last>Finch</last></editor>
      <doi>10.18653/v1/W17-32</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Vancouver</address>
      <month>August</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="7c17e941">W17-3200</url>
      <bibkey>ws-2017-neural</bibkey>
    </frontmatter>
    <paper id="1">
      <title>An Empirical Study of Adequate <a href="https://en.wikipedia.org/wiki/Vision_span">Vision Span</a> for Attention-Based Neural Machine Translation</title>
      <author><first>Raphael</first><last>Shu</last></author>
      <author><first>Hideki</first><last>Nakayama</last></author>
      <pages>1–10</pages>
      <url hash="dcef8c0a">W17-3201</url>
      <doi>10.18653/v1/W17-3201</doi>
      <abstract>Recently, the attention mechanism plays a key role to achieve high performance for Neural Machine Translation models. However, as it computes a <a href="https://en.wikipedia.org/wiki/Score_function">score function</a> for the encoder states in all positions at each decoding step, the attention model greatly increases the <a href="https://en.wikipedia.org/wiki/Computational_complexity_theory">computational complexity</a>. In this paper, we investigate the adequate vision span of attention models in the context of <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>, by proposing a novel attention framework that is capable of reducing redundant score computation dynamically. The term <a href="https://en.wikipedia.org/wiki/Vision_span">vision span</a>’ means a window of the encoder states considered by the attention model in one step. In our experiments, we found that the average window size of vision span can be reduced by over 50 % with modest loss in accuracy on English-Japanese and German-English translation tasks.</abstract>
      <bibkey>shu-nakayama-2017-empirical</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/aspec">ASPEC</pwcdataset>
    </paper>
    <paper id="2">
      <title>Analyzing Neural MT Search and Model Performance<fixed-case>MT</fixed-case> Search and Model Performance</title>
      <author><first>Jan</first><last>Niehues</last></author>
      <author><first>Eunah</first><last>Cho</last></author>
      <author><first>Thanh-Le</first><last>Ha</last></author>
      <author><first>Alex</first><last>Waibel</last></author>
      <pages>11–17</pages>
      <url hash="757e6e5d">W17-3202</url>
      <doi>10.18653/v1/W17-3202</doi>
      <abstract>In this paper, we offer an in-depth analysis about the modeling and search performance. We address the question if a more complex <a href="https://en.wikipedia.org/wiki/Search_algorithm">search algorithm</a> is necessary. Furthermore, we investigate the question if more complex <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> which might only be applicable during rescoring are promising. By separating the <a href="https://en.wikipedia.org/wiki/Feasible_region">search space</a> and the <a href="https://en.wikipedia.org/wiki/Mathematical_model">modeling</a> using n-best list reranking, we analyze the influence of both parts of an NMT system independently. By comparing differently performing NMT systems, we show that the better translation is already in the <a href="https://en.wikipedia.org/wiki/Feasible_region">search space</a> of the translation systems with less performance. This results indicate that the current <a href="https://en.wikipedia.org/wiki/Search_algorithm">search algorithms</a> are sufficient for the <a href="https://en.wikipedia.org/wiki/Network_topology">NMT systems</a>. Furthermore, we could show that even a relatively small n-best list of 50 hypotheses already contain notably better translations.<tex-math>n</tex-math>-best list of 50 hypotheses already contain notably better translations. </abstract>
      <bibkey>niehues-etal-2017-analyzing</bibkey>
    </paper>
    <paper id="3">
      <title>Stronger Baselines for Trustable Results in <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a></title>
      <author><first>Michael</first><last>Denkowski</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>18–27</pages>
      <url hash="c52b6e90">W17-3203</url>
      <doi>10.18653/v1/W17-3203</doi>
      <abstract>Interest in <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> has grown rapidly as its effectiveness has been demonstrated across language and data scenarios. New research regularly introduces architectural and algorithmic improvements that lead to significant gains over vanilla NMT implementations. However, these new <a href="https://en.wikipedia.org/wiki/Software_development_process">techniques</a> are rarely evaluated in the context of previously published <a href="https://en.wikipedia.org/wiki/Software_development_process">techniques</a>, specifically those that are widely used in state-of-the-art production and shared-task systems. As a result, it is often difficult to determine whether improvements from research will carry over to <a href="https://en.wikipedia.org/wiki/System">systems</a> deployed for real-world use. In this work, we recommend three specific <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> that are relatively easy to implement and result in much stronger experimental systems. Beyond reporting significantly higher BLEU scores, we conduct an in-depth analysis of where improvements originate and what inherent weaknesses of basic NMT models are being addressed. We then compare the relative gains afforded by several other techniques proposed in the literature when starting with vanilla systems versus our stronger baselines, showing that experimental conclusions may change depending on the baseline chosen. This indicates that choosing a strong <a href="https://en.wikipedia.org/wiki/Baseline_(medicine)">baseline</a> is crucial for reporting reliable experimental results.</abstract>
      <bibkey>denkowski-neubig-2017-stronger</bibkey>
    </paper>
    <paper id="5">
      <title>Cost Weighting for Neural Machine Translation Domain Adaptation</title>
      <author><first>Boxing</first><last>Chen</last></author>
      <author><first>Colin</first><last>Cherry</last></author>
      <author><first>George</first><last>Foster</last></author>
      <author><first>Samuel</first><last>Larkin</last></author>
      <pages>40–46</pages>
      <url hash="ca2717a7">W17-3205</url>
      <doi>10.18653/v1/W17-3205</doi>
      <abstract>In this paper, we propose a new domain adaptation technique for <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> called cost weighting, which is appropriate for adaptation scenarios in which a small in-domain data set and a large general-domain data set are available. Cost weighting incorporates a domain classifier into the neural machine translation training algorithm, using features derived from the encoder representation in order to distinguish in-domain from out-of-domain data. Classifier probabilities are used to weight sentences according to their domain similarity when updating the parameters of the neural translation model. We compare cost weighting to two traditional domain adaptation techniques developed for <a href="https://en.wikipedia.org/wiki/Statistical_machine_translation">statistical machine translation</a> : data selection and sub-corpus weighting. Experiments on two large-data tasks show that both the traditional techniques and our novel proposal lead to significant gains, with cost weighting outperforming the traditional methods.</abstract>
      <bibkey>chen-etal-2017-cost</bibkey>
    </paper>
    <paper id="6">
      <title>Detecting Untranslated Content for Neural Machine Translation</title>
      <author><first>Isao</first><last>Goto</last></author>
      <author><first>Hideki</first><last>Tanaka</last></author>
      <pages>47–55</pages>
      <url hash="4c229d40">W17-3206</url>
      <doi>10.18653/v1/W17-3206</doi>
      <abstract>Despite its promise, neural machine translation (NMT) has a serious problem in that source content may be mistakenly left untranslated. The ability to detect untranslated content is important for the practical use of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NMT</a>. We evaluate two types of <a href="https://en.wikipedia.org/wiki/Probability">probability</a> with which to detect untranslated content : the cumulative attention (ATN) probability and back translation (BT) probability from the target sentence to the source sentence. Experiments on detecting untranslated content in Japanese-English patent translations show that ATN and BT are each more effective than random choice, BT is more effective than ATN, and the combination of the two provides further improvements. We also confirmed the effectiveness of using <a href="https://en.wikipedia.org/wiki/Atrial_natriuretic_peptide">ATN</a> and <a href="https://en.wikipedia.org/wiki/Thiamine_triphosphate">BT</a> to rerank the n-best NMT outputs.</abstract>
      <bibkey>goto-tanaka-2017-detecting</bibkey>
    </paper>
    <paper id="7">
      <title>Beam Search Strategies for Neural Machine Translation</title>
      <author><first>Markus</first><last>Freitag</last></author>
      <author><first>Yaser</first><last>Al-Onaizan</last></author>
      <pages>56–60</pages>
      <url hash="49ffbe56">W17-3207</url>
      <doi>10.18653/v1/W17-3207</doi>
      <abstract>The basic concept in Neural Machine Translation (NMT) is to train a large Neural Network that maximizes the <a href="https://en.wikipedia.org/wiki/Translation">translation</a> performance on a given <a href="https://en.wikipedia.org/wiki/Parallel_text">parallel corpus</a>. NMT is then using a simple left-to-right beam-search decoder to generate new translations that approximately maximize the trained conditional probability. The current beam search strategy generates the target sentence word by word from left-to-right while keeping a fixed amount of active candidates at each time step. First, this simple <a href="https://en.wikipedia.org/wiki/Search_algorithm">search</a> is less adaptive as it also expands candidates whose scores are much worse than the current best. Secondly, it does not expand hypotheses if they are not within the best scoring candidates, even if their scores are close to the best one. The latter one can be avoided by increasing the <a href="https://en.wikipedia.org/wiki/Beam_diameter">beam size</a> until no performance improvement can be observed. While you can reach better performance, this has the drawback of a slower decoding speed. In this paper, we concentrate on speeding up the <a href="https://en.wikipedia.org/wiki/Codec">decoder</a> by applying a more flexible beam search strategy whose candidate size may vary at each time step depending on the candidate scores. We speed up the original decoder by up to 43 % for the two language pairs <a href="https://en.wikipedia.org/wiki/German_language">German</a> to <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a> to <a href="https://en.wikipedia.org/wiki/English_language">English</a> without losing any translation quality.</abstract>
      <bibkey>freitag-al-onaizan-2017-beam</bibkey>
    </paper>
    <paper id="9">
      <title>Detecting Cross-Lingual Semantic Divergence for Neural Machine Translation</title>
      <author><first>Marine</first><last>Carpuat</last></author>
      <author><first>Yogarshi</first><last>Vyas</last></author>
      <author><first>Xing</first><last>Niu</last></author>
      <pages>69–79</pages>
      <url hash="7222f763">W17-3209</url>
      <doi>10.18653/v1/W17-3209</doi>
      <abstract>Parallel corpora are often not as parallel as one might assume : non-literal translations and noisy translations abound, even in curated corpora routinely used for training and evaluation. We use a cross-lingual textual entailment system to distinguish sentence pairs that are parallel in meaning from those that are not, and show that filtering out divergent examples from training improves translation quality.</abstract>
      <bibkey>carpuat-etal-2017-detecting</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/opensubtitles">OpenSubtitles</pwcdataset>
    </paper>
  </volume>
  <volume id="34">
    <meta>
      <booktitle>Proceedings of the 15th Meeting on the Mathematics of Language</booktitle>
      <url hash="2fc75e0b">W17-34</url>
      <editor><first>Makoto</first><last>Kanazawa</last></editor>
      <editor><first>Philippe</first><last>de Groote</last></editor>
      <editor><first>Mehrnoosh</first><last>Sadrzadeh</last></editor>
      <doi>10.18653/v1/W17-34</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>London, UK</address>
      <month>July</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="158ea1eb">W17-3400</url>
      <bibkey>ws-2017-mathematics</bibkey>
    </frontmatter>
    </volume>
  <volume id="35">
    <meta>
      <booktitle>Proceedings of the 10th International Conference on Natural Language Generation</booktitle>
      <url hash="ec011b53">W17-35</url>
      <editor><first>Jose M.</first><last>Alonso</last></editor>
      <editor><first>Alberto</first><last>Bugarín</last></editor>
      <editor><first>Ehud</first><last>Reiter</last></editor>
      <doi>10.18653/v1/W17-35</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Santiago de Compostela, Spain</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="ef73cb1e">W17-3500</url>
      <bibkey>ws-2017-international-natural</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Linguistic realisation as <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> : Comparing different MT models for AMR-to-text generation<fixed-case>MT</fixed-case> models for <fixed-case>AMR</fixed-case>-to-text generation</title>
      <author><first>Thiago</first><last>Castro Ferreira</last></author>
      <author><first>Iacer</first><last>Calixto</last></author>
      <author><first>Sander</first><last>Wubben</last></author>
      <author><first>Emiel</first><last>Krahmer</last></author>
      <pages>1–10</pages>
      <url hash="6428598f">W17-3501</url>
      <doi>10.18653/v1/W17-3501</doi>
      <abstract>In this paper, we study AMR-to-text generation, framing it as a translation task and comparing two different MT approaches (Phrase-based and Neural MT). We systematically study the effects of 3 AMR preprocessing steps (Delexicalisation, <a href="https://en.wikipedia.org/wiki/Data_compression">Compression</a>, and Linearisation) applied before the MT phase. Our results show that <a href="https://en.wikipedia.org/wiki/Data_preprocessing">preprocessing</a> indeed helps, although the benefits differ for the two MT models.</abstract>
      <bibkey>castro-ferreira-etal-2017-linguistic</bibkey>
    </paper>
    <paper id="2">
      <title>A Survey on Intelligent Poetry Generation : <a href="https://en.wikipedia.org/wiki/Language">Languages</a>, Features, <a href="https://en.wikipedia.org/wiki/Technology">Techniques</a>, Reutilisation and Evaluation</title>
      <author><first>Hugo</first><last>Gonçalo Oliveira</last></author>
      <pages>11–20</pages>
      <url hash="0ff98da2">W17-3502</url>
      <doi>10.18653/v1/W17-3502</doi>
      <abstract>Poetry generation is becoming popular among researchers of <a href="https://en.wikipedia.org/wiki/Natural-language_generation">Natural Language Generation</a>, <a href="https://en.wikipedia.org/wiki/Computational_creativity">Computational Creativity</a> and, broadly, <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">Artificial Intelligence</a>. To produce text that may be regarded as <a href="https://en.wikipedia.org/wiki/Poetry">poetry</a>, <a href="https://en.wikipedia.org/wiki/Poetry">poetry generation systems</a> are typically knowledge-intensive and have to deal with several levels of language, from lexical to semantics. Interest on the topic resulted in the development of several <a href="https://en.wikipedia.org/wiki/Poetry_generator">poetry generators</a> described in the literature, with different features covered or handled differently, by a broad range of alternative approaches, as well as different perspectives on <a href="https://en.wikipedia.org/wiki/Evaluation">evaluation</a>, another challenging aspect due the underlying subjectivity. This paper surveys intelligent poetry generators around a set of relevant axis for poetry generation   targeted languages, form and content features, techniques, reutilisation of material, and evaluation   and aims to organise work developed on this topic so far.</abstract>
      <bibkey>goncalo-oliveira-2017-survey</bibkey>
    </paper>
    <paper id="4">
      <title>Content Selection for Real-time Sports News Construction from Commentary Texts</title>
      <author><first>Jin-ge</first><last>Yao</last></author>
      <author><first>Jianmin</first><last>Zhang</last></author>
      <author><first>Xiaojun</first><last>Wan</last></author>
      <author><first>Jianguo</first><last>Xiao</last></author>
      <pages>31–40</pages>
      <url hash="3ef24fba">W17-3504</url>
      <doi>10.18653/v1/W17-3504</doi>
      <abstract>We study the task of constructing sports news report automatically from <a href="https://en.wikipedia.org/wiki/Sports_commentator">live commentary</a> and focus on content selection. Rather than receiving every piece of text of a sports match before news construction, as in previous related work, we novelly verify the feasibility of a more challenging but more useful setting to generate news report on the fly by treating live text input as a stream. Specifically, we design various scoring functions to address different requirements of the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. The near submodularity of scoring functions makes it possible to adapt efficient <a href="https://en.wikipedia.org/wiki/Greedy_algorithm">greedy algorithms</a> even in stream data settings. Experiments suggest that our proposed framework can already produce comparable results compared with previous work that relies on a supervised learning-to-rank model with heavy feature engineering.</abstract>
      <bibkey>yao-etal-2017-content</bibkey>
    </paper>
    <paper id="5">
      <title>Improving the Naturalness and Expressivity of <a href="https://en.wikipedia.org/wiki/Language_generation">Language Generation</a> for Spanish<fixed-case>S</fixed-case>panish</title>
      <author><first>Cristina</first><last>Barros</last></author>
      <author><first>Dimitra</first><last>Gkatzia</last></author>
      <author><first>Elena</first><last>Lloret</last></author>
      <pages>41–50</pages>
      <url hash="f1e7825e">W17-3505</url>
      <doi>10.18653/v1/W17-3505</doi>
      <abstract>We present a flexible Natural Language Generation approach for <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, focused on the surface realisation stage, which integrates an inflection module in order to improve the naturalness and expressivity of the generated language. This inflection module inflects the verbs using an <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">ensemble of trainable algorithms</a> whereas the other types of words (e.g. nouns, <a href="https://en.wikipedia.org/wiki/Determiner">determiners</a>, etc) are inflected using hand-crafted rules. We show that our approach achieves 2 % higher <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> than two state-of-art inflection generation approaches. Furthermore, our proposed approach also predicts an extra feature : the inflection of the <a href="https://en.wikipedia.org/wiki/Imperative_mood">imperative mood</a>, which was not taken into account by previous work. We also present a user evaluation, where we demonstrate that the proposed method significantly improves the perceived naturalness of the generated language.</abstract>
      <bibkey>barros-etal-2017-improving</bibkey>
    </paper>
    <paper id="6">
      <title>What is the Role of Recurrent Neural Networks (RNNs) in an Image Caption Generator?<fixed-case>RNN</fixed-case>s) in an Image Caption Generator?</title>
      <author><first>Marc</first><last>Tanti</last></author>
      <author><first>Albert</first><last>Gatt</last></author>
      <author><first>Kenneth</first><last>Camilleri</last></author>
      <pages>51–60</pages>
      <url hash="b04c1bab">W17-3506</url>
      <doi>10.18653/v1/W17-3506</doi>
      <abstract>Image captioning has evolved into a core task for Natural Language Generation and has also proved to be an important testbed for deep learning approaches to handling multimodal representations. Most contemporary approaches rely on a combination of a convolutional network to handle image features, and a <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent network</a> to encode linguistic information. The latter is typically viewed as the primary generation component. Beyond this high-level characterisation, a CNN+RNN model supports a variety of architectural designs. The dominant model in the literature is one in which visual features encoded by a CNN are injected as part of the linguistic encoding process, driving the RNN’s linguistic choices. By contrast, it is possible to envisage an <a href="https://en.wikipedia.org/wiki/Architecture">architecture</a> in which visual and linguistic features are encoded separately, and merged at a subsequent stage. In this paper, we address two related questions : (1) Is direct injection the best way of combining multimodal information, or is a late merging alternative better for the image captioning task? (2) To what extent should a <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent network</a> be viewed as actually generating, rather than simply encoding, linguistic information?</abstract>
      <bibkey>tanti-etal-2017-role</bibkey>
      <pwccode url="https://github.com/mtanti/rnn-role" additional="true">mtanti/rnn-role</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/flickr30k">Flickr30k</pwcdataset>
    </paper>
    <paper id="7">
      <title>Exploring the Behavior of Classic REG Algorithms in the Description of Characters in 3D Images<fixed-case>REG</fixed-case> Algorithms in the Description of Characters in 3<fixed-case>D</fixed-case> Images</title>
      <author><first>Gonzalo</first><last>Méndez</last></author>
      <author><first>Raquel</first><last>Hervás</last></author>
      <author><first>Susana</first><last>Bautista</last></author>
      <author><first>Adrián</first><last>Rabadán</last></author>
      <author><first>Teresa</first><last>Rodríguez</last></author>
      <pages>61–69</pages>
      <url hash="c585d16b">W17-3507</url>
      <doi>10.18653/v1/W17-3507</doi>
      <abstract>Describing people and characters can be very useful in different contexts, such as computational narrative or image description for the visually impaired. However, a review of the existing literature shows that the automatic generation of people descriptions has not received much attention. Our work focuses on the description of people in snapshots from a <a href="https://en.wikipedia.org/wiki/3D_computer_graphics">3D environment</a>. First, we have conducted a survey to identify the way in which people describe other people under different conditions. We have used the information extracted from this survey to design several Referring Expression Generation algorithms which produce similar results. We have evaluated these <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> with users in order to identify which ones generate the best description for specific characters in different situations. The evaluation has shown that, in order to generate good descriptions, a combination of different <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> has to be used depending on the features and situation of the person to be described.</abstract>
      <bibkey>mendez-etal-2017-exploring</bibkey>
    </paper>
    <paper id="8">
      <title>Co-PoeTryMe : a Co-Creative Interface for the Composition of Poetry<fixed-case>P</fixed-case>oe<fixed-case>T</fixed-case>ry<fixed-case>M</fixed-case>e: a Co-Creative Interface for the Composition of Poetry</title>
      <author><first>Hugo</first><last>Gonçalo Oliveira</last></author>
      <author><first>Tiago</first><last>Mendes</last></author>
      <author><first>Ana</first><last>Boavida</last></author>
      <pages>70–71</pages>
      <url hash="f2bff3d8">W17-3508</url>
      <doi>10.18653/v1/W17-3508</doi>
      <abstract>Co-PoeTryMe is a web application for poetry composition, guided by the user, though with the help of automatic features, such as the generation of full (editable) drafts, as well as the acquisition of additional well-formed lines, or semantically-related words, possibly constrained by the number of syllables, <a href="https://en.wikipedia.org/wiki/Rhyme">rhyme</a>, or polarity. Towards the final poem, the latter can replace lines or words in the draft.</abstract>
      <bibkey>goncalo-oliveira-etal-2017-co</bibkey>
    </paper>
    <paper id="9">
      <title>Refer-iTTS : A System for Referring in Spoken Installments to Objects in Real-World Images<fixed-case>TTS</fixed-case>: A System for Referring in Spoken Installments to Objects in Real-World Images</title>
      <author><first>Sina</first><last>Zarrieß</last></author>
      <author><first>M. Soledad</first><last>López Gambino</last></author>
      <author><first>David</first><last>Schlangen</last></author>
      <pages>72–73</pages>
      <url hash="8e6392ba">W17-3509</url>
      <doi>10.18653/v1/W17-3509</doi>
      <abstract>Current referring expression generation systems mostly deliver their output as one-shot, written expressions. We present on-going work on incremental generation of spoken expressions referring to objects in real-world images. This approach extends upon previous work using the words-as-classifier model for generation. We implement this generator in an incremental dialogue processing framework such that we can exploit an existing interface to incremental text-to-speech synthesis. Our <a href="https://en.wikipedia.org/wiki/System">system</a> generates and synthesizes <a href="https://en.wikipedia.org/wiki/Reference">referring expressions</a> while continuously observing <a href="https://en.wikipedia.org/wiki/Nonverbal_communication">non-verbal user reactions</a>.</abstract>
      <bibkey>zarriess-etal-2017-refer</bibkey>
    </paper>
    <paper id="10">
      <title>Finding the right answers for customers</title>
      <author><first>Frank</first><last>Schilder</last></author>
      <pages>74</pages>
      <url hash="6042115b">W17-3510</url>
      <doi>10.18653/v1/W17-3510</doi>
      <abstract>This talk will present a few NLG systems developed within <a href="https://en.wikipedia.org/wiki/Thomson_Reuters">Thomson Reuters</a> providing information to professionals such as lawyers, accountants or traders. Based on the experience developing these system, I will discuss the usefulness of <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">automatic metrics</a>, <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowd-sourced evaluation</a>, corpora studies and expert reviews. I will conclude with exploring the question of whether developers of NLG systems need to follow ethical guidelines and how those guidelines could be established.</abstract>
      <bibkey>schilder-2017-finding</bibkey>
    </paper>
    <paper id="14">
      <title>Evaluation of a Runyankore grammar engine for healthcare messages<fixed-case>R</fixed-case>unyankore grammar engine for healthcare messages</title>
      <author><first>Joan</first><last>Byamugisha</last></author>
      <author><first>C. Maria</first><last>Keet</last></author>
      <author><first>Brian</first><last>DeRenzi</last></author>
      <pages>105–113</pages>
      <url hash="a297c746">W17-3514</url>
      <doi>10.18653/v1/W17-3514</doi>
      <abstract>Natural Language Generation (NLG) can be used to generate personalized health information, which is especially useful when provided in one’s own language. However, the NLG technique widely used in different domains and languagestemplateswas shown to be inapplicable to <a href="https://en.wikipedia.org/wiki/Bantu_languages">Bantu languages</a>, due to their characteristic agglutinative structure. We present here our use of the grammar engine NLG technique to generate text in <a href="https://en.wikipedia.org/wiki/Nkore_language">Runyankore</a>, a Bantu language indigenous to <a href="https://en.wikipedia.org/wiki/Uganda">Uganda</a>. Our grammar engine adds to previous work in this field with new rules for <a href="https://en.wikipedia.org/wiki/Cardinality">cardinality constraints</a>, prepositions in roles, the passive, and phonological conditioning. We evaluated the generated text with linguists and non-linguists, who regarded most text as grammatically correct and understandable ; and over 60 % of them regarded all the text generated by our system to have been authored by a human being.</abstract>
      <bibkey>byamugisha-etal-2017-evaluation</bibkey>
    </paper>
    <paper id="18">
      <title>The WebNLG Challenge : Generating Text from <a href="https://en.wikipedia.org/wiki/Resource_Description_Framework">RDF Data</a><fixed-case>W</fixed-case>eb<fixed-case>NLG</fixed-case> Challenge: Generating Text from <fixed-case>RDF</fixed-case> Data</title>
      <author><first>Claire</first><last>Gardent</last></author>
      <author><first>Anastasia</first><last>Shimorina</last></author>
      <author><first>Shashi</first><last>Narayan</last></author>
      <author><first>Laura</first><last>Perez-Beltrachini</last></author>
      <pages>124–133</pages>
      <url hash="84063568">W17-3518</url>
      <doi>10.18653/v1/W17-3518</doi>
      <abstract>The WebNLG challenge consists in mapping sets of <a href="https://en.wikipedia.org/wiki/Resource_Description_Framework">RDF triples</a> to text. It provides a common benchmark on which to train, evaluate and compare <a href="https://en.wikipedia.org/wiki/Microplanners">microplanners</a>, i.e. generation systems that verbalise a given content by making a range of complex interacting choices including referring expression generation, aggregation, <a href="https://en.wikipedia.org/wiki/Lexicalization">lexicalisation</a>, surface realisation and <a href="https://en.wikipedia.org/wiki/Sentence_segmentation">sentence segmentation</a>. In this paper, we introduce the microplanning task, describe data preparation, introduce our evaluation methodology, analyse participant results and provide a brief description of the participating systems.</abstract>
      <bibkey>gardent-etal-2017-webnlg</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/webnlg">WebNLG</pwcdataset>
    </paper>
    <paper id="20">
      <title>Integrated sentence generation using charts</title>
      <author><first>Alexander</first><last>Koller</last></author>
      <author><first>Nikos</first><last>Engonopoulos</last></author>
      <pages>139–143</pages>
      <url hash="113f3eff">W17-3520</url>
      <doi>10.18653/v1/W17-3520</doi>
      <abstract>Integrating surface realization and the generation of referring expressions into a single <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> can improve the quality of the generated sentences. Existing <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> for doing this, such as <a href="https://en.wikipedia.org/wiki/SPUD">SPUD</a> and CRISP, are search-based and can be slow or incomplete. We offer a chart-based algorithm for integrated sentence generation and demonstrate its runtime efficiency.</abstract>
      <bibkey>koller-engonopoulos-2017-integrated</bibkey>
    </paper>
    <paper id="21">
      <title>Adapting SimpleNLG to Spanish<fixed-case>S</fixed-case>imple<fixed-case>NLG</fixed-case> to <fixed-case>S</fixed-case>panish</title>
      <author><first>Alejandro</first><last>Ramos-Soto</last></author>
      <author><first>Julio</first><last>Janeiro-Gallardo</last></author>
      <author><first>Alberto</first><last>Bugarín Diz</last></author>
      <pages>144–148</pages>
      <url hash="82d739e9">W17-3521</url>
      <doi>10.18653/v1/W17-3521</doi>
      <abstract>We describe SimpleNLG-ES, an adaptation of the SimpleNLG realization library for the <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish language</a>. Our <a href="https://en.wikipedia.org/wiki/Implementation">implementation</a> is based on the bilingual English-French SimpleNLG-EnFr adaptation. The <a href="https://en.wikipedia.org/wiki/Library_(computing)">library</a> has been tested using a battery of examples that ensure that the most common <a href="https://en.wikipedia.org/wiki/Syntax">syntax</a>, <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphology</a> and orthography rules for <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a> are met. The <a href="https://en.wikipedia.org/wiki/Library_(computing)">library</a> is currently being used in three different projects for the development of data-to-text systems in the meteorological, statistical data information, and business intelligence application domains.</abstract>
      <bibkey>ramos-soto-etal-2017-adapting</bibkey>
    </paper>
    <paper id="22">
      <title>G-TUNA : a corpus of referring expressions in <a href="https://en.wikipedia.org/wiki/German_language">German</a>, including duration information<fixed-case>G</fixed-case>-<fixed-case>TUNA</fixed-case>: a corpus of referring expressions in <fixed-case>G</fixed-case>erman, including duration information</title>
      <author><first>David</first><last>Howcroft</last></author>
      <author><first>Jorrig</first><last>Vogels</last></author>
      <author><first>Vera</first><last>Demberg</last></author>
      <pages>149–153</pages>
      <url hash="2db28967">W17-3522</url>
      <doi>10.18653/v1/W17-3522</doi>
      <abstract>Corpora of referring expressions elicited from human participants in a controlled environment are an important resource for research on automatic referring expression generation. We here present G-TUNA, a new corpus of referring expressions for <a href="https://en.wikipedia.org/wiki/German_language">German</a>. Using the furniture stimuli set developed for the TUNA and D-TUNA corpora, our corpus extends on these <a href="https://en.wikipedia.org/wiki/Corpus_linguistics">corpora</a> by providing data collected in a simulated driving dual-task setting, and additionally provides exact duration annotations for the spoken referring expressions. This <a href="https://en.wikipedia.org/wiki/Speech_corpus">corpus</a> will hence allow researchers to analyze the interaction between referring expression length and speech rate, under conditions where the listener is under high vs. low cognitive load.</abstract>
      <bibkey>howcroft-etal-2017-g</bibkey>
    </paper>
    <paper id="23">
      <title>Toward an NLG System for <a href="https://en.wikipedia.org/wiki/Bantu_languages">Bantu languages</a> : first steps with Runyankore (demo)<fixed-case>NLG</fixed-case> System for <fixed-case>B</fixed-case>antu languages: first steps with <fixed-case>R</fixed-case>unyankore (demo)</title>
      <author><first>Joan</first><last>Byamugisha</last></author>
      <author><first>C. Maria</first><last>Keet</last></author>
      <author><first>Brian</first><last>DeRenzi</last></author>
      <pages>154–155</pages>
      <url hash="e1ce7ce6">W17-3523</url>
      <doi>10.18653/v1/W17-3523</doi>
      <abstract>There are many domain-specific and language-specific NLG systems, of which it may be possible to adapt to related domains and languages. The languages in the <a href="https://en.wikipedia.org/wiki/Bantu_languages">Bantu language family</a> have their own set of features distinct from other major groups, which therefore severely limits the options to bootstrap an NLG system from existing ones. We present here our first proof-of-concept application for knowledge-to-text NLG as a plugin to the <a href="https://en.wikipedia.org/wiki/Protege">Protege 5.x ontology development system</a>, tailored to <a href="https://en.wikipedia.org/wiki/Nkore_language">Runyankore</a>, a <a href="https://en.wikipedia.org/wiki/Bantu_languages">Bantu language</a> indigenous to Uganda. It comprises a basic annotation model for linguistic information such as <a href="https://en.wikipedia.org/wiki/Noun_class">noun class</a>, an implementation of existing verbalisation rules and a CFG for verbs, and a basic interface for <a href="https://en.wikipedia.org/wiki/Data_entry_clerk">data entry</a>.</abstract>
      <bibkey>byamugisha-etal-2017-toward</bibkey>
    </paper>
    <paper id="24">
      <title>A working, non-trivial, topically indifferent NLG System for 17 languages<fixed-case>NLG</fixed-case> System for 17 languages</title>
      <author><first>Robert</first><last>Weißgraeber</last></author>
      <author><first>Andreas</first><last>Madsack</last></author>
      <pages>156–157</pages>
      <url hash="2d716b15">W17-3524</url>
      <doi>10.18653/v1/W17-3524</doi>
      <abstract>A fully fledged practical working application for a rule-based NLG system is presented that is able to create non-trivial, human sounding narrative from structured data, in any language and for any topic.</abstract>
      <bibkey>weissgraeber-madsack-2017-working</bibkey>
    </paper>
    <paper id="25">
      <title>Generating titles for millions of browse pages on an e-Commerce site</title>
      <author><first>Prashant</first><last>Mathur</last></author>
      <author><first>Nicola</first><last>Ueffing</last></author>
      <author><first>Gregor</first><last>Leusch</last></author>
      <pages>158–167</pages>
      <url hash="8d20dfb4">W17-3525</url>
      <doi>10.18653/v1/W17-3525</doi>
      <abstract>We present two approaches to generate titles for browse pages in five different languages, namely <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/German_language">German</a>, <a href="https://en.wikipedia.org/wiki/French_language">French</a>, <a href="https://en.wikipedia.org/wiki/Italian_language">Italian</a> and <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>. These browse pages are structured search pages in an e-commerce domain. We first present a rule-based approach to generate these browse page titles. In addition, we also present a hybrid approach which uses a phrase-based statistical machine translation engine on top of the rule-based system to assemble the best title. For the two languages <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/German_language">German</a> we have access to a large amount of already available rule-based generated and curated titles. For these languages we present an automatic post-editing approach which learns how to post-edit the rule-based titles into curated titles.</abstract>
      <bibkey>mathur-etal-2017-generating</bibkey>
    </paper>
    <paper id="26">
      <title>Towards Automatic Generation of Product Reviews from Aspect-Sentiment Scores</title>
      <author><first>Hongyu</first><last>Zang</last></author>
      <author><first>Xiaojun</first><last>Wan</last></author>
      <pages>168–177</pages>
      <url hash="8fb78184">W17-3526</url>
      <doi>10.18653/v1/W17-3526</doi>
      <abstract>Data-to-text generation is very essential and important in machine writing applications. The recent <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning models</a>, like <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">Recurrent Neural Networks (RNNs)</a>, have shown a bright future for relevant text generation tasks. However, rare work has been done for automatic generation of long reviews from user opinions. In this paper, we introduce a <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural network model</a> to generate long Chinese reviews from aspect-sentiment scores representing users’ opinions. We conduct our study within the framework of encoder-decoder networks, and we propose a hierarchical structure with aligned attention in the Long-Short Term Memory (LSTM) decoder. Experiments show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms retrieval based baseline methods, and also beats the sequential generation models in qualitative evaluations.</abstract>
      <bibkey>zang-wan-2017-towards</bibkey>
    </paper>
    <paper id="27">
      <title>A model of suspense for narrative generation</title>
      <author><first>Richard</first><last>Doust</last></author>
      <author><first>Paul</first><last>Piwek</last></author>
      <pages>178–187</pages>
      <url hash="7149a40f">W17-3527</url>
      <doi>10.18653/v1/W17-3527</doi>
      <abstract>Most work on automatic generation of narratives, and more specifically <a href="https://en.wikipedia.org/wiki/Suspense">suspenseful narrative</a>, has focused on detailed domain-specific modelling of character psychology and <a href="https://en.wikipedia.org/wiki/Plot_(narrative)">plot structure</a>. Recent work in <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational linguistics</a> on the automatic learning of narrative schemas suggests an alternative approach that exploits such <a href="https://en.wikipedia.org/wiki/Schema_(psychology)">schemas</a> as a starting point for modelling and measuring <a href="https://en.wikipedia.org/wiki/Suspense">suspense</a>. We propose a domain-independent model for tracking <a href="https://en.wikipedia.org/wiki/Suspense">suspense</a> in a story which can be used to predict the audience’s suspense response on a sentence-by-sentence basis at the content determination stage of narrative generation. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> lends itself as the theoretical foundation for a <a href="https://en.wikipedia.org/wiki/Suspense">suspense module</a> that is compatible with alternative narrative generation theories. The <a href="https://en.wikipedia.org/wiki/Proposal_(business)">proposal</a> is evaluated by human judges’ normalised average scores correlate strongly with predicted values.</abstract>
      <bibkey>doust-piwek-2017-model</bibkey>
    </paper>
    <paper id="28">
      <title>Data-Driven News Generation for Automated Journalism</title>
      <author><first>Leo</first><last>Leppänen</last></author>
      <author><first>Myriam</first><last>Munezero</last></author>
      <author><first>Mark</first><last>Granroth-Wilding</last></author>
      <author><first>Hannu</first><last>Toivonen</last></author>
      <pages>188–197</pages>
      <url hash="d46eb900">W17-3528</url>
      <doi>10.18653/v1/W17-3528</doi>
      <abstract>Despite increasing amounts of data and ever improving <a href="https://en.wikipedia.org/wiki/Natural-language_generation">natural language generation techniques</a>, work on <a href="https://en.wikipedia.org/wiki/Automated_journalism">automated journalism</a> is still relatively scarce. In this paper, we explore the field and challenges associated with building a journalistic natural language generation system. We present a set of requirements that should guide system design, including <a href="https://en.wikipedia.org/wiki/Transparency_and_translucency">transparency</a>, <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>, modifiability and transferability. Guided by the requirements, we present a data-driven architecture for automated journalism that is largely domain and language independent. We illustrate its practical application in the production of <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a> about the 2017 Finnish municipal elections in three languages, demonstrating the successfulness of the data-driven, modular approach of the design. We then draw some lessons for future <a href="https://en.wikipedia.org/wiki/Automated_journalism">automated journalism</a>.</abstract>
      <bibkey>leppanen-etal-2017-data</bibkey>
    </paper>
    <paper id="29">
      <title>Data Augmentation for Visual Question Answering</title>
      <author><first>Kushal</first><last>Kafle</last></author>
      <author><first>Mohammed</first><last>Yousefhussien</last></author>
      <author><first>Christopher</first><last>Kanan</last></author>
      <pages>198–202</pages>
      <url hash="35e91de8">W17-3529</url>
      <doi>10.18653/v1/W17-3529</doi>
      <abstract>Data augmentation is widely used to train <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural networks</a> for image classification tasks. Simply flipping images can help learning tremendously by increasing the number of training images by a factor of two. However, little work has been done studying <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a> in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. Here, we describe two methods for <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a> for Visual Question Answering (VQA). The <a href="https://en.wikipedia.org/wiki/First_Amendment_to_the_United_States_Constitution">first</a> uses existing <a href="https://en.wikipedia.org/wiki/Semantic_annotation">semantic annotations</a> to generate new questions. The second method is a generative approach using <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural networks</a>. Experiments show that the proposed <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a> improves performance of both <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a> and state-of-the-art VQA algorithms.</abstract>
      <bibkey>kafle-etal-2017-data</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/coco-qa">COCO-QA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/vqg">VQG</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-question-answering">Visual Question Answering</pwcdataset>
    </paper>
    <paper id="31">
      <title>A Comparison of Neural Models for Word Ordering</title>
      <author><first>Eva</first><last>Hasler</last></author>
      <author><first>Felix</first><last>Stahlberg</last></author>
      <author><first>Marcus</first><last>Tomalin</last></author>
      <author><first>Adrià</first><last>de Gispert</last></author>
      <author><first>Bill</first><last>Byrne</last></author>
      <pages>208–212</pages>
      <url hash="fbc9e207">W17-3531</url>
      <doi>10.18653/v1/W17-3531</doi>
      <abstract>We compare several language models for the word-ordering task and propose a new bag-to-sequence neural model based on attention-based sequence-to-sequence models. We evaluate the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> on a large German WMT data set where it significantly outperforms existing <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>. We also describe a novel search strategy for LM-based word ordering and report results on the English Penn Treebank. Our best model setup outperforms prior work both in terms of speed and quality.</abstract>
      <bibkey>hasler-etal-2017-comparison</bibkey>
      <pwccode url="https://github.com/ehasler/tensorflow" additional="false">ehasler/tensorflow</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="32">
      <title>Investigating the content and form of referring expressions in <a href="https://en.wikipedia.org/wiki/Mandarin_Chinese">Mandarin</a> : introducing the Mtuna corpus<fixed-case>M</fixed-case>andarin: introducing the Mtuna corpus</title>
      <author><first>Kees</first><last>van Deemter</last></author>
      <author><first>Le</first><last>Sun</last></author>
      <author><first>Rint</first><last>Sybesma</last></author>
      <author><first>Xiao</first><last>Li</last></author>
      <author><first>Bo</first><last>Chen</last></author>
      <author><first>Muyun</first><last>Yang</last></author>
      <pages>213–217</pages>
      <url hash="9b2049f1">W17-3532</url>
      <doi>10.18653/v1/W17-3532</doi>
      <abstract>East Asian languages are thought to handle reference differently from <a href="https://en.wikipedia.org/wiki/Language">languages</a> such as <a href="https://en.wikipedia.org/wiki/English_language">English</a>, particularly in terms of the marking of definiteness and <a href="https://en.wikipedia.org/wiki/Grammatical_number">number</a>. We present the first Data-Text corpus for Referring Expressions in <a href="https://en.wikipedia.org/wiki/Mandarin_Chinese">Mandarin</a>, and we use this <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> to test some initial hypotheses inspired by the theoretical linguistics literature. Our findings suggest that function words deserve more attention in Referring Expressions Generation than they have so far received, and they have a bearing on the debate about whether different languages make different trade-offs between clarity and brevity.</abstract>
      <bibkey>van-deemter-etal-2017-investigating</bibkey>
    </paper>
    <paper id="33">
      <title>Realization of long sentences using chunking</title>
      <author><first>Ewa</first><last>Muszyńska</last></author>
      <author><first>Ann</first><last>Copestake</last></author>
      <pages>218–222</pages>
      <url hash="311e9455">W17-3533</url>
      <doi>10.18653/v1/W17-3533</doi>
      <abstract>We propose sentence chunking as a way to reduce the time and memory costs of realization of long sentences. During chunking we divide the semantic representation of a sentence into smaller components which can be processed and recombined without loss of information. Our meaning representation of choice is the Dependency Minimal Recursion Semantics (DMRS). We show that realizing chunks of a sentence and combining the results of such realizations increases the coverage for long sentences, significantly reduces the resources required and does not affect the quality of the realization.</abstract>
      <bibkey>muszynska-copestake-2017-realization</bibkey>
    </paper>
    <paper id="34">
      <title>SaToS : Assessing and Summarising Terms of Services from German Webshops<fixed-case>S</fixed-case>a<fixed-case>T</fixed-case>o<fixed-case>S</fixed-case>: Assessing and Summarising Terms of Services from <fixed-case>G</fixed-case>erman Webshops</title>
      <author><first>Daniel</first><last>Braun</last></author>
      <author><first>Elena</first><last>Scepankova</last></author>
      <author><first>Patrick</first><last>Holl</last></author>
      <author><first>Florian</first><last>Matthes</last></author>
      <pages>223–227</pages>
      <url hash="71661b23">W17-3534</url>
      <doi>10.18653/v1/W17-3534</doi>
      <abstract>Every time we buy something online, we are confronted with <a href="https://en.wikipedia.org/wiki/Terms_of_service">Terms of Services</a>. However, only a few people actually read these terms, before accepting them, often to their disadvantage. In this paper, we present the SaToS browser plugin which summarises and simplifies <a href="https://en.wikipedia.org/wiki/Terms_of_service">Terms of Services</a> from German webshops.</abstract>
      <bibkey>braun-etal-2017-satos</bibkey>
    </paper>
    <paper id="35">
      <title>Textually Summarising Incomplete Data</title>
      <author><first>Stephanie</first><last>Inglis</last></author>
      <author><first>Ehud</first><last>Reiter</last></author>
      <author><first>Somayajulu</first><last>Sripada</last></author>
      <pages>228–232</pages>
      <url hash="9b9069f1">W17-3535</url>
      <doi>10.18653/v1/W17-3535</doi>
      <abstract>Many data-to-text NLG systems work with data sets which are incomplete, ie some of the data is missing. We have worked with data journalists to understand how they describe incomplete data, and are building NLG algorithms based on these insights. A pilot evaluation showed mixed results, and highlighted several areas where we need to improve our <a href="https://en.wikipedia.org/wiki/System">system</a>.</abstract>
      <bibkey>inglis-etal-2017-textually</bibkey>
    </paper>
    <paper id="37">
      <title>Analysing Data-To-Text Generation Benchmarks</title>
      <author><first>Laura</first><last>Perez-Beltrachini</last></author>
      <author><first>Claire</first><last>Gardent</last></author>
      <pages>238–242</pages>
      <url hash="ed818668">W17-3537</url>
      <doi>10.18653/v1/W17-3537</doi>
      <abstract>A generation system can only be as good as the data it is trained on. In this short paper, we propose a <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> for analysing data-to-text corpora used for training Natural Language Generation (NLG) systems. We apply this <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> to three existing <a href="https://en.wikipedia.org/wiki/Benchmark_(computing)">benchmarks</a>. We conclude by eliciting a set of criteria for the creation of a data-to-text benchmark which could help better support the development, evaluation and comparison of linguistically sophisticated data-to-text generators.</abstract>
      <bibkey>perez-beltrachini-gardent-2017-analysing</bibkey>
    </paper>
    <paper id="38">
      <title>Linguistic Description of Complex Phenomena with the rLDCP R Package<fixed-case>LDCP</fixed-case> <fixed-case>R</fixed-case> Package</title>
      <author><first>Jose</first><last>Alonso</last></author>
      <author><first>Patricia</first><last>Conde-Clemente</last></author>
      <author><first>Gracian</first><last>Trivino</last></author>
      <pages>243–244</pages>
      <url hash="8558217d">W17-3538</url>
      <doi>10.18653/v1/W17-3538</doi>
      <abstract>Monitoring and analysis of complex phenomena attract the attention of both academy and industry. Dealing with data produced by <a href="https://en.wikipedia.org/wiki/Complex_system">complex phenomena</a> requires the use of advance <a href="https://en.wikipedia.org/wiki/Computational_intelligence">computational intelligence techniques</a>. Namely, linguistic description of complex phenomena constitutes a mature research line. It is supported by the Computational Theory of Perceptions grounded on the <a href="https://en.wikipedia.org/wiki/Fuzzy_set">Fuzzy Sets Theory</a>. Its aim is the development of computational systems with the ability to generate vague descriptions of the world in a similar way how humans do. This is a human-centric and multi-disciplinary research work. Moreover, its success is a matter of careful design ; thus, developers play a key role. The rLDCP R package was designed to facilitate the development of new applications. This demo introduces the use of rLDCP, for both beginners and advance developers, in practical use cases.</abstract>
      <bibkey>alonso-etal-2017-linguistic</bibkey>
    </paper>
    <paper id="39">
      <title>A demo of FORGe : the Pompeu Fabra Open Rule-based Generator<fixed-case>FORG</fixed-case>e: the <fixed-case>P</fixed-case>ompeu <fixed-case>F</fixed-case>abra Open Rule-based Generator</title>
      <author><first>Simon</first><last>Mille</last></author>
      <author><first>Leo</first><last>Wanner</last></author>
      <pages>245–246</pages>
      <url hash="59ea9e8a">W17-3539</url>
      <doi>10.18653/v1/W17-3539</doi>
      <abstract>This demo paper presents the multilingual deep sentence generator developed by the TALN group at Universitat Pompeu Fabra, implemented as a series of rule-based graph-transducers for the syntacticization of the input graphs, the resolution of morphological agreements, and the linearization of the trees.</abstract>
      <bibkey>mille-wanner-2017-demo</bibkey>
    </paper>
    <paper id="40">
      <title>Referential Success of Set Referring Expressions with Fuzzy Properties</title>
      <author><first>Nicolás</first><last>Marín</last></author>
      <author><first>Gustavo</first><last>Rivas-Gervilla</last></author>
      <author><first>Daniel</first><last>Sánchez</last></author>
      <pages>247–251</pages>
      <url hash="001da225">W17-3540</url>
      <doi>10.18653/v1/W17-3540</doi>
      <abstract>We introduce the <a href="https://en.wikipedia.org/wiki/Property_(philosophy)">properties</a> to be satisfied by measures of referential success of set referring expressions with fuzzy properties. We define families of measures on the basis of n-cardinality measures and we illustrate some of them with a toy example.</abstract>
      <bibkey>marin-etal-2017-referential</bibkey>
    </paper>
    <paper id="41">
      <title>Neural Response Generation for <a href="https://en.wikipedia.org/wiki/Customer_service">Customer Service</a> based on Personality Traits</title>
      <author><first>Jonathan</first><last>Herzig</last></author>
      <author><first>Michal</first><last>Shmueli-Scheuer</last></author>
      <author><first>Tommy</first><last>Sandbank</last></author>
      <author><first>David</first><last>Konopnicki</last></author>
      <pages>252–256</pages>
      <url hash="3b8606ec">W17-3541</url>
      <doi>10.18653/v1/W17-3541</doi>
      <abstract>We present a neural response generation model that generates responses conditioned on a target personality. The <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> learns high level features based on the target personality, and uses them to update its hidden state. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves performance improvements in both perplexity and BLEU scores over a baseline sequence-to-sequence model, and is validated by human judges.</abstract>
      <bibkey>herzig-etal-2017-neural</bibkey>
    </paper>
    <paper id="42">
      <title>Neural Paraphrase Generation using <a href="https://en.wikipedia.org/wiki/Transfer_learning">Transfer Learning</a></title>
      <author><first>Florin</first><last>Brad</last></author>
      <author><first>Traian</first><last>Rebedea</last></author>
      <pages>257–261</pages>
      <url hash="590fdf91">W17-3542</url>
      <doi>10.18653/v1/W17-3542</doi>
      <abstract>Progress in statistical paraphrase generation has been hindered for a long time by the lack of large monolingual parallel corpora. In this paper, we adapt the neural machine translation approach to <a href="https://en.wikipedia.org/wiki/Paraphrase_generation">paraphrase generation</a> and perform <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> from the closely related task of <a href="https://en.wikipedia.org/wiki/Logical_consequence">entailment generation</a>. We evaluate the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> on the Microsoft Research Paraphrase (MSRP) corpus and show that the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is able to generate sentences that capture part of the original meaning, but fails to pick up on important words or to show large lexical variation.</abstract>
      <bibkey>brad-rebedea-2017-neural</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
  </volume>
  <volume id="36">
    <meta>
      <booktitle>Proceedings of the 6th Workshop on Recent Advances in <fixed-case>RST</fixed-case> and Related Formalisms</booktitle>
      <url hash="ee4760da">W17-36</url>
      <editor id="maite-taboada"><first>M.</first><last>Taboada</last></editor>
      <editor id="iria-da-cunha"><first>I.</first><last>da Cunha</last></editor>
      <editor><first>E.G.</first><last>Maziero</last></editor>
      <editor id="paula-cardoso"><first>P.</first><last>Cardoso</last></editor>
      <editor id="juliano-d-antonio"><first>J.D.</first><last>Antonio</last></editor>
      <editor id="mikel-iruskieta"><first>M.</first><last>Iruskieta</last></editor>
      <doi>10.18653/v1/W17-36</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Santiago de Compostela, Spain</address>
      <month>September</month>
      <year>2017</year>
      <isbn>978-1-945626-78-4</isbn>
    </meta>
    <frontmatter>
      <url hash="24ea456f">W17-3600</url>
      <bibkey>ws-2017-recent</bibkey>
    </frontmatter>
    </volume>
  <volume id="37">
    <meta>
      <booktitle>Proceedings of the 1st Workshop on Explainable Computational Intelligence (<fixed-case>XCI</fixed-case> 2017)</booktitle>
      <url hash="ece48fe1">W17-37</url>
      <editor id="martin-pereira-farina"><first>M.</first><last>Pereira-Fariña</last></editor>
      <editor id="chris-reed"><first>C.</first><last>Reed</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Dundee, United Kingdom</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="23d4b946">W17-3700</url>
      <doi>10.18653/v1/W37-1</doi>
      <bibkey>ws-2017-explainable</bibkey>
    </frontmatter>
    </volume>
  <volume id="38">
    <meta>
      <booktitle>Proceedings of the Linguistic Resources for Automatic Natural Language Generation - <fixed-case>L</fixed-case>i<fixed-case>RA</fixed-case>@<fixed-case>NLG</fixed-case></booktitle>
      <url hash="e5ee7c07">W17-38</url>
      <editor><first>Kristina</first><last>Kocijan</last></editor>
      <editor><first>Peter</first><last>Machonis</last></editor>
      <editor><first>Max</first><last>Silberztein</last></editor>
      <doi>10.18653/v1/W17-38</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Santiago de Compostela, Spain</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="6d6b5918">W17-3800</url>
      <bibkey>ws-2017-linguistic-resources</bibkey>
    </frontmatter>
    </volume>
  <volume id="39">
    <meta>
      <booktitle>Proceedings of the Workshop on Computational Creativity in Natural Language Generation (<fixed-case>CC</fixed-case>-<fixed-case>NLG</fixed-case> 2017)</booktitle>
      <url hash="d4d9196b">W17-39</url>
      <editor><first>Hugo</first><last>Gonçalo Oliveira</last></editor>
      <editor><first>Ben</first><last>Burtenshaw</last></editor>
      <editor><first>Mike</first><last>Kestemont</last></editor>
      <editor><first>Tom</first><last>De Smedt</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Santiago de Compostela, Spain</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="2d8d7afe">W17-3900</url>
      <doi>10.18653/v1/W17-3900</doi>
      <bibkey>ws-2017-creativity</bibkey>
    </frontmatter>
    </volume>
  <volume id="40">
    <meta>
      <booktitle>Proceedings of the 13th International Conference on Finite State Methods and Natural Language Processing (<fixed-case>FSMNLP</fixed-case> 2017)</booktitle>
      <editor><first>Frank</first><last>Drewes</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Umeå, Sweden</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="e80afec2">W17-4000</url>
      <doi>10.18653/v1/W17-4000</doi>
      <bibkey>ws-2017-international-finite</bibkey>
    </frontmatter>
    </volume>
  <volume id="41">
    <meta>
      <booktitle>Proceedings of the First Workshop on Subword and Character Level Models in <fixed-case>NLP</fixed-case></booktitle>
      <url hash="946b862f">W17-41</url>
      <editor><first>Manaal</first><last>Faruqui</last></editor>
      <editor><first>Hinrich</first><last>Schuetze</last></editor>
      <editor><first>Isabel</first><last>Trancoso</last></editor>
      <editor><first>Yadollah</first><last>Yaghoobzadeh</last></editor>
      <doi>10.18653/v1/W17-41</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Copenhagen, Denmark</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="6d8bd577">W17-4100</url>
      <bibkey>ws-2017-subword</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Character and Subword-Based Word Representation for Neural Language Modeling Prediction</title>
      <author><first>Matthieu</first><last>Labeau</last></author>
      <author><first>Alexandre</first><last>Allauzen</last></author>
      <pages>1–13</pages>
      <url hash="e802ba24">W17-4101</url>
      <doi>10.18653/v1/W17-4101</doi>
      <abstract>Most of neural language models use different kinds of <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> for <a href="https://en.wikipedia.org/wiki/Word_prediction">word prediction</a>. While <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> can be associated to each word in the vocabulary or derived from <a href="https://en.wikipedia.org/wiki/Character_(computing)">characters</a> as well as factored morphological decomposition, these word representations are mainly used to parametrize the input, i.e. the context of prediction. This work investigates the effect of using subword units (character and factored morphological decomposition) to build output representations for neural language modeling. We present a case study on <a href="https://en.wikipedia.org/wiki/Czech_language">Czech</a>, a morphologically-rich language, experimenting with different input and output representations. When working with the full training vocabulary, despite unstable training, our experiments show that augmenting the output word representations with character-based embeddings can significantly improve the performance of the model. Moreover, reducing the size of the output look-up table, to let the character-based embeddings represent rare words, brings further improvement.</abstract>
      <bibkey>labeau-allauzen-2017-character</bibkey>
    </paper>
    <paper id="2">
      <title>Learning variable length units for SMT between related languages via Byte Pair Encoding<fixed-case>SMT</fixed-case> between related languages via Byte Pair Encoding</title>
      <author><first>Anoop</first><last>Kunchukuttan</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>14–24</pages>
      <url hash="00c7b375">W17-4102</url>
      <doi>10.18653/v1/W17-4102</doi>
      <abstract>We explore the use of <a href="https://en.wikipedia.org/wiki/Segment_(linguistics)">segments</a> learnt using Byte Pair Encoding (referred to as BPE units) as basic units for <a href="https://en.wikipedia.org/wiki/Statistical_machine_translation">statistical machine translation</a> between related languages and compare it with orthographic syllables, which are currently the best performing basic units for this translation task. BPE identifies the most frequent character sequences as basic units, while orthographic syllables are linguistically motivated pseudo-syllables. We show that BPE units modestly outperform orthographic syllables as units of translation, showing up to 11 % increase in BLEU score. While orthographic syllables can be used only for languages whose <a href="https://en.wikipedia.org/wiki/Writing_system">writing systems</a> use vowel representations, BPE is writing system independent and we show that BPE outperforms other units for non-vowel writing systems too. Our results are supported by extensive experimentation spanning multiple language families and <a href="https://en.wikipedia.org/wiki/Writing_system">writing systems</a>.</abstract>
      <bibkey>kunchukuttan-bhattacharyya-2017-learning</bibkey>
    </paper>
    <paper id="3">
      <title>Character Based Pattern Mining for Neology Detection</title>
      <author><first>Gaël</first><last>Lejeune</last></author>
      <author><first>Emmanuel</first><last>Cartier</last></author>
      <pages>25–30</pages>
      <url hash="90918ebb">W17-4103</url>
      <doi>10.18653/v1/W17-4103</doi>
      <abstract>Detecting neologisms is essential in real-time natural language processing applications. Not only can it enable to follow the lexical evolution of languages, but it is also essential for updating linguistic resources and <a href="https://en.wikipedia.org/wiki/Parsing">parsers</a>. In this paper, neology detection is considered as a classification task where a system has to assess whether a given lexical item is an actual <a href="https://en.wikipedia.org/wiki/Neologism">neologism</a> or not. We propose a combination of an unsupervised data mining technique and a supervised machine learning approach. It is inspired by current researches in <a href="https://en.wikipedia.org/wiki/Stylometry">stylometry</a> and on token-level and character-level patterns. We train and evaluate our system on a manually designed reference dataset in <a href="https://en.wikipedia.org/wiki/French_language">French</a> and <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a>. We show that this approach is able to largely outperform state-of-the-art neology detection systems. Furthermore, character-level patterns exhibit good properties for multilingual extensions of the <a href="https://en.wikipedia.org/wiki/System">system</a>.</abstract>
      <bibkey>lejeune-cartier-2017-character</bibkey>
    </paper>
    <paper id="4">
      <title>Automated Word Stress Detection in Russian<fixed-case>R</fixed-case>ussian</title>
      <author><first>Maria</first><last>Ponomareva</last></author>
      <author><first>Kirill</first><last>Milintsevich</last></author>
      <author><first>Ekaterina</first><last>Chernyak</last></author>
      <author><first>Anatoly</first><last>Starostin</last></author>
      <pages>31–35</pages>
      <url hash="b72aa8ea">W17-4104</url>
      <doi>10.18653/v1/W17-4104</doi>
      <abstract>In this study we address the problem of automated word stress detection in <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a> using character level models and no part-speech-taggers. We use a simple bidirectional RNN with LSTM nodes and achieve <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 90 % or higher. We experiment with two training datasets and show that using the data from an annotated corpus is much more efficient than using only a <a href="https://en.wikipedia.org/wiki/Dictionary">dictionary</a>, since it allows to retain the context of the word and its <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological features</a>.</abstract>
      <bibkey>ponomareva-etal-2017-automated</bibkey>
    </paper>
    <paper id="5">
      <title>A Syllable-based Technique for Word Embeddings of Korean Words<fixed-case>K</fixed-case>orean Words</title>
      <author><first>Sanghyuk</first><last>Choi</last></author>
      <author><first>Taeuk</first><last>Kim</last></author>
      <author><first>Jinseok</first><last>Seol</last></author>
      <author><first>Sang-goo</first><last>Lee</last></author>
      <pages>36–40</pages>
      <url hash="bb4093bf">W17-4105</url>
      <doi>10.18653/v1/W17-4105</doi>
      <abstract>Word embedding has become a fundamental component to many NLP tasks such as <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a> and <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>. However, popular <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> that learn such embeddings are unaware of the <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphology of words</a>, so it is not directly applicable to highly <a href="https://en.wikipedia.org/wiki/Agglutinative_language">agglutinative languages</a> such as <a href="https://en.wikipedia.org/wiki/Korean_language">Korean</a>. We propose a syllable-based learning model for <a href="https://en.wikipedia.org/wiki/Korean_language">Korean</a> using a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a>, in which word representation is composed of trained syllable vectors. Our <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> successfully produces morphologically meaningful representation of Korean words compared to the original Skip-gram embeddings. The results also show that it is quite robust to the Out-of-Vocabulary problem.</abstract>
      <bibkey>choi-etal-2017-syllable</bibkey>
    </paper>
    <paper id="6">
      <title>Supersense Tagging with a Combination of Character, Subword, and Word-level Representations</title>
      <author><first>Youhyun</first><last>Shin</last></author>
      <author><first>Sang-goo</first><last>Lee</last></author>
      <pages>41–45</pages>
      <url hash="98cee1c8">W17-4106</url>
      <doi>10.18653/v1/W17-4106</doi>
      <abstract>Recently, there has been increased interest in utilizing <a href="https://en.wikipedia.org/wiki/Character_(symbol)">characters or subwords</a> for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing (NLP) tasks</a>. However, the effect of utilizing <a href="https://en.wikipedia.org/wiki/Character_(symbol)">character</a>, subword, and word-level information simultaneously has not been examined so far. In this paper, we propose a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> to leverage various levels of <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">input features</a> to improve on the performance of an supersense tagging task. Detailed analysis of experimental results show that different levels of input representation offer distinct characteristics that explain performance discrepancy among different tasks.</abstract>
      <bibkey>shin-lee-2017-supersense</bibkey>
    </paper>
    <paper id="7">
      <title>Weakly supervised learning of allomorphy</title>
      <author><first>Miikka</first><last>Silfverberg</last></author>
      <author><first>Mans</first><last>Hulden</last></author>
      <pages>46–56</pages>
      <url hash="70823639">W17-4107</url>
      <doi>10.18653/v1/W17-4107</doi>
      <abstract>Most NLP resources that offer annotations at the word segment level provide morphological annotation that includes features indicating tense, <a href="https://en.wikipedia.org/wiki/Grammatical_aspect">aspect</a>, <a href="https://en.wikipedia.org/wiki/Linguistic_modality">modality</a>, <a href="https://en.wikipedia.org/wiki/Grammatical_gender">gender</a>, <a href="https://en.wikipedia.org/wiki/Grammatical_case">case</a>, and other inflectional information. Such <a href="https://en.wikipedia.org/wiki/Information">information</a> is rarely aligned to the relevant parts of the wordsi.e. the <a href="https://en.wikipedia.org/wiki/Allomorphism">allomorphs</a>, as such <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a> would be very costly. These unaligned weak labelings are commonly provided by annotated NLP corpora such as <a href="https://en.wikipedia.org/wiki/Treebank">treebanks</a> in various languages. Although they lack alignment information, the presence / absence of labels at the word level is also consistent with the amount of <a href="https://en.wikipedia.org/wiki/Supervisor">supervision</a> assumed to be provided to L1 and L2 learners. In this paper, we explore several methods to learn this latent alignment between parts of word forms and the <a href="https://en.wikipedia.org/wiki/Grammaticality">grammatical information</a> provided. All the <a href="https://en.wikipedia.org/wiki/Linguistic_description">methods</a> under investigation favor hypotheses regarding allomorphs of morphemes that re-use a small inventory, i.e. implicitly minimize the number of <a href="https://en.wikipedia.org/wiki/Allomorphism">allomorphs</a> that a <a href="https://en.wikipedia.org/wiki/Morpheme">morpheme</a> can be realized as. We show that the provided <a href="https://en.wikipedia.org/wiki/Information">information</a> offers a significant advantage for both <a href="https://en.wikipedia.org/wiki/Word_segmentation">word segmentation</a> and the learning of allomorphy.</abstract>
      <bibkey>silfverberg-hulden-2017-weakly</bibkey>
    </paper>
    <paper id="8">
      <title>Character-based recurrent neural networks for morphological relational reasoning</title>
      <author><first>Olof</first><last>Mogren</last></author>
      <author><first>Richard</first><last>Johansson</last></author>
      <pages>57–63</pages>
      <url hash="f4a8a472">W17-4108</url>
      <doi>10.18653/v1/W17-4108</doi>
      <abstract>We present a <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> for predicting word forms based on morphological relational reasoning with <a href="https://en.wikipedia.org/wiki/Analogy">analogies</a>. While previous work has explored tasks such as <a href="https://en.wikipedia.org/wiki/Inflection">morphological inflection</a> and reinflection, these models rely on an explicit enumeration of morphological features, which may not be available in all cases. To address the task of predicting a word form given a demo relation (a pair of word forms) and a query word, we devise a character-based recurrent neural network architecture using three separate encoders and a decoder. We also investigate a multiclass learning setup, where the prediction of the relation type label is used as an auxiliary task. Our results show that the exact form can be predicted for <a href="https://en.wikipedia.org/wiki/English_language">English</a> with an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 94.7 %. For <a href="https://en.wikipedia.org/wiki/Swedish_language">Swedish</a>, which has a more complex morphology with more <a href="https://en.wikipedia.org/wiki/Inflection">inflectional patterns</a> for <a href="https://en.wikipedia.org/wiki/Noun">nouns</a> and <a href="https://en.wikipedia.org/wiki/Verb">verbs</a>, the accuracy is 89.3 %. We also show that using the auxiliary task of learning the relation type speeds up convergence and improves the prediction accuracy for the word generation task.<i>morphological relational reasoning</i> with analogies. While previous work has explored
      tasks such as morphological inflection and reinflection, these models rely
      on an explicit enumeration of morphological features, which may not be
      available in all cases. To address the task of predicting a word form
      given a <i>demo relation</i> (a pair of word forms) and a <i>query word</i>, we devise a
      character-based recurrent neural network architecture using three separate
      encoders and a decoder. We also investigate a multiclass learning setup,
      where the prediction of the relation type label is used as an auxiliary
      task. Our results show that the exact form can be predicted for English
      with an accuracy of 94.7%. For Swedish, which has a more complex
      morphology with more inflectional patterns for nouns and verbs, the
      accuracy is 89.3%. We also show that using the auxiliary task of learning
      the relation type speeds up convergence and improves the prediction
      accuracy for the word generation task.
    </abstract>
      <bibkey>mogren-johansson-2017-character</bibkey>
    </paper>
    <paper id="10">
      <title>Exploring Cross-Lingual Transfer of Morphological Knowledge In Sequence-to-Sequence Models</title>
      <author><first>Huiming</first><last>Jin</last></author>
      <author><first>Katharina</first><last>Kann</last></author>
      <pages>70–75</pages>
      <url hash="e0660689">W17-4110</url>
      <doi>10.18653/v1/W17-4110</doi>
      <abstract>Multi-task training is an effective method to mitigate the data sparsity problem. It has recently been applied for cross-lingual transfer learning for paradigm completionthe task of producing inflected forms of lemmatawith sequence-to-sequence networks. However, it is still vague how the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> transfers knowledge across languages, as well as if and which information is shared. To investigate this, we propose a set of data-dependent experiments using an existing encoder-decoder recurrent neural network for the task. Our results show that indeed the performance gains surpass a pure regularization effect and that knowledge about <a href="https://en.wikipedia.org/wiki/Language">language</a> and <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphology</a> can be transferred.</abstract>
      <bibkey>jin-kann-2017-exploring</bibkey>
    </paper>
    <paper id="11">
      <title>Unlabeled Data for Morphological Generation With Character-Based Sequence-to-Sequence Models</title>
      <author><first>Katharina</first><last>Kann</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>76–81</pages>
      <url hash="f67983a0">W17-4111</url>
      <doi>10.18653/v1/W17-4111</doi>
      <abstract>We present a semi-supervised way of training a character-based encoder-decoder recurrent neural network for morphological reinflectionthe task of generating one inflected wordform from another. This is achieved by using unlabeled tokens or random strings as training data for an autoencoding task, adapting a network for morphological reinflection, and performing multi-task training. We thus use limited labeled data more effectively, obtaining up to 9.92 % improvement over state-of-the-art <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baselines</a> for 8 different languages.</abstract>
      <bibkey>kann-schutze-2017-unlabeled</bibkey>
    </paper>
    <paper id="12">
      <title>Vowel and Consonant Classification through <a href="https://en.wikipedia.org/wiki/Spectral_decomposition">Spectral Decomposition</a></title>
      <author><first>Patricia</first><last>Thaine</last></author>
      <author><first>Gerald</first><last>Penn</last></author>
      <pages>82–91</pages>
      <url hash="bd936fb8">W17-4112</url>
      <doi>10.18653/v1/W17-4112</doi>
      <attachment type="attachment" hash="fbab5779">W17-4112.Attachment.rar</attachment>
      <abstract>We consider two related problems in this paper. Given an undeciphered alphabetic writing system or mono-alphabetic cipher, determine : (1) which of its letters are vowels and which are consonants ; and (2) whether the <a href="https://en.wikipedia.org/wiki/Writing_system">writing system</a> is a vocalic alphabet or an <a href="https://en.wikipedia.org/wiki/Abjad">abjad</a>. We are able to show that a very simple <a href="https://en.wikipedia.org/wiki/Spectral_decomposition">spectral decomposition</a> based on character co-occurrences provides nearly perfect performance with respect to answering both question types.</abstract>
      <bibkey>thaine-penn-2017-vowel</bibkey>
    </paper>
    <paper id="13">
      <title>Syllable-level Neural Language Model for Agglutinative Language</title>
      <author><first>Seunghak</first><last>Yu</last></author>
      <author><first>Nilesh</first><last>Kulkarni</last></author>
      <author><first>Haejun</first><last>Lee</last></author>
      <author><first>Jihie</first><last>Kim</last></author>
      <pages>92–96</pages>
      <url hash="a370485a">W17-4113</url>
      <doi>10.18653/v1/W17-4113</doi>
      <attachment type="attachment" hash="26afe284">W17-4113.Attachment.zip</attachment>
      <abstract>We introduce a novel method to diminish the problem of out of vocabulary words by introducing an embedding method which leverages the agglutinative property of language. We propose additional embedding derived from <a href="https://en.wikipedia.org/wiki/Syllable">syllables</a> and <a href="https://en.wikipedia.org/wiki/Morpheme">morphemes</a> for the words to improve the performance of <a href="https://en.wikipedia.org/wiki/Language_model">language model</a>. We apply the above method to input prediction tasks and achieve state of the art performance in terms of Key Stroke Saving (KSS) w.r.t. to existing device input prediction methods.</abstract>
      <bibkey>yu-etal-2017-syllable</bibkey>
    </paper>
    <paper id="15">
      <title>Word Representation Models for Morphologically Rich Languages in <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a></title>
      <author><first>Ekaterina</first><last>Vylomova</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <author><first>Xuanli</first><last>He</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <pages>103–108</pages>
      <url hash="fc60ba90">W17-4115</url>
      <doi>10.18653/v1/W17-4115</doi>
      <abstract>Out-of-vocabulary words present a great challenge for <a href="https://en.wikipedia.org/wiki/Machine_translation">Machine Translation</a>. Recently various character-level compositional models were proposed to address this issue. In current research we incorporate two most popular neural architectures, namely LSTM and CNN, into hard- and soft-attentional models of translation for character-level representation of the source. We propose semantic and morphological intrinsic evaluation of encoder-level representations. Our analysis of the learned representations reveals that character-based LSTM seems to be better at capturing morphological aspects compared to character-based CNN. We also show that hard-attentional model provides better character-level representations compared to vanilla one.</abstract>
      <bibkey>vylomova-etal-2017-word</bibkey>
    </paper>
    <paper id="16">
      <title>Spell-Checking based on <a href="https://en.wikipedia.org/wiki/Syllabification">Syllabification</a> and Character-level Graphs for a Peruvian Agglutinative Language<fixed-case>P</fixed-case>eruvian Agglutinative Language</title>
      <author><first>Carlo</first><last>Alva</last></author>
      <author><first>Arturo</first><last>Oncevay</last></author>
      <pages>109–116</pages>
      <url hash="9ced2163">W17-4116</url>
      <doi>10.18653/v1/W17-4116</doi>
      <abstract>There are several <a href="https://en.wikipedia.org/wiki/Indigenous_languages_of_the_Americas">native languages</a> in Peru which are mostly agglutinative. These <a href="https://en.wikipedia.org/wiki/Language">languages</a> are transmitted from generation to generation mainly in <a href="https://en.wikipedia.org/wiki/Oral_tradition">oral form</a>, causing different forms of writing across different communities. For this reason, there are recent efforts to standardize the <a href="https://en.wikipedia.org/wiki/Spelling">spelling</a> in the written texts, and it would be beneficial to support these tasks with an automatic tool such as an <a href="https://en.wikipedia.org/wiki/Spell_checker">spell-checker</a>. In this way, this spelling corrector is being developed based on two steps : an automatic rule-based syllabification method and a character-level graph to detect the degree of error in a misspelled word. The experiments were realized on Shipibo-konibo, a highly agglutinative and amazonian language, and the results obtained have been promising in a dataset built for the purpose.</abstract>
      <bibkey>alva-oncevay-2017-spell</bibkey>
    </paper>
    <paper id="17">
      <title>What do we need to know about an unknown word when parsing German<fixed-case>G</fixed-case>erman</title>
      <author><first>Bich-Ngoc</first><last>Do</last></author>
      <author><first>Ines</first><last>Rehbein</last></author>
      <author><first>Anette</first><last>Frank</last></author>
      <pages>117–123</pages>
      <url hash="6feff618">W17-4117</url>
      <doi>10.18653/v1/W17-4117</doi>
      <abstract>We propose a new type of subword embedding designed to provide more information about unknown compounds, a major source for OOV words in <a href="https://en.wikipedia.org/wiki/German_language">German</a>. We present an extrinsic evaluation where we use the compound embeddings as input to a neural dependency parser and compare the results to the ones obtained with other types of <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a>. Our evaluation shows that adding compound embeddings yields a significant improvement of 2 % LAS over using word embeddings when no POS information is available. When adding POS embeddings to the input, however, the effect levels out. This suggests that it is not the missing information about the <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> of the unknown words that causes problems for parsing <a href="https://en.wikipedia.org/wiki/German_language">German</a>, but the lack of morphological information for unknown words. To augment our evaluation, we also test the new embeddings in a language modelling task that requires both syntactic and semantic information.</abstract>
      <bibkey>do-etal-2017-need</bibkey>
    </paper>
    <paper id="18">
      <title>A General-Purpose Tagger with <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Networks</a></title>
      <author><first>Xiang</first><last>Yu</last></author>
      <author><first>Agnieszka</first><last>Falenska</last></author>
      <author><first>Ngoc Thang</first><last>Vu</last></author>
      <pages>124–129</pages>
      <url hash="fe8c8dfa">W17-4118</url>
      <doi>10.18653/v1/W17-4118</doi>
      <abstract>We present a general-purpose tagger based on convolutional neural networks (CNN), used for both composing word vectors and encoding context information. The CNN tagger is robust across different tagging tasks : without task-specific tuning of hyper-parameters, it achieves state-of-the-art results in <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech tagging</a>, morphological tagging and supertagging. The CNN tagger is also robust against the out-of-vocabulary problem ; it performs well on artificially unnormalized texts.</abstract>
      <bibkey>yu-etal-2017-general</bibkey>
    </paper>
    <paper id="19">
      <title>Reconstruction of Word Embeddings from Sub-Word Parameters</title>
      <author><first>Karl</first><last>Stratos</last></author>
      <pages>130–135</pages>
      <url hash="4b4899dd">W17-4119</url>
      <doi>10.18653/v1/W17-4119</doi>
      <abstract>Pre-trained word embeddings improve the performance of a neural model at the cost of increasing the model size. We propose to benefit from this resource without paying the cost by operating strictly at the sub-lexical level. Our approach is quite simple : before task-specific training, we first optimize sub-word parameters to reconstruct pre-trained word embeddings using various distance measures. We report interesting results on a variety of tasks : word similarity, word analogy, and <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech tagging</a>.</abstract>
      <bibkey>stratos-2017-reconstruction</bibkey>
    </paper>
    <paper id="20">
      <title>Inflection Generation for Spanish Verbs using <a href="https://en.wikipedia.org/wiki/Supervised_learning">Supervised Learning</a><fixed-case>S</fixed-case>panish Verbs using Supervised Learning</title>
      <author><first>Cristina</first><last>Barros</last></author>
      <author><first>Dimitra</first><last>Gkatzia</last></author>
      <author><first>Elena</first><last>Lloret</last></author>
      <pages>136–141</pages>
      <url hash="c907745d">W17-4120</url>
      <doi>10.18653/v1/W17-4120</doi>
      <abstract>We present a novel supervised approach to inflection generation for <a href="https://en.wikipedia.org/wiki/Spanish_verbs">verbs in Spanish</a>. Our system takes as input the verb’s lemma form and the desired features such as <a href="https://en.wikipedia.org/wiki/Grammatical_person">person</a>, <a href="https://en.wikipedia.org/wiki/Grammatical_number">number</a>, <a href="https://en.wikipedia.org/wiki/Grammatical_tense">tense</a>, and is able to predict the appropriate <a href="https://en.wikipedia.org/wiki/Grammatical_conjugation">grammatical conjugation</a>. Even though our approach learns from fewer examples comparing to previous work, it is able to deal with all the Spanish moods (indicative, subjunctive and imperative) in contrast to previous work which only focuses on indicative and subjunctive moods. We show that in an intrinsic evaluation, our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves 99 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>, outperforming (although not significantly) two competitive state-of-art systems. The successful results obtained clearly indicate that our approach could be integrated into wider approaches related to <a href="https://en.wikipedia.org/wiki/Text_generator">text generation</a> in <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>.</abstract>
      <bibkey>barros-etal-2017-inflection</bibkey>
    </paper>
    <paper id="22">
      <title>Sub-character Neural Language Modelling in Japanese<fixed-case>J</fixed-case>apanese</title>
      <author><first>Viet</first><last>Nguyen</last></author>
      <author><first>Julian</first><last>Brooke</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <pages>148–153</pages>
      <url hash="f50fa3ad">W17-4122</url>
      <doi>10.18653/v1/W17-4122</doi>
      <abstract>In <a href="https://en.wikipedia.org/wiki/Languages_of_East_Asia">East Asian languages</a> such as <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese</a> and <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a>, the <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> of a character are (somewhat) reflected in its sub-character elements. This paper examines the effect of using <a href="https://en.wikipedia.org/wiki/Character_(computing)">sub-characters</a> for <a href="https://en.wikipedia.org/wiki/Language_model">language modeling</a> in <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese</a>. This is achieved by decomposing <a href="https://en.wikipedia.org/wiki/Character_(computing)">characters</a> according to a range of character decomposition datasets, and training a neural language model over variously decomposed character representations. Our results indicate that <a href="https://en.wikipedia.org/wiki/Language_model">language modelling</a> can be improved through the inclusion of <a href="https://en.wikipedia.org/wiki/Character_(computing)">sub-characters</a>, though this result depends on a good choice of <a href="https://en.wikipedia.org/wiki/Data_set">decomposition dataset</a> and the appropriate granularity of decomposition.</abstract>
      <bibkey>nguyen-etal-2017-sub</bibkey>
    </paper>
    <paper id="23">
      <title>Byte-based Neural Machine Translation</title>
      <author><first>Marta R.</first><last>Costa-jussà</last></author>
      <author><first>Carlos</first><last>Escolano</last></author>
      <author><first>José A. R.</first><last>Fonollosa</last></author>
      <pages>154–158</pages>
      <url hash="d975533b">W17-4123</url>
      <doi>10.18653/v1/W17-4123</doi>
      <abstract>This paper presents experiments comparing character-based and byte-based neural machine translation systems. The main motivation of the byte-based neural machine translation system is to build multi-lingual neural machine translation systems that can share the same vocabulary. We compare the performance of both systems in several language pairs and we see that the performance in test is similar for most language pairs while the training time is slightly reduced in the case of byte-based neural machine translation.</abstract>
      <bibkey>costa-jussa-etal-2017-byte</bibkey>
    </paper>
    <paper id="24">
      <title>Improving Opinion-Target Extraction with Character-Level Word Embeddings</title>
      <author><first>Soufian</first><last>Jebbara</last></author>
      <author><first>Philipp</first><last>Cimiano</last></author>
      <pages>159–167</pages>
      <url hash="e2eb410c">W17-4124</url>
      <doi>10.18653/v1/W17-4124</doi>
      <abstract>Fine-grained sentiment analysis is receiving increasing attention in recent years. Extracting opinion target expressions (OTE) in reviews is often an important step in fine-grained, aspect-based sentiment analysis. Retrieving this information from <a href="https://en.wikipedia.org/wiki/User-generated_content">user-generated text</a>, however, can be difficult. Customer reviews, for instance, are prone to contain misspelled words and are difficult to process due to their <a href="https://en.wikipedia.org/wiki/Domain-specific_language">domain-specific language</a>. In this work, we investigate whether character-level models can improve the performance for the identification of opinion target expressions. We integrate information about the character structure of a word into a sequence labeling system using character-level word embeddings and show their positive impact on the <a href="https://en.wikipedia.org/wiki/System">system</a>’s performance. Specifically, we obtain an increase by 3.3 points <a href="https://en.wikipedia.org/wiki/F-score">F1-score</a> with respect to our baseline model. In further experiments, we reveal encoded character patterns of the learned embeddings and give a nuanced view of the performance differences of both models.</abstract>
      <bibkey>jebbara-cimiano-2017-improving</bibkey>
    </paper>
  </volume>
  <volume id="42">
    <meta>
      <booktitle>Proceedings of the 2017 <fixed-case>EMNLP</fixed-case> Workshop: Natural Language Processing meets Journalism</booktitle>
      <url hash="7e7ad15a">W17-42</url>
      <editor><first>Octavian</first><last>Popescu</last></editor>
      <editor><first>Carlo</first><last>Strapparava</last></editor>
      <doi>10.18653/v1/W17-42</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Copenhagen, Denmark</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="e5b08238">W17-4200</url>
      <bibkey>ws-2017-2017</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Predicting News Values from <a href="https://en.wikipedia.org/wiki/Headline">Headline Text</a> and Emotions</title>
      <author><first>Maria Pia</first><last>di Buono</last></author>
      <author><first>Jan</first><last>Šnajder</last></author>
      <author><first>Bojana</first><last>Dalbelo Bašić</last></author>
      <author><first>Goran</first><last>Glavaš</last></author>
      <author><first>Martin</first><last>Tutek</last></author>
      <author><first>Natasa</first><last>Milic-Frayling</last></author>
      <pages>1–6</pages>
      <url hash="968057b5">W17-4201</url>
      <doi>10.18653/v1/W17-4201</doi>
      <abstract>We present a preliminary study on predicting news values from headline text and emotions. We perform a <a href="https://en.wikipedia.org/wiki/Multivariate_analysis">multivariate analysis</a> on a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> manually annotated with news values and emotions, discovering interesting correlations among them. We then train two competitive machine learning models   an SVM and a CNN   to predict news values from headline text and emotions as features. We find that, while both models yield a satisfactory performance, some news values are more difficult to detect than others, while some profit more from including emotion information.</abstract>
      <bibkey>di-buono-etal-2017-predicting</bibkey>
    </paper>
    <paper id="2">
      <title>Predicting User Views in Online News</title>
      <author><first>Daniel</first><last>Hardt</last></author>
      <author><first>Owen</first><last>Rambow</last></author>
      <pages>7–12</pages>
      <url hash="306ea53e">W17-4202</url>
      <doi>10.18653/v1/W17-4202</doi>
      <abstract>We analyze user viewing behavior on an <a href="https://en.wikipedia.org/wiki/Online_newspaper">online news site</a>. We collect data from 64,000 <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a>, and use text features to predict frequency of user views. We compare predictiveness of the headline and teaser (viewed before clicking) and the body (viewed after clicking). Both are predictive of clicking behavior, with the full article text being most predictive.</abstract>
      <bibkey>hardt-rambow-2017-predicting</bibkey>
    </paper>
    <paper id="4">
      <title>What to Write? A topic recommender for journalists</title>
      <author><first>Alessandro</first><last>Cucchiarelli</last></author>
      <author><first>Christian</first><last>Morbidoni</last></author>
      <author><first>Giovanni</first><last>Stilo</last></author>
      <author><first>Paola</first><last>Velardi</last></author>
      <pages>19–24</pages>
      <url hash="bb0a367f">W17-4204</url>
      <doi>10.18653/v1/W17-4204</doi>
      <abstract>In this paper we present a <a href="https://en.wikipedia.org/wiki/Recommender_system">recommender system</a>, What To Write and Why, capable of suggesting to a journalist, for a given event, the aspects still uncovered in news articles on which the readers focus their interest. The basic idea is to characterize an event according to the echo it receives in online news sources and associate it with the corresponding readers’ communicative and informative patterns, detected through the analysis of <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> and <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a>, respectively. Our methodology temporally aligns the results of this analysis and recommends the concepts that emerge as topics of interest from <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> andWikipedia, either not covered or poorly covered in the published news articles.</abstract>
      <bibkey>cucchiarelli-etal-2017-write</bibkey>
    </paper>
    <paper id="5">
      <title>Comparing Attitudes to Climate Change in the Media using <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> based on Latent Dirichlet Allocation<fixed-case>L</fixed-case>atent <fixed-case>D</fixed-case>irichlet <fixed-case>A</fixed-case>llocation</title>
      <author><first>Ye</first><last>Jiang</last></author>
      <author><first>Xingyi</first><last>Song</last></author>
      <author><first>Jackie</first><last>Harrison</last></author>
      <author><first>Shaun</first><last>Quegan</last></author>
      <author><first>Diana</first><last>Maynard</last></author>
      <pages>25–30</pages>
      <url hash="7f40239f">W17-4205</url>
      <doi>10.18653/v1/W17-4205</doi>
      <abstract>News media typically present biased accounts of news stories, and different publications present different angles on the same event. In this research, we investigate how different publications differ in their approach to stories about climate change, by examining the sentiment and topics presented. To understand these attitudes, we find sentiment targets by combining Latent Dirichlet Allocation (LDA) with SentiWordNet, a general sentiment lexicon. Using LDA, we generate topics containing keywords which represent the sentiment targets, and then annotate the data using SentiWordNet before regrouping the articles based on topic similarity. Preliminary analysis identifies clearly different attitudes on the same issue presented in different <a href="https://en.wikipedia.org/wiki/Source_(journalism)">news sources</a>. Ongoing work is investigating how systematic these attitudes are between different publications, and how these may change over time.</abstract>
      <bibkey>jiang-etal-2017-comparing</bibkey>
    </paper>
    <paper id="6">
      <title>Language-based Construction of Explorable News Graphs for Journalists</title>
      <author><first>Rémi</first><last>Bois</last></author>
      <author><first>Guillaume</first><last>Gravier</last></author>
      <author><first>Eric</first><last>Jamet</last></author>
      <author><first>Emmanuel</first><last>Morin</last></author>
      <author><first>Pascale</first><last>Sébillot</last></author>
      <author><first>Maxime</first><last>Robert</last></author>
      <pages>31–36</pages>
      <url hash="ba94b342">W17-4206</url>
      <doi>10.18653/v1/W17-4206</doi>
      <abstract>Faced with ever-growing news archives, media professionals are in need of advanced tools to explore the information surrounding specific events. This problem is most commonly answered by browsing news datasets, going from article to article and viewing unaltered original content. In this article, we introduce an efficient way to generate links between news items, allowing such browsing through an easily explorable graph, and enrich this <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph</a> by automatically typing links in order to inform the user on the nature of the relation between two news pieces. User evaluations are conducted on real world data with <a href="https://en.wikipedia.org/wiki/Journalist">journalists</a> in order to assess for the interest of both the <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph representation</a> and link typing in a press reviewing task, showing the system to be of significant help for their work.</abstract>
      <bibkey>bois-etal-2017-language</bibkey>
    </paper>
    <paper id="7">
      <title>Storyteller : Visual Analytics of Perspectives on Rich Text Interpretations<fixed-case>S</fixed-case>toryteller: Visual Analytics of Perspectives on Rich Text Interpretations</title>
      <author><first>Maarten</first><last>van Meersbergen</last></author>
      <author><first>Piek</first><last>Vossen</last></author>
      <author><first>Janneke</first><last>van der Zwaan</last></author>
      <author><first>Antske</first><last>Fokkens</last></author>
      <author><first>Willem</first><last>van Hage</last></author>
      <author><first>Inger</first><last>Leemans</last></author>
      <author><first>Isa</first><last>Maks</last></author>
      <pages>37–45</pages>
      <url hash="a046c269">W17-4207</url>
      <doi>10.18653/v1/W17-4207</doi>
      <abstract>Complexity of <a href="https://en.wikipedia.org/wiki/Event_data">event data</a> in texts makes it difficult to assess its content, especially when considering larger collections in which different sources report on the same or similar situations. We present a system that makes it possible to visually analyze complex event and emotion data extracted from texts. We show that we can abstract from different data models for events and emotions to a single <a href="https://en.wikipedia.org/wiki/Data_model">data model</a> that can show the complex relations in four dimensions. The <a href="https://en.wikipedia.org/wiki/Visualization_(graphics)">visualization</a> has been applied to analyze 1) dynamic developments in how people both conceive and express emotions in theater plays and 2) how stories are told from the perspectyive of their sources based on rich event data extracted from news or biographies.</abstract>
      <bibkey>van-meersbergen-etal-2017-storyteller</bibkey>
    </paper>
    <paper id="8">
      <title>Analyzing the Revision Logs of a Japanese Newspaper for Article Quality Assessment<fixed-case>J</fixed-case>apanese Newspaper for Article Quality Assessment</title>
      <author><first>Hideaki</first><last>Tamori</last></author>
      <author><first>Yuta</first><last>Hitomi</last></author>
      <author><first>Naoaki</first><last>Okazaki</last></author>
      <author><first>Kentaro</first><last>Inui</last></author>
      <pages>46–50</pages>
      <url hash="5490bb4f">W17-4208</url>
      <doi>10.18653/v1/W17-4208</doi>
      <abstract>We address the issue of the quality of journalism and analyze daily article revision logs from a <a href="https://en.wikipedia.org/wiki/List_of_newspapers_in_Japan">Japanese newspaper company</a>. The revision logs contain data that can help reveal the requirements of quality journalism such as the types and number of edit operations and aspects commonly focused in revision. This study also discusses potential applications such as <a href="https://en.wikipedia.org/wiki/Quality_assessment">quality assessment</a> and automatic article revision as our future research directions.</abstract>
      <bibkey>tamori-etal-2017-analyzing</bibkey>
    </paper>
    <paper id="9">
      <title>Improved Abusive Comment Moderation with User Embeddings</title>
      <author><first>John</first><last>Pavlopoulos</last></author>
      <author><first>Prodromos</first><last>Malakasiotis</last></author>
      <author><first>Juli</first><last>Bakagianni</last></author>
      <author><first>Ion</first><last>Androutsopoulos</last></author>
      <pages>51–55</pages>
      <url hash="8b52b4d6">W17-4209</url>
      <doi>10.18653/v1/W17-4209</doi>
      <abstract>Experimenting with a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> of approximately 1.6 M user comments from a Greek news sports portal, we explore how a state of the art RNN-based moderation method can be improved by adding <a href="https://en.wikipedia.org/wiki/Graph_embedding">user embeddings</a>, <a href="https://en.wikipedia.org/wiki/Graph_embedding">user type embeddings</a>, user biases, or <a href="https://en.wikipedia.org/wiki/Graph_embedding">user type biases</a>. We observe improvements in all cases, with user embeddings leading to the biggest performance gains.</abstract>
      <bibkey>pavlopoulos-etal-2017-improved</bibkey>
    </paper>
    <paper id="10">
      <title>Incongruent Headlines : Yet Another Way to Mislead Your Readers</title>
      <author><first>Sophie</first><last>Chesney</last></author>
      <author><first>Maria</first><last>Liakata</last></author>
      <author><first>Massimo</first><last>Poesio</last></author>
      <author><first>Matthew</first><last>Purver</last></author>
      <pages>56–61</pages>
      <url hash="7b994c7b">W17-4210</url>
      <doi>10.18653/v1/W17-4210</doi>
      <abstract>This paper discusses the problem of incongruent headlines : those which do not accurately represent the information contained in the article with which they occur. We emphasise that this phenomenon should be considered separately from recognised problematic headline types such as <a href="https://en.wikipedia.org/wiki/Clickbait">clickbait</a> and <a href="https://en.wikipedia.org/wiki/Sensationalism">sensationalism</a>, arguing that existing natural language processing (NLP) methods applied to these related concepts are not appropriate for the automatic detection of headline incongruence, as an analysis beyond stylistic traits is necessary. We therefore suggest a number of alternative <a href="https://en.wikipedia.org/wiki/Methodology">methodologies</a> that may be appropriate to the task at hand as a foundation for future work in this area. In addition, we provide an analysis of existing data sets which are related to this work, and motivate the need for a novel <a href="https://en.wikipedia.org/wiki/Data_set">data set</a> in this domain.</abstract>
      <bibkey>chesney-etal-2017-incongruent</bibkey>
    </paper>
    <paper id="11">
      <title>Unsupervised Event Clustering and Aggregation from Newswire and Web Articles</title>
      <author><first>Swen</first><last>Ribeiro</last></author>
      <author><first>Olivier</first><last>Ferret</last></author>
      <author><first>Xavier</first><last>Tannier</last></author>
      <pages>62–67</pages>
      <url hash="a78ace18">W17-4211</url>
      <doi>10.18653/v1/W17-4211</doi>
      <abstract>In this paper, we present an unsupervised pipeline approach for clustering <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a> based on identified event instances in their content. We leverage press agency newswire and monolingual word alignment techniques to build meaningful and linguistically varied clusters of articles from the web in the perspective of a broader event type detection task. We validate our approach on a manually annotated corpus of Web articles.</abstract>
      <bibkey>ribeiro-etal-2017-unsupervised</bibkey>
    </paper>
    <paper id="12">
      <title>Semantic Storytelling, Cross-lingual Event Detection and other Semantic Services for a Newsroom Content Curation Dashboard</title>
      <author><first>Julian</first><last>Moreno-Schneider</last></author>
      <author><first>Ankit</first><last>Srivastava</last></author>
      <author><first>Peter</first><last>Bourgonje</last></author>
      <author><first>David</first><last>Wabnitz</last></author>
      <author><first>Georg</first><last>Rehm</last></author>
      <pages>68–73</pages>
      <url hash="79d278ba">W17-4212</url>
      <doi>10.18653/v1/W17-4212</doi>
      <abstract>We present a prototypical content curation dashboard, to be used in the newsroom, and several of its underlying semantic content analysis components (such as <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>, entity linking, summarisation and temporal expression analysis). The idea is to enable journalists (a) to process incoming content (agency reports, twitter feeds, <a href="https://en.wikipedia.org/wiki/Report">reports</a>, blog posts, <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> etc.) and (b) to create new articles more easily and more efficiently. The prototype system also allows the automatic annotation of events in incoming content for the purpose of supporting journalists in identifying important, relevant or meaningful events and also to adapt the content currently in production accordingly in a semi-automatic way. One of our long-term goals is to support journalists building up entire storylines with automatic means. In the present <a href="https://en.wikipedia.org/wiki/Prototype">prototype</a> they are generated in a <a href="https://en.wikipedia.org/wiki/Front_and_back_ends">backend service</a> using <a href="https://en.wikipedia.org/wiki/Cluster_analysis">clustering methods</a> that operate on the extracted events.</abstract>
      <bibkey>moreno-schneider-etal-2017-semantic</bibkey>
    </paper>
    <paper id="13">
      <title>Deception Detection in News Reports in the <a href="https://en.wikipedia.org/wiki/Russian_language">Russian Language</a> : Lexics and Discourse<fixed-case>R</fixed-case>ussian Language: Lexics and Discourse</title>
      <author><first>Dina</first><last>Pisarevskaya</last></author>
      <pages>74–79</pages>
      <url hash="877d9eb2">W17-4213</url>
      <doi>10.18653/v1/W17-4213</doi>
      <abstract>News verification and automated fact checking tend to be very important issues in our world. The research is initial. We collected a corpus for <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a> (174 news reports, truthful and fake ones). We held two experiments, for both we applied SVMs algorithm (linear / rbf kernel) and <a href="https://en.wikipedia.org/wiki/Random_forest">Random Forest</a> to classify the news reports into 2 classes : truthful / deceptive. In the first experiment, we used 18 <a href="https://en.wikipedia.org/wiki/Marker_(linguistics)">markers</a> on lexics level, mostly frequencies of POS tags in texts. In the second experiment, on <a href="https://en.wikipedia.org/wiki/Discourse_analysis">discourse level</a> we used frequencies of rhetorical relations types in texts. The classification task in the first experiment is solved better by SVMs (rbf kernel) (f-measure 0.65). The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> based on RST features shows best results with Random Forest Classifier (f-measure 0.54) and should be modified. In the next research, the combination of different deception detection markers for the <a href="https://en.wikipedia.org/wiki/Russian_language">Russian language</a> should be taken in order to make a better <a href="https://en.wikipedia.org/wiki/Predictive_modelling">predictive model</a>.</abstract>
      <bibkey>pisarevskaya-2017-deception</bibkey>
    </paper>
    <paper id="14">
      <title>Fake news stance detection using stacked ensemble of classifiers</title>
      <author><first>James</first><last>Thorne</last></author>
      <author><first>Mingjie</first><last>Chen</last></author>
      <author><first>Giorgos</first><last>Myrianthous</last></author>
      <author><first>Jiashu</first><last>Pu</last></author>
      <author><first>Xiaoxuan</first><last>Wang</last></author>
      <author><first>Andreas</first><last>Vlachos</last></author>
      <pages>80–83</pages>
      <url hash="42e8b186">W17-4214</url>
      <doi>10.18653/v1/W17-4214</doi>
      <abstract>Fake news has become a hotly debated topic in <a href="https://en.wikipedia.org/wiki/Journalism">journalism</a>. In this paper, we present our entry to the 2017 Fake News Challenge which models the detection of fake news as a stance classification task that finished in 11th place on the leader board. Our entry is an ensemble system of classifiers developed by students in the context of their coursework. We show how we used the stacking ensemble method for this purpose and obtained improvements in classification accuracy exceeding each of the individual models’ performance on the development data. Finally, we discuss aspects of the experimental setup of the challenge.</abstract>
      <bibkey>thorne-etal-2017-fake</bibkey>
    </paper>
    <paper id="15">
      <title>From <a href="https://en.wikipedia.org/wiki/Clickbait">Clickbait</a> to Fake News Detection : An Approach based on Detecting the Stance of Headlines to Articles</title>
      <author><first>Peter</first><last>Bourgonje</last></author>
      <author><first>Julian</first><last>Moreno Schneider</last></author>
      <author><first>Georg</first><last>Rehm</last></author>
      <pages>84–89</pages>
      <url hash="a38cb813">W17-4215</url>
      <doi>10.18653/v1/W17-4215</doi>
      <abstract>We present a <a href="https://en.wikipedia.org/wiki/System">system</a> for the detection of the stance of headlines with regard to their corresponding <a href="https://en.wikipedia.org/wiki/Article_(grammar)">article bodies</a>. The approach can be applied in <a href="https://en.wikipedia.org/wiki/Fake_news">fake news</a>, especially clickbait detection scenarios. The component is part of a larger platform for the curation of digital content ; we consider veracity and relevancy an increasingly important part of curating online information. We want to contribute to the debate on how to deal with <a href="https://en.wikipedia.org/wiki/Fake_news">fake news</a> and related online phenomena with technological means, by providing means to separate related from unrelated headlines and further classifying the related headlines. On a publicly available <a href="https://en.wikipedia.org/wiki/Data_set">data set</a> annotated for the stance of headlines with regard to their corresponding <a href="https://en.wikipedia.org/wiki/Article_(publishing)">article bodies</a>, we achieve a <a href="https://en.wikipedia.org/wiki/Weighted_arithmetic_mean">(weighted) accuracy score</a> of 89.59.</abstract>
      <bibkey>bourgonje-etal-2017-clickbait</bibkey>
    </paper>
    <paper id="16">
      <title>‘Fighting’ or ‘Conflict’? An Approach to Revealing Concepts of Terms in Political Discourse</title>
      <author><first>Linyuan</first><last>Tang</last></author>
      <author><first>Kyo</first><last>Kageura</last></author>
      <pages>90–94</pages>
      <url hash="da66bd72">W17-4216</url>
      <doi>10.18653/v1/W17-4216</doi>
      <abstract>Previous work on the epistemology of <a href="https://en.wikipedia.org/wiki/Fact-checking">fact-checking</a> indicated the dilemma between the needs of binary answers for the public and ambiguity of political discussion. Determining concepts represented by terms in <a href="https://en.wikipedia.org/wiki/Discourse_analysis">political discourse</a> can be considered as a Word-Sense Disambiguation (WSD) task. The analysis of political discourse, however, requires identifying precise concepts of terms from relatively small data. This work attempts to provide a basic <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> for revealing concepts of terms in <a href="https://en.wikipedia.org/wiki/Discourse_analysis">political discourse</a> with explicit contextual information. The framework consists of three parts : 1) extracting important terms, 2) generating concordance for each term with stipulative definitions and explanations, and 3) agglomerating similar information of the term by <a href="https://en.wikipedia.org/wiki/Hierarchical_clustering">hierarchical clustering</a>. Utterances made by Prime Minister Abe Shinzo in the Diet of Japan are used to examine our <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a>. Importantly, we revealed the conceptual inconsistency of the term Sonritsu-kiki-jitai. The <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> was proved to work, but only for a small number of terms due to lack of explicit contextual information.</abstract>
      <bibkey>tang-kageura-2017-fighting</bibkey>
    </paper>
    <paper id="17">
      <title>A News Chain Evaluation Methodology along with a Lattice-based Approach for News Chain Construction</title>
      <author><first>Mustafa</first><last>Toprak</last></author>
      <author><first>Özer</first><last>Özkahraman</last></author>
      <author><first>Selma</first><last>Tekir</last></author>
      <pages>95–99</pages>
      <url hash="c5b2fb85">W17-4217</url>
      <doi>10.18653/v1/W17-4217</doi>
      <abstract>Chain construction is an important requirement for understanding news and establishing the context. A news chain can be defined as a coherent set of articles that explains an event or a story. There’s a lack of well-established methods in this area. In this work, we propose a <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> to evaluate the goodness of a given news chain and implement a concept lattice-based news chain construction method by Hossain et al.. The methodology part is vital as it directly affects the growth of research in this area. Our proposed methodology consists of collected news chains from different studies and two goodness metrics, minedge and <a href="https://en.wikipedia.org/wiki/Statistical_dispersion">dispersion coefficient</a> respectively. We assess the utility of the lattice-based news chain construction method by our proposed <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a>.</abstract>
      <bibkey>toprak-etal-2017-news</bibkey>
    </paper>
    <paper id="18">
      <title>Using New York Times Picks to Identify Constructive Comments<fixed-case>N</fixed-case>ew <fixed-case>Y</fixed-case>ork <fixed-case>T</fixed-case>imes Picks to Identify Constructive Comments</title>
      <author><first>Varada</first><last>Kolhatkar</last></author>
      <author><first>Maite</first><last>Taboada</last></author>
      <pages>100–105</pages>
      <url hash="400f83d2">W17-4218</url>
      <doi>10.18653/v1/W17-4218</doi>
      <abstract>We examine the extent to which we are able to automatically identify constructive online comments. We build several classifiers using New York Times Picks as positive examples and non-constructive thread comments from the Yahoo News Annotated Comments Corpus as negative examples of constructive online comments. We evaluate these <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> on a crowd-annotated corpus containing 1,121 comments. Our best <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> achieves a top F1 score of 0.84.</abstract>
      <bibkey>kolhatkar-taboada-2017-using</bibkey>
    </paper>
    <paper id="19">
      <title>An <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP Analysis</a> of Exaggerated Claims in Science News<fixed-case>NLP</fixed-case> Analysis of Exaggerated Claims in Science News</title>
      <author><first>Yingya</first><last>Li</last></author>
      <author><first>Jieke</first><last>Zhang</last></author>
      <author><first>Bei</first><last>Yu</last></author>
      <pages>106–111</pages>
      <url hash="31e4c633">W17-4219</url>
      <doi>10.18653/v1/W17-4219</doi>
      <abstract>The discrepancy between science and media has been affecting the effectiveness of <a href="https://en.wikipedia.org/wiki/Science_communication">science communication</a>. Original findings from <a href="https://en.wikipedia.org/wiki/Scientific_literature">science publications</a> may be distorted with altered claim strength when reported to the public, causing misinformation spread. This study conducts an NLP analysis of exaggerated claims in <a href="https://en.wikipedia.org/wiki/Science_journalism">science news</a>, and then constructed prediction models for identifying claim strength levels in <a href="https://en.wikipedia.org/wiki/Science_journalism">science reporting</a>. The results demonstrate different writing styles journal articles and news / press releases use for reporting scientific findings. Preliminary prediction models reached promising result with room for further improvement.</abstract>
      <bibkey>li-etal-2017-nlp</bibkey>
    </paper>
  </volume>
  <volume id="43">
    <meta>
      <booktitle>Proceedings of the 2nd Workshop on Structured Prediction for Natural Language Processing</booktitle>
      <url hash="5211be47">W17-43</url>
      <editor><first>Kai-Wei</first><last>Chang</last></editor>
      <editor><first>Ming-Wei</first><last>Chang</last></editor>
      <editor><first>Vivek</first><last>Srikumar</last></editor>
      <editor><first>Alexander M.</first><last>Rush</last></editor>
      <doi>10.18653/v1/W17-43</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Copenhagen, Denmark</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="dde22064">W17-4300</url>
      <bibkey>ws-2017-structured</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Dependency Parsing with Dilated Iterated Graph CNNs<fixed-case>CNN</fixed-case>s</title>
      <author><first>Emma</first><last>Strubell</last></author>
      <author><first>Andrew</first><last>McCallum</last></author>
      <pages>1–6</pages>
      <url hash="90c5f7e5">W17-4301</url>
      <doi>10.18653/v1/W17-4301</doi>
      <abstract>Dependency parses are an effective way to inject linguistic knowledge into many downstream tasks, and many practitioners wish to efficiently parse sentences at scale. Recent advances in <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit">GPU hardware</a> have enabled <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a> to achieve significant gains over the previous best models, these models still fail to leverage GPUs’ capability for <a href="https://en.wikipedia.org/wiki/Massively_parallel">massive parallelism</a> due to their requirement of sequential processing of the sentence. In response, we propose Dilated Iterated Graph Convolutional Neural Networks (DIG-CNNs) for graph-based dependency parsing, a graph convolutional architecture that allows for efficient end-to-end GPU parsing. In experiments on the English Penn TreeBank benchmark, we show that DIG-CNNs perform on par with some of the best <a href="https://en.wikipedia.org/wiki/Parsing">neural network parsers</a>.</abstract>
      <bibkey>strubell-mccallum-2017-dependency</bibkey>
    </paper>
    <paper id="2">
      <title>Entity Identification as Multitasking</title>
      <author><first>Karl</first><last>Stratos</last></author>
      <pages>7–11</pages>
      <url hash="2afb4196">W17-4302</url>
      <doi>10.18653/v1/W17-4302</doi>
      <abstract>Standard approaches in <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity identification</a> hard-code boundary detection and type prediction into labels and perform <a href="https://en.wikipedia.org/wiki/Viterbi_algorithm">Viterbi</a>. This has two disadvantages : 1. the <a href="https://en.wikipedia.org/wiki/Run_time_(program_lifecycle_phase)">runtime complexity</a> grows quadratically in the number of types, and 2. there is no natural segment-level representation. In this paper, we propose a neural architecture that addresses these disadvantages. We frame the problem as <a href="https://en.wikipedia.org/wiki/Computer_multitasking">multitasking</a>, separating boundary detection and type prediction but optimizing them jointly. Despite its simplicity, this <a href="https://en.wikipedia.org/wiki/Computer_architecture">architecture</a> performs competitively with fully structured models such as BiLSTM-CRFs while scaling linearly in the number of types. Furthermore, by construction, the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> induces type-disambiguating embeddings of predicted mentions.</abstract>
      <bibkey>stratos-2017-entity</bibkey>
      <pwccode url="https://github.com/karlstratos/mention2vec" additional="false">karlstratos/mention2vec</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
    </paper>
    <paper id="3">
      <title>Towards Neural Machine Translation with Latent Tree Attention</title>
      <author><first>James</first><last>Bradbury</last></author>
      <author><first>Richard</first><last>Socher</last></author>
      <pages>12–16</pages>
      <url hash="46b98036">W17-4303</url>
      <doi>10.18653/v1/W17-4303</doi>
      <attachment type="attachment" hash="ef034f06">W17-4303.Attachment.zip</attachment>
      <abstract>Building <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> that take advantage of the hierarchical structure of language without a priori annotation is a longstanding goal in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. We introduce such a model for the task of <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>, pairing a recurrent neural network grammar encoder with a novel attentional RNNG decoder and applying policy gradient reinforcement learning to induce unsupervised tree structures on both the source and target. When trained on character-level datasets with no explicit segmentation or parse annotation, the model learns a plausible segmentation and shallow parse, obtaining performance close to an attentional baseline.</abstract>
      <bibkey>bradbury-socher-2017-towards</bibkey>
    </paper>
    <paper id="4">
      <title>Structured Prediction via Learning to Search under Bandit Feedback</title>
      <author><first>Amr</first><last>Sharaf</last></author>
      <author><first>Hal</first><last>Daumé III</last></author>
      <pages>17–26</pages>
      <url hash="3c2c0f98">W17-4304</url>
      <doi>10.18653/v1/W17-4304</doi>
      <abstract>We present an <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> for <a href="https://en.wikipedia.org/wiki/Structured_prediction">structured prediction</a> under online bandit feedback. The <a href="https://en.wikipedia.org/wiki/Learning">learner</a> repeatedly predicts a sequence of actions, generating a structured output. It then observes <a href="https://en.wikipedia.org/wiki/Feedback">feedback</a> for that <a href="https://en.wikipedia.org/wiki/Output_(economics)">output</a> and no others. We consider two cases : a pure bandit setting in which it only observes a loss, and more fine-grained feedback in which it observes a loss for every action. We find that the fine-grained feedback is necessary for strong empirical performance, because it allows for a robust variance-reduction strategy. We empirically compare a number of different <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> and exploration methods and show the efficacy of BLS on sequence labeling and dependency parsing tasks.</abstract>
      <bibkey>sharaf-daume-iii-2017-structured</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="5">
      <title>Syntax Aware LSTM model for <a href="https://en.wikipedia.org/wiki/Semantic_Role_Labeling">Semantic Role Labeling</a><fixed-case>LSTM</fixed-case> model for Semantic Role Labeling</title>
      <author><first>Feng</first><last>Qian</last></author>
      <author><first>Lei</first><last>Sha</last></author>
      <author><first>Baobao</first><last>Chang</last></author>
      <author><first>Lu-chen</first><last>Liu</last></author>
      <author><first>Ming</first><last>Zhang</last></author>
      <pages>27–32</pages>
      <url hash="5cec393a">W17-4305</url>
      <doi>10.18653/v1/W17-4305</doi>
      <abstract>In Semantic Role Labeling (SRL) task, the tree structured dependency relation is rich in syntax information, but it is not well handled by existing models. In this paper, we propose Syntax Aware Long Short Time Memory (SA-LSTM). The structure of SA-LSTM changes according to dependency structure of each sentence, so that SA-LSTM can model the whole tree structure of dependency relation in an architecture engineering way. Experiments demonstrate that on Chinese Proposition Bank (CPB) 1.0, SA-LSTM improves <a href="https://en.wikipedia.org/wiki/F-number">F1</a> by 2.06 % than ordinary bi-LSTM with feature engineered dependency relation information, and gives state-of-the-art <a href="https://en.wikipedia.org/wiki/F-number">F1</a> of 79.92 %. On English CoNLL 2005 dataset, SA-LSTM brings improvement (2.1 %) to bi-LSTM model and also brings slight improvement (0.3 %) when added to the <a href="https://en.wikipedia.org/wiki/State-of-the-art">state-of-the-art model</a>.</abstract>
      <bibkey>qian-etal-2017-syntax</bibkey>
    </paper>
    <paper id="7">
      <title>Boosting Information Extraction Systems with Character-level Neural Networks and Free Noisy Supervision</title>
      <author><first>Philipp</first><last>Meerkamp</last></author>
      <author><first>Zhengyi</first><last>Zhou</last></author>
      <pages>44–51</pages>
      <url hash="9d1eb796">W17-4307</url>
      <doi>10.18653/v1/W17-4307</doi>
      <abstract>We present an <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> to boost the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a> of existing <a href="https://en.wikipedia.org/wiki/Information_extraction">information extraction systems</a>. This is achieved by augmenting the existing <a href="https://en.wikipedia.org/wiki/Parsing">parser</a>, which may be constraint-based or hybrid statistical, with a character-level neural network. Our architecture combines the ability of constraint-based or hybrid extraction systems to easily incorporate <a href="https://en.wikipedia.org/wiki/Domain_knowledge">domain knowledge</a> with the ability of <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural networks</a> to leverage large amounts of data to learn complex features. The <a href="https://en.wikipedia.org/wiki/Computer_network">network</a> is trained using a measure of consistency between extracted data and existing <a href="https://en.wikipedia.org/wiki/Database">databases</a> as a form of cheap, noisy supervision. Our <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> does not require large scale manual annotation or a <a href="https://en.wikipedia.org/wiki/Code_refactoring">system rewrite</a>. It has led to large precision improvements over an existing, highly-tuned production information extraction system used at <a href="https://en.wikipedia.org/wiki/Bloomberg_L.P.">Bloomberg LP</a> for financial language text.</abstract>
      <bibkey>meerkamp-zhou-2017-boosting</bibkey>
    </paper>
    <paper id="8">
      <title>Piecewise Latent Variables for Neural Variational Text Processing</title>
      <author><first>Iulian Vlad</first><last>Serban</last></author>
      <author><first>Alexander</first><last>Ororbia II</last></author>
      <author><first>Joelle</first><last>Pineau</last></author>
      <author><first>Aaron</first><last>Courville</last></author>
      <pages>52–62</pages>
      <url hash="1a84cf2e">W17-4308</url>
      <doi>10.18653/v1/W17-4308</doi>
      <abstract>Advances in neural variational inference have facilitated the learning of powerful directed graphical models with continuous latent variables, such as variational autoencoders. The hope is that such <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> will learn to represent rich, multi-modal latent factors in real-world data, such as <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language text</a>. However, current models often assume simplistic priors on the latent variables-such as the uni-modal Gaussian distribution-which are incapable of representing complex latent factors efficiently. To overcome this restriction, we propose the simple, but highly flexible, piecewise constant distribution. This <a href="https://en.wikipedia.org/wiki/Probability_distribution">distribution</a> has the capacity to represent an exponential number of modes of a latent target distribution, while remaining mathematically tractable. Our results demonstrate that incorporating this new latent distribution into different models yields substantial improvements in natural language processing tasks such as document modeling and <a href="https://en.wikipedia.org/wiki/Natural-language_generation">natural language generation</a> for <a href="https://en.wikipedia.org/wiki/Dialogue">dialogue</a>.</abstract>
      <bibkey>serban-etal-2017-piecewise-latent</bibkey>
      <pwccode url="https://github.com/julianser/hred-latent-piecewise" additional="true">julianser/hred-latent-piecewise</pwccode>
    </paper>
  </volume>
  <volume id="44">
    <meta>
      <booktitle>Proceedings of the 3rd Workshop on Noisy User-generated Text</booktitle>
      <url hash="c19f6979">W17-44</url>
      <editor><first>Leon</first><last>Derczynski</last></editor>
      <editor><first>Wei</first><last>Xu</last></editor>
      <editor><first>Alan</first><last>Ritter</last></editor>
      <editor><first>Tim</first><last>Baldwin</last></editor>
      <doi>10.18653/v1/W17-44</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Copenhagen, Denmark</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="dfc64f32">W17-4400</url>
      <bibkey>ws-2017-noisy</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Boundary-based MWE segmentation with text partitioning<fixed-case>MWE</fixed-case> segmentation with text partitioning</title>
      <author><first>Jake</first><last>Williams</last></author>
      <pages>1–10</pages>
      <url hash="3985b4c0">W17-4401</url>
      <doi>10.18653/v1/W17-4401</doi>
      <abstract>This submission describes the development of a fine-grained, text-chunking algorithm for the task of comprehensive MWE segmentation. This <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> notably focuses on the identification of colloquial and idiomatic language. The submission also includes a thorough model evaluation in the context of two recent shared tasks, spanning 19 different languages and many text domains, including noisy, user-generated text. Evaluations exhibit the presented model as the best overall for purposes of MWE segmentation, and <a href="https://en.wikipedia.org/wiki/Open-source_software">open-source software</a> is released with the submission (although links are withheld for purposes of anonymity). Additionally, the authors acknowledge the existence of a pre-print document on arxiv.org, which should be avoided to maintain anonymity in review.</abstract>
      <bibkey>williams-2017-boundary</bibkey>
    </paper>
    <paper id="2">
      <title>Towards the Understanding of Gaming Audiences by Modeling Twitch Emotes</title>
      <author><first>Francesco</first><last>Barbieri</last></author>
      <author><first>Luis</first><last>Espinosa-Anke</last></author>
      <author><first>Miguel</first><last>Ballesteros</last></author>
      <author><first>Juan</first><last>Soler-Company</last></author>
      <author><first>Horacio</first><last>Saggion</last></author>
      <pages>11–20</pages>
      <url hash="2bbd5a68">W17-4402</url>
      <doi>10.18653/v1/W17-4402</doi>
      <abstract>Videogame streaming platforms have become a paramount example of noisy user-generated text. These are websites where <a href="https://en.wikipedia.org/wiki/Video_game">gaming</a> is broadcasted, and allows interaction with viewers via integrated chatrooms. Probably the best known <a href="https://en.wikipedia.org/wiki/Computing_platform">platform</a> of this kind is <a href="https://en.wikipedia.org/wiki/Twitch.tv">Twitch</a>, which has more than 100 million monthly viewers. Despite these numbers, and unlike other <a href="https://en.wikipedia.org/wiki/Computing_platform">platforms</a> featuring short messages (e.g. Twitter), <a href="https://en.wikipedia.org/wiki/Twitch.tv">Twitch</a> has not received much attention from the Natural Language Processing community. In this paper we aim at bridging this gap by proposing two important tasks specific to the Twitch platform, namely (1) Emote prediction ; and (2) Trolling detection. In our experiments, we evaluate three models : a BOW baseline, a logistic supervised classifiers based on word embeddings, and a bidirectional long short-term memory recurrent neural network (LSTM). Our results show that the LSTM model outperforms the other two models, where explicit features with proven effectiveness for similar tasks were encoded.</abstract>
      <bibkey>barbieri-etal-2017-towards</bibkey>
    </paper>
    <paper id="4">
      <title>To normalize, or not to normalize : The impact of <a href="https://en.wikipedia.org/wiki/Normalization_(image_processing)">normalization</a> on Part-of-Speech tagging</title>
      <author><first>Rob</first><last>van der Goot</last></author>
      <author><first>Barbara</first><last>Plank</last></author>
      <author><first>Malvina</first><last>Nissim</last></author>
      <pages>31–39</pages>
      <url hash="6df20b7c">W17-4404</url>
      <doi>10.18653/v1/W17-4404</doi>
      <abstract>Does <a href="https://en.wikipedia.org/wiki/Normalization_(statistics)">normalization</a> help Part-of-Speech (POS) tagging accuracy on noisy, non-canonical data? To the best of our knowledge, little is known on the actual impact of <a href="https://en.wikipedia.org/wiki/Normalization_(statistics)">normalization</a> in a real-world scenario, where gold error detection is not available. We investigate the effect of automatic normalization on POS tagging of tweets. We also compare <a href="https://en.wikipedia.org/wiki/Normalization_(statistics)">normalization</a> to strategies that leverage large amounts of unlabeled data kept in its raw form. Our results show that <a href="https://en.wikipedia.org/wiki/Normalization_(statistics)">normalization</a> helps, but does not add consistently beyond just word embedding layer initialization. The latter approach yields a tagging model that is competitive with a Twitter state-of-the-art <a href="https://en.wikipedia.org/wiki/Tag_(metadata)">tagger</a>.</abstract>
      <bibkey>van-der-goot-etal-2017-normalize</bibkey>
      <pwccode url="https://github.com/bplank/wnut-2017-pos-norm" additional="false">bplank/wnut-2017-pos-norm</pwccode>
    </paper>
    <paper id="5">
      <title>Constructing an Alias List for Named Entities during an Event</title>
      <author><first>Anietie</first><last>Andy</last></author>
      <author><first>Mark</first><last>Dredze</last></author>
      <author><first>Mugizi</first><last>Rwebangira</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <pages>40–44</pages>
      <url hash="1f2b9368">W17-4405</url>
      <doi>10.18653/v1/W17-4405</doi>
      <abstract>In certain fields, real-time knowledge from events can help in making informed decisions. In order to extract pertinent real-time knowledge related to an event, it is important to identify the <a href="https://en.wikipedia.org/wiki/Named_entity">named entities</a> and their corresponding <a href="https://en.wikipedia.org/wiki/Pseudonym">aliases</a> related to the event. The problem of identifying aliases of named entities that spike has remained unexplored. In this paper, we introduce an <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a>, EntitySpike, that identifies entities that spike in popularity in tweets from a given time period, and constructs an alias list for these spiked entities. EntitySpike uses a temporal heuristic to identify named entities with similar context that occur in the same time period (within minutes) during an event. Each entity is encoded as a vector using this temporal heuristic. We show how these entity-vectors can be used to create a named entity alias list. We evaluated our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> on a dataset of temporally ordered tweets from a single event, the 2013 <a href="https://en.wikipedia.org/wiki/55th_Annual_Grammy_Awards">Grammy Awards show</a>. We carried out various experiments on tweets that were published in the same time period and show that our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> identifies most entity name aliases and outperforms a competitive baseline.</abstract>
      <bibkey>andy-etal-2017-constructing</bibkey>
    </paper>
    <paper id="6">
      <title>Incorporating <a href="https://en.wikipedia.org/wiki/Metadata">Metadata</a> into Content-Based User Embeddings</title>
      <author><first>Linzi</first><last>Xing</last></author>
      <author><first>Michael J.</first><last>Paul</last></author>
      <pages>45–49</pages>
      <url hash="0293e22d">W17-4406</url>
      <doi>10.18653/v1/W17-4406</doi>
      <abstract>Low-dimensional vector representations of social media users can benefit applications like <a href="https://en.wikipedia.org/wiki/Recommender_system">recommendation systems</a> and user attribute inference. Recent work has shown that user embeddings can be improved by combining different types of <a href="https://en.wikipedia.org/wiki/Information">information</a>, such as text and network data. We propose a data augmentation method that allows novel feature types to be used within off-the-shelf embedding models. Experimenting with the task of <a href="https://en.wikipedia.org/wiki/Recommender_system">friend recommendation</a> on a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> of 5,019 <a href="https://en.wikipedia.org/wiki/Twitter">Twitter users</a>, we show that our approach can lead to substantial performance gains with the simple addition of network and geographic features.</abstract>
      <bibkey>xing-paul-2017-incorporating</bibkey>
    </paper>
    <paper id="7">
      <title>Simple Queries as Distant Labels for Predicting Gender on Twitter<fixed-case>T</fixed-case>witter</title>
      <author><first>Chris</first><last>Emmery</last></author>
      <author><first>Grzegorz</first><last>Chrupała</last></author>
      <author><first>Walter</first><last>Daelemans</last></author>
      <pages>50–55</pages>
      <url hash="1090f1f5">W17-4407</url>
      <doi>10.18653/v1/W17-4407</doi>
      <abstract>The majority of research on extracting missing user attributes from <a href="https://en.wikipedia.org/wiki/User_profile">social media profiles</a> use costly hand-annotated labels for <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>. Distantly supervised methods exist, although these generally rely on knowledge gathered using external sources. This paper demonstrates the effectiveness of gathering distant labels for self-reported gender on <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> using simple queries. We confirm the reliability of this query heuristic by comparing with <a href="https://en.wikipedia.org/wiki/Annotation">manual annotation</a>. Moreover, using these labels for distant supervision, we demonstrate competitive model performance on the same data as <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> trained on manual annotations. As such, we offer a cheap, extensible, and fast alternative that can be employed beyond the task of <a href="https://en.wikipedia.org/wiki/Gender">gender classification</a>.</abstract>
      <bibkey>emmery-etal-2017-simple</bibkey>
    </paper>
    <paper id="8">
      <title>A <a href="https://en.wikipedia.org/wiki/Dataset">Dataset</a> and Classifier for Recognizing Social Media English<fixed-case>E</fixed-case>nglish</title>
      <author><first>Su Lin</first><last>Blodgett</last></author>
      <author><first>Johnny</first><last>Wei</last></author>
      <author><first>Brendan</first><last>O’Connor</last></author>
      <pages>56–61</pages>
      <url hash="84f47821">W17-4408</url>
      <doi>10.18653/v1/W17-4408</doi>
      <abstract>While <a href="https://en.wikipedia.org/wiki/Language_identification">language identification</a> works well on standard texts, it performs much worse on social media language, in particular dialectal languageeven for <a href="https://en.wikipedia.org/wiki/English_language">English</a>. First, to support work on English language identification, we contribute a new dataset of <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> annotated for English versus non-English, with attention to <a href="https://en.wikipedia.org/wiki/Ambiguity">ambiguity</a>, <a href="https://en.wikipedia.org/wiki/Code-switching">code-switching</a>, and automatic generation issues. It is randomly sampled from all public messages, avoiding biases towards pre-existing <a href="https://en.wikipedia.org/wiki/Classifier_(linguistics)">language classifiers</a>. Second, we find that a demographic language modelwhich identifies messages with language similar to that used by several <a href="https://en.wikipedia.org/wiki/Race_and_ethnicity_in_the_United_States">U.S. ethnic populations</a> on Twittercan be used to improve English language identification performance when combined with a traditional supervised language identifier. It increases <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall</a> with almost no loss of <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a>, including, surprisingly, for <a href="https://en.wikipedia.org/wiki/English_language">English messages</a> written by non-U.S. authors. Our <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and identifier ensemble are available online.</abstract>
      <bibkey>blodgett-etal-2017-dataset</bibkey>
    </paper>
    <paper id="9">
      <title>Evaluating hypotheses in <a href="https://en.wikipedia.org/wiki/Geolocation">geolocation</a> on a very large sample of Twitter<fixed-case>T</fixed-case>witter</title>
      <author><first>Bahar</first><last>Salehi</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>62–67</pages>
      <url hash="75208040">W17-4409</url>
      <doi>10.18653/v1/W17-4409</doi>
      <abstract>Recent work in <a href="https://en.wikipedia.org/wiki/Geolocation">geolocation</a> has made several hypotheses about what <a href="https://en.wikipedia.org/wiki/Marker_(linguistics)">linguistic markers</a> are relevant to detect where people write from. In this paper, we examine six hypotheses against a corpus consisting of all geo-tagged tweets from the US, or whose geo-tags could be inferred, in a 19 % sample of Twitter history. Our experiments lend support to all six hypotheses, including that spelling variants and <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a> are strong predictors of <a href="https://en.wikipedia.org/wiki/Location">location</a>. We also study what kinds of common nouns are predictive of location after controlling for named entities such as <a href="https://en.wikipedia.org/wiki/Dolphin">dolphins</a> or <a href="https://en.wikipedia.org/wiki/Shark">sharks</a></abstract>
      <bibkey>salehi-sogaard-2017-evaluating</bibkey>
    </paper>
    <paper id="10">
      <title>The Effect of <a href="https://en.wikipedia.org/wiki/Error_rate">Error Rate</a> in Artificially Generated Data for Automatic Preposition and Determiner Correction</title>
      <author><first>Fraser</first><last>Bowen</last></author>
      <author><first>Jon</first><last>Dehdari</last></author>
      <author><first>Josef</first><last>van Genabith</last></author>
      <pages>68–76</pages>
      <url hash="4c32e328">W17-4410</url>
      <doi>10.18653/v1/W17-4410</doi>
      <abstract>In this research we investigate the impact of mismatches in the density and type of error between training and test data on a <a href="https://en.wikipedia.org/wiki/Nervous_system">neural system</a> correcting preposition and determiner errors. We use synthetically produced training data to control error density and type, and real error data for testing. Our results show it is possible to combine error types, although <a href="https://en.wikipedia.org/wiki/Preposition_and_postposition">prepositions</a> and <a href="https://en.wikipedia.org/wiki/Determiner">determiners</a> behave differently in terms of how much error should be artificially introduced into the training data in order to get the best results.</abstract>
      <bibkey>bowen-etal-2017-effect</bibkey>
    </paper>
    <paper id="11">
      <title>An Entity Resolution Approach to Isolate Instances of Human Trafficking Online</title>
      <author><first>Chirag</first><last>Nagpal</last></author>
      <author><first>Kyle</first><last>Miller</last></author>
      <author><first>Benedikt</first><last>Boecking</last></author>
      <author><first>Artur</first><last>Dubrawski</last></author>
      <pages>77–84</pages>
      <url hash="927b6b56">W17-4411</url>
      <doi>10.18653/v1/W17-4411</doi>
      <abstract>Human trafficking is a challenging law enforcement problem, and traces of victims of such activity manifest as ‘escort advertisements’ on various online forums. Given the large, heterogeneous and noisy structure of this <a href="https://en.wikipedia.org/wiki/Data">data</a>, building <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> to predict instances of <a href="https://en.wikipedia.org/wiki/Smuggling">trafficking</a> is a convoluted task. In this paper we propose an entity resolution pipeline using a notion of proxy labels, in order to extract clusters from this data with prior history of human trafficking activity. We apply this <a href="https://en.wikipedia.org/wiki/Pipeline_(software)">pipeline</a> to 5 M records from <a href="https://en.wikipedia.org/wiki/Backpage">backpage.com</a> and report on the performance of this approach, challenges in terms of <a href="https://en.wikipedia.org/wiki/Scalability">scalability</a>, and some significant domain specific characteristics of our resolved entities.</abstract>
      <bibkey>nagpal-etal-2017-entity</bibkey>
    </paper>
    <paper id="12">
      <title>Noisy Uyghur Text Normalization<fixed-case>U</fixed-case>yghur Text Normalization</title>
      <author><first>Osman</first><last>Tursun</last></author>
      <author><first>Ruket</first><last>Cakici</last></author>
      <pages>85–93</pages>
      <url hash="92fe6cb9">W17-4412</url>
      <doi>10.18653/v1/W17-4412</doi>
      <abstract>Uyghur is the second largest and most actively used social media language in China. However, a non-negligible part of <a href="https://en.wikipedia.org/wiki/Uyghur_language">Uyghur text</a> appearing in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> is unsystematically written with the <a href="https://en.wikipedia.org/wiki/Latin_alphabet">Latin alphabet</a>, and it continues to increase in size. Uyghur text in this format is incomprehensible and ambiguous even to native Uyghur speakers. In addition, Uyghur texts in this form lack the potential for any kind of advancement for the <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP tasks</a> related to the <a href="https://en.wikipedia.org/wiki/Uyghur_language">Uyghur language</a>. Restoring and preventing noisy Uyghur text written with unsystematic Latin alphabets will be essential to the protection of Uyghur language and improving the accuracy of Uyghur NLP tasks. To this purpose, in this work we propose and compare the noisy channel model and the neural encoder-decoder model as <a href="https://en.wikipedia.org/wiki/Normalization_(statistics)">normalizing methods</a>.</abstract>
      <bibkey>tursun-cakici-2017-noisy</bibkey>
    </paper>
    <paper id="13">
      <title>Crowdsourcing Multiple Choice Science Questions</title>
      <author><first>Johannes</first><last>Welbl</last></author>
      <author><first>Nelson F.</first><last>Liu</last></author>
      <author><first>Matt</first><last>Gardner</last></author>
      <pages>94–106</pages>
      <url hash="82a80892">W17-4413</url>
      <doi>10.18653/v1/W17-4413</doi>
      <abstract>We present a novel method for obtaining high-quality, domain-targeted multiple choice questions from crowd workers. Generating these questions can be difficult without trading away originality, <a href="https://en.wikipedia.org/wiki/Relevance">relevance</a> or diversity in the answer options. Our method addresses these problems by leveraging a large corpus of domain-specific text and a small set of existing questions. It produces model suggestions for document selection and answer distractor choice which aid the human question generation process. With this <a href="https://en.wikipedia.org/wiki/Methodology">method</a> we have assembled SciQ, a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> of 13.7 K multiple choice science exam questions. We demonstrate that the method produces in-domain questions by providing an analysis of this new <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and by showing that humans can not distinguish the crowdsourced questions from original questions. When using SciQ as additional training data to existing questions, we observe accuracy improvements on real science exams.</abstract>
      <bibkey>welbl-etal-2017-crowdsourcing</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/sciq">SciQ</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="14">
      <title>A Text Normalisation System for Non-Standard English Words<fixed-case>E</fixed-case>nglish Words</title>
      <author><first>Emma</first><last>Flint</last></author>
      <author><first>Elliot</first><last>Ford</last></author>
      <author><first>Olivia</first><last>Thomas</last></author>
      <author><first>Andrew</first><last>Caines</last></author>
      <author><first>Paula</first><last>Buttery</last></author>
      <pages>107–115</pages>
      <url hash="7ff172d2">W17-4414</url>
      <doi>10.18653/v1/W17-4414</doi>
      <abstract>This paper investigates the problem of text normalisation ; specifically, the normalisation of non-standard words (NSWs) in <a href="https://en.wikipedia.org/wiki/English_language">English</a>. Non-standard words can be defined as those word tokens which do not have a dictionary entry, and can not be pronounced using the usual letter-to-phoneme conversion rules ; e.g. lbs, 99.3 %, # EMNLP2017. NSWs pose a challenge to the proper functioning of text-to-speech technology, and the solution is to spell them out in such a way that they can be pronounced appropriately. We describe our four-stage normalisation system made up of components for <a href="https://en.wikipedia.org/wiki/Detection">detection</a>, <a href="https://en.wikipedia.org/wiki/Taxonomy_(biology)">classification</a>, division and expansion of NSWs. Performance is favourabe compared to previous work in the field (Sproat et al. 2001, Normalization of non-standard words), as well as state-of-the-art text-to-speech software. Further, we update Sproat et al.’s NSW taxonomy, and create a more customisable system where users are able to input their own abbreviations and specify into which variety of English (currently available : British or American) they wish to normalise.</abstract>
      <bibkey>flint-etal-2017-text</bibkey>
    </paper>
    <paper id="15">
      <title>Huntsville, hospitals, and hockey teams : Names can reveal your location</title>
      <author><first>Bahar</first><last>Salehi</last></author>
      <author><first>Dirk</first><last>Hovy</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>116–121</pages>
      <url hash="10de0092">W17-4415</url>
      <doi>10.18653/v1/W17-4415</doi>
      <abstract>Geolocation is the task of identifying a social media user’s primary location, and in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>, there is a growing literature on to what extent automated analysis of social media posts can help. However, not all content features are equally revealing of a user’s location. In this paper, we evaluate nine name entity (NE) types. Using various metrics, we find that GEO-LOC, FACILITY and SPORT-TEAM are more informative for <a href="https://en.wikipedia.org/wiki/Geolocation">geolocation</a> than other NE types. Using these types, we improve geolocation accuracy and reduce <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">distance error</a> over various famous text-based methods.</abstract>
      <bibkey>salehi-etal-2017-huntsville</bibkey>
    </paper>
    <paper id="16">
      <title>Improving Document Clustering by Removing Unnatural Language</title>
      <author><first>Myungha</first><last>Jang</last></author>
      <author><first>Jinho D.</first><last>Choi</last></author>
      <author><first>James</first><last>Allan</last></author>
      <pages>122–130</pages>
      <url hash="3e6449d0">W17-4416</url>
      <doi>10.18653/v1/W17-4416</doi>
      <abstract>Technical documents contain a fair amount of unnatural language, such as tables, <a href="https://en.wikipedia.org/wiki/Formula">formulas</a>, and <a href="https://en.wikipedia.org/wiki/Pseudo-code">pseudo-code</a>. Unnatural language can bean important factor of confusing existing NLP tools. This paper presents an effective method of distinguishing unnatural language from <a href="https://en.wikipedia.org/wiki/Natural_language">natural language</a>, and evaluates the impact of un-natural language detection on NLP tasks such as <a href="https://en.wikipedia.org/wiki/Document_clustering">document clustering</a>. We view this problem as an information extraction task and build a multiclass classification model identifying unnatural language components into four categories. First, we create a new annotated corpus by collecting slides and papers in various for-mats, <a href="https://en.wikipedia.org/wiki/PDF">PPT</a>, <a href="https://en.wikipedia.org/wiki/PDF">PDF</a>, and <a href="https://en.wikipedia.org/wiki/HTML">HTML</a>, where unnatural language components are annotated into four categories. We then explore features available from <a href="https://en.wikipedia.org/wiki/Plain_text">plain text</a> to build a <a href="https://en.wikipedia.org/wiki/Statistical_model">statistical model</a> that can handle any format as long as it is converted into plain text. Our experiments show that re-moving unnatural language components gives an absolute improvement in document cluster-ing by up to 15 %. Our corpus and tool are publicly available</abstract>
      <bibkey>jang-etal-2017-improving</bibkey>
    </paper>
    <paper id="17">
      <title>Lithium NLP : A System for Rich Information Extraction from Noisy User Generated Text on <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a><fixed-case>NLP</fixed-case>: A System for Rich Information Extraction from Noisy User Generated Text on Social Media</title>
      <author><first>Preeti</first><last>Bhargava</last></author>
      <author><first>Nemanja</first><last>Spasojevic</last></author>
      <author><first>Guoning</first><last>Hu</last></author>
      <pages>131–139</pages>
      <url hash="30671aca">W17-4417</url>
      <doi>10.18653/v1/W17-4417</doi>
      <abstract>In this paper, we describe the Lithium Natural Language Processing (NLP) system-a resource-constrained, high-throughput and language-agnostic system for information extraction from noisy user generated text on social media. Lithium NLP extracts a rich set of information including entities, topics, <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a> and <a href="https://en.wikipedia.org/wiki/Sentimentality">sentiment</a> from text. We discuss several real world applications of the <a href="https://en.wikipedia.org/wiki/System">system</a> currently incorporated in Lithium products. We also compare our <a href="https://en.wikipedia.org/wiki/System">system</a> with existing commercial and academic NLP systems in terms of performance, information extracted and languages supported. We show that Lithium NLP is at par with and in some cases, outperforms state-of-the-art commercial NLP systems.</abstract>
      <bibkey>bhargava-etal-2017-lithium</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/dawt">DAWT</pwcdataset>
    </paper>
    <paper id="18">
      <title>Results of the WNUT2017 Shared Task on Novel and Emerging Entity Recognition<fixed-case>WNUT</fixed-case>2017 Shared Task on Novel and Emerging Entity Recognition</title>
      <author><first>Leon</first><last>Derczynski</last></author>
      <author><first>Eric</first><last>Nichols</last></author>
      <author><first>Marieke</first><last>van Erp</last></author>
      <author><first>Nut</first><last>Limsopatham</last></author>
      <pages>140–147</pages>
      <url hash="488f749c">W17-4418</url>
      <doi>10.18653/v1/W17-4418</doi>
      <abstract>This shared <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> focuses on identifying unusual, previously-unseen entities in the context of emerging discussions. Named entities form the basis of many modern approaches to other tasks (like event clustering and summarization), but recall on them is a real problem in noisy text-even among annotators. This drop tends to be due to novel entities and <a href="https://en.wikipedia.org/wiki/Surface_(topology)">surface forms</a>. Take for example the tweet so.. kktny in 30 mins? ! even human experts find the entity ‘kktny’ hard to detect and resolve. The goal of this task is to provide a definition of emerging and of rare entities, and based on that, also datasets for detecting these <a href="https://en.wikipedia.org/wiki/Non-physical_entity">entities</a>. The task as described in this paper evaluated the ability of participating entries to detect and classify novel and emerging <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entities</a> in noisy text.</abstract>
      <bibkey>derczynski-etal-2017-results</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wnut-2017-emerging-and-rare-entity">WNUT 2017</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ipm-nel">IPM NEL</pwcdataset>
    </paper>
    <paper id="19">
      <title>A Multi-task Approach for <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">Named Entity Recognition</a> in Social Media Data</title>
      <author><first>Gustavo</first><last>Aguilar</last></author>
      <author><first>Suraj</first><last>Maharjan</last></author>
      <author><first>Adrian Pastor</first><last>López-Monroy</last></author>
      <author><first>Thamar</first><last>Solorio</last></author>
      <pages>148–153</pages>
      <url hash="0f023974">W17-4419</url>
      <doi>10.18653/v1/W17-4419</doi>
      <abstract>Named Entity Recognition for <a href="https://en.wikipedia.org/wiki/Social_media">social media data</a> is challenging because of its inherent noisiness. In addition to improper grammatical structures, it contains <a href="https://en.wikipedia.org/wiki/Orthographic_error">spelling inconsistencies</a> and numerous <a href="https://en.wikipedia.org/wiki/Abbreviation">informal abbreviations</a>. We propose a novel multi-task approach by employing a more general secondary task of Named Entity (NE) segmentation together with the primary task of fine-grained NE categorization. The multi-task neural network architecture learns higher order feature representations from word and character sequences along with basic Part-of-Speech tags and gazetteer information. This <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> acts as a <a href="https://en.wikipedia.org/wiki/Feature_extraction">feature extractor</a> to feed a Conditional Random Fields classifier. We were able to obtain the first position in the 3rd Workshop on Noisy User-generated Text (WNUT-2017) with a 41.86 % entity F1-score and a 40.24 % surface F1-score.</abstract>
      <bibkey>aguilar-etal-2017-multi</bibkey>
      <pwccode url="https://github.com/tavo91/NER-WNUT17" additional="false">tavo91/NER-WNUT17</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wnut-2017-emerging-and-rare-entity">WNUT 2017</pwcdataset>
    </paper>
    <paper id="21">
      <title>Multi-channel BiLSTM-CRF Model for Emerging Named Entity Recognition in <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a><fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case>-<fixed-case>CRF</fixed-case> Model for Emerging Named Entity Recognition in Social Media</title>
      <author><first>Bill Y.</first><last>Lin</last></author>
      <author><first>Frank</first><last>Xu</last></author>
      <author><first>Zhiyi</first><last>Luo</last></author>
      <author><first>Kenny</first><last>Zhu</last></author>
      <pages>160–165</pages>
      <url hash="ae94c276">W17-4421</url>
      <doi>10.18653/v1/W17-4421</doi>
      <abstract>In this paper, we present our multi-channel neural architecture for recognizing emerging named entity in social media messages, which we applied in the Novel and Emerging Named Entity Recognition shared task at the EMNLP 2017 Workshop on Noisy User-generated Text (W-NUT). We propose a novel approach, which incorporates comprehensive word representations with multi-channel information and Conditional Random Fields (CRF) into a traditional Bidirectional Long Short-Term Memory (BiLSTM) neural network without using any additional hand-craft features such as gazetteers. In comparison with other <a href="https://en.wikipedia.org/wiki/System">systems</a> participating in the shared task, our <a href="https://en.wikipedia.org/wiki/System">system</a> won the 2nd place.</abstract>
      <bibkey>lin-etal-2017-multi</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/ipm-nel">IPM NEL</pwcdataset>
    </paper>
    <paper id="22">
      <title>Transfer Learning and Sentence Level Features for Named Entity Recognition on Tweets</title>
      <author><first>Pius</first><last>von Däniken</last></author>
      <author><first>Mark</first><last>Cieliebak</last></author>
      <pages>166–171</pages>
      <url hash="4278deca">W17-4422</url>
      <doi>10.18653/v1/W17-4422</doi>
      <abstract>We present our system for the WNUT 2017 Named Entity Recognition challenge on Twitter data. We describe two modifications of a basic neural network architecture for sequence tagging. First, we show how we exploit additional labeled data, where the Named Entity tags differ from the target task. Then, we propose a way to incorporate <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentence level features</a>. Our system uses both methods and ranked second for entity level annotations, achieving an F1-score of 40.78, and <a href="https://en.wikipedia.org/wiki/Second">second</a> for surface form annotations, achieving an F1-score of 39.33.</abstract>
      <bibkey>von-daniken-cieliebak-2017-transfer</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wnut-2017-emerging-and-rare-entity">WNUT 2017</pwcdataset>
    </paper>
    <paper id="24">
      <title>A Feature-based Ensemble Approach to Recognition of Emerging and Rare Named Entities</title>
      <author><first>Utpal Kumar</first><last>Sikdar</last></author>
      <author><first>Björn</first><last>Gambäck</last></author>
      <pages>177–181</pages>
      <url hash="06c64737">W17-4424</url>
      <doi>10.18653/v1/W17-4424</doi>
      <abstract>Detecting previously unseen named entities in text is a challenging task. The paper describes how three initial classifier models were built using Conditional Random Fields (CRFs), Support Vector Machines (SVMs) and a Long Short-Term Memory (LSTM) recurrent neural network. The outputs of these three <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> were then used as <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> to train another CRF classifier working as an <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble</a>. 5-fold cross-validation based on training and development data for the emerging and rare named entity recognition shared task showed <a href="https://en.wikipedia.org/wiki/Precision_(statistics)">precision</a>, <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall</a> and <a href="https://en.wikipedia.org/wiki/F-number">F1-score</a> of 66.87 %, 46.75 % and 54.97 %, respectively. For surface form evaluation, the CRF ensemble-based system achieved precision, <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall</a> and F1 scores of 65.18 %, 45.20 % and 53.30 %. When applied to unseen test data, the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> reached 47.92 % <a href="https://en.wikipedia.org/wiki/Precision_(statistics)">precision</a>, 31.97 % recall and 38.55 % <a href="https://en.wikipedia.org/wiki/F-number">F1-score</a> for entity level evaluation, with the corresponding surface form evaluation values of 44.91 %, 30.47 % and 36.31 %.</abstract>
      <bibkey>sikdar-gamback-2017-feature</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wnut-2017-emerging-and-rare-entity">WNUT 2017</pwcdataset>
    </paper>
  </volume>
  <volume id="45">
    <meta>
      <booktitle>Proceedings of the Workshop on New Frontiers in Summarization</booktitle>
      <url hash="2b465fdf">W17-45</url>
      <editor><first>Lu</first><last>Wang</last></editor>
      <editor><first>Jackie Chi Kit</first><last>Cheung</last></editor>
      <editor><first>Giuseppe</first><last>Carenini</last></editor>
      <editor id="fei-liu-utdallas"><first>Fei</first><last>Liu</last></editor>
      <doi>10.18653/v1/W17-45</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Copenhagen, Denmark</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="f53f30f9">W17-4500</url>
      <bibkey>ws-2017-new</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Video Highlights Detection and Summarization with Lag-Calibration based on Concept-Emotion Mapping of Crowdsourced Time-Sync Comments</title>
      <author><first>Qing</first><last>Ping</last></author>
      <author><first>Chaomei</first><last>Chen</last></author>
      <pages>1–11</pages>
      <url hash="4c17b58a">W17-4501</url>
      <doi>10.18653/v1/W17-4501</doi>
      <abstract>With the prevalence of <a href="https://en.wikipedia.org/wiki/Online_video_platform">video sharing</a>, there are increasing demands for automatic video digestion such as highlight detection. Recently, <a href="https://en.wikipedia.org/wiki/Computing_platform">platforms</a> with crowdsourced time-sync video comments have emerged worldwide, providing a good opportunity for highlight detection. However, this task is non-trivial : (1) time-sync comments often lag behind their corresponding shot ; (2) time-sync comments are semantically sparse and noisy ; (3) to determine which shots are highlights is highly subjective. The present paper aims to tackle these challenges by proposing a framework that (1) uses concept-mapped lexical-chains for lag-calibration ; (2) models video highlights based on comment intensity and combination of <a href="https://en.wikipedia.org/wiki/Emotion">emotion</a> and concept concentration of each shot ; (3) summarize each detected highlight using improved SumBasic with emotion and concept mapping. Experiments on large real-world datasets show that our highlight detection method and summarization method both outperform other benchmarks with considerable margins.</abstract>
      <bibkey>ping-chen-2017-video</bibkey>
    </paper>
    <paper id="2">
      <title>Multimedia Summary Generation from Online Conversations : Current Approaches and Future Directions</title>
      <author><first>Enamul</first><last>Hoque</last></author>
      <author><first>Giuseppe</first><last>Carenini</last></author>
      <pages>12–19</pages>
      <url hash="a49bc1d2">W17-4502</url>
      <doi>10.18653/v1/W17-4502</doi>
      <abstract>With the proliferation of Web-based social media, asynchronous conversations have become very common for supporting <a href="https://en.wikipedia.org/wiki/Online_communication">online communication</a> and <a href="https://en.wikipedia.org/wiki/Collaboration">collaboration</a>. Yet the increasing volume and complexity of conversational data often make it very difficult to get insights about the discussions. We consider combining textual summary with visual representation of conversational data as a promising way of supporting the user in exploring conversations. In this paper, we report our current work on developing visual interfaces that present multimedia summary combining text and visualization for online conversations and how our solutions have been tailored for a variety of domain problems. We then discuss the key challenges and opportunities for future work in this research space.</abstract>
      <bibkey>hoque-carenini-2017-multimedia</bibkey>
    </paper>
    <paper id="4">
      <title>Towards Improving Abstractive Summarization via Entailment Generation</title>
      <author><first>Ramakanth</first><last>Pasunuru</last></author>
      <author><first>Han</first><last>Guo</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>27–32</pages>
      <url hash="fc721b24">W17-4504</url>
      <doi>10.18653/v1/W17-4504</doi>
      <abstract>Abstractive summarization, the task of rewriting and compressing a document into a short summary, has achieved considerable success with neural sequence-to-sequence models. However, these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> can still benefit from stronger <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language inference skills</a>, since a correct summary is logically entailed by the input document, i.e., it should not contain any contradictory or unrelated information. We incorporate such knowledge into an abstractive summarization model via <a href="https://en.wikipedia.org/wiki/Multi-task_learning">multi-task learning</a>, where we share its decoder parameters with those of an entailment generation model. We achieve promising initial improvements based on multiple metrics and datasets (including a test-only setting). The domain mismatch between the entailment (captions) and summarization (news) datasets suggests that the model is learning some domain-agnostic inference skills.</abstract>
      <bibkey>pasunuru-etal-2017-towards</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="5">
      <title>Coarse-to-Fine Attention Models for Document Summarization</title>
      <author><first>Jeffrey</first><last>Ling</last></author>
      <author><first>Alexander</first><last>Rush</last></author>
      <pages>33–42</pages>
      <url hash="d43ccab9">W17-4505</url>
      <doi>10.18653/v1/W17-4505</doi>
      <abstract>Sequence-to-sequence models with <a href="https://en.wikipedia.org/wiki/Attention">attention</a> have been successful for a variety of NLP problems, but their speed does not scale well for tasks with long source sequences such as <a href="https://en.wikipedia.org/wiki/Document_summarization">document summarization</a>. We propose a novel coarse-to-fine attention model that hierarchically reads a document, using coarse attention to select top-level chunks of text and fine attention to read the words of the chosen chunks. While the computation for training standard attention models scales linearly with source sequence length, our method scales with the number of top-level chunks and can handle much longer sequences. Empirically, we find that while coarse-to-fine attention models lag behind state-of-the-art baselines, our method achieves the desired behavior of sparsely attending to subsets of the document for generation.</abstract>
      <bibkey>ling-rush-2017-coarse</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
    </paper>
    <paper id="6">
      <title>Automatic Community Creation for Abstractive Spoken Conversations Summarization</title>
      <author><first>Karan</first><last>Singla</last></author>
      <author><first>Evgeny</first><last>Stepanov</last></author>
      <author><first>Ali Orkan</first><last>Bayer</last></author>
      <author><first>Giuseppe</first><last>Carenini</last></author>
      <author><first>Giuseppe</first><last>Riccardi</last></author>
      <pages>43–47</pages>
      <url hash="226d5abd">W17-4506</url>
      <doi>10.18653/v1/W17-4506</doi>
      <abstract>Summarization of spoken conversations is a challenging task, since it requires deep understanding of dialogs. Abstractive summarization techniques rely on linking the summary sentences to sets of original conversation sentences, i.e. communities. Unfortunately, such linking information is rarely available or requires trained annotators. We propose and experiment automatic community creation using <a href="https://en.wikipedia.org/wiki/Cosine_similarity">cosine similarity</a> on different levels of representation : raw text, WordNet SynSet IDs, and <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>. We show that the abstractive summarization systems with automatic communities significantly outperform previously published results on both English and Italian corpora.</abstract>
      <bibkey>singla-etal-2017-automatic</bibkey>
    </paper>
    <paper id="7">
      <title>Combining <a href="https://en.wikipedia.org/wiki/Graph_degeneracy">Graph Degeneracy</a> and Submodularity for Unsupervised Extractive Summarization</title>
      <author><first>Antoine</first><last>Tixier</last></author>
      <author><first>Polykarpos</first><last>Meladianos</last></author>
      <author><first>Michalis</first><last>Vazirgiannis</last></author>
      <pages>48–58</pages>
      <url hash="c70b5fbf">W17-4507</url>
      <doi>10.18653/v1/W17-4507</doi>
      <abstract>We present a fully unsupervised, extractive text summarization system that leverages a submodularity framework introduced by past research. The <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> allows summaries to be generated in a greedy way while preserving near-optimal performance guarantees. Our main contribution is the novel coverage reward term of the <a href="https://en.wikipedia.org/wiki/Loss_function">objective function</a> optimized by the <a href="https://en.wikipedia.org/wiki/Greedy_algorithm">greedy algorithm</a>. This component builds on the graph-of-words representation of text and the k-core decomposition algorithm to assign meaningful scores to words. We evaluate our approach on the AMI and ICSI meeting speech corpora, and on the DUC2001 news corpus. We reach state-of-the-art performance on all <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a>. Results indicate that our method is particularly well-suited to the meeting domain.</abstract>
      <bibkey>tixier-etal-2017-combining</bibkey>
      <pwccode url="https://github.com/Tixierae/EMNLP2017_NewSum" additional="false">Tixierae/EMNLP2017_NewSum</pwccode>
    </paper>
    <paper id="8">
      <title>TL;DR : Mining Reddit to Learn Automatic Summarization<fixed-case>TL</fixed-case>;<fixed-case>DR</fixed-case>: Mining <fixed-case>R</fixed-case>eddit to Learn Automatic Summarization</title>
      <author><first>Michael</first><last>Völske</last></author>
      <author><first>Martin</first><last>Potthast</last></author>
      <author><first>Shahbaz</first><last>Syed</last></author>
      <author><first>Benno</first><last>Stein</last></author>
      <pages>59–63</pages>
      <url hash="15edbee2">W17-4508</url>
      <doi>10.18653/v1/W17-4508</doi>
      <abstract>Recent advances in <a href="https://en.wikipedia.org/wiki/Automatic_text_summarization">automatic text summarization</a> have used deep neural networks to generate high-quality abstractive summaries, but the performance of these models strongly depends on large amounts of suitable training data. We propose a new method for mining <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> for author-provided summaries, taking advantage of the common practice of appending a TL;DR to long posts. A case study using a large Reddit crawl yields the Webis-TLDR-17 dataset, complementing existing corpora primarily from the <a href="https://en.wikipedia.org/wiki/News_media">news genre</a>. Our technique is likely applicable to other <a href="https://en.wikipedia.org/wiki/Social_media">social media sites</a> and <a href="https://en.wikipedia.org/wiki/Web_crawler">general web crawls</a>.</abstract>
      <bibkey>volske-etal-2017-tl</bibkey>
    </paper>
    <paper id="9">
      <title>Topic Model Stability for Hierarchical Summarization</title>
      <author><first>John</first><last>Miller</last></author>
      <author><first>Kathleen</first><last>McCoy</last></author>
      <pages>64–73</pages>
      <url hash="c3449a42">W17-4509</url>
      <doi>10.18653/v1/W17-4509</doi>
      <attachment type="attachment" hash="5758042c">W17-4509.Attachment.zip</attachment>
      <abstract>We envisioned responsive generic hierarchical text summarization with summaries organized by section and paragraph based on hierarchical structure topic models. But we had to be sure that <a href="https://en.wikipedia.org/wiki/Topic_model">topic models</a> were stable for the sampled corpora. To that end we developed a methodology for aligning multiple hierarchical structure topic models run over the same corpus under similar conditions, calculating a representative centroid model, and reporting stability of the centroid model. We ran stability experiments for standard corpora and a development corpus of Global Warming articles. We found flat and hierarchical structures of two levels plus the root offer stable centroid models, but hierarchical structures of three levels plus the <a href="https://en.wikipedia.org/wiki/Zero_of_a_function">root</a> did n’t seem stable enough for use in hierarchical summarization.</abstract>
      <bibkey>miller-mccoy-2017-topic</bibkey>
    </paper>
    <paper id="10">
      <title>Learning to Score System Summaries for Better Content Selection Evaluation.</title>
      <author><first>Maxime</first><last>Peyrard</last></author>
      <author><first>Teresa</first><last>Botschen</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>74–84</pages>
      <url hash="185edd10">W17-4510</url>
      <doi>10.18653/v1/W17-4510</doi>
      <abstract>The evaluation of summaries is a challenging but crucial task of the summarization field. In this work, we propose to learn an automatic scoring metric based on the human judgements available as part of classical summarization datasets like TAC-2008 and TAC-2009. Any existing automatic scoring metrics can be included as <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>, the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> learns the combination exhibiting the best correlation with human judgments. The <a href="https://en.wikipedia.org/wiki/Reliability_(statistics)">reliability</a> of the new <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metric</a> is tested in a further manual evaluation where we ask humans to evaluate summaries covering the whole scoring spectrum of the <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metric</a>. We release the trained <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metric</a> as an open-source tool.</abstract>
      <bibkey>peyrard-etal-2017-learning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
    </paper>
    <paper id="13">
      <title>A Pilot Study of Domain Adaptation Effect for Neural Abstractive Summarization</title>
      <author><first>Xinyu</first><last>Hua</last></author>
      <author><first>Lu</first><last>Wang</last></author>
      <pages>100–106</pages>
      <url hash="26749dd1">W17-4513</url>
      <doi>10.18653/v1/W17-4513</doi>
      <abstract>We study the problem of <a href="https://en.wikipedia.org/wiki/Domain_adaptation">domain adaptation</a> for neural abstractive summarization. We make initial efforts in investigating what information can be transferred to a new domain. Experimental results on <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news stories</a> and <a href="https://en.wikipedia.org/wiki/Opinion_piece">opinion articles</a> indicate that neural summarization model benefits from <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">pre-training</a> based on extractive summaries. We also find that the combination of in-domain and out-of-domain setup yields better summaries when in-domain data is insufficient. Further analysis shows that, the <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> is capable to select salient content even trained on out-of-domain data, but requires in-domain data to capture the style for a target domain.</abstract>
      <bibkey>hua-wang-2017-pilot</bibkey>
    </paper>
  </volume>
  <volume id="46">
    <meta>
      <booktitle>Proceedings of the Workshop on Speech-Centric Natural Language Processing</booktitle>
      <url hash="11048b62">W17-46</url>
      <editor><first>Nicholas</first><last>Ruiz</last></editor>
      <editor><first>Srinivas</first><last>Bangalore</last></editor>
      <doi>10.18653/v1/W17-46</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Copenhagen, Denmark</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="bc0cc197">W17-4600</url>
      <bibkey>ws-2017-speech</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Analyzing Human and Machine Performance In Resolving Ambiguous Spoken Sentences</title>
      <author><first>Hussein</first><last>Ghaly</last></author>
      <author><first>Michael</first><last>Mandel</last></author>
      <pages>18–26</pages>
      <url hash="e777f461">W17-4603</url>
      <doi>10.18653/v1/W17-4603</doi>
      <attachment type="attachment" hash="a25b8afa">W17-4603.Attachment.zip</attachment>
      <abstract>Written sentences can be more ambiguous than <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">spoken sentences</a>. We investigate this difference for two different types of <a href="https://en.wikipedia.org/wiki/Ambiguity">ambiguity</a> : prepositional phrase (PP) attachment and sentences where the addition of commas changes the meaning. We recorded a native English speaker saying several of each type of sentence both with and without disambiguating contextual information. These <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentences</a> were then presented either as text or audio and either with or without context to subjects who were asked to select the proper interpretation of the sentence. Results suggest that comma-ambiguous sentences are easier to disambiguate than PP-attachment-ambiguous sentences, possibly due to the presence of clear prosodic boundaries, namely silent pauses. Subject performance for sentences with PP-attachment ambiguity without context was 52 % for text only while it was 72.4 % for <a href="https://en.wikipedia.org/wiki/Sound_recording_and_reproduction">audio only</a>, suggesting that <a href="https://en.wikipedia.org/wiki/Sound_recording_and_reproduction">audio</a> has more disambiguating information than <a href="https://en.wikipedia.org/wiki/Written_language">text</a>. Using an analysis of acoustic features of two PP-attachment sentences, a simple classifier was implemented to resolve the PP-attachment ambiguity being early or late closure with a mean accuracy of 80 %.</abstract>
      <bibkey>ghaly-mandel-2017-analyzing</bibkey>
    </paper>
    <paper id="4">
      <title>Parsing transcripts of speech</title>
      <author><first>Andrew</first><last>Caines</last></author>
      <author><first>Michael</first><last>McCarthy</last></author>
      <author><first>Paula</first><last>Buttery</last></author>
      <pages>27–36</pages>
      <url hash="8187eb7d">W17-4604</url>
      <doi>10.18653/v1/W17-4604</doi>
      <abstract>We present an analysis of <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> performance on speech data, comparing word type and token frequency distributions with written data, and evaluating parse accuracy by length of input string. We find that <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> performance tends to deteriorate with increasing length of string, more so for spoken than for written texts. We train an alternative parsing model with added <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech data</a> and demonstrate improvements in <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> on speech-units, with no deterioration in performance on <a href="https://en.wikipedia.org/wiki/Written_language">written text</a>.</abstract>
      <bibkey>caines-etal-2017-parsing</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/english-web-treebank">English Web Treebank</pwcdataset>
    </paper>
    <paper id="6">
      <title>End-to-End Information Extraction without Token-Level Supervision</title>
      <author><first>Rasmus Berg</first><last>Palm</last></author>
      <author><first>Dirk</first><last>Hovy</last></author>
      <author><first>Florian</first><last>Laws</last></author>
      <author><first>Ole</first><last>Winther</last></author>
      <pages>48–52</pages>
      <url hash="bb11479d">W17-4606</url>
      <doi>10.18653/v1/W17-4606</doi>
      <abstract>Most state-of-the-art information extraction approaches rely on token-level labels to find the areas of interest in text. Unfortunately, these labels are time-consuming and costly to create, and consequently, not available for many real-life IE tasks. To make matters worse, token-level labels are usually not the desired output, but just an intermediary step. End-to-end (E2E) models, which take raw text as input and produce the desired output directly, need not depend on token-level labels. We propose an E2E model based on pointer networks, which can be trained directly on pairs of raw input and output text. We evaluate our model on the ATIS data set, MIT restaurant corpus and the MIT movie corpus and compare to neural baselines that do use token-level labels. We achieve competitive results, within a few percentage points of the baselines, showing the feasibility of E2E information extraction without the need for token-level labels. This opens up new possibilities, as for many tasks currently addressed by human extractors, raw input and output data are available, but not token-level labels.</abstract>
      <bibkey>palm-etal-2017-end</bibkey>
      <pwccode url="https://github.com/rasmusbergpalm/e2e-ie-release" additional="false">rasmusbergpalm/e2e-ie-release</pwccode>
    </paper>
    <paper id="7">
      <title>Spoken Term Discovery for <a href="https://en.wikipedia.org/wiki/Language_documentation">Language Documentation</a> using Translations</title>
      <author><first>Antonios</first><last>Anastasopoulos</last></author>
      <author><first>Sameer</first><last>Bansal</last></author>
      <author><first>David</first><last>Chiang</last></author>
      <author><first>Sharon</first><last>Goldwater</last></author>
      <author><first>Adam</first><last>Lopez</last></author>
      <pages>53–58</pages>
      <url hash="a25c47fb">W17-4607</url>
      <doi>10.18653/v1/W17-4607</doi>
      <abstract>Vast amounts of speech data collected for <a href="https://en.wikipedia.org/wiki/Language_documentation">language documentation</a> and research remain untranscribed and unsearchable, but often a small amount of speech may have text translations available. We present a <a href="https://en.wikipedia.org/wiki/Methodology">method</a> for partially labeling additional speech with translations in this <a href="https://en.wikipedia.org/wiki/Scenario">scenario</a>. We modify an unsupervised speech-to-translation alignment model and obtain prototype speech segments that match the translation words, which are in turn used to discover terms in the unlabelled data. We evaluate our method on a Spanish-English speech translation corpus and on two corpora of endangered languages, <a href="https://en.wikipedia.org/wiki/Arapaho_language">Arapaho</a> and Ainu, demonstrating its appropriateness and applicability in an actual very-low-resource scenario.</abstract>
      <bibkey>anastasopoulos-etal-2017-spoken</bibkey>
    </paper>
    <paper id="8">
      <title>Amharic-English Speech Translation in Tourism Domain<fixed-case>A</fixed-case>mharic-<fixed-case>E</fixed-case>nglish Speech Translation in Tourism Domain</title>
      <author><first>Michael</first><last>Melese</last></author>
      <author><first>Laurent</first><last>Besacier</last></author>
      <author><first>Million</first><last>Meshesha</last></author>
      <pages>59–66</pages>
      <url hash="12f1ca13">W17-4608</url>
      <doi>10.18653/v1/W17-4608</doi>
      <abstract>This paper describes speech translation from Amharic-to-English, particularly Automatic Speech Recognition (ASR) with post-editing feature and Amharic-English Statistical Machine Translation (SMT). ASR experiment is conducted using morpheme language model (LM) and phoneme acoustic model(AM). Likewise, SMT conducted using word and morpheme as unit. Morpheme based translation shows a 6.29 BLEU score at a 76.4 % of recognition accuracy while word based translation shows a 12.83 BLEU score using 77.4 % word recognition accuracy. Further, after post-edit on Amharic ASR using <a href="https://en.wikipedia.org/wiki/Corpus_linguistics">corpus based n-gram</a>, the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">word recognition accuracy</a> increased by 1.42 %. Since post-edit approach reduces <a href="https://en.wikipedia.org/wiki/Propagation_of_uncertainty">error propagation</a>, the word based translation accuracy improved by 0.25 (1.95 %) BLEU score. We are now working towards further improving propagated errors through different <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> at each unit of speech translation cascading component.</abstract>
      <bibkey>melese-etal-2017-amharic</bibkey>
    </paper>
    <paper id="9">
      <title>Speech- and Text-driven Features for Automated Scoring of English Speaking Tasks<fixed-case>E</fixed-case>nglish Speaking Tasks</title>
      <author><first>Anastassia</first><last>Loukina</last></author>
      <author><first>Nitin</first><last>Madnani</last></author>
      <author><first>Aoife</first><last>Cahill</last></author>
      <pages>67–77</pages>
      <url hash="de7f3228">W17-4609</url>
      <doi>10.18653/v1/W17-4609</doi>
      <abstract>We consider the automatic scoring of a <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> for which both the content of the response as well its spoken fluency are important. We combine <a href="https://en.wikipedia.org/wiki/Software_feature">features</a> from a text-only content scoring system originally designed for written responses with several categories of acoustic features. Although adding any single category of acoustic features to the text-only system on its own does not significantly improve performance, adding all acoustic features together does yield a small but significant improvement. These results are consistent for responses to open-ended questions and to questions focused on some given source material.</abstract>
      <bibkey>loukina-etal-2017-speech</bibkey>
    </paper>
    </volume>
  <volume id="47">
    <meta>
      <booktitle>Proceedings of the Second Conference on Machine Translation</booktitle>
      <url hash="74a92d19">W17-47</url>
      <editor><first>Ondřej</first><last>Bojar</last></editor>
      <editor><first>Christian</first><last>Buck</last></editor>
      <editor><first>Rajen</first><last>Chatterjee</last></editor>
      <editor><first>Christian</first><last>Federmann</last></editor>
      <editor><first>Yvette</first><last>Graham</last></editor>
      <editor><first>Barry</first><last>Haddow</last></editor>
      <editor><first>Matthias</first><last>Huck</last></editor>
      <editor><first>Antonio Jimeno</first><last>Yepes</last></editor>
      <editor><first>Philipp</first><last>Koehn</last></editor>
      <editor><first>Julia</first><last>Kreutzer</last></editor>
      <doi>10.18653/v1/W17-47</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Copenhagen, Denmark</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="28fdcb09">W17-4700</url>
      <bibkey>ws-2017-machine</bibkey>
    </frontmatter>
    </volume>
  <volume id="48">
    <meta>
      <booktitle>Proceedings of the Third Workshop on Discourse in Machine Translation</booktitle>
      <url hash="9d769d1b">W17-48</url>
      <editor><first>Bonnie</first><last>Webber</last></editor>
      <editor><first>Andrei</first><last>Popescu-Belis</last></editor>
      <editor><first>Jörg</first><last>Tiedemann</last></editor>
      <doi>10.18653/v1/W17-48</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Copenhagen, Denmark</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="181b3fae">W17-4800</url>
      <bibkey>ws-2017-discourse</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Findings of the 2017 DiscoMT Shared Task on Cross-lingual Pronoun Prediction<fixed-case>D</fixed-case>isco<fixed-case>MT</fixed-case> Shared Task on Cross-lingual Pronoun Prediction</title>
      <author><first>Sharid</first><last>Loáiciga</last></author>
      <author><first>Sara</first><last>Stymne</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <author><first>Christian</first><last>Hardmeier</last></author>
      <author><first>Jörg</first><last>Tiedemann</last></author>
      <author><first>Mauro</first><last>Cettolo</last></author>
      <author><first>Yannick</first><last>Versley</last></author>
      <pages>1–16</pages>
      <url hash="613dcb6a">W17-4801</url>
      <doi>10.18653/v1/W17-4801</doi>
      <attachment type="attachment" hash="693f1b4a">W17-4801.Attachment.zip</attachment>
      <abstract>We describe the design, the setup, and the evaluation results of the DiscoMT 2017 shared task on cross-lingual pronoun prediction. The task asked participants to predict a <a href="https://en.wikipedia.org/wiki/Pronoun">target-language pronoun</a> given a <a href="https://en.wikipedia.org/wiki/Pronoun">source-language pronoun</a> in the context of a sentence. We further provided a lemmatized target-language human-authored translation of the source sentence, and automatic word alignments between the source sentence words and the target-language lemmata. The aim of the task was to predict, for each target-language pronoun placeholder, the word that should replace it from a small, closed set of classes, using any type of information that can be extracted from the entire document. We offered four subtasks, each for a different language pair and translation direction : <a href="https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language">English-to-French</a>, <a href="https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language">English-to-German</a>, German-to-English, and <a href="https://en.wikipedia.org/wiki/Spanish_as_a_second_or_foreign_language">Spanish-to-English</a>. Five teams participated in the shared task, making submissions for all language pairs. The evaluation results show that most participating teams outperformed two strong n-gram-based language model-based baseline systems by a sizable margin.</abstract>
      <bibkey>loaiciga-etal-2017-findings</bibkey>
    </paper>
    <paper id="3">
      <title>Using a Graph-based Coherence Model in Document-Level Machine Translation</title>
      <author><first>Leo</first><last>Born</last></author>
      <author><first>Mohsen</first><last>Mesgar</last></author>
      <author><first>Michael</first><last>Strube</last></author>
      <pages>26–35</pages>
      <url hash="24bc92cd">W17-4803</url>
      <doi>10.18653/v1/W17-4803</doi>
      <abstract>Although <a href="https://en.wikipedia.org/wiki/Coherence_(linguistics)">coherence</a> is an important aspect of any text generation system, it has received little attention in the context of machine translation (MT) so far. We hypothesize that the quality of document-level translation can be improved if MT models take into account the semantic relations among sentences during <a href="https://en.wikipedia.org/wiki/Translation">translation</a>. We integrate the graph-based coherence model proposed by Mesgar and Strube, (2016) with Docent (Hardmeier et al., 2012, Hardmeier, 2014) a document-level machine translation system. The application of this graph-based coherence modeling approach is novel in the context of <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>. We evaluate the coherence model and its effects on the quality of the <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>. The result of our experiments shows that our <a href="https://en.wikipedia.org/wiki/Coherence_(physics)">coherence model</a> slightly improves the quality of translation in terms of the average Meteor score.</abstract>
      <bibkey>born-etal-2017-using</bibkey>
    </paper>
    <paper id="4">
      <title>Treatment of Markup in <a href="https://en.wikipedia.org/wiki/Statistical_machine_translation">Statistical Machine Translation</a></title>
      <author><first>Mathias</first><last>Müller</last></author>
      <pages>36–46</pages>
      <url hash="191698e2">W17-4804</url>
      <doi>10.18653/v1/W17-4804</doi>
      <abstract>We present work on handling <a href="https://en.wikipedia.org/wiki/XML">XML markup</a> in Statistical Machine Translation (SMT). The methods we propose can be used to effectively preserve <a href="https://en.wikipedia.org/wiki/Markup_language">markup</a> (for instance inline formatting or structure) and to place <a href="https://en.wikipedia.org/wiki/Markup_language">markup</a> correctly in a machine-translated segment. We evaluate our approaches with parallel data that naturally contains <a href="https://en.wikipedia.org/wiki/Markup_language">markup</a> or where <a href="https://en.wikipedia.org/wiki/Markup_language">markup</a> was inserted to create synthetic examples. In our experiments, hybrid reinsertion has proven the most accurate method to handle <a href="https://en.wikipedia.org/wiki/Markup_language">markup</a>, while alignment masking and alignment reinsertion should be regarded as viable alternatives. We provide implementations of all the <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">methods</a> described and they are freely available as an open-source framework.</abstract>
      <bibkey>muller-2017-treatment</bibkey>
    </paper>
    <paper id="5">
      <title>A BiLSTM-based System for Cross-lingual Pronoun Prediction<fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case>-based System for Cross-lingual Pronoun Prediction</title>
      <author><first>Sara</first><last>Stymne</last></author>
      <author><first>Sharid</first><last>Loáiciga</last></author>
      <author><first>Fabienne</first><last>Cap</last></author>
      <pages>47–53</pages>
      <url hash="26b6596d">W17-4805</url>
      <doi>10.18653/v1/W17-4805</doi>
      <abstract>We describe the Uppsala system for the 2017 DiscoMT shared task on cross-lingual pronoun prediction. The <a href="https://en.wikipedia.org/wiki/System">system</a> is based on a lower layer of BiLSTMs reading the source and target sentences respectively. Classification is based on the BiLSTM representation of the source and target positions for the <a href="https://en.wikipedia.org/wiki/Pronoun">pronouns</a>. In addition we enrich our system with dependency representations from an <a href="https://en.wikipedia.org/wiki/Parsing">external parser</a> and <a href="https://en.wikipedia.org/wiki/Character_encoding">character representations</a> of the source sentence. We show that these additions perform well for <a href="https://en.wikipedia.org/wiki/German_language">German</a> and <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a> as source languages. Our <a href="https://en.wikipedia.org/wiki/System">system</a> is competitive and is in first or second place for all language pairs.</abstract>
      <bibkey>stymne-etal-2017-bilstm</bibkey>
    </paper>
    <paper id="6">
      <title>Neural Machine Translation for Cross-Lingual Pronoun Prediction</title>
      <author><first>Sebastien</first><last>Jean</last></author>
      <author><first>Stanislas</first><last>Lauly</last></author>
      <author><first>Orhan</first><last>Firat</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <pages>54–57</pages>
      <url hash="3781aa92">W17-4806</url>
      <doi>10.18653/v1/W17-4806</doi>
      <abstract>In this paper we present our systems for the DiscoMT 2017 cross-lingual pronoun prediction shared task. For all four language pairs, we trained a standard attention-based neural machine translation system as well as three variants that incorporate information from the preceding source sentence. We show that our <a href="https://en.wikipedia.org/wiki/System">systems</a>, which are not specifically designed for pronoun prediction and may be used to generate complete sentence translations, generally achieve competitive results on this task.</abstract>
      <bibkey>jean-etal-2017-neural</bibkey>
    </paper>
    <paper id="7">
      <title>Predicting Pronouns with a Convolutional Network and an <a href="https://en.wikipedia.org/wiki/N-gram_model">N-gram Model</a></title>
      <author><first>Christian</first><last>Hardmeier</last></author>
      <pages>58–62</pages>
      <url hash="bc5024ec">W17-4807</url>
      <doi>10.18653/v1/W17-4807</doi>
      <abstract>This paper describes the UU-Hardmeier system submitted to the DiscoMT 2017 shared task on cross-lingual pronoun prediction. The system is an ensemble of <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural networks</a> combined with a source-aware n-gram language model.</abstract>
      <bibkey>hardmeier-2017-predicting</bibkey>
    </paper>
    <paper id="8">
      <title>Cross-Lingual Pronoun Prediction with <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Recurrent Neural Networks</a> v2.0</title>
      <author><first>Juhani</first><last>Luotolahti</last></author>
      <author><first>Jenna</first><last>Kanerva</last></author>
      <author><first>Filip</first><last>Ginter</last></author>
      <pages>63–66</pages>
      <url hash="f3266b9d">W17-4808</url>
      <doi>10.18653/v1/W17-4808</doi>
      <abstract>In this paper we present our <a href="https://en.wikipedia.org/wiki/System">system</a> in the DiscoMT 2017 Shared Task on Crosslingual Pronoun Prediction. Our entry builds on our last year’s success, our system based on deep recurrent neural networks outperformed all the other systems with a clear margin. This year we investigate whether different pre-trained word embeddings can be used to improve the neural systems, and whether the recently published Gated Convolutions outperform the Gated Recurrent Units used last year.</abstract>
      <bibkey>luotolahti-etal-2017-cross</bibkey>
    </paper>
    <paper id="9">
      <title>Combining the output of two coreference resolution systems for two source languages to improve annotation projection</title>
      <author><first>Yulia</first><last>Grishina</last></author>
      <pages>67–72</pages>
      <url hash="471e6bb3">W17-4809</url>
      <doi>10.18653/v1/W17-4809</doi>
      <abstract>Although parallel coreference corpora can to a high degree support the development of SMT systems, there are no large-scale parallel datasets available due to the complexity of the annotation task and the variability in annotation schemes. In this study, we exploit an annotation projection method to combine the output of two coreference resolution systems for two different source languages (English, German) in order to create an annotated corpus for a third language (Russian). We show that our technique is superior to projecting annotations from a single source language, and we provide an in-depth analysis of the projected annotations in order to assess the perspectives of our approach.</abstract>
      <bibkey>grishina-2017-combining</bibkey>
    </paper>
    <paper id="10">
      <title>Discovery of Discourse-Related Language Contrasts through Alignment Discrepancies in English-German Translation<fixed-case>E</fixed-case>nglish-<fixed-case>G</fixed-case>erman Translation</title>
      <author><first>Ekaterina</first><last>Lapshinova-Koltunski</last></author>
      <author><first>Christian</first><last>Hardmeier</last></author>
      <pages>73–81</pages>
      <url hash="91b8cb2a">W17-4810</url>
      <doi>10.18653/v1/W17-4810</doi>
      <abstract>In this paper, we analyse alignment discrepancies for discourse structures in English-German parallel data   sentence pairs, in which discourse structures in target or source texts have no alignment in the corresponding parallel sentences. The discourse-related structures are designed in form of linguistic patterns based on the information delivered by automatic part-of-speech and dependency annotation. In addition to alignment errors (existing structures left unaligned), these alignment discrepancies can be caused by language contrasts or through the phenomena of explicitation and implicitation in the translation process. We propose a new approach including new type of resources for corpus-based language contrast analysis and apply it to study and classify the contrasts found in our English-German parallel corpus. As unaligned discourse structures may also result in the loss of discourse information in the MT training data, we hope to deliver information in support of discourse-aware machine translation (MT).</abstract>
      <bibkey>lapshinova-koltunski-hardmeier-2017-discovery</bibkey>
    </paper>
    <paper id="11">
      <title>Neural Machine Translation with Extended Context</title>
      <author><first>Jörg</first><last>Tiedemann</last></author>
      <author><first>Yves</first><last>Scherrer</last></author>
      <pages>82–92</pages>
      <url hash="d608da85">W17-4811</url>
      <doi>10.18653/v1/W17-4811</doi>
      <abstract>We investigate the use of extended context in attention-based neural machine translation. We base our experiments on translated movie subtitles and discuss the effect of increasing the segments beyond single translation units. We study the use of extended source language context as well as bilingual context extensions. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> learn to distinguish between information from different segments and are surprisingly robust with respect to translation quality. In this pilot study, we observe interesting cross-sentential attention patterns that improve textual coherence in <a href="https://en.wikipedia.org/wiki/Translation_(biology)">translation</a> at least in some selected cases.</abstract>
      <bibkey>tiedemann-scherrer-2017-neural</bibkey>
    </paper>
    <paper id="12">
      <title>Translating Implicit Discourse Connectives Based on Cross-lingual Annotation and Alignment</title>
      <author><first>Hongzheng</first><last>Li</last></author>
      <author><first>Philippe</first><last>Langlais</last></author>
      <author><first>Yaohong</first><last>Jin</last></author>
      <pages>93–98</pages>
      <url hash="a38e86b2">W17-4812</url>
      <doi>10.18653/v1/W17-4812</doi>
      <abstract>Implicit discourse connectives and relations are distributed more widely in Chinese texts, when translating into <a href="https://en.wikipedia.org/wiki/English_language">English</a>, such connectives are usually translated explicitly. Towards Chinese-English MT, in this paper we describe cross-lingual annotation and alignment of dis-course connectives in a parallel corpus, describing related surveys and findings. We then conduct some evaluation experiments to testify the <a href="https://en.wikipedia.org/wiki/Translation">translation of implicit connectives</a> and whether representing implicit connectives explicitly in source language can improve the final <a href="https://en.wikipedia.org/wiki/Translation">translation</a> performance significantly. Preliminary results show it has little improvement by just inserting explicit connectives for implicit relations.</abstract>
      <bibkey>li-etal-2017-translating</bibkey>
    </paper>
    <paper id="14">
      <title>On Integrating Discourse in <a href="https://en.wikipedia.org/wiki/Machine_translation">Machine Translation</a></title>
      <author><first>Karin</first><last>Sim Smith</last></author>
      <pages>110–121</pages>
      <url hash="721d2725">W17-4814</url>
      <doi>10.18653/v1/W17-4814</doi>
      <abstract>As the quality of Machine Translation (MT) improves, research on improving discourse in automatic translations becomes more viable. This has resulted in an increase in the amount of work on <a href="https://en.wikipedia.org/wiki/Discourse">discourse</a> in MT. However many of the existing <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> and <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> have yet to integrate these insights. Part of this is due to the evaluation methodology, based as it is largely on matching to a single reference. At a time when MT is increasingly being used in a <a href="https://en.wikipedia.org/wiki/Pipeline_(software)">pipeline</a> for other tasks, the semantic element of the translation process needs to be properly integrated into the task. Moreover, in order to take MT to another level, it will need to judge output not based on a single reference translation, but based on notions of <a href="https://en.wikipedia.org/wiki/Fluency">fluency</a> and of adequacy   ideally with reference to the source text.</abstract>
      <bibkey>sim-smith-2017-integrating</bibkey>
    </paper>
  </volume>
  <volume id="49">
    <meta>
      <booktitle>Proceedings of the Workshop on Stylistic Variation</booktitle>
      <url hash="a72855d7">W17-49</url>
      <editor><first>Julian</first><last>Brooke</last></editor>
      <editor><first>Thamar</first><last>Solorio</last></editor>
      <editor><first>Moshe</first><last>Koppel</last></editor>
      <doi>10.18653/v1/W17-49</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Copenhagen, Denmark</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="7f4d6e7d">W17-4900</url>
      <bibkey>ws-2017-stylistic</bibkey>
    </frontmatter>
    <paper id="1">
      <title>From Shakespeare to <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> : What are Language Styles all about?<fixed-case>T</fixed-case>witter: What are Language Styles all about?</title>
      <author><first>Wei</first><last>Xu</last></author>
      <pages>1–9</pages>
      <url hash="6331da4e">W17-4901</url>
      <doi>10.18653/v1/W17-4901</doi>
      <abstract>As <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> research is growing and largely driven by the availability of data, we expanded research from news and small-scale dialog corpora to web and social media. User-generated data and <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourcing</a> opened the door for investigating <a href="https://en.wikipedia.org/wiki/Human_language">human language</a> of various styles with more statistical power and real-world applications. In this position / survey paper, I will review and discuss seven language styles that I believe to be important and interesting to study : influential work in the past, challenges at the present, and potential impact for the future.</abstract>
      <bibkey>xu-2017-shakespeare</bibkey>
    </paper>
    <paper id="2">
      <title>Shakespearizing Modern Language Using Copy-Enriched Sequence to Sequence Models</title>
      <author><first>Harsh</first><last>Jhamtani</last></author>
      <author><first>Varun</first><last>Gangal</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <author><first>Eric</first><last>Nyberg</last></author>
      <pages>10–19</pages>
      <url hash="bdc7b44f">W17-4902</url>
      <doi>10.18653/v1/W17-4902</doi>
      <attachment type="attachment" hash="cb761d23">W17-4902.Attachment.zip</attachment>
      <abstract>Variations in <a href="https://en.wikipedia.org/wiki/Writing_style">writing styles</a> are commonly used to adapt the content to a specific context, audience, or purpose. However, applying stylistic variations is still by and large a manual process, and there have been little efforts towards automating it. In this paper we explore automated methods to transform text from <a href="https://en.wikipedia.org/wiki/Modern_English">modern English</a> to <a href="https://en.wikipedia.org/wiki/Old_English">Shakespearean English</a> using an end to end trainable neural model with pointers to enable copy action. To tackle limited amount of parallel data, we pre-train embeddings of words by leveraging external dictionaries mapping Shakespearean words to modern English words as well as additional text. Our methods are able to get a BLEU score of 31 +, an improvement of   6 points above the strongest baseline. We publicly release our code to foster further research in this area.</abstract>
      <bibkey>jhamtani-etal-2017-shakespearizing</bibkey>
      <pwccode url="https://github.com/harsh19/Shakespearizing-Modern-English" additional="false">harsh19/Shakespearizing-Modern-English</pwccode>
    </paper>
    <paper id="3">
      <title>Discovering Stylistic Variations in Distributional Vector Space Models via Lexical Paraphrases</title>
      <author><first>Xing</first><last>Niu</last></author>
      <author><first>Marine</first><last>Carpuat</last></author>
      <pages>20–27</pages>
      <url hash="742c19b5">W17-4903</url>
      <doi>10.18653/v1/W17-4903</doi>
      <abstract>Detecting and analyzing stylistic variation in <a href="https://en.wikipedia.org/wiki/Language">language</a> is relevant to diverse Natural Language Processing applications. In this work, we investigate whether salient dimensions of style variations are embedded in standard distributional vector spaces of word meaning. We hypothesizes that distances between embeddings of lexical paraphrases can help isolate <a href="https://en.wikipedia.org/wiki/Style_(manner_of_address)">style</a> from meaning variations and help identify latent style dimensions. We conduct a qualitative analysis of latent style dimensions, and show the effectiveness of identified style subspaces on a lexical formality prediction task.</abstract>
      <bibkey>niu-carpuat-2017-discovering</bibkey>
    </paper>
    <paper id="4">
      <title>Harvesting Creative Templates for Generating Stylistically Varied Restaurant Reviews</title>
      <author><first>Shereen</first><last>Oraby</last></author>
      <author><first>Sheideh</first><last>Homayon</last></author>
      <author><first>Marilyn</first><last>Walker</last></author>
      <pages>28–36</pages>
      <url hash="6fd0dd27">W17-4904</url>
      <doi>10.18653/v1/W17-4904</doi>
      <abstract>Many of the creative and figurative elements that make language exciting are lost in <a href="https://en.wikipedia.org/wiki/Translation">translation</a> in current natural language generation engines. In this paper, we explore a method to harvest templates from positive and negative reviews in the restaurant domain, with the goal of vastly expanding the types of stylistic variation available to the <a href="https://en.wikipedia.org/wiki/Natural-language_generation">natural language generator</a>. We learn hyperbolic adjective patterns that are representative of the strongly-valenced expressive language commonly used in either positive or negative reviews. We then identify and delexicalize entities, and use <a href="https://en.wikipedia.org/wiki/Heuristic">heuristics</a> to extract generation templates from review sentences. We evaluate the learned templates against more traditional review templates, using subjective measures of convincingness, <a href="https://en.wikipedia.org/wiki/Interest_(emotion)">interestingness</a>, and <a href="https://en.wikipedia.org/wiki/Naturalness_(philosophy)">naturalness</a>. Our results show that the learned <a href="https://en.wikipedia.org/wiki/Template_(word_processing)">templates</a> score highly on these measures. Finally, we analyze the linguistic categories that characterize the learned positive and negative templates. We plan to use the learned <a href="https://en.wikipedia.org/wiki/Template_(word_processing)">templates</a> to improve the conversational style of dialogue systems in the restaurant domain.</abstract>
      <bibkey>oraby-etal-2017-harvesting</bibkey>
    </paper>
    <paper id="6">
      <title>Deep Learning : Detecting Metaphoricity in Adjective-Noun Pairs</title>
      <author><first>Yuri</first><last>Bizzoni</last></author>
      <author><first>Stergios</first><last>Chatzikyriakidis</last></author>
      <author><first>Mehdi</first><last>Ghanimifard</last></author>
      <pages>43–52</pages>
      <url hash="ff4e570a">W17-4906</url>
      <doi>10.18653/v1/W17-4906</doi>
      <abstract>Metaphor is one of the most studied and widespread figures of speech and an essential element of individual style. In this paper we look at metaphor identification in Adjective-Noun pairs. We show that using a single <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> combined with pre-trained vector embeddings can outperform the <a href="https://en.wikipedia.org/wiki/State_of_the_art">state of the art</a> in terms of <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>. In specific, the approach presented in this paper is based on two ideas : a) <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> via using pre-trained vectors representing adjective noun pairs, and b) a <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> as a model of composition that predicts a metaphoricity score as output. We present several different <a href="https://en.wikipedia.org/wiki/Systems_architecture">architectures</a> for our <a href="https://en.wikipedia.org/wiki/System">system</a> and evaluate their performances. Variations on dataset size and on the kinds of <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> are also investigated. We show considerable improvement over the previous <a href="https://en.wikipedia.org/wiki/Statistical_inference">approaches</a> both in terms of <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and w.r.t the size of <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">annotated training data</a>.</abstract>
      <bibkey>bizzoni-etal-2017-deep</bibkey>
    </paper>
    <paper id="7">
      <title>Authorship Attribution with <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Networks</a> and POS-Eliding<fixed-case>POS</fixed-case>-Eliding</title>
      <author><first>Julian</first><last>Hitschler</last></author>
      <author><first>Esther</first><last>van den Berg</last></author>
      <author><first>Ines</first><last>Rehbein</last></author>
      <pages>53–58</pages>
      <url hash="f7c7ea45">W17-4907</url>
      <doi>10.18653/v1/W17-4907</doi>
      <abstract>We use a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a> to perform authorship identification on a very homogeneous dataset of scientific publications. In order to investigate the effect of domain biases, we obscure words below a certain frequency threshold, retaining only their POS-tags. This <a href="https://en.wikipedia.org/wiki/Procedure_(term)">procedure</a> improves test performance due to better <a href="https://en.wikipedia.org/wiki/Generalization">generalization</a> on unseen data. Using our <a href="https://en.wikipedia.org/wiki/Methodology">method</a>, we are able to predict the authors of scientific publications in the same discipline at levels well above chance.</abstract>
      <bibkey>hitschler-etal-2017-authorship</bibkey>
    </paper>
    <paper id="8">
      <title>Topic and audience effects on distinctively Scottish vocabulary usage in Twitter data<fixed-case>S</fixed-case>cottish vocabulary usage in <fixed-case>T</fixed-case>witter data</title>
      <author><first>Philippa</first><last>Shoemark</last></author>
      <author><first>James</first><last>Kirby</last></author>
      <author><first>Sharon</first><last>Goldwater</last></author>
      <pages>59–68</pages>
      <url hash="e4dc0252">W17-4908</url>
      <doi>10.18653/v1/W17-4908</doi>
      <abstract>Sociolinguistic research suggests that speakers modulate their language style in response to their audience. Similar effects have recently been claimed to occur in the informal written context of <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>, with users choosing less region-specific and non-standard vocabulary when addressing larger audiences. However, these studies have not carefully controlled for the possible confound of topic : that is, tweets addressed to a broad audience might also tend towards topics that engender a more <a href="https://en.wikipedia.org/wiki/Style_(manner_of_address)">formal style</a>. In addition, it is not clear to what extent previous results generalize to different samples of users. Using mixed-effects models, we show that audience and topic have independent effects on the rate of distinctively Scottish usage in two demographically distinct Twitter user samples. However, not all effects are consistent between the two groups, underscoring the importance of replicating studies on distinct user samples before drawing strong conclusions from social media data.</abstract>
      <bibkey>shoemark-etal-2017-topic</bibkey>
    </paper>
    <paper id="9">
      <title>Differences in type-token ratio and part-of-speech frequencies in male and female Russian written texts<fixed-case>R</fixed-case>ussian written texts</title>
      <author><first>Tatiana</first><last>Litvinova</last></author>
      <author><first>Pavel</first><last>Seredin</last></author>
      <author><first>Olga</first><last>Litvinova</last></author>
      <author><first>Olga</first><last>Zagorovskaya</last></author>
      <pages>69–73</pages>
      <url hash="4f2753e2">W17-4909</url>
      <doi>10.18653/v1/W17-4909</doi>
      <abstract>The differences in the frequencies of some parts of speech (POS), particularly <a href="https://en.wikipedia.org/wiki/Function_word">function words</a>, and <a href="https://en.wikipedia.org/wiki/Lexical_diversity">lexical diversity</a> in male and female speech have been pointed out in a number of papers. The <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> using exclusively context-independent parameters have proved to be highly effective. However, there are still issues that have to be addressed as a lot of studies are performed for <a href="https://en.wikipedia.org/wiki/English_language">English</a> and the genre and topic of texts is sometimes neglected. The aim of this paper is to investigate the association between context-independent parameters of Russian written texts and the gender of their authors and to design predictive re-gression models. A number of correlations were found. The obtained data is in good agreement with the results obtained for other languages. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> based on 5 parameters with the highest <a href="https://en.wikipedia.org/wiki/Correlation_and_dependence">correlation coefficients</a> was designed.</abstract>
      <bibkey>litvinova-etal-2017-differences</bibkey>
    </paper>
    <paper id="10">
      <title>Modeling Communicative Purpose with Functional Style : Corpus and Features for German Genre and Register Analysis<fixed-case>G</fixed-case>erman Genre and Register Analysis</title>
      <author><first>Thomas</first><last>Haider</last></author>
      <author><first>Alexis</first><last>Palmer</last></author>
      <pages>74–84</pages>
      <url hash="1398d70a">W17-4910</url>
      <doi>10.18653/v1/W17-4910</doi>
      <abstract>While there is wide acknowledgement in NLP of the utility of document characterization by genre, it is quite difficult to determine a definitive set of <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">features</a> or even a comprehensive list of <a href="https://en.wikipedia.org/wiki/Genre">genres</a>. This paper addresses both issues. First, with <a href="https://en.wikipedia.org/wiki/Prototype_semantics">prototype semantics</a>, we develop a hierarchical taxonomy of discourse functions. We implement the <a href="https://en.wikipedia.org/wiki/Taxonomy_(biology)">taxonomy</a> by developing a new text genre corpus of contemporary German to perform a text based comparative register analysis. Second, we extract a host of style features, both deep and shallow, aiming beyond linguistically motivated features at situational correlates in texts. The feature sets are used for supervised text genre classification, on which our models achieve high <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>. The combination of the corpus typology and feature sets allows us to characterize types of communicative purpose in a comparative setup, by qualitative interpretation of style feature loadings of a regularized discriminant analysis. Finally, to determine the dependence of genre on topics (which are arguably the distinguishing factor of sub-genre), we compare and combine our style models with Latent Dirichlet Allocation features across different corpus settings with unstable topics.</abstract>
      <bibkey>haider-palmer-2017-modeling</bibkey>
    </paper>
    <paper id="11">
      <title>Stylistic Variation in Television Dialogue for Natural Language Generation</title>
      <author><first>Grace</first><last>Lin</last></author>
      <author><first>Marilyn</first><last>Walker</last></author>
      <pages>85–93</pages>
      <url hash="74e137b2">W17-4911</url>
      <doi>10.18653/v1/W17-4911</doi>
      <abstract>Conversation is a critical component of <a href="https://en.wikipedia.org/wiki/Storytelling">storytelling</a>, where key information is often revealed by what / how a character says it. We focus on the issue of character voice and build stylistic models with <a href="https://en.wikipedia.org/wiki/Linguistic_description">linguistic features</a> related to <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language generation decisions</a>. Using a dialogue corpus of the television series, The <a href="https://en.wikipedia.org/wiki/The_Big_Bang_Theory">Big Bang Theory</a>, we apply <a href="https://en.wikipedia.org/wiki/Content_analysis">content analysis</a> to extract relevant linguistic features to build character-based stylistic models, and we test the model-fit through an user perceptual experiment with Amazon’s Mechanical Turk. The results are encouraging in that human subjects tend to perceive the generated utterances as being more similar to the character they are modeled on, than to another random character.</abstract>
      <bibkey>lin-walker-2017-stylistic</bibkey>
    </paper>
    <paper id="12">
      <title>Controlling Linguistic Style Aspects in Neural Language Generation</title>
      <author><first>Jessica</first><last>Ficler</last></author>
      <author><first>Yoav</first><last>Goldberg</last></author>
      <pages>94–104</pages>
      <url hash="19944bd8">W17-4912</url>
      <doi>10.18653/v1/W17-4912</doi>
      <abstract>Most work on neural natural language generation (NNLG) focus on controlling the content of the generated text. We experiment with controling several stylistic aspects of the generated text, in addition to its content. The method is based on conditioned RNN language model, where the desired content as well as the stylistic parameters serve as conditioning contexts. We demonstrate the approach on the movie reviews domain and show that it is successful in generating coherent sentences corresponding to the required <a href="https://en.wikipedia.org/wiki/Style_(sociolinguistics)">linguistic style</a> and content.</abstract>
      <bibkey>ficler-goldberg-2017-controlling</bibkey>
    </paper>
    <paper id="13">
      <title>Approximating Style by N-gram-based Annotation</title>
      <author><first>Melanie</first><last>Andresen</last></author>
      <author><first>Heike</first><last>Zinsmeister</last></author>
      <pages>105–115</pages>
      <url hash="a3023263">W17-4913</url>
      <doi>10.18653/v1/W17-4913</doi>
      <abstract>The concept of <a href="https://en.wikipedia.org/wiki/Style_(visual_arts)">style</a> is much debated in theoretical as well as empirical terms. From an empirical perspective, the key question is how to operationalize <a href="https://en.wikipedia.org/wiki/Style_(manner_of_address)">style</a> and thus make it accessible for <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a> and <a href="https://en.wikipedia.org/wiki/Quantification_(science)">quantification</a>. In <a href="https://en.wikipedia.org/wiki/Authorship_attribution">authorship attribution</a>, many different approaches have successfully resolved this issue at the cost of <a href="https://en.wikipedia.org/wiki/Interpretability">linguistic interpretability</a> : The resulting <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> may be able to distinguish one <a href="https://en.wikipedia.org/wiki/Variety_(linguistics)">language variety</a> from the other, but do not give us much information on their distinctive linguistic properties. We approach the issue of interpreting stylistic features by extracting linear and syntactic n-grams that are distinctive for a <a href="https://en.wikipedia.org/wiki/Variety_(linguistics)">language variety</a>. We present a study that exemplifies this process by a comparison of the German academic languages of linguistics and <a href="https://en.wikipedia.org/wiki/German_literature">literary studies</a>. Overall, our findings show that distinctive <a href="https://en.wikipedia.org/wiki/N-gram">n-grams</a> can be related to linguistic categories. The results suggest that the <a href="https://en.wikipedia.org/wiki/Style_(manner_of_address)">style</a> of German literary studies is characterized by nominal structures and the style of linguistics by <a href="https://en.wikipedia.org/wiki/Linguistic_description">verbal ones</a>.</abstract>
      <bibkey>andresen-zinsmeister-2017-approximating</bibkey>
    </paper>
    <paper id="14">
      <title>Assessing the Stylistic Properties of Neurally Generated Text in Authorship Attribution</title>
      <author><first>Enrique</first><last>Manjavacas</last></author>
      <author><first>Jeroen</first><last>De Gussem</last></author>
      <author><first>Walter</first><last>Daelemans</last></author>
      <author><first>Mike</first><last>Kestemont</last></author>
      <pages>116–125</pages>
      <url hash="54aa787c">W17-4914</url>
      <doi>10.18653/v1/W17-4914</doi>
      <abstract>Recent applications of neural language models have led to an increased interest in the <a href="https://en.wikipedia.org/wiki/Natural-language_generation">automatic generation of natural language</a>. However impressive, the evaluation of neurally generated text has so far remained rather informal and anecdotal. Here, we present an attempt at the systematic assessment of one aspect of the quality of neurally generated text. We focus on a specific aspect of neural language generation : its ability to reproduce authorial writing styles. Using established <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> for <a href="https://en.wikipedia.org/wiki/Attribution_(psychology)">authorship attribution</a>, we empirically assess the <a href="https://en.wikipedia.org/wiki/Style_(visual_arts)">stylistic qualities</a> of neurally generated text. In comparison to conventional <a href="https://en.wikipedia.org/wiki/Language_model">language models</a>, neural models generate fuzzier text, that is relatively harder to attribute correctly. Nevertheless, our results also suggest that neurally generated text offers more valuable perspectives for the augmentation of training data.</abstract>
      <bibkey>manjavacas-etal-2017-assessing</bibkey>
    </paper>
  </volume>
  <volume id="50">
    <meta>
      <booktitle>Proceedings of the 12th Workshop on Innovative Use of <fixed-case>NLP</fixed-case> for Building Educational Applications</booktitle>
      <url hash="2109e9ee">W17-50</url>
      <editor><first>Joel</first><last>Tetreault</last></editor>
      <editor><first>Jill</first><last>Burstein</last></editor>
      <editor><first>Claudia</first><last>Leacock</last></editor>
      <editor><first>Helen</first><last>Yannakoudakis</last></editor>
      <doi>10.18653/v1/W17-50</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Copenhagen, Denmark</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="656e8ef3">W17-5000</url>
      <bibkey>ws-2017-innovative</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Question Difficulty   How to Estimate Without Norming, How to Use for Automated Grading</title>
      <author><first>Ulrike</first><last>Padó</last></author>
      <pages>1–10</pages>
      <url hash="96189a4c">W17-5001</url>
      <doi>10.18653/v1/W17-5001</doi>
      <abstract>Question difficulty estimates guide test creation, but are too costly for small-scale testing. We empirically verify that <a href="https://en.wikipedia.org/wiki/Bloom’s_taxonomy">Bloom’s Taxonomy</a>, a standard tool for difficulty estimation during question creation, reliably predicts question difficulty observed after testing in a short-answer corpus. We also find that difficulty is mirrored in the amount of variation in student answers, which can be computed before <a href="https://en.wikipedia.org/wiki/Grading_in_education">grading</a>. We show that question difficulty and its approximations are useful for automated grading, allowing us to identify the optimal feature set for <a href="https://en.wikipedia.org/wiki/Grading_in_education">grading</a> each question even in an unseen-question setting.<i>automated grading</i>, allowing us to identify the optimal feature set for grading each question even in an unseen-question setting. </abstract>
      <bibkey>pado-2017-question</bibkey>
    </paper>
    <paper id="2">
      <title>Combining CNNs and Pattern Matching for Question Interpretation in a Virtual Patient Dialogue System<fixed-case>CNN</fixed-case>s and Pattern Matching for Question Interpretation in a Virtual Patient Dialogue System</title>
      <author><first>Lifeng</first><last>Jin</last></author>
      <author><first>Michael</first><last>White</last></author>
      <author><first>Evan</first><last>Jaffe</last></author>
      <author><first>Laura</first><last>Zimmerman</last></author>
      <author><first>Douglas</first><last>Danforth</last></author>
      <pages>11–21</pages>
      <url hash="cfa68374">W17-5002</url>
      <doi>10.18653/v1/W17-5002</doi>
      <abstract>For <a href="https://en.wikipedia.org/wiki/Medical_school">medical students</a>, virtual patient dialogue systems can provide useful training opportunities without the cost of employing actors to portray standardized patients. This work utilizes word- and character-based convolutional neural networks (CNNs) for question identification in a virtual patient dialogue system, outperforming a strong word- and character-based logistic regression baseline. While the CNNs perform well given sufficient training data, the best <a href="https://en.wikipedia.org/wiki/System">system</a> performance is ultimately achieved by combining CNNs with a hand-crafted pattern matching system that is robust to label sparsity, providing a 10 % boost in <a href="https://en.wikipedia.org/wiki/System">system accuracy</a> and an error reduction of 47 % as compared to the pattern-matching system alone.</abstract>
      <bibkey>jin-etal-2017-combining-cnns</bibkey>
    </paper>
    <paper id="3">
      <title>Continuous fluency tracking and the challenges of varying text complexity</title>
      <author><first>Beata</first><last>Beigman Klebanov</last></author>
      <author><first>Anastassia</first><last>Loukina</last></author>
      <author><first>John</first><last>Sabatini</last></author>
      <author><first>Tenaha</first><last>O’Reilly</last></author>
      <pages>22–32</pages>
      <url hash="6de32a9a">W17-5003</url>
      <doi>10.18653/v1/W17-5003</doi>
      <abstract>This paper is a preliminary report on using text complexity measurement in the service of a new <a href="https://en.wikipedia.org/wiki/Educational_software">educational application</a>. We describe a reading intervention where a child takes turns reading a book aloud with a virtual reading partner. Our ultimate goal is to provide meaningful feedback to the parent or the teacher by continuously tracking the child’s improvement in <a href="https://en.wikipedia.org/wiki/Literacy">reading fluency</a>. We show that this would not be a simple endeavor, due to an intricate relationship between text complexity from the point of view of <a href="https://en.wikipedia.org/wiki/Sentence_processing">comprehension</a> and <a href="https://en.wikipedia.org/wiki/Reading_rate">reading rate</a>.</abstract>
      <bibkey>beigman-klebanov-etal-2017-continuous</bibkey>
    </paper>
    <paper id="4">
      <title>Auxiliary Objectives for Neural Error Detection Models</title>
      <author><first>Marek</first><last>Rei</last></author>
      <author><first>Helen</first><last>Yannakoudakis</last></author>
      <pages>33–43</pages>
      <url hash="e568a502">W17-5004</url>
      <doi>10.18653/v1/W17-5004</doi>
      <abstract>We investigate the utility of different auxiliary objectives and training strategies within a neural sequence labeling approach to <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error detection</a> in learner writing. Auxiliary costs provide the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> with additional linguistic information, allowing it to learn general-purpose compositional features that can then be exploited for other objectives. Our experiments show that a joint learning approach trained with parallel labels on in-domain data improves performance over the previous best <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error detection system</a>. While the resulting <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> has the same number of parameters, the additional objectives allow <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> to be optimised more efficiently and achieve better performance.</abstract>
      <bibkey>rei-yannakoudakis-2017-auxiliary</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/fce">FCE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="5">
      <title>Linked Data for Language-Learning Applications</title>
      <author><first>Robyn</first><last>Loughnane</last></author>
      <author><first>Kate</first><last>McCurdy</last></author>
      <author><first>Peter</first><last>Kolb</last></author>
      <author><first>Stefan</first><last>Selent</last></author>
      <pages>44–51</pages>
      <url hash="689966d6">W17-5005</url>
      <doi>10.18653/v1/W17-5005</doi>
      <abstract>The use of <a href="https://en.wikipedia.org/wiki/Linked_data">linked data</a> within language-learning applications is an open research question. A research prototype is presented that applies linked-data principles to store linguistic annotation generated from language-learning content using a variety of NLP tools. The result is a <a href="https://en.wikipedia.org/wiki/Database">database</a> that links learning content, <a href="https://en.wikipedia.org/wiki/Annotation">linguistic annotation</a> and <a href="https://en.wikipedia.org/wiki/Open-source_software">open-source resources</a>, on top of which a diverse range of tools for language-learning applications can be built.</abstract>
      <bibkey>loughnane-etal-2017-linked</bibkey>
    </paper>
    <paper id="6">
      <title>Predicting Specificity in Classroom Discussion</title>
      <author><first>Luca</first><last>Lugini</last></author>
      <author><first>Diane</first><last>Litman</last></author>
      <pages>52–61</pages>
      <url hash="5f20ca8a">W17-5006</url>
      <doi>10.18653/v1/W17-5006</doi>
      <abstract>High quality classroom discussion is important to student development, enhancing abilities to express claims, reason about other students’ claims, and retain information for longer periods of time. Previous small-scale studies have shown that one indicator of classroom discussion quality is <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">specificity</a>. In this paper we tackle the problem of predicting specificity for classroom discussions. We propose several <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> and feature sets capable of outperforming the state of the art in specificity prediction. Additionally, we provide a set of meaningful, interpretable features that can be used to analyze classroom discussions at a pedagogical level.</abstract>
      <bibkey>lugini-litman-2017-predicting</bibkey>
    </paper>
    <paper id="7">
      <title>A Report on the 2017 Native Language Identification Shared Task</title>
      <author><first>Shervin</first><last>Malmasi</last></author>
      <author><first>Keelan</first><last>Evanini</last></author>
      <author><first>Aoife</first><last>Cahill</last></author>
      <author><first>Joel</first><last>Tetreault</last></author>
      <author><first>Robert</first><last>Pugh</last></author>
      <author><first>Christopher</first><last>Hamill</last></author>
      <author><first>Diane</first><last>Napolitano</last></author>
      <author><first>Yao</first><last>Qian</last></author>
      <pages>62–75</pages>
      <url hash="f41b153b">W17-5007</url>
      <doi>10.18653/v1/W17-5007</doi>
      <abstract>Native Language Identification (NLI) is the task of automatically identifying the native language (L1) of an individual based on their language production in a learned language. It is typically framed as a classification task where the set of <a href="https://en.wikipedia.org/wiki/L1_(protein)">L1s</a> is known a priori. Two previous shared tasks on NLI have been organized where the aim was to identify the L1 of learners of <a href="https://en.wikipedia.org/wiki/English_language">English</a> based on essays (2013) and spoken responses (2016) they provided during a standardized assessment of academic English proficiency. The 2017 shared task combines the inputs from the two prior tasks for the first time. There are three tracks : <a href="https://en.wikipedia.org/wiki/Natural_language_understanding">NLI</a> on the essay only, <a href="https://en.wikipedia.org/wiki/Natural_language_understanding">NLI</a> on the spoken response only (based on a transcription of the response and i-vector acoustic features), and <a href="https://en.wikipedia.org/wiki/Natural_language_understanding">NLI</a> using both responses. We believe this makes for a more interesting <a href="https://en.wikipedia.org/wiki/Task_(computing)">shared task</a> while building on the methods and results from the previous two <a href="https://en.wikipedia.org/wiki/Task_(computing)">shared tasks</a>. In this paper, we report the results of the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">shared task</a>. A total of 19 teams competed across the three different sub-tasks. The fusion track showed that combining the written and spoken responses provides a large boost in <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">prediction accuracy</a>. Multiple classifier systems (e.g. ensembles and meta-classifiers) were the most effective in all tasks, with most based on traditional <a href="https://en.wikipedia.org/wiki/Classifier_(linguistics)">classifiers</a> (e.g. SVMs) with lexical / syntactic features.</abstract>
      <bibkey>malmasi-etal-2017-report</bibkey>
    </paper>
    <paper id="8">
      <title>Evaluation of Automatically Generated Pronoun Reference Questions</title>
      <author><first>Arief Yudha</first><last>Satria</last></author>
      <author><first>Takenobu</first><last>Tokunaga</last></author>
      <pages>76–85</pages>
      <url hash="9b6ff513">W17-5008</url>
      <doi>10.18653/v1/W17-5008</doi>
      <abstract>This study provides a detailed analysis of evaluation of English pronoun reference questions which are created automatically by machine. Pronoun reference questions are multiple choice questions that ask test takers to choose an antecedent of a target pronoun in a reading passage from four options. The <a href="https://en.wikipedia.org/wiki/Evaluation">evaluation</a> was performed from two perspectives : the perspective of English teachers and that of English learners. Item analysis suggests that machine-generated questions achieve comparable quality with <a href="https://en.wikipedia.org/wiki/Questionnaire">human-made questions</a>. Correlation analysis revealed a strong correlation between the scores of machine-generated questions and that of human-made questions.</abstract>
      <bibkey>satria-tokunaga-2017-evaluation</bibkey>
    </paper>
    <paper id="10">
      <title>Collecting fluency corrections for spoken learner English<fixed-case>E</fixed-case>nglish</title>
      <author><first>Andrew</first><last>Caines</last></author>
      <author><first>Emma</first><last>Flint</last></author>
      <author><first>Paula</first><last>Buttery</last></author>
      <pages>91–100</pages>
      <url hash="94509f43">W17-5010</url>
      <doi>10.18653/v1/W17-5010</doi>
      <abstract>We present crowdsourced collection of <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error annotations</a> for <a href="https://en.wikipedia.org/wiki/Transcription_(linguistics)">transcriptions</a> of spoken learner English. Our emphasis in <a href="https://en.wikipedia.org/wiki/Data_collection">data collection</a> is on fluency corrections, a more complete correction than has traditionally been aimed for in grammatical error correction research (GEC). Fluency corrections require improvements to the text, taking discourse and utterance level semantics into account : the result is a more naturalistic, holistic version of the original. We propose that this shifted emphasis be reflected in a new name for the task : ‘holistic error correction’ (HEC). We analyse crowdworker behaviour in <a href="https://en.wikipedia.org/wiki/Higher_Education_Commission_(Pakistan)">HEC</a> and conclude that the method is useful with certain amendments for future work.</abstract>
      <bibkey>caines-etal-2017-collecting</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2014-shared-task-grammatical-error">CoNLL-2014 Shared Task: Grammatical Error Correction</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/fce">FCE</pwcdataset>
    </paper>
    <paper id="12">
      <title>An Investigation into the Pedagogical Features of Documents</title>
      <author><first>Emily</first><last>Sheng</last></author>
      <author><first>Prem</first><last>Natarajan</last></author>
      <author><first>Jonathan</first><last>Gordon</last></author>
      <author><first>Gully</first><last>Burns</last></author>
      <pages>109–120</pages>
      <url hash="f19e0aa0">W17-5012</url>
      <doi>10.18653/v1/W17-5012</doi>
      <abstract>Characterizing the content of a technical document in terms of its learning utility can be useful for applications related to <a href="https://en.wikipedia.org/wiki/Education">education</a>, such as generating reading lists from large collections of documents. We refer to this learning utility as the pedagogical value of the document to the learner. While pedagogical value is an important concept that has been studied extensively within the education domain, there has been little work exploring it from a computational, i.e., natural language processing (NLP), perspective. To allow a computational exploration of this concept, we introduce the notion of pedagogical roles of documents (e.g., <a href="https://en.wikipedia.org/wiki/Tutorial">Tutorial</a> and Survey) as an intermediary component for the study of pedagogical value. Given the lack of available corpora for our exploration, we create the first annotated corpus of pedagogical roles and use it to test baseline techniques for automatic prediction of such <a href="https://en.wikipedia.org/wiki/Role">roles</a>.</abstract>
      <bibkey>sheng-etal-2017-investigation</bibkey>
    </paper>
    <paper id="13">
      <title>Combining Multiple Corpora for Readability Assessment for People with Cognitive Disabilities</title>
      <author><first>Victoria</first><last>Yaneva</last></author>
      <author><first>Constantin</first><last>Orăsan</last></author>
      <author><first>Richard</first><last>Evans</last></author>
      <author><first>Omid</first><last>Rohanian</last></author>
      <pages>121–132</pages>
      <url hash="77e7d74f">W17-5013</url>
      <doi>10.18653/v1/W17-5013</doi>
      <abstract>Given the lack of large user-evaluated corpora in disability-related NLP research (e.g. text simplification or readability assessment for people with cognitive disabilities), the question of choosing suitable training data for NLP models is not straightforward. The use of large generic corpora may be problematic because such <a href="https://en.wikipedia.org/wiki/Data">data</a> may not reflect the needs of the target population. The use of the available user-evaluated corpora may be problematic because these <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> are not large enough to be used as training data. In this paper we explore a third approach, in which a large generic corpus is combined with a smaller population-specific corpus to train a <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> which is evaluated using two sets of unseen user-evaluated data. One of these <a href="https://en.wikipedia.org/wiki/Set_(mathematics)">sets</a>, the ASD Comprehension corpus, is developed for the purposes of this study and made freely available. We explore the effects of the size and type of the training data used on the performance of the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a>, and the effects of the type of the unseen test datasets on the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> performance.</abstract>
      <bibkey>yaneva-etal-2017-combining</bibkey>
    </paper>
    <paper id="14">
      <title>Automatic Extraction of High-Quality Example Sentences for Word Learning Using a <a href="https://en.wikipedia.org/wiki/Determinantal_point_process">Determinantal Point Process</a></title>
      <author><first>Arseny</first><last>Tolmachev</last></author>
      <author><first>Sadao</first><last>Kurohashi</last></author>
      <pages>133–142</pages>
      <url hash="4b8a0a8b">W17-5014</url>
      <doi>10.18653/v1/W17-5014</doi>
      <attachment type="attachment" hash="e7ca3c38">W17-5014.Attachment.zip</attachment>
      <abstract>Flashcard systems are effective tools for learning words but have their limitations in teaching word usage. To overcome this problem, we propose a novel flashcard system that shows a new example sentence on each repetition. This <a href="https://en.wikipedia.org/wiki/Extension_(semantics)">extension</a> requires high-quality example sentences, automatically extracted from a huge corpus. To do this, we use a <a href="https://en.wikipedia.org/wiki/Determinantal_point_process">Determinantal Point Process</a> which scales well to large data and allows to naturally represent sentence similarity and quality as <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>. Our human evaluation experiment on <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese language</a> indicates that the proposed method successfully extracted high-quality example sentences.</abstract>
      <bibkey>tolmachev-kurohashi-2017-automatic</bibkey>
    </paper>
    <paper id="16">
      <title>An Error-Oriented Approach to Word Embedding Pre-Training</title>
      <author><first>Youmna</first><last>Farag</last></author>
      <author><first>Marek</first><last>Rei</last></author>
      <author><first>Ted</first><last>Briscoe</last></author>
      <pages>149–158</pages>
      <url hash="cc5cd881">W17-5016</url>
      <doi>10.18653/v1/W17-5016</doi>
      <abstract>We propose a novel word embedding pre-training approach that exploits writing errors in learners’ scripts. We compare our method to previous models that tune the embeddings based on script scores and the discrimination between correct and corrupt word contexts in addition to the generic commonly-used embeddings pre-trained on large corpora. The comparison is achieved by using the aforementioned models to bootstrap a <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> that learns to predict a holistic score for <a href="https://en.wikipedia.org/wiki/Scripting_language">scripts</a>. Furthermore, we investigate augmenting our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> with <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error corrections</a> and monitor the impact on performance. Our results show that our error-oriented approach outperforms other comparable ones which is further demonstrated when training on more data. Additionally, extending the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> with corrections provides further performance gains when data sparsity is an issue.</abstract>
      <bibkey>farag-etal-2017-error</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/fce">FCE</pwcdataset>
    </paper>
    <paper id="17">
      <title>Investigating neural architectures for short answer scoring</title>
      <author><first>Brian</first><last>Riordan</last></author>
      <author><first>Andrea</first><last>Horbach</last></author>
      <author><first>Aoife</first><last>Cahill</last></author>
      <author><first>Torsten</first><last>Zesch</last></author>
      <author><first>Chong Min</first><last>Lee</last></author>
      <pages>159–168</pages>
      <url hash="e6df53c3">W17-5017</url>
      <doi>10.18653/v1/W17-5017</doi>
      <abstract>Neural approaches to <a href="https://en.wikipedia.org/wiki/Automated_essay_scoring">automated essay scoring</a> have recently shown state-of-the-art performance. The automated essay scoring task typically involves a broad notion of writing quality that encompasses <a href="https://en.wikipedia.org/wiki/Content_(media)">content</a>, <a href="https://en.wikipedia.org/wiki/Grammar">grammar</a>, <a href="https://en.wikipedia.org/wiki/Organization">organization</a>, and <a href="https://en.wikipedia.org/wiki/Convention_(norm)">conventions</a>. This differs from the short answer content scoring task, which focuses on content accuracy. The inputs to neural essay scoring models   ngrams and embeddings   are arguably well-suited to evaluate content in short answer scoring tasks. We investigate how several basic neural approaches similar to those used for automated essay scoring perform on short answer scoring. We show that neural architectures can outperform a strong non-neural baseline, but performance and optimal parameter settings vary across the more diverse types of prompts typical of short answer scoring.</abstract>
      <bibkey>riordan-etal-2017-investigating</bibkey>
    </paper>
    <paper id="18">
      <title>Human and Automated CEFR-based Grading of Short Answers<fixed-case>CEFR</fixed-case>-based Grading of Short Answers</title>
      <author><first>Anaïs</first><last>Tack</last></author>
      <author><first>Thomas</first><last>François</last></author>
      <author><first>Sophie</first><last>Roekhaut</last></author>
      <author><first>Cédrick</first><last>Fairon</last></author>
      <pages>169–179</pages>
      <url hash="2f2b53b6">W17-5018</url>
      <doi>10.18653/v1/W17-5018</doi>
      <abstract>This paper is concerned with the task of automatically assessing the written proficiency level of non-native (L2) learners of <a href="https://en.wikipedia.org/wiki/English_language">English</a>. Drawing on previous research on automated L2 writing assessment following the Common European Framework of Reference for Languages (CEFR), we investigate the possibilities and difficulties of deriving the CEFR level from short answers to open-ended questions, which has not yet been subjected to numerous studies up to date. The object of our study is twofold : to examine the intricacy involved with both human and automated CEFR-based grading of short answers. On the one hand, we describe the compilation of a learner corpus of short answers graded with CEFR levels by three certified Cambridge examiners. We mainly observe that, although the shortness of the answers is reported as undermining a clear-cut evaluation, the length of the answer does not necessarily correlate with inter-examiner disagreement. On the other hand, we explore the development of a soft-voting system for the automated CEFR-based grading of short answers and draw tentative conclusions about its use in a computer-assisted testing (CAT) setting.</abstract>
      <bibkey>tack-etal-2017-human</bibkey>
    </paper>
    <paper id="19">
      <title>GEC into the future : Where are we going and how do we get there?<fixed-case>GEC</fixed-case> into the future: Where are we going and how do we get there?</title>
      <author><first>Keisuke</first><last>Sakaguchi</last></author>
      <author><first>Courtney</first><last>Napoles</last></author>
      <author><first>Joel</first><last>Tetreault</last></author>
      <pages>180–187</pages>
      <url hash="1080199b">W17-5019</url>
      <doi>10.18653/v1/W17-5019</doi>
      <abstract>The field of grammatical error correction (GEC) has made tremendous bounds in the last ten years, but new questions and obstacles are revealing themselves. In this position paper, we discuss the issues that need to be addressed and provide recommendations for the field to continue to make progress, and propose a new shared task. We invite suggestions and critiques from the audience to make the new shared task a community-driven venture.</abstract>
      <bibkey>sakaguchi-etal-2017-gec</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/fce">FCE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/jfleg">JFLEG</pwcdataset>
    </paper>
    <paper id="20">
      <title>Detecting Off-topic Responses to Visual Prompts</title>
      <author><first>Marek</first><last>Rei</last></author>
      <pages>188–197</pages>
      <url hash="3632bc4d">W17-5020</url>
      <doi>10.18653/v1/W17-5020</doi>
      <abstract>Automated methods for essay scoring have made great progress in recent years, achieving accuracies very close to human annotators. However, a known weakness of such automated scorers is not taking into account the semantic relevance of the submitted text. While there is existing work on detecting answer relevance given a textual prompt, very little previous research has been done to incorporate visual writing prompts. We propose a neural architecture and several extensions for detecting off-topic responses to visual prompts and evaluate it on a dataset of texts written by <a href="https://en.wikipedia.org/wiki/Language_acquisition">language learners</a>.</abstract>
      <bibkey>rei-2017-detecting</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/flickr30k">Flickr30k</pwcdataset>
    </paper>
    <paper id="21">
      <title>Combining Textual and Speech Features in the NLI Task Using State-of-the-Art Machine Learning Techniques<fixed-case>NLI</fixed-case> Task Using State-of-the-Art Machine Learning Techniques</title>
      <author><first>Pavel</first><last>Ircing</last></author>
      <author><first>Jan</first><last>Švec</last></author>
      <author><first>Zbyněk</first><last>Zajíc</last></author>
      <author><first>Barbora</first><last>Hladká</last></author>
      <author><first>Martin</first><last>Holub</last></author>
      <pages>198–209</pages>
      <url hash="bca5fad6">W17-5021</url>
      <doi>10.18653/v1/W17-5021</doi>
      <abstract>We summarize the involvement of our CEMI team in the NLI Shared Task 2017, which deals with both textual and speech input data. We submitted the results achieved by using three different system architectures ; each of them combines multiple <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning models</a> trained on various <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">feature sets</a>. As expected, better results are achieved with the <a href="https://en.wikipedia.org/wiki/System">systems</a> that use both the <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">textual data</a> and the <a href="https://en.wikipedia.org/wiki/Speech">spoken responses</a>. Combining the input data of two different modalities led to a rather dramatic improvement in <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> performance. Our best performing method is based on a set of feed-forward neural networks whose hidden-layer outputs are combined together using a softmax layer. We achieved a macro-averaged F1 score of 0.9257 on the evaluation (unseen) test set and our team placed first in the main task together with other three teams.</abstract>
      <bibkey>ircing-etal-2017-combining</bibkey>
    </paper>
    <paper id="22">
      <title>Native Language Identification Using a Mixture of Character and Word N-grams</title>
      <author><first>Elham</first><last>Mohammadi</last></author>
      <author><first>Hadi</first><last>Veisi</last></author>
      <author><first>Hessam</first><last>Amini</last></author>
      <pages>210–216</pages>
      <url hash="6ddb7b1d">W17-5022</url>
      <doi>10.18653/v1/W17-5022</doi>
      <attachment type="attachment" hash="b2df0f3f">W17-5022.Attachment.pdf</attachment>
      <abstract>Native language identification (NLI) is the task of determining an author’s native language, based on a piece of his / her writing in a second language. In recent years, NLI has received much attention due to its challenging nature and its applications in <a href="https://en.wikipedia.org/wiki/Language_pedagogy">language pedagogy</a> and <a href="https://en.wikipedia.org/wiki/Forensic_linguistics">forensic linguistics</a>. We participated in the NLI2017 shared task under the name UT-DSP. In our effort to implement a method for <a href="https://en.wikipedia.org/wiki/Native-language_identification">native language identification</a>, we made use of a fusion of character and word N-grams, and achieved an optimal <a href="https://en.wikipedia.org/wiki/F-number">F1-Score</a> of 77.64 %, using both essay and speech transcription datasets.</abstract>
      <bibkey>mohammadi-etal-2017-native</bibkey>
    </paper>
    <paper id="24">
      <title>Can string kernels pass the test of time in Native Language Identification?</title>
      <author><first>Radu Tudor</first><last>Ionescu</last></author>
      <author><first>Marius</first><last>Popescu</last></author>
      <pages>224–234</pages>
      <url hash="5534e26c">W17-5024</url>
      <doi>10.18653/v1/W17-5024</doi>
      <abstract>We describe a machine learning approach for the 2017 shared task on Native Language Identification (NLI). The proposed approach combines several <a href="https://en.wikipedia.org/wiki/Kernel_(operating_system)">kernels</a> using <a href="https://en.wikipedia.org/wiki/Multiple_kernel_learning">multiple kernel learning</a>. While most of our kernels are based on character p-grams (also known as n-grams) extracted from essays or speech transcripts, we also use a kernel based on i-vectors, a low-dimensional representation of audio recordings, provided by the shared task organizers. For the learning stage, we choose Kernel Discriminant Analysis (KDA) over Kernel Ridge Regression (KRR), because the former <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> obtains better results than the latter one on the development set. In our previous work, we have used a similar machine learning approach to achieve state-of-the-art NLI results. The goal of this paper is to demonstrate that our shallow and simple approach based on string kernels (with minor improvements) can pass the test of time and reach state-of-the-art performance in the 2017 NLI shared task, despite the recent advances in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. We participated in all three tracks, in which the competitors were allowed to use only the essays (essay track), only the speech transcripts (speech track), or both (fusion track). Using only the data provided by the organizers for training our <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>, we have reached a macro F1 score of 86.95 % in the closed essay track, a macro F1 score of 87.55 % in the closed speech track, and a macro F1 score of 93.19 % in the closed fusion track.</abstract>
      <bibkey>ionescu-popescu-2017-string</bibkey>
    </paper>
    <paper id="25">
      <title>Neural Networks and Spelling Features for Native Language Identification</title>
      <author><first>Johannes</first><last>Bjerva</last></author>
      <author><first>Gintarė</first><last>Grigonytė</last></author>
      <author><first>Robert</first><last>Östling</last></author>
      <author><first>Barbara</first><last>Plank</last></author>
      <pages>235–239</pages>
      <url hash="7f8fac76">W17-5025</url>
      <doi>10.18653/v1/W17-5025</doi>
      <abstract>We present the RUG-SU team’s submission at the Native Language Identification Shared Task 2017. We combine several approaches into an ensemble, based on spelling error features, a simple <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> using word representations, a deep residual network using word and character features, and a system based on a <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network</a>. Our best <a href="https://en.wikipedia.org/wiki/System">system</a> is an ensemble of <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a>, reaching an F1 score of 0.8323. Although our <a href="https://en.wikipedia.org/wiki/System">system</a> is not the highest ranking one, we do outperform the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a> by far.</abstract>
      <bibkey>bjerva-etal-2017-neural</bibkey>
    <title_ar>الشبكات العصبية وميزات التدقيق الإملائي لتحديد اللغة الأصلية</title_ar>
      <title_pt>Redes neurais e recursos de ortografia para identificação de idioma nativo</title_pt>
      <title_es>Redes neuronales y funciones de ortografía para la identificación del idioma nativo</title_es>
      <title_hi>मूल भाषा पहचान के लिए तंत्रिका नेटवर्क और वर्तनी सुविधाएँ</title_hi>
      <title_ja>ネイティブ言語識別のためのニューラルネットワークとスペル機能</title_ja>
      <title_zh>以母语识神经网络拼写</title_zh>
      <title_ga>Líonraí Néaracha agus Gnéithe Litrithe d'Aithint Teanga Dúchais</title_ga>
      <title_ka>Name</title_ka>
      <title_el>Νευρικά δίκτυα και χαρακτηριστικά ορθογραφίας για τον προσδιορισμό της μητρικής γλώσσας</title_el>
      <title_hu>Neurális hálózatok és helyesírási funkciók az anyanyelv azonosításához</title_hu>
      <title_it>Reti neurali e funzionalità ortografiche per l'identificazione della lingua nativa</title_it>
      <title_kk>Тәуелді тіл идентификациясы үшін нейрондық желі және емлер қасиеттері</title_kk>
      <title_lt>Neuraliniai tinklai ir ortografijos savybės gimtosios kalbos identifikavimui</title_lt>
      <title_mk>Неурални мрежи и функции на правопис за идентификација на роден јазик</title_mk>
      <title_ms>Name</title_ms>
      <title_mt>Netwerks Newrali u Karatteristiċi tal-Ittestjar għall-Identifikazzjoni tal-Lingwa Nativa</title_mt>
      <title_ml>സ്വഭാവ ഭാഷ തിരിച്ചറിയുന്നതിനുള്ള നെയുറല്‍ നെറ്റര്‍ വര്‍ക്കുകളും അക്ഷരസഞ്ചയത്തിനുള്ള പ്ര</title_ml>
      <title_mn>Түүнчлэн хэлний идентификацийн мэдрэлийн сүлжээг, Spelling Features for Native Language Identification</title_mn>
      <title_no>Neurale nettverk og staveringsfunksjonar for Native Language Identification</title_no>
      <title_pl>Sieci neuronowe i funkcje pisowni dla identyfikacji języka ojczystego</title_pl>
      <title_ro>Rețele neurale și caracteristici ortografice pentru identificarea limbii native</title_ro>
      <title_si>Native language ID</title_si>
      <title_so>Isticmaalka luqada asalka ah</title_so>
      <title_sr>Neuralne mreže i karakteristike pisma za identifikaciju prirodnog jezika</title_sr>
      <title_sv>Neurala nätverk och stavningsfunktioner för identifiering av ursprungsspråk</title_sv>
      <title_ur>نئورل نیٹورک اور سپٹل ویکتورک کے لئے موجود زبان شناسایی</title_ur>
      <title_ta>Native language identification</title_ta>
      <title_uz>Name</title_uz>
      <title_vi>Hệ thần kinh và tính năng chính tả Native LanguageNhận diện</title_vi>
      <title_bg>Нервни мрежи и правописни функции за идентификация на родния език</title_bg>
      <title_nl>Neurale netwerken en spellingsfuncties voor identificatie van moedertaal</title_nl>
      <title_hr>Neuralne mreže i karakteristike pisma za identifikaciju prirodnog jezika</title_hr>
      <title_da>Neurale netværk og stavefunktioner til identifikation af oprindeligt sprog</title_da>
      <title_id>Rangkaian Neural dan Features Ejaan untuk Identifikasi Bahasa Nasional</title_id>
      <title_de>Neuronale Netzwerke und Rechtschreibfunktionen für die Identifizierung der Muttersprache</title_de>
      <title_fa>شبکه‌های عصبی و ویژگی‌های مشخص‌گذاری برای شناسایی زبان طبیعی</title_fa>
      <title_ko>모국어 식별에 사용되는 신경 네트워크와 맞춤법 특징</title_ko>
      <title_tr>Natal Diller Kimligi üçin näralar şebekleri we Ymlany Maliýetleri</title_tr>
      <title_sq>Rrjetet neuronale dhe funksionet e ortografikës për identifikimin e gjuhës natyrore</title_sq>
      <title_af>Name</title_af>
      <title_sw>Mtandao wa Kiraia na Tafsiri za Ujadala wa Lugha asilia</title_sw>
      <title_az>仃뙲慬⁁쒟污爠盉餠쒰浬즙爠쒰얟慲整泉饲椊</title_az>
      <title_hy>Neural Networks and Spelling Features for Native Language Identification</title_hy>
      <title_am>የኩነቶች መረጃ</title_am>
      <title_bn>নিউরেল নেটওয়ার্ক এবং বানান বৈশিষ্ট্য</title_bn>
      <title_cs>Neurální sítě a funkce pravopisu pro identifikaci rodného jazyka</title_cs>
      <title_ca>Les xarxes neuronals i les característiques ortogràfiques per a identificar la llengua nativa</title_ca>
      <title_bs>Neuralne mreže i karakteristike pisma za identifikaciju domaćih jezika</title_bs>
      <title_et>Närvivõrgud ja õigekirja funktsioonid emakeele identifitseerimiseks</title_et>
      <title_fi>Neuroverkot ja oikeinkirjoitusominaisuudet äidinkielen tunnistamiseen</title_fi>
      <title_jv>structural navigation</title_jv>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_sk>Živčna omrežja in funkcije črkovanja za identifikacijo maternega jezika</title_sk>
      <title_he>רשתות עצביות ותחויות האישור לזהות שפת מקומית</title_he>
      <title_bo>སྒེར་གྱི་སྐད་རིགས་ངོ་འཛུགས་དང་དག་ཆ་དག་ཆ་ཁྱད་ཆོས</title_bo>
      <abstract_ar>نقدم تقديم فريق RUG-SU في المهمة المشتركة لتحديد اللغة الأصلية لعام 2017. نحن نجمع بين عدة طرق في مجموعة ، استنادًا إلى ميزات الأخطاء الإملائية ، وشبكة عصبية بسيطة تستخدم تمثيلات الكلمات ، وشبكة عميقة متبقية باستخدام ميزات الكلمات والحرف ، و نظام يعتمد على شبكة عصبية متكررة. أفضل نظام لدينا هو مجموعة من الشبكات العصبية ، وصلت إلى 0.8323 درجة F1. على الرغم من أن نظامنا ليس هو الأعلى مرتبة ، إلا أننا تفوقنا في الأداء على خط الأساس إلى حد بعيد.</abstract_ar>
      <abstract_pt>Apresentamos a submissão da equipe RUG-SU no Native Language Identification Shared Task 2017. Combinamos várias abordagens em um conjunto, com base em recursos de erro de ortografia, uma rede neural simples usando representações de palavras, uma rede residual profunda usando recursos de palavras e caracteres e um sistema baseado em uma rede neural recorrente. Nosso melhor sistema é um conjunto de redes neurais, atingindo uma pontuação F1 de 0,8323. Embora nosso sistema não seja o de classificação mais alta, superamos de longe a linha de base.</abstract_pt>
      <abstract_es>Presentamos la presentación del equipo de RUG-SU en la tarea compartida de identificación del idioma nativo 2017. Combinamos varios enfoques en un conjunto, basado en características de errores ortográficos, una red neuronal simple que usa representaciones de palabras, una red residual profunda que usa características de palabras y caracteres, y un sistema basado en una red neuronal recurrente. Nuestro mejor sistema es un conjunto de redes neuronales, que alcanza una puntuación F1 de 0.8323. Aunque nuestro sistema no es el más alto, superamos con creces el de referencia.</abstract_es>
      <abstract_ja>2017年のネイティブ言語識別共有タスクで、RUG - SUチームの提出物を提示します。スペルエラーの特徴、単語表現を使用した単純なニューラルネットワーク、単語と文字の特徴を使用した深い残留ネットワーク、再帰的なニューラルネットワークに基づくシステムに基づいて、いくつかのアプローチを組み合わせています。当社の最高のシステムは、0.8323のF 1スコアに達するニューラルネットワークのアンサンブルです。当社のシステムは最高ランクのものではありませんが、ベースラインを遥かに上回るパフォーマンスを発揮します。</abstract_ja>
      <abstract_hi>हम मूल भाषा पहचान साझा कार्य 2017 में RUG-SU टीम के सबमिशन को प्रस्तुत करते हैं। हम वर्तनी त्रुटि सुविधाओं के आधार पर एक पहनावा में कई दृष्टिकोणों को जोड़ते हैं, शब्द प्रतिनिधित्व का उपयोग करके एक सरल तंत्रिका नेटवर्क, शब्द और चरित्र सुविधाओं का उपयोग करके एक गहरा अवशिष्ट नेटवर्क, और एक आवर्तक तंत्रिका नेटवर्क पर आधारित एक प्रणाली। हमारी सबसे अच्छी प्रणाली तंत्रिका नेटवर्क का एक पहनावा है, जो 0.8323 के एफ 1 स्कोर तक पहुंचती है। यद्यपि हमारा सिस्टम उच्चतम रैंकिंग वाला नहीं है, हम अब तक बेसलाइन को मात देते हैं।</abstract_hi>
      <abstract_zh>2017年母语识共RUG-SU团队。 合数术组合成一,基于拼写错误,用单词之简神经网络,用单词符之深残差网络,及递归神经网络之系统。 至统者,神经网络之会也,至0.8323之F1数也。 虽非至统,至于目前为止,吾实胜基线。</abstract_zh>
      <abstract_ga>Cuirimid aighneacht na foirne RUG-SU i láthair ag Tasc Comhroinnte Aitheantais Teanga Dúchais 2017. Cuirimid roinnt cineálacha cur chuige le chéile i ensemble, bunaithe ar ghnéithe earráide litrithe, líonra néarúil simplí ag baint úsáide as léirithe focal, líonra iarmharach domhain a úsáideann gnéithe focal agus carachtair, agus córas atá bunaithe ar líonra neural athfhillteach. Is é an córas is fearr atá againn ná ensemble de líonraí neural, ag baint amach scór F1 de 0.8323. Cé nach bhfuil ár gcóras ar an gceann is airde rangú, is fearr i bhfad an bonnlíne atá againn.</abstract_ga>
      <abstract_ka>ჩვენ ვამხსენებთ RUG-SU ჯგუფის შემდეგ 2017 წლის ადგილური ენის იდენტიფიკაციის განმავლობაში. ჩვენ შევყვანით რამდენიმე დახმარებების შეცდომის ფუნქციებზე, სიტყვების გამოყენებას, სიტყვების გამოყენებას, სიტყვების და სიტყვების ფუნქციების გამოყენებას, სიტყვების და სიტყვების ფუ ჩვენი საუკეთესო სისტემა არის ნეიროლური ქსელების ინსნემბელი, რომელიც F1 წერტილის 0.8323-ის წერტილია. მაგრამ ჩვენი სისტემა არ არის ყველაზე უფრო დიდი სისტემა, ჩვენ უფრო დიდი სისტემას გავაკეთებთ.</abstract_ka>
      <abstract_hu>A RUG-SU csapat benyújtását bemutatjuk a 2017-es anyanyelvi azonosítási megosztott feladaton. Több megközelítést kombinálunk egy együttesbe, amelyek a helyesírási hiba jellemzői, egy egyszerű neurális hálózat szóreprezentációk segítségével, egy mély maradék hálózat szó- és karakterfunkciók segítségével, valamint egy visszatérő neurális hálózaton alapulnak. A legjobb rendszerünk az idegi hálózatok együttese, amelyek F1 pontszámot érnek el 0,8323. Bár a rendszerünk nem a legmagasabb rangú, messze felülmúljuk az alapvető teljesítményt.</abstract_hu>
      <abstract_el>Παρουσιάζουμε την υποβολή της ομάδας στην κοινή εργασία ταυτοποίησης μητρικής γλώσσας 2017. Συνδυάζουμε διάφορες προσεγγίσεις σε ένα σύνολο, βασισμένο σε χαρακτηριστικά ορθογραφικού σφάλματος, ένα απλό νευρωνικό δίκτυο χρησιμοποιώντας αναπαραστάσεις λέξεων, ένα βαθύ υπολειμματικό δίκτυο χρησιμοποιώντας χαρακτηριστικά λέξεων και χαρακτήρων, και ένα σύστημα βασισμένο σε ένα επαναλαμβανόμενο νευρωνικό δίκτυο. Το καλύτερο μας σύστημα είναι ένα σύνολο νευρωνικών δικτύων, που φτάνουν σε βαθμολογία F1 0.8323. Αν και το σύστημά μας δεν είναι το υψηλότερο σύστημα κατάταξης, ξεπερνάμε κατά πολύ τη βασική γραμμή.</abstract_el>
      <abstract_it>Presentiamo la presentazione del team RUG-SU alla Native Language Identification Shared Task 2017. Combiniamo diversi approcci in un insieme, basato su caratteristiche di errore ortografico, una semplice rete neurale che utilizza rappresentazioni di parole, una rete residua profonda che utilizza caratteristiche di parole e caratteri e un sistema basato su una rete neurale ricorrente. Il nostro sistema migliore è un insieme di reti neurali, raggiungendo un punteggio F1 di 0,8323. Anche se il nostro sistema non è il più alto in classifica, superiamo di gran lunga la linea di base.</abstract_it>
      <abstract_kk>Біз 2017 жылы Тілдер идентификациясының ортақ тапсырмасына RUG-SU командасының жіберілуін келтірдік. Емле қатенің қасиеттеріне негізделген, сөздердің түсініктерін қолданатын кәдімгі невралдық желі, сөз мен таңбалар мүмкіндіктерін қолданатын түрлі желі, қайталанатын невралдық желіне негізделген жүйені қолдана Біздің ең жақсы жүйеміз - невралдық желілердің символы, F1 деңгейі 0,8323 деңгейі жеткізеді. Біздің жүйеміз ең жоғары жоғары жоғары емес дегенде, біз негізгі жолды қазірше жеткіземіз.</abstract_kk>
      <abstract_lt>Mes pristatome RUG-SU komandos pateiktą pranešimą bendroje vietinės kalbos identifikavimo užduotyje 2017 m. Mes sujungiame kelis metodus į komplektą, pagrįstą rašymo klaidų savybėmis, paprastu nerviniu tinklu, naudojančiu žodžių atspaudus, giliu likutiniu tinklu, naudojančiu žodžių ir simbolių savybes, ir sistema, pagrįsta pasikartojančiu nerviniu tinklu. Mūsų geriausia sistema yra nervinių tinklų rinkinys, kurio F1 rezultatas yra 0,8323. Although our system is not the highest ranking one, we do outperform the baseline by far.</abstract_lt>
      <abstract_mk>Го претставуваме поднесувањето на тимот РУГ-СУ на Делената задача за идентификација на роден јазик 2017. Комбинираме неколку пристапи во ансембл, базирани на карактеристики на грешка во правописот, едноставна нервна мрежа користејќи репрезентации на зборови, длабока ресуидна мрежа користејќи карактеристики на зборови и карактеристики, и систем базиран на ре Нашиот најдобар систем е ансембл на нервни мрежи, достигнувајќи резултат F1 од 0,8323. Although our system is not the highest ranking one, we do outperform the baseline by far.</abstract_mk>
      <abstract_ml>നാഷണല്‍ ഭാഷയുടെ തിരിച്ചറിയുന്നതില്‍ ഞങ്ങള്‍ RUG-SU ടീമിന്‍റെ സന്ദേശം കാണിക്കുന്നു. വാക്ക് പ്രതിനിധികള്‍ ഉപയോഗിച്ച്, വാക്കിന്റെ പ്രതിനിധികള്‍ ഉപയോഗിച്ച്, വാക്കിന്റെ പ്രതിനിധികള്‍ ഉപയോഗിച്ച്, വാക്കും അക്ഷരത്തിന്റെ വിശേഷതകള്‍ ഉപയോഗിച്ച നമ്മുടെ ഏറ്റവും നല്ല സിസ്റ്റമാണ് ന്യൂറല്‍ നെറ്റര്‍ നെറ്റര്‍ നെറ്റര്‍ക്കുകളുടെ ഒരു സ്കോര്‍ ആയിരിക്കുന്നത്. എഫ നമ്മുടെ സിസ്റ്റത്തിന്റെ അത്യുന്നതമായ റെഞ്ചിങ്ങ് അല്ലെങ്കിലും, നമ്മള്‍ അടിസ്ഥാനത്തില്‍ നിന്നും അധി</abstract_ml>
      <abstract_ms>Kami memperkenalkan penghantaran pasukan RUG-SU pada Tugas Berkongsi Identifikasi Bahasa asli 2017. Kami menggabungkan beberapa pendekatan ke dalam kumpulan, berdasarkan ciri ralat ejaan, rangkaian saraf sederhana menggunakan perwakilan perkataan, rangkaian sisa dalam menggunakan ciri perkataan dan aksara, dan sistem berdasarkan rangkaian saraf berulang. Sistem terbaik kita adalah kumpulan rangkaian saraf, mencapai skor F1 0.8323. Walaupun sistem kita bukanlah yang tertinggi, kita melampaui dasar jauh.</abstract_ms>
      <abstract_mt>Aħna nippreżentaw is-sottomissjoni tat-tim RUG-SU fil-Kompitu Konġunt tal-Identifikazzjoni tal-Lingwa Nazzjonali 2017. Aħna ngħaqdu diversi approċċi f’ensemble, ibbażati fuq karatteristiċi ta’ żball fl-ortografija, netwerk newrali sempliċi li juża rappreżentazzjonijiet tal-kliem, netwerk residwu fond li juża karatteristiċi tal-kliem u tal-karattru, u sistema bbażata fuq netwerk newrali rikorrenti. L-aħjar sistema tagħna hija ġabra ta’ netwerks newrali, li jilħqu punteġġ F1 ta’ 0.8323. Although our system is not the highest ranking one, we do outperform the baseline by far.</abstract_mt>
      <abstract_mn>Бид РUG-SU багийнхаа 2017 оны Түүнчлэн хэлний идентификацийн хуваалтын ажил дээр тайлбарлаж байна. Бид хэд хэдэн арга барилгуудыг зэрэг бичлэгийн алдаа гаргасан, үг илэрхийлэлтэй ашиглан энгийн мэдрэлийн сүлжээ, үг, хариу дүрсийг ашиглан гүн гүнзгий үлдсэн сүлжээ, дахин дахин сэтгэл сүлжээнд суурилсан системийг нэгтгэдэг Бидний хамгийн шилдэг систем бол мэдрэлийн сүлжээний загвар юм. F1 тоо 0.8323 байдаг. Гэхдээ бидний систем хамгийн өндөр хэмжээний биш ч гэсэн, бид суурь шугам дээр урт хугацаанд илүү их хийдэг.</abstract_mn>
      <abstract_no>Vi presenterer oppgåva til RUG-SU-gruppa i den delte oppgåva 2017. Vi kombinerer fleire tilnærmingar til eit ensembel, basert på stavefeilingsfunksjonar, eit enkel neuralnettverk med ordrepresentasjonar, eit dyp nettverk med ord og teiknfunksjonar, og eit system basert på eit rekursært neuralnettverk. Det beste systemet vårt er ein ensembel av neuralnettverk, som når ei F1- poeng med 0,8323. Selv om systemet vår ikkje er den høgste rankeringa, utfører vi baselinja langt.</abstract_no>
      <abstract_pl>Przedstawiamy zgłoszenie zespołu RUG-SU podczas wspólnego zadania identyfikacji języka ojczystego 2017. Łączymy kilka podejść w zespół, opartych na cechach błędów pisowni, prostej sieci neuronowej wykorzystującej reprezentacje słów, głębokiej sieci resztkowej wykorzystującej cechy słowa i znaków oraz system oparty na powtarzającej się sieci neuronowej. Naszym najlepszym systemem jest zespół sieci neuronowych, osiągający wynik F1 0.8323. Chociaż nasz system nie jest najwyższym rankingiem, zdecydowanie przewyższamy wartość bazową.</abstract_pl>
      <abstract_ro>Prezentăm depunerea echipei RUG-SU la Activitatea partajată de identificare a limbii native 2017. Combinăm mai multe abordări într-un ansamblu, bazat pe caracteristicile erorilor de ortografie, o rețea neuronală simplă care utilizează reprezentări de cuvinte, o rețea reziduală profundă care utilizează caracteristici de cuvinte și caractere și un sistem bazat pe o rețea neurală recurentă. Cel mai bun sistem al nostru este un ansamblu de rețele neuronale, atingând un scor F1 de 0.8323. Deși sistemul nostru nu este cel mai înalt rang, depășim performanța de bază cu mult.</abstract_ro>
      <abstract_sr>Predstavljamo podnošenje tima RUG-SU-a u zadatku za dijeljenje identifikacije jezika iz rodnog jezika 2017. Kombinaramo nekoliko pristupa u ensemblu, na osnovu karakteristika greške pisanja, jednostavne neuralne mreže koristeći predstavljanje rijeèi, duboku ostatku mrežu koristeći reèi i karakteristike, i sistem zasnovan na recirenoj neuralnoj mreži. Naš najbolji sistem je ensemble neuralnih mreža, koji postiže F1 rezultat od 0,8323. Iako naš sistem nije najviši ranking, do sada više izvršavamo početnu liniju.</abstract_sr>
      <abstract_si>අපි RUG-SU කණ්ඩායමේ පිළිගන්නේ 2017 ජාතික භාෂාව පරීක්ෂණය සම්බන්ධ වැඩකට. අපි වාර්තාව ප්‍රතිචාරයක් භාවිත කරනවා වාර්තාව සහ අකුරුවක් සඳහා සාමාන්‍ය න්‍යුරෝල ජාලය, වචන සහ අකුරුවක් භාවිත කරනවා වචන සහ පද්ධති අපේ හොඳම පද්ධතිය තමයි න්‍යූරල් ජාලයේ සංකේතයක්, F1 ප්‍රමාණයක් 0.8323 වෙනුවෙන්. අපේ පද්ධතිය තරම් උන්ම ප්‍රමාණයක් නෙවෙයි නමුත්, අපි දුරටත් පද්ධතිය ප්‍රමාණය කරන්නේ.</abstract_si>
      <abstract_sv>Vi presenterar RUG-SU-teamets bidrag vid Native Language Identification Shared Task 2017. Vi kombinerar flera tillvägagångssätt till en ensemble, baserat på stavfel funktioner, ett enkelt neuralt nätverk med ordrepresentationer, ett djupt restnätverk med ord och tecken funktioner, och ett system baserat på ett återkommande neuralt nätverk. Vårt bästa system är en ensemble av neurala nätverk, når en F1 poäng på 0,8323. Även om vårt system inte är det högsta rankade systemet, överträffar vi baslinjen med långt.</abstract_sv>
      <abstract_so>Waxaannu soo bandhignaynaa warqada kooxda RUG-SU ee aqoonsiga afka hooyo ee lagu sharciyey shaqo 2017. Waxaynu ku soo ururinnaa qaabab badan oo ku saabsan khalad ku qoran, shabakad neurada ah oo fudud oo isticmaalaya macluumaad, shabakad aad u dheer oo ku nooshahay isticmaalka hadal iyo tababar, iyo nidaam ku saleysan shabako cayaar ah oo soo socda. nidaamka ugu wanaagsan waa shabakado neurada ah oo gaadha koox F1 oo 0.8323 ah. In kastoo nidaamkayagu ma aha mid aad u sareeya, waxaynu sameynaa heerka hoose meel fog.</abstract_so>
      <abstract_ta>நாங்கள் RUG-SU குழு கூட்டத்தின் கூறுதலை நாட்டு மொழி அடையாளத்தில் கூடிய பணி 2017 பகிர்ந்துள்ளது. எழுத்து பிழை பண்புகளை அடிப்படையில், சொல் பிரதிபலிகளை பயன்படுத்தி ஒரு சுலபமான புதிய வலைப்பின்னல், வார்த்தை குறிப்பிடுதல்களை பயன்படுத்தி ஒரு ஆழமான மீதமான வலைப் எங்கள் சிறந்த அமைப்பு புதிய வலைப்பின்னல் எங்கள் அமைப்பு அதிக உயர்ந்த உயர்ந்த வரிசையில் இல்லை எனினும், நாம் தூரத்திற்கு அடிப்படைக்கோட்டில் மேல</abstract_ta>
      <abstract_ur>ہم نے RUG-SU تیم کے مطابق ملک کی زبان شناساتی مشترک ٹاکس 2017 میں پیش کیا ہے. ہم ایک ایسمبل میں بہت سی تقریبیں جمع کرتے ہیں، اسپلینگ کی خطا فوائل پر بنیاد رکھتے ہیں، ایک ساده نئورل نیٹورک کلمات کی تعلیمات کے مطابق، ایک عمیق باقی رہنے والی نیٹورک کلمات اور شخصیٹ فوائل کے مطابق، اور ایک سیسٹم جو ایک دوبارہ ہمارا بہترین سیستم نیورل نیٹ ورک کا ایک انامبل ہے، جو 0.8323 کی F1 اسکور تک پہنچتی ہے۔ اگرچہ ہمارا سیستم سب سے بلند مرتبہ نہیں ہے، ہم اسٹیلین کو دور تک زیادہ کررہے ہیں۔</abstract_ur>
      <abstract_uz>Biz nativiy tillar identifikasini 2017 bilan bog'liq vazifa bilan bogʻliq qilgan RUG-SU jamiyasini taqdimiz. @ info: whatsthis Bizning eng yaxshi tizimmiz neyrol tarmoqlarining bir misol, 0.8323 darajaga F1 qismiga ega. Agar biz tizimmiz eng yuqori darajada emas, biz asosiy satrni bir necha bajaramiz.</abstract_uz>
      <abstract_vi>Chúng tôi xin giới thiệu s ự đệ trình của đội RuG-SU tại tổ chức Chia sẻ bí mật ngôn ngữ bản địa Chúng tôi kết hợp nhiều phương pháp trong một kết hợp, dựa trên tính năng lỗi chính tả, một mạng thần kinh đơn giản dùng các biểu hiện từ, một mạng lưới thâm niên sâu dùng các tính năng từ và ký tự, và một hệ thống dựa trên mạng thần kinh liên tục. Hệ thống tốt nhất của chúng ta là một kết hợp của các mạng thần kinh, đạt được điểm F1 của 0.8323. Mặc dù hệ thống của chúng tôi không phải hạng cao nhất, nhưng chúng tôi hoàn toàn vượt trội hơn so với thực tế.</abstract_vi>
      <abstract_hr>Predstavljamo podatke ekipe RUG-SU-a na dijeljenom zadatku 2017. godine. Kombinaramo nekoliko pristupa u ensemblu, na temelju karakteristika greške pisanja, jednostavne neuralne mreže koristeći predstavljanje riječi, duboku ostatku mrežu koristeći riječi i karakteristike, i sustav zasnovan na recirenoj neuralnoj mreži. Naš najbolji sustav je ensembl neuralnih mreža, koji postigne F1 rezultat od 0,8323. Iako naš sistem nije najviši ranking, do sada više izvršavamo početnu liniju.</abstract_hr>
      <abstract_bg>Представяме представянето на екипа на РУГ-СУ на споделената задача за идентификация на родния език 2017. Комбинираме няколко подхода в ансамбъл, базиран на правописни грешки, проста невронна мрежа, използваща думи, дълбока остатъчна мрежа, използваща думи и знаци, и система, базирана на повтаряща се невронна мрежа. Най-добрата ни система е ансамбъл от невронни мрежи, достигащ резултат от 0.8323. Въпреки че нашата система не е най-високата класация, ние надминаваме базовата база далеч.</abstract_bg>
      <abstract_nl>We presenteren de inzending van het RUG-SU team tijdens de Native Language Identification Shared Task 2017. We combineren verschillende benaderingen in een ensemble, gebaseerd op spelfouten, een eenvoudig neuraal netwerk met woordrepresentaties, een diep residueel netwerk met woord- en karakterkenmerken en een systeem gebaseerd op een terugkerend neuraal netwerk. Ons beste systeem is een ensemble van neurale netwerken, die een F1 score van 0.8323 bereiken. Hoewel ons systeem niet de hoogste rangschikking is, presteren we de baseline ver.</abstract_nl>
      <abstract_da>Vi præsenterer RUG-SU-teamets indsendelse på Native Language Identification Shared Task 2017. Vi kombinerer flere tilgange i et ensemble, baseret på stavefejlfunktioner, et simpelt neuralt netværk ved hjælp af ord repræsentationer, et dybt restnetværk ved hjælp af ord og tegn funktioner, og et system baseret på et tilbagevendende neuralt netværk. Vores bedste system er et ensemble af neurale netværk, der når en F1 score på 0,8323. Selvom vores system ikke er det højeste rangerende system, overgår vi baseline langt.</abstract_da>
      <abstract_de>Wir stellen die Einreichung des RUG-SU-Teams bei der Native Language Identification Shared Task 2017 vor. Wir kombinieren verschiedene Ansätze zu einem Ensemble, basierend auf Rechtschreibfehlermerkmalen, einem einfachen neuronalen Netzwerk mit Wortdarstellungen, einem tiefen Restnetzwerk mit Wort- und Zeichenmerkmalen und einem System basierend auf einem wiederkehrenden neuronalen Netzwerk. Unser bestes System ist ein Ensemble neuronaler Netze, das eine F1-Punktzahl von 0.8323 erreicht. Obwohl unser System nicht das höchste Ranking hat, übertreffen wir die Baseline bei weitem.</abstract_de>
      <abstract_id>Kami mempersembahkan pengiriman tim RUG-SU di Tugas Berkongsi Identifikasi Bahasa asli 2017. Kami menggabungkan beberapa pendekatan ke dalam sebuah ensemble, berdasarkan fitur kesalahan ejaan, jaringan saraf sederhana menggunakan representation kata, jaringan sisa dalam menggunakan fitur kata dan karakter, dan sistem berdasarkan jaringan saraf berkurang. Our best system is an ensemble of neural networks, reaching an F1 score of 0.8323.  Meskipun sistem kita bukan yang tertinggi, kita melampaui batas dasar sejauh ini.</abstract_id>
      <abstract_ko>우리는 2017년 모국어 인식 공유 임무에서 RUG-SU 팀이 제출한 자료를 선보였다.우리는 몇 가지 방법을 맞춤법 오류 특징을 바탕으로 한 통합, 단어로 표시하는 간단한 신경 네트워크, 단어와 문자 특징을 사용하는 깊이 있는 잔차 네트워크, 그리고 귀속 신경 네트워크를 바탕으로 하는 시스템으로 조합할 것이다.우리의 가장 좋은 시스템은 신경 네트워크로 F1의 성적이 0.8323점에 이르렀다.비록 우리 시스템이 가장 높은 순위는 아니지만, 우리의 활약은 확실히 기준선을 훨씬 능가한다.</abstract_ko>
      <abstract_fa>ما تحویل تیم RUG-SU را در کار مشترک شناسایی زبان طبیعی 2017 پیشنهاد می کنیم. ما چندین روش‌های درگیری به یک انگلیسی را ترکیب می‌کنیم، بر اساس ویژه‌های خطای نوشتن، شبکه عصبی ساده با استفاده از نمایش‌دهندگان کلمه، شبکه عمیقی از ویژه‌های کلمه و شخصیت‌ها، و سیستم بر اساس شبکه عصبی بازگشت. بهترین سیستم ما یک جمله از شبکه های عصبی است که به یک امتیاز F1 از 0.8323 رسیده است. اگرچه سیستم ما بالاترین درجه‌ی نقطه‌ی نقطه‌ی نقطه‌ی نقطه‌ی نقطه‌ی نقطه‌ی نقطه‌ی نقطه‌ی نقطه‌ی نقطه‌ی</abstract_fa>
      <abstract_sw>Tunawasilisha ujumbe wa timu ya RUG-SU kwenye utambulisho wa lugha ya asili ulioshirikisha kazi 2017. Tunaunganisha mbinu kadhaa katika kituo hicho, kwa kutumia utambulisho wa makosa ya kuelezea, mtandao rahisi wa neurali kwa kutumia uwakilizaji wa maneno, Mtandao wa ndani unaotumia maneno na tabia, na mfumo unaotumia mtandao wa neurali unaoendelea. Mfumo wetu bora ni mfumo wa mitandao ya neura, unafikia score ya F1 ya 0.8323. Ingawa mfumo wetu hauna vyeo vya juu zaidi, tunafanya kazi zaidi ya msingi mpaka mbali.</abstract_sw>
      <abstract_tr>Biz RUG-SU toparynyň 2017-nji ýylda ýerli dil kimligini paýlaşdyryp görkezip Biz bir rakam içine bir näçe yaklaşgalary birleştirip, imlâ hata özelliklerine dayanan, kelime temsillerini kullanan basit näral a ğ, kelime we karakter özelliklerine dayanan derin bir ağ ve tekrar ağ üstüne dayanan bir sistemi birleştirip bileris. Biziň iň gowy sistemimiz näyral şebekeleriň gönülleridir, F1 अ 0.8323 we ýetirilýär. Biziň sistemamyz iň ýokary dereje däldir, we şu wagtlar baseliniň üstüni çykýarys.</abstract_tr>
      <abstract_af>Ons voorsien die RUG-SU-team se onderskrywing by die Natiewe Taal Identifikasie Gedeelde Taak 2017. Ons kombinieer verskeie toegang binne 'n ensembel, gebaseer op speletjie fout funksies, 'n eenvoudige neuralnetwerk gebruik word voorstellings, 'n diep oorblywende netwerk gebruik word en karakterfunksies, en 'n stelsel gebaseer op 'n herhaalde neuralnetwerk. Ons beste stelsel is 'n ensemble van neuralnetwerke, wat 'n F1 punt van 0.8323 bereik het. Alhoewel ons stelsel nie die hoogste rangering een is nie, ons doen die basislien af.</abstract_af>
      <abstract_sq>Ne paraqesim paraqitjen e ekipit RUG-SU në detyrën e përbashkët të identifikimit të gjuhës vendase 2017. Ne kombinojmë disa qasje në një komplet, bazuar në funksionet e gabimeve të ortografikës, një rrjet nervor të thjeshtë duke përdorur përfaqësimet e fjalëve, një rrjet të thellë të mbetur duke përdorur funksionet e fjalës dhe karakterit, dhe një sistem bazuar në një rrjet nervor të përsëritur. Sistemi ynë më i mirë është një grup rrjetesh nervore, duke arritur një rezultat F1 prej 0.8323. Megjithëse sistemi ynë nuk është i nivelit më të lartë, ne e kalojmë bazën deri tani.</abstract_sq>
      <abstract_am>የአብዛዊ ቋንቋ ማወቃየት 2017 የRUG-SU ቡድን አዋጅ እናቀርባታለን፡፡ በጽሑፍ የስህተት ምርጫዎች፣ ቃላትን ምረጡ የሚጠቀም ቀላል የናውራዊ መረብ፣ ቃልና የፊደል ምርጫዎች በተጠቃሚ ጥልቅ የጥልቅ መረብ እና በንግግር እና በሥርዓት ምርጫዎች እና በተደገመ የደብዳቤ መረብ ላይ የተመሳሳይ ስርዓት እና የደብዳቤ መረብ ላይ የተመሳሳይ Our best system is an ensemble of neural networks, reaching an F1 score of 0.8323.  ምንም እንኳን ስርዓታችን ከፍተኛ ደረጃዎች አይደለም፣ መደቡን ከሩቅ እናደርጋለን፡፡</abstract_am>
      <abstract_hy>We present the RUG-SU team's submission at the Native Language Identification Shared Task 2017.  Մենք համադրում ենք բազմաթիվ մոտեցումներ երգչախմբի մեջ, հիմնված ուղղագրության սխալ հատկությունների վրա, պարզ նյարդային ցանց, որը օգտագործում է բառերի ներկայացումներ, խորը մնացած ցանց, որը օգտագործում է բառեր և բնավորություններ, և համակարգ, որը հիմնված է վեր Մեր լավագույն համակարգը նյարդային ցանցերի համակարգ է, որը հասնում է F1-ի 0.8323 գնահատականին: Չնայած մեր համակարգը ամենաբարձր դասակարգը չէ, մենք շատ ավելի լավ ենք արտադրում հիմքի արդյունքը:</abstract_hy>
      <abstract_ca>We present the RUG-SU team's submission at the Native Language Identification Shared Task 2017.  Combinem diversos enfocaments en un conjunt, basat en característiques d'error ortografic, una xarxa neural senzilla utilitzant representacions de paraules, una xarxa residual profunda utilitzant característiques de paraules i caràcters, i un sistema basat en una xarxa neural recurrent. El nostre millor sistema és un conjunt de xarxes neurals, arribant a una puntuació F1 de 0,8323. Tot i que el nostre sistema no és el més alt, superem el nivell de referència de lluny.</abstract_ca>
      <abstract_bn>আমরা স্বাভাবিক ভাষার পরিচিতিতে রুজি-এসউ টিমের প্রতি উপস্থাপন করেছি। বানান সমস্যার বৈশিষ্ট্য, শব্দ প্রতিনিধিত্ব ব্যবহার করে একটি সাধারণ নিউরেল নেটওয়ার্ক, শব্দ এবং চরিত্র ব্যবহার করে গভীর বাকী নেটওয়ার্ক, এবং পুনরায় নির্বাচন নে আমাদের সবচেয়ে ভালো সিস্টেম হচ্ছে নিউরেল নেটওয়ার্কের একটি স্কোর, যা ০. 8323 এর একটি F1 স্কোর পৌঁছায়। Although our system is not the highest ranking one, we do outperform the baseline by far.</abstract_bn>
      <abstract_bs>Predstavljamo podatke ekipe RUG-SU-a na zadatku za dijeljenje identifikacije jezika, 2017. Kombinaramo nekoliko pristupa u ensemblu, na osnovu karakteristika greške pisanja, jednostavne neuralne mreže koristeći predstave riječi, duboku ostatku mrežu koristeći riječi i karakteristike, i sistem zasnovan na recirenoj neuralnoj mreži. Naš najbolji sistem je ensemble neuralnih mreža, koji postigne F1 rezultat od 0,8323. Iako naš sistem nije najviši ranking, do sada više izvršavamo početnu liniju.</abstract_bs>
      <abstract_cs>Představujeme podání týmu RUG-SU na sdíleném úkolu Native Language Identification Shared Task 2017. Kombinujeme několik přístupů do souboru, založených na pravopisných chybách, jednoduché neuronové síti pomocí slovních reprezentací, hluboké zbytkové sítě využívající slovní a znakové rysy a systém založený na recidivující neuronové síti. Naším nejlepším systémem je soubor neuronových sítí, které dosahují F1 skóre 0.8323. Přestože náš systém není nejvyšší hodnocení, zdaleka překonáváme základní hodnotu.</abstract_cs>
      <abstract_et>Tutvustame RUG-SU meeskonna esitlust emakeele identifitseerimise jagatud ülesandel 2017. Kombineerime mitmeid lähenemisviise ansambliks, mis põhinevad õigekirjaveafunktsioonidel, lihtsal sõnarepresentatsiooni kasutaval närvivõrgul, sõna- ja märgifunktsioone kasutaval sügaval jääkvõrgul ning korduval närvivõrgul põhineval süsteemil. Meie parim süsteem on närvivõrkude ansambel, saavutades F1 skoori 0,8323. Kuigi meie süsteem ei ole kõige kõrgemal positsioonil, siis tuleme me olulisest olukorrast kaugelt üle.</abstract_et>
      <abstract_fi>Esittelemme RUG-SU-tiimin ilmoituksen Native Language Identification Shared Task 2017 -tapahtumassa. Yhdistämme useita lähestymistapoja oikeinkirjoitusvirheiden ominaisuuksiin, yksinkertaiseen sanaesitystä hyödyntävään neuroverkkoon, sana- ja merkkiominaisuuksia hyödyntävään syvään jäännösverkkoon sekä toistuvaan neuroverkkoon perustuvaan järjestelmään. Paras järjestelmämme on neuroverkkojen kokonaisuus, joka saavuttaa F1-pisteen 0,8323. Vaikka järjestelmämme ei ole korkeimmalla sijalla, suoriudumme perusaikataulusta selvästi.</abstract_fi>
      <abstract_az>Biz RUG-SU tayfasının 2017-ci ilin təşkil edilməsi ilə birlikdə təşkil edirik. İmlər xətası özelliklərinə dayanan bir neçə yaxınlıqları, sözləri göstərən basit nöral a ğ, söz və karakter özelliklərinə istifadə edən çətinli şəbəkə və yenidən nöral ağ üzərində dayanan bir sistemi ilə birləşdiririk. Bizim ən yaxşı sistemimiz nöral ağlarının ensembliyidir, F1 dərəcəsinin 0.8323 olduğunu görür. Sistemimiz ən yüksək dərəcələr deyil olsa da, bu səhifəni uzaqlaşdırırıq.</abstract_az>
      <abstract_jv>We present the RUG-SU task Awak dhéwé éntukno karo akeh sampeyan akeh lan akeh simbol, basa kang dibutuhke kelas urip, tambah kuwi alam sing gambar nggambar gambar kelas representations, tambah banter liwih dumadhi sing gambar kelas word lan caratar dumadhi, lan sistem sing basa gambar uwis seneng tambah banter Sistem sing paling dhéwé kuwi arkalan tambah nêrung, sampeyan F1 sing kator 0. Mangkin dhéwé sistem sing paling dhéwé, awak dhéwé iso nggawe liyan sing paling dhéwé.</abstract_jv>
      <abstract_he>אנחנו מציגים את ההצגה של צוות RUG-SU במשימה משותפת לזהות שפת האדומה 2017. אנחנו משלבים כמה גישות לתוך אסמבל, מבוסס על תכונות שגיאות תיאום, רשת עצבית פשוטה בשימוש ביצועי מילים, רשת שאריות עמוקה בשימוש תכונות מילים ודמות, ומערכת מבוססת על רשת עצבית חוזרת. המערכת הטובה ביותר שלנו היא אסמבל של רשתות עצביות, מגיעה לתוצאה F1 של 0.8323. למרות שהמערכת שלנו היא לא המדרגות הגבוהה ביותר, אנחנו עושים מעבר לבסיס עד רחוק.</abstract_he>
      <abstract_sk>Prijavo ekipe RUG-SU predstavljamo na skupni nalogi identifikacije maternega jezika 2017. V ansambel združujemo več pristopov, ki temeljijo na funkcijah črkovalnih napak, preprostem nevronskem omrežju z uporabo besednih reprezentacij, globokem preostalem omrežju z uporabo besednih in znakov ter sistemu, ki temelji na ponavljajočem se nevronskem omrežju. Naš najboljši sistem je komplet nevronskih omrežij, ki doseže rezultat F1 0,8323. Čeprav naš sistem ni najvišji, smo daleč boljši od osnovne vrednosti.</abstract_sk>
      <abstract_ha>Tuna halatar da ma'anar RUG-SU a cikin Taifan Taifa Tuna haɗa zaɓa ɓo masu yawa zuwa wani ensemble, a kan salon da wasu misogi na spelling, wata shirin neural mai sauƙi da ke yi amfani da tsaro masu magana, wani jerin mai sauri da zai yi amfani da haske da tsaro masu hushi, da wani na'ura a kan zane wani zane na farata. Tsarinmu mafi kyaun na'uranmu yana samun taryutan neura, yana samun score F1 na 0.8323. Kuma kõ da tsarin mu bai zama da mafi ɗaukaka darajõji ba, sai muna tafiyar da mafi ƙasƙanci a wuri.</abstract_ha>
      <abstract_bo>ང་ཚོས་རྒྱལ་ཁབ་ཀྱི་སྐད་རིགས་དམིགས་འཛུགས་ཀྱི་ལས་འགུལ་གྱི་ལྡོག་པ་(RUG-SU)དང་མཉམ་དུ་སྔོན་སྒྲིག We combine several approaches into an ensemble, based on spelling error features, a simple neural network using word representations, a deep residual network using word and character features, and a system based on a recurrent neural network. ང་ཚོའི་མ་ལག་གི་ཁྱད་ཚད་ཀྱི་དྲ་རྒྱ་ཞིག་ཡིན་པ་ལྟར་བཤད་ཀྱི་ཡོད།F1 རིམ་འབ 0.8323 ཡིན། ང་ཚོའི་རིམ་ལུགས་དེ་འཇིག་རྟེན་འདི་ལས་མཐོ་ཤོས་མེད་ཀྱང་།</abstract_bo>
      </paper>
    <paper id="26">
      <title>A study of N-gram and Embedding Representations for Native Language Identification</title>
      <author><first>Sowmya</first><last>Vajjala</last></author>
      <author><first>Sagnik</first><last>Banerjee</last></author>
      <pages>240–248</pages>
      <url hash="5b639437">W17-5026</url>
      <doi>10.18653/v1/W17-5026</doi>
      <abstract>We report on our experiments with N-gram and embedding based feature representations for Native Language Identification (NLI) as a part of the NLI Shared Task 2017 (team name : NLI-ISU). Our best performing system on the test set for written essays had a macro F1 of 0.8264 and was based on word uni, bi and trigram features. We explored <a href="https://en.wikipedia.org/wiki/N-gram">n-grams</a> covering word, character, POS and word-POS mixed representations for this task. For embedding based feature representations, we employed both word and document embeddings. We had a relatively poor performance with all embedding representations compared to n-grams, which could be because of the fact that embeddings capture semantic similarities whereas L1 differences are more stylistic in nature.</abstract>
      <bibkey>vajjala-banerjee-2017-study</bibkey>
      <pwccode url="https://github.com/nishkalavallabhi/NLIST2017" additional="false">nishkalavallabhi/NLIST2017</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/italki-nli">italki NLI</pwcdataset>
    </paper>
    <paper id="29">
      <title>Structured Generation of Technical Reading Lists</title>
      <author><first>Jonathan</first><last>Gordon</last></author>
      <author><first>Stephen</first><last>Aguilar</last></author>
      <author><first>Emily</first><last>Sheng</last></author>
      <author><first>Gully</first><last>Burns</last></author>
      <pages>261–270</pages>
      <url hash="fdc64311">W17-5029</url>
      <doi>10.18653/v1/W17-5029</doi>
      <abstract>Learners need to find suitable documents to read and prioritize them in an appropriate order. We present a method of automatically generating reading lists, selecting documents based on their pedagogical value to the learner and ordering them using the structure of concepts in the domain. Resulting reading lists related to <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational linguistics</a> were evaluated by advanced learners and judged to be near the quality of those generated by domain experts. We provide an open-source implementation of our <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">method</a> to enable future work on reading list generation.</abstract>
      <bibkey>gordon-etal-2017-structured</bibkey>
    </paper>
    <paper id="30">
      <title>Effects of Lexical Properties on Viewing Time per Word in Autistic and Neurotypical Readers</title>
      <author><first>Sanja</first><last>Štajner</last></author>
      <author><first>Victoria</first><last>Yaneva</last></author>
      <author><first>Ruslan</first><last>Mitkov</last></author>
      <author><first>Simone Paolo</first><last>Ponzetto</last></author>
      <pages>271–281</pages>
      <url hash="a3bf34ca">W17-5030</url>
      <doi>10.18653/v1/W17-5030</doi>
      <abstract>Eye tracking studies from the past few decades have shaped the way we think of word complexity and <a href="https://en.wikipedia.org/wiki/Cognitive_load">cognitive load</a> : words that are long, rare and ambiguous are more difficult to read. However, online processing techniques have been scarcely applied to investigating the reading difficulties of people with autism and what vocabulary is challenging for them. We present parallel gaze data obtained from adult readers with autism and a control group of neurotypical readers and show that the former required higher cognitive effort to comprehend the texts as evidenced by three gaze-based measures. We divide all words into four classes based on their viewing times for both groups and investigate the relationship between longer viewing times and word length, word frequency, and four cognitively-based measures (word concreteness, familiarity, age of acquisition and imagability).</abstract>
      <bibkey>stajner-etal-2017-effects</bibkey>
    </paper>
    <paper id="31">
      <title>Transparent text quality assessment with <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural networks</a></title>
      <author><first>Robert</first><last>Östling</last></author>
      <author><first>Gintare</first><last>Grigonyte</last></author>
      <pages>282–286</pages>
      <url hash="123d41f8">W17-5031</url>
      <doi>10.18653/v1/W17-5031</doi>
      <abstract>We present a very simple model for text quality assessment based on a <a href="https://en.wikipedia.org/wiki/Deep_convolutional_neural_network">deep convolutional neural network</a>, where the only supervision required is one corpus of user-generated text of varying quality, and one contrasting text corpus of consistently high quality. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is able to provide local quality assessments in different parts of a text, which allows visual feedback about where potentially problematic parts of the text are located, as well as a way to evaluate which textual features are captured by our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>. We evaluate our method on two corpora : a large corpus of manually graded student essays and a longitudinal corpus of language learner written production, and find that the text quality metric learned by our model is a fairly strong predictor of both essay grade and learner proficiency level.</abstract>
      <bibkey>ostling-grigonyte-2017-transparent</bibkey>
    </paper>
    <paper id="32">
      <title>Artificial Error Generation with Machine Translation and Syntactic Patterns</title>
      <author><first>Marek</first><last>Rei</last></author>
      <author><first>Mariano</first><last>Felice</last></author>
      <author><first>Zheng</first><last>Yuan</last></author>
      <author><first>Ted</first><last>Briscoe</last></author>
      <pages>287–292</pages>
      <url hash="f4d2ac61">W17-5032</url>
      <doi>10.18653/v1/W17-5032</doi>
      <abstract>Shortage of available training data is holding back progress in the area of automated error detection. This paper investigates two alternative methods for artificially generating writing errors, in order to create additional resources. We propose treating error generation as a machine translation task, where grammatically correct text is translated to contain errors. In addition, we explore a system for extracting textual patterns from an annotated corpus, which can then be used to insert <a href="https://en.wikipedia.org/wiki/Error_(linguistics)">errors</a> into grammatically correct sentences. Our experiments show that the inclusion of <a href="https://en.wikipedia.org/wiki/Errors-in-variables_models">artificially generated errors</a> significantly improves <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error detection accuracy</a> on both FCE and CoNLL 2014 datasets.</abstract>
      <bibkey>rei-etal-2017-artificial</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/fce">FCE</pwcdataset>
    </paper>
    <paper id="33">
      <title>Modelling semantic acquisition in second language learning</title>
      <author><first>Ekaterina</first><last>Kochmar</last></author>
      <author><first>Ekaterina</first><last>Shutova</last></author>
      <pages>293–302</pages>
      <url hash="cd6a486c">W17-5033</url>
      <doi>10.18653/v1/W17-5033</doi>
      <abstract>Using methods of <a href="https://en.wikipedia.org/wiki/Statistical_inference">statistical analysis</a>, we investigate how semantic knowledge is acquired in <a href="https://en.wikipedia.org/wiki/English_language">English</a> as a second language and evaluate the pace of development across a number of predicate types and content word combinations, as well as across the levels of language proficiency and native languages. Our exploratory study helps identify the most problematic areas for <a href="https://en.wikipedia.org/wiki/Language_acquisition">language learners</a> with different backgrounds and at different stages of learning.</abstract>
      <bibkey>kochmar-shutova-2017-modelling</bibkey>
    </paper>
    <paper id="34">
      <title>Multiple Choice Question Generation Utilizing An Ontology</title>
      <author><first>Katherine</first><last>Stasaski</last></author>
      <author><first>Marti A.</first><last>Hearst</last></author>
      <pages>303–312</pages>
      <url hash="49ef3315">W17-5034</url>
      <doi>10.18653/v1/W17-5034</doi>
      <attachment type="attachment" hash="c07f85ba">W17-5034.Attachment.zip</attachment>
      <abstract>Ontologies provide a structured representation of concepts and the relationships which connect them. This work investigates how a pre-existing educational Biology ontology can be used to generate useful practice questions for students by using the connectivity structure in a novel way. It also introduces a novel way to generate multiple-choice distractors from the <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontology</a>, and compares this to a baseline of using embedding representations of nodes. An assessment by an experienced science teacher shows a significant advantage over a baseline when using the <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontology</a> for distractor generation. A subsequent study with three science teachers on the results of a modified question generation algorithm finds significant improvements. An in-depth analysis of the teachers’ comments yields useful insights for any researcher working on automated question generation for <a href="https://en.wikipedia.org/wiki/Educational_technology">educational applications</a>.</abstract>
      <bibkey>stasaski-hearst-2017-multiple</bibkey>
    </paper>
    <paper id="35">
      <title>Simplifying metaphorical language for young readers : A corpus study on news text</title>
      <author><first>Magdalena</first><last>Wolska</last></author>
      <author><first>Yulia</first><last>Clausen</last></author>
      <pages>313–318</pages>
      <url hash="6da15064">W17-5035</url>
      <doi>10.18653/v1/W17-5035</doi>
      <abstract>The paper presents first results of an ongoing project on <a href="https://en.wikipedia.org/wiki/Text_simplification">text simplification</a> focusing on <a href="https://en.wikipedia.org/wiki/Metaphor">linguistic metaphors</a>. Based on an analysis of a parallel corpus of news text professionally simplified for different grade levels, we identify six types of simplification choices falling into two broad categories : preserving metaphors or dropping them. An annotation study on almost 300 source sentences with <a href="https://en.wikipedia.org/wiki/Metaphor">metaphors</a> (grade level 12) and their simplified counterparts (grade 4) is conducted. The results show that most <a href="https://en.wikipedia.org/wiki/Metaphor">metaphors</a> are preserved and when they are dropped, the semantic content tends to be preserved rather than dropped, however, it is reworded without metaphorical language. In general, some of the expected tendencies in <a href="https://en.wikipedia.org/wiki/Complexity_reduction">complexity reduction</a>, measured with psycholinguistic variables linked to metaphor comprehension, are observed, suggesting good prospect for machine learning-based metaphor simplification.</abstract>
      <bibkey>wolska-clausen-2017-simplifying</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/newsela">Newsela</pwcdataset>
    </paper>
    <paper id="37">
      <title>Connecting the Dots : Towards Human-Level Grammatical Error Correction</title>
      <author><first>Shamil</first><last>Chollampatt</last></author>
      <author><first>Hwee Tou</first><last>Ng</last></author>
      <pages>327–333</pages>
      <url hash="19659d06">W17-5037</url>
      <doi>10.18653/v1/W17-5037</doi>
      <abstract>We build a grammatical error correction (GEC) system primarily based on the state-of-the-art statistical machine translation (SMT) approach, using task-specific features and tuning, and further enhance it with the modeling power of neural network joint models. The SMT-based system is weak in generalizing beyond patterns seen during training and lacks granularity below the word level. To address this issue, we incorporate a character-level SMT component targeting the misspelled words that the original SMT-based system fails to correct. Our final <a href="https://en.wikipedia.org/wiki/System">system</a> achieves 53.14 % F 0.5 score on the benchmark CoNLL-2014 test set, an improvement of 3.62 % F 0.5 over the best previous published score.</abstract>
      <bibkey>chollampatt-ng-2017-connecting</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2014-shared-task-grammatical-error">CoNLL-2014 Shared Task: Grammatical Error Correction</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/jfleg">JFLEG</pwcdataset>
    </paper>
    <paper id="38">
      <title>Question Generation for <a href="https://en.wikipedia.org/wiki/Language_acquisition">Language Learning</a> : From ensuring texts are read to supporting learning</title>
      <author><first>Maria</first><last>Chinkina</last></author>
      <author><first>Detmar</first><last>Meurers</last></author>
      <pages>334–344</pages>
      <url hash="c94efaf5">W17-5038</url>
      <doi>10.18653/v1/W17-5038</doi>
      <abstract>In Foreign Language Teaching and Learning (FLTL), questions are systematically used to assess the learner’s understanding of a text. Computational linguistic approaches have been developed to generate such <a href="https://en.wikipedia.org/wiki/Question">questions</a> automatically given a text (e.g., Heilman, 2011). In this paper, we want to broaden the perspective on the different functions questions can play in FLTL and discuss how automatic question generation can support the different uses. Complementing the focus on meaning and comprehension, we want to highlight the fact that questions can also be used to make learners notice form aspects of the <a href="https://en.wikipedia.org/wiki/Linguistic_system">linguistic system</a> and their interpretation. Automatically generating questions that target linguistic forms and grammatical categories in a text in essence supports incidental focus-on-form (Loewen, 2005) in a meaning-focused reading task. We discuss two types of questions serving this purpose, how they can be generated automatically ; and we report on a crowd-sourcing evaluation comparing automatically generated to manually written questions targeting particle verbs, a challenging linguistic form for learners of <a href="https://en.wikipedia.org/wiki/English_language">English</a>.</abstract>
      <bibkey>chinkina-meurers-2017-question</bibkey>
    </paper>
    <paper id="39">
      <title>Systematically Adapting <a href="https://en.wikipedia.org/wiki/Machine_translation">Machine Translation</a> for Grammatical Error Correction</title>
      <author><first>Courtney</first><last>Napoles</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <pages>345–356</pages>
      <url hash="72b6c6e5">W17-5039</url>
      <doi>10.18653/v1/W17-5039</doi>
      <abstract>n this work we adapt machine translation (MT) to grammatical error correction, identifying how components of the statistical MT pipeline can be modified for this task and analyzing how each modification impacts system performance. We evaluate the contribution of each of these components with standard evaluation metrics and automatically characterize the morphological and lexical transformations made in system output. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> rivals the current state of the art using a fraction of the training data.</abstract>
      <bibkey>napoles-callison-burch-2017-systematically</bibkey>
      <pwccode url="https://github.com/cnap/smt-for-gec" additional="false">cnap/smt-for-gec</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/fce">FCE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/jfleg">JFLEG</pwcdataset>
    </paper>
    <paper id="40">
      <title>Fine-grained essay scoring of a complex writing task for native speakers</title>
      <author><first>Andrea</first><last>Horbach</last></author>
      <author><first>Dirk</first><last>Scholten-Akoun</last></author>
      <author><first>Yuning</first><last>Ding</last></author>
      <author><first>Torsten</first><last>Zesch</last></author>
      <pages>357–366</pages>
      <url hash="17ff4b5e">W17-5040</url>
      <doi>10.18653/v1/W17-5040</doi>
      <abstract>Automatic essay scoring is nowadays successfully used even in high-stakes tests, but this is mainly limited to holistic scoring of learner essays. We present a new dataset of <a href="https://en.wikipedia.org/wiki/Essay">essays</a> written by highly proficient German native speakers that is scored using a fine-grained rubric with the goal to provide detailed feedback. Our experiments with two state-of-the-art scoring systems (a neural and a SVM-based one) show a large drop in performance compared to existing datasets. This demonstrates the need for such <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> that allow to guide research on more elaborate essay scoring methods.</abstract>
      <bibkey>horbach-etal-2017-fine</bibkey>
    </paper>
    <paper id="42">
      <title>CIC-FBK Approach to Native Language Identification<fixed-case>CIC</fixed-case>-<fixed-case>FBK</fixed-case> Approach to Native Language Identification</title>
      <author><first>Ilia</first><last>Markov</last></author>
      <author><first>Lingzhen</first><last>Chen</last></author>
      <author><first>Carlo</first><last>Strapparava</last></author>
      <author><first>Grigori</first><last>Sidorov</last></author>
      <pages>374–381</pages>
      <url hash="ee973acf">W17-5042</url>
      <doi>10.18653/v1/W17-5042</doi>
      <abstract>We present the CIC-FBK system, which took part in the Native Language Identification (NLI) Shared Task 2017. Our approach combines <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> commonly used in previous NLI research, i.e., word n-grams, lemma n-grams, part-of-speech n-grams, and function words, with recently introduced character n-grams from misspelled words, and <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> that are novel in this task, such as typed character n-grams, and syntactic n-grams of words and of syntactic relation tags. We use log-entropy weighting scheme and perform <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> using the Support Vector Machines (SVM) algorithm. Our <a href="https://en.wikipedia.org/wiki/System">system</a> achieved 0.8808 macro-averaged F1-score and shared the 1st rank in the NLI Shared Task 2017 scoring.</abstract>
      <bibkey>markov-etal-2017-cic</bibkey>
    </paper>
    <paper id="43">
      <title>The Power of Character N-grams in Native Language Identification</title>
      <author><first>Artur</first><last>Kulmizev</last></author>
      <author><first>Bo</first><last>Blankers</last></author>
      <author><first>Johannes</first><last>Bjerva</last></author>
      <author><first>Malvina</first><last>Nissim</last></author>
      <author><first>Gertjan</first><last>van Noord</last></author>
      <author><first>Barbara</first><last>Plank</last></author>
      <author><first>Martijn</first><last>Wieling</last></author>
      <pages>382–389</pages>
      <url hash="92747834">W17-5043</url>
      <doi>10.18653/v1/W17-5043</doi>
      <abstract>In this paper, we explore the performance of a linear SVM trained on language independent character features for the NLI Shared Task 2017. Our basic <a href="https://en.wikipedia.org/wiki/System">system</a> (GRONINGEN) achieves the best performance (87.56 F1-score) on the evaluation set using only 1-9 character n-grams as <a href="https://en.wikipedia.org/wiki/Feature_(computer_vision)">features</a>. We compare this against several ensemble and meta-classifiers in order to examine how the <a href="https://en.wikipedia.org/wiki/Linear_system">linear system</a> fares when combined with other, especially non-linear classifiers. Special emphasis is placed on the topic bias that exists by virtue of the assessment essay prompt distribution.</abstract>
      <bibkey>kulmizev-etal-2017-power</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="44">
      <title>Classifier Stacking for Native Language Identification</title>
      <author><first>Wen</first><last>Li</last></author>
      <author><first>Liang</first><last>Zou</last></author>
      <pages>390–397</pages>
      <url hash="40cf159b">W17-5044</url>
      <doi>10.18653/v1/W17-5044</doi>
      <abstract>This paper reports our contribution (team WLZ) to the NLI Shared Task 2017 (essay track). We first extract lexical and syntactic features from the essays, perform feature weighting and selection, and train linear support vector machine (SVM) classifiers each on an individual feature type. The output of base classifiers, as probabilities for each class, are then fed into a <a href="https://en.wikipedia.org/wiki/Multilayer_perceptron">multilayer perceptron</a> to predict the native language of the author. We also report the performance of each feature type, as well as the best <a href="https://en.wikipedia.org/wiki/Software_feature">features</a> of a type. Our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 86.55 %, which is among the best performing <a href="https://en.wikipedia.org/wiki/System">systems</a> of this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">shared task</a>.</abstract>
      <bibkey>li-zou-2017-classifier</bibkey>
    </paper>
    <paper id="45">
      <title>Native Language Identification on Text and Speech</title>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <author><first>Alina Maria</first><last>Ciobanu</last></author>
      <author><first>Liviu P.</first><last>Dinu</last></author>
      <pages>398–404</pages>
      <url hash="23898633">W17-5045</url>
      <doi>10.18653/v1/W17-5045</doi>
      <abstract>This paper presents an <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble system</a> combining the output of multiple SVM classifiers to native language identification (NLI). The system was submitted to the NLI Shared Task 2017 fusion track which featured students essays and spoken responses in form of <a href="https://en.wikipedia.org/wiki/Transcription_(linguistics)">audio transcriptions</a> and iVectors by non-native English speakers of eleven native languages. Our system competed in the challenge under the team name ZCD and was based on an ensemble of SVM classifiers trained on <a href="https://en.wikipedia.org/wiki/Character_(computing)">character n-grams</a> achieving 83.58 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and ranking 3rd in the shared task.</abstract>
      <bibkey>zampieri-etal-2017-native</bibkey>
    </paper>
    <paper id="47">
      <title>A deep-learning based native-language classification by using a <a href="https://en.wikipedia.org/wiki/Latent_semantic_analysis">latent semantic analysis</a> for the NLI Shared Task 2017<fixed-case>NLI</fixed-case> Shared Task 2017</title>
      <author><first>Yoo Rhee</first><last>Oh</last></author>
      <author><first>Hyung-Bae</first><last>Jeon</last></author>
      <author><first>Hwa Jeon</first><last>Song</last></author>
      <author><first>Yun-Kyung</first><last>Lee</last></author>
      <author><first>Jeon-Gue</first><last>Park</last></author>
      <author><first>Yun-Keun</first><last>Lee</last></author>
      <pages>413–422</pages>
      <url hash="9565b944">W17-5047</url>
      <doi>10.18653/v1/W17-5047</doi>
      <abstract>This paper proposes a deep-learning based native-language identification (NLI) using a latent semantic analysis (LSA) as a participant (ETRI-SLP) of the NLI Shared Task 2017 where the NLI Shared Task 2017 aims to detect the native language of an essay or speech response of a standardized assessment of English proficiency for academic purposes. To this end, we use the six unit forms of a text data such as character 4/5/6-grams and word 1/2/3-grams. For each unit form of text data, we convert it into a count-based vector, extract a 2000-rank LSA feature, and perform a linear discriminant analysis (LDA) based dimension reduction. From the count-based vector or the LSA-LDA feature, we also obtain the output prediction values of a support vector machine (SVM) based classifier, the output prediction values of a deep neural network (DNN) based classifier, and the bottleneck values of a DNN based classifier. In order to incorporate the various kinds of text-based features and a speech-based i-vector feature, we design two DNN based ensemble classifiers for late fusion and early fusion, respectively. From the NLI experiments, the F1 (macro) scores are obtained as 0.8601, 0.8664, and 0.9220 for the essay track, the speech track, and the fusion track, respectively. The proposed method has comparable performance to the top-ranked teams for the speech and fusion tracks, although it has slightly lower performance for the essay track.</abstract>
      <bibkey>oh-etal-2017-deep</bibkey>
    </paper>
    <paper id="48">
      <title>Fusion of Simple Models for Native Language Identification</title>
      <author><first>Fabio</first><last>Kepler</last></author>
      <author><first>Ramon</first><last>F. Astudillo</last></author>
      <author><first>Alberto</first><last>Abad</last></author>
      <pages>423–429</pages>
      <url hash="db6d6575">W17-5048</url>
      <doi>10.18653/v1/W17-5048</doi>
      <abstract>In this paper we describe the approaches we explored for the 2017 Native Language Identification shared task. We focused on simple word and sub-word units avoiding heavy use of hand-crafted features. Following recent trends, we explored linear and neural networks models to attempt to compensate for the lack of rich feature use. Initial efforts yielded <a href="https://en.wikipedia.org/wiki/F-number">f1-scores</a> of 82.39 % and 83.77 % in the development and test sets of the <a href="https://en.wikipedia.org/wiki/Fusion_power">fusion track</a>, and were officially submitted to the task as team L2F. After the task was closed, we carried on further experiments and relied on a late fusion strategy for combining our simple proposed approaches with modifications of the baselines provided by the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. As expected, the i-vectors based sub-system dominates the performance of the system combinations, and results in the major contributor to our achieved scores. Our best combined <a href="https://en.wikipedia.org/wiki/System">system</a> achieves 90.1 % and 90.2 % <a href="https://en.wikipedia.org/wiki/F-number">f1-score</a> in the development and test sets of the <a href="https://en.wikipedia.org/wiki/Fusion_energy">fusion track</a>, respectively.</abstract>
      <bibkey>kepler-etal-2017-fusion</bibkey>
    </paper>
    <paper id="50">
      <title>Using Gaze to Predict Text Readability</title>
      <author><first>Ana Valeria</first><last>González-Garduño</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>438–443</pages>
      <url hash="da61e863">W17-5050</url>
      <doi>10.18653/v1/W17-5050</doi>
      <abstract>We show that text readability prediction improves significantly from hard parameter sharing with models predicting first pass duration, total fixation duration and regression duration. Specifically, we induce multi-task Multilayer Perceptrons and Logistic Regression models over sentence representations that capture various <a href="https://en.wikipedia.org/wiki/Aggregate_statistics">aggregate statistics</a>, from two different text readability corpora for English, as well as the Dundee eye-tracking corpus. Our approach leads to significant improvements over Single task learning and over previous <a href="https://en.wikipedia.org/wiki/System">systems</a>. In addition, our improvements are consistent across <a href="https://en.wikipedia.org/wiki/Sample_size_determination">train sample sizes</a>, making our approach especially applicable to <a href="https://en.wikipedia.org/wiki/Sample_size_determination">small datasets</a>.</abstract>
      <bibkey>gonzalez-garduno-sogaard-2017-using</bibkey>
    </paper>
    <paper id="51">
      <title>Annotating Orthographic Target Hypotheses in a German L1 Learner Corpus<fixed-case>G</fixed-case>erman <fixed-case>L</fixed-case>1 Learner Corpus</title>
      <author><first>Ronja</first><last>Laarmann-Quante</last></author>
      <author><first>Katrin</first><last>Ortmann</last></author>
      <author><first>Anna</first><last>Ehlert</last></author>
      <author><first>Maurice</first><last>Vogel</last></author>
      <author><first>Stefanie</first><last>Dipper</last></author>
      <pages>444–456</pages>
      <url hash="4cd9c088">W17-5051</url>
      <doi>10.18653/v1/W17-5051</doi>
      <abstract>NLP applications for learners often rely on annotated learner corpora. Thereby, it is important that the <a href="https://en.wikipedia.org/wiki/Annotation">annotations</a> are both meaningful for the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, and consistent and reliable. We present a new longitudinal L1 learner corpus for <a href="https://en.wikipedia.org/wiki/German_language">German</a> (handwritten texts collected in grade 24), which is transcribed and annotated with a target hypothesis that strictly only corrects orthographic errors, and is thereby tailored to research and tool development for orthographic issues in <a href="https://en.wikipedia.org/wiki/Primary_school">primary school</a>. While for most <a href="https://en.wikipedia.org/wiki/Corpus_linguistics">corpora</a>, <a href="https://en.wikipedia.org/wiki/Transcription_(biology)">transcription</a> and target hypothesis are not evaluated, we conducted a detailed inter-annotator agreement study for both tasks. Although we achieved high agreement, our discussion of cases of disagreement shows that even with detailed guidelines, annotators differ here and there for different reasons, which should also be considered when working with transcriptions and target hypotheses of other corpora, especially if no explicit guidelines for their construction are known.</abstract>
      <bibkey>laarmann-quante-etal-2017-annotating</bibkey>
    </paper>
    <paper id="52">
      <title>A Large Scale Quantitative Exploration of Modeling Strategies for Content Scoring</title>
      <author><first>Nitin</first><last>Madnani</last></author>
      <author><first>Anastassia</first><last>Loukina</last></author>
      <author><first>Aoife</first><last>Cahill</last></author>
      <pages>457–467</pages>
      <url hash="a968c033">W17-5052</url>
      <doi>10.18653/v1/W17-5052</doi>
      <abstract>We explore various supervised learning strategies for automated scoring of content knowledge for a large corpus of 130 different content-based questions spanning four subject areas (Science, Math, English Language Arts, and Social Studies) and containing over 230,000 responses scored by human raters. Based on our analyses, we provide specific recommendations for content scoring. These are based on patterns observed across multiple questions and assessments and are, therefore, likely to generalize to other scenarios and prove useful to the community as automated content scoring becomes more popular in schools and classrooms.</abstract>
      <bibkey>madnani-etal-2017-large</bibkey>
    </paper>
  </volume>
  <volume id="51">
    <meta>
      <booktitle>Proceedings of the 4th Workshop on Argument Mining</booktitle>
      <url hash="e429c94f">W17-51</url>
      <editor><first>Ivan</first><last>Habernal</last></editor>
      <editor><first>Iryna</first><last>Gurevych</last></editor>
      <editor><first>Kevin</first><last>Ashley</last></editor>
      <editor><first>Claire</first><last>Cardie</last></editor>
      <editor><first>Nancy</first><last>Green</last></editor>
      <editor><first>Diane</first><last>Litman</last></editor>
      <editor><first>Georgios</first><last>Petasis</last></editor>
      <editor><first>Chris</first><last>Reed</last></editor>
      <editor><first>Noam</first><last>Slonim</last></editor>
      <editor><first>Vern</first><last>Walker</last></editor>
      <doi>10.18653/v1/W17-51</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Copenhagen, Denmark</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="700d9dfd">W17-5100</url>
      <bibkey>ws-2017-argument</bibkey>
    </frontmatter>
    <paper id="1">
      <title>200K+ Crowdsourced Political Arguments for a New Chilean Constitution<fixed-case>K</fixed-case>+ Crowdsourced Political Arguments for a New <fixed-case>C</fixed-case>hilean Constitution</title>
      <author><first>Constanza</first><last>Fierro</last></author>
      <author><first>Claudio</first><last>Fuentes</last></author>
      <author><first>Jorge</first><last>Pérez</last></author>
      <author><first>Mauricio</first><last>Quezada</last></author>
      <pages>1–10</pages>
      <url hash="95995a04">W17-5101</url>
      <doi>10.18653/v1/W17-5101</doi>
      <abstract>In this paper we present the dataset of 200,000 + political arguments produced in the local phase of the 2016 Chilean constitutional process. We describe the human processing of this <a href="https://en.wikipedia.org/wiki/Data">data</a> by the government officials, and the manual tagging of arguments performed by members of our research group. Afterwards we focus on classification tasks that mimic the human processes, comparing <a href="https://en.wikipedia.org/wiki/Linear_map">linear methods</a> with neural network architectures. The experiments show that some of the <a href="https://en.wikipedia.org/wiki/Manual_labour">manual tasks</a> are suitable for <a href="https://en.wikipedia.org/wiki/Automation">automatization</a>. In particular, the best methods achieve a 90 % top-5 accuracy in a multi-class classification of arguments, and 65 % macro-averaged F1-score for tagging arguments according to a three-part argumentation model.</abstract>
      <bibkey>fierro-etal-2017-200k</bibkey>
    </paper>
    <paper id="2">
      <title>Analyzing the Semantic Types of Claims and Premises in an Online Persuasive Forum</title>
      <author><first>Christopher</first><last>Hidey</last></author>
      <author><first>Elena</first><last>Musi</last></author>
      <author><first>Alyssa</first><last>Hwang</last></author>
      <author><first>Smaranda</first><last>Muresan</last></author>
      <author><first>Kathy</first><last>McKeown</last></author>
      <pages>11–21</pages>
      <url hash="555c0a8b">W17-5102</url>
      <doi>10.18653/v1/W17-5102</doi>
      <abstract>Argumentative text has been analyzed both theoretically and computationally in terms of argumentative structure that consists of argument components (e.g., claims, premises) and their argumentative relations (e.g., support, attack). Less emphasis has been placed on analyzing the semantic types of <a href="https://en.wikipedia.org/wiki/Argument_(linguistics)">argument components</a>. We propose a two-tiered annotation scheme to label claims and premises and their semantic types in an online persuasive forum, Change My View, with the long-term goal of understanding what makes a message persuasive. Premises are annotated with the three types of persuasive modes : <a href="https://en.wikipedia.org/wiki/Ethos">ethos</a>, <a href="https://en.wikipedia.org/wiki/Logos">logos</a>, <a href="https://en.wikipedia.org/wiki/Pathos">pathos</a>, while claims are labeled as interpretation, evaluation, agreement, or disagreement, the latter two designed to account for the dialogical nature of our corpus. We aim to answer three questions : 1) can humans reliably annotate the semantic types of argument components? 2) are types of premises / claims positioned in recurrent orders? and 3) are certain types of claims and/or premises more likely to appear in persuasive messages than in non-persuasive messages?</abstract>
      <bibkey>hidey-etal-2017-analyzing</bibkey>
    </paper>
    <paper id="3">
      <title>Annotation of argument structure in Japanese legal documents<fixed-case>J</fixed-case>apanese legal documents</title>
      <author><first>Hiroaki</first><last>Yamada</last></author>
      <author><first>Simone</first><last>Teufel</last></author>
      <author><first>Takenobu</first><last>Tokunaga</last></author>
      <pages>22–31</pages>
      <url hash="eab3ca88">W17-5103</url>
      <doi>10.18653/v1/W17-5103</doi>
      <abstract>We propose a method for the annotation of Japanese civil judgment documents, with the purpose of creating flexible summaries of these. The first step, described in the current paper, concerns content selection, i.e., the question of which material should be extracted initially for the summary. In particular, we utilize the hierarchical argument structure of the <a href="https://en.wikipedia.org/wiki/Judgment_(law)">judgment documents</a>. Our main contributions are a) the design of an annotation scheme that stresses the connection between legal points (called issue topics) and argument structure, b) an adaptation of rhetorical status to suit the Japanese legal system and c) the definition of a linked argument structure based on legal sub-arguments. In this paper, we report agreement between two annotators on several aspects of the overall task.</abstract>
      <bibkey>yamada-etal-2017-annotation</bibkey>
    </paper>
    <paper id="4">
      <title>Improving Claim Stance Classification with Lexical Knowledge Expansion and Context Utilization</title>
      <author><first>Roy</first><last>Bar-Haim</last></author>
      <author><first>Lilach</first><last>Edelstein</last></author>
      <author><first>Charles</first><last>Jochim</last></author>
      <author><first>Noam</first><last>Slonim</last></author>
      <pages>32–38</pages>
      <url hash="b2884325">W17-5104</url>
      <doi>10.18653/v1/W17-5104</doi>
      <abstract>Stance classification is a core component in on-demand argument construction pipelines. Previous work on claim stance classification relied on background knowledge such as manually-composed sentiment lexicons. We show that both <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and <a href="https://en.wikipedia.org/wiki/Coverage_(telecommunication)">coverage</a> can be significantly improved through automatic expansion of the initial lexicon. We also developed a set of contextual features that further improves the state-of-the-art for this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>.</abstract>
      <bibkey>bar-haim-etal-2017-improving</bibkey>
    </paper>
    <paper id="5">
      <title>Mining Argumentative Structure from Natural Language text using Automatically Generated Premise-Conclusion Topic Models</title>
      <author><first>John</first><last>Lawrence</last></author>
      <author><first>Chris</first><last>Reed</last></author>
      <pages>39–48</pages>
      <url hash="66848df1">W17-5105</url>
      <doi>10.18653/v1/W17-5105</doi>
      <abstract>This paper presents a <a href="https://en.wikipedia.org/wiki/Scientific_method">method</a> of extracting argumentative structure from <a href="https://en.wikipedia.org/wiki/Natural_language">natural language text</a>. The approach presented is based on the way in which we understand an argument being made, not just from the words said, but from existing <a href="https://en.wikipedia.org/wiki/Context_(language_use)">contextual knowledge</a> and understanding of the broader issues. We leverage high-precision, low-recall techniques in order to automatically build a large corpus of inferential statements related to the text’s topic. These <a href="https://en.wikipedia.org/wiki/Statement_(logic)">statements</a> are then used to produce a <a href="https://en.wikipedia.org/wiki/Matrix_(mathematics)">matrix</a> representing the <a href="https://en.wikipedia.org/wiki/Inference">inferential relationship</a> between different aspects of the topic. From this <a href="https://en.wikipedia.org/wiki/Matrix_(mathematics)">matrix</a>, we are able to determine connectedness and directionality of inference between statements in the original text. By following this approach, we obtain results that compare favourably to those of other similar techniques to classify premise-conclusion pairs (with results 22 points above baseline), but without the requirement of large volumes of annotated, domain specific data.</abstract>
      <bibkey>lawrence-reed-2017-mining</bibkey>
    </paper>
    <paper id="6">
      <title>Building an Argument Search Engine for the <a href="https://en.wikipedia.org/wiki/World_Wide_Web">Web</a></title>
      <author><first>Henning</first><last>Wachsmuth</last></author>
      <author><first>Martin</first><last>Potthast</last></author>
      <author><first>Khalid</first><last>Al-Khatib</last></author>
      <author><first>Yamen</first><last>Ajjour</last></author>
      <author><first>Jana</first><last>Puschmann</last></author>
      <author><first>Jiani</first><last>Qu</last></author>
      <author><first>Jonas</first><last>Dorsch</last></author>
      <author><first>Viorel</first><last>Morari</last></author>
      <author><first>Janek</first><last>Bevendorff</last></author>
      <author><first>Benno</first><last>Stein</last></author>
      <pages>49–59</pages>
      <url hash="c632d16d">W17-5106</url>
      <doi>10.18653/v1/W17-5106</doi>
      <abstract>Computational argumentation is expected to play a critical role in the future of <a href="https://en.wikipedia.org/wiki/Web_search_engine">web search</a>. To make this happen, many search-related questions must be revisited, such as how people query for arguments, how to mine arguments from the web, or how to rank them. In this paper, we develop an argument search framework for studying these and further questions. The framework allows for the composition of approaches to acquiring, mining, assessing, indexing, querying, retrieving, ranking, and presenting arguments while relying on standard infrastructure and interfaces. Based on the <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a>, we build a prototype search engine, called args, that relies on an initial, freely accessible index of nearly 300k arguments crawled from reliable <a href="https://en.wikipedia.org/wiki/Web_resource">web resources</a>. The <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> and the argument search engine are intended as an environment for collaborative research on computational argumentation and its practical evaluation.</abstract>
      <bibkey>wachsmuth-etal-2017-building</bibkey>
    </paper>
    <paper id="7">
      <title>Argument Relation Classification Using a Joint Inference Model</title>
      <author><first>Yufang</first><last>Hou</last></author>
      <author><first>Charles</first><last>Jochim</last></author>
      <pages>60–66</pages>
      <url hash="1b02cd76">W17-5107</url>
      <doi>10.18653/v1/W17-5107</doi>
      <abstract>In this paper, we address the problem of argument relation classification where <a href="https://en.wikipedia.org/wiki/Argument_(linguistics)">argument units</a> are from different texts. We design a joint inference method for the task by modeling argument relation classification and <a href="https://en.wikipedia.org/wiki/Stance_(linguistics)">stance classification</a> jointly. We show that our joint model improves the results over several strong baselines.</abstract>
      <bibkey>hou-jochim-2017-argument</bibkey>
    </paper>
    <paper id="8">
      <title>Projection of Argumentative Corpora from Source to Target Languages</title>
      <author><first>Ahmet</first><last>Aker</last></author>
      <author><first>Huangpan</first><last>Zhang</last></author>
      <pages>67–72</pages>
      <url hash="17f3ccb4">W17-5108</url>
      <doi>10.18653/v1/W17-5108</doi>
      <attachment type="attachment" hash="12a22abd">W17-5108.Attachment.txt</attachment>
      <abstract>Argumentative corpora are costly to create and are available in only few languages with <a href="https://en.wikipedia.org/wiki/English_language">English</a> dominating the area. In this paper we release the first publicly available Mandarin argumentative corpus. The <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> is created by exploiting the idea of comparable corpora from <a href="https://en.wikipedia.org/wiki/Statistical_machine_translation">Statistical Machine Translation</a>. We use existing <a href="https://en.wikipedia.org/wiki/Text_corpus">corpora</a> in <a href="https://en.wikipedia.org/wiki/English_language">English</a> and manually map the claims and premises to comparable corpora in <a href="https://en.wikipedia.org/wiki/Mandarin_Chinese">Mandarin</a>. We also implement a simple solution to automate this approach with the view of creating argumentative corpora in other less-resourced languages. In this way we introduce a new task of multi-lingual argument mapping that can be evaluated using our English-Mandarin argumentative corpus. The preliminary results of our automatic argument mapper mirror the simplicity of our approach, but provide a baseline for further improvements.</abstract>
      <bibkey>aker-zhang-2017-projection</bibkey>
    </paper>
    <paper id="9">
      <title>Manual Identification of Arguments with Implicit Conclusions Using Semantic Rules for Argument Mining</title>
      <author><first>Nancy</first><last>Green</last></author>
      <pages>73–78</pages>
      <url hash="1aca8fdb">W17-5109</url>
      <doi>10.18653/v1/W17-5109</doi>
      <abstract>This paper describes a pilot study to evaluate human analysts’ ability to identify the <a href="https://en.wikipedia.org/wiki/Argumentation_theory">argumentation scheme</a> and premises of an argument having an implicit conclusion. In preparation for the study, argumentation scheme definitions were crafted for <a href="https://en.wikipedia.org/wiki/Scientific_literature">genetics research articles</a>. The schemes were defined in <a href="https://en.wikipedia.org/wiki/Semantics">semantic terms</a>, following a proposal to use semantic rules to mine arguments in that literature.</abstract>
      <bibkey>green-2017-manual</bibkey>
    </paper>
    <paper id="10">
      <title>Unsupervised corpuswide claim detection</title>
      <author><first>Ran</first><last>Levy</last></author>
      <author><first>Shai</first><last>Gretz</last></author>
      <author><first>Benjamin</first><last>Sznajder</last></author>
      <author><first>Shay</first><last>Hummel</last></author>
      <author><first>Ranit</first><last>Aharonov</last></author>
      <author><first>Noam</first><last>Slonim</last></author>
      <pages>79–84</pages>
      <url hash="80aaf25a">W17-5110</url>
      <doi>10.18653/v1/W17-5110</doi>
      <attachment type="attachment" hash="fc36c7d8">W17-5110.Attachment.zip</attachment>
      <abstract>Automatic claim detection is a fundamental argument mining task that aims to automatically mine claims regarding a topic of consideration. Previous works on mining argumentative content have assumed that a set of relevant documents is given in advance. Here, we present a first corpus wide claim detection framework, that can be directly applied to massive corpora. Using simple and intuitive empirical observations, we derive a claim sentence query by which we are able to directly retrieve sentences in which the <a href="https://en.wikipedia.org/wiki/Prior_probability">prior probability</a> to include topic-relevant claims is greatly enhanced. Next, we employ simple <a href="https://en.wikipedia.org/wiki/Heuristic">heuristics</a> to rank the sentences, leading to an unsupervised corpuswide claim detection system, with precision that outperforms previously reported results on the task of claim detection given relevant documents and labeled data.</abstract>
      <bibkey>levy-etal-2017-unsupervised</bibkey>
    </paper>
    <paper id="11">
      <title>Using Question-Answering Techniques to Implement a Knowledge-Driven Argument Mining Approach</title>
      <author><first>Patrick</first><last>Saint-Dizier</last></author>
      <pages>85–90</pages>
      <url hash="5b0d7869">W17-5111</url>
      <doi>10.18653/v1/W17-5111</doi>
      <abstract>This short paper presents a first implementation of a knowledge-driven argument mining approach. The major processing steps and <a href="https://en.wikipedia.org/wiki/Resource_(computer_science)">language resources</a> of the <a href="https://en.wikipedia.org/wiki/System">system</a> are surveyed. An indicative evaluation outlines challenges and improvement directions.</abstract>
      <bibkey>saint-dizier-2017-using</bibkey>
    </paper>
    <paper id="12">
      <title>What works and what does not : Classifier and feature analysis for <a href="https://en.wikipedia.org/wiki/Argument_mining">argument mining</a></title>
      <author><first>Ahmet</first><last>Aker</last></author>
      <author><first>Alfred</first><last>Sliwa</last></author>
      <author><first>Yuan</first><last>Ma</last></author>
      <author><first>Ruishen</first><last>Lui</last></author>
      <author><first>Niravkumar</first><last>Borad</last></author>
      <author><first>Seyedeh</first><last>Ziyaei</last></author>
      <author><first>Mina</first><last>Ghobadi</last></author>
      <pages>91–96</pages>
      <url hash="3085c27a">W17-5112</url>
      <doi>10.18653/v1/W17-5112</doi>
      <abstract>This paper offers a comparative analysis of the performance of different supervised machine learning methods and <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">feature sets</a> on argument mining tasks. Specifically, we address the tasks of extracting argumentative segments from texts and predicting the structure between those <a href="https://en.wikipedia.org/wiki/Segment_(linguistics)">segments</a>. Eight <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> and different combinations of six feature types reported in previous work are evaluated. The results indicate that overall best performing features are the structural ones. Although the performance of <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> varies depending on the feature combinations and corpora used for training and testing, <a href="https://en.wikipedia.org/wiki/Random_forest">Random Forest</a> seems to be among the best performing <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a>. These results build a basis for further development of <a href="https://en.wikipedia.org/wiki/Argument_mining">argument mining techniques</a> and can guide an implementation of <a href="https://en.wikipedia.org/wiki/Argument_mining">argument mining</a> into different applications such as argument based search.</abstract>
      <bibkey>aker-etal-2017-works</bibkey>
    </paper>
    <paper id="13">
      <title>Unsupervised Detection of Argumentative Units though Topic Modeling Techniques</title>
      <author><first>Alfio</first><last>Ferrara</last></author>
      <author><first>Stefano</first><last>Montanelli</last></author>
      <author><first>Georgios</first><last>Petasis</last></author>
      <pages>97–107</pages>
      <url hash="bdd0759f">W17-5113</url>
      <doi>10.18653/v1/W17-5113</doi>
      <abstract>In this paper we present a new unsupervised approach, Attraction to Topics   A2 T, for the detection of argumentative units, a sub-task of <a href="https://en.wikipedia.org/wiki/Argument_mining">argument mining</a>. Motivated by the importance of topic identification in manual annotation, we examine whether <a href="https://en.wikipedia.org/wiki/Topic_modeling">topic modeling</a> can be used for performing unsupervised detection of argumentative sentences, and to what extend <a href="https://en.wikipedia.org/wiki/Topic_modeling">topic modeling</a> can be used to classify sentences as claims and premises. Preliminary evaluation results suggest that topic information can be successfully used for the detection of argumentative sentences, at least for corpora used for evaluation. Our approach has been evaluated on two English corpora, the first of which contains 90 persuasive essays, while the second is a collection of 340 documents from <a href="https://en.wikipedia.org/wiki/User-generated_content">user generated content</a>.</abstract>
      <bibkey>ferrara-etal-2017-unsupervised</bibkey>
    </paper>
    <paper id="14">
      <title>Using Complex Argumentative Interactions to Reconstruct the Argumentative Structure of Large-Scale Debates</title>
      <author><first>John</first><last>Lawrence</last></author>
      <author><first>Chris</first><last>Reed</last></author>
      <pages>108–117</pages>
      <url hash="fc2cd5d1">W17-5114</url>
      <doi>10.18653/v1/W17-5114</doi>
      <abstract>In this paper we consider the insights that can be gained by considering large scale argument networks and the complex interactions between their constituent propositions. We investigate <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> for analysing properties of these <a href="https://en.wikipedia.org/wiki/Social_network">networks</a>, illustrating these using a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus of arguments</a> taken from the 2016 US Presidential Debates. We present techniques for determining these <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">features</a> directly from <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language text</a> and show that there is a strong correlation between these automatically identified <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">features</a> and the argumentative structure contained within the text. Finally, we combine these <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> with argument mining techniques and show how the identification of argumentative relations can be improved by considering the larger context in which they occur.</abstract>
      <bibkey>lawrence-reed-2017-using</bibkey>
    </paper>
    <paper id="15">
      <title>Unit Segmentation of Argumentative Texts</title>
      <author><first>Yamen</first><last>Ajjour</last></author>
      <author><first>Wei-Fan</first><last>Chen</last></author>
      <author><first>Johannes</first><last>Kiesel</last></author>
      <author><first>Henning</first><last>Wachsmuth</last></author>
      <author><first>Benno</first><last>Stein</last></author>
      <pages>118–128</pages>
      <url hash="c8fa9c85">W17-5115</url>
      <doi>10.18653/v1/W17-5115</doi>
      <abstract>The segmentation of an argumentative text into argument units and their non-argumentative counterparts is the first step in identifying the argumentative structure of the text. Despite its importance for <a href="https://en.wikipedia.org/wiki/Argument_mining">argument mining</a>, unit segmentation has been approached only sporadically so far. This paper studies the major parameters of unit segmentation systematically. We explore the effectiveness of various <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>, when capturing words separately, along with their neighbors, or even along with the entire text. Each such context is reflected by one <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning model</a> that we evaluate within and across three domains of texts. Among the <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a>, our new deep learning approach capturing the entire text turns out best within all domains, with an F-score of up to 88.54. While structural features generalize best across domains, the <a href="https://en.wikipedia.org/wiki/Domain_transfer">domain transfer</a> remains hard, which points to major challenges of unit segmentation.</abstract>
      <bibkey>ajjour-etal-2017-unit</bibkey>
      <pwccode url="https://github.com/webis-de/unit-segmentation-of-argumentative-texts" additional="false">webis-de/unit-segmentation-of-argumentative-texts</pwccode>
    </paper>
  </volume>
  <volume id="52">
    <meta>
      <booktitle>Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</booktitle>
      <url hash="68aa2440">W17-52</url>
      <editor><first>Alexandra</first><last>Balahur</last></editor>
      <editor><first>Saif M.</first><last>Mohammad</last></editor>
      <editor><first>Erik</first><last>van der Goot</last></editor>
      <doi>10.18653/v1/W17-52</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Copenhagen, Denmark</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="68fbec9c">W17-5200</url>
      <bibkey>ws-2017-approaches</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Detecting Sarcasm Using Different Forms Of Incongruity</title>
      <author><first>Aditya</first><last>Joshi</last></author>
      <pages>1</pages>
      <url hash="19c082ba">W17-5201</url>
      <doi>10.18653/v1/W17-5201</doi>
      <abstract>Sarcasm is a form of <a href="https://en.wikipedia.org/wiki/Irony">verbal irony</a> that is intended to express contempt or ridicule. Often quoted as a challenge to <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a>, <a href="https://en.wikipedia.org/wiki/Sarcasm">sarcasm</a> involves use of words of positive or no polarity to convey negative sentiment. Incongruity has been observed to be at the heart of sarcasm understanding in humans. Our work in sarcasm detection identifies different forms of incongruity and employs different machine learning techniques to capture them. This talk will describe the approach, datasets and challenges in sarcasm detection using different forms of incongruity. We identify two forms of <a href="https://en.wikipedia.org/wiki/Incongruity">incongruity</a> : <a href="https://en.wikipedia.org/wiki/Incongruity">incongruity</a> which can be understood based on the target text and common background knowledge, and <a href="https://en.wikipedia.org/wiki/Incongruity">incongruity</a> which can be understood based on the target text and additional, specific context. The former involves use of <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment-based features</a>, <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>, and <a href="https://en.wikipedia.org/wiki/Topic_model">topic models</a>. The latter involves creation of author’s historical context based on their historical data, and creation of conversational context for sarcasm detection of dialogue.</abstract>
      <bibkey>joshi-2017-detecting</bibkey>
    </paper>
    <paper id="3">
      <title>Annotation, Modelling and Analysis of Fine-Grained Emotions on a Stance and Sentiment Detection Corpus</title>
      <author><first>Hendrik</first><last>Schuff</last></author>
      <author><first>Jeremy</first><last>Barnes</last></author>
      <author><first>Julian</first><last>Mohme</last></author>
      <author><first>Sebastian</first><last>Padó</last></author>
      <author><first>Roman</first><last>Klinger</last></author>
      <pages>13–23</pages>
      <url hash="91de65d7">W17-5203</url>
      <doi>10.18653/v1/W17-5203</doi>
      <abstract>There is a rich variety of data sets for sentiment analysis (viz., polarity and subjectivity classification). For the more challenging task of detecting discrete emotions following the definitions of Ekman and Plutchik, however, there are much fewer data sets, and notably no resources for the social media domain. This paper contributes to closing this gap by extending the SemEval 2016 stance and sentiment datasetwith emotion annotation. We (a) analyse annotation reliability and annotation merging ; (b) investigate the relation between emotion annotation and the other annotation layers (stance, sentiment) ; (c) report modelling results as a baseline for future work.<i>SemEval 2016 stance and sentiment dataset</i>

with emotion annotation. We (a) analyse annotation reliability and annotation merging; (b) investigate the relation between emotion annotation and the other annotation layers (stance, sentiment); (c) report modelling results as a baseline for future work. </abstract>
      <attachment type="presentation" hash="b8f5a99c">W17-5203.Presentation.pdf</attachment>
      <bibkey>schuff-etal-2017-annotation</bibkey>
    </paper>
    <paper id="4">
      <title>Ranking Right-Wing Extremist Social Media Profiles by Similarity to Democratic and Extremist Groups</title>
      <author><first>Matthias</first><last>Hartung</last></author>
      <author><first>Roman</first><last>Klinger</last></author>
      <author><first>Franziska</first><last>Schmidtke</last></author>
      <author><first>Lars</first><last>Vogel</last></author>
      <pages>24–33</pages>
      <url hash="5f1141a2">W17-5204</url>
      <doi>10.18653/v1/W17-5204</doi>
      <abstract>Social media are used by an increasing number of political actors. A small subset of these is interested in pursuing extremist motives such as <a href="https://en.wikipedia.org/wiki/Mobilization">mobilization</a>, recruiting or radicalization activities. In order to counteract these trends, online providers and state institutions reinforce their monitoring efforts, mostly relying on manual workflows. We propose a machine learning approach to support manual attempts towards identifying right-wing extremist content in <a href="https://en.wikipedia.org/wiki/Twitter">German Twitter profiles</a>. Based on a fine-grained conceptualization of <a href="https://en.wikipedia.org/wiki/Far-right_politics">right-wing extremism</a>, we frame the task as ranking each individual profile on a continuum spanning different degrees of <a href="https://en.wikipedia.org/wiki/Far-right_politics">right-wing extremism</a>, based on a <a href="https://en.wikipedia.org/wiki/Nearest_neighbour_search">nearest neighbour approach</a>. A quantitative evaluation reveals that our <a href="https://en.wikipedia.org/wiki/Ranking_(statistics)">ranking model</a> yields robust performance (up to 0.81 F_1 score) when being used for predicting discrete class labels. At the same time, the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> provides plausible continuous ranking scores for a small sample of borderline cases at the division of right-wing extremism and New Right political movements.<tex-math>_1</tex-math> score) when being used for predicting discrete class labels. At the same time, the model provides plausible continuous ranking scores for a small sample of borderline cases at the division of right-wing extremism and New Right political movements. </abstract>
      <bibkey>hartung-etal-2017-ranking</bibkey>
    </paper>
    <paper id="5">
      <title>WASSA-2017 Shared Task on Emotion Intensity<fixed-case>WASSA</fixed-case>-2017 Shared Task on Emotion Intensity</title>
      <author><first>Saif</first><last>Mohammad</last></author>
      <author><first>Felipe</first><last>Bravo-Marquez</last></author>
      <pages>34–49</pages>
      <url hash="bf540ff8">W17-5205</url>
      <doi>10.18653/v1/W17-5205</doi>
      <abstract>We present the first shared task on detecting the intensity of emotion felt by the speaker of a tweet. We create the first datasets of <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> annotated for <a href="https://en.wikipedia.org/wiki/Anger">anger</a>, <a href="https://en.wikipedia.org/wiki/Fear">fear</a>, <a href="https://en.wikipedia.org/wiki/Joy">joy</a>, and sadness intensities using a technique called bestworst scaling (BWS). We show that the annotations lead to reliable fine-grained intensity scores (rankings of tweets by intensity). The <a href="https://en.wikipedia.org/wiki/Data">data</a> was partitioned into training, development, and test sets for the competition. Twenty-two teams participated in the shared task, with the best system obtaining a Pearson correlation of 0.747 with the gold intensity scores. We summarize the machine learning setups, resources, and tools used by the participating teams, with a focus on the techniques and resources that are particularly useful for the task. The emotion intensity dataset and the shared task are helping improve our understanding of how we convey more or less intense emotions through language.</abstract>
      <bibkey>mohammad-bravo-marquez-2017-wassa</bibkey>
    </paper>
    <paper id="6">
      <title>IMS at EmoInt-2017 : Emotion Intensity Prediction with Affective Norms, Automatically Extended Resources and <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a><fixed-case>IMS</fixed-case> at <fixed-case>E</fixed-case>mo<fixed-case>I</fixed-case>nt-2017: Emotion Intensity Prediction with Affective Norms, Automatically Extended Resources and Deep Learning</title>
      <author><first>Maximilian</first><last>Köper</last></author>
      <author><first>Evgeny</first><last>Kim</last></author>
      <author><first>Roman</first><last>Klinger</last></author>
      <pages>50–57</pages>
      <url hash="0fb17ba2">W17-5206</url>
      <doi>10.18653/v1/W17-5206</doi>
      <abstract>Our submission to the WASSA-2017 shared task on the prediction of emotion intensity in tweets is a supervised learning method with extended lexicons of affective norms. We combine three main information sources in a random forrest regressor, namely (1), manually created resources, (2) automatically extended lexicons, and (3) the output of a neural network (CNN-LSTM) for sentence regression. All three <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">feature sets</a> perform similarly well in isolation (.67 macro average Pearson correlation). The <a href="https://en.wikipedia.org/wiki/Combination">combination</a> achieves.72 on the official test set (ranked 2nd out of 22 participants). Our analysis reveals that performance is increased by providing cross-emotional intensity predictions. The automatic extension of lexicon features benefit from domain specific embeddings. Complementary ratings for affective norms increase the impact of <a href="https://en.wikipedia.org/wiki/Lexicon">lexicon features</a>. Our resources (ratings for 1.6 million twitter specific words) and our <a href="https://en.wikipedia.org/wiki/Implementation">implementation</a> is publicly available at.<url>http://www.ims.uni-stuttgart.de/data/ims_emoint</url>.
    </abstract>
      <bibkey>koper-etal-2017-ims</bibkey>
    </paper>
    <paper id="7">
      <title>Prayas at EmoInt 2017 : An Ensemble of Deep Neural Architectures for Emotion Intensity Prediction in Tweets<fixed-case>E</fixed-case>mo<fixed-case>I</fixed-case>nt 2017: An Ensemble of Deep Neural Architectures for Emotion Intensity Prediction in Tweets</title>
      <author><first>Pranav</first><last>Goel</last></author>
      <author><first>Devang</first><last>Kulshreshtha</last></author>
      <author><first>Prayas</first><last>Jain</last></author>
      <author><first>Kaushal Kumar</first><last>Shukla</last></author>
      <pages>58–65</pages>
      <url hash="64dce5f5">W17-5207</url>
      <doi>10.18653/v1/W17-5207</doi>
      <abstract>The paper describes the best performing system for EmoInt-a shared task to predict the intensity of emotions in tweets. Intensity is a real valued score, between 0 and 1. The <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a> are classified as-anger, <a href="https://en.wikipedia.org/wiki/Fear">fear</a>, <a href="https://en.wikipedia.org/wiki/Joy">joy</a> and sadness. We apply three different deep neural network based models, which approach the problem from essentially different directions. Our final performance quantified by an average pearson correlation score of 74.7 and an average spearman correlation score of 73.5 is obtained using an <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble</a> of the three <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>. We outperform the <a href="https://en.wikipedia.org/wiki/Baseline_(medicine)">baseline model</a> of the shared task by 9.9 % and 9.4 % pearson and spearman correlation scores respectively.</abstract>
      <bibkey>goel-etal-2017-prayas</bibkey>
    </paper>
    <paper id="9">
      <title>Towards Syntactic Iberian Polarity Classification<fixed-case>I</fixed-case>berian Polarity Classification</title>
      <author><first>David</first><last>Vilares</last></author>
      <author><first>Marcos</first><last>Garcia</last></author>
      <author><first>Miguel A.</first><last>Alonso</last></author>
      <author><first>Carlos</first><last>Gómez-Rodríguez</last></author>
      <pages>67–73</pages>
      <url hash="5328ccf7">W17-5209</url>
      <doi>10.18653/v1/W17-5209</doi>
      <abstract>Lexicon-based methods using syntactic rules for polarity classification rely on <a href="https://en.wikipedia.org/wiki/Parsing">parsers</a> that are dependent on the language and on <a href="https://en.wikipedia.org/wiki/Treebank">treebank guidelines</a>. Thus, <a href="https://en.wikipedia.org/wiki/Rule_of_inference">rules</a> are also dependent and require adaptation, especially in multilingual scenarios. We tackle this challenge in the context of the <a href="https://en.wikipedia.org/wiki/Iberian_Peninsula">Iberian Peninsula</a>, releasing the first symbolic syntax-based Iberian system with rules shared across five official languages : <a href="https://en.wikipedia.org/wiki/Basque_language">Basque</a>, <a href="https://en.wikipedia.org/wiki/Catalan_language">Catalan</a>, <a href="https://en.wikipedia.org/wiki/Galician_language">Galician</a>, <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a> and <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>. The model is made available.</abstract>
      <bibkey>vilares-etal-2017-towards</bibkey>
      <pwccode url="https://github.com/aghie/uuusa" additional="false">aghie/uuusa</pwccode>
    </paper>
    <paper id="12">
      <title>Forecasting Consumer Spending from Purchase Intentions Expressed on <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a></title>
      <author><first>Viktor</first><last>Pekar</last></author>
      <author><first>Jane</first><last>Binner</last></author>
      <pages>92–101</pages>
      <url hash="07c88256">W17-5212</url>
      <doi>10.18653/v1/W17-5212</doi>
      <abstract>Consumer spending is an important macroeconomic indicator that is used by policy-makers to judge the health of an economy. In this paper we present a novel method for predicting future consumer spending from <a href="https://en.wikipedia.org/wiki/Social_media">social media data</a>. In contrast to previous work that largely relied on <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a>, the proposed method models <a href="https://en.wikipedia.org/wiki/Consumer_spending">consumer spending</a> from purchase intentions found on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. Our experiments with time series analysis models and machine-learning regression models reveal utility of this data for making short-term forecasts of consumer spending : for three- and seven-day horizons, prediction variables derived from social media help to improve forecast accuracy by 11 % to 18 % for all the three models, in comparison to models that used only autoregressive predictors.</abstract>
      <bibkey>pekar-binner-2017-forecasting</bibkey>
    </paper>
    <paper id="13">
      <title>Mining fine-grained opinions on closed captions of YouTube videos with an attention-RNN<fixed-case>Y</fixed-case>ou<fixed-case>T</fixed-case>ube videos with an attention-<fixed-case>RNN</fixed-case></title>
      <author><first>Edison</first><last>Marrese-Taylor</last></author>
      <author><first>Jorge</first><last>Balazs</last></author>
      <author><first>Yutaka</first><last>Matsuo</last></author>
      <pages>102–111</pages>
      <url hash="b69f7de9">W17-5213</url>
      <doi>10.18653/v1/W17-5213</doi>
      <abstract>Video reviews are the natural evolution of written product reviews. In this paper we target this phenomenon and introduce the first dataset created from closed captions of YouTube product review videos as well as a new attention-RNN model for <a href="https://en.wikipedia.org/wiki/Aspect_extraction">aspect extraction</a> and joint aspect extraction and sentiment classification. Our model provides state-of-the-art performance on <a href="https://en.wikipedia.org/wiki/Aspect_extraction">aspect extraction</a> without requiring the usage of hand-crafted features on the SemEval ABSA corpus, while it outperforms the baseline on the joint task. In our dataset, the attention-RNN model outperforms the baseline for both tasks, but we observe important performance drops for all models in comparison to <a href="https://en.wikipedia.org/wiki/SemEval">SemEval</a>. These results, as well as further experiments on <a href="https://en.wikipedia.org/wiki/Domain_adaptation">domain adaptation</a> for <a href="https://en.wikipedia.org/wiki/Aspect_extraction">aspect extraction</a>, suggest that differences between speech and written text, which have been discussed extensively in the literature, also extend to the domain of product reviews, where they are relevant for fine-grained opinion mining.</abstract>
      <bibkey>marrese-taylor-etal-2017-mining</bibkey>
      <pwccode url="https://github.com/epochx/opinatt" additional="false">epochx/opinatt</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/youtubean">Youtubean</pwcdataset>
    </paper>
    <paper id="16">
      <title>Investigating Redundancy in Emoji Use : Study on a Twitter Based Corpus<fixed-case>T</fixed-case>witter Based Corpus</title>
      <author><first>Giulia</first><last>Donato</last></author>
      <author><first>Patrizia</first><last>Paggio</last></author>
      <pages>118–126</pages>
      <url hash="d58ee996">W17-5216</url>
      <doi>10.18653/v1/W17-5216</doi>
      <abstract>In this paper we present an annotated corpus created with the aim of analyzing the informative behaviour of <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a>   an issue of importance for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> and <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. The corpus consists of 2475 tweets all containing at least one <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a>, which has been annotated using one of the three possible classes : <a href="https://en.wikipedia.org/wiki/Redundancy_(information_theory)">Redundant</a>, Non Redundant, and Non Redundant + POS. We explain how the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> was collected, describe the annotation procedure and the <a href="https://en.wikipedia.org/wiki/Interface_(computing)">interface</a> developed for the task. We provide an analysis of the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>, considering also possible predictive features, discuss the problematic aspects of the <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a>, and suggest future improvements.</abstract>
      <bibkey>donato-paggio-2017-investigating</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
    </paper>
    <paper id="17">
      <title>Modeling Temporal Progression of Emotional Status in Mental Health Forum : A Recurrent Neural Net Approach</title>
      <author><first>Kishaloy</first><last>Halder</last></author>
      <author><first>Lahari</first><last>Poddar</last></author>
      <author><first>Min-Yen</first><last>Kan</last></author>
      <pages>127–135</pages>
      <url hash="7a77ffac">W17-5217</url>
      <doi>10.18653/v1/W17-5217</doi>
      <abstract>Patients turn to <a href="https://en.wikipedia.org/wiki/Online_health_communities">Online Health Communities</a> not only for information on specific conditions but also for <a href="https://en.wikipedia.org/wiki/Emotional_support">emotional support</a>. Previous research has indicated that the progression of emotional status can be studied through the linguistic patterns of an individual’s posts. We analyze a real-world dataset from the Mental Health section of HealthBoards.com. Estimated from the word usages in their posts, we find that the emotional progress across patients vary widely. We study the problem of predicting a patient’s emotional status in the future from her past posts and we propose a Recurrent Neural Network (RNN) based architecture to address it. We find that the future emotional status can be predicted with reasonable accuracy given her historical posts and participation features. Our evaluation results demonstrate the efficacy of our proposed <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a>, by outperforming <a href="https://en.wikipedia.org/wiki/Software_architecture">state-of-the-art approaches</a> with over 0.13 reduction in <a href="https://en.wikipedia.org/wiki/Mean_absolute_error">Mean Absolute Error</a>.</abstract>
      <bibkey>halder-etal-2017-modeling</bibkey>
    </paper>
    <paper id="18">
      <title>Towards an integrated pipeline for aspect-based sentiment analysis in various domains</title>
      <author><first>Orphée</first><last>De Clercq</last></author>
      <author><first>Els</first><last>Lefever</last></author>
      <author><first>Gilles</first><last>Jacobs</last></author>
      <author><first>Tijl</first><last>Carpels</last></author>
      <author><first>Véronique</first><last>Hoste</last></author>
      <pages>136–142</pages>
      <url hash="749e5a8c">W17-5218</url>
      <doi>10.18653/v1/W17-5218</doi>
      <abstract>This paper presents an integrated ABSA pipeline for <a href="https://en.wikipedia.org/wiki/Dutch_language">Dutch</a> that has been developed and tested on qualitative user feedback coming from three domains : <a href="https://en.wikipedia.org/wiki/Retail">retail</a>, <a href="https://en.wikipedia.org/wiki/Bank">banking</a> and <a href="https://en.wikipedia.org/wiki/Human_resources">human resources</a>. The two latter <a href="https://en.wikipedia.org/wiki/Domain_(software_engineering)">domains</a> provide <a href="https://en.wikipedia.org/wiki/Service-oriented_architecture">service-oriented data</a>, which has not been investigated before in ABSA. By performing in-domain and cross-domain experiments the validity of our approach was investigated. We show promising results for the three ABSA subtasks, aspect term extraction, aspect category classification and aspect polarity classification.</abstract>
      <bibkey>de-clercq-etal-2017-towards</bibkey>
    </paper>
    <paper id="19">
      <title>Building a SentiWordNet for Odia<fixed-case>S</fixed-case>enti<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et for <fixed-case>O</fixed-case>dia</title>
      <author><first>Gaurav</first><last>Mohanty</last></author>
      <author><first>Abishek</first><last>Kannan</last></author>
      <author><first>Radhika</first><last>Mamidi</last></author>
      <pages>143–148</pages>
      <url hash="b01d15a4">W17-5219</url>
      <doi>10.18653/v1/W17-5219</doi>
      <abstract>As a discipline of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a>, <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> is used to extract and analyze <a href="https://en.wikipedia.org/wiki/Subjectivity">subjective information</a> present in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language data</a>. The task of <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> has acquired wide commercial uses including social media monitoring tasks, survey responses, review systems, etc. Languages like <a href="https://en.wikipedia.org/wiki/English_language">English</a> have several resources which aid in the task of <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a>. SentiWordNet and Subjectivity WordList are examples of such tools and resources. With more data being available in native vernacular, language-specific SentiWordNet(s) have become essential. For resource poor languages, creating such SentiWordNet(s) is a difficult task to achieve. One solution is to use available resources in <a href="https://en.wikipedia.org/wiki/English_language">English</a> and translate the final source lexicon to target lexicon via <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>. Machine translation systems for the English-Odia language pair have not yet been developed. In this paper, we discuss a method to create a SentiWordNet for <a href="https://en.wikipedia.org/wiki/Odia_language">Odia</a>, which is resource-poor, by only using resources which are currently available for <a href="https://en.wikipedia.org/wiki/Languages_of_India">Indian languages</a>. The lexicon created, would serve as a tool for Sentiment Analysis related task specific to Odia data.</abstract>
      <bibkey>mohanty-etal-2017-building</bibkey>
    </paper>
    <paper id="20">
      <title>Lexicon Integrated CNN Models with Attention for Sentiment Analysis<fixed-case>CNN</fixed-case> Models with Attention for Sentiment Analysis</title>
      <author><first>Bonggun</first><last>Shin</last></author>
      <author><first>Timothy</first><last>Lee</last></author>
      <author><first>Jinho D.</first><last>Choi</last></author>
      <pages>149–158</pages>
      <url hash="20416cc7">W17-5220</url>
      <doi>10.18653/v1/W17-5220</doi>
      <abstract>With the advent of <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>, <a href="https://en.wikipedia.org/wiki/Lexicon">lexicons</a> are no longer fully utilized for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> although they still provide important features in the traditional setting. This paper introduces a novel approach to <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> that integrates lexicon embeddings and an <a href="https://en.wikipedia.org/wiki/Attentional_control">attention mechanism</a> into <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Networks</a>. Our approach performs separate convolutions for word and lexicon embeddings and provides a global view of the document using <a href="https://en.wikipedia.org/wiki/Attention">attention</a>. Our models are experimented on both the SemEval’16 Task 4 dataset and the Stanford Sentiment Treebank and show comparative or better results against the existing state-of-the-art systems. Our analysis shows that lexicon embeddings allow building high-performing models with much smaller word embeddings, and the attention mechanism effectively dims out noisy words for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a>.</abstract>
      <bibkey>shin-etal-2017-lexicon</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="21">
      <title>Explaining Recurrent Neural Network Predictions in Sentiment Analysis</title>
      <author><first>Leila</first><last>Arras</last></author>
      <author><first>Grégoire</first><last>Montavon</last></author>
      <author><first>Klaus-Robert</first><last>Müller</last></author>
      <author><first>Wojciech</first><last>Samek</last></author>
      <pages>159–168</pages>
      <url hash="f4e2d379">W17-5221</url>
      <doi>10.18653/v1/W17-5221</doi>
      <abstract>Recently, a technique called Layer-wise Relevance Propagation (LRP) was shown to deliver insightful explanations in the form of input space relevances for understanding feed-forward neural network classification decisions. In the present work, we extend the usage of LRP to <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural networks</a>. We propose a specific propagation rule applicable to multiplicative connections as they arise in recurrent network architectures such as LSTMs and GRUs. We apply our technique to a word-based bi-directional LSTM model on a five-class sentiment prediction task, and evaluate the resulting LRP relevances both qualitatively and quantitatively, obtaining better results than a gradient-based related method which was used in previous work.</abstract>
      <bibkey>arras-etal-2017-explaining</bibkey>
      <pwccode url="https://github.com/ArrasL/LRP_for_LSTM" additional="false">ArrasL/LRP_for_LSTM</pwccode>
    </paper>
    <paper id="22">
      <title>GradAscent at EmoInt-2017 : Character and Word Level Recurrent Neural Network Models for Tweet Emotion Intensity Detection<fixed-case>G</fixed-case>rad<fixed-case>A</fixed-case>scent at <fixed-case>E</fixed-case>mo<fixed-case>I</fixed-case>nt-2017: Character and Word Level Recurrent Neural Network Models for Tweet Emotion Intensity Detection</title>
      <author><first>Egor</first><last>Lakomkin</last></author>
      <author><first>Chandrakant</first><last>Bothe</last></author>
      <author><first>Stefan</first><last>Wermter</last></author>
      <pages>169–174</pages>
      <url hash="93b6cb93">W17-5222</url>
      <doi>10.18653/v1/W17-5222</doi>
      <abstract>The WASSA 2017 EmoInt shared task has the goal to predict emotion intensity values of <a href="https://en.wikipedia.org/wiki/Twitter">tweet messages</a>. Given the text of a tweet and its emotion category (anger, joy, fear, and sadness), the participants were asked to build a system that assigns emotion intensity values. Emotion intensity estimation is a challenging problem given the short length of the tweets, the noisy structure of the text and the lack of annotated data. To solve this problem, we developed an ensemble of two neural models, processing input on the character. and word-level with a lexicon-driven system. The correlation scores across all four emotions are averaged to determine the bottom-line competition metric, and our system ranks place forth in full intensity range and third in 0.5-1 range of intensity among 23 systems at the time of writing (June 2017).</abstract>
      <bibkey>lakomkin-etal-2017-gradascent</bibkey>
    </paper>
    <paper id="23">
      <title>NUIG at EmoInt-2017 : BiLSTM and SVR Ensemble to Detect Emotion Intensity<fixed-case>NUIG</fixed-case> at <fixed-case>E</fixed-case>mo<fixed-case>I</fixed-case>nt-2017: <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case> and <fixed-case>SVR</fixed-case> Ensemble to Detect Emotion Intensity</title>
      <author><first>Vladimir</first><last>Andryushechkin</last></author>
      <author><first>Ian</first><last>Wood</last></author>
      <author><first>James</first><last>O’ Neill</last></author>
      <pages>175–179</pages>
      <url hash="33735ce8">W17-5223</url>
      <doi>10.18653/v1/W17-5223</doi>
      <abstract>This paper describes the entry NUIG in the WASSA 2017 (8th Workshop on Computational Approaches to Subjectivity, Sentiment &amp; Social Media Analysis) shared task on <a href="https://en.wikipedia.org/wiki/Emotion_recognition">emotion recognition</a>. The NUIG system used an SVR (SVM regression) and BLSTM ensemble, utilizing primarily n-grams (for SVR features) and tweet word embeddings (for BLSTM features). Experiments were carried out on several other candidate features, some of which were added to the SVR model. Parameter selection for the SVR model was run as a <a href="https://en.wikipedia.org/wiki/Grid_search">grid search</a> whilst parameters for the BLSTM model were selected through a non-exhaustive ad-hoc search.</abstract>
      <bibkey>andryushechkin-etal-2017-nuig</bibkey>
    </paper>
    <paper id="24">
      <title>Unsupervised Aspect Term Extraction with B-LSTM &amp; CRF using Automatically Labelled Datasets<fixed-case>B</fixed-case>-<fixed-case>LSTM</fixed-case> &amp; <fixed-case>CRF</fixed-case> using Automatically Labelled Datasets</title>
      <author><first>Athanasios</first><last>Giannakopoulos</last></author>
      <author><first>Claudiu</first><last>Musat</last></author>
      <author><first>Andreea</first><last>Hossmann</last></author>
      <author><first>Michael</first><last>Baeriswyl</last></author>
      <pages>180–188</pages>
      <url hash="045037b3">W17-5224</url>
      <doi>10.18653/v1/W17-5224</doi>
      <abstract>Aspect Term Extraction (ATE) identifies opinionated aspect terms in texts and is one of the tasks in the SemEval Aspect Based Sentiment Analysis (ABSA) contest. The small amount of available datasets for supervised ATE and the costly human annotation for aspect term labelling give rise to the need for unsupervised ATE. In this paper, we introduce an <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> that achieves top-ranking performance for supervised ATE. Moreover, it can be used efficiently as feature extractor and <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> for <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised ATE</a>. Our second contribution is a method to automatically construct <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> for ATE. We train a <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> on our automatically labelled datasets and evaluate it on the human annotated SemEval ABSA test sets. Compared to a strong rule-based baseline, we obtain a dramatically higher <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> and attain <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a> values above 80 %. Our <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised method</a> beats the supervised ABSA baseline from <a href="https://en.wikipedia.org/wiki/SemEval">SemEval</a>, while preserving high precision scores.</abstract>
      <bibkey>giannakopoulos-etal-2017-unsupervised</bibkey>
    </paper>
    <paper id="27">
      <title>YNU-HPCC at EmoInt-2017 : Using a CNN-LSTM Model for Sentiment Intensity Prediction<fixed-case>YNU</fixed-case>-<fixed-case>HPCC</fixed-case> at <fixed-case>E</fixed-case>mo<fixed-case>I</fixed-case>nt-2017: Using a <fixed-case>CNN</fixed-case>-<fixed-case>LSTM</fixed-case> Model for Sentiment Intensity Prediction</title>
      <author><first>You</first><last>Zhang</last></author>
      <author><first>Hang</first><last>Yuan</last></author>
      <author><first>Jin</first><last>Wang</last></author>
      <author><first>Xuejie</first><last>Zhang</last></author>
      <pages>200–204</pages>
      <url hash="05d6a032">W17-5227</url>
      <doi>10.18653/v1/W17-5227</doi>
      <abstract>In this paper, we present a system that uses a convolutional neural network with long short-term memory (CNN-LSTM) model to complete the task. The CNN-LSTM model has two combined parts : CNN extracts local n-gram features within tweets and LSTM composes the <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> to capture long-distance dependency across tweets. Additionally, we used other three models (CNN, LSTM, BiLSTM) as baseline algorithms. Our introduced <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> showed good performance in the experimental results.</abstract>
      <bibkey>zhang-etal-2017-ynu-hpcc</bibkey>
    </paper>
    <paper id="28">
      <title>Seernet at EmoInt-2017 : Tweet Emotion Intensity Estimator<fixed-case>E</fixed-case>mo<fixed-case>I</fixed-case>nt-2017: Tweet Emotion Intensity Estimator</title>
      <author><first>Venkatesh</first><last>Duppada</last></author>
      <author><first>Sushant</first><last>Hiray</last></author>
      <pages>205–211</pages>
      <url hash="9b0c2fc5">W17-5228</url>
      <doi>10.18653/v1/W17-5228</doi>
      <attachment type="poster" hash="defb80b0">W17-5228.Poster.pdf</attachment>
      <abstract>The paper describes experiments on estimating emotion intensity in <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> using a generalized regressor system. The system combines various independent feature extractors, trains them on general regressors and finally combines the best performing models to create an <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble</a>. The proposed <a href="https://en.wikipedia.org/wiki/System">system</a> stood 3rd out of 22 systems in leaderboard of WASSA-2017 Shared Task on Emotion Intensity.</abstract>
      <bibkey>duppada-hiray-2017-seernet</bibkey>
      <pwccode url="https://github.com/SEERNET/EmoInt" additional="false">SEERNET/EmoInt</pwccode>
    </paper>
    <paper id="30">
      <title>NSEmo at EmoInt-2017 : An Ensemble to Predict Emotion Intensity in Tweets<fixed-case>NSE</fixed-case>mo at <fixed-case>E</fixed-case>mo<fixed-case>I</fixed-case>nt-2017: An Ensemble to Predict Emotion Intensity in Tweets</title>
      <author><first>Sreekanth</first><last>Madisetty</last></author>
      <author><first>Maunendra Sankar</first><last>Desarkar</last></author>
      <pages>219–224</pages>
      <url hash="660c7241">W17-5230</url>
      <doi>10.18653/v1/W17-5230</doi>
      <abstract>In this paper, we describe a <a href="https://en.wikipedia.org/wiki/Methodology">method</a> to predict emotion intensity in <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a>. Our approach is an ensemble of three <a href="https://en.wikipedia.org/wiki/Regression_analysis">regression methods</a>. The first method uses content-based features (hashtags, <a href="https://en.wikipedia.org/wiki/Emoticon">emoticons</a>, elongated words, etc.). The second method considers <a href="https://en.wikipedia.org/wiki/N-gram">word n-grams</a> and character n-grams for training. The final method uses <a href="https://en.wikipedia.org/wiki/Lexicon">lexicons</a>, <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>, <a href="https://en.wikipedia.org/wiki/N-gram">word n-grams</a>, character n-grams for training the model. An <a href="https://en.wikipedia.org/wiki/Ensemble_cast">ensemble</a> of these three <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> gives better performance than individual methods. We applied our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> on WASSA emotion dataset. Achieved results are as follows : <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">average Pearson correlation</a> is 0.706, <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">average Spearman correlation</a> is 0.696, <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">average Pearson correlation</a> for gold scores in range 0.5 to 1 is 0.539, and <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">average Spearman correlation</a> for gold scores in range 0.5 to 1 is 0.514.</abstract>
      <bibkey>madisetty-desarkar-2017-nsemo</bibkey>
    </paper>
    <paper id="31">
      <title>Tecnolengua Lingmotif at EmoInt-2017 : A lexicon-based approach<fixed-case>T</fixed-case>ecnolengua <fixed-case>L</fixed-case>ingmotif at <fixed-case>E</fixed-case>mo<fixed-case>I</fixed-case>nt-2017: A lexicon-based approach</title>
      <author><first>Antonio</first><last>Moreno-Ortiz</last></author>
      <pages>225–232</pages>
      <url hash="524609d7">W17-5231</url>
      <doi>10.18653/v1/W17-5231</doi>
      <abstract>In this paper we describe Tecnolengua Group’s participation in the shared task on emotion intensity at WASSA 2017. We used the Lingmotif tool and a new, complementary tool, Lingmotif Learn, which we developed for this occasion. We based our intensity predictions for the four test datasets entirely on Lingmotif’s TSS (text sentiment score) feature. We also developed <a href="https://en.wikipedia.org/wiki/Mechanism_design">mechanisms</a> for dealing with the <a href="https://en.wikipedia.org/wiki/Idiosyncrasy">idiosyncrasies</a> of <a href="https://en.wikipedia.org/wiki/Twitter">Twitter text</a>. Results were comparatively poor, but the experience meant a good opportunity for us to identify issues in our score calculation for short texts, a genre for which the Lingmotif tool was not originally designed.</abstract>
      <bibkey>moreno-ortiz-2017-tecnolengua</bibkey>
    </paper>
    <paper id="32">
      <title>EmoAtt at EmoInt-2017 : Inner attention sentence embedding for Emotion Intensity<fixed-case>E</fixed-case>mo<fixed-case>A</fixed-case>tt at <fixed-case>E</fixed-case>mo<fixed-case>I</fixed-case>nt-2017: Inner attention sentence embedding for Emotion Intensity</title>
      <author><first>Edison</first><last>Marrese-Taylor</last></author>
      <author><first>Yutaka</first><last>Matsuo</last></author>
      <pages>233–237</pages>
      <url hash="ba60c4f5">W17-5232</url>
      <doi>10.18653/v1/W17-5232</doi>
      <abstract>In this paper we describe a deep learning system that has been designed and built for the WASSA 2017 Emotion Intensity Shared Task. We introduce a representation learning approach based on inner attention on top of an <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">RNN</a>. Results show that our model offers good capabilities and is able to successfully identify emotion-bearing words to predict intensity without leveraging on lexicons, obtaining the 13 t place among 22 shared task competitors.</abstract>
      <bibkey>marrese-taylor-matsuo-2017-emoatt</bibkey>
      <pwccode url="https://github.com/epochx/emoatt" additional="false">epochx/emoatt</pwccode>
    </paper>
    <paper id="34">
      <title>DMGroup at EmoInt-2017 : Emotion Intensity Using Ensemble Method<fixed-case>DMG</fixed-case>roup at <fixed-case>E</fixed-case>mo<fixed-case>I</fixed-case>nt-2017: Emotion Intensity Using Ensemble Method</title>
      <author><first>Song</first><last>Jiang</last></author>
      <author><first>Xiaotian</first><last>Han</last></author>
      <pages>243–248</pages>
      <url hash="abfb5f92">W17-5234</url>
      <doi>10.18653/v1/W17-5234</doi>
      <abstract>In this paper, we present a novel ensemble learning architecture for emotion intensity analysis, particularly a novel framework of ensemble method. The ensemble method has two stages and each stage includes several single machine learning models. In stage1, we employ both linear and nonlinear regression models to obtain a more diverse emotion intensity representation. In stage2, we use two <a href="https://en.wikipedia.org/wiki/Regression_analysis">regression models</a> including <a href="https://en.wikipedia.org/wiki/Linear_regression">linear regression</a> and <a href="https://en.wikipedia.org/wiki/XGBoost">XGBoost</a>. The result of stage1 serves as the input of stage2, so the two different type models (linear and non-linear) in stage2 can describe the input in two opposite aspects. We also added a method for analyzing and splitting multi-words hashtags and appending them to the emotion intensity corpus before feeding it to our model. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves 0.571 <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson-measure</a> for the average of four emotions.</abstract>
      <bibkey>jiang-han-2017-dmgroup</bibkey>
    </paper>
    <paper id="35">
      <title>UWat-Emote at EmoInt-2017 : Emotion Intensity Detection using Affect Clues, Sentiment Polarity and Word Embeddings<fixed-case>UW</fixed-case>at-Emote at <fixed-case>E</fixed-case>mo<fixed-case>I</fixed-case>nt-2017: Emotion Intensity Detection using Affect Clues, Sentiment Polarity and Word Embeddings</title>
      <author><first>Vineet</first><last>John</last></author>
      <author><first>Olga</first><last>Vechtomova</last></author>
      <pages>249–254</pages>
      <url hash="d5ba3751">W17-5235</url>
      <doi>10.18653/v1/W17-5235</doi>
      <abstract>This paper describes the UWaterloo affect prediction system developed for EmoInt-2017. We delve into our feature selection approach for affect intensity, affect presence, sentiment intensity and sentiment presence lexica alongside pre-trained word embeddings, which are utilized to extract emotion intensity signals from tweets in an ensemble learning approach. The system employs emotion specific model training, and utilizes distinct <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> for each of the emotion corpora in isolation. Our system utilizes gradient boosted regression as the primary learning technique to predict the final emotion intensities.</abstract>
      <bibkey>john-vechtomova-2017-uwat</bibkey>
    </paper>
    <paper id="36">
      <title>LIPN-UAM at EmoInt-2017 : Combination of Lexicon-based features and Sentence-level Vector Representations for Emotion Intensity Determination<fixed-case>LIPN</fixed-case>-<fixed-case>UAM</fixed-case> at <fixed-case>E</fixed-case>mo<fixed-case>I</fixed-case>nt-2017:Combination of Lexicon-based features and Sentence-level Vector Representations for Emotion Intensity Determination</title>
      <author><first>Davide</first><last>Buscaldi</last></author>
      <author><first>Belem</first><last>Priego</last></author>
      <pages>255–258</pages>
      <url hash="bf5ca0e1">W17-5236</url>
      <doi>10.18653/v1/W17-5236</doi>
      <abstract>This paper presents the combined LIPN-UAM participation in the WASSA 2017 Shared Task on Emotion Intensity. In particular, the paper provides some highlights on the Tweetaneuse system that was presented to the shared task. We combined lexicon-based features with sentence-level vector representations to implement a random forest regressor.</abstract>
      <bibkey>buscaldi-priego-2017-lipn</bibkey>
    </paper>
    <paper id="37">
      <title>deepCybErNet at EmoInt-2017 : Deep Emotion Intensities in Tweets<fixed-case>C</fixed-case>yb<fixed-case>E</fixed-case>r<fixed-case>N</fixed-case>et at <fixed-case>E</fixed-case>mo<fixed-case>I</fixed-case>nt-2017: Deep Emotion Intensities in Tweets</title>
      <author><first>Vinayakumar</first><last>R</last></author>
      <author><first>Premjith</first><last>B</last></author>
      <author><first>Sachin Kumar</first><last>S</last></author>
      <author><first>Soman</first><last>KP</last></author>
      <author><first>Prabaharan</first><last>Poornachandran</last></author>
      <pages>259–263</pages>
      <url hash="eff37d6c">W17-5237</url>
      <doi>10.18653/v1/W17-5237</doi>
      <abstract>This working note presents the methodology used in deepCybErNet submission to the shared task on Emotion Intensities in Tweets (EmoInt) WASSA-2017. The goal of the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> is to predict a real valued score in the range [ 0-1 ] for a particular tweet with an <a href="https://en.wikipedia.org/wiki/Emotion">emotion type</a>. To do this, we used Bag-of-Words and embedding based on recurrent network architecture. We have developed two systems and experiments are conducted on the Emotion Intensity shared Task 1 data base at WASSA-2017. A system which uses <a href="https://en.wikipedia.org/wiki/Word_embedding">word embedding</a> based on recurrent network architecture has achieved highest 5 fold cross-validation accuracy. This has used <a href="https://en.wikipedia.org/wiki/Embedding">embedding</a> with <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent network</a> to extract optimal features at tweet level and <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a> for <a href="https://en.wikipedia.org/wiki/Prediction">prediction</a>. These methods are highly language independent and experimental results shows that the proposed methods are apt for predicting a real valued score in than range [ 0-1 ] for a given tweet with its emotion type.</abstract>
      <bibkey>r-etal-2017-deepcybernet</bibkey>
    </paper>
  </volume>
  <volume id="53">
    <meta>
      <booktitle>Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for <fixed-case>NLP</fixed-case></booktitle>
      <url hash="648c78e9">W17-53</url>
      <editor><first>Samuel</first><last>Bowman</last></editor>
      <editor><first>Yoav</first><last>Goldberg</last></editor>
      <editor><first>Felix</first><last>Hill</last></editor>
      <editor><first>Angeliki</first><last>Lazaridou</last></editor>
      <editor><first>Omer</first><last>Levy</last></editor>
      <editor><first>Roi</first><last>Reichart</last></editor>
      <editor><first>Anders</first><last>Søgaard</last></editor>
      <doi>10.18653/v1/W17-53</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Copenhagen, Denmark</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="c52a1ddb">W17-5300</url>
      <bibkey>ws-2017-evaluating</bibkey>
    </frontmatter>
    <paper id="1">
      <title>The RepEval 2017 Shared Task : Multi-Genre Natural Language Inference with Sentence Representations<fixed-case>R</fixed-case>ep<fixed-case>E</fixed-case>val 2017 Shared Task: Multi-Genre Natural Language Inference with Sentence Representations</title>
      <author><first>Nikita</first><last>Nangia</last></author>
      <author><first>Adina</first><last>Williams</last></author>
      <author><first>Angeliki</first><last>Lazaridou</last></author>
      <author><first>Samuel</first><last>Bowman</last></author>
      <pages>1–10</pages>
      <url hash="a649bd72">W17-5301</url>
      <doi>10.18653/v1/W17-5301</doi>
      <abstract>This paper presents the results of the RepEval 2017 Shared Task, which evaluated neural network sentence representation learning models on the Multi-Genre Natural Language Inference corpus (MultiNLI) recently introduced by Williams et al. All of the five participating teams beat the bidirectional LSTM (BiLSTM) and continuous bag of words baselines reported in Williams et al. The best single <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> used stacked BiLSTMs with residual connections to extract <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentence features</a> and reached 74.5 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> on the genre-matched test set. Surprisingly, the results of the competition were fairly consistent across the genre-matched and genre-mismatched test sets, and across subsets of the test data representing a variety of linguistic phenomena, suggesting that all of the submitted systems learned reasonably domain-independent representations for sentence meaning.</abstract>
      <bibkey>nangia-etal-2017-repeval</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="2">
      <title>Traversal-Free Word Vector Evaluation in Analogy Space</title>
      <author><first>Xiaoyin</first><last>Che</last></author>
      <author><first>Nico</first><last>Ring</last></author>
      <author><first>Willi</first><last>Raschkowski</last></author>
      <author><first>Haojin</first><last>Yang</last></author>
      <author><first>Christoph</first><last>Meinel</last></author>
      <pages>11–15</pages>
      <url hash="af3a77e9">W17-5302</url>
      <doi>10.18653/v1/W17-5302</doi>
      <abstract>In this paper, we propose an alternative evaluating metric for word analogy questions (A to B is as C to D) in word vector evaluation. Different from the traditional method which predicts the fourth word by the given three, we measure the similarity directly on the relations of two pairs of given words, just as shifting the relation vectors into a new analogy space. Cosine and Euclidean distances are then calculated as measurements. Observation and experiments shows the proposed analogy space evaluation could offer a more comprehensive evaluating result on word vectors with word analogy questions. Meanwhile, <a href="https://en.wikipedia.org/wiki/Computational_complexity_theory">computational complexity</a> are remarkably reduced by avoiding traversing the vocabulary.</abstract>
      <bibkey>che-etal-2017-traversal</bibkey>
    </paper>
    <paper id="3">
      <title>Hypothesis Testing based Intrinsic Evaluation of Word Embeddings</title>
      <author><first>Nishant</first><last>Gurnani</last></author>
      <pages>16–20</pages>
      <url hash="ef8e14ff">W17-5303</url>
      <doi>10.18653/v1/W17-5303</doi>
      <abstract>We introduce the cross-match test-an exact, distribution free, high-dimensional hypothesis test as an intrinsic evaluation metric for <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>. We show that <a href="https://en.wikipedia.org/wiki/Cross-matching">cross-match</a> is an effective means of measuring the distributional similarity between different <a href="https://en.wikipedia.org/wiki/Vector_space">vector representations</a> and of evaluating the <a href="https://en.wikipedia.org/wiki/Statistical_significance">statistical significance</a> of different vector embedding models. Additionally, we find that <a href="https://en.wikipedia.org/wiki/Cross-matching">cross-match</a> can be used to provide a quantitative measure of linguistic similarity for selecting bridge languages for <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>. We demonstrate that the results of the <a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing">hypothesis test</a> align with our expectations and note that the framework of two sample hypothesis testing is not limited to <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> and can be extended to all <a href="https://en.wikipedia.org/wiki/Vector_space">vector representations</a>.</abstract>
      <bibkey>gurnani-2017-hypothesis</bibkey>
    </paper>
    <paper id="4">
      <title>Evaluation of word embeddings against <a href="https://en.wikipedia.org/wiki/Cognition">cognitive processes</a> : primed reaction times in lexical decision and naming tasks</title>
      <author><first>Jeremy</first><last>Auguste</last></author>
      <author><first>Arnaud</first><last>Rey</last></author>
      <author><first>Benoit</first><last>Favre</last></author>
      <pages>21–26</pages>
      <url hash="8d1a0ea3">W17-5304</url>
      <doi>10.18653/v1/W17-5304</doi>
      <abstract>This work presents a <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> for word similarity evaluation grounded on cognitive sciences experimental data. Word pair similarities are compared to <a href="https://en.wikipedia.org/wiki/Mental_chronometry">reaction times</a> of subjects in large scale lexical decision and naming tasks under <a href="https://en.wikipedia.org/wiki/Semantic_priming">semantic priming</a>. Results show that GloVe embeddings lead to significantly higher correlation with experimental measurements than other controlled and off-the-shelf embeddings, and that the choice of a <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training corpus</a> is less important than that of the <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a>. Comparison of rankings with other datasets shows that the cognitive phenomenon covers more aspects than simply <a href="https://en.wikipedia.org/wiki/Word_sense">word relatedness</a> or <a href="https://en.wikipedia.org/wiki/Similarity_(psychology)">similarity</a>.</abstract>
      <bibkey>auguste-etal-2017-evaluation</bibkey>
    </paper>
    <paper id="5">
      <title>Playing with Embeddings : Evaluating embeddings for Robot Language Learning through MUD Games<fixed-case>MUD</fixed-case> Games</title>
      <author><first>Anmol</first><last>Gulati</last></author>
      <author><first>Kumar Krishna</first><last>Agrawal</last></author>
      <pages>27–30</pages>
      <url hash="41dd01dc">W17-5305</url>
      <doi>10.18653/v1/W17-5305</doi>
      <abstract>Acquiring language provides a ubiquitous mode of communication, across humans and robots. To this effect, distributional representations of words based on co-occurrence statistics, have provided significant advancements ranging across <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> to <a href="https://en.wikipedia.org/wiki/Sentence_processing">comprehension</a>. In this paper, we study the suitability of using general purpose word-embeddings for language learning in robots. We propose using text-based games as a proxy to evaluating <a href="https://en.wikipedia.org/wiki/Word_embedding">word embedding</a> on real robots. Based in a risk-reward setting, we review the effectiveness of the embeddings in navigating tasks in fantasy games, as an approximation to their performance on more complex scenarios, like language assisted robot navigation.</abstract>
      <bibkey>gulati-agrawal-2017-playing</bibkey>
    </paper>
    <paper id="6">
      <title>Recognizing Textual Entailment in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> Using Word Embeddings<fixed-case>T</fixed-case>witter Using Word Embeddings</title>
      <author><first>Octavia-Maria</first><last>Şulea</last></author>
      <pages>31–35</pages>
      <url hash="9d057a3c">W17-5306</url>
      <doi>10.18653/v1/W17-5306</doi>
      <abstract>In this paper, we investigate the application of <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning techniques</a> and <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> to the task of Recognizing Textual Entailment (RTE) in <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a>. We look at a manually labeled dataset consisting of user generated short texts posted on Twitter (tweets) and related to four recent media events (the <a href="https://en.wikipedia.org/wiki/Charlie_Hebdo_shooting">Charlie Hebdo shooting</a>, the Ottawa shooting, the Sydney Siege, and the German Wings crash) and test to what extent neural techniques and embeddings are able to distinguish between tweets that entail or contradict each other or that claim unrelated things. We obtain comparable results to the state of the art in a train-test setting, but we show that, due to the noisy aspect of the data, results plummet in an evaluation strategy crafted to better simulate a real-life train-test scenario.</abstract>
      <bibkey>sulea-2017-recognizing</bibkey>
    </paper>
    <paper id="9">
      <title>Character-level Intra Attention Network for Natural Language Inference</title>
      <author><first>Han</first><last>Yang</last></author>
      <author><first>Marta R.</first><last>Costa-jussà</last></author>
      <author><first>José A. R.</first><last>Fonollosa</last></author>
      <pages>46–50</pages>
      <url hash="f5772b1d">W17-5309</url>
      <doi>10.18653/v1/W17-5309</doi>
      <abstract>Natural language inference (NLI) is a central problem in <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">language understanding</a>. End-to-end artificial neural networks have reached state-of-the-art performance in NLI field recently. In this paper, we propose Character-level Intra Attention Network (CIAN) for the NLI task. In our model, we use the character-level convolutional network to replace the standard word embedding layer, and we use the intra attention to capture the intra-sentence semantics. The proposed CIAN model provides improved results based on a newly published MNLI corpus.</abstract>
      <bibkey>yang-etal-2017-character</bibkey>
      <pwccode url="https://github.com/yanghanxy/CIAN" additional="false">yanghanxy/CIAN</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="10">
      <title>Refining <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">Raw Sentence Representations</a> for Textual Entailment Recognition via <a href="https://en.wikipedia.org/wiki/Attention">Attention</a></title>
      <author><first>Jorge</first><last>Balazs</last></author>
      <author><first>Edison</first><last>Marrese-Taylor</last></author>
      <author><first>Pablo</first><last>Loyola</last></author>
      <author><first>Yutaka</first><last>Matsuo</last></author>
      <pages>51–55</pages>
      <url hash="18d63644">W17-5310</url>
      <doi>10.18653/v1/W17-5310</doi>
      <abstract>In this paper we present the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> used by the team Rivercorners for the 2017 RepEval shared task. First, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> separately encodes a pair of sentences into variable-length representations by using a bidirectional LSTM. Later, <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> creates fixed-length raw representations by means of simple aggregation functions, which are then refined using an <a href="https://en.wikipedia.org/wiki/Attentional_control">attention mechanism</a>. Finally it combines the refined <a href="https://en.wikipedia.org/wiki/Representation_(mathematics)">representations</a> of both sentences into a single vector to be used for <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a>. With this model we obtained test accuracies of 72.057 % and 72.055 % in the matched and mismatched evaluation tracks respectively, outperforming the LSTM baseline, and obtaining performances similar to a model that relies on shared information between sentences (ESIM). When using an <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble</a> both accuracies increased to 72.247 % and 72.827 % respectively.</abstract>
      <bibkey>balazs-etal-2017-refining</bibkey>
      <pwccode url="https://github.com/jabalazs/repeval_rivercorners" additional="false">jabalazs/repeval_rivercorners</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
    </paper>
    </volume>
  <volume id="54">
    <meta>
      <booktitle>Proceedings of the First Workshop on Building Linguistically Generalizable <fixed-case>NLP</fixed-case> Systems</booktitle>
      <url hash="f166c301">W17-54</url>
      <editor><first>Emily</first><last>Bender</last></editor>
      <editor><first>Hal</first><last>Daumé III</last></editor>
      <editor><first>Allyson</first><last>Ettinger</last></editor>
      <editor><first>Sudha</first><last>Rao</last></editor>
      <doi>10.18653/v1/W17-54</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Copenhagen, Denmark</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="0f5bd557">W17-5400</url>
      <bibkey>ws-2017-building-linguistically</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Towards Linguistically Generalizable NLP Systems : A Workshop and Shared Task<fixed-case>NLP</fixed-case> Systems: A Workshop and Shared Task</title>
      <author><first>Allyson</first><last>Ettinger</last></author>
      <author><first>Sudha</first><last>Rao</last></author>
      <author><first>Hal</first><last>Daumé III</last></author>
      <author><first>Emily M.</first><last>Bender</last></author>
      <pages>1–10</pages>
      <url hash="9e6840fb">W17-5401</url>
      <doi>10.18653/v1/W17-5401</doi>
      <abstract>This paper presents a summary of the first Workshop on Building Linguistically Generalizable Natural Language Processing Systems, and the associated Build It Break It, The Language Edition shared task. The goal of this workshop was to bring together researchers in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> and <a href="https://en.wikipedia.org/wiki/Linguistics">linguistics</a> with a carefully designed shared task aimed at testing the generalizability of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP systems</a> beyond the distributions of their training data. We describe the motivation, setup, and participation of the shared task, provide discussion of some highlighted results, and discuss lessons learned.</abstract>
      <bibkey>ettinger-etal-2017-towards</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/qa-srl">QA-SRL</pwcdataset>
    </paper>
    <paper id="2">
      <title>Analysing Errors of Open Information Extraction Systems</title>
      <author><first>Rudolf</first><last>Schneider</last></author>
      <author><first>Tom</first><last>Oberhauser</last></author>
      <author><first>Tobias</first><last>Klatt</last></author>
      <author><first>Felix A.</first><last>Gers</last></author>
      <author><first>Alexander</first><last>Löser</last></author>
      <pages>11–18</pages>
      <url hash="bbb995e6">W17-5402</url>
      <doi>10.18653/v1/W17-5402</doi>
      <abstract>We report results on benchmarking Open Information Extraction (OIE) systems using RelVis, a toolkit for benchmarking Open Information Extraction systems. Our comprehensive <a href="https://en.wikipedia.org/wiki/Benchmark_(computing)">benchmark</a> contains three data sets from the news domain and one data set from <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a> with overall 4522 labeled sentences and 11243 binary or n-ary OIE relations. In our analysis on these data sets we compared the performance of four popular OIE systems, ClausIE, OpenIE 4.2, Stanford OpenIE and PredPatt. In addition, we evaluated the impact of five common error classes on a subset of 749 n-ary tuples. From our deep analysis we unreveal important research directions for a next generation on OIE systems.</abstract>
      <bibkey>schneider-etal-2017-analysing</bibkey>
    </paper>
    <paper id="3">
      <title>Massively Multilingual Neural Grapheme-to-Phoneme Conversion</title>
      <author><first>Ben</first><last>Peters</last></author>
      <author><first>Jon</first><last>Dehdari</last></author>
      <author><first>Josef</first><last>van Genabith</last></author>
      <pages>19–26</pages>
      <url hash="cbcf8c96">W17-5403</url>
      <doi>10.18653/v1/W17-5403</doi>
      <abstract>Grapheme-to-phoneme conversion (g2p) is necessary for text-to-speech and automatic speech recognition systems. Most g2p systems are monolingual : they require language-specific data or handcrafting of rules. Such systems are difficult to extend to low resource languages, for which data and handcrafted rules are not available. As an alternative, we present a neural sequence-to-sequence approach to g2p which is trained on spellingpronunciation pairs in hundreds of languages. The system shares a single encoder and decoder across all languages, allowing it to utilize the intrinsic similarities between different <a href="https://en.wikipedia.org/wiki/Writing_system">writing systems</a>. We show an 11 % improvement in phoneme error rate over an approach based on adapting high-resource monolingual g2p models to low-resource languages. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is also much more compact relative to previous <a href="https://en.wikipedia.org/wiki/Scientific_modelling">approaches</a>.</abstract>
      <bibkey>peters-etal-2017-massively</bibkey>
      <pwccode url="https://github.com/bpopeters/mg2p" additional="false">bpopeters/mg2p</pwccode>
    </paper>
    <paper id="4">
      <title>BIBI System Description : Building with CNNs and Breaking with <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Reinforcement Learning</a><fixed-case>BIBI</fixed-case> System Description: Building with <fixed-case>CNN</fixed-case>s and Breaking with Deep Reinforcement Learning</title>
      <author><first>Yitong</first><last>Li</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <pages>27–32</pages>
      <url hash="63288a99">W17-5404</url>
      <doi>10.18653/v1/W17-5404</doi>
      <abstract>This paper describes our submission to the sentiment analysis sub-task of Build It, Break It : The Language Edition (BIBI), on both the builder and breaker sides. As a builder, we use <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural nets</a>, trained on both phrase and sentence data. As a breaker, we use <a href="https://en.wikipedia.org/wiki/Q-learning">Q-learning</a> to learn minimal change pairs, and apply a token substitution method automatically. We analyse the results to gauge the <a href="https://en.wikipedia.org/wiki/Robustness_(computer_science)">robustness</a> of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP systems</a>.</abstract>
      <bibkey>li-etal-2017-bibi</bibkey>
    </paper>
    <paper id="5">
      <title>Breaking NLP : Using <a href="https://en.wikipedia.org/wiki/Morphosyntax">Morphosyntax</a>, <a href="https://en.wikipedia.org/wiki/Semantics">Semantics</a>, <a href="https://en.wikipedia.org/wiki/Pragmatics">Pragmatics</a> and World Knowledge to Fool Sentiment Analysis Systems<fixed-case>NLP</fixed-case>: Using Morphosyntax, Semantics, Pragmatics and World Knowledge to Fool Sentiment Analysis Systems</title>
      <author><first>Taylor</first><last>Mahler</last></author>
      <author><first>Willy</first><last>Cheung</last></author>
      <author><first>Micha</first><last>Elsner</last></author>
      <author><first>David</first><last>King</last></author>
      <author><first>Marie-Catherine</first><last>de Marneffe</last></author>
      <author><first>Cory</first><last>Shain</last></author>
      <author><first>Symon</first><last>Stevens-Guille</last></author>
      <author><first>Michael</first><last>White</last></author>
      <pages>33–39</pages>
      <url hash="94340603">W17-5405</url>
      <doi>10.18653/v1/W17-5405</doi>
      <revision id="1" href="W17-5405v1" hash="6cf8880f" />
      <revision id="2" href="W17-5405v2" hash="94340603">No description of the changes were recorded.</revision>
      <abstract>This paper describes our breaker submission to the 2017 EMNLP Build It Break It shared task on <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a>. In order to cause the builder systems to make incorrect predictions, we edited items in the blind test data according to linguistically interpretable strategies that allow us to assess the ease with which the builder systems learn various components of linguistic structure. On the whole, our submitted pairs break all systems at a high rate (72.6 %), indicating that <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> as an NLP task may still have a lot of ground to cover. Of the breaker strategies that we consider, we find our semantic and pragmatic manipulations to pose the most substantial difficulties for the builder systems.</abstract>
      <bibkey>mahler-etal-2017-breaking</bibkey>
    </paper>
    <paper id="6">
      <title>An Adaptable Lexical Simplification Architecture for Major Ibero-Romance Languages<fixed-case>I</fixed-case>bero-<fixed-case>R</fixed-case>omance Languages</title>
      <author><first>Daniel</first><last>Ferrés</last></author>
      <author><first>Horacio</first><last>Saggion</last></author>
      <author><first>Xavier</first><last>Gómez Guinovart</last></author>
      <pages>40–47</pages>
      <url hash="86eefb71">W17-5406</url>
      <doi>10.18653/v1/W17-5406</doi>
      <abstract>Lexical Simplification is the task of reducing the lexical complexity of <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">textual documents</a> by replacing difficult words with easier to read (or understand) expressions while preserving the original meaning. The development of robust pipelined multilingual architectures able to adapt to new languages is of paramount importance in <a href="https://en.wikipedia.org/wiki/Lexical_simplification">lexical simplification</a>. This paper describes and evaluates a modular hybrid linguistic-statistical Lexical Simplifier that deals with the four major Ibero-Romance Languages : <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a>, <a href="https://en.wikipedia.org/wiki/Catalan_language">Catalan</a>, and <a href="https://en.wikipedia.org/wiki/Galician_language">Galician</a>. The architecture of the <a href="https://en.wikipedia.org/wiki/System">system</a> is the same for the four languages addressed, only the language resources used during <a href="https://en.wikipedia.org/wiki/Simplification">simplification</a> are language specific.</abstract>
      <bibkey>ferres-etal-2017-adaptable</bibkey>
    </paper>
    <paper id="7">
      <title>Cross-genre Document Retrieval : Matching between Conversational and Formal Writings</title>
      <author><first>Tomasz</first><last>Jurczyk</last></author>
      <author><first>Jinho D.</first><last>Choi</last></author>
      <pages>48–53</pages>
      <url hash="20674708">W17-5407</url>
      <doi>10.18653/v1/W17-5407</doi>
      <abstract>This paper challenges a cross-genre document retrieval task, where the queries are in <a href="https://en.wikipedia.org/wiki/Formal_writing">formal writing</a> and the target documents are in conversational writing. In this task, a query, is a sentence extracted from either a summary or a plot of an episode in a TV show, and the target document consists of transcripts from the corresponding episode. To establish a strong baseline, we employ the current state-of-the-art <a href="https://en.wikipedia.org/wiki/Web_search_engine">search engine</a> to perform <a href="https://en.wikipedia.org/wiki/Document_retrieval">document retrieval</a> on the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> collected for this work. We then introduce a structure reranking approach to improve the initial ranking by utilizing syntactic and semantic structures generated by <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP tools</a>. Our evaluation shows an improvement of more than 4 % when the structure reranking is applied, which is very promising.</abstract>
      <bibkey>jurczyk-choi-2017-cross</bibkey>
    </paper>
    <paper id="9">
      <title>Strawman : An Ensemble of Deep Bag-of-Ngrams for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a><fixed-case>S</fixed-case>trawman: An Ensemble of Deep Bag-of-Ngrams for Sentiment Analysis</title>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <pages>59–60</pages>
      <url hash="1583ab11">W17-5409</url>
      <doi>10.18653/v1/W17-5409</doi>
      <abstract>This paper describes a builder entry, named strawman, to the sentence-level sentiment analysis task of the Build It, Break It shared task of the First Workshop on Building Linguistically Generalizable NLP Systems. The goal of a builder is to provide an automated sentiment analyzer that would serve as a target for breakers whose goal is to find pairs of minimally-differing sentences that break the analyzer.</abstract>
      <bibkey>cho-2017-strawman</bibkey>
      <pwccode url="https://github.com/kyunghyuncho/strawman" additional="false">kyunghyuncho/strawman</pwccode>
    </paper>
    <paper id="10">
      <title>Breaking Sentiment Analysis of Movie Reviews</title>
      <author><first>Ieva</first><last>Staliūnaitė</last></author>
      <author><first>Ben</first><last>Bonfil</last></author>
      <pages>61–64</pages>
      <url hash="480f98ff">W17-5410</url>
      <doi>10.18653/v1/W17-5410</doi>
      <abstract>The current paper covers several strategies we used to ‘break’ predictions of <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis systems</a> participating in the BLGNLP2017 workshop. Specifically, we identify difficulties of participating systems in understanding <a href="https://en.wikipedia.org/wiki/Modal_logic">modals</a>, subjective judgments, world-knowledge based references and certain differences in <a href="https://en.wikipedia.org/wiki/Syntax">syntax</a> and perspective.</abstract>
      <bibkey>staliunaite-bonfil-2017-breaking</bibkey>
    </paper>
  </volume>
  <volume id="55">
    <meta>
      <booktitle>Proceedings of the 18th Annual <fixed-case>SIG</fixed-case>dial Meeting on Discourse and Dialogue</booktitle>
      <url hash="20fbb7ea">W17-55</url>
      <editor><first>Kristiina</first><last>Jokinen</last></editor>
      <editor><first>Manfred</first><last>Stede</last></editor>
      <editor><first>David</first><last>DeVault</last></editor>
      <editor><first>Annie</first><last>Louis</last></editor>
      <doi>10.18653/v1/W17-55</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Saarbrücken, Germany</address>
      <month>August</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="c6b39408">W17-5500</url>
      <bibkey>ws-2017-sigdial</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Automatic Mapping of French Discourse Connectives to PDTB Discourse Relations<fixed-case>F</fixed-case>rench Discourse Connectives to <fixed-case>PDTB</fixed-case> Discourse Relations</title>
      <author><first>Majid</first><last>Laali</last></author>
      <author><first>Leila</first><last>Kosseim</last></author>
      <pages>1–6</pages>
      <url hash="b7517078">W17-5501</url>
      <doi>10.18653/v1/W17-5501</doi>
      <abstract>In this paper, we present an approach to exploit phrase tables generated by <a href="https://en.wikipedia.org/wiki/Statistical_machine_translation">statistical machine translation</a> in order to map French discourse connectives to <a href="https://en.wikipedia.org/wiki/Discourse_analysis">discourse relations</a>. Using this approach, we created DisCoRel, a lexicon of French discourse connectives and their PDTB relations. When evaluated against LEXCONN, DisCoRel achieves a recall of 0.81 and an Average Precision of 0.68 for the Concession and Condition relations.</abstract>
      <bibkey>laali-kosseim-2017-automatic</bibkey>
      <pwccode url="https://github.com/mjlaali/ConcoLeDisCo" additional="false">mjlaali/ConcoLeDisCo</pwccode>
    </paper>
    <paper id="2">
      <title>Towards Full Text Shallow Discourse Relation Annotation : Experiments with Cross-Paragraph Implicit Relations in the PDTB<fixed-case>PDTB</fixed-case></title>
      <author><first>Rashmi</first><last>Prasad</last></author>
      <author><first>Katherine</first><last>Forbes Riley</last></author>
      <author><first>Alan</first><last>Lee</last></author>
      <pages>7–16</pages>
      <url hash="5346413e">W17-5502</url>
      <doi>10.18653/v1/W17-5502</doi>
      <abstract>Full text discourse parsing relies on texts comprehensively annotated with <a href="https://en.wikipedia.org/wiki/Discourse_analysis">discourse relations</a>. To this end, we address a significant gap in the inter-sentential discourse relations annotated in the Penn Discourse Treebank (PDTB), namely the class of cross-paragraph implicit relations, which account for 30 % of inter-sentential relations in the corpus. We present our annotation study to explore the <a href="https://en.wikipedia.org/wiki/Incidence_(epidemiology)">incidence rate</a> of adjacent vs. non-adjacent implicit relations in cross-paragraph contexts, and the relative degree of difficulty in annotating them. Our experiments show a high incidence of non-adjacent relations that are difficult to annotate reliably, suggesting the practicality of backing off from their annotation to reduce noise for corpus-based studies. Our resulting guidelines follow the PDTB adjacency constraint for implicits while employing an underspecified representation of non-adjacent implicits, and yield 62 % inter-annotator agreement on this task.</abstract>
      <bibkey>prasad-etal-2017-towards</bibkey>
    </paper>
    <paper id="3">
      <title>User-initiated Sub-dialogues in State-of-the-art Dialogue Systems</title>
      <author><first>Staffan</first><last>Larsson</last></author>
      <pages>17–22</pages>
      <url hash="bf975fe2">W17-5503</url>
      <doi>10.18653/v1/W17-5503</doi>
      <abstract>We test state of the art <a href="https://en.wikipedia.org/wiki/Dialogue_system">dialogue systems</a> for their behaviour in response to user-initiated sub-dialogues, i.e. interactions where a system question is responded to with a question or request from the user, who thus initiates a sub-dialogue. We look at sub-dialogues both within a single app (where the sub-dialogue concerns another topic in the original domain) and across apps (where the sub-dialogue concerns a different domain). The overall conclusion of the tests is that none of the <a href="https://en.wikipedia.org/wiki/System">systems</a> can be said to deal appropriately with user-initiated sub-dialogues.</abstract>
      <bibkey>larsson-2017-user</bibkey>
    </paper>
    <paper id="4">
      <title>A Multimodal Dialogue System for Medical Decision Support inside Virtual Reality</title>
      <author><first>Alexander</first><last>Prange</last></author>
      <author><first>Margarita</first><last>Chikobava</last></author>
      <author><first>Peter</first><last>Poller</last></author>
      <author><first>Michael</first><last>Barz</last></author>
      <author><first>Daniel</first><last>Sonntag</last></author>
      <pages>23–26</pages>
      <url hash="ab77c47a">W17-5504</url>
      <doi>10.18653/v1/W17-5504</doi>
      <abstract>We present a multimodal dialogue system that allows doctors to interact with a medical decision support system in <a href="https://en.wikipedia.org/wiki/Virtual_reality">virtual reality (VR)</a>. We integrate an interactive visualization of patient records and radiology image data, as well as therapy predictions. Therapy predictions are computed in real-time using a <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning model</a>.</abstract>
      <bibkey>prange-etal-2017-multimodal</bibkey>
    </paper>
    <paper id="5">
      <title>Generative Encoder-Decoder Models for Task-Oriented Spoken Dialog Systems with Chatting Capability</title>
      <author><first>Tiancheng</first><last>Zhao</last></author>
      <author><first>Allen</first><last>Lu</last></author>
      <author><first>Kyusong</first><last>Lee</last></author>
      <author><first>Maxine</first><last>Eskenazi</last></author>
      <pages>27–36</pages>
      <url hash="20e96998">W17-5505</url>
      <doi>10.18653/v1/W17-5505</doi>
      <abstract>Generative encoder-decoder models offer great promise in developing domain-general dialog systems. However, they have mainly been applied to open-domain conversations. This paper presents a practical and novel <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> for building task-oriented dialog systems based on encoder-decoder models. This <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> enables encoder-decoder models to accomplish slot-value independent decision-making and interact with <a href="https://en.wikipedia.org/wiki/Database">external databases</a>. Moreover, this paper shows the flexibility of the proposed method by interleaving chatting capability with a slot-filling system for better out-of-domain recovery. The models were trained on both <a href="https://en.wikipedia.org/wiki/User_data">real-user data</a> from a bus information system and <a href="https://en.wikipedia.org/wiki/Human–computer_interaction">human-human chat data</a>. Results show that the proposed <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> achieves good performance in both offline evaluation metrics and in task success rate with <a href="https://en.wikipedia.org/wiki/User_(computing)">human users</a>.</abstract>
      <bibkey>zhao-etal-2017-generative</bibkey>
    </paper>
    <paper id="6">
      <title>Key-Value Retrieval Networks for Task-Oriented Dialogue</title>
      <author><first>Mihail</first><last>Eric</last></author>
      <author><first>Lakshmi</first><last>Krishnan</last></author>
      <author><first>Francois</first><last>Charette</last></author>
      <author><first>Christopher D.</first><last>Manning</last></author>
      <pages>37–49</pages>
      <url hash="3257b29b">W17-5506</url>
      <doi>10.18653/v1/W17-5506</doi>
      <abstract>Neural task-oriented dialogue systems often struggle to smoothly interface with a <a href="https://en.wikipedia.org/wiki/Knowledge_base">knowledge base</a>. In this work, we seek to address this problem by proposing a new neural dialogue agent that is able to effectively sustain grounded, multi-domain discourse through a novel key-value retrieval mechanism. The <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> is end-to-end differentiable and does not need to explicitly model dialogue state or belief trackers. We also release a new dataset of 3,031 dialogues that are grounded through underlying knowledge bases and span three distinct tasks in the in-car personal assistant space : <a href="https://en.wikipedia.org/wiki/Calendaring_software">calendar scheduling</a>, <a href="https://en.wikipedia.org/wiki/Weather_forecasting">weather information retrieval</a>, and point-of-interest navigation. Our architecture is simultaneously trained on data from all domains and significantly outperforms a competitive rule-based system and other existing neural dialogue architectures on the provided domains according to both automatic and human evaluation metrics.</abstract>
      <bibkey>eric-etal-2017-key</bibkey>
      <pwccode url="" additional="true" />
    </paper>
    <paper id="7">
      <title>Lexical Acquisition through Implicit Confirmations over Multiple Dialogues</title>
      <author><first>Kohei</first><last>Ono</last></author>
      <author><first>Ryu</first><last>Takeda</last></author>
      <author><first>Eric</first><last>Nichols</last></author>
      <author><first>Mikio</first><last>Nakano</last></author>
      <author><first>Kazunori</first><last>Komatani</last></author>
      <pages>50–59</pages>
      <url hash="98531ad5">W17-5507</url>
      <doi>10.18653/v1/W17-5507</doi>
      <abstract>We address the problem of acquiring the <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontological categories</a> of unknown terms through implicit confirmation in dialogues. We develop an approach that makes implicit confirmation requests with an unknown term’s predicted category. Our approach does not degrade user experience with repetitive explicit confirmations, but the <a href="https://en.wikipedia.org/wiki/System">system</a> has difficulty determining if information in the confirmation request can be correctly acquired. To overcome this challenge, we propose a method for determining whether or not the predicted category is correct, which is included in an implicit confirmation request. Our method exploits multiple user responses to implicit confirmation requests containing the same <a href="https://en.wikipedia.org/wiki/Ontological_category">ontological category</a>. Experimental results revealed that the proposed method exhibited a higher precision rate for determining the correctly predicted categories than when only single user responses were considered.</abstract>
      <bibkey>ono-etal-2017-lexical</bibkey>
    </paper>
    <paper id="8">
      <title>Utterance Intent Classification of a Spoken Dialogue System with Efficiently Untied Recursive Autoencoders</title>
      <author><first>Tsuneo</first><last>Kato</last></author>
      <author><first>Atsushi</first><last>Nagai</last></author>
      <author><first>Naoki</first><last>Noda</last></author>
      <author><first>Ryosuke</first><last>Sumitomo</last></author>
      <author><first>Jianming</first><last>Wu</last></author>
      <author><first>Seiichi</first><last>Yamamoto</last></author>
      <pages>60–64</pages>
      <url hash="79fa2c28">W17-5508</url>
      <doi>10.18653/v1/W17-5508</doi>
      <abstract>Recursive autoencoders (RAEs) for compositionality of a vector space model were applied to utterance intent classification of a smartphone-based Japanese-language spoken dialogue system. Though the RAEs express a nonlinear operation on the vectors of child nodes, the <a href="https://en.wikipedia.org/wiki/Operation_(mathematics)">operation</a> is considered to be different intrinsically depending on types of <a href="https://en.wikipedia.org/wiki/Vertex_(graph_theory)">child nodes</a>. To relax the difference, a data-driven untying of autoencoders (AEs) is proposed. The experimental result of the utterance intent classification showed an improved accuracy with the proposed method compared with the basic tied RAE and untied RAE based on a manual rule.</abstract>
      <bibkey>kato-etal-2017-utterance</bibkey>
    </paper>
    <paper id="9">
      <title>Reward-Balancing for Statistical Spoken Dialogue Systems using Multi-objective Reinforcement Learning</title>
      <author><first>Stefan</first><last>Ultes</last></author>
      <author><first>Paweł</first><last>Budzianowski</last></author>
      <author><first>Iñigo</first><last>Casanueva</last></author>
      <author><first>Nikola</first><last>Mrkšić</last></author>
      <author><first>Lina M.</first><last>Rojas-Barahona</last></author>
      <author><first>Pei-Hao</first><last>Su</last></author>
      <author><first>Tsung-Hsien</first><last>Wen</last></author>
      <author><first>Milica</first><last>Gašić</last></author>
      <author><first>Steve</first><last>Young</last></author>
      <pages>65–70</pages>
      <url hash="2e8fd517">W17-5509</url>
      <doi>10.18653/v1/W17-5509</doi>
      <abstract>Reinforcement learning is widely used for dialogue policy optimization where the <a href="https://en.wikipedia.org/wiki/Reward_system">reward function</a> often consists of more than one <a href="https://en.wikipedia.org/wiki/Function_(mathematics)">component</a>, e.g., the dialogue success and the dialogue length. In this work, we propose a structured method for finding a good balance between these components by searching for the optimal reward component weighting. To render this search feasible, we use multi-objective reinforcement learning to significantly reduce the number of training dialogues required. We apply our proposed method to find optimized component weights for six domains and compare them to a default baseline.</abstract>
      <bibkey>ultes-etal-2017-reward</bibkey>
    </paper>
    <paper id="11">
      <title>Demonstration of interactive teaching for end-to-end dialog control with hybrid code networks</title>
      <author><first>Jason D.</first><last>Williams</last></author>
      <author><first>Lars</first><last>Liden</last></author>
      <pages>82–85</pages>
      <url hash="eb730c0d">W17-5511</url>
      <doi>10.18653/v1/W17-5511</doi>
      <abstract>This is a demonstration of interactive teaching for practical end-to-end dialog systems driven by a <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network</a>. In this approach, a developer teaches the <a href="https://en.wikipedia.org/wiki/Computer_network">network</a> by interacting with the <a href="https://en.wikipedia.org/wiki/System">system</a> and providing on-the-spot corrections. Once a <a href="https://en.wikipedia.org/wiki/System">system</a> is deployed, a developer can also correct mistakes in logged dialogs. This demonstration shows both of these teaching methods applied to dialog systems in three domains : pizza ordering, <a href="https://en.wikipedia.org/wiki/Restaurant">restaurant information</a>, and <a href="https://en.wikipedia.org/wiki/Weather_forecasting">weather forecasts</a>.</abstract>
      <bibkey>williams-liden-2017-demonstration</bibkey>
    </paper>
    <paper id="12">
      <title>Sub-domain Modelling for <a href="https://en.wikipedia.org/wiki/Dialogue_management">Dialogue Management</a> with Hierarchical Reinforcement Learning</title>
      <author><first>Paweł</first><last>Budzianowski</last></author>
      <author><first>Stefan</first><last>Ultes</last></author>
      <author><first>Pei-Hao</first><last>Su</last></author>
      <author><first>Nikola</first><last>Mrkšić</last></author>
      <author><first>Tsung-Hsien</first><last>Wen</last></author>
      <author><first>Iñigo</first><last>Casanueva</last></author>
      <author><first>Lina M.</first><last>Rojas-Barahona</last></author>
      <author><first>Milica</first><last>Gašić</last></author>
      <pages>86–92</pages>
      <url hash="2c28b631">W17-5512</url>
      <doi>10.18653/v1/W17-5512</doi>
      <abstract>Human conversation is inherently complex, often spanning many different topics / domains. This makes <a href="https://en.wikipedia.org/wiki/Policy_learning">policy learning</a> for <a href="https://en.wikipedia.org/wiki/Dialogue_system">dialogue systems</a> very challenging. Standard flat reinforcement learning methods do not provide an efficient <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> for modelling such <a href="https://en.wikipedia.org/wiki/Dialogue">dialogues</a>. In this paper, we focus on the under-explored problem of multi-domain dialogue management. First, we propose a new <a href="https://en.wikipedia.org/wiki/Methodology">method</a> for hierarchical reinforcement learning using the option framework. Next, we show that the proposed <a href="https://en.wikipedia.org/wiki/Architecture">architecture</a> learns faster and arrives at a better <a href="https://en.wikipedia.org/wiki/Policy">policy</a> than the existing flat ones do. Moreover, we show how pretrained policies can be adapted to more complex systems with an additional set of new actions. In doing that, we show that our approach has the potential to facilitate policy optimisation for more sophisticated multi-domain dialogue systems.</abstract>
      <bibkey>budzianowski-etal-2017-sub</bibkey>
    </paper>
    <paper id="13">
      <title>MACA : A Modular Architecture for Conversational Agents<fixed-case>MACA</fixed-case>: A Modular Architecture for Conversational Agents</title>
      <author><first>Hoai Phuoc</first><last>Truong</last></author>
      <author><first>Prasanna</first><last>Parthasarathi</last></author>
      <author><first>Joelle</first><last>Pineau</last></author>
      <pages>93–102</pages>
      <url hash="7e5c59ff">W17-5513</url>
      <doi>10.18653/v1/W17-5513</doi>
      <abstract>We propose a <a href="https://en.wikipedia.org/wiki/Software_architecture">software architecture</a> designed to ease the implementation of <a href="https://en.wikipedia.org/wiki/Dialogue_system">dialogue systems</a>. The Modular Architecture for Conversational Agents (MACA) uses a plug-n-play style that allows quick prototyping, thereby facilitating the development of new techniques and the reproduction of previous work. The <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> separates the domain of the conversation from the agent’s dialogue strategy, and as such can be easily extended to multiple domains. MACA provides tools to host dialogue agents on Amazon Mechanical Turk (mTurk) for data collection and allows processing of other sources of training data. The current version of the <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> already incorporates several domains and existing <a href="https://en.wikipedia.org/wiki/Dialogue">dialogue strategies</a> from the recent literature.</abstract>
      <bibkey>truong-etal-2017-maca</bibkey>
    </paper>
    <paper id="14">
      <title>Sequential Dialogue Context Modeling for Spoken Language Understanding</title>
      <author><first>Ankur</first><last>Bapna</last></author>
      <author><first>Gokhan</first><last>Tür</last></author>
      <author><first>Dilek</first><last>Hakkani-Tür</last></author>
      <author><first>Larry</first><last>Heck</last></author>
      <pages>103–114</pages>
      <url hash="6637ae89">W17-5514</url>
      <doi>10.18653/v1/W17-5514</doi>
      <abstract>Spoken Language Understanding (SLU) is a key component of goal oriented dialogue systems that would parse user utterances into semantic frame representations. Traditionally SLU does not utilize the dialogue history beyond the previous system turn and contextual ambiguities are resolved by the downstream components. In this paper, we explore novel approaches for modeling dialogue context in a recurrent neural network (RNN) based language understanding system. We propose the Sequential Dialogue Encoder Network, that allows <a href="https://en.wikipedia.org/wiki/Context_(language_use)">encoding context</a> from the dialogue history in <a href="https://en.wikipedia.org/wiki/Chronology">chronological order</a>. We compare the performance of our proposed architecture with two context models, one that uses just the previous turn context and another that encodes dialogue context in a memory network, but loses the order of utterances in the dialogue history. Experiments with a multi-domain dialogue dataset demonstrate that the proposed <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> results in reduced semantic frame error rates.</abstract>
      <bibkey>bapna-etal-2017-sequential</bibkey>
    </paper>
    <paper id="15">
      <title>Redundancy Localization for the Conversationalization of Unstructured Responses</title>
      <author><first>Sebastian</first><last>Krause</last></author>
      <author><first>Mikhail</first><last>Kozhevnikov</last></author>
      <author><first>Eric</first><last>Malmi</last></author>
      <author><first>Daniele</first><last>Pighin</last></author>
      <pages>115–126</pages>
      <url hash="2b8d65c9">W17-5515</url>
      <doi>10.18653/v1/W17-5515</doi>
      <abstract>Conversational agents offer users a <a href="https://en.wikipedia.org/wiki/Natural-language_user_interface">natural-language interface</a> to accomplish tasks, entertain themselves, or access information. Informational dialogue is particularly challenging in that the agent has to hold a conversation on an open topic, and to achieve a reasonable coverage it generally needs to digest and present <a href="https://en.wikipedia.org/wiki/Unstructured_data">unstructured information</a> from textual sources. Making responses based on such sources sound natural and fit appropriately into the conversation context is a topic of ongoing research, one of the key issues of which is preventing the agent’s responses from sounding repetitive. Targeting this issue, we propose a new task, known as redundancy localization, which aims to pinpoint semantic overlap between text passages. To help address it systematically, we formalize the task, prepare a public dataset with fine-grained redundancy labels, and propose a model utilizing a weak training signal defined over the results of a passage-retrieval system on web texts. The proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> demonstrates superior performance compared to a state-of-the-art entailment model and yields encouraging results when applied to a real-world dialogue.</abstract>
      <bibkey>krause-etal-2017-redundancy</bibkey>
    </paper>
    <paper id="16">
      <title>Attentive listening system with backchanneling, response generation and flexible turn-taking</title>
      <author><first>Divesh</first><last>Lala</last></author>
      <author><first>Pierrick</first><last>Milhorat</last></author>
      <author><first>Koji</first><last>Inoue</last></author>
      <author><first>Masanari</first><last>Ishida</last></author>
      <author><first>Katsuya</first><last>Takanashi</last></author>
      <author><first>Tatsuya</first><last>Kawahara</last></author>
      <pages>127–136</pages>
      <url hash="6b80bff8">W17-5516</url>
      <doi>10.18653/v1/W17-5516</doi>
      <abstract>Attentive listening systems are designed to let people, especially senior people, keep talking to maintain <a href="https://en.wikipedia.org/wiki/Communication">communication ability</a> and <a href="https://en.wikipedia.org/wiki/Mental_health">mental health</a>. This paper addresses key components of an attentive listening system which encourages users to talk smoothly. First, we introduce continuous prediction of end-of-utterances and generation of backchannels, rather than generating backchannels after end-point detection of utterances. This improves subjective evaluations of backchannels. Second, we propose an effective statement response mechanism which detects focus words and responds in the form of a question or partial repeat. This can be applied to any statement. Moreover, a flexible turn-taking mechanism is designed which uses backchannels or <a href="https://en.wikipedia.org/wiki/Filler_(materials)">fillers</a> when the turn-switch is ambiguous. These techniques are integrated into a <a href="https://en.wikipedia.org/wiki/Humanoid_robot">humanoid robot</a> to conduct attentive listening. We test the feasibility of the <a href="https://en.wikipedia.org/wiki/System">system</a> in a pilot experiment and show that it can produce coherent dialogues during conversation.</abstract>
      <bibkey>lala-etal-2017-attentive</bibkey>
    </paper>
    <paper id="17">
      <title>Natural Language Input for In-Car Spoken Dialog Systems : How Natural is Natural?</title>
      <author><first>Patricia</first><last>Braunger</last></author>
      <author><first>Wolfgang</first><last>Maier</last></author>
      <pages>137–146</pages>
      <url hash="3fdc645c">W17-5517</url>
      <doi>10.18653/v1/W17-5517</doi>
      <abstract>Recent spoken dialog systems are moving away from <a href="https://en.wikipedia.org/wiki/Command_and_control">command and control</a> towards a more intuitive and natural style of interaction. In order to choose an appropriate system design which allows the <a href="https://en.wikipedia.org/wiki/System">system</a> to deal with naturally spoken user input, a definition of what exactly constitutes naturalness in <a href="https://en.wikipedia.org/wiki/Input_(computer_science)">user input</a> is important. In this paper, we examine how different user groups naturally speak to an automotive spoken dialog system (SDS). We conduct a <a href="https://en.wikipedia.org/wiki/User_study">user study</a> in which we collect freely spoken user utterances for a wide range of use cases in <a href="https://en.wikipedia.org/wiki/German_language">German</a>. By means of a comparative study of the utterances from the study with interpersonal utterances, we provide criteria what constitutes naturalness in the user input of an state-of-the-art automotive SDS.</abstract>
      <bibkey>braunger-maier-2017-natural</bibkey>
    </paper>
    <paper id="18">
      <title>Sample-efficient Actor-Critic Reinforcement Learning with Supervised Data for Dialogue Management</title>
      <author><first>Pei-Hao</first><last>Su</last></author>
      <author><first>Paweł</first><last>Budzianowski</last></author>
      <author><first>Stefan</first><last>Ultes</last></author>
      <author><first>Milica</first><last>Gašić</last></author>
      <author><first>Steve</first><last>Young</last></author>
      <pages>147–157</pages>
      <url hash="5b6ab749">W17-5518</url>
      <doi>10.18653/v1/W17-5518</doi>
      <abstract>Deep reinforcement learning (RL) methods have significant potential for dialogue policy optimisation. However, <a href="https://en.wikipedia.org/wiki/They_(2017_film)">they</a> suffer from a poor performance in the early stages of learning. This is especially problematic for <a href="https://en.wikipedia.org/wiki/Educational_technology">on-line learning</a> with real users. Two <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">approaches</a> are introduced to tackle this problem. Firstly, to speed up the learning process, two sample-efficient neural networks algorithms : trust region actor-critic with experience replay (TRACER) and episodic natural actor-critic with experience replay (eNACER) are presented. For TRACER, the <a href="https://en.wikipedia.org/wiki/Trust_region">trust region</a> helps to control the learning step size and avoid catastrophic model changes. For eNACER, the natural gradient identifies the steepest ascent direction in policy space to speed up the <a href="https://en.wikipedia.org/wiki/Convergence_of_random_variables">convergence</a>. Both models employ off-policy learning with experience replay to improve sample-efficiency. Secondly, to mitigate the cold start issue, a corpus of demonstration data is utilised to pre-train the models prior to on-line reinforcement learning. Combining these two approaches, we demonstrate a practical approach to learn deep RL-based dialogue policies and demonstrate their effectiveness in a task-oriented information seeking domain.</abstract>
      <bibkey>su-etal-2017-sample</bibkey>
    </paper>
    <paper id="19">
      <title>A surprisingly effective out-of-the-box char2char model on the E2E NLG Challenge dataset<fixed-case>E</fixed-case>2<fixed-case>E</fixed-case> <fixed-case>NLG</fixed-case> Challenge dataset</title>
      <author><first>Shubham</first><last>Agarwal</last></author>
      <author><first>Marc</first><last>Dymetman</last></author>
      <pages>158–163</pages>
      <url hash="b1499241">W17-5519</url>
      <doi>10.18653/v1/W17-5519</doi>
      <abstract>We train a char2char model on the E2E NLG Challenge data, by exploiting out-of-the-box the recently released tfseq2seq framework, using some of the standard options offered by this tool. With minimal effort, and in particular without delexicalization, <a href="https://en.wikipedia.org/wiki/Lexicalization">tokenization</a> or lowercasing, the obtained raw predictions, according to a small scale human evaluation, are excellent on the linguistic side and quite reasonable on the adequacy side, the primary downside being the possible omissions of semantic material. However, in a significant number of cases (more than 70 %), a perfect solution can be found in the top-20 predictions, indicating promising directions for solving the remaining issues.</abstract>
      <bibkey>agarwal-dymetman-2017-surprisingly</bibkey>
    </paper>
    <paper id="20">
      <title>Interaction Quality Estimation Using Long Short-Term Memories</title>
      <author><first>Niklas</first><last>Rach</last></author>
      <author><first>Wolfgang</first><last>Minker</last></author>
      <author><first>Stefan</first><last>Ultes</last></author>
      <pages>164–169</pages>
      <url hash="67d88030">W17-5520</url>
      <doi>10.18653/v1/W17-5520</doi>
      <abstract>For estimating the Interaction Quality (IQ) in Spoken Dialogue Systems (SDS), the dialogue history is of significant importance. Previous works included this information manually in the form of precomputed temporal features into the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification process</a>. Here, we employ a deep learning architecture based on Long Short-Term Memories (LSTM) to extract this information automatically from the data, thus estimating <a href="https://en.wikipedia.org/wiki/Intelligence_quotient">IQ</a> solely by using current exchange features. We show that it is thereby possible to achieve competitive results as in a scenario where manually optimized temporal features have been included.</abstract>
      <bibkey>rach-etal-2017-interaction</bibkey>
    </paper>
    <paper id="22">
      <title>Evaluating Natural Language Understanding Services for Conversational Question Answering Systems</title>
      <author><first>Daniel</first><last>Braun</last></author>
      <author><first>Adrian</first><last>Hernandez Mendez</last></author>
      <author><first>Florian</first><last>Matthes</last></author>
      <author><first>Manfred</first><last>Langen</last></author>
      <pages>174–185</pages>
      <url hash="f5442366">W17-5522</url>
      <doi>10.18653/v1/W17-5522</doi>
      <abstract>Conversational interfaces recently gained a lot of attention. One of the reasons for the current hype is the fact that <a href="https://en.wikipedia.org/wiki/Chatbot">chatbots</a> (one particularly popular form of conversational interfaces) nowadays can be created without any programming knowledge, thanks to different toolkits and so-called Natural Language Understanding (NLU) services. While these NLU services are already widely used in both, industry and science, so far, they have not been analysed systematically. In this paper, we present a method to evaluate the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> performance of NLU services. Moreover, we present two new <a href="https://en.wikipedia.org/wiki/Text_corpus">corpora</a>, one consisting of annotated questions and one consisting of annotated questions with the corresponding answers. Based on these <a href="https://en.wikipedia.org/wiki/Text_corpus">corpora</a>, we conduct an evaluation of some of the most popular NLU services. Thereby we want to enable both, researchers and companies to make more educated decisions about which service they should use.</abstract>
      <bibkey>braun-etal-2017-evaluating</bibkey>
      <pwccode url="https://github.com/sebischair/NLU-Evaluation-Scripts" additional="false">sebischair/NLU-Evaluation-Scripts</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/nlu-evaluation-corpora">NLU Evaluation Corpora</pwcdataset>
    </paper>
    <paper id="23">
      <title>The Role of Conversation Context for Sarcasm Detection in Online Interactions</title>
      <author><first>Debanjan</first><last>Ghosh</last></author>
      <author><first>Alexander</first><last>Richard Fabbri</last></author>
      <author><first>Smaranda</first><last>Muresan</last></author>
      <pages>186–196</pages>
      <url hash="d3183294">W17-5523</url>
      <doi>10.18653/v1/W17-5523</doi>
      <abstract>Computational models for sarcasm detection have often relied on the content of utterances in isolation. However, speaker’s sarcastic intent is not always obvious without additional context. Focusing on social media discussions, we investigate two issues : (1) does modeling of <a href="https://en.wikipedia.org/wiki/Context_(language_use)">conversation context</a> help in sarcasm detection and (2) can we understand what part of <a href="https://en.wikipedia.org/wiki/Context_(language_use)">conversation context</a> triggered the <a href="https://en.wikipedia.org/wiki/Sarcasm">sarcastic reply</a>. To address the first issue, we investigate several types of Long Short-Term Memory (LSTM) networks that can model both the conversation context and the sarcastic response. We show that the conditional LSTM network (Rocktschel et al. 2015) and LSTM networks with sentence level attention on context and response outperform the LSTM model that reads only the response. To address the second issue, we present a qualitative analysis of <a href="https://en.wikipedia.org/wiki/Attention">attention weights</a> produced by the LSTM models with <a href="https://en.wikipedia.org/wiki/Attention">attention</a> and discuss the results compared with human performance on the task.</abstract>
      <bibkey>ghosh-etal-2017-role</bibkey>
      <pwccode url="https://github.com/debanjanghosh/sarcasm_context" additional="true">debanjanghosh/sarcasm_context</pwccode>
    </paper>
    <paper id="24">
      <title>VOILA : An Optimised Dialogue System for Interactively Learning Visually-Grounded Word Meanings (Demonstration System)<fixed-case>VOILA</fixed-case>: An Optimised Dialogue System for Interactively Learning Visually-Grounded Word Meanings (Demonstration System)</title>
      <author><first>Yanchao</first><last>Yu</last></author>
      <author><first>Arash</first><last>Eshghi</last></author>
      <author><first>Oliver</first><last>Lemon</last></author>
      <pages>197–200</pages>
      <url hash="88904f88">W17-5524</url>
      <doi>10.18653/v1/W17-5524</doi>
      <abstract>We present VOILA : an optimised, multi-modal dialogue agent for interactive learning of visually grounded word meanings from a human user. VOILA is : (1) able to learn new visual categories interactively from users from scratch ; (2) trained on real human-human dialogues in the same domain, and so is able to conduct natural spontaneous dialogue ; (3) optimised to find the most effective trade-off between the accuracy of the visual categories it learns and the cost it incurs to users. VOILA is deployed on Furhat, a human-like, multi-modal robot head with back-projection of the face, and a graphical virtual character.</abstract>
      <bibkey>yu-etal-2017-voila</bibkey>
    </paper>
    <paper id="25">
      <title>The E2E Dataset : New Challenges For End-to-End Generation<fixed-case>E</fixed-case>2<fixed-case>E</fixed-case> Dataset: New Challenges For End-to-End Generation</title>
      <author><first>Jekaterina</first><last>Novikova</last></author>
      <author><first>Ondřej</first><last>Dušek</last></author>
      <author><first>Verena</first><last>Rieser</last></author>
      <pages>201–206</pages>
      <url hash="f20430c0">W17-5525</url>
      <doi>10.18653/v1/W17-5525</doi>
      <abstract>This paper describes the E2E data, a new dataset for training end-to-end, data-driven natural language generation systems in the restaurant domain, which is ten times bigger than existing, frequently used datasets in this area. The E2E dataset poses new challenges : (1) its human reference texts show more <a href="https://en.wikipedia.org/wiki/Lexicon">lexical richness</a> and <a href="https://en.wikipedia.org/wiki/Syntax">syntactic variation</a>, including <a href="https://en.wikipedia.org/wiki/Discourse">discourse phenomena</a> ; (2) generating from this set requires content selection. As such, learning from this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> promises more natural, varied and less template-like system utterances. We also establish a <a href="https://en.wikipedia.org/wiki/Baseline_(medicine)">baseline</a> on this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>, which illustrates some of the difficulties associated with this <a href="https://en.wikipedia.org/wiki/Data">data</a>.</abstract>
      <bibkey>novikova-etal-2017-e2e</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/e2e">E2E</pwcdataset>
    </paper>
    <paper id="26">
      <title>Frames : a corpus for adding <a href="https://en.wikipedia.org/wiki/Memory">memory</a> to goal-oriented dialogue systems<fixed-case>F</fixed-case>rames: a corpus for adding memory to goal-oriented dialogue systems</title>
      <author><first>Layla</first><last>El Asri</last></author>
      <author><first>Hannes</first><last>Schulz</last></author>
      <author><first>Shikhar</first><last>Sharma</last></author>
      <author><first>Jeremie</first><last>Zumer</last></author>
      <author><first>Justin</first><last>Harris</last></author>
      <author><first>Emery</first><last>Fine</last></author>
      <author><first>Rahul</first><last>Mehrotra</last></author>
      <author><first>Kaheer</first><last>Suleman</last></author>
      <pages>207–219</pages>
      <url hash="30c83c01">W17-5526</url>
      <doi>10.18653/v1/W17-5526</doi>
      <revision id="1" href="W17-5526v1" hash="ba3003a6" />
      <revision id="2" href="W17-5526v2" hash="30c83c01">No description of the changes were recorded.</revision>
      <abstract>This paper proposes a new dataset, Frames, composed of 1369 human-human dialogues with an average of 15 turns per dialogue. This <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> contains goal-oriented dialogues between users who are given some constraints to book a trip and assistants who search a database to find appropriate trips. The users exhibit complex decision-making behaviour which involve comparing trips, exploring different options, and selecting among the trips that were discussed during the dialogue. To drive research on dialogue systems towards handling such <a href="https://en.wikipedia.org/wiki/Behavior">behaviour</a>, we have annotated and released the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and we propose in this paper a task called frame tracking. This <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> consists of keeping track of different <a href="https://en.wikipedia.org/wiki/Frame_(artificial_intelligence)">semantic frames</a> throughout each dialogue. We propose a rule-based baseline and analyse the frame tracking task through this <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a>.</abstract>
      <bibkey>el-asri-etal-2017-frames</bibkey>
    </paper>
    <paper id="27">
      <title>Towards a General, Continuous Model of Turn-taking in Spoken Dialogue using LSTM Recurrent Neural Networks<fixed-case>LSTM</fixed-case> Recurrent Neural Networks</title>
      <author><first>Gabriel</first><last>Skantze</last></author>
      <pages>220–230</pages>
      <url hash="b6c1913a">W17-5527</url>
      <doi>10.18653/v1/W17-5527</doi>
      <abstract>Previous models of turn-taking have mostly been trained for specific turn-taking decisions, such as discriminating between turn shifts and turn retention in pauses. In this paper, we present a predictive, continuous model of turn-taking using Long Short-Term Memory (LSTM) Recurrent Neural Networks (RNN). The <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> is trained on <a href="https://en.wikipedia.org/wiki/Human–computer_interaction">human-human dialogue data</a> to predict upcoming <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech activity</a> in a future time window. We show how this general <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> can be applied to two different <a href="https://en.wikipedia.org/wiki/Computational_complexity_theory">tasks</a> that <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> was not specifically trained for. First, to predict whether a turn-shift will occur or not in pauses, where the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves a better performance than human observers, and better than results achieved with more traditional models. Second, to make a prediction at speech onset whether the utterance will be a short backchannel or a longer utterance. Finally, we show how the hidden layer in the <a href="https://en.wikipedia.org/wiki/Computer_network">network</a> can be used as a <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">feature vector</a> for turn-taking decisions in a human-robot interaction scenario.</abstract>
      <bibkey>skantze-2017-towards</bibkey>
    </paper>
    <paper id="28">
      <title>Neural-based Natural Language Generation in Dialogue using RNN Encoder-Decoder with Semantic Aggregation<fixed-case>RNN</fixed-case> Encoder-Decoder with Semantic Aggregation</title>
      <author><first>Van-Khanh</first><last>Tran</last></author>
      <author><first>Le-Minh</first><last>Nguyen</last></author>
      <author><first>Satoshi</first><last>Tojo</last></author>
      <pages>231–240</pages>
      <url hash="01fff806">W17-5528</url>
      <doi>10.18653/v1/W17-5528</doi>
      <abstract>Natural language generation (NLG) is an important component in spoken dialogue systems. This paper presents a model called Encoder-Aggregator-Decoder which is an extension of an Recurrent Neural Network based Encoder-Decoder architecture. The proposed Semantic Aggregator consists of two components : an Aligner and a Refiner. The Aligner is a conventional <a href="https://en.wikipedia.org/wiki/Attention">attention</a> calculated over the encoded input information, while the Refiner is another <a href="https://en.wikipedia.org/wiki/Attention">attention or gating mechanism</a> stacked over the attentive Aligner in order to further select and aggregate the semantic elements. The proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> can be jointly trained both sentence planning and surface realization to produce <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language utterances</a>. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> was extensively assessed on four different NLG domains, in which the experimental results showed that the proposed generator consistently outperforms the previous methods on all the NLG domains.</abstract>
      <bibkey>tran-etal-2017-neural</bibkey>
    </paper>
    <paper id="29">
      <title>Beyond On-hold Messages : Conversational Time-buying in Task-oriented Dialogue</title>
      <author><first>Soledad</first><last>López Gambino</last></author>
      <author><first>Sina</first><last>Zarrieß</last></author>
      <author><first>David</first><last>Schlangen</last></author>
      <pages>241–246</pages>
      <url hash="b7ca1a9b">W17-5529</url>
      <doi>10.18653/v1/W17-5529</doi>
      <abstract>A common convention in <a href="https://en.wikipedia.org/wiki/Graphical_user_interface">graphical user interfaces</a> is to indicate a <a href="https://en.wikipedia.org/wiki/Wait_state">wait state</a>, for example while a program is preparing a response, through a changed cursor state or a <a href="https://en.wikipedia.org/wiki/Progress_bar">progress bar</a>. What should the analogue be in a spoken conversational system? To address this question, we set up an experiment in which a human information provider (IP) was given their information only in a delayed and incremental manner, which systematically created situations where the IP had the turn but could not provide task-related information. Our data analysis shows that 1) IPs bridge the gap until they can provide information by re-purposing a whole variety of task- and grounding-related communicative actions (e.g. echoing the user’s request, <a href="https://en.wikipedia.org/wiki/Signaling_(telecommunications)">signaling understanding</a>, asserting partially relevant information), rather than being silent or explicitly asking for time (e.g. please wait), and that 2) IPs combined these actions productively to ensure an ongoing conversation. These results, we argue, indicate that natural conversational interfaces should also be able to manage their time flexibly using a variety of conversational resources.</abstract>
      <bibkey>lopez-gambino-etal-2017-beyond</bibkey>
    </paper>
    <paper id="30">
      <title>Neural-based Context Representation Learning for Dialog Act Classification</title>
      <author><first>Daniel</first><last>Ortega</last></author>
      <author><first>Ngoc Thang</first><last>Vu</last></author>
      <pages>247–252</pages>
      <url hash="b418b44b">W17-5530</url>
      <doi>10.18653/v1/W17-5530</doi>
      <abstract>We explore context representation learning methods in neural-based models for dialog act classification. We propose and compare extensively different methods which combine <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network architectures</a> and attention mechanisms (AMs) at different context levels. Our experimental results on two benchmark datasets show consistent improvements compared to the <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> without contextual information and reveal that the most suitable AM in the <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> depends on the nature of the dataset.</abstract>
      <bibkey>ortega-vu-2017-neural</bibkey>
    </paper>
    <paper id="31">
      <title>Predicting Success in Goal-Driven Human-Human Dialogues</title>
      <author><first>Michael</first><last>Noseworthy</last></author>
      <author><first>Jackie Chi Kit</first><last>Cheung</last></author>
      <author><first>Joelle</first><last>Pineau</last></author>
      <pages>253–262</pages>
      <url hash="d1a762c5">W17-5531</url>
      <doi>10.18653/v1/W17-5531</doi>
      <abstract>In goal-driven dialogue systems, success is often defined based on a structured definition of the goal. This requires that the <a href="https://en.wikipedia.org/wiki/Dialogue_system">dialogue system</a> be constrained to handle a specific class of goals and that there be a mechanism to measure success with respect to that goal. However, in many human-human dialogues the diversity of goals makes it infeasible to define success in such a way. To address this scenario, we consider the task of automatically predicting success in goal-driven human-human dialogues using only the information communicated between participants in the form of text. We build a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> from <a href="https://en.wikipedia.org/wiki/Stackoverflow">stackoverflow.com</a> which consists of exchanges between two users in the technical domain where ground-truth success labels are available. We then propose a turn-based hierarchical neural network model that can be used to predict success without requiring a structured goal definition. We show this model outperforms <a href="https://en.wikipedia.org/wiki/Heuristics_in_judgment_and_decision-making">rule-based heuristics</a> and other baselines as it is able to detect patterns over the course of a dialogue and capture notions such as <a href="https://en.wikipedia.org/wiki/Gratitude">gratitude</a>.</abstract>
      <bibkey>noseworthy-etal-2017-predicting</bibkey>
    </paper>
    <paper id="32">
      <title>Generating and Evaluating Summaries for Partial Email Threads : Conversational Bayesian Surprise and Silver Standards<fixed-case>B</fixed-case>ayesian Surprise and Silver Standards</title>
      <author><first>Jordon</first><last>Johnson</last></author>
      <author><first>Vaden</first><last>Masrani</last></author>
      <author><first>Giuseppe</first><last>Carenini</last></author>
      <author><first>Raymond</first><last>Ng</last></author>
      <pages>263–272</pages>
      <url hash="a414e746">W17-5532</url>
      <doi>10.18653/v1/W17-5532</doi>
      <abstract>We define and motivate the problem of summarizing partial email threads. This problem introduces the challenge of generating reference summaries for partial threads when human annotation is only available for the threads as a whole, particularly when the human-selected sentences are not uniformly distributed within the threads. We propose an oracular algorithm for generating these reference summaries with arbitrary length, and we are making the resulting <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> publicly available. In addition, we apply a recent <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised method</a> based on Bayesian Surprise that incorporates background knowledge into partial thread summarization, extend it with conversational features, and modify the mechanism by which it handles redundancy. Experiments with our method indicate improved performance over the baseline for shorter partial threads ; and our results suggest that the potential benefits of background knowledge to partial thread summarization should be further investigated with larger datasets.</abstract>
      <bibkey>johnson-etal-2017-generating</bibkey>
    </paper>
    <paper id="33">
      <title>Enabling robust and fluid spoken dialogue with cognitively impaired users</title>
      <author><first>Ramin</first><last>Yaghoubzadeh</last></author>
      <author><first>Stefan</first><last>Kopp</last></author>
      <pages>273–283</pages>
      <url hash="018fdb89">W17-5533</url>
      <doi>10.18653/v1/W17-5533</doi>
      <abstract>We present the flexdiam dialogue management architecture, which was developed in a series of projects dedicated to tailoring spoken interaction to the needs of users with cognitive impairments in an everyday assistive domain, using a multimodal front-end. This hybrid DM architecture affords incremental processing of uncertain input, a flexible, mixed-initiative information grounding process that can be adapted to users’ cognitive capacities and interactive idiosyncrasies, and generic mechanisms that foster transitions in the joint discourse state that are understandable and controllable by those users, in order to effect a robust interaction for users with varying capacities.</abstract>
      <bibkey>yaghoubzadeh-kopp-2017-enabling</bibkey>
    </paper>
    <paper id="34">
      <title>Adversarial evaluation for open-domain dialogue generation</title>
      <author><first>Elia</first><last>Bruni</last></author>
      <author><first>Raquel</first><last>Fernández</last></author>
      <pages>284–288</pages>
      <url hash="b390d7c9">W17-5534</url>
      <doi>10.18653/v1/W17-5534</doi>
      <abstract>We investigate the potential of adversarial evaluation methods for open-domain dialogue generation systems, comparing the performance of a discriminative agent to that of humans on the same task. Our results show that the task is hard, both for automated models and humans, but that a discriminative agent can learn patterns that lead to above-chance performance.</abstract>
      <bibkey>bruni-fernandez-2017-adversarial</bibkey>
    </paper>
    <paper id="35">
      <title>Exploring Joint Neural Model for Sentence Level Discourse Parsing and <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a></title>
      <author><first>Bita</first><last>Nejat</last></author>
      <author><first>Giuseppe</first><last>Carenini</last></author>
      <author><first>Raymond</first><last>Ng</last></author>
      <pages>289–298</pages>
      <url hash="4df4af59">W17-5535</url>
      <doi>10.18653/v1/W17-5535</doi>
      <abstract>Discourse Parsing and <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> are two fundamental tasks in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a> that have been shown to be mutually beneficial. In this work, we design and compare two Neural Based models for jointly learning both <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a>. In the proposed approach, we first create a <a href="https://en.wikipedia.org/wiki/Vector_graphics">vector representation</a> for all the <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">text segments</a> in the input sentence. Next, we apply three different Recursive Neural Net models : one for discourse structure prediction, one for discourse relation prediction and one for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a>. Finally, we combine these Neural Nets in two different joint models : <a href="https://en.wikipedia.org/wiki/Computer_multitasking">Multi-tasking</a> and Pre-training. Our results on two standard corpora indicate that both methods result in improvements in each task but <a href="https://en.wikipedia.org/wiki/Multi-tasking">Multi-tasking</a> has a bigger impact than Pre-training. Specifically for Discourse Parsing, we see improvements in the prediction of the set of contrastive relations.</abstract>
      <bibkey>nejat-etal-2017-exploring</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="38">
      <title>Finding Structure in <a href="https://en.wikipedia.org/wiki/Figurative_language">Figurative Language</a> : Metaphor Detection with Topic-based Frames</title>
      <author><first>Hyeju</first><last>Jang</last></author>
      <author><first>Keith</first><last>Maki</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <author><first>Carolyn</first><last>Rosé</last></author>
      <pages>320–330</pages>
      <url hash="a2d9d4b8">W17-5538</url>
      <doi>10.18653/v1/W17-5538</doi>
      <abstract>In this paper, we present a novel and highly effective method for <a href="https://en.wikipedia.org/wiki/Inductive_reasoning">induction</a> and application of metaphor frame templates as a step toward detecting metaphor in extended discourse. We infer implicit facets of a given metaphor frame using a semi-supervised bootstrapping approach on an unlabeled corpus. Our model applies this frame facet information to metaphor detection, and achieves the state-of-the-art performance on a social media dataset when building upon other proven <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> in a nonlinear machine learning model. In addition, we illustrate the mechanism through which the frame and topic information enable the more accurate metaphor detection.</abstract>
      <bibkey>jang-etal-2017-finding</bibkey>
    </paper>
    <paper id="39">
      <title>Using <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement Learning</a> to Model Incrementality in a Fast-Paced Dialogue Game</title>
      <author><first>Ramesh</first><last>Manuvinakurike</last></author>
      <author><first>David</first><last>DeVault</last></author>
      <author><first>Kallirroi</first><last>Georgila</last></author>
      <pages>331–341</pages>
      <url hash="aefa7388">W17-5539</url>
      <doi>10.18653/v1/W17-5539</doi>
      <abstract>We apply <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement Learning (RL)</a> to the problem of incremental dialogue policy learning in the context of a fast-paced dialogue game. We compare the <a href="https://en.wikipedia.org/wiki/Policy">policy</a> learned by RL with a high-performance baseline policy which has been shown to perform very efficiently (nearly as well as humans) in this dialogue game. The RL policy outperforms the baseline policy in offline simulations (based on real user data). We provide a detailed comparison of the RL policy and the baseline policy, including information about how much effort and time it took to develop each one of them. We also highlight the cases where the RL policy performs better, and show that understanding the RL policy can provide valuable insights which can inform the creation of an even better rule-based policy.</abstract>
      <bibkey>manuvinakurike-etal-2017-using</bibkey>
    </paper>
    <paper id="40">
      <title>Inferring Narrative Causality between Event Pairs in Films</title>
      <author><first>Zhichao</first><last>Hu</last></author>
      <author><first>Marilyn</first><last>Walker</last></author>
      <pages>342–351</pages>
      <url hash="c721beaa">W17-5540</url>
      <doi>10.18653/v1/W17-5540</doi>
      <attachment type="poster" hash="0a68b01e">W17-5540.Poster.pdf</attachment>
      <abstract>To understand <a href="https://en.wikipedia.org/wiki/Narrative">narrative</a>, humans draw inferences about the underlying relations between <a href="https://en.wikipedia.org/wiki/Narrative">narrative events</a>. Cognitive theories of narrative understanding define these inferences as four different types of <a href="https://en.wikipedia.org/wiki/Causality">causality</a>, that include pairs of events A, B where A physically causes B (X drop, X break), to pairs of events where A causes emotional state B (Y saw X, Y felt fear). Previous work on learning narrative relations from <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">text</a> has either focused on strict physical causality, or has been vague about what relation is being learned. This paper learns pairs of causal events from a corpus of film scene descriptions which are action rich and tend to be told in chronological order. We show that event pairs induced using our methods are of high quality and are judged to have a stronger <a href="https://en.wikipedia.org/wiki/Causality">causal relation</a> than event pairs from Rel-Grams.</abstract>
      <bibkey>hu-walker-2017-inferring</bibkey>
    </paper>
    <paper id="42">
      <title>Information Navigation System with Discovering User Interests</title>
      <author><first>Koichiro</first><last>Yoshino</last></author>
      <author><first>Yu</first><last>Suzuki</last></author>
      <author><first>Satoshi</first><last>Nakamura</last></author>
      <pages>356–359</pages>
      <url hash="b729bb20">W17-5542</url>
      <doi>10.18653/v1/W17-5542</doi>
      <abstract>We demonstrate an information navigation system for sightseeing domains that has a <a href="https://en.wikipedia.org/wiki/User_interface">dialogue interface</a> for discovering user interests for <a href="https://en.wikipedia.org/wiki/Tourism">tourist activities</a>. The system discovers interests of a user with focus detection on user utterances, and proactively presents related information to the discovered user interest. A partially observable Markov decision process (POMDP)-based dialogue manager, which is extended with user focus states, controls the behavior of the system to provide information with several dialogue acts for providing information. We transferred the belief-update function and the policy of the manager from other <a href="https://en.wikipedia.org/wiki/System">system</a> trained on a different domain to show the generality of defined dialogue acts for our information navigation system.</abstract>
      <bibkey>yoshino-etal-2017-information</bibkey>
    </paper>
    <paper id="43">
      <title>Modelling Protagonist Goals and Desires in First-Person Narrative</title>
      <author><first>Elahe</first><last>Rahimtoroghi</last></author>
      <author><first>Jiaqi</first><last>Wu</last></author>
      <author><first>Ruimin</first><last>Wang</last></author>
      <author><first>Pranav</first><last>Anand</last></author>
      <author><first>Marilyn</first><last>Walker</last></author>
      <pages>360–369</pages>
      <url hash="94429379">W17-5543</url>
      <doi>10.18653/v1/W17-5543</doi>
      <attachment type="presentation" hash="941a39b2">W17-5543.Presentation.pdf</attachment>
      <abstract>Many genres of natural language text are narratively structured, a testament to our predilection for organizing our experiences as narratives. There is broad consensus that understanding a narrative requires identifying and tracking the goals and desires of the characters and their narrative outcomes. However, to date, there has been limited work on <a href="https://en.wikipedia.org/wiki/Computational_model">computational models</a> for this <a href="https://en.wikipedia.org/wiki/Problem_solving">problem</a>. We introduce a new dataset, DesireDB, which includes gold-standard labels for identifying statements of desire, textual evidence for desire fulfillment, and annotations for whether the stated desire is fulfilled given the evidence in the narrative context. We report experiments on tracking desire fulfillment using different methods, and show that LSTM Skip-Thought model achieves <a href="https://en.wikipedia.org/wiki/F-measure">F-measure</a> of 0.7 on our <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>.</abstract>
      <bibkey>rahimtoroghi-etal-2017-modelling</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/desiredb">DesireDB</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mctest">MCTest</pwcdataset>
    </paper>
    <paper id="44">
      <title>SHIHbot : A Facebook chatbot for Sexual Health Information on HIV / AIDS<fixed-case>SHIH</fixed-case>bot: A <fixed-case>F</fixed-case>acebook chatbot for Sexual Health Information on <fixed-case>HIV</fixed-case>/<fixed-case>AIDS</fixed-case></title>
      <author><first>Jacqueline</first><last>Brixey</last></author>
      <author><first>Rens</first><last>Hoegen</last></author>
      <author><first>Wei</first><last>Lan</last></author>
      <author><first>Joshua</first><last>Rusow</last></author>
      <author><first>Karan</first><last>Singla</last></author>
      <author><first>Xusen</first><last>Yin</last></author>
      <author><first>Ron</first><last>Artstein</last></author>
      <author><first>Anton</first><last>Leuski</last></author>
      <pages>370–373</pages>
      <url hash="dc8753a0">W17-5544</url>
      <doi>10.18653/v1/W17-5544</doi>
      <abstract>We present the implementation of an autonomous chatbot, SHIHbot, deployed on <a href="https://en.wikipedia.org/wiki/Facebook">Facebook</a>, which answers a wide variety of sexual health questions on HIV / AIDS. The chatbot’s response database is com-piled from professional medical and public health resources in order to provide reliable information to users. The system’s backend is NPCEditor, a response selection platform trained on linked questions and answers ; to our knowledge this is the first retrieval-based chatbot deployed on a large public social network.</abstract>
      <bibkey>brixey-etal-2017-shihbot</bibkey>
    </paper>
    <paper id="45">
      <title>How Would You Say It? Eliciting Lexically Diverse Dialogue for Supervised Semantic Parsing</title>
      <author><first>Abhilasha</first><last>Ravichander</last></author>
      <author><first>Thomas</first><last>Manzini</last></author>
      <author><first>Matthias</first><last>Grabmair</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <author><first>Jonathan</first><last>Francis</last></author>
      <author><first>Eric</first><last>Nyberg</last></author>
      <pages>374–383</pages>
      <url hash="c357b049">W17-5545</url>
      <doi>10.18653/v1/W17-5545</doi>
      <abstract>Building dialogue interfaces for real-world scenarios often entails training semantic parsers starting from zero examples. How can we build <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> that better capture the variety of ways users might phrase their queries, and what queries are actually realistic? Wang et al. (2015) proposed a method to build semantic parsing datasets by generating canonical utterances using a <a href="https://en.wikipedia.org/wiki/Grammar">grammar</a> and having crowdworkers paraphrase them into natural wording. A limitation of this approach is that it induces bias towards using similar language as the canonical utterances. In this work, we present a <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> that elicits meaningful and lexically diverse queries from users for semantic parsing tasks. Starting from a seed lexicon and a <a href="https://en.wikipedia.org/wiki/Generative_grammar">generative grammar</a>, we pair logical forms with mixed text-image representations and ask crowdworkers to paraphrase and confirm the plausibility of the queries that they generated. We use this method to build a semantic parsing dataset from scratch for a dialog agent in a smart-home simulation. We find evidence that this dataset, which we have named SmartHome, is demonstrably more lexically diverse and difficult to parse than existing domain-specific semantic parsing datasets.</abstract>
      <bibkey>ravichander-etal-2017-say</bibkey>
    </paper>
    <paper id="47">
      <title>A data-driven model of explanations for a <a href="https://en.wikipedia.org/wiki/Chatbot">chatbot</a> that helps to practice conversation in a foreign language</title>
      <author><first>Sviatlana</first><last>Höhn</last></author>
      <pages>395–405</pages>
      <url hash="f44f881c">W17-5547</url>
      <doi>10.18653/v1/W17-5547</doi>
      <abstract>This article describes a <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> of other-initiated self-repair for a <a href="https://en.wikipedia.org/wiki/Chatbot">chatbot</a> that helps to practice conversation in a foreign language. The <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> was developed using a <a href="https://en.wikipedia.org/wiki/Instant_messaging">corpus of instant messaging conversations</a> between <a href="https://en.wikipedia.org/wiki/German_language">German native and non-native speakers</a>. Conversation Analysis helped to create <a href="https://en.wikipedia.org/wiki/Computational_model">computational models</a> from a small number of examples. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> has been validated in an AIML-based chatbot. Unlike typical retrieval-based dialogue systems, the explanations are generated at run-time from a linguistic database.</abstract>
      <bibkey>hohn-2017-data</bibkey>
    </paper>
  </volume>
  <volume id="56">
    <meta>
      <booktitle>Proceedings of the First Workshop on Curation and Applications of Parallel and Comparable Corpora</booktitle>
      <url hash="159b82ed">W17-56</url>
      <editor><first>Haithem</first><last>Afli</last></editor>
      <editor><first>Chao-Hong</first><last>Liu</last></editor>
      <publisher>Asian Federation of Natural Language Processing</publisher>
      <address>Taipei, Taiwan</address>
      <month>November</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="07635f6b">W17-5600</url>
      <bibkey>ws-2017-curation</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Building a Better Bitext for Structurally Different Languages through Self-training</title>
      <author><first>Jungyeul</first><last>Park</last></author>
      <author><first>Loïc</first><last>Dugast</last></author>
      <author><first>Jeen-Pyo</first><last>Hong</last></author>
      <author><first>Chang-Uk</first><last>Shin</last></author>
      <author><first>Jeong-Won</first><last>Cha</last></author>
      <pages>1–10</pages>
      <url hash="02fe425e">W17-5601</url>
      <abstract>We propose a novel method to bootstrap the construction of parallel corpora for new pairs of structurally different languages. We do so by combining the use of a <a href="https://en.wikipedia.org/wiki/Pivot_language">pivot language</a> and <a href="https://en.wikipedia.org/wiki/Self-help">self-training</a>. A <a href="https://en.wikipedia.org/wiki/Pivot_language">pivot language</a> enables the use of existing translation models to bootstrap the <a href="https://en.wikipedia.org/wiki/Sequence_alignment">alignment</a> and a self-training procedure enables to achieve better <a href="https://en.wikipedia.org/wiki/Sequence_alignment">alignment</a>, both at the document and sentence level. We also propose several evaluation methods for the resulting <a href="https://en.wikipedia.org/wiki/Sequence_alignment">alignment</a>.</abstract>
      <bibkey>park-etal-2017-building</bibkey>
    </paper>
    <paper id="3">
      <title>Learning Phrase Embeddings from <a href="https://en.wikipedia.org/wiki/Paraphrase">Paraphrases</a> with GRUs<fixed-case>GRU</fixed-case>s</title>
      <author><first>Zhihao</first><last>Zhou</last></author>
      <author><first>Lifu</first><last>Huang</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <pages>16–23</pages>
      <url hash="9aa898fc">W17-5603</url>
      <abstract>Learning phrase representations has been widely explored in many <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing tasks</a> (e.g., <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a>, <a href="https://en.wikipedia.org/wiki/Machine_translation">Machine Translation</a>) and has shown promising improvements. Previous studies either learn non-compositional phrase representations with general word embedding learning techniques or learn compositional phrase representations based on syntactic structures, which either require huge amounts of human annotations or can not be easily generalized to all phrases. In this work, we propose to take advantage of large-scaled paraphrase database and present a pairwise-GRU framework to generate compositional phrase representations. Our <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> can be re-used to generate <a href="https://en.wikipedia.org/wiki/Representation_(systemics)">representations</a> for any phrases. Experimental results show that our <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> achieves state-of-the-art results on several phrase similarity tasks.</abstract>
      <bibkey>zhou-etal-2017-learning</bibkey>
    </paper>
  </volume>
  <volume id="57">
    <meta>
      <booktitle>Proceedings of the 4th Workshop on <fixed-case>A</fixed-case>sian Translation (<fixed-case>WAT</fixed-case>2017)</booktitle>
      <url hash="dedf7cf3">W17-57</url>
      <editor><first>Toshiaki</first><last>Nakazawa</last></editor>
      <editor><first>Isao</first><last>Goto</last></editor>
      <publisher>Asian Federation of Natural Language Processing</publisher>
      <address>Taipei, Taiwan</address>
      <month>November</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="9cd1fe89">W17-5700</url>
      <bibkey>ws-2017-asian</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Controlling Target Features in <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a> via Prefix Constraints</title>
      <author><first>Shunsuke</first><last>Takeno</last></author>
      <author><first>Masaaki</first><last>Nagata</last></author>
      <author><first>Kazuhide</first><last>Yamamoto</last></author>
      <pages>55–63</pages>
      <url hash="0549fd2e">W17-5702</url>
      <abstract>We propose prefix constraints, a novel method to enforce constraints on target sentences in <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a>. It places a sequence of special tokens at the beginning of target sentence (target prefix), while side constraints places a special token at the end of source sentence (source suffix). Prefix constraints can be predicted from source sentence jointly with target sentence, while side constraints (Sennrich et al., 2016) must be provided by the user or predicted by some other methods. In both <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">methods</a>, special tokens are designed to encode arbitrary features on target-side or metatextual information. We show that prefix constraints are more flexible than side constraints and can be used to control the behavior of neural machine translation, in terms of output length, bidirectional decoding, domain adaptation, and unaligned target word generation.<i>prefix constraints</i>, a novel method to enforce constraints on
      target sentences in neural machine translation. It places a sequence of
      special tokens at the beginning of target sentence (target prefix), while
      side constraints places a special token at the end of source sentence
      (source suffix). Prefix constraints can be predicted from source sentence
      jointly with target sentence, while side constraints (Sennrich et al., 2016) must be provided by
      the user or predicted by some other methods. In both methods, special
      tokens are designed to encode arbitrary features on target-side or
      metatextual information. We show that prefix constraints are more flexible
      than side constraints and can be used to control the behavior of neural
      machine translation, in terms of output length, bidirectional decoding,
      domain adaptation, and unaligned target word generation.
    </abstract>
      <bibkey>takeno-etal-2017-controlling</bibkey>
    </paper>
    <paper id="3">
      <title>Improving Japanese-to-English Neural Machine Translation by Paraphrasing the Target Language<fixed-case>J</fixed-case>apanese-to-<fixed-case>E</fixed-case>nglish Neural Machine Translation by Paraphrasing the Target Language</title>
      <author><first>Yuuki</first><last>Sekizawa</last></author>
      <author><first>Tomoyuki</first><last>Kajiwara</last></author>
      <author><first>Mamoru</first><last>Komachi</last></author>
      <pages>64–69</pages>
      <url hash="4fcab713">W17-5703</url>
      <abstract>Neural machine translation (NMT) produces sentences that are more fluent than those produced by <a href="https://en.wikipedia.org/wiki/Statistical_machine_translation">statistical machine translation (SMT)</a>. However, NMT has a very high <a href="https://en.wikipedia.org/wiki/Computational_cost">computational cost</a> because of the high dimensionality of the output layer. Generally, NMT restricts the size of vocabulary, which results in infrequent words being treated as out-of-vocabulary (OOV) and degrades the performance of the <a href="https://en.wikipedia.org/wiki/Translation">translation</a>. In evaluation, we achieved a statistically significant BLEU score improvement of 0.55-0.77 over the baselines including the <a href="https://en.wikipedia.org/wiki/State-of-the-art">state-of-the-art method</a>.</abstract>
      <bibkey>sekizawa-etal-2017-improving</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/aspec">ASPEC</pwcdataset>
    </paper>
    <paper id="7">
      <title>XMU Neural Machine Translation Systems for WAT 2017<fixed-case>XMU</fixed-case> Neural Machine Translation Systems for <fixed-case>WAT</fixed-case> 2017</title>
      <author><first>Boli</first><last>Wang</last></author>
      <author><first>Zhixing</first><last>Tan</last></author>
      <author><first>Jinming</first><last>Hu</last></author>
      <author><first>Yidong</first><last>Chen</last></author>
      <author><first>Xiaodong</first><last>Shi</last></author>
      <pages>95–98</pages>
      <url hash="c3067c4e">W17-5707</url>
      <abstract>This paper describes the Neural Machine Translation systems of Xiamen University for the shared translation tasks of WAT 2017. Our <a href="https://en.wikipedia.org/wiki/System">systems</a> are based on the Encoder-Decoder framework with <a href="https://en.wikipedia.org/wiki/Attention">attention</a>. We participated in three subtasks. We experimented subword segmentation, <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">synthetic training data</a> and model ensembling. Experiments show that all these <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> can give substantial improvements.</abstract>
      <bibkey>wang-etal-2017-xmu-neural</bibkey>
    </paper>
    <paper id="8">
      <title>A Bag of Useful Tricks for Practical <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a> : Embedding Layer Initialization and Large Batch Size</title>
      <author><first>Masato</first><last>Neishi</last></author>
      <author><first>Jin</first><last>Sakuma</last></author>
      <author><first>Satoshi</first><last>Tohda</last></author>
      <author><first>Shonosuke</first><last>Ishiwatari</last></author>
      <author><first>Naoki</first><last>Yoshinaga</last></author>
      <author><first>Masashi</first><last>Toyoda</last></author>
      <pages>99–109</pages>
      <url hash="10c6a9ec">W17-5708</url>
      <abstract>In this paper, we describe the team UT-IIS’s system and results for the WAT 2017 translation tasks. We further investigated several tricks including a novel technique for initializing embedding layers using only the <a href="https://en.wikipedia.org/wiki/Parallel_corpus">parallel corpus</a>, which increased the BLEU score by 1.28, found a practical large batch size of 256, and gained insights regarding <a href="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)">hyperparameter settings</a>. Ultimately, our <a href="https://en.wikipedia.org/wiki/System">system</a> obtained a better result than the state-of-the-art <a href="https://en.wikipedia.org/wiki/System">system</a> of WAT 2016. Our code is available on.<url>https://github.com/nem6ishi/wat17</url>. </abstract>
      <bibkey>neishi-etal-2017-bag</bibkey>
      <pwccode url="https://github.com/nem6ishi/wat17" additional="false">nem6ishi/wat17</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/aspec">ASPEC</pwcdataset>
    </paper>
    <paper id="9">
      <title>Patent NMT integrated with Large Vocabulary Phrase Translation by SMT at WAT 2017<fixed-case>NMT</fixed-case> integrated with Large Vocabulary Phrase Translation by <fixed-case>SMT</fixed-case> at <fixed-case>WAT</fixed-case> 2017</title>
      <author><first>Zi</first><last>Long</last></author>
      <author><first>Ryuichiro</first><last>Kimura</last></author>
      <author><first>Takehito</first><last>Utsuro</last></author>
      <author><first>Tomoharu</first><last>Mitsuhashi</last></author>
      <author><first>Mikio</first><last>Yamamoto</last></author>
      <pages>110–118</pages>
      <url hash="a017090a">W17-5709</url>
      <abstract>Neural machine translation (NMT) can not handle a larger vocabulary because the <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training complexity</a> and decoding complexity proportionally increase with the number of target words. This problem becomes even more serious when translating patent documents, which contain many <a href="https://en.wikipedia.org/wiki/Jargon">technical terms</a> that are observed infrequently. Long et al. (2017) proposed to select phrases that contain out-of-vocabulary words using the statistical approach of branching entropy. The selected phrases are then replaced with tokens during training and post-translated by the phrase translation table of SMT. In this paper, we apply the <a href="https://en.wikipedia.org/wiki/Methodology">method</a> proposed by Long et al. (2017) to the WAT 2017 Japanese-Chinese and Japanese-English patent datasets. Evaluation on Japanese-to-Chinese, Chinese-to-Japanese, Japanese-to-English and English-to-Japanese patent sentence translation proved the effectiveness of phrases selected with branching entropy, where the NMT model of Long et al. (2017) achieves a substantial improvement over a baseline NMT model without the technique proposed by Long et al.</abstract>
      <bibkey>long-etal-2017-patent</bibkey>
    </paper>
    <paper id="12">
      <title>A Simple and Strong Baseline : NAIST-NICT Neural Machine Translation System for WAT2017 English-Japanese Translation Task<fixed-case>NAIST</fixed-case>-<fixed-case>NICT</fixed-case> Neural Machine Translation System for <fixed-case>WAT</fixed-case>2017 <fixed-case>E</fixed-case>nglish-<fixed-case>J</fixed-case>apanese Translation Task</title>
      <author><first>Yusuke</first><last>Oda</last></author>
      <author><first>Katsuhito</first><last>Sudoh</last></author>
      <author><first>Satoshi</first><last>Nakamura</last></author>
      <author><first>Masao</first><last>Utiyama</last></author>
      <author><first>Eiichiro</first><last>Sumita</last></author>
      <pages>135–139</pages>
      <url hash="1e5af071">W17-5712</url>
      <abstract>This paper describes the details about the NAIST-NICT machine translation system for WAT2017 English-Japanese Scientific Paper Translation Task. The system consists of a language-independent tokenizer and an attentional encoder-decoder style neural machine translation model. According to the official results, our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves higher translation accuracy than any systems submitted previous campaigns despite simple <a href="https://en.wikipedia.org/wiki/Conceptual_model">model architecture</a>.</abstract>
      <bibkey>oda-etal-2017-simple</bibkey>
    </paper>
    <paper id="13">
      <title>Comparison of <a href="https://en.wikipedia.org/wiki/Simultaneous_multithreading">SMT</a> and <a href="https://en.wikipedia.org/wiki/Simultaneous_multithreading">NMT</a> trained with large Patent Corpora : Japio at WAT2017<fixed-case>SMT</fixed-case> and <fixed-case>NMT</fixed-case> trained with large Patent Corpora: <fixed-case>J</fixed-case>apio at <fixed-case>WAT</fixed-case>2017</title>
      <author><first>Satoshi</first><last>Kinoshita</last></author>
      <author><first>Tadaaki</first><last>Oshio</last></author>
      <author><first>Tomoharu</first><last>Mitsuhashi</last></author>
      <pages>140–145</pages>
      <url hash="9d5ff223">W17-5713</url>
      <abstract>Japio participates in patent subtasks (JPC-EJ / JE / CJ / KJ) with phrase-based statistical machine translation (SMT) and neural machine translation (NMT) systems which are trained with its own patent corpora in addition to the subtask corpora provided by organizers of WAT2017. In EJ and CJ subtasks, SMT and NMT systems whose sizes of training corpora are about 50 million and 10 million sentence pairs respectively achieved comparable scores for automatic evaluations, but NMT systems were superior to SMT systems for both official and in-house human evaluations.</abstract>
      <bibkey>kinoshita-etal-2017-comparison</bibkey>
    </paper>
    <paper id="14">
      <title>Kyoto University Participation to WAT 2017<fixed-case>K</fixed-case>yoto <fixed-case>U</fixed-case>niversity Participation to <fixed-case>WAT</fixed-case> 2017</title>
      <author><first>Fabien</first><last>Cromieres</last></author>
      <author><first>Raj</first><last>Dabre</last></author>
      <author><first>Toshiaki</first><last>Nakazawa</last></author>
      <author><first>Sadao</first><last>Kurohashi</last></author>
      <pages>146–153</pages>
      <url hash="5bc667aa">W17-5714</url>
      <abstract>We describe here our approaches and results on the WAT 2017 shared translation tasks. Following our good results with <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a> in the previous shared task, we continue this approach this year, with incremental improvements in <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> and training methods. We focused on the ASPEC dataset and could improve the state-of-the-art results for Chinese-to-Japanese and Japanese-to-Chinese translations.</abstract>
      <bibkey>cromieres-etal-2017-kyoto</bibkey>
      <pwccode url="https://github.com/fabiencro/knmt" additional="false">fabiencro/knmt</pwccode>
    </paper>
    <paper id="15">
      <title>CUNI NMT System for WAT 2017 Translation Tasks<fixed-case>CUNI</fixed-case> <fixed-case>NMT</fixed-case> System for <fixed-case>WAT</fixed-case> 2017 Translation Tasks</title>
      <author><first>Tom</first><last>Kocmi</last></author>
      <author><first>Dušan</first><last>Variš</last></author>
      <author><first>Ondřej</first><last>Bojar</last></author>
      <pages>154–159</pages>
      <url hash="fb7b5f5f">W17-5715</url>
      <abstract>The paper presents this year’s CUNI submissions to the WAT 2017 Translation Task focusing on the Japanese-English translation, namely Scientific papers subtask, Patents subtask and Newswire subtask. We compare two neural network architectures, the standard sequence-to-sequence with attention (Seq2Seq) and an architecture using convolutional sentence encoder (FBConv2Seq), both implemented in the NMT framework Neural Monkey that we currently participate in developing. We also compare various types of preprocessing of the source <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">Japanese sentences</a> and their impact on the overall results. Furthermore, we include the results of our experiments with out-of-domain data obtained by combining the corpora provided for each subtask.</abstract>
      <bibkey>kocmi-etal-2017-cuni</bibkey>
    </paper>
    <paper id="16">
      <title>Tokyo Metropolitan University Neural Machine Translation System for WAT 2017<fixed-case>T</fixed-case>okyo Metropolitan University Neural Machine Translation System for <fixed-case>WAT</fixed-case> 2017</title>
      <author><first>Yukio</first><last>Matsumura</last></author>
      <author><first>Mamoru</first><last>Komachi</last></author>
      <pages>160–166</pages>
      <url hash="600972ce">W17-5716</url>
      <abstract>In this paper, we describe our neural machine translation (NMT) system, which is based on the attention-based NMT and uses long short-term memories (LSTM) as RNN. We implemented <a href="https://en.wikipedia.org/wiki/Beam_search">beam search</a> and ensemble decoding in the NMT system. The <a href="https://en.wikipedia.org/wiki/System">system</a> was tested on the 4th Workshop on Asian Translation (WAT 2017) shared tasks. In our experiments, we participated in the scientific paper subtasks and attempted Japanese-English, English-Japanese, and Japanese-Chinese translation tasks. The experimental results showed that implementation of <a href="https://en.wikipedia.org/wiki/Beam_search">beam search</a> and ensemble decoding can effectively improve the translation quality.</abstract>
      <bibkey>matsumura-komachi-2017-tokyo</bibkey>
    </paper>
    <paper id="17">
      <title>Comparing Recurrent and Convolutional Architectures for English-Hindi Neural Machine Translation<fixed-case>E</fixed-case>nglish-<fixed-case>H</fixed-case>indi Neural Machine Translation</title>
      <author><first>Sandhya</first><last>Singh</last></author>
      <author><first>Ritesh</first><last>Panjwani</last></author>
      <author><first>Anoop</first><last>Kunchukuttan</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>167–170</pages>
      <url hash="77bf8678">W17-5717</url>
      <abstract>In this paper, we empirically compare the two encoder-decoder neural machine translation architectures : convolutional sequence to sequence model (ConvS2S) and recurrent sequence to sequence model (RNNS2S) for English-Hindi language pair as part of IIT Bombay’s submission to WAT2017 shared task. We report the results for both English-Hindi and Hindi-English direction of language pair.</abstract>
      <bibkey>singh-etal-2017-comparing</bibkey>
    </paper>
  </volume>
  <volume id="58">
    <meta>
      <booktitle>Proceedings of the International Workshop on Digital Disease Detection using Social Media 2017 (<fixed-case>DDDSM</fixed-case>-2017)</booktitle>
      <url hash="499e18b6">W17-58</url>
      <editor><first>Jitendra</first><last>Jonnagaddala</last></editor>
      <editor><first>Hong-Jie</first><last>Dai</last></editor>
      <editor><first>Yung-Chun</first><last>Chang</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Taipei, Taiwan</address>
      <month>November</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="039a6375">W17-5800</url>
      <bibkey>ws-2017-international-digital</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Automatic detection of stance towards vaccination in online discussion forums</title>
      <author><first>Maria</first><last>Skeppstedt</last></author>
      <author><first>Andreas</first><last>Kerren</last></author>
      <author><first>Manfred</first><last>Stede</last></author>
      <pages>1–8</pages>
      <url hash="cfe637e0">W17-5801</url>
      <abstract>A classifier for automatic detection of stance towards vaccination in <a href="https://en.wikipedia.org/wiki/Internet_forum">online forums</a> was trained and evaluated. Debate posts from six discussion threads on the British parental website Mumsnet were manually annotated for stance ‘against’ or ‘for’ vaccination, or as ‘undecided’. A <a href="https://en.wikipedia.org/wiki/Support_vector_machine">support vector machine</a>, trained to detect the three classes, achieved a macro F-score of 0.44, while a macro F-score of 0.62 was obtained by the same type of classifier on the binary classification task of distinguishing stance ‘against’ vaccination from stance ‘for’ vaccination. These results show that vaccine stance detection in <a href="https://en.wikipedia.org/wiki/Internet_forum">online forums</a> is a difficult task, at least for the type of <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> investigated and for the relatively small training corpus that was used. Future work will therefore include an expansion of the training data and an evaluation of other types of <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> and <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>.</abstract>
      <bibkey>skeppstedt-etal-2017-automatic</bibkey>
    </paper>
    <paper id="2">
      <title>Analysing the Causes of <a href="https://en.wikipedia.org/wiki/Depression_(mood)">Depressed Mood</a> from Depression Vulnerable Individuals</title>
      <author><first>Noor Fazilla</first><last>Abd Yusof</last></author>
      <author><first>Chenghua</first><last>Lin</last></author>
      <author><first>Frank</first><last>Guerin</last></author>
      <pages>9–17</pages>
      <url hash="0ac21eb9">W17-5802</url>
      <abstract>We develop a <a href="https://en.wikipedia.org/wiki/Computational_model">computational model</a> to discover the potential causes of depression by analysing the topics in a <a href="https://en.wikipedia.org/wiki/User-generated_content">usergenerated text</a>. We show the most prominent causes, and how these <a href="https://en.wikipedia.org/wiki/Causality">causes</a> evolve over time. Also, we highlight the differences in causes between students with low and high neuroticism. Our studies demonstrate that the topics reveal valuable clues about the causes contributing to <a href="https://en.wikipedia.org/wiki/Depression_(mood)">depressed mood</a>. Identifying causes can have a significant impact on improving the quality of depression care ; thereby providing greater insights into a patient’s state for pertinent treatment recommendations. Hence, this study significantly expands the ability to discover the potential factors that trigger depression, making it possible to increase the efficiency of depression treatment.</abstract>
      <bibkey>abd-yusof-etal-2017-analysing</bibkey>
    </paper>
    <paper id="3">
      <title>Multivariate Linear Regression of Symptoms-related Tweets for Infectious Gastroenteritis Scale Estimation</title>
      <author><first>Ryo</first><last>Takeuchi</last></author>
      <author><first>Hayate</first><last>Iso</last></author>
      <author><first>Kaoru</first><last>Ito</last></author>
      <author><first>Shoko</first><last>Wakamiya</last></author>
      <author><first>Eiji</first><last>Aramaki</last></author>
      <pages>18–25</pages>
      <url hash="d32e222a">W17-5803</url>
      <abstract>To date, various Twitter-based event detection systems have been proposed. Most of their targets, however, share common characteristics. They are seasonal or global events such as <a href="https://en.wikipedia.org/wiki/Earthquake">earthquakes</a> and <a href="https://en.wikipedia.org/wiki/Influenza_pandemic">flu pandemics</a>. In contrast, this study targets unseasonal and local disease events. Our system investigates the frequencies of disease-related words such as <a href="https://en.wikipedia.org/wiki/Nausea">nausea</a>, chill, and <a href="https://en.wikipedia.org/wiki/Diarrhea">diarrhea</a> and estimates the number of patients using regression of these word frequencies. Experiments conducted using Japanese 47 areas from January 2017 to April 2017 revealed that the detection of small and unseasonal event is extremely difficult (overall performance : 0.13). However, we found that the event scale and the detection performance show high correlation in the specified cases (in the phase of patient increasing or decreasing). The results also suggest that when 150 and more patients appear in a high population area, we can expect that our social sensors detect this <a href="https://en.wikipedia.org/wiki/Outbreak">outbreak</a>. Based on these results, we can infer that social sensors can reliably detect unseasonal and local disease events under certain conditions, just as they can for seasonal or global events.</abstract>
      <bibkey>takeuchi-etal-2017-multivariate</bibkey>
    </paper>
    <paper id="5">
      <title>Using a Recurrent Neural Network Model for Classification of Tweets Conveyed Influenza-related Information</title>
      <author><first>Chen-Kai</first><last>Wang</last></author>
      <author><first>Onkar</first><last>Singh</last></author>
      <author><first>Zhao-Li</first><last>Tang</last></author>
      <author><first>Hong-Jie</first><last>Dai</last></author>
      <pages>33–38</pages>
      <url hash="b4407d76">W17-5805</url>
      <abstract>Traditional disease surveillance systems depend on outpatient reporting and virological test results released by hospitals. These <a href="https://en.wikipedia.org/wiki/Data">data</a> have valid and accurate information about emerging outbreaks but it’s often not timely. In recent years the exponential growth of users getting connected to <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> provides immense knowledge about <a href="https://en.wikipedia.org/wiki/Epidemic">epidemics</a> by sharing related information. Social media can now flag more immediate concerns related to out-breaks in real time. In this paper we apply the long short-term memory recurrent neural net-work (RNN) architecture to classify tweets conveyed influenza-related information and compare its performance with baseline algorithms including support vector machine (SVM), <a href="https://en.wikipedia.org/wiki/Decision_tree_learning">decision tree</a>, <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">naive Bayes</a>, simple logistics, and <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">naive Bayes multinomial</a>. The developed RNN model achieved an <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> of 0.845 on the MedWeb task test set, which outperforms the <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> of SVM without applying the synthetic minority oversampling technique by 0.08. The <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> of the RNN model is within 1 % of the highest score achieved by SVM with oversampling technique.</abstract>
      <bibkey>wang-etal-2017-using</bibkey>
    </paper>
    <paper id="6">
      <title>ZikaHack 2016 : A digital disease detection competition<fixed-case>Z</fixed-case>ika<fixed-case>H</fixed-case>ack 2016: A digital disease detection competition</title>
      <author><first>Dillon C</first><last>Adam</last></author>
      <author><first>Jitendra</first><last>Jonnagaddala</last></author>
      <author><first>Daniel</first><last>Han-Chen</last></author>
      <author><first>Sean</first><last>Batongbacal</last></author>
      <author><first>Luan</first><last>Almeida</last></author>
      <author><first>Jing Z</first><last>Zhu</last></author>
      <author><first>Jenny J</first><last>Yang</last></author>
      <author><first>Jumail M</first><last>Mundekkat</last></author>
      <author><first>Steven</first><last>Badman</last></author>
      <author><first>Abrar</first><last>Chughtai</last></author>
      <author><first>C Raina</first><last>MacIntyre</last></author>
      <pages>39–46</pages>
      <url hash="5faa88d5">W17-5806</url>
      <abstract>Effective response to infectious diseases outbreaks relies on the rapid and early detection of those outbreaks. Invalidated, yet timely and openly available digital information can be used for the early detection of outbreaks. Public health surveillance authorities can exploit these early warnings to plan and co-ordinate rapid surveillance and emergency response programs. In 2016, a digital disease detection competition named ZikaHack was launched. The objective of the competition was for multidisciplinary teams to design, develop and demonstrate innovative digital disease detection solutions to retrospectively detect the 2015-16 Brazilian Zika virus outbreak earlier than traditional surveillance methods. In this paper, an overview of the ZikaHack competition is provided. The challenges and lessons learned in organizing this <a href="https://en.wikipedia.org/wiki/Competition">competition</a> are also discussed for use by other researchers interested in organizing similar <a href="https://en.wikipedia.org/wiki/Competition">competitions</a>.</abstract>
      <bibkey>adam-etal-2017-zikahack</bibkey>
    </paper>
    <paper id="9">
      <title>Chemical-Induced Disease Detection Using Invariance-based Pattern Learning Model</title>
      <author><first>Neha</first><last>Warikoo</last></author>
      <author><first>Yung-Chun</first><last>Chang</last></author>
      <author><first>Wen-Lian</first><last>Hsu</last></author>
      <pages>57–64</pages>
      <url hash="4c8126c5">W17-5809</url>
      <abstract>In this work, we introduce a novel feature engineering approach named algebraic invariance to identify discriminative patterns for learning relation pair features for the chemical-disease relation (CDR) task of BioCreative V. Our method exploits the existing structural similarity of the key concepts of relation descriptions from the CDR corpus to generate robust linguistic patterns for SVM tree kernel-based learning. Preprocessing of the training data classifies the entity pairs as either related or unrelated to build instance types for both inter-sentential and intra-sentential scenarios. An <a href="https://en.wikipedia.org/wiki/Invariant_(mathematics)">invariant function</a> is proposed to process and optimally cluster similar patterns for both positive and negative instances. The learning model for CDR pairs is based on the SVM tree kernel approach, which generates feature trees and vectors and is modeled on suitable invariance based patterns, bringing brevity, precision and context to the identifier features. Results demonstrate that our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> outperformed other compared approaches, achieved a high <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall rate</a> of 85.08 %, and averaged an F1-score of 54.34 % without the use of any additional <a href="https://en.wikipedia.org/wiki/Knowledge_base">knowledge bases</a>.</abstract>
      <bibkey>warikoo-etal-2017-chemical</bibkey>
    </paper>
  </volume>
  <volume id="59">
    <meta>
      <booktitle>Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (<fixed-case>NLPTEA</fixed-case> 2017)</booktitle>
      <url hash="e181ef63">W17-59</url>
      <editor><first>Yuen-Hsien</first><last>Tseng</last></editor>
      <editor><first>Hsin-Hsi</first><last>Chen</last></editor>
      <editor><first>Lung-Hao</first><last>Lee</last></editor>
      <editor><first>Liang-Chih</first><last>Yu</last></editor>
      <publisher>Asian Federation of Natural Language Processing</publisher>
      <address>Taipei, Taiwan</address>
      <month>December</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="35dfc336">W17-5900</url>
      <bibkey>ws-2017-natural</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Understanding Non-Native Writings : Can a <a href="https://en.wikipedia.org/wiki/Parsis">Parser</a> Help?</title>
      <author><first>Jirka</first><last>Hana</last></author>
      <author><first>Barbora</first><last>Hladká</last></author>
      <pages>12–16</pages>
      <url hash="994efe52">W17-5902</url>
      <abstract>We present a pilot study on parsing non-native texts written by learners of <a href="https://en.wikipedia.org/wiki/Czech_language">Czech</a>. We performed experiments that have shown that at least high-level syntactic functions, like subject, predicate, and object, can be assigned based on a <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> trained on standard <a href="https://en.wikipedia.org/wiki/First_language">native language</a>.</abstract>
      <bibkey>hana-hladka-2017-understanding</bibkey>
    </paper>
    <paper id="3">
      <title>Carrier Sentence Selection for Fill-in-the-blank Items<fixed-case>C</fixed-case>arrier Sentence Selection for Fill-in-the-blank Items</title>
      <author><first>Shu</first><last>Jiang</last></author>
      <author><first>John</first><last>Lee</last></author>
      <pages>17–22</pages>
      <url hash="1233bce0">W17-5903</url>
      <abstract>Fill-in-the-blank items are a common form of exercise in computer-assisted language learning systems. To automatically generate an effective item, the system must be able to select a high-quality carrier sentence that illustrates the usage of the target word. Previous approaches for carrier sentence selection have considered <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentence length</a>, vocabulary difficulty, the position of the target word and the presence of <a href="https://en.wikipedia.org/wiki/Finite_verb">finite verbs</a>. This paper investigates the utility of word co-occurrence statistics and <a href="https://en.wikipedia.org/wiki/Lexical_similarity">lexical similarity</a> as selection criteria. In an evaluation on generating fill-in-the-blank items for learning <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a> as a foreign language, we show that these two criteria can improve carrier sentence quality.</abstract>
      <bibkey>jiang-lee-2017-carrier</bibkey>
    </paper>
    <paper id="6">
      <title>Chinese Spelling Check based on N-gram and String Matching Algorithm<fixed-case>C</fixed-case>hinese Spelling Check based on N-gram and String Matching Algorithm</title>
      <author><first>Jui-Feng</first><last>Yeh</last></author>
      <author><first>Li-Ting</first><last>Chang</last></author>
      <author><first>Chan-Yi</first><last>Liu</last></author>
      <author><first>Tsung-Wei</first><last>Hsu</last></author>
      <pages>35–38</pages>
      <url hash="21fd3319">W17-5906</url>
      <abstract>This paper presents a Chinese spelling check approach based on <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> combined with string match algorithm to treat the problems resulted from the influence caused by Cantonese mother tone. N-grams first used to detecting the probability of sentence constructed by the writers, a string matching algorithm called Knuth-Morris-Pratt (KMP) Algorithm is used to detect and correct the error. According to the experimental results, the proposed approach can detect the error and provide the corresponding correction.</abstract>
      <bibkey>yeh-etal-2017-chinese</bibkey>
    </paper>
    <paper id="7">
      <title>N-gram Model for Chinese Grammatical Error Diagnosis<fixed-case>C</fixed-case>hinese Grammatical Error Diagnosis</title>
      <author><first>Jianbo</first><last>Zhao</last></author>
      <author><first>Hao</first><last>Liu</last></author>
      <author><first>Zuyi</first><last>Bao</last></author>
      <author><first>Xiaopeng</first><last>Bai</last></author>
      <author><first>Si</first><last>Li</last></author>
      <author><first>Zhiqing</first><last>Lin</last></author>
      <pages>39–44</pages>
      <url hash="6ca017c3">W17-5907</url>
      <abstract>Detection and correction of Chinese grammatical errors have been two of major challenges for Chinese automatic grammatical error diagnosis. This paper presents an <a href="https://en.wikipedia.org/wiki/N-gram_model">N-gram model</a> for automatic detection and correction of Chinese grammatical errors in NLPTEA 2017 task. The experiment results show that the proposed <a href="https://en.wikipedia.org/wiki/Methodology">method</a> is good at correction of <a href="https://en.wikipedia.org/wiki/Chinese_grammar">Chinese grammatical errors</a>.</abstract>
      <bibkey>zhao-etal-2017-n</bibkey>
    </paper>
    <paper id="8">
      <title>The Influence of Spelling Errors on Content Scoring Performance</title>
      <author><first>Andrea</first><last>Horbach</last></author>
      <author><first>Yuning</first><last>Ding</last></author>
      <author><first>Torsten</first><last>Zesch</last></author>
      <pages>45–53</pages>
      <url hash="1ca27570">W17-5908</url>
      <abstract>Spelling errors occur frequently in educational settings, but their influence on <a href="https://en.wikipedia.org/wiki/Score_(game)">automatic scoring</a> is largely unknown. We therefore investigate the influence of spelling errors on content scoring performance using the example of the ASAP corpus. We conduct an annotation study on the nature of spelling errors in the ASAP dataset and utilize these finding in machine learning experiments that measure the influence of spelling errors on automatic content scoring. Our main finding is that scoring methods using both token and character n-gram features are robust against spelling errors up to the error frequency in ASAP.</abstract>
      <bibkey>horbach-etal-2017-influence</bibkey>
    </paper>
    <paper id="9">
      <title>Analyzing the Impact of Spelling Errors on POS-Tagging and Chunking in Learner English<fixed-case>POS</fixed-case>-Tagging and Chunking in Learner <fixed-case>E</fixed-case>nglish</title>
      <author><first>Tomoya</first><last>Mizumoto</last></author>
      <author><first>Ryo</first><last>Nagata</last></author>
      <pages>54–58</pages>
      <url hash="54dbb9f9">W17-5909</url>
      <abstract>Part-of-speech (POS) tagging and chunking have been used in tasks targeting learner English ; however, to the best our knowledge, few studies have evaluated their performance and no studies have revealed the causes of POS-tagging / chunking errors in detail. Therefore, we investigate performance and analyze the causes of failure. We focus on spelling errors that occur frequently in learner English. We demonstrate that spelling errors reduced POS-tagging performance by 0.23 % owing to spelling errors, and that a <a href="https://en.wikipedia.org/wiki/Spell_checker">spell checker</a> is not necessary for POS-tagging / chunking of learner English.</abstract>
      <bibkey>mizumoto-nagata-2017-analyzing</bibkey>
    </paper>
    <paper id="10">
      <title>Complex Word Identification : Challenges in Data Annotation and System Performance</title>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <author><first>Shervin</first><last>Malmasi</last></author>
      <author><first>Gustavo</first><last>Paetzold</last></author>
      <author><first>Lucia</first><last>Specia</last></author>
      <pages>59–63</pages>
      <url hash="0ede0a62">W17-5910</url>
      <abstract>This paper revisits the problem of complex word identification (CWI) following up the SemEval CWI shared task. We use <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble classifiers</a> to investigate how well <a href="https://en.wikipedia.org/wiki/Computational_complexity_theory">computational methods</a> can discriminate between complex and non-complex words. Furthermore, we analyze the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> performance to understand what makes lexical complexity challenging. Our findings show that most systems performed poorly on the SemEval CWI dataset, and one of the reasons for that is the way in which human annotation was performed.</abstract>
      <bibkey>zampieri-etal-2017-complex</bibkey>
    </paper>
    <paper id="11">
      <title>Suggesting Sentences for <a href="https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language">ESL</a> using Kernel Embeddings<fixed-case>ESL</fixed-case> using Kernel Embeddings</title>
      <author><first>Kent</first><last>Shioda</last></author>
      <author><first>Mamoru</first><last>Komachi</last></author>
      <author><first>Rue</first><last>Ikeya</last></author>
      <author><first>Daichi</first><last>Mochihashi</last></author>
      <pages>64–68</pages>
      <url hash="cd95eb5b">W17-5911</url>
      <abstract>Sentence retrieval is an important NLP application for <a href="https://en.wikipedia.org/wiki/English_language">English</a> as a Second Language (ESL) learners. ESL learners are familiar with <a href="https://en.wikipedia.org/wiki/Web_search_engine">web search engines</a>, but generic web search results may not be adequate for composing documents in a specific domain. However, if we build our own <a href="https://en.wikipedia.org/wiki/Web_search_engine">search system</a> specialized to a domain, it may be subject to the data sparseness problem. Recently proposed <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> partially addresses the data sparseness problem, but fails to extract sentences relevant to queries owing to the modeling of the latent intent of the query. Thus, we propose a method of retrieving example sentences using kernel embeddings and N-gram windows. This method implicitly models latent intent of query and sentences, and alleviates the problem of noisy alignment. Our results show that our method achieved higher precision in sentence retrieval for <a href="https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language">ESL</a> in the domain of a university press release corpus, as compared to a previous unsupervised method used for a semantic textual similarity task.</abstract>
      <bibkey>shioda-etal-2017-suggesting</bibkey>
    </paper>
    <paper id="12">
      <title>Event Timeline Generation from History Textbooks</title>
      <author><first>Harsimran</first><last>Bedi</last></author>
      <author><first>Sangameshwar</first><last>Patil</last></author>
      <author><first>Swapnil</first><last>Hingmire</last></author>
      <author><first>Girish</first><last>Palshikar</last></author>
      <pages>69–77</pages>
      <url hash="7e750e6f">W17-5912</url>
      <abstract>Event timeline serves as the basic structure of history, and it is used as a disposition of key phenomena in studying history as a subject in secondary school. In order to enable a student to understand a historical phenomenon as a series of connected events, we present a system for automatic event timeline generation from <a href="https://en.wikipedia.org/wiki/Textbook">history textbooks</a>. Additionally, we propose Message Sequence Chart (MSC) and time-map based visualization techniques to visualize an event timeline. We also identify key computational challenges in developing <a href="https://en.wikipedia.org/wiki/Natural-language_user_interface">natural language processing based applications</a> for <a href="https://en.wikipedia.org/wiki/Textbook">history textbooks</a>.</abstract>
      <bibkey>bedi-etal-2017-event</bibkey>
    </paper>
  </volume>
  <volume id="60">
    <meta>
      <booktitle>Proceedings of the 9th <fixed-case>SIGHAN</fixed-case> Workshop on <fixed-case>C</fixed-case>hinese Language Processing</booktitle>
      <url hash="8c8f63f7">W17-60</url>
      <editor><first>Yue</first><last>Zhang</last></editor>
      <editor><first>Zhifang</first><last>Sui</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Taiwan</address>
      <month>December</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="7205cdde">W17-6000</url>
      <bibkey>ws-2017-sighan</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Group Linguistic Bias Aware Neural Response Generation</title>
      <author><first>Jianan</first><last>Wang</last></author>
      <author><first>Xin</first><last>Wang</last></author>
      <author><first>Fang</first><last>Li</last></author>
      <author><first>Zhen</first><last>Xu</last></author>
      <author><first>Zhuoran</first><last>Wang</last></author>
      <author><first>Baoxun</first><last>Wang</last></author>
      <pages>1–10</pages>
      <url hash="723591e8">W17-6001</url>
      <abstract>For practical chatbots, one of the essential factor for improving <a href="https://en.wikipedia.org/wiki/User_experience">user experience</a> is the capability of customizing the talking style of the agents, that is, to make <a href="https://en.wikipedia.org/wiki/Chatbot">chatbots</a> provide responses meeting users’ preference on language styles, topics, etc. To address this issue, this paper proposes to incorporate linguistic biases, which implicitly involved in the conversation corpora generated by human groups in the Social Network Services (SNS), into the encoder-decoder based response generator. By attaching a specially designed neural component to dynamically control the impact of linguistic biases in response generation, a Group Linguistic Bias Aware Neural Response Generation (GLBA-NRG) model is eventually presented. The experimental results on the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> from the Chinese SNS show that the proposed <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> outperforms the current response generating models by producing both meaningful and vivid responses with customized styles.</abstract>
      <bibkey>wang-etal-2017-group</bibkey>
    </paper>
    <paper id="2">
      <title>Neural Regularized Domain Adaptation for Chinese Word Segmentation<fixed-case>C</fixed-case>hinese Word Segmentation</title>
      <author><first>Zuyi</first><last>Bao</last></author>
      <author><first>Si</first><last>Li</last></author>
      <author><first>Weiran</first><last>Xu</last></author>
      <author><first>Sheng</first><last>Gao</last></author>
      <pages>11–20</pages>
      <url hash="c768c9e1">W17-6002</url>
      <abstract>For Chinese word segmentation, the large-scale annotated corpora mainly focus on <a href="https://en.wikipedia.org/wiki/News_agency">newswire</a> and only a handful of annotated data is available in other domains such as <a href="https://en.wikipedia.org/wiki/Patent">patents</a> and <a href="https://en.wikipedia.org/wiki/Literature">literature</a>. Considering the limited amount of annotated target domain data, it is a challenge for segmenters to learn domain-specific information while avoid getting over-fitted at the same time. In this paper, we propose a neural regularized domain adaptation method for <a href="https://en.wikipedia.org/wiki/Chinese_word_segmentation">Chinese word segmentation</a>. The teacher networks trained in source domain are employed to regularize the training process of the student network by preserving the <a href="https://en.wikipedia.org/wiki/General_knowledge">general knowledge</a>. In the experiments, our neural regularized domain adaptation method achieves a better performance comparing to previous methods.</abstract>
      <bibkey>bao-etal-2017-neural</bibkey>
    </paper>
    <paper id="5">
      <title>Learning from Parenthetical Sentences for Term Translation in Machine Translation</title>
      <author><first>Guoping</first><last>Huang</last></author>
      <author><first>Jiajun</first><last>Zhang</last></author>
      <author><first>Yu</first><last>Zhou</last></author>
      <author><first>Chengqing</first><last>Zong</last></author>
      <pages>37–45</pages>
      <url hash="ce9469b4">W17-6005</url>
      <abstract>Terms extensively exist in specific domains, and term translation plays a critical role in domain-specific machine translation (MT) tasks. However, it’s a challenging task to translate them correctly for the huge number of pre-existing terms and the endless new terms. To achieve better term translation quality, it is necessary to inject external term knowledge into the underlying MT system. Fortunately, there are plenty of term translation knowledge in parenthetical sentences on the Internet. In this paper, we propose a simple, straightforward and effective <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> to improve term translation by learning from <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">parenthetical sentences</a>. This framework includes : (1) a focused web crawler ; (2) a parenthetical sentence filter, acquiring parenthetical sentences including bilingual term pairs ; (3) a term translation knowledge extractor, extracting bilingual term translation candidates ; (4) a probability learner, generating the term translation table for MT decoders. The extensive experiments demonstrate that our proposed <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> significantly improves the translation quality of terms and sentences.</abstract>
      <bibkey>huang-etal-2017-learning-parenthetical</bibkey>
    </paper>
  </volume>
  <volume id="62">
    <meta>
      <booktitle>Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms</booktitle>
      <url hash="4b4c1c80">W17-62</url>
      <editor><first>Marco</first><last>Kuhlmann</last></editor>
      <editor><first>Tatjana</first><last>Scheffler</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Umeå, Sweden</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="255f3d5c">W17-6200</url>
      <bibkey>ws-2017-international-tree</bibkey>
    </frontmatter>
    </volume>
  <volume id="63">
    <meta>
      <booktitle>Proceedings of the 15th International Conference on Parsing Technologies</booktitle>
      <url hash="df9fcac4">W17-63</url>
      <editor><first>Yusuke</first><last>Miyao</last></editor>
      <editor><first>Kenji</first><last>Sagae</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Pisa, Italy</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="24788c8f">W17-6300</url>
      <bibkey>ws-2017-international-parsing</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Automatically Acquired Lexical Knowledge Improves Japanese Joint Morphological and Dependency Analysis<fixed-case>J</fixed-case>apanese Joint Morphological and Dependency Analysis</title>
      <author><first>Daisuke</first><last>Kawahara</last></author>
      <author><first>Yuta</first><last>Hayashibe</last></author>
      <author><first>Hajime</first><last>Morita</last></author>
      <author><first>Sadao</first><last>Kurohashi</last></author>
      <pages>1–10</pages>
      <url hash="23464eb5">W17-6301</url>
      <abstract>This paper presents a joint model for morphological and dependency analysis based on automatically acquired lexical knowledge. This model takes advantage of rich lexical knowledge to simultaneously resolve <a href="https://en.wikipedia.org/wiki/Word_segmentation">word segmentation</a>, POS, and dependency ambiguities. In our experiments on <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese</a>, we show the effectiveness of our joint model over conventional pipeline models.</abstract>
      <bibkey>kawahara-etal-2017-automatically</bibkey>
    </paper>
    <paper id="2">
      <title>Dependency Language Models for Transition-based Dependency Parsing</title>
      <author><first>Juntao</first><last>Yu</last></author>
      <author><first>Bernd</first><last>Bohnet</last></author>
      <pages>11–17</pages>
      <url hash="f26105cb">W17-6302</url>
      <abstract>In this paper, we present an approach to improve the accuracy of a strong transition-based dependency parser by exploiting dependency language models that are extracted from a large parsed corpus. We integrated a small number of <a href="https://en.wikipedia.org/wiki/Software_feature">features</a> based on the dependency language models into the <a href="https://en.wikipedia.org/wiki/Parsing">parser</a>. To demonstrate the effectiveness of the proposed approach, we evaluate our <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> on standard English and Chinese data where the base parser could achieve competitive accuracy scores. Our enhanced <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> achieved state-of-the-art <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> on <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese data</a> and competitive results on <a href="https://en.wikipedia.org/wiki/English_language">English data</a>. We gained a large absolute improvement of one point (UAS) on <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a> and 0.5 points for <a href="https://en.wikipedia.org/wiki/English_language">English</a>.</abstract>
      <bibkey>yu-bohnet-2017-dependency</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="3">
      <title>Lexicalized vs. Delexicalized Parsing in Low-Resource Scenarios</title>
      <author><first>Agnieszka</first><last>Falenska</last></author>
      <author><first>Özlem</first><last>Çetinoğlu</last></author>
      <pages>18–24</pages>
      <url hash="52ce4cc3">W17-6303</url>
      <abstract>We present a systematic analysis of <a href="https://en.wikipedia.org/wiki/Lexicalization">lexicalized vs. delexicalized parsing</a> in low-resource scenarios, and propose a <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> to choose one method over another under certain conditions. We create a set of simulation experiments on 41 languages and apply our findings to 9 low-resource languages. Experimental results show that our <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> chooses the best approach in 8 out of 9 cases.</abstract>
      <bibkey>falenska-cetinoglu-2017-lexicalized</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="5">
      <title>Prepositional Phrase Attachment over Word Embedding Products</title>
      <author><first>Pranava Swaroop</first><last>Madhyastha</last></author>
      <author><first>Xavier</first><last>Carreras</last></author>
      <author><first>Ariadna</first><last>Quattoni</last></author>
      <pages>32–43</pages>
      <url hash="8784a888">W17-6305</url>
      <abstract>We present a low-rank multi-linear model for the task of solving prepositional phrase attachment ambiguity (PP task). Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> exploits tensor products of word embeddings, capturing all possible conjunctions of latent embeddings. Our results on a wide range of datasets and task settings show that <a href="https://en.wikipedia.org/wiki/Tensor_product">tensor products</a> are the best compositional operation and that a relatively simple multi-linear model that uses only word embeddings of lexical features can outperform more complex non-linear architectures that exploit the same information. Our proposed model gives the current best reported performance on an out-of-domain evaluation and performs competively on out-of-domain dependency parsing datasets.</abstract>
      <bibkey>madhyastha-etal-2017-prepositional</bibkey>
    </paper>
    <paper id="6">
      <title>L1-L2 Parallel Dependency Treebank as Learner Corpus<fixed-case>L</fixed-case>1-<fixed-case>L</fixed-case>2 Parallel Dependency Treebank as Learner Corpus</title>
      <author><first>John</first><last>Lee</last></author>
      <author><first>Keying</first><last>Li</last></author>
      <author><first>Herman</first><last>Leung</last></author>
      <pages>44–49</pages>
      <url hash="d119a0a7">W17-6306</url>
      <abstract>This opinion paper proposes the use of parallel treebank as learner corpus. We show how an L1-L2 parallel treebank   i.e., <a href="https://en.wikipedia.org/wiki/Parse_tree">parse trees</a> of non-native sentences, aligned to the <a href="https://en.wikipedia.org/wiki/Parse_tree">parse trees</a> of their target hypotheses   can facilitate retrieval of sentences with specific learner errors. We argue for its benefits, in terms of corpus re-use and interoperability, over a conventional learner corpus annotated with error tags. As a proof of concept, we conduct a case study on word-order errors made by learners of <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a> as a foreign language. We report <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">precision</a> and <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall</a> in retrieving a range of word-order error categories from L1-L2 tree pairs annotated in the Universal Dependency framework.</abstract>
      <bibkey>lee-etal-2017-l1</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="7">
      <title>Splitting Complex English Sentences<fixed-case>E</fixed-case>nglish Sentences</title>
      <author><first>John</first><last>Lee</last></author>
      <author><first>J. Buddhika K. Pathirage</first><last>Don</last></author>
      <pages>50–55</pages>
      <url hash="0107370a">W17-6307</url>
      <abstract>This paper applies parsing technology to the task of syntactic simplification of English sentences, focusing on the identification of text spans that can be removed from a complex sentence. We report the most comprehensive evaluation to-date on this task, using a dataset of sentences that exhibit simplification based on coordination, subordination, punctuation / parataxis, adjectival clauses, participial phrases, and appositive phrases. We train a <a href="https://en.wikipedia.org/wiki/Decision_tree">decision tree</a> with features derived from text span length, POS tags and dependency relations, and show that it significantly outperforms a parser-only baseline.</abstract>
      <bibkey>lee-don-2017-splitting</bibkey>
    </paper>
    <paper id="8">
      <title>Hierarchical Word Structure-based Parsing : A Feasibility Study on UD-style Dependency Parsing in <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese</a><fixed-case>UD</fixed-case>-style Dependency Parsing in <fixed-case>J</fixed-case>apanese</title>
      <author><first>Takaaki</first><last>Tanaka</last></author>
      <author><first>Katsuhiko</first><last>Hayashi</last></author>
      <author><first>Masaaki</first><last>Nagata</last></author>
      <pages>56–60</pages>
      <url hash="9b90dd7f">W17-6308</url>
      <abstract>In applying word-based dependency parsing such as Universal Dependencies (UD) to <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese</a>, the uncertainty of <a href="https://en.wikipedia.org/wiki/Word_segmentation">word segmentation</a> emerges for defining a word unit of the dependencies. We introduce the following hierarchical word structures to dependency parsing in <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese</a> : morphological units (a short unit word, SUW) and syntactic units (a long unit word, LUW). An SUW can be used to segment a sentence consistently, while it is too short to represent syntactic construction. An LUW is a unit including functional multiwords and LUW-based analysis facilitates the capturing of syntactic structure and makes <a href="https://en.wikipedia.org/wiki/Parsing">parsing</a> results more precise than SUW-based analysis. This paper describes the results of a feasibility study on the ability and the effectiveness of parsing methods based on hierarchical word structure (LUW chunking+parsing) in comparison to single layer word structure (SUW parsing). We also show joint analysis of LUW-chunking and dependency parsing improves the performance of identifying predicate-argument structures, while there is not much difference between overall results of them. not much difference between overall results of them.</abstract>
      <bibkey>tanaka-etal-2017-hierarchical</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="9">
      <title>Leveraging Newswire Treebanks for Parsing Conversational Data with Argument Scrambling</title>
      <author><first>Riyaz A.</first><last>Bhat</last></author>
      <author><first>Irshad</first><last>Bhat</last></author>
      <author><first>Dipti</first><last>Sharma</last></author>
      <pages>61–66</pages>
      <url hash="e44604a6">W17-6309</url>
      <abstract>We investigate the problem of parsing conversational data of morphologically-rich languages such as <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a> where argument scrambling occurs frequently. We evaluate a state-of-the-art non-linear transition-based parsing system on a new dataset containing 506 dependency trees for sentences from Bollywood (Hindi) movie scripts and Twitter posts of Hindi monolingual speakers. We show that a <a href="https://en.wikipedia.org/wiki/Dependency_grammar">dependency parser</a> trained on a newswire treebank is strongly biased towards the <a href="https://en.wikipedia.org/wiki/Canonical_form">canonical structures</a> and degrades when applied to conversational data. Inspired by <a href="https://en.wikipedia.org/wiki/Transformational_grammar">Transformational Generative Grammar</a> (Chomsky, 1965), we mitigate the <a href="https://en.wikipedia.org/wiki/Sampling_bias">sampling bias</a> by generating all theoretically possible alternative word orders of a clause from the existing (kernel) structures in the <a href="https://en.wikipedia.org/wiki/Treebank">treebank</a>. Training our <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> on canonical and transformed structures improves performance on conversational data by around 9 % LAS over the baseline newswire parser.</abstract>
      <bibkey>bhat-etal-2017-leveraging</bibkey>
    </paper>
    <paper id="10">
      <title>Using <a href="https://en.wikipedia.org/wiki/Hyperlink">hyperlinks</a> to improve multilingual partial parsers</title>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>67–71</pages>
      <url hash="b2cbce94">W17-6310</url>
      <abstract>Syntactic annotation is costly and not available for the vast majority of the world’s languages. We show that sometimes we can do away with less labeled data by exploiting more readily available forms of <a href="https://en.wikipedia.org/wiki/Markup_language">mark-up</a>. Specifically, we revisit an idea from Valentin Spitkovsky’s work (2010), namely that <a href="https://en.wikipedia.org/wiki/Hyperlink">hyperlinks</a> typically bracket syntactic constituents or chunks. We strengthen his results by showing that not only can <a href="https://en.wikipedia.org/wiki/Hyperlink">hyperlinks</a> help in low resource scenarios, exemplified here by Quechua, but learning from <a href="https://en.wikipedia.org/wiki/Hyperlink">hyperlinks</a> can also improve state-of-the-art NLP models for English newswire. We also present out-of-domain evaluation on English Ontonotes 4.0.</abstract>
      <bibkey>sogaard-2017-using</bibkey>
      <pwccode url="https://bitbucket.org/soegaard/hyperlink-iwpt17" additional="false">soegaard/hyperlink-iwpt17</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="11">
      <title>Correcting prepositional phrase attachments using multimodal corpora</title>
      <author><first>Sebastien</first><last>Delecraz</last></author>
      <author><first>Alexis</first><last>Nasr</last></author>
      <author><first>Frederic</first><last>Bechet</last></author>
      <author><first>Benoit</first><last>Favre</last></author>
      <pages>72–77</pages>
      <url hash="35ad76e0">W17-6311</url>
      <abstract>PP-attachments are an important source of errors in parsing <a href="https://en.wikipedia.org/wiki/Natural_language">natural language</a>. We propose in this article to use data coming from a multimodal corpus, combining textual, visual and conceptual information, as well as a correction strategy, to propose alternative attachments in the output of a <a href="https://en.wikipedia.org/wiki/Parsing">parser</a>.</abstract>
      <bibkey>delecraz-etal-2017-correcting</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/flickr30k">Flickr30k</pwcdataset>
    </paper>
    <paper id="12">
      <title>Exploiting Structure in <a href="https://en.wikipedia.org/wiki/Parsing">Parsing</a> to 1-Endpoint-Crossing Graphs</title>
      <author><first>Robin</first><last>Kurtz</last></author>
      <author><first>Marco</first><last>Kuhlmann</last></author>
      <pages>78–87</pages>
      <url hash="1e512ce1">W17-6312</url>
      <abstract>Deep dependency parsing can be cast as the search for maximum acyclic subgraphs in weighted digraphs. Because this search problem is intractable in the general case, we consider its restriction to the class of 1-endpoint-crossing (1ec) graphs, which has high coverage on standard data sets. Our main contribution is a characterization of 1ec graphs as a subclass of the <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graphs</a> with pagenumber at most 3. Building on this we show how to extend an existing <a href="https://en.wikipedia.org/wiki/Parsing">parsing algorithm</a> for 1-endpoint-crossing trees to the full class. While the <a href="https://en.wikipedia.org/wiki/Time_complexity">runtime complexity</a> of the extended <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> is polynomial in the length of the input sentence, it features a large constant, which poses a challenge for practical implementations.</abstract>
      <bibkey>kurtz-kuhlmann-2017-exploiting</bibkey>
    </paper>
    <paper id="13">
      <title>Effective Online Reordering with Arc-Eager Transitions</title>
      <author><first>Ryosuke</first><last>Kohita</last></author>
      <author><first>Hiroshi</first><last>Noji</last></author>
      <author><first>Yuji</first><last>Matsumoto</last></author>
      <pages>88–98</pages>
      <url hash="f6f6895d">W17-6313</url>
      <abstract>We present a new <a href="https://en.wikipedia.org/wiki/Transition_system">transition system</a> with word reordering for unrestricted non-projective dependency parsing. Our system is based on decomposed arc-eager rather than arc-standard, which allows more flexible ambiguity resolution between a local projective and non-local crossing attachment. In our experiment on Universal Dependencies 2.0, we find our <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> outperforms the ordinary swap-based parser particularly on languages with a large amount of non-projectivity.</abstract>
      <bibkey>kohita-etal-2017-effective</bibkey>
    </paper>
    <paper id="14">
      <title>Arc-Hybrid Non-Projective Dependency Parsing with a Static-Dynamic Oracle</title>
      <author><first>Miryam</first><last>de Lhoneux</last></author>
      <author><first>Sara</first><last>Stymne</last></author>
      <author><first>Joakim</first><last>Nivre</last></author>
      <pages>99–104</pages>
      <url hash="cdcdbfd3">W17-6314</url>
      <abstract>In this paper, we extend the arc-hybrid system for transition-based parsing with a swap transition that enables reordering of the words and construction of non-projective trees. Although this extension breaks the arc-decomposability of the transition system, we show how the existing dynamic oracle for this <a href="https://en.wikipedia.org/wiki/System">system</a> can be modified and combined with a static oracle only for the swap transition. Experiments on 5 languages show that the new <a href="https://en.wikipedia.org/wiki/System">system</a> gives competitive accuracy and is significantly better than a <a href="https://en.wikipedia.org/wiki/System">system</a> trained with a purely static oracle.</abstract>
      <attachment type="presentation" hash="8a33edae">W17-6314.Presentation.pdf</attachment>
      <bibkey>de-lhoneux-etal-2017-arc</bibkey>
      <revision id="1" href="W17-6314v1" hash="0d8de8ec" />
      <revision id="2" href="W17-6314v2" hash="cdcdbfd3" date="2022-02-11">Added missing acknowledgment.</revision>
      <pwccode url="https://github.com/UppsalaNLP/uuparser" additional="false">UppsalaNLP/uuparser</pwccode>
    </paper>
    <paper id="15">
      <title>Encoder-Decoder Shift-Reduce Syntactic Parsing</title>
      <author><first>Jiangming</first><last>Liu</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <pages>105–114</pages>
      <url hash="533746b4">W17-6315</url>
      <abstract>Encoder-decoder neural networks have been used for many <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP tasks</a>, such as <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a>. They have also been applied to constituent parsing by using bracketed tree structures as a target language, translating input sentences into syntactic trees. A more commonly used method to linearize syntactic trees is the shift-reduce system, which uses a sequence of transition-actions to build <a href="https://en.wikipedia.org/wiki/Tree_(data_structure)">trees</a>. We empirically investigate the effectiveness of applying the encoder-decoder network to transition-based parsing. On standard benchmarks, our system gives comparable results to the stack LSTM parser for dependency parsing, and significantly better results compared to the aforementioned <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> for constituent parsing, which uses bracketed tree formats.</abstract>
      <bibkey>liu-zhang-2017-encoder</bibkey>
      <pwccode url="https://github.com/LeonCrashCode/Encoder-Decoder-Parser" additional="false">LeonCrashCode/Encoder-Decoder-Parser</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="18">
      <title>Evaluating LSTM models for grammatical function labelling<fixed-case>LSTM</fixed-case> models for grammatical function labelling</title>
      <author><first>Bich-Ngoc</first><last>Do</last></author>
      <author><first>Ines</first><last>Rehbein</last></author>
      <pages>128–133</pages>
      <url hash="533d98d9">W17-6318</url>
      <abstract>To improve grammatical function labelling for <a href="https://en.wikipedia.org/wiki/German_language">German</a>, we augment the labelling component of a neural dependency parser with a decision history. We present different ways to encode the history, using different LSTM architectures, and show that our models yield significant improvements, resulting in a LAS for <a href="https://en.wikipedia.org/wiki/German_language">German</a> that is close to the best result from the SPMRL 2014 shared task (without the reranker).</abstract>
      <bibkey>do-rehbein-2017-evaluating</bibkey>
    </paper>
  </volume>
  <volume id="65">
    <meta>
      <booktitle>Proceedings of the Fourth International Conference on Dependency Linguistics (Depling 2017)</booktitle>
      <url hash="394e5eae">W17-65</url>
      <editor><first>Simonetta</first><last>Montemagni</last></editor>
      <editor><first>Joakim</first><last>Nivre</last></editor>
      <publisher>Linköping University Electronic Press</publisher>
      <address>Pisa,Italy</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="85bed991">W17-6500</url>
      <bibkey>ws-2017-international-dependency</bibkey>
    </frontmatter>
    </volume>
  <volume id="66">
    <meta>
      <booktitle>Proceedings of the 11th <fixed-case>B</fixed-case>razilian Symposium in Information and Human Language Technology</booktitle>
      <url hash="0008f51a">W17-66</url>
      <editor><first>Gustavo Henrique</first><last>Paetzold</last></editor>
      <editor><first>Vládia</first><last>Pinheiro</last></editor>
      <publisher>Sociedade Brasileira de Computação</publisher>
      <address>Uberlândia, Brazil</address>
      <month>October</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="4bda168d">W17-6600</url>
      <bibkey>ws-2017-brazilian</bibkey>
    </frontmatter>
    </volume>
  <volume id="68">
    <meta>
      <booktitle><fixed-case>IWCS</fixed-case> 2017 - 12th International Conference on Computational Semantics - Long papers</booktitle>
      <editor><first>Claire</first><last>Gardent</last></editor>
      <editor><first>Christian</first><last>Retoré</last></editor>
    </meta>
    <frontmatter>
      <url hash="9769d87e">W17-6800</url>
      <bibkey>ws-2017-iwcs</bibkey>
    </frontmatter>
    </volume>
  <volume id="69">
    <meta>
      <booktitle><fixed-case>IWCS</fixed-case> 2017 — 12th International Conference on Computational Semantics — Short papers</booktitle>
      <editor><first>Claire</first><last>Gardent</last></editor>
      <editor><first>Christian</first><last>Retoré</last></editor>
    </meta>
    <frontmatter>
      <url hash="d9c4922e">W17-6900</url>
      <bibkey>ws-2017-iwcs-2017</bibkey>
    </frontmatter>
    </volume>
  <volume id="70">
    <meta>
      <booktitle>Proceedings of Language, Ontology, Terminology and Knowledge Structures Workshop (<fixed-case>LOTKS</fixed-case> 2017)</booktitle>
      <editor><first>Francesca</first><last>Frontini</last></editor>
      <editor><first>Larisa</first><last>Grčić Simeunović</last></editor>
      <editor><first>Špela</first><last>Vintar</last></editor>
      <editor><first>Anas Fahad</first><last>Khan</last></editor>
      <editor><first>Artemis</first><last>Parvisi</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Montpellier, France</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="05d724da">W17-7000</url>
      <bibkey>ws-2017-language-ontology</bibkey>
    </frontmatter>
    </volume>
  <volume id="71">
    <meta>
      <booktitle>Proceedings of the <fixed-case>IWCS</fixed-case> workshop on Foundations of Situated and Multimodal Communication</booktitle>
      <editor><first>Nicholas</first><last>Asher</last></editor>
      <editor><first>Julie</first><last>Hunter</last></editor>
      <editor><first>Alex</first><last>Lascarides</last></editor>
    </meta>
    <frontmatter>
      <url hash="02997d1c">W17-7100</url>
      <bibkey>ws-2017-iwcs-foundations</bibkey>
    </frontmatter>
    </volume>
  <volume id="72">
    <meta>
      <booktitle>Proceedings of the Computing Natural Language Inference Workshop</booktitle>
    </meta>
    <frontmatter>
      <bibkey>ws-2017-computing</bibkey>
    </frontmatter>
    </volume>
  <volume id="73">
    <meta>
      <booktitle>Proceedings of the 2nd Workshop on Semantic Deep Learning (<fixed-case>S</fixed-case>em<fixed-case>D</fixed-case>eep-2)</booktitle>
      <editor><first>Dagmar</first><last>Gromann</last></editor>
      <editor><first>Thierry</first><last>Declerck</last></editor>
      <editor><first>Georg</first><last>Heigl</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Montpellier, France</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="ece9fd5b">W17-7300</url>
      <bibkey>ws-2017-semantic</bibkey>
    </frontmatter>
    </volume>
  <volume id="74">
    <meta>
      <booktitle>Proceedings of the 13th Joint <fixed-case>ISO</fixed-case>-<fixed-case>ACL</fixed-case> Workshop on Interoperable Semantic Annotation (<fixed-case>ISA</fixed-case>-13)</booktitle>
    </meta>
    <frontmatter>
      <url hash="21e8f1d4">W17-7400</url>
      <bibkey>ws-2017-joint-iso</bibkey>
    </frontmatter>
    </volume>
  <volume id="75">
    <meta>
      <booktitle>Proceedings of the 14th International Conference on Natural Language Processing (<fixed-case>ICON</fixed-case>-2017)</booktitle>
      <editor><first>Sivaji</first><last>Bandyopadhyay</last></editor>
      <publisher>NLP Association of India</publisher>
      <address>Kolkata, India</address>
      <month>December</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="86396239">W17-7500</url>
      <bibkey>ws-2017-international-natural-language</bibkey>
    </frontmatter>
    </volume>
  <volume id="76">
    <meta>
      <booktitle>Proceedings of the 16th International Workshop on Treebanks and Linguistic Theories</booktitle>
      <url hash="941f7505">W17-76</url>
      <editor><first>Jan</first><last>Hajič</last></editor>
      <address>Prague, Czech Republic</address>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="e8061d6c">W17-7600</url>
      <bibkey>ws-2017-international-treebanks</bibkey>
    </frontmatter>
    </volume>
  <volume id="77">
    <meta>
      <booktitle>Proceedings of the 1st Workshop on Natural Language Processing and Information Retrieval associated with <fixed-case>RANLP</fixed-case> 2017</booktitle>
      <editor><first>Mireille</first><last>Makary</last></editor>
      <editor><first>Michael</first><last>Oakes</last></editor>
      <publisher>INCOMA Inc.</publisher>
      <address>Varna, Bulgaria</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <doi>10.26615/978-954-452-038-0_</doi>
      <bibkey>ws-2017-natural-language</bibkey>
    </frontmatter>
    </volume>
  <volume id="78">
    <meta>
      <booktitle>Proceedings of the Workshop Knowledge Resources for the Socio-Economic Sciences and Humanities associated with <fixed-case>RANLP</fixed-case> 2017</booktitle>
      <editor><first>Kalliopi</first><last>Zervanou</last></editor>
      <editor><first>Petya</first><last>Osenova</last></editor>
      <editor><first>Eveline</first><last>Wandl-Vogt</last></editor>
      <editor><first>Dan</first><last>Cristea</last></editor>
      <publisher>INCOMA Inc.</publisher>
      <address>Varna</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <doi>10.26615/978-954-452-040-3_</doi>
      <bibkey>ws-2017-knowledge</bibkey>
    </frontmatter>
    </volume>
  <volume id="79">
    <meta>
      <booktitle>Proceedings of the Workshop Human-Informed Translation and Interpreting Technology</booktitle>
      <editor><first>Irina</first><last>Temnikova</last></editor>
      <editor><first>Constantin</first><last>Orasan</last></editor>
      <editor><first>Gloria Corpas</first><last>Pastor</last></editor>
      <editor><first>Stephan</first><last>Vogel</last></editor>
      <publisher>Association for Computational Linguistics, Shoumen, Bulgaria</publisher>
      <address>Varna, Bulgaria</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <doi>10.26615/978-954-452-042-7_</doi>
      <bibkey>ws-2017-human</bibkey>
    </frontmatter>
    </volume>
  <volume id="80">
    <meta>
      <booktitle>Proceedings of the Biomedical <fixed-case>NLP</fixed-case> Workshop associated with <fixed-case>RANLP</fixed-case> 2017</booktitle>
      <editor><first>Svetla</first><last>Boytcheva</last></editor>
      <editor><first>Kevin Bretonnel</first><last>Cohen</last></editor>
      <editor><first>Guergana</first><last>Savova</last></editor>
      <editor><first>Galia</first><last>Angelova</last></editor>
      <publisher>INCOMA Ltd.</publisher>
      <address>Varna, Bulgaria</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <doi>10.26615/978-954-452-044-1_</doi>
      <bibkey>ws-2017-biomedical</bibkey>
    </frontmatter>
    </volume>
  <volume id="81">
    <meta>
      <booktitle>Proceedings of the First Workshop on Language technology for Digital Humanities in Central and (South-)Eastern <fixed-case>E</fixed-case>urope</booktitle>
      <editor><first>Anca</first><last>Dinu</last></editor>
      <editor><first>Petya</first><last>Osenova</last></editor>
      <editor><first>Cristina</first><last>Vertan</last></editor>
      <publisher>INCOMA Inc.</publisher>
      <address>Varna</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <doi>0.26615/978-954-452-046-5_</doi>
      <bibkey>ws-2017-language-technology</bibkey>
    </frontmatter>
    </volume>
</collection>