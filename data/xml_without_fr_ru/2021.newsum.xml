<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.newsum">
  <volume id="1" ingest-date="2021-10-28">
    <meta>
      <booktitle>Proceedings of the Third Workshop on New Frontiers in Summarization</booktitle>
      <editor><first>Giuseppe</first><last>Carenini</last></editor>
      <editor><first>Jackie Chi Kit</first><last>Cheung</last></editor>
      <editor><first>Yue</first><last>Dong</last></editor>
      <editor id="fei-liu-utdallas"><first>Fei</first><last>Liu</last></editor>
      <editor><first>Lu</first><last>Wang</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online and in Dominican Republic</address>
      <month>November</month>
      <year>2021</year>
    </meta>
    <frontmatter>
      <url hash="50975032">2021.newsum-1.0</url>
      <bibkey>newsum-2021-new</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Sentence-level Planning for Especially Abstractive Summarization</title>
      <author><first>Andreas</first><last>Marfurt</last></author>
      <author><first>James</first><last>Henderson</last></author>
      <pages>1–14</pages>
      <abstract>Abstractive summarization models heavily rely on copy mechanisms, such as the pointer network or <a href="https://en.wikipedia.org/wiki/Attention">attention</a>, to achieve good performance, measured by textual overlap with reference summaries. As a result, the generated summaries stay close to the formulations in the source document. We propose the * sentence planner * model to generate more abstractive summaries. It includes a hierarchical decoder that first generates a <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">representation</a> for the next summary sentence, and then conditions the word generator on this <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">representation</a>. Our generated summaries are more abstractive and at the same time achieve high ROUGE scores when compared to human reference summaries. We verify the effectiveness of our design decisions with extensive evaluations.</abstract>
      <url hash="6c478295">2021.newsum-1.1</url>
      <bibkey>marfurt-henderson-2021-sentence</bibkey>
      <doi>10.18653/v1/2021.newsum-1.1</doi>
      <pwccode url="https://github.com/idiap/sentence-planner" additional="false">idiap/sentence-planner</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
    </paper>
    <paper id="2">
      <title>Template-aware Attention Model for Earnings Call Report Generation</title>
      <author><first>Yangchen</first><last>Huang</last></author>
      <author><first>Prashant K.</first><last>Dhingra</last></author>
      <author><first>Seyed Danial</first><last>Mohseni Taheri</last></author>
      <pages>15–24</pages>
      <abstract>Earning calls are among important resources for investors and analysts for updating their price targets. Firms usually publish corresponding transcripts soon after earnings events. However, raw transcripts are often too long and miss the coherent structure. To enhance the clarity, analysts write well-structured reports for some important earnings call events by analyzing them, requiring time and effort. In this paper, we propose TATSum (Template-Aware aTtention model for Summarization), a generalized neural summarization approach for structured report generation, and evaluate its performance in the earnings call domain. We build a large corpus with thousands of transcripts and reports using historical earnings events. We first generate a candidate set of reports from the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> as potential soft templates which do not impose actual rules on the output. Then, we employ an encoder model with margin-ranking loss to rank the candidate set and select the best quality template. Finally, the transcript and the selected soft template are used as input in a seq2seq framework for report generation. Empirical results on the earnings call dataset show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> significantly outperforms state-of-the-art models in terms of informativeness and structure.</abstract>
      <url hash="7a331d05">2021.newsum-1.2</url>
      <bibkey>huang-etal-2021-template</bibkey>
      <doi>10.18653/v1/2021.newsum-1.2</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
    </paper>
    <paper id="6">
      <title>Evaluation of Summarization Systems across Gender, Age, and Race</title>
      <author><first>Anna</first><last>Jørgensen</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>51–56</pages>
      <abstract>Summarization systems are ultimately evaluated by human annotators and raters. Usually, annotators and raters do not reflect the demographics of end users, but are recruited through student populations or crowdsourcing platforms with skewed demographics. For two different evaluation scenarios   evaluation against gold summaries and system output ratings   we show that summary evaluation is sensitive to protected attributes. This can severely bias system development and evaluation, leading us to build models that cater for some groups rather than others.</abstract>
      <url hash="29131b06">2021.newsum-1.6</url>
      <bibkey>jorgensen-sogaard-2021-evaluation</bibkey>
      <doi>10.18653/v1/2021.newsum-1.6</doi>
    </paper>
    <paper id="8">
      <title>Capturing Speaker Incorrectness : Speaker-Focused Post-Correction for Abstractive Dialogue Summarization</title>
      <author><first>Dongyub</first><last>Lee</last></author>
      <author><first>Jungwoo</first><last>Lim</last></author>
      <author><first>Taesun</first><last>Whang</last></author>
      <author><first>Chanhee</first><last>Lee</last></author>
      <author><first>Seungwoo</first><last>Cho</last></author>
      <author><first>Mingun</first><last>Park</last></author>
      <author><first>Heuiseok</first><last>Lim</last></author>
      <pages>65–73</pages>
      <abstract>In this paper, we focus on improving the quality of the summary generated by neural abstractive dialogue summarization systems. Even though pre-trained language models generate well-constructed and promising results, it is still challenging to summarize the conversation of multiple participants since the summary should include a description of the overall situation and the actions of each speaker. This paper proposes self-supervised strategies for speaker-focused post-correction in abstractive dialogue summarization. Specifically, our model first discriminates which type of speaker correction is required in a draft summary and then generates a revised summary according to the required type. Experimental results show that our proposed method adequately corrects the draft summaries, and the revised summaries are significantly improved in both quantitative and qualitative evaluations.</abstract>
      <url hash="72e1d5f4">2021.newsum-1.8</url>
      <bibkey>lee-etal-2021-capturing</bibkey>
      <doi>10.18653/v1/2021.newsum-1.8</doi>
    <title_ar>التقاط عدم صحة المتحدث: التصحيح اللاحق الذي يركز على المتحدث من أجل تلخيص الحوار التجريدي</title_ar>
      <title_pt>Capturando a Incorreção do Falante: Pós-Correção Focada no Falante para Resumo do Diálogo Abstrativo</title_pt>
      <title_es>Capturar la incorrección del orador: corrección posterior centrada en el orador para el resumen de diálogos abstractivos</title_es>
      <title_ja>スピーカーの不正確さの把握：抽象的な対話の要約のためのスピーカーに焦点を当てた事後修正</title_ja>
      <title_zh>捕言人误:以言者为心后校正,用象对总结</title_zh>
      <title_hi>कैप्चरिंग स्पीकर अशुद्धता: अमूर्त संवाद सारांशीकरण के लिए स्पीकर-केंद्रित पोस्ट-सुधार</title_hi>
      <title_ga>Easpa Cainteoir a Ghabháil: Iarcheartú Dírithe ar an gCainteoir le haghaidh Achoimre ar Idirphlé Teibí</title_ga>
      <title_it>Cattura Errore dell'altoparlante: Post-correzione focalizzata sull'altoparlante per la sintesi del dialogo astratto</title_it>
      <title_el>Καταγραφή της λανθασμένης ομιλίας: Μεταδιόρθωση εστιασμένη στον ομιλητή για αφηρημένη περίληψη διαλόγου</title_el>
      <title_kk>Диалог тізімін түсіру дұрыс: Абстрактивті диалогтың тұжырымдамасының сәйкес түзетуі</title_kk>
      <title_hu>Hangszóró helytelen rögzítése: Hangszóróközpontú utókorrekció az absztrakt párbeszéd összefoglalásához</title_hu>
      <title_lt>Kalbėtojo sugavimas klaidingas: kalbėtojui skirta korekcija po abstrakcinio dialogo santraukos</title_lt>
      <title_ms>Menangkap Salah Penutur: Pembetulan Setelah Fokus Penutur untuk Penapisan Dialog Abstraktif</title_ms>
      <title_ml>സംസാരിക്കുന്നവനെ പിടിച്ചുവെക്കുന്നതില്‍ തെറ്റാണ്: അബ്ട്രാക്ടിക്ടീവ് ഡയലോഗിന്റെ സുമാറ്റം</title_ml>
      <title_mk>Грешка на говорникот: По-корекција фокусирана на говорникот за апстрактивен дијалог</title_mk>
      <title_ka>სტრიქტრების შეცდომა: სტრიქტრების შეცდომა დასწორება აბსტრაქტიგური დიალოგის საზოგადომიზაციისთვის</title_ka>
      <title_mn>Дууслагчийн буруу байдлыг барьж байна: Дууслагчийн хэвлэл дээр хэвлэлийн дараа засах</title_mn>
      <title_ro>Capturarea incorectății difuzorului: Post-corectare axată pe difuzor pentru rezumarea dialogului abstract</title_ro>
      <title_mt>Il-Qbid tal-Irkorrettezza tal-kelliem: Post-Korrezzjoni ffukata fuq il-kelliem għas-Sommarju tad-Djalogu Abstrattiv</title_mt>
      <title_sr>Uhvaćenje nepravednosti govornika: Predsjednika-fokusirana nakon korekcije za sažetak abstraktivnog dijaloga</title_sr>
      <title_si>ස්පීකර් වැරැද්දත්: ස්පීකර්- ස්පීකර්- ස්පීකර්- ස්පීක්ස් පොස්ට- සුදුසුම් සඳහා සංවාද සංවාදය</title_si>
      <title_no>Feil ved henting av taler: Uttaler- fokusert post- korreksjon for samandrag av abstraktiv dialogvindauge</title_no>
      <title_pl>Przechwytywanie niepoprawności głośnika: korekcja po skorygowaniu głośnika w celu abstrakcyjnego podsumowania dialogu</title_pl>
      <title_so>Dhaqso: Speaker-Focused Post-Correction for Abstractive Dialog Summarization</title_so>
      <title_ta>பேச்சாளர் சரியை பிடித்துக் கொள்வது: சுருக்கம் செய்வதற்கான பேச்சாளர் பின் திருத்தம்</title_ta>
      <title_ur>سپیکر غلطی کاپیٹ کرتا ہے: سپیکر-فوکس-فوکس پوس-اصلاح کے لئے بغلطی ڈالیلوگ جمع کرنا</title_ur>
      <title_sv>Fånga högtalarfel: Högtalarfokuserad efterkorrigering för sammanfattning av abstrakta dialoger</title_sv>
      <title_uz>Name</title_uz>
      <title_vi>Nhận lỗi của người chủ tịch:</title_vi>
      <title_bg>Заснемане на неправилността на говорителя: Фокусирана към говорителя следкорекция за обобщаване на абстрактния диалог</title_bg>
      <title_nl>Onjuiste spreker vastleggen: op spreker gerichte post-correctie voor abstracte dialoogsamenvatting</title_nl>
      <title_hr>Uhvaćenje nepravednosti govornika: Predsjednika-fokusirana nakon isprave za sažetak abstraktivnog dijaloga</title_hr>
      <title_da>Optagelse af højttaler ukorrekt: Højttalerfokuseret efterkorrektion til opsummering af abstrakt dialog</title_da>
      <title_de>Sprecherfehler erfassen: Sprecherfokussierte Nachkorrektur für abstrakte Dialogezusammenfassung</title_de>
      <title_ko>말하는 사람의 오류 포착: 말하는 사람을 중심으로 하는 추상적인 대화 요약 후 바로잡기</title_ko>
      <title_fa>دریافت اشتباهی صحبت‌کننده: تعمیر بعد از اصلاح سخنرانی برای جمع کردن محاورۀ محاورۀ مصاحبه</title_fa>
      <title_id>Menangkap Gagal Pembicara: Pembetulan Setelah Fokus Pembicara untuk Penapisan Dialog Abstraktif</title_id>
      <title_sw>Msemaji wa Kuzungumza: Mfumo wa Uharibifu wa Mazungumzo ya Uzungumzaji</title_sw>
      <title_tr>Gürjüçin ýalňyşlyg metini görkez: sözler-fokuslanýan soňra düzenleme</title_tr>
      <title_af>Opneem Speaker Verkeerde: Speaker- Fokuseerde Poskorreksie vir Abstraktiewe Dialoog Opsomming</title_af>
      <title_sq>Duke kapur gabimin e zëdhënësit: Postkorrektimi i fokusuar nga zëdhënësi për përmbledhjen e dialogut abstraktiv</title_sq>
      <title_am>አዲስ ዶሴ ፍጠር</title_am>
      <title_hy>Capturing Speaker Incorrectness: Speaker-Focused Post-Correction for Abstractive Dialogue Summarization</title_hy>
      <title_az>S칬yl톛nicinin 톛dal톛ti yakalan캼r: S칬yl톛nici-F톛rqli Dialoog Q톛rql톛m톛si 칲칞칲n S칬yl톛nici-F톛rql톛ndiril톛n Sonra D칲z톛ltm톛</title_az>
      <title_bn>স্পেকারের সঠিকভাবে ক্যাপ্ট্রেটিভ ডায়ালগ সামারিজেশনের জন্য স্পেকার- ফোকাস-ফোকাসের পর সংশোধন</title_bn>
      <title_bs>Uhvaćenje nepravednosti govornika: Predsjednika-fokusirana nakon korekcije za sažetak abstraktivnog dijaloga</title_bs>
      <title_ca>Captura incorrecta del parlant: Post-correcció centrada en el parlant per a resumir el diàleg abstract</title_ca>
      <title_cs>Zachycení nesprávnosti mluvčího: Postkorekce zaměřená na mluvčího pro abstraktivní shrnutí dialogu</title_cs>
      <title_et>Kõneleja ebaõigsuse jäädvustamine: kõneleja keskendumine järelkorrektsioon kokkuvõtlikuks dialoogiks</title_et>
      <title_fi>Kaiuttimen virheettömyyden kaappaaminen: Kaiuttimen keskinäinen jälkikorjaus tiivistelmää varten</title_fi>
      <title_sk>Zajemanje nepravilnosti zvočnika: popravek, osredotočen na zvočnik, za povzetek pogovora</title_sk>
      <title_ha>@ action</title_ha>
      <title_he>תפיסת דיבור לא נכונה: תיקון לאחר תיקון מרוכז על דיבור</title_he>
      <title_bo>རྣམ་བརྗོད་པའི་སྐད་བརྡ་སྤྲོད་མི་དང་འགྱུར་བ: གཏོང་བྱེད་མཁན་གྱི་འཕྲིན་རིམ་གླེང་སྒྲོམ་Summarization</title_bo>
      <title_jv>politenessoffpolite"), and when there is a change ("assertivepoliteness</title_jv>
      <abstract_ar>في هذه الورقة ، نركز على تحسين جودة الملخص الناتج عن أنظمة تلخيص الحوار التجريدي العصبي. على الرغم من أن النماذج اللغوية المدربة مسبقًا تولد نتائج جيدة البناء وواعدة ، إلا أنه لا يزال من الصعب تلخيص محادثة العديد من المشاركين نظرًا لأن الملخص يجب أن يتضمن وصفًا للموقف العام وإجراءات كل متحدث. تقترح هذه الورقة استراتيجيات تخضع للإشراف الذاتي للتصحيح اللاحق الذي يركز على المتحدث في تلخيص الحوار التجريدي. على وجه التحديد ، يميز نموذجنا أولاً نوع تصحيح السماعات المطلوب في مسودة الملخص ثم يُنشئ ملخصًا منقحًا وفقًا للنوع المطلوب. تظهر النتائج التجريبية أن طريقتنا المقترحة تصحح بشكل كاف مسودات الملخصات ، وقد تم تحسين الملخصات المنقحة بشكل كبير في كل من التقييمات الكمية والنوعية.</abstract_ar>
      <abstract_pt>Neste artigo, nos concentramos em melhorar a qualidade do resumo gerado por sistemas de sumarização de diálogo abstrativo neural. Embora os modelos de linguagem pré-treinados gerem resultados bem construídos e promissores, ainda é um desafio resumir a conversa de vários participantes, pois o resumo deve incluir uma descrição da situação geral e das ações de cada falante. Este artigo propõe estratégias auto-supervisionadas para pós-correção focada no falante na sumarização de diálogos abstratos. Especificamente, nosso modelo primeiro discrimina qual tipo de correção de falante é necessária em um rascunho de resumo e, em seguida, gera um resumo revisado de acordo com o tipo necessário. Os resultados experimentais mostram que nosso método proposto corrige adequadamente os resumos preliminares, e os resumos revisados são significativamente melhorados em avaliações quantitativas e qualitativas.</abstract_pt>
      <abstract_es>En este artículo, nos centramos en mejorar la calidad del resumen generado por los sistemas de resumen de diálogo abstractivo neuronal. A pesar de que los modelos lingüísticos previamente entrenados generan resultados prometedores y bien construidos, sigue siendo difícil resumir la conversación de varios participantes, ya que el resumen debe incluir una descripción de la situación general y las acciones de cada orador. Este artículo propone estrategias autosupervisadas para la corrección posterior centrada en el orador en el resumen de diálogos abstractivos. Específicamente, nuestro modelo primero discrimina qué tipo de corrección del orador se requiere en un borrador de resumen y luego genera un resumen revisado de acuerdo con el tipo requerido. Los resultados experimentales muestran que nuestro método propuesto corrige adecuadamente los borradores de resúmenes, y que los resúmenes revisados mejoran significativamente en las evaluaciones cuantitativas y cualitativas.</abstract_es>
      <abstract_hi>इस पेपर में, हम तंत्रिका अमूर्त संवाद सारांशीकरण प्रणालियों द्वारा उत्पन्न सारांश की गुणवत्ता में सुधार करने पर ध्यान केंद्रित करते हैं। भले ही पूर्व-प्रशिक्षित भाषा मॉडल अच्छी तरह से निर्मित और आशाजनक परिणाम उत्पन्न करते हैं, फिर भी कई प्रतिभागियों की बातचीत को संक्षेप में प्रस्तुत करना चुनौतीपूर्ण है क्योंकि सारांश में समग्र स्थिति और प्रत्येक वक्ता के कार्यों का विवरण शामिल होना चाहिए। यह पेपर अमूर्त संवाद सारांशीकरण में स्पीकर-केंद्रित पोस्ट-सुधार के लिए आत्म-पर्यवेक्षित रणनीतियों का प्रस्ताव करता है। विशेष रूप से, हमारा मॉडल पहले भेदभाव करता है कि ड्राफ्ट सारांश में किस प्रकार के स्पीकर सुधार की आवश्यकता होती है और फिर आवश्यक प्रकार के अनुसार एक संशोधित सारांश उत्पन्न करता है। प्रयोगात्मक परिणामों से पता चलता है कि हमारी प्रस्तावित विधि पर्याप्त रूप से मसौदा सारांश को सही करती है, और संशोधित सारांश मात्रात्मक और गुणात्मक मूल्यांकन दोनों में काफी सुधार हुए हैं।</abstract_hi>
      <abstract_zh>本文者,专注于崇神经抽象摘要系统生成之摘要也。 虽预训之言,形有所欲,而数参与者之对犹有挑战性,摘要有一体之事,与言者之言也。 本文发抽象对话总结中以言者为心矫自监督策略。 先于摘要草之中,别于言者,然后因其成摘要。 实验结果表明者,所以极正于摘要草案也;所以尽正于定者摘要所以显于定定性也。</abstract_zh>
      <abstract_ja>本稿では、抽象的なニューラルダイアログサマリゼーションシステムによって生成されるサマリの質の向上に焦点を当てる。事前にトレーニングされた言語モデルは、十分に構築された有望な結果を生み出すが、要約には全体的な状況と各スピーカーの行動の説明が含まれているはずであるため、複数の参加者の会話を要約することは依然として困難である。本稿では，抽象的な対話の要約におけるスピーカー重視の事後補正のための自主管理戦略を提案する．具体的には、我々のモデルはまず、ドラフトサマリーでどのタイプのスピーカー補正が必要かを区別し、次に必要なタイプに応じて修正されたサマリーを生成します。実験結果は、提案された方法がドラフトサマリーを適切に修正し、改訂されたサマリーは定量的評価と定性的評価の両方で大幅に改善されていることを示している。</abstract_ja>
      <abstract_ga>Sa pháipéar seo, dírímid ar fheabhas a chur ar cháilíocht na hachoimre a ghineann córais achomair idirphlé teibí néaracha. Cé go ngineann samhlacha teanga réamh-oilte torthaí dea-thógtha agus gealltanais, tá sé fós dúshlánach achoimre a dhéanamh ar chomhrá na n-il-rannpháirtithe mar ba chóir go mbeadh cur síos san achoimre ar chás iomlán agus ar ghníomhaíochtaí gach cainteora. Molann an páipéar seo straitéisí féin-mhaoirsithe maidir le hiarcheartú cainteoir-dhírithe in achoimriú idirphlé teibí. Go sonrach, déanann ár múnla idirdhealú ar dtús cén cineál ceartúcháin cainteora a theastaíonn i ndréacht-achoimre agus ansin gineann sé achoimre athbhreithnithe de réir an chineáil riachtanach. Léiríonn torthaí turgnamhacha go gceartaíonn ár modh molta na dréacht-achoimrí go leordhóthanach, agus go bhfuil feabhas suntasach tagtha ar na hachoimrí athbhreithnithe i meastóireachtaí cainníochtúla agus cáilíochtúla araon.</abstract_ga>
      <abstract_hu>Jelen tanulmányban a neurális absztraktív párbeszéd összefoglaló rendszerek által generált összefoglaló minőségének javítására összpontosítunk. Annak ellenére, hogy az előképzett nyelvi modellek jól felépített és ígéretes eredményeket eredményeznek, még mindig kihívást jelent több résztvevő beszélgetésének összefoglalása, mivel az összefoglalónak tartalmaznia kell az általános helyzetet és az egyes előadók tevékenységét. Ez a tanulmány önfelügyelt stratégiákat javasol az előadófókuszú posztkorrekcióhoz az absztrakt párbeszéd összefoglalásában. Konkrétan modellünk először megkülönbözteti, hogy milyen típusú hangszórójavításra van szükség az összefoglaló tervezetében, majd a szükséges típusnak megfelelően módosított összefoglalót generál. Kísérleti eredmények azt mutatják, hogy javasolt módszerünk megfelelően korrigálja az összefoglalótervezeteket, és a felülvizsgált összefoglalók jelentősen javulnak mind a mennyiségi, mind a minőségi értékelésekben.</abstract_hu>
      <abstract_it>In questo articolo, ci concentriamo sul miglioramento della qualità del riassunto generato dai sistemi neurali di sintesi del dialogo astratto. Anche se modelli linguistici pre-formati generano risultati ben costruiti e promettenti, è ancora difficile riassumere la conversazione di più partecipanti poiché il riassunto dovrebbe includere una descrizione della situazione generale e delle azioni di ogni oratore. Questo articolo propone strategie auto-supervisionate per la post-correzione focalizzata sugli speaker nella sintesi astratta del dialogo. Nello specifico, il nostro modello prima discrimina il tipo di correzione dell'altoparlante richiesto in una bozza di riepilogo e poi genera un riepilogo rivisto in base al tipo richiesto. I risultati sperimentali dimostrano che il metodo proposto corregge adeguatamente i progetti di sintesi e che i riassunti rivisti sono notevolmente migliorati sia nelle valutazioni quantitative che qualitative.</abstract_it>
      <abstract_el>Στην παρούσα εργασία εστιάζουμε στη βελτίωση της ποιότητας της σύνοψης που δημιουργείται από συστήματα σύνοψης νευρικών αφηρημένων διαλόγων. Παρόλο που τα προ-εκπαιδευμένα γλωσσικά μοντέλα παράγουν καλά δομημένα και ελπιδοφόρα αποτελέσματα, εξακολουθεί να είναι δύσκολο να συνοψίσουμε τη συζήτηση πολλών συμμετεχόντων δεδομένου ότι η περίληψη θα πρέπει να περιλαμβάνει μια περιγραφή της συνολικής κατάστασης και των ενεργειών του κάθε ομιλητή. Η παρούσα εργασία προτείνει αυτοεποπτικές στρατηγικές για τη μετα-διόρθωση με επίκεντρο ομιλητή στην αφηρημένη περίληψη διαλόγου. Συγκεκριμένα, το μοντέλο μας διακρίνει πρώτα ποιος τύπος διόρθωσης ομιλητή απαιτείται σε ένα προσχέδιο σύνοψης και στη συνέχεια δημιουργεί μια αναθεωρημένη σύνοψη σύμφωνα με τον απαιτούμενο τύπο. Τα πειραματικά αποτελέσματα δείχνουν ότι η προτεινόμενη μέθοδος διορθώνει επαρκώς τα προσχέδια περιλήψεων, ενώ οι αναθεωρημένες περιλήψεις βελτιώνονται σημαντικά τόσο σε ποσοτικές όσο και σε ποιοτικές αξιολογήσεις.</abstract_el>
      <abstract_lt>Šiame dokumente daugiausia dėmesio skiriame santraukos kokybės gerinimui, kurį sukuria neurologinio abstrakcinio dialogo santraukų sistemos. Nors iš anksto parengti kalbų modeliai duoda gerai sukurtų ir žadančių rezultatų, vis dar sunku apibendrinti daugelio dalyvių pokalbį, nes santraukoje turėtų būti aprašyta bendra padėtis ir kiekvieno kalbėtojo veiksmai. Šiame dokumente siūlomos savarankiškai prižiūrimos strategijos, skirtos kalbėtojams po korekcijos abstraktyvio dialogo santraukoje. Konkrečiai, mūsų model is pirmiausia diskriminuoja, kokio tipo kalbėtojo pataisymą reikia santraukos projekte, o vėliau sukuria pataisytą santrauką pagal reikiamą tipą. Eksperimentiniai rezultatai rodo, kad mūsų siūlomas metodas tinkamai koreguoja santraukų projektus, o peržiūrėtos santraukos gerokai patobulinamos tiek kiekybiniuose, tiek kokybiniuose vertinimuose.</abstract_lt>
      <abstract_ka>ამ დოკუნეში, ჩვენ კონუტურებთ ნეიროლური აბსტრაქტიგური დიალოგის სისტემის გამოსახულების კონუტურაციის კონუტურაციაზე. მაგრამ საუკეთესო ენის მოდელები უკეთესოდ კონფიგურაციული და საუკეთესო შედეგების შექმნა, ეს უკეთესოდ ძალიან ძალიან შერძელებელია, რადგან საუკეთესო მხოლოდ მოწყობინებელების პარამეტრებ ეს დოკუმენტი აბსტრაქტიგური დიალოგის რეზიუმიზაციაში თავიდან დამუშავებული სტრაქტიგური სტრაქტიგური სტრაქტიგური სტრაქტიგური შესახებ განსაკუთრებულია, ჩვენი მოდელი პირველი დისკრიმინაცია, რომელიც საკუთრების კონფიგურაცია მოჭირდება პროგრამეტში საკუთრები და შემდეგ შექმნა რედაქტირებული საკუთრები, რომე ექსპერიმენტიური წარმოდგენები გამოჩვენება, რომ ჩვენი წარმოდგენილი მეტი საკმაოდ რესუმენტიურად რესუმენტირებას და რესუმენტირებული რესუმენტირები მნიშვნელოვანია კო</abstract_ka>
      <abstract_mk>Во овој документ, се фокусираме на подобрување на квалитетот на резултатот генериран од невралниот апстрактивен дијалог систем за резултати. И покрај тоа што предобучените јазички модели генерираат добро изградени и ветувачки резултати, сé уште е тешко да се резимира разговорот на повеќе учесници, бидејќи резултатот треба да вклучува опис на целокупната ситуација и дејствата на секој говорник. Овој документ предлага самонадгледувани стратегии за посткорекција фокусирана на говорникот во апстрактивната резултатација на дијалогот. Специфично, нашиот модел прво дискриминира кој тип на корекција на говорникот е потребен во нацрт-резултат и потоа генерира ревидиран резултат според потребниот тип. Експерименталните резултати покажуваат дека нашиот предложен метод соодветно ги коригира нацрт-резултатите, а ревидираните резултати се значително подобрени во квантитивните и квалитетните проценки.</abstract_mk>
      <abstract_ms>Dalam kertas ini, kita fokus pada meningkatkan kualiti ringkasan yang dijana oleh sistem ringkasan dialog abstraktif saraf. Walaupun model bahasa pra-dilatih menghasilkan hasil yang baik-bina dan berjanji, ia masih mencabar untuk ringkasan perbualan beberapa peserta kerana ringkasan patut termasuk deskripsi situasi umum dan tindakan setiap pembicara. Kertas ini mencadangkan strategi mengawasi diri sendiri untuk pembetulan selepas fokus pembicara dalam ringkasan dialog abstraktif. Secara khusus, model kita pertama-tama mendiskriminasi jenis pembetulan pembicara yang diperlukan dalam ringkasan drpd dan kemudian menghasilkan ringkasan diubah mengikut jenis yang diperlukan. Keputusan percubaan menunjukkan bahawa kaedah yang kami cadangkan betulkan ringkasan drpd, dan ringkasan yang diubah meningkatkan secara signifikan dalam kedua-dua penilaian kuantitatif dan kualitatif.</abstract_ms>
      <abstract_kk>Бұл қағазда, невралдық абстрактивті диалогтың тұжырымдамасын жасайтын тұжырымдамасының сапатын жақсарту үшін көздейміз. Алдын- ала оқылған тіл үлгілері жақсы құрылған және әлемді нәтижелерді жасауға болады, бірнеше қатысушылардың сұхбатын жазып тұруға әлі қиын болады, себебі тұжырымдығы жалпы жағдайды және әрбір Бұл қағаз абстрактивті диалогтың тұжырымдамасында өзінің бақылау стратегияларын ұсынады. Ескерту үлгісіміз біріншіден сөздердің түрлерін түзетуге қажет болып, керек түріне сәйкес келтірілген тұжырымдамызды жасайды. Эксперименталдық нәтижелері біздің таңдалған әдіміміз дұрыс жазылған тұжырымдық жобаларды дұрыс түзетуді көрсетеді, және түзетілген тұжырымдық тұжырымдықтар санаттық және квал</abstract_kk>
      <abstract_mt>F’dan id-dokument, niffokaw fuq it-titjib tal-kwalità tas-sommarju ġġenerat mis-sistemi ta’ sommarju tad-djalogu astrattiv newrali. Even though pre-trained language models generate well-constructed and promising results, it is still challenging to summarize the conversation of multiple participants since the summary should include a description of the overall situation and the actions of each speaker.  Dan id-dokument jipproponi strateġiji awtosorveljati għal wara korrezzjoni ffukata fuq il-kelliema fis-sommarju tad-djalogu astrattiv. Speċifikament, il-mudell tagħna l-ewwel jiddiskrimina liema tip ta’ korrezzjoni tal-kelliema hija meħtieġa f’abbozz ta’ sommarju u mbagħad jiġġenera sommarju rivedut skont it-tip meħtieġ. Ir-riżultati esperimentali juru li l-metodu propost tagħna jikkoreġi b’mod adegwat l-abbozzi tas-sommarji, u s-sommarji riveduti jittejbu b’mod sinifikanti kemm fl-evalwazzjonijiet kwantitattivi kif ukoll kwalitattivi.</abstract_mt>
      <abstract_mn>Энэ цаасан дээр бид мэдрэлийн abstractive диалог дээр гаргасан нийлүүлэлтийн сайн сайн сайжруулахын тулд анхаарлаа төвлөрүүлнэ. Өмнөх сургалтын хэл загварууд сайн бүтээгдэхүүнтэй, амлалтай үр дүнг бий болгодог ч гэсэн, олон оролцогчдын яриаг цуглуулахад хэцүү болно. Олон нийтлэл нь ярьдаг бүх нөхцөл байдал болон илтгэгч бүрийн үйлдлийн тухай дүрсл Энэ цаас илтгэгч дээр анхаарлаа зохицуулахын дараа нь өөрийгөө удирдах стратегийг санал болгодог. Ялангуяа бидний загвар анхны хэлбэрээр илтгэгчийн зөвшөөрөл хэрэгтэй хэлбэрийг тодорхойлж, дараа нь шаардлагатай хэлбэрээр шинэчлэгдсэн жишээг бий болгодог. Үүний туршилтын үр дүнд бидний санал өгсөн арга загварыг зөвхөн зөвшөөрөх боломжтой. Шинэ санал өгсөн орнууд нь хэмжээст болон квалификацийн оюутнууд хоёулаа маш сайжруулагддаг.</abstract_mn>
      <abstract_ml>ഈ പത്രത്തില്‍ നമ്മള്‍ ന്യൂറല്‍ പ്രത്യേക സംവിധാന സംവിധാനങ്ങള്‍ ഉല്‍പാദിപ്പിക്കുന്ന സംവിധാനത്തിന്റെ ഗുണവിശേഷത്തി മുമ്പ് പരിശീലന ഭാഷ മോഡലുകള്‍ നന്നായി നിര്‍മ്മിക്കുകയും വാഗ്ദാനം നല്‍കുകയും ചെയ്യുന്ന ഫലങ്ങള്‍ ഉണ്ടാക്കുകയും ചെയ്താലും പല പങ്കാളികളുടെ സംസാരം കുറിച്ച ഈ പത്രത്തില്‍ സ്വയം നിരീക്ഷിച്ചുകൊണ്ടിരിക്കുന്ന സ്പേക്ടര്‍ ഫോക്സോക്സ് സംസാരിക്കുന്ന പിന്നില്‍ സംസാരിക് പ്രത്യേകിച്ച്, നമ്മുടെ മോഡല്‍ ആദ്യം വ്യത്യസ്ത്രീകരിക്കുന്നു. ഏത് തരം സംസാരിക്കുന്ന സംസാരിക്കുന്ന സംസാരിക്കുന്നതിന്റ പരീക്ഷണ ഫലങ്ങള്‍ കാണിച്ചു കൊണ്ടിരിക്കുന്നു നമ്മുടെ പ്രൊദ്ദേശിക്കപ്പെട്ട രീതിയില്‍ വേര്‍പ്പെടുത്തുന്നത് ശരിയായി ശരിയാക്കുന്നത്</abstract_ml>
      <abstract_pl>W artykule skupiamy się na poprawie jakości podsumowania generowanego przez neuronowe abstrakcyjne systemy podsumowywania dialogu. Chociaż wstępnie przeszkolone modele językowe generują dobrze skonstruowane i obiecujące rezultaty, ciągle trudno jest podsumować rozmowę wielu uczestników, ponieważ podsumowanie powinno zawierać opis ogólnej sytuacji i działań każdego mówcy. Niniejszy artykuł proponuje samodzielnie nadzorowane strategie postkorekcji ukierunkowanej na mówcę w abstrakcyjnym podsumowaniu dialogu. W szczególności nasz model najpierw rozróżnia, jaki rodzaj korekty głośnika jest wymagany w projekcie podsumowania, a następnie generuje zmienione podsumowanie według wymaganego typu. Wyniki eksperymentalne pokazują, że proponowana przez nas metoda odpowiednio koryguje projekty streszczeń, a zmienione streszczenia znacząco ulegają poprawie zarówno w ocenach ilościowych, jak i jakościowych.</abstract_pl>
      <abstract_no>I denne papiret fokuserer vi på å forbetra kvaliteten til sammendragen laga av neiralabstraktive dialogsamanseringssystemer. Selv om først trengte språk-modeller genererer godt konstruert og forventande resultat, er det fremdeles vanskeleg å samansera samtalen av fleire deltakarar sidan sammendragen bør innehalda ei skildring av den generelle situasjonen og handlingane av kvar taler. Denne papiret foreslår sjølvoversikte strategiar for postkorrigering med taler i abstraktiv dialogsamansering. Spesifisert, vår modell først diskriminerer kva type talekorreksjon krevst i eit sammendrag, og så lagar ein revisert sammendrag etter den nødvendige typen. Eksperimentale resultat viser at vår foreslått metode korrigerer prosjektet for sammendragar tilstrekkeleg, og de reviserte sammendragane er betydelig forbetra i både kvantitative og kvalitative evalueringa.</abstract_no>
      <abstract_sr>U ovom papiru, fokusiramo se na poboljšanje kvalitete sažetka proizvedenog od sustava sažetanja neuronskog abstraktivnog dijaloga. Iako predobučeni jezički modeli stvaraju dobro konstruirane i obećavajuće rezultate, još uvek je teško sažeti razgovor višestrukih učesnika jer sažetak treba uključiti opis ukupne situacije i akcije svakog govornika. Ovaj papir predlaže samoopraćene strategije za postkorekciju usredotočene na govornika u sažetak apstraktivnog dijaloga. Posebno, naš model prvi diskriminira koji je tip korekcije govornika potrebno u sažetku, a onda stvara revidiran sažetak prema potrebnom tipu. Eksperimentalni rezultati pokazuju da naša predložena metoda adekvatno ispravlja projekt sažetaka, a revidirane sažetke su značajno poboljšane u kvantitativnim i kvalitativnim procenama.</abstract_sr>
      <abstract_si>මේ පත්තරේ අපි බලන්නේ න්‍යූරාල් සංවාද සංවාදය පද්ධතියෙන් නිර්මාණය කරපු සංවාදයේ කුළුවත් වැඩි ක ප්‍රධානය කරපු භාෂාව මොඩල් හොඳින් නිර්මාණය සහ පොරොන්දු වාර්තාවක් නිර්මාණය කරනවා නමුත්, ඒක තාමත් ප්‍රශ්නය කරපු අංක අංකාරීන්ග මේ පැත්තේ ස්වයංග්‍රහණ සංවාදය සම්පූර්ණයෙන් ස්වයංග්‍රහණය කරනවා ස්වයංග්‍රහණ සංවාදය සඳහා ස්ව විශේෂයෙන්, අපේ මොඩල් මුලින්ම විශේෂය කරනවා කියලා ස්පීකර් විශේෂය ක්‍රමයක් විශේෂය කරනවා කියලා ප්‍රතිචාරයක් සං පරීක්ෂණ ප්‍රතිචාර ප්‍රතිචාරයක් පෙන්වන්නේ අපේ ප්‍රතිචාරිත විධානය සඳහා ප්‍රතිචාරිත විධානය සහ ප්‍රතිචාරිත ව</abstract_si>
      <abstract_sv>I denna uppsats fokuserar vi på att förbättra kvaliteten på den sammanfattning som genereras av neurala abstraktiva dialogsammanfattningssystem. Även om förberedda språkmodeller genererar välkonstruerade och lovande resultat är det fortfarande svårt att sammanfatta konversationen mellan flera deltagare eftersom sammanfattningen bör innehålla en beskrivning av den övergripande situationen och varje talares agerande. Denna uppsats föreslår självövervakade strategier för talarfokuserad post-korrigering i abstraktiv dialog sammanfattning. Specifikt definierar vår modell först vilken typ av högtalarkorrigering som krävs i ett utkast till sammanfattning och genererar sedan en reviderad sammanfattning enligt önskad typ. Experimentella resultat visar att vår föreslagna metod korrekt korrigerar utkastet till sammanfattningar, och de reviderade sammanfattningarna förbättras avsevärt i både kvantitativa och kvalitativa utvärderingar.</abstract_sv>
      <abstract_so>Qoraalkan waxaan ku kalsoonaynaa horumarinta qiimaha summalka ee ku soo dhashay nidaamka soo jiilaalka xilliga ee neurada. Inkastoo samooyin afka hore lagu tababariyey ay soo dhashaan matooyin wanaagsan oo ballan leh, waxaa weli dhibaato ah in loo soo koobi karo hadalka kuwa kala qayb qaata, sababtoo ah xigaalku waa inay ku jirtaa tilmaamo xaaladda oo dhan iyo falimaha hadal walba. This paper proposes self-supervised strategies for speaker-focused post-correction in abstractive dialogue summarization.  Si gaar ah, modellkayaga marka ugu horeysa wuxuu takoorisaa saxda hadalka ee nooca looga baahan yahay saxafka dhawaaqa, markaasna wuxuu soo bandhigaa summar cusub sida loo baahan yahay. Abaalka imtixaanka waxaa tusaya in awoodkeennu uu si ku filan u hagaajiyo jardiinada summalka, qiimeynta hore ee qiyaastii iyo qiimeynta.</abstract_so>
      <abstract_ta>இந்த காகிதத்தில், நாம் புதிய புதிய சுருக்கல் சுருக்கம் அமைப்புகளால் உருவாக்கப்பட்ட சுருக்கத்தின் தரம் மேம்படுத்து முன்பு பயிற்சிக்கப்பட்ட மொழி மாதிரி நன்றாக உருவாக்கப்பட்டுள்ளது மற்றும் வாக்குறுதியான முடிவுகளை உருவாக்குகிறது எனினும், சுருக்கத்தில் பல பங்கு இந்த காகிதத்தில் பேச்சாளர்- கவனமாக்கப்பட்ட பின்திருத்தம் செய்யப்பட்ட உரையாடல் சுருக்கம் செய்யும் போது திருத்தமு குறிப்பிட்டு, எங்கள் மாதிரி முதலில் பேச்சாளர் எந்த வகையின் திருத்தம் தேவைப்படுகிறது என்பதை விளக்குகிறது பின்னர் தேவைப்படும்  பரிசோதனை முடிவுகள் தெரிவிக்கப்பட்டுள்ளது என்பது நமது முன்னோக்கப்பட்ட முறைமையின் சுருக்குகளை சரிபார்க்க போதுமான முறையிடப்பட்ட சுருக</abstract_ta>
      <abstract_ro>În această lucrare, ne concentrăm pe îmbunătățirea calității rezumatului generat de sistemele de sintetizare a dialogului abstractiv neural. Chiar dacă modelele lingvistice pre-instruite generează rezultate bine construite și promițătoare, este încă dificil să rezumăm conversația mai multor participanți, deoarece rezumatul ar trebui să includă o descriere a situației generale și a acțiunilor fiecărui vorbitor. Această lucrare propune strategii auto-supravegheate pentru post-corectarea axată pe speaker în rezumatul dialogului abstractiv. Mai exact, modelul nostru discriminează mai întâi tipul de corecție a difuzorului necesar într-un proiect de rezumat și apoi generează un rezumat revizuit în funcție de tipul necesar. Rezultatele experimentale arată că metoda propusă corectează în mod adecvat proiectele de rezumat, iar rezumatele revizuite sunt îmbunătățite semnificativ atât în evaluările cantitative, cât și calitative.</abstract_ro>
      <abstract_ur>اس کاغذ میں، ہم نے نئورل غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر اگرچہ پہلے کی تعلیم کی زبان مدل بہت اچھی طرح بنائی اور وعدہ دینے والی نتیجے پیدا کرتی ہیں، یہ اب بھی بہت سے مشرکوں کی باتوں کی تعریف کرنا مشکل ہے، کیونکہ اس تعریف کے ذریعہ ایک سارے موقعیت اور ہر صحبت کرنے والے کے کاموں کی تعریف میں شامل ہوتی ہے. This paper proposes self-supervised strategies for speaker-focused post-correction in abstractive dialog summarization. مخصوص طور پر، ہمارا مدل پہلے تفریق کرتا ہے کہ کس طرح سپیکر اصلاح کی ضرورت ہے ایک ڈرافوٹ سرجمع میں اور پھر ضرورت کی طرح ایک سرجمع پیدا کرتا ہے۔ Experimental results show that our proposed method adequately corrects the draft summaries, and the revised summaries are significantly improved in both quantitative and qualitative evaluations.</abstract_ur>
      <abstract_vi>Trong tờ giấy này, chúng tôi tập trung vào việc cải thiện chất lượng của bản tóm tắt tạo ra bởi hệ thống cấu hình về cuộc đối thoại trừu tượng. Mặc dù các mô hình ngôn ngữ được huấn luyện trước tạo ra kết quả tích cực và đầy hứa hẹn, nhưng vẫn khó khăn trong việc tổng kết lại cuộc đối thoại của nhiều người tham gia, vì bản tóm tắt phải có một mô tả tình hình tổng thể và hành động của mỗi người diễn đạt. Đề tài này đề xuất các chiến lược được giám sát bởi loa, sau khi sửa chữa hồ sơ. Cụ thể, mẫu của chúng ta trước tiên phân biệt kiểu sửa chữa loa nào cần phải trong một bản tóm tắt và sau đó tạo ra một bản tóm tắt theo kiểu cần thiết. Kết quả thí nghiệm cho thấy phương pháp của chúng ta cải thiện bản tóm tắt một cách thích đáng, và những bản tóm tắt đã được cải thiện đáng kể cả về chất lượng và chất lượng.</abstract_vi>
      <abstract_uz>Bu hujjatda, biz neyrolik abstraktiv muloqat tizimi yaratgan summary sifatini oshirishga foydalanamiz. Even though pre-trained language models generate well-constructed and promising results, it is still challenging to summarize the conversation of multiple participants since the summary should include a description of the overall situation and the actions of each speaker.  Bu qogʻoz avto- toʻgʻri muloqat tahrirlashda gapiruvchi foydalanuvchi foydalanuvchi strategiyani o'zimni nazorat qiladi. Koʻrsatilgan, bizning modelimizning birinchi qiymatni o'zgartirish turida qanday qilinadi va keyin kerak boʻlgan turdagi xabarga oʻzgarishni yaratish. Tekshirish natijalari namoyishga taʼminlovchi soʻzni tahrirlash imkoniyatini ko'rsatadi. Taʼminlovchi qiymati va qiymati haqida juda muhimiy o'zgartiriladi.</abstract_uz>
      <abstract_bg>В настоящата статия се фокусираме върху подобряване качеството на резюмето, генерирано от системите за обобщаване на невронните абстрактни диалози. Въпреки че предварително обучените езикови модели генерират добре конструирани и обещаващи резултати, все още е трудно да се обобщи разговорите на множество участници, тъй като резюмето трябва да включва описание на цялостната ситуация и действията на всеки оратор. Настоящата статия предлага самостоятелно контролирани стратегии за фокусирана към говорителя посткорекция в абстрактното обобщаване на диалога. По-конкретно, нашият модел първо дискриминира кой тип корекция на говорителя се изисква в чернова резюме и след това генерира ревизирано резюме според необходимия тип. Експерименталните резултати показват, че предложеният от нас метод адекватно коригира проектозабщенията, а ревизираните резюмета са значително подобрени както в количествените, така и в качествените оценки.</abstract_bg>
      <abstract_da>I denne artikel fokuserer vi på at forbedre kvaliteten af det resumé, der genereres af neurale abstraktive dialogopsummeringssystemer. Selvom forududdannede sprogmodeller genererer velkonstruerede og lovende resultater, er det stadig udfordrende at opsummere samtalen mellem flere deltagere, da resuméet bør indeholde en beskrivelse af den overordnede situation og de enkelte taleres handlinger. Denne artikel foreslår selvovervågede strategier for talerfokuseret post-korrektion i abstraktiv dialog resuméering. Specielt diskriminerer vores model først, hvilken type højttalerregering der kræves i et udkast til resumé og genererer derefter en revideret resumé i henhold til den ønskede type. Eksperimentelle resultater viser, at vores foreslåede metode korrekt korrigerer udkastet til resuméer, og de reviderede resuméer er betydeligt forbedret i både kvantitative og kvalitative evalueringer.</abstract_da>
      <abstract_nl>In dit artikel richten we ons op het verbeteren van de kwaliteit van de samenvatting gegenereerd door neuronale abstractieve dialoogsamenvattingssystemen. Hoewel voorgetrainde taalmodellen goed geconstrueerde en veelbelovende resultaten genereren, is het nog steeds een uitdaging om het gesprek van meerdere deelnemers samen te vatten, aangezien de samenvatting een beschrijving van de algemene situatie en de acties van elke spreker moet bevatten. Deze paper stelt zelfbegeleide strategieën voor spreker-gerichte post-correctie in abstractieve dialoogsamenvatting voor. Concreet onderscheidt ons model eerst welk type sprekercorrectie vereist is in een ontwerpsamenvatting en genereert vervolgens een herziene samenvatting volgens het vereiste type. Uit experimentele resultaten blijkt dat onze voorgestelde methode de ontwerpsamenvattingen adequaat corrigeert en dat de herziene samenvattingen aanzienlijk verbeterd zijn in zowel kwantitatieve als kwalitatieve evaluaties.</abstract_nl>
      <abstract_hr>U ovom papiru, usredotočili smo se na poboljšanje kvalitete sažetka proizvedenog sustavima sažetanja neuronskog apstraktivnog dijaloga. Iako predobučeni jezički modeli stvaraju dobro konstruirane i obećavajuće rezultate, još uvijek je teško sažeti razgovor višestrukih učesnika jer sažetak treba uključiti opis ukupne situacije i djela svakog govornika. U ovom papiru predlaže samopouzdane strategije za postkorekciju usredotočene na govornika u sažetak apstraktivnog dijaloga. Posebno, naš model prvi diskriminira koji je tip korištenja govornika potreban u sažetku projekta, a zatim stvara reviziran sažetak prema potrebnoj vrsti. Eksperimentalni rezultati pokazuju da naša predložena metoda adekvatno ispravlja nacrt sažetaka, a revidirane sažetke značajno su poboljšane u kvantitativnim i kvalitativnim procjenama.</abstract_hr>
      <abstract_de>In diesem Beitrag konzentrieren wir uns auf die Verbesserung der Qualität der durch neuronale abstraktive Dialogzusammenfassungssysteme generierten Zusammenfassung. Auch wenn vortrainierte Sprachmodelle gut konstruierte und vielversprechende Ergebnisse liefern, ist es immer noch schwierig, das Gespräch mehrerer Teilnehmer zusammenzufassen, da die Zusammenfassung eine Beschreibung der Gesamtsituation und der Handlungen jedes Sprechers enthalten sollte. In diesem Beitrag werden selbstüberwachte Strategien zur sprecherfokussierten Nachkorrektur in der abstraktiven Dialogzusammenfassung vorgeschlagen. Konkret unterscheidet unser Modell zunächst, welche Art von Lautsprecherkorrektur in einer Zusammenfassung erforderlich ist und generiert dann eine überarbeitete Zusammenfassung entsprechend dem gewünschten Typ. Die experimentellen Ergebnisse zeigen, dass unsere vorgeschlagene Methode die Entwürfe der Zusammenfassungen adäquat korrigiert und die revidierten Zusammenfassungen sowohl in quantitativen als auch qualitativen Bewertungen signifikant verbessert werden.</abstract_de>
      <abstract_id>Dalam kertas ini, kita fokus pada meningkatkan kualitas ringkasan yang dihasilkan oleh sistem penglihatan dialog abstraktif saraf. Meskipun model bahasa yang dilatih sebelumnya menghasilkan hasil yang baik dan berjanji, masih sulit untuk mengungkapkan percakapan dari beberapa peserta karena ringkasan harus mengandung deskripsi situasi umum dan tindakan setiap pembicara. Kertas ini mengusulkan strategi yang diawasi oleh diri sendiri untuk pembicara fokus setelah koreksi dalam ringkasan dialog abstraktif. Specifically, our model first discriminates which type of speaker correction is required in a draft summary and then generates a revised summary according to the required type.  Hasil eksperimen menunjukkan bahwa metode kami yang diusulkan secara adekwat memperbaiki daftar ringkasan, dan ringkasan yang diubah secara signifikan diperbaiki dalam kedua evaluasi kuantitatif dan kualitatif.</abstract_id>
      <abstract_fa>در این کاغذ، ما روی بهترین کیفیت جمع توسط سیستم جمع کردن محاورهای عصبی تمرکز می کنیم. اگرچه مدلهای زبانی پیش آموزش شده‌اند نتیجه‌های بسیار ساخته و وعده‌دهنده را تولید می‌کنند، هنوز سخت است که مکالمه‌های چندین مشترک را جمع کنید، از آنجا که جمع باید توضیح موقعیت عمومی و عمل‌های هر صحبت کننده را جمع کند. این کاغذ پیشنهاد استراتژی‌های خودکنترل برای تغییر بعد از تغییر دادن با صحبت‌کننده در جمع کردن محاورۀ محاورۀ مثبت می‌کند. مخصوصا، مدل ما اول تفریح می‌کند که کدام نوع اصلاح سخنرانی در یک عمومی نیاز دارد و سپس یک عمومی تغییر داده شده را بر اساس نوع لازم تولید می‌کند. نتیجه‌های تجربه نشان می‌دهد که روش پیشنهاد ما به اندازه‌ای که پیشنهاد کرده‌ایم جمع‌آوری‌ها را درست می‌کند، و جمع‌آوری‌ها که تغییر داده‌ایم به اندازه‌ای در ارزیابی‌های مقداری و کیفیت بس</abstract_fa>
      <abstract_ko>본고에서 우리는 신경 추상적 대화 요약 시스템이 생성한 요약의 질을 향상시키는 데 주력한다.비록 미리 훈련된 언어 모델이 좋은 구축과 희망적인 결과를 얻었지만 여러 참여자의 대화를 정리하는 것은 여전히 도전이다. 왜냐하면 정리는 전체적인 상황과 모든 발언자의 행동에 대한 묘사를 포함해야 하기 때문이다.본고는 추상적인 대화 요약에서 말하는 사람을 중심으로 하는 사후 교정의 자기 감독 전략을 제시했다.구체적으로 말하자면 우리의 모델은 먼저 요약 초고에서 어떤 유형의 말하는 사람이 수정해야 하는지를 구분한 다음에 필요한 유형에 따라 수정된 요약을 생성한다.실험 결과에 의하면 우리가 제시한 방법은 요약 초고를 충분히 수정했고 수정된 요약은 정량과 정성 평가에서 현저하게 개선되었다.</abstract_ko>
      <abstract_sw>Katika gazeti hili, tunalenga kuboresha kiwango cha muhtasari kilichotengenezwa na mfumo wa muhtasari wa mazungumzo yasiyo na ubora. Hata kama mifano ya lugha iliyoendelea imetengeneza matokeo mazuri na yenye kuahidini, bado inachanganya muhtasari wa mazungumzo ya washiriki kadhaa tangu muhtasari unapaswa kuwa na maelezo ya hali ya jumla na vitendo vya kila msemaji. Makala hii inapendekeza mikakati ya kujitazama kwa ajili ya kuongea wenye lengo la kurekebisha baada ya kurekebisha kwenye muhtasari wa mazungumzo yasiyo na maana. Bila shaka, mtindo wetu wa kwanza unapambana na a in a gani ya uharibifu wa mazungumzaji unahitajika katika rasimu ya muhtasari na kisha kujenga muhtasari wa kurekebisha kwa mujibu wa aina inayohitajika. Matokeo ya majaribio yanaonyesha kuwa mbinu yetu ya pendekezo inasahihisha rasimu ya muhtasari, na muhtasari wa muhtasari ulioboreshwa vimeboreshwa kwa kiasi kikubwa na kiasi kikubwa.</abstract_sw>
      <abstract_tr>Bu kagyzda, neural abstraktiv dijalog jemgyýetleme sistemalary tarapyndan üretilen toparyň keyfiýetini geliştirmek üçin üns berýäris Öň bilim öňündeki dil nusgalary gowy inşa edilen we söz berýän netijeleri döretýän bolsa-da, toplantyň hemme durumynyň we her çykyşyň netijesini ýazmak üçin bir näçe iştirakçileriniň gürrüňini gutarmak kynçylykly. Bu kagyz sözleri fokus edilen soňra düzeltmek üçin özüni gözleýän strategiýalary teklip edýär. Adatça, biziň nusgamyz ilkinji gezek çykyşyň hili hili çykyşyň düzeltmegini ahmal we soňra gerekli türdene görä döretýär. Experimental netijelerimiz teklip eden metodumyzyň taslaýyşyň düzgün düzeltmegini görkezýär we düzenlenen toparyň hem calamlaryň hem kiçiselişi deňlemelerde has baglanýandygyny görkezýär.</abstract_tr>
      <abstract_af>In hierdie papier, ons fokus op die kwaliteit van die opsomming wat deur neurale abstraktiewe dialoog opsomming stelsels genereer is om te verbeter. Selfs al die vooraf-opgelei taal modele genereer goed-konstrukteerde en beloftende resultate, is dit nog moeilik om die gesprek van veelvuldige deelnaders te opsomming omdat die opsomming 'n beskrywing van die hele situasie en die aksies van elke sprekker moet insluit. Hierdie papier voorstel self-superviseer strategies vir sprekker-fokuseerde post-korreksie in abstraktiewe dialoog opsomming. Spesifieke, ons model eerste diskrimineer wat tipe spreker korreksie benodig word in 'n voorwerp opsomming en dan genereer 'n hervergroot opsomming volgens die benodig tipe. Eksperimentele resultate wys dat ons voorgestelde metode die projekt opsommings adequate korrigeer, en die hervergroot opsommings is betekeurig verbeter in beide kvantitatiewe en kwaliteiteit evaluering.</abstract_af>
      <abstract_sq>Në këtë letër, ne përqëndrohemi në përmirësimin e cilësisë së përmbledhjes së gjeneruar nga sistemet abstraktive të përmbledhjes së dialogut nervor. Edhe pse modelet e gjuhës së paratrajnuara gjenerojnë rezultate të ndërtuara dhe premtuese, është ende e vështirë të përmbledhësh bisedën e pjesëmarrësve të shumëfishtë pasi përmbledhja duhet të përfshijë një përshkrim të gjendjes së përgjithshme dhe veprimeve të çdo fjalësi. Ky dokument propozon strategji vetë-mbikqyrura për postkorreksionin e fokusuar nga folësi në përmbledhjen abstraktive të dialogut. Specifically, our model first discriminates which type of speaker correction is required in a draft summary and then generates a revised summary according to the required type.  Rezultatet eksperimentale tregojnë se metoda jonë e propozuar korrekton në mënyrë të përshtatshme projekt-përmbledhjet dhe përmbledhjet e revizuara janë përmirësuar ndjeshëm si në vlerësimet kuantitative ashtu edhe kualitative.</abstract_sq>
      <abstract_am>በዚህ ፕሮግራም፣ የነዌብ አካባቢ አካባቢ የጥያቄ አካባቢ አካባቢ ማነሳትን እናሳውቃለን፡፡ ከቀድሞ ተማሪ የቋንቋ ምሳሌዎች መልካም የተመሠረቱና የተስፋ ፍሬዎችን አፍስቷል ቢሆንም እንኳ፣ በተጠቃሚ ጉዳዩ የብዙ ተጋሪዎችን ንግግር ማጠቃቀሚያ ይችላል፡፡ ይህ ፕሮግራም የንግግር አካባቢ አካባቢ አካባቢ አካባቢ ማነሻ ማቀናጃ ላይ ራሳቸውን በመጠበቅ ጥቅምቶችን ያስባል፡፡ በተለይም፣ ሞዴላያችን በመጀመሪያ የቋንቋዎች ማቀናጃ ምን ዓይነት እንዲያስፈልጋቸው እና በቁጥጥር እንዲያስፈልገው እንደተፈላጊው ዓይነት የተመለሰውን አቋራጭ የሚያደርጋል፡፡ በተፈተናው ውጤቶች የሥርዓታችንን ሥርዓት በኩል እንዲያስተካክሉ እና የተመለሱት ጉዳዩ በቁጥጥር እና በሚያስፈልጉት ውጤቶች በሙሉ ትክክል ይሻላል፡፡</abstract_am>
      <abstract_hy>Այս թղթի մեջ մենք կենտրոնանում ենք նյարդային աբստրակտիվ խոսակցության համառոտագրման համակարգերի որակի բարելավման վրա: Չնայած, որ նախապատրաստված լեզվի մոդելները լավ կառուցված և խոստացող արդյունքներ են ստեղծում, դեռևս դժվար է համառոտագրել բազմաթիվ մասնակիցների խոսակցությունը, քանի որ համառոտագրությունը պետք է ներառի ընդհանուր իրավիճակի և յուրաքանչյուր խոս Այս փաստաթղթին առաջարկում է ինքնավերահսկվող ռազմավարություններ խոսնակի կենտրոնացված հետուղղությունների համար վերացրական երկխոսության համառոտագրության մեջ: Specifically, our model first discriminates which type of speaker correction is required in a draft summary and then generates a revised summary according to the required type.  Փորձարկվող արդյունքները ցույց են տալիս, որ մեր առաջարկած մեթոդը համապատասխանաբար ուղղել է համառոտագրությունների նախագիծը, և վերափոխված համառոտագրությունները նշանակալի բարելավվում են քանակական և որակական գնահատականների մեջ:</abstract_hy>
      <abstract_az>Bu kağızda, nöral abstraktiv dialoğu təmizləmə sistemlərindən yaratdığı təmizlənmənin keyfiyyətini yaxşılaşdırmağa odaqlanırıq. Əvvəlcə təhsil edilmiş dil modelləri yaxşı inşa edilmiş və söz verilən sonuçları təşkil etmiş olsa da, hələ də çoxlu iştirakçilərin söhbətini təmizləməsi çətindir, çünki bu qurbanlıq bütün durumların və hər söhbətçinin əməllərinin təfsil edilməsi lazımdır. Bu kağıt, özünü gözləyir, danışmaq üçün danışmaq məqsədilə sonrakı düzəltmə stratejiləri təklif edir. Şübhəsiz ki, modellərimiz ilk dəfə sözləşdirici düzəltməsi üçün hansı növlünün istifadə edilməsi lazımdır və sonra ehtiyacı olan növ ilə yenidən dəyişdirilmiş istifadə edir. Experimental sonuçları göstərir ki, təklif metodumuzun düzəltməsini tamamilə düzəltər və yenilənmiş toplamlar kvantitatlı və kvalitatlı değerlendirmələrdə çox yaxşılaşdırılır.</abstract_az>
      <abstract_bn>এই কাগজটিতে আমরা নিউরুল আত্মসংক্রান্ত ডায়ালগের সারসংক্ষেপ ব্যবস্থার মান উন্নত করার দিকে মনোযোগ প্রদান করি। যদিও পূর্ব প্রশিক্ষিত ভাষার মডেল ভালো নির্মাণ এবং প্রতিশ্রুতিশীল ফলাফল তৈরি করে, তবুও সার্ষাৎকারে বেশ কয়েকজন অংশগ্রহণকারীর কথোপকথন সংক্ষেপের চ্য এই পত্রিকাটি সংক্রান্ত ডায়ালগের সারসংক্ষেপের জন্য স্পেক্টর-ফোকাস করা পোস্ট সংস্কারের জন্য নিজেকে পর্যবেক্ষণ করা  বিশেষ করে, আমাদের মডেল প্রথমে বৈষম্য করে দেয় যে কোন ধরনের বক্তৃপক্ষের সংশ্লিষ্ট সংশ্লিষ্ট সংশোধনের প্রয়োজন এবং তারপর প্রয়োজনীয় ধরনে পরীক্ষার ফলাফল দেখা যাচ্ছে যে আমাদের প্রস্তাবিত পদ্ধতি যথেষ্ট পরিমাণ সংক্রান্ত সংক্ষেপ সঠিক করে দেয়া হয়েছে এবং সংশ্লিষ্ট সংক্ষেপ গুরু</abstract_bn>
      <abstract_bs>U ovom papiru, fokusiramo se na poboljšanje kvalitete sažetka proizvedenog sustavima sažetanja neuronskog abstraktivnog dijaloga. Iako predobučeni jezički modeli stvaraju dobro konstruirane i obećavajuće rezultate, još uvijek je teško sažeti razgovor višestrukih učesnika, jer sažetak treba uključiti opis ukupne situacije i akcije svakog govornika. Ovaj papir predlaže samoopraćene strategije za postkorekciju na govornici u sažetku apstraktivnog dijaloga. Posebno, naš model prvi diskriminira koji je tip korekcije govornika potrebno u projektu sažetka i onda stvara revidiran sažetak prema potrebnom tipu. Eksperimentalni rezultati pokazuju da naša predložena metoda adekvatno ispravlja nacrt sažetaka, a revidirane sažetke su značajno poboljšane u kvantitativnim i kvalitativnim procjenama.</abstract_bs>
      <abstract_cs>V tomto článku se zaměřujeme na zlepšení kvality souhrnu generovaného neuronovými abstraktivními systémy souhrnu dialogů. Přestože předškolené jazykové modely generují dobře sestavené a slibné výsledky, je stále náročné shrnout konverzaci více účastníků, protože souhrn by měl obsahovat popis celkové situace a akce jednotlivých řečníků. Tento příspěvek navrhuje vlastně dohledné strategie pro post-korekci zaměřené na řečníka v abstraktivní shrnutí dialogu. Konkrétně náš model nejprve rozlišuje, jaký typ korekce mluvčího je v návrhu shrnutí požadován a poté generuje revidované shrnutí podle požadovaného typu. Z experimentálních výsledků vyplývá, že naše navrhovaná metoda adekvátně korekuje návrhy shrnutí a revidované shrnutí jsou výrazně zlepšeny jak kvantitativním, tak kvalitativním hodnocením.</abstract_cs>
      <abstract_et>Käesolevas töös keskendume neuroabstraktiivse dialoogi kokkuvõtte kvaliteedi parandamisele. Kuigi eelnevalt koolitatud keelemudelid annavad hästi konstrueeritud ja paljulubavaid tulemusi, on siiski keeruline kokku võtta mitme osaleja vestlus, sest kokkuvõttes peaks olema kirjeldatud üldist olukorda ja iga kõneleja tegevust. Käesolev töö pakub välja isejärelevalve strateegiad kõnelejale keskendunud järelkorrektsiooniks abstraktse dialoogi kokkuvõttes. Täpsemalt diskrimineerib meie mudel esmalt, millist tüüpi kõneleja parandust on vaja kokkuvõtte kavandis ja seejärel genereerib läbivaadatud kokkuvõtte vastavalt vajalikule tüübile. Katsetulemused näitavad, et meie kavandatud meetod parandab kokkuvõtete eelnõusid piisavalt ning läbivaadatud kokkuvõtteid parandatakse oluliselt nii kvantitatiivsete kui ka kvalitatiivsete hindamiste puhul.</abstract_et>
      <abstract_fi>Tässä artikkelissa keskitytään parantamaan neuroabstraktiivisten dialogin yhteenvetojärjestelmien tuottaman yhteenvedon laatua. Vaikka esikoulutetut kielimallit tuottavat hyvin rakennettuja ja lupaavia tuloksia, on silti haastavaa tiivistää useiden osallistujien keskustelua, sillä tiivistelmässä tulisi olla kuvaus kokonaistilanteesta ja kunkin puhujan toiminnasta. Tässä artikkelissa ehdotetaan itsevalvottavia strategioita puhujakoskeisen jälkikorjauksen tekemiseksi abstraktiivisen dialogin yhteenvedossa. Mallimme erittelee ensin, minkä tyyppistä puhujakorjausta tiivistelmäluonnoksessa vaaditaan, ja luo sitten tarkistetun tiivistelmän vaaditun tyypin mukaan. Kokeelliset tulokset osoittavat, että ehdotettu menetelmä korjaa yhteenvetoluonnokset asianmukaisesti ja tarkistettuja yhteenvetoja parannetaan merkittävästi sekä määrällisissä että laadullisissa arvioinneissa.</abstract_fi>
      <abstract_ca>En aquest paper, ens centrem en millorar la qualitat del resum generat pels sistemes de resum del diàleg abstractiu neural. Malgrat que els models de llenguatge pré-entrenats generin resultats ben construïts i prometedors, encara és difícil resumir la conversa de múltiples participants, ja que el resum hauria d'incloure una descripció de la situació global i les accions de cada orador. Aquest paper propon estratègies auto-supervisades per a la post-correcció centrada en els oradors en una resumen del diàleg abstracte. Concretament, el nostre model discrimina primer quin tipus de correcció d'orador es requereix en un projecte de resum i genera un resum revisat segons el tipus requerit. Experimental results show that our proposed method adequately corrects the draft summaries, and the revised summaries are significantly improved in both quantitative and qualitative evaluations.</abstract_ca>
      <abstract_jv>Nang pember iki, kita dipontrol kanggo nggawe kalitas ning resumen sing gagale tarjamahan karo sistem resumen sing nyeangke alat. politenessoffpolite"), and when there is a change ("assertive Gambar iki dipunangke dipunangke dipunangke dipunangke dipunangke dipunangke dipunangke email-custom-header-Security j</abstract_jv>
      <abstract_sk>V prispevku se osredotočamo na izboljšanje kakovosti povzetka, ki ga ustvarijo sistemi za povzetek nevronskega abstraktivnega dialoga. Čeprav vnaprej usposobljeni jezikovni modeli ustvarjajo dobro zgrajene in obetavne rezultate, je še vedno težko povzeti pogovor več udeležencev, saj mora povzetek vsebovati opis celotnega stanja in dejanj vsakega govornika. V prispevku so predlagane samonadzorovane strategije za postkorrekcijo v abstraktivnem povzetku dialoga, usmerjene v govornika. Natančneje, naš model najprej razlikuje, katero vrsto popravka govornika je potrebna v osnutku povzetka, nato pa ustvari revidiran povzetek glede na zahtevano vrsto. Poskusni rezultati kažejo, da naša predlagana metoda ustrezno popravi osnutke povzetkov, revidirani povzetki pa so bistveno izboljšani tako v kvantitativnih kot kvalitativnih ocenah.</abstract_sk>
      <abstract_ha>Daga wannan takardan, Munã fokus zuwa a kyautata sifar ƙara wanda aka ƙãga na zauren akwatin zauren akwatin bayanin neural na'ura da baka keɓata. Even though pre-trained language models generate well-constructed and promising results, it is still challenging to summarize the conversation of multiple participants since the summary should include a description of the overall situation and the actions of each speaker.  Wannan karatun na faransa da tunakin bayani-da-zura wa mai magana da aka zura-zura cikin kurarin zauren akwatin bayani na farat ɗaya. A ƙayyade, misalinmu na farkon ka bambana wata nau'in shiryarwa da za'a buƙata cikin wani matsayi na ƙarami kuma ya ƙãga wata kure da aka riga karya da shi kamar nau'in da aka ƙayyade. Matarin jarrabai na nuna cewa metodinmu da aka buƙata don ya cika gaskiyar tsayi, kuma an kyautata ƙararin da aka riga kare shi mai girma a ƙayyade ƙaddara da lissafi.</abstract_ha>
      <abstract_he>בעיתון הזה, אנחנו מתמקדים בשיפור באיכות הסכם שנוצר ע"י מערכות הסכם הדיולוגים העצביים אוסטרקטיביים. למרות שדוגמני שפה מאומנים מראש יוצרים תוצאות בונות ומבטיחות היטב, זה עדיין מאתגר לסכם את השיחה של מרובים משתתפים מאחר שהסכם צריך לכלול תיאור של המצב הכללי והפעולות של כל דובר. העבודה הזו מציעה אסטרטגיות משגיחות על עצמה עבור תיקון לאחר תיקון ממוקד על רמקולים במסכם הדיולוגים האסטרקטיבי. במיוחד, המודל שלנו קודם מבחין באיזה סוג של תיקון רמקול נדרש בסדרון סדרון ואז יוצר סדרון מעודכן לפי הסוג הנדרש. תוצאות ניסיוניות מראות שהשיטה המוצעת שלנו תוקנת כראוי את סדרי התערוכות, והסדרות המעודדות משתפרות באופן משמעותי בהערכות הכמותיות והאיכותיות.</abstract_he>
      <abstract_bo>འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་འོང་ཚོས་གནས་སྟངས་ཕྱོགས་ཀྱི་མཐོ་རིམ་མཐུན་བཟོ་རྒྱུ་དང་། སྔོན་གྲངས་བསྐུལ་གྱི་སྐད་ཡིག ཤོག་བྱང་འདིས་ཁོང་ཚོའི་ནང་དུ་རང་ཉིད་ལྟ་སྟངས་ཅན་གྱི་འཇུག་སྟངས་དང་བློ་གཏོང་བར་གནས་སྟངས་དང་ཐད་ཚོར་མཁན་མཐུ དམིགས་བསལ་ན། ང་ཚོའི་མ་དབྱིབས་སྔོན་འཛུགས་པ་དེ་གནད་སྡུད་མཛོད་ཁ་ཤས་ཐོག་ཏེ་་བཟོ་རྣམ་གྲངས ངའི་སྒེར་གྱི་གྲུབ་འབྲས་བ་དེ་ནི་ང་ཚོའི་དམིགས་འཛུགས་གྱི་ཐབས་ལམ་དེ་ཆོས་ཉིད་ཡོད་མིན་པས།</abstract_bo>
      </paper>
    <paper id="11">
      <title>Context or No Context? A preliminary exploration of human-in-the-loop approach for Incremental Temporal Summarization in meetings</title>
      <author><first>Nicole</first><last>Beckage</last></author>
      <author><first>Shachi</first><last>H Kumar</last></author>
      <author><first>Saurav</first><last>Sahay</last></author>
      <author><first>Ramesh</first><last>Manuvinakurike</last></author>
      <pages>96–106</pages>
      <abstract>Incremental meeting temporal summarization, summarizing relevant information of partial multi-party meeting dialogue, is emerging as the next challenge in summarization research. Here we examine the extent to which human abstractive summaries of the preceding increments (context) can be combined with extractive meeting dialogue to generate abstractive summaries. We find that previous context improves ROUGE scores. Our findings further suggest that contexts begin to outweigh the dialogue. Using <a href="https://en.wikipedia.org/wiki/Keyphrase_extraction">keyphrase extraction</a> and semantic role labeling (SRL), we find that SRL captures relevant information without overwhelming the the model architecture. By compressing the previous contexts by ~70 %, we achieve better ROUGE scores over our baseline models. Collectively, these results suggest that context matters, as does the way in which context is presented to the model.</abstract>
      <url hash="8b52edd0">2021.newsum-1.11</url>
      <bibkey>beckage-etal-2021-context</bibkey>
      <doi>10.18653/v1/2021.newsum-1.11</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
    </paper>
    <paper id="12">
      <title>Are We Summarizing the Right Way? A Survey of Dialogue Summarization Data Sets</title>
      <author><first>Don</first><last>Tuggener</last></author>
      <author><first>Margot</first><last>Mieskes</last></author>
      <author><first>Jan</first><last>Deriu</last></author>
      <author><first>Mark</first><last>Cieliebak</last></author>
      <pages>107–118</pages>
      <abstract>Dialogue summarization is a long-standing task in the field of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>, and several data sets with <a href="https://en.wikipedia.org/wiki/Dialogue">dialogues</a> and associated human-written summaries of different styles exist. However, it is unclear for which type of dialogue which type of summary is most appropriate. For this reason, we apply a linguistic model of dialogue types to derive matching summary items and NLP tasks. This allows us to map existing dialogue summarization data sets into this <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> and identify gaps and potential directions for future work. As part of this process, we also provide an extensive overview of existing dialogue summarization data sets.</abstract>
      <url hash="86503840">2021.newsum-1.12</url>
      <bibkey>tuggener-etal-2021-summarizing</bibkey>
      <doi>10.18653/v1/2021.newsum-1.12</doi>
    </paper>
    <paper id="13">
      <title>Modeling Endorsement for Multi-Document Abstractive Summarization</title>
      <author><first>Logan</first><last>Lebanoff</last></author>
      <author><first>Bingqing</first><last>Wang</last></author>
      <author><first>Zhe</first><last>Feng</last></author>
      <author id="fei-liu-utdallas"><first>Fei</first><last>Liu</last></author>
      <pages>119–130</pages>
      <abstract>A crucial difference between single- and multi-document summarization is how <a href="https://en.wikipedia.org/wiki/Salience_(neuroscience)">salient content</a> manifests itself in the document(s). While such <a href="https://en.wikipedia.org/wiki/Content_(media)">content</a> may appear at the beginning of a single document, essential information is frequently reiterated in a set of documents related to a particular topic, resulting in an endorsement effect that increases information salience. In this paper, we model the cross-document endorsement effect and its utilization in multiple document summarization. Our method generates a synopsis from each document, which serves as an endorser to identify salient content from other documents. Strongly endorsed text segments are used to enrich a neural encoder-decoder model to consolidate them into an abstractive summary. The method has a great potential to learn from fewer examples to identify salient content, which alleviates the need for costly retraining when the set of documents is dynamically adjusted. Through extensive experiments on benchmark multi-document summarization datasets, we demonstrate the effectiveness of our proposed method over strong published baselines. Finally, we shed light on future research directions and discuss broader challenges of this task using a case study.</abstract>
      <url hash="23d249a2">2021.newsum-1.13</url>
      <bibkey>lebanoff-etal-2021-modeling</bibkey>
      <doi>10.18653/v1/2021.newsum-1.13</doi>
      <pwccode url="https://github.com/ucfnlp/endorser-summ" additional="false">ucfnlp/endorser-summ</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wcep">WCEP</pwcdataset>
    </paper>
    <paper id="14">
      <title>SUBSUME : A Dataset for Subjective Summary Extraction from Wikipedia Documents<fixed-case>SUBSUME</fixed-case>: A Dataset for Subjective Summary Extraction from <fixed-case>W</fixed-case>ikipedia Documents</title>
      <author><first>Nishant</first><last>Yadav</last></author>
      <author><first>Matteo</first><last>Brucato</last></author>
      <author><first>Anna</first><last>Fariha</last></author>
      <author><first>Oscar</first><last>Youngquist</last></author>
      <author><first>Julian</first><last>Killingback</last></author>
      <author><first>Alexandra</first><last>Meliou</last></author>
      <author><first>Peter</first><last>Haas</last></author>
      <pages>131–141</pages>
      <abstract>Many <a href="https://en.wikipedia.org/wiki/Application_software">applications</a> require generation of summaries tailored to the user’s information needs, i.e., their intent. Methods that express intent via explicit user queries fall short when query interpretation is subjective. Several <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> exist for <a href="https://en.wikipedia.org/wiki/Automatic_summarization">summarization</a> with objective intents where, for each document and intent (e.g., weather), a single summary suffices for all users. No <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> exist, however, for <a href="https://en.wikipedia.org/wiki/Intention_(philosophy)">subjective intents</a> (e.g., interesting places) where different users will provide different summaries. We present <a href="https://en.wikipedia.org/wiki/Subset">SUBSUME</a>, the first <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> for evaluation of SUBjective SUMmary Extraction systems. SUBSUME contains 2,200 (document, intent, summary) triplets over 48 Wikipedia pages, with ten intents of varying subjectivity, provided by 103 individuals over Mechanical Turk. We demonstrate statistically that the intents in <a href="https://en.wikipedia.org/wiki/Subspecies">SUBSUME</a> vary systematically in <a href="https://en.wikipedia.org/wiki/Subjectivity">subjectivity</a>. To indicate SUBSUME’s usefulness, we explore a collection of baseline algorithms for subjective extractive summarization and show that (i) as expected, example-based approaches better capture subjective intents than query-based ones, and (ii) there is ample scope for improving upon the baseline algorithms, thereby motivating further research on this challenging problem.</abstract>
      <url hash="6d84def1">2021.newsum-1.14</url>
      <bibkey>yadav-etal-2021-subsume</bibkey>
      <doi>10.18653/v1/2021.newsum-1.14</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/subsume">SubSumE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
    </paper>
    </volume>
</collection>