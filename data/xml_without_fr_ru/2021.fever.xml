<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.fever">
  <volume id="1" ingest-date="2021-10-28">
    <meta>
      <booktitle>Proceedings of the Fourth Workshop on Fact Extraction and VERification (FEVER)</booktitle>
      <editor><first>Rami</first><last>Aly</last></editor>
      <editor><first>Christos</first><last>Christodoulopoulos</last></editor>
      <editor><first>Oana</first><last>Cocarascu</last></editor>
      <editor><first>Zhijiang</first><last>Guo</last></editor>
      <editor><first>Arpit</first><last>Mittal</last></editor>
      <editor><first>Michael</first><last>Schlichtkrull</last></editor>
      <editor><first>James</first><last>Thorne</last></editor>
      <editor><first>Andreas</first><last>Vlachos</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Dominican Republic</address>
      <month>November</month>
      <year>2021</year>
    </meta>
    <frontmatter>
      <url hash="9a076571">2021.fever-1.0</url>
      <bibkey>fever-2021-fact</bibkey>
    </frontmatter>
    <paper id="1">
      <title>The Fact Extraction and VERification Over Unstructured and Structured information (FEVEROUS) Shared Task<fixed-case>VER</fixed-case>ification Over Unstructured and Structured information (<fixed-case>FEVEROUS</fixed-case>) Shared Task</title>
      <author><first>Rami</first><last>Aly</last></author>
      <author><first>Zhijiang</first><last>Guo</last></author>
      <author><first>Michael Sejr</first><last>Schlichtkrull</last></author>
      <author><first>James</first><last>Thorne</last></author>
      <author><first>Andreas</first><last>Vlachos</last></author>
      <author><first>Christos</first><last>Christodoulopoulos</last></author>
      <author><first>Oana</first><last>Cocarascu</last></author>
      <author><first>Arpit</first><last>Mittal</last></author>
      <pages>1–13</pages>
      <abstract>The Fact Extraction and VERification Over Unstructured and Structured information (FEVEROUS) shared task, asks participating systems to determine whether human-authored claims are Supported or Refuted based on evidence retrieved from <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a> (or NotEnoughInfo if the claim can not be verified). Compared to the FEVER 2018 shared task, the main challenge is the addition of structured data (tables and lists) as a source of evidence. The claims in the FEVEROUS dataset can be verified using only structured evidence, only unstructured evidence, or a mixture of both. Submissions are evaluated using the FEVEROUS score that combines label accuracy and evidence retrieval. Unlike FEVER 2018, FEVEROUS requires partial evidence to be returned for NotEnoughInfo claims, and the claims are longer and thus more complex. The shared task received 13 entries, six of which were able to beat the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline system</a>. The winning team was Bust a move !, achieving a FEVEROUS score of 27 % (+9 % compared to the baseline). In this paper we describe the shared task, present the full results and highlight commonalities and innovations among the participating systems.</abstract>
      <url hash="86f86949">2021.fever-1.1</url>
      <bibkey>aly-etal-2021-fact</bibkey>
      <doi>10.18653/v1/2021.fever-1.1</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/fever">FEVER</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/feverous">FEVEROUS</pwcdataset>
    </paper>
    <paper id="4">
      <title>FaBULOUS : Fact-checking Based on Understanding of Language Over Unstructured and Structured information<fixed-case>F</fixed-case>a<fixed-case>BULOUS</fixed-case>: Fact-checking Based on Understanding of Language Over Unstructured and Structured information</title>
      <author><first>Mostafa</first><last>Bouziane</last></author>
      <author><first>Hugo</first><last>Perrin</last></author>
      <author><first>Amine</first><last>Sadeq</last></author>
      <author><first>Thanh</first><last>Nguyen</last></author>
      <author><first>Aurélien</first><last>Cluzeau</last></author>
      <author><first>Julien</first><last>Mardas</last></author>
      <pages>31–39</pages>
      <abstract>As part of the FEVEROUS shared task, we developed a robust and finely tuned architecture to handle the joint retrieval and entailment on text data as well as structured data like tables. We proposed two <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training schemes</a> to tackle the hurdles inherent to multi-hop multi-modal datasets. The first one allows having a robust retrieval of full evidence sets, while the second one enables <a href="https://en.wikipedia.org/wiki/Logical_consequence">entailment</a> to take full advantage of noisy evidence inputs. In addition, our work has revealed important insights and potential avenue of research for future improvement on this kind of <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>. In preliminary evaluation on the FEVEROUS shared task test set, our system achieves 0.271 FEVEROUS score, with 0.4258 evidence recall and 0.5607 entailment accuracy.</abstract>
      <url hash="de37efe9">2021.fever-1.4</url>
      <bibkey>bouziane-etal-2021-fabulous</bibkey>
      <doi>10.18653/v1/2021.fever-1.4</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/feverous">FEVEROUS</pwcdataset>
    </paper>
    <paper id="5">
      <title>Team Papelo at FEVEROUS : Multi-hop Evidence Pursuit<fixed-case>FEVEROUS</fixed-case>: Multi-hop Evidence Pursuit</title>
      <author><first>Christopher</first><last>Malon</last></author>
      <pages>40–49</pages>
      <abstract>We develop a system for the FEVEROUS fact extraction and verification task that ranks an initial set of potential evidence and then pursues missing evidence in subsequent hops by trying to generate it, with a next hop prediction module whose output is matched against page elements in a predicted article. Seeking evidence with the next hop prediction module continues to improve FEVEROUS score for up to seven hops. Label classification is trained on possibly incomplete extracted evidence chains, utilizing hints that facilitate <a href="https://en.wikipedia.org/wiki/Numerical_analysis">numerical comparison</a>. The system achieves.281 FEVEROUS score and.658 label accuracy on the development set, and finishes in second place with.259 FEVEROUS score and.576 label accuracy on the test set.</abstract>
      <url hash="6a85bead">2021.fever-1.5</url>
      <bibkey>malon-2021-team</bibkey>
      <doi>10.18653/v1/2021.fever-1.5</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/fever">FEVER</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/feverous">FEVEROUS</pwcdataset>
    </paper>
    <paper id="8">
      <title>Stance Detection in German News Articles<fixed-case>G</fixed-case>erman News Articles</title>
      <author><first>Laura</first><last>Mascarell</last></author>
      <author><first>Tatyana</first><last>Ruzsics</last></author>
      <author><first>Christian</first><last>Schneebeli</last></author>
      <author><first>Philippe</first><last>Schlattner</last></author>
      <author><first>Luca</first><last>Campanella</last></author>
      <author><first>Severin</first><last>Klingler</last></author>
      <author><first>Cristina</first><last>Kadar</last></author>
      <pages>66–77</pages>
      <abstract>The widespread use of the <a href="https://en.wikipedia.org/wiki/Internet">Internet</a> and the rapid dissemination of information poses the challenge of identifying the veracity of its content. Stance detection, which is the task of predicting the position of a text in regard to a specific target (e.g. claim or debate question), has been used to determine the veracity of information in tasks such as rumor classification and fake news detection. While most of the work and available datasets for stance detection address short texts snippets extracted from textual dialogues, <a href="https://en.wikipedia.org/wiki/Social_media">social media platforms</a>, or <a href="https://en.wikipedia.org/wiki/Headline">news headlines</a> with a strong focus on the <a href="https://en.wikipedia.org/wiki/English_language">English language</a>, there is a lack of resources targeting long texts in other languages. Our contribution in this paper is twofold. First, we present a German dataset of debate questions and <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a> that is manually annotated for stance and emotion detection. Second, we leverage the dataset to tackle the supervised task of classifying the stance of a news article with regards to a debate question and provide baseline models as a reference for future work on stance detection in German news articles.</abstract>
      <url hash="4fb37b21">2021.fever-1.8</url>
      <bibkey>mascarell-etal-2021-stance</bibkey>
      <doi>10.18653/v1/2021.fever-1.8</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/x-stance">x-stance</pwcdataset>
    </paper>
    <paper id="9">
      <title>FANG-COVID : A New Large-Scale Benchmark Dataset for Fake News Detection in German<fixed-case>FANG</fixed-case>-<fixed-case>COVID</fixed-case>: A New Large-Scale Benchmark Dataset for Fake News Detection in <fixed-case>G</fixed-case>erman</title>
      <author><first>Justus</first><last>Mattern</last></author>
      <author><first>Yu</first><last>Qiao</last></author>
      <author><first>Elma</first><last>Kerz</last></author>
      <author><first>Daniel</first><last>Wiechmann</last></author>
      <author><first>Markus</first><last>Strohmaier</last></author>
      <pages>78–91</pages>
      <abstract>As the world continues to fight the COVID-19 pandemic, it is simultaneously fighting an ‘infodemic’   a flood of <a href="https://en.wikipedia.org/wiki/Disinformation">disinformation</a> and spread of <a href="https://en.wikipedia.org/wiki/Conspiracy_theory">conspiracy theories</a> leading to health threats and the division of society. To combat this infodemic, there is an urgent need for <a href="https://en.wikipedia.org/wiki/Benchmarking">benchmark datasets</a> that can help researchers develop and evaluate <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> geared towards automatic detection of disinformation. While there are increasing efforts to create adequate, open-source benchmark datasets for <a href="https://en.wikipedia.org/wiki/English_language">English</a>, comparable resources are virtually unavailable for <a href="https://en.wikipedia.org/wiki/German_language">German</a>, leaving research for the <a href="https://en.wikipedia.org/wiki/German_language">German language</a> lagging significantly behind. In this paper, we introduce the new benchmark dataset FANG-COVID consisting of 28,056 real and 13,186 fake German news articles related to the COVID-19 pandemic as well as data on their propagation on <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>. Furthermore, we propose an explainable textual- and social context-based model for <a href="https://en.wikipedia.org/wiki/Fake_news">fake news detection</a>, compare its performance to black-box models and perform feature ablation to assess the relative importance of human-interpretable features in distinguishing <a href="https://en.wikipedia.org/wiki/Fake_news">fake news</a> from authentic news.</abstract>
      <url hash="f99d4cc6">2021.fever-1.9</url>
      <bibkey>mattern-etal-2021-fang</bibkey>
      <doi>10.18653/v1/2021.fever-1.9</doi>
      <pwccode url="https://github.com/justusmattern/fang-covid" additional="false">justusmattern/fang-covid</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/coaid">CoAID</pwcdataset>
    </paper>
    <paper id="11">
      <title>Automatic Fact-Checking with Document-level Annotations using BERT and Multiple Instance Learning<fixed-case>BERT</fixed-case> and Multiple Instance Learning</title>
      <author><first>Aalok</first><last>Sathe</last></author>
      <author><first>Joonsuk</first><last>Park</last></author>
      <pages>101–107</pages>
      <abstract>Automatic fact-checking is crucial for recognizing misinformation spreading on the internet. Most existing fact-checkers break down the process into several subtasks, one of which determines candidate evidence sentences that can potentially support or refute the claim to be verified ; typically, evidence sentences with gold-standard labels are needed for this. In a more realistic setting, however, such <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentence-level annotations</a> are not available. In this paper, we tackle the natural language inference (NLI) subtaskgiven a document and a (sentence) claim, determine whether the document supports or refutes the claimonly using document-level annotations. Using fine-tuned BERT and <a href="https://en.wikipedia.org/wiki/Multiple_instance_learning">multiple instance learning</a>, we achieve 81.9 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>, significantly outperforming the existing results on the WikiFactCheck-English dataset.</abstract>
      <url hash="b7136d60">2021.fever-1.11</url>
      <bibkey>sathe-park-2021-automatic</bibkey>
      <doi>10.18653/v1/2021.fever-1.11</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/fever">FEVER</pwcdataset>
    </paper>
    <paper id="12">
      <title>Neural Re-rankers for Evidence Retrieval in the FEVEROUS Task<fixed-case>FEVEROUS</fixed-case> Task</title>
      <author><first>Mohammed</first><last>Saeed</last></author>
      <author><first>Giulio</first><last>Alfarano</last></author>
      <author><first>Khai</first><last>Nguyen</last></author>
      <author><first>Duc</first><last>Pham</last></author>
      <author><first>Raphael</first><last>Troncy</last></author>
      <author><first>Paolo</first><last>Papotti</last></author>
      <pages>108–112</pages>
      <abstract>Computational fact-checking has gained a lot of traction in the machine learning and natural language processing communities. A plethora of solutions have been developed, but methods which leverage both structured and unstructured information to detect <a href="https://en.wikipedia.org/wiki/Misinformation">misinformation</a> are of particular relevance. In this paper, we tackle the FEVEROUS (Fact Extraction and VERification Over Unstructured and Structured information) challenge which consists of an open source baseline system together with a benchmark dataset containing 87,026 verified claims. We extend this baseline model by improving the evidence retrieval module yielding the best evidence F1 score among the competitors in the challenge leaderboard while obtaining an overall FEVEROUS score of 0.20 (5th best ranked system).</abstract>
      <url hash="7dc480f8">2021.fever-1.12</url>
      <bibkey>saeed-etal-2021-neural</bibkey>
      <doi>10.18653/v1/2021.fever-1.12</doi>
    </paper>
    <paper id="13">
      <title>A Fact Checking and Verification System for FEVEROUS Using a Zero-Shot Learning Approach<fixed-case>FEVEROUS</fixed-case> Using a Zero-Shot Learning Approach</title>
      <author><first>Orkun</first><last>Temiz</last></author>
      <author><first>Özgün Ozan</first><last>Kılıç</last></author>
      <author><first>Arif Ozan</first><last>Kızıldağ</last></author>
      <author><first>Tuğba</first><last>Taşkaya Temizel</last></author>
      <pages>113–120</pages>
      <abstract>In this paper, we propose a novel fact checking and verification system to check claims against <a href="https://en.wikipedia.org/wiki/Content_(media)">Wikipedia content</a>. Our system retrieves relevant Wikipedia pages using <a href="https://en.wikipedia.org/wiki/Anserini">Anserini</a>, uses BERT-large-cased question answering model to select correct evidence, and verifies claims using XLNET natural language inference model by comparing it with the evidence. Table cell evidence is obtained through looking for entity-matching cell values and TAPAS table question answering model. The <a href="https://en.wikipedia.org/wiki/Pipeline_transport">pipeline</a> utilizes zero-shot capabilities of existing <a href="https://en.wikipedia.org/wiki/Computer_simulation">models</a> and all the <a href="https://en.wikipedia.org/wiki/Computer_simulation">models</a> used in the <a href="https://en.wikipedia.org/wiki/Pipeline_transport">pipeline</a> requires no additional training. Our <a href="https://en.wikipedia.org/wiki/System">system</a> got a <a href="https://en.wikipedia.org/wiki/Extreme_value">FEVEROUS score</a> of 0.06 and a <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">label accuracy</a> of 0.39 in <a href="https://en.wikipedia.org/wiki/Extreme_value">FEVEROUS challenge</a>.</abstract>
      <url hash="4eeba4d4">2021.fever-1.13</url>
      <bibkey>temiz-etal-2021-fact</bibkey>
      <doi>10.18653/v1/2021.fever-1.13</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/fever">FEVER</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/feverous">FEVEROUS</pwcdataset>
    <title_es>Un sistema de verificación y verificación de datos para FEVEROUS mediante un enfoque de aprendizaje de tiro cero</title_es>
      <title_pt>Um sistema de verificação e verificação de fatos para FEVEROUS usando uma abordagem de aprendizado zero-shot</title_pt>
      <title_ar>نظام التحقق من الحقائق والتحقق منها لـ FEVEROUS باستخدام نهج التعلم الصفري</title_ar>
      <title_ja>ゼロショット学習アプローチを用いたFEVEROUSのファクトチェックと検証システム</title_ja>
      <title_zh>用零镜头学者FEVEROUS核验系统</title_zh>
      <title_hi>एक शून्य शॉट सीखने के दृष्टिकोण का उपयोग कर बुखार के लिए एक तथ्य की जाँच और सत्यापन प्रणाली</title_hi>
      <title_ga>C처ras Seice찼la agus F챠oraithe F챠ric챠 do FHEABHS횣 Ag 횣s찼id Cur Chuige Foghlama Nialais</title_ga>
      <title_el>Ένα σύστημα ελέγχου και επαλήθευσης γεγονότων για τη χρήση μιας προσέγγισης μηδενικής μάθησης</title_el>
      <title_ka>Name</title_ka>
      <title_it>Un sistema di controllo e verifica dei fatti per FEVEROUS utilizzando un approccio di apprendimento a colpo zero</title_it>
      <title_mk>Name</title_mk>
      <title_lt>FAKTų tikrinimo ir tikrinimo sistema, taikoma NULL mokymosi metodui</title_lt>
      <title_ml>FEVEROUS-നുള്ള ഫാക്റ്റ് പരിശോധിക്കുന്നതും പരിശോധിക്കുന്നതുമായ സിസ്റ്റം പൂജ്യ- ഷോട്ട് പഠിക്കുന്നതിന</title_ml>
      <title_hu>Tényellenőrző és ellenőrző rendszer a FEVEROUS számára a nulla lövéses tanulási megközelítés alkalmazásával</title_hu>
      <title_mt>A Fact Checking and Verification System for FEVEROUS Using a Zero-Shot Learning Approach</title_mt>
      <title_no>Name</title_no>
      <title_pl>System kontroli faktów i weryfikacji dla FEVEROUS wykorzystujący zerowe podejście do uczenia się</title_pl>
      <title_ms>Name</title_ms>
      <title_mn>НҮБ-Shot суралцах ойлголтыг ашиглах үнэний шалгалт болон шалгалт систем</title_mn>
      <title_sr>Sistem provjere i provjere činjenica za četiri godine koristeći pristup učenju nula pucnjava</title_sr>
      <title_ro>Un sistem de verificare și verificare a faptelor pentru FEVEROUS folosind o abordare de învățare zero-shot</title_ro>
      <title_kk>МЕСЕРДЕР үшін факттерді тексеру мен тексеру жүйесіName</title_kk>
      <title_so>Isticmaalka barashada iskuulka</title_so>
      <title_ur>Name</title_ur>
      <title_si>Name</title_si>
      <title_sv>Ett system för faktakontroll och verifiering av FEVEROUS med hjälp av en noll-skott inlärningsmetod</title_sv>
      <title_ta>Name</title_ta>
      <title_vi>Một hệ thống kiểm tra thực tế cho đáng sợ sử dụng phương pháp học bắn không.</title_vi>
      <title_uz>Name</title_uz>
      <title_bg>Система за проверка и проверка на фактите за FEVEROUS, използваща подход за обучение без изстрел</title_bg>
      <title_da>Et system til kontrol og verifikation af fakta for FEVEROUS ved hjælp af en Zero-Shot Learning Approach</title_da>
      <title_nl>Een feitencontrole- en verificatiesysteem voor FEVEROUS met behulp van een Zero-Shot Learning aanpak</title_nl>
      <title_hr>Sistem provjere i provjere činjenica za NEKOLIKO KORISTI pristup učenju nule pucnje</title_hr>
      <title_de>Ein Fact Checking und Verification System für FEVEROUS unter Verwendung eines Zero-Shot Learning Ansatzes</title_de>
      <title_id>Sistem Pemeriksaan dan Verifikasi Fakta untuk FEVEROUS menggunakan pendekatan Belajar Zero-Shot</title_id>
      <title_ko>영포 학습 방법에 기초한 열사실 검사 및 검증 시스템</title_ko>
      <title_fa>Name</title_fa>
      <title_sw>Mfumo wa Kuchungulia na Uchunguzi wa Ukweli wa FEVEROUS kwa kutumia Mafunzo ya Kujifunza Siro-Shot</title_sw>
      <title_tr>FEVEROUS Zero-Shot öwrenmek Approsyny ullanýan</title_tr>
      <title_am>የውይይት መድረክ</title_am>
      <title_hy>Comment</title_hy>
      <title_az>Sıfır-Shot Öyrənmə Yaxınlığını istifadə etmək və Verilmə Sistemi</title_az>
      <title_af>Name</title_af>
      <title_sq>Një sistem kontrollimi dhe verifikimi i fakteve për FEVEROUS duke përdorur një metodë mësimi zero-shot</title_sq>
      <title_bn>ফেভেরোসের জন্য একটি ফ্যাক্ট পরীক্ষা এবং সার্ফিকেশন সিস্টেম ব্যবহার করে জিরো- শুট শিক্ষা ব্যবহার করে</title_bn>
      <title_cs>Systém kontroly a ověřování faktů pro FEVEROUS s využitím přístupu nulového učení</title_cs>
      <title_ca>Un sistema de verificació i verificació de fets per a FEVEROUS utilitzant un enfocament d'aprenentatge zero-shot</title_ca>
      <title_et>Faktide kontrollimise ja kontrollimise süsteem FEVEROUS kasutades null-shot õppimise lähenemisviisi</title_et>
      <title_fi>Faktojen tarkistus- ja todentamisjärjestelmä FEVEROUS-järjestelmälle käyttäen nollashot-oppimismenetelmää</title_fi>
      <title_bs>Sistem provjere i provjere činjenica za četiri godine koristeći pristup učenju nule pucnje</title_bs>
      <title_jv>1</title_jv>
      <title_ha>A Fact Checking and Verification System for FEVEROUS Using a Zero-Shot Learning Approach</title_ha>
      <title_sk>Sistem za preverjanje dejstev in preverjanje za FEVEROUS z uporabo pristopa učenja brez poskusa</title_sk>
      <title_bo>A Fact Checking and Verification System for FEVEROUS Using a Zero-Shot Learning Approach</title_bo>
      <title_he>A Fact Checking and Verification System for FEVEROUS Using a Zero-Shot Learning Approach</title_he>
      <abstract_es>En este artículo, proponemos un novedoso sistema de verificación y verificación de datos para comparar las afirmaciones con el contenido de Wikipedia. Nuestro sistema recupera páginas relevantes de Wikipedia con Anserini, utiliza el modelo de respuesta a preguntas de casos grandes de Bert para seleccionar la evidencia correcta y verifica las afirmaciones utilizando el modelo de inferencia de lenguaje natural XLNET comparándola con la evidencia. La evidencia de celda de tabla se obtiene buscando valores de celda coincidentes con la entidad y el modelo de respuesta a preguntas de tabla TAPAS. El pipeline utiliza las capacidades zero-shot de los modelos existentes y todos los modelos utilizados en el pipeline no requieren capacitación adicional. Nuestro sistema obtuvo una puntuación FEVEROUS de 0.06 y una precisión de etiqueta de 0.39 en el desafío FEVEROUS.</abstract_es>
      <abstract_ar>في هذه الورقة ، نقترح نظامًا جديدًا للتحقق من الحقائق والتحقق منها للتحقق من الادعاءات ضد محتوى ويكيبيديا. يقوم نظامنا باسترداد صفحات ويكيبيديا ذات الصلة باستخدام Anserini ، ويستخدم نموذج BERT للإجابة على الأسئلة ذات الأحرف الكبيرة لتحديد الدليل الصحيح ، والتحقق من المطالبات باستخدام نموذج الاستدلال باللغة الطبيعية لـ XLNET من خلال مقارنتها بالأدلة. يتم الحصول على دليل خلية الجدول من خلال البحث عن قيم خلية مطابقة الكيان ونموذج الإجابة على أسئلة جدول TAPAS. يستخدم خط الأنابيب إمكانات إطلاق النار الصفري للنماذج الحالية ولا تتطلب جميع النماذج المستخدمة في خط الأنابيب أي تدريب إضافي. حصل نظامنا على درجة FEVEROUS قدرها 0.06 ودقة تسمية 0.39 في تحدي FEVEROUS.</abstract_ar>
      <abstract_pt>Neste artigo, propomos um novo sistema de verificação e verificação de fatos para verificar reivindicações contra o conteúdo da Wikipédia. Nosso sistema recupera as páginas relevantes da Wikipédia usando o Anserini, usa o modelo BERT de resposta a perguntas em letras maiúsculas para selecionar evidências corretas e verifica as alegações usando o modelo de inferência de linguagem natural XLNET comparando-o com as evidências. A evidência da célula da tabela é obtida por meio da procura de valores de célula de correspondência de entidade e do modelo de resposta a perguntas da tabela TAPAS. O pipeline utiliza recursos de tiro zero de modelos existentes e todos os modelos usados no pipeline não requerem treinamento adicional. Nosso sistema obteve uma pontuação FEVEROUS de 0,06 e uma precisão de etiqueta de 0,39 no desafio FEVEROUS.</abstract_pt>
      <abstract_ja>本稿では、ウィキペディアのコンテンツに対する主張をチェックするための新規の事実確認・検証システムを提案する。当社のシステムは、Anseriniを使用して関連するWikipediaページを取得し、BERT大文字の質問回答モデルを使用して正しい証拠を選択し、それを証拠と比較することによってXLNET自然言語推論モデルを使用して主張を検証します。テーブルセルの証拠は、エンティティマッチングセル値とTAPASテーブル質問応答モデルを探すことによって得られる。パイプラインは既存のモデルのゼロショット機能を利用しており、パイプラインで使用されるすべてのモデルは追加のトレーニングを必要としません。当社のシステムは、FEVEROUSチャレンジで0.06のFEVEROUSスコアと0.39のラベル精度を得ました。</abstract_ja>
      <abstract_zh>本文中,发一新事检查和验系统,以检维基百科声明。 臣等统用Anserini检维基百科页面,用BERT大例问答模形以择正证,并用XLNET自然语言推理模型校证以验声明。 求其单元格直与TAPAS表问以得单元格证。 管道用现模的零发功能,管道中所用的所有模形都不要额外训练。 系于 FEVEROUS 挑战得 FEVEROUS 分数 0.06 分,标准确度为 0.39。</abstract_zh>
      <abstract_hi>इस पेपर में, हम विकिपीडिया सामग्री के खिलाफ दावों की जांच करने के लिए एक उपन्यास तथ्य जांच और सत्यापन प्रणाली का प्रस्ताव करते हैं। हमारा सिस्टम Anserini का उपयोग करके प्रासंगिक विकिपीडिया पृष्ठों को पुनः प्राप्त करता है, सही सबूत का चयन करने के लिए BERT-large-cased question answering मॉडल का उपयोग करता है, और सबूत के साथ तुलना करके XLNET प्राकृतिक भाषा अनुमान मॉडल का उपयोग करके दावों को सत्यापित करता है। तालिका सेल साक्ष्य एंटिटी-मिलान सेल मानों और TAPAS तालिका प्रश्न उत्तर देने वाले मॉडल की तलाश के माध्यम से प्राप्त किया जाता है। पाइपलाइन मौजूदा मॉडल की शून्य-शॉट क्षमताओं का उपयोग करती है और पाइपलाइन में उपयोग किए जाने वाले सभी मॉडलों को कोई अतिरिक्त प्रशिक्षण की आवश्यकता नहीं होती है। हमारे सिस्टम को 0.06 का एक बुखार स्कोर और 0.39 की लेबल सटीकता मिली है।</abstract_hi>
      <abstract_ga>Sa pháipéar seo, molaimid córas nua seiceála agus fíoraithe fíricí chun éilimh i gcoinne ábhar Vicipéide a sheiceáil. Aisghabhann ár gcóras leathanaigh Vicipéide ábhartha ag baint úsáide as Anserini, úsáideann múnla freagartha ceisteanna cás-mhór BERT chun an fhianaise cheart a roghnú, agus fíoraíonn sé éilimh ag baint úsáide as samhail tátail nádúrtha teanga XLNET trína chur i gcomparáid leis an bhfianaise. Faightear fianaise cille tábla trí luachanna cille aonán-mheaitseála a lorg agus samhail freagartha ceisteanna tábla TAPAS. Baineann an phíblíne úsáid as cumais nialas lámhaigh na samhlacha atá ann cheana féin agus níl aon oiliúint bhreise ag teastáil ó na samhlacha go léir a úsáidtear sa phíblíne. Fuair ár gcóras scór FEVEROUS de 0.06 agus cruinneas lipéad 0.39 i ndúshlán FEVEROUS.</abstract_ga>
      <abstract_el>Σε αυτή την εργασία, προτείνουμε ένα νέο σύστημα ελέγχου και επαλήθευσης γεγονότων για τον έλεγχο ισχυρισμών έναντι περιεχομένου της Βικιπαίδειας. Το σύστημά μας ανακτά σχετικές σελίδες της Βικιπαίδειας χρησιμοποιώντας Ανσέρινι, χρησιμοποιεί μοντέλο απάντησης μεγάλων περιπτώσεων για να επιλέξει σωστά αποδεικτικά στοιχεία και επαληθεύει ισχυρισμούς χρησιμοποιώντας μοντέλο συμπερασμάτων φυσικής γλώσσας συγκρίνοντάς τα με τα αποδεικτικά στοιχεία. Τα στοιχεία κελιών πίνακα λαμβάνονται μέσω αναζήτησης τιμών κελιών που ταιριάζουν με οντότητα και μοντέλου απάντησης σε ερωτήσεις πίνακα TAPAS. Ο αγωγός χρησιμοποιεί τις δυνατότητες μηδενικής βολής των υφιστάμενων μοντέλων και όλα τα μοντέλα που χρησιμοποιούνται στον αγωγό δεν απαιτούν πρόσθετη εκπαίδευση. Το σύστημά μας πήρε ένα ΠΕΡΑΣΜΑ σκορ 0.06 και μια ακρίβεια ετικετών 0.39 στην πρόκληση ΠΕΡΑΣΜΑ.</abstract_el>
      <abstract_hu>Ebben a tanulmányban egy új tényellenőrző és ellenőrző rendszert javasolunk a Wikipédia tartalmával szembeni igények ellenőrzésére. Rendszerünk Anserini segítségével lekérdezi a releváns Wikipedia oldalakat, BERT-nagybetűs kérdésválasztási modellt használ a helyes bizonyítékok kiválasztásához, és XLNET természetes nyelvű következtetési modellt használva ellenőrzi az állításokat a bizonyítékokkal való összehasonlításával. A táblázatcellák bizonyítékait az entitáshoz illeszkedő cellaértékek és a TAPAS táblázat kérdésre válaszoló modell keresésével szerezzük meg. A csővezeték a meglévő modellek zéró lövési képességeit használja, és a csővezetékben használt összes modell nem igényel további képzést. Rendszerünk a FEVEROUS pontszámot 0,06-ra és a címke pontosságát 0,39-re kapta a FEVEROUS kihívásban.</abstract_hu>
      <abstract_ka>ამ დომენტში ჩვენ პრომენტური ფაქტის შემოწმება და შემოწმება სისტემა, რომელიც ვიკიპედიაში შესახებ წინაწმება. ჩვენი სისტემის შესაბამისი Wikipedia გვერდების გამოყენება Anserini, გამოყენება BERT- დიდი კითხვის შესაბამისი მოდელის შესაბამისათვის მარტივი წესების შესაბამისათვის, და დარწმება წესების გამოყენება XLNET ნა ცხრილის უჯრედების მოწმება მიიღება განსაზღვრებული უჯრედების მნიშვნელობით და TAPAS ცხრილის მოკითხვის მოდელი. პრობლინის გამოყენება არსებული მოდელების შესაძლებლობას და ყველა მოდელების გამოყენება პრობლინში არსებობს დამატებული განაკლება. ჟთჟრვმარა ნთ თმა ნწკჲლკჲ ოჲლსფაგანვ ჲრ 0,06 თ ლთბვრკა ოპაგთლნჲჟრ ჲრ 0,39 გ გჟთფკთ ოპვეგთე.</abstract_ka>
      <abstract_it>In questo articolo, proponiamo un nuovo sistema di verifica e verifica dei fatti per verificare i reclami contro i contenuti di Wikipedia. Il nostro sistema recupera le pagine Wikipedia pertinenti utilizzando Anserini, utilizza il modello BERT-large cased question responsing per selezionare le prove corrette e verifica le affermazioni utilizzando il modello di inferenza del linguaggio naturale XLNET confrontandolo con le prove. L'evidenza delle celle della tabella è ottenuta cercando i valori delle celle corrispondenti all'entità e il modello di risposta alle domande della tabella TAPAS. La pipeline utilizza funzionalità zero-shot dei modelli esistenti e tutti i modelli utilizzati nella pipeline non richiedono alcuna formazione aggiuntiva. Il nostro sistema ha ottenuto un punteggio FEVEROUS di 0,06 e una precisione dell'etichetta di 0,39 nella sfida FEVEROUS.</abstract_it>
      <abstract_kk>Бұл қағазда, Википедия мазмұнына қарсы жаңа тексеру жүйесін тексеру және тексеру жүйесін ұсынамыз. Біздің жүйеміз Anserini қолданып маңызды Wikipedia парақтарын алу үшін BERT- үлкен сұрақ жауап үлгісін дұрыс мәліметті таңдау үшін қолданады, және XLNET табиғи тілдердің басқару үлгісін мәліметтер Кесте ұяшықтарының мәндері мен TAPAS кестесінің сұрау үлгісін іздеп табылады. Қызық жолы бар үлгілердің нөл түрлендіру мүмкіндігін пайдаланатын және қосымша оқыту керек болмайды. Біздің жүйеміз 0,06 деген деңгейінде бірнеше нәтижесі бар және 0,39 деңгейіндегі дұрыс жазылды.</abstract_kk>
      <abstract_mk>In this paper, we propose a novel fact checking and verification system to check claims against Wikipedia content.  Our system retrieves relevant Wikipedia pages using Anserini, uses BERT-large-cased question answering model to select correct evidence, and verifies claims using XLNET natural language inference model by comparing it with the evidence.  Доказите за табеловите ќелии се добиваат преку барање на вредности на ќелиите кои се совпаѓаат со ентитетите и моделот на одговор на табелата на TAPAS. Гасоводот ги користи нула-стрелачките способности на постоечките модели и сите модели кои се користат во гасоводот не бараат дополнителна обука. Нашиот систем доби ФЕВЕРОС оценка од 0,06 и точност на етикетата од 0,39 во ФЕВЕРОС предизвик.</abstract_mk>
      <abstract_ms>Dalam kertas ini, kami cadangkan sistem pemeriksaan fakta baru dan pemeriksaan untuk memeriksa klaim terhadap kandungan Wikipedia. Sistem kami mengambil halaman Wikipedia yang berkaitan menggunakan Anserini, menggunakan model BERT-besar-cased menjawab soalan untuk memilih bukti yang betul, dan mengesahkan klaim menggunakan model XLNET bahasa kebiasaan dengan membandingkannya dengan bukti. Table cell evidence is obtained through looking for entity-matching cell values and TAPAS table question answering model.  Saluran paip menggunakan kemampuan tembakan sifar bagi model yang ada dan semua model yang digunakan dalam saluran paip tidak memerlukan latihan tambahan. Sistem kita mendapat skor FEVEROUS 0.06 dan ketepatan label 0.39 dalam tantangan FEVEROUS.</abstract_ms>
      <abstract_ml>ഈ പത്രത്തില്‍, വിക്കിപിഡിയയുടെ ഉള്ളടക്കം പരിശോധിക്കുന്നതിനും പരിശോധിക്കുന്ന ഒരു നോവല്‍ സത്യം പരിശോധിക്കു നമ്മുടെ സിസ്റ്റത്തില്‍ വിക്കിപീഡിയയുടെ പേജുകള്‍ ആന്‍സെരിനി ഉപയോഗിച്ച് വില്‍ക്കിപ്പീഡിയയുടെ പേജുകള്‍ വീണ്ടെടുക്കുന്നു. ബെര്‍ട്ടി-വലിയ കാസ് ചോദ സാധാരണ സെല്‍ മൂല്യങ്ങള്‍ തേടുന്നതിനാല്‍ ടേബിളിലെ സെല്‍ തെളിവുകള്‍ ലഭ്യമാകുന്നു. ടാപാസ് ടേബിളിന്റെ മോഡലിന് ഈ പൈപ്പെലൈന്‍ നിലവിലുള്ള മോഡലുകളുടെ പൂജ്യത്തിന്റെ കഴിവുകള്‍ ഉപയോഗിക്കുന്നു. പൈപ്പെലൈനില്‍ ഉപയോഗിക്കുന്ന എല്ലാ മ നമ്മുടെ സിസ്റ്റത്തിന്റെ ഒരു ഫെവെറോസ് സ്കോര്‍ 0. 06 കിട്ടിയിരുന്നു. ഫെവെറോസ് ച്യാലേവലില്‍ 0.39 ന്റെ ലേബ്റ്റ്</abstract_ml>
      <abstract_lt>Šiame dokumente siūlome naują faktų tikrinimo ir tikrinimo sistemą, skirtą patikrinti teiginius dėl Wikipedia turinio. Our system retrieves relevant Wikipedia pages using Anserini, uses BERT-large-cased question answering model to select correct evidence, and verifies claims using XLNET natural language inference model by comparing it with the evidence.  lentelės langelių įrodymai gaunami ieškant subjektui atitinkančių langelių verčių ir TAPAS lentelės klausimų atsakymo modelio. Vamzdynas naudoja esamų modelių nulinio nuotraukos pajėgumus, o visiems vamzdynuose naudojamiems modeliams papildomo mokymo nereikia. Mūsų sistema gavo FEVEROUS 0,06 ir 0,39 etiketės tikslumą FEVEROUS iššūkyje.</abstract_lt>
      <abstract_pl>W niniejszym artykule proponujemy nowy system sprawdzania faktów i weryfikacji w celu sprawdzenia roszczeń w stosunku do treści Wikipedii. Nasz system pobiera odpowiednie strony Wikipedii przy użyciu Anserini, wykorzystuje model odpowiedzi na duże pytania BERT do wyboru prawidłowych dowodów i weryfikuje twierdzenia za pomocą modelu wnioskowania języka naturalnego XLNET poprzez porównanie go z dowodami. Dowody na komórkę tabeli uzyskuje się poprzez wyszukiwanie wartości komórek pasujących do podmiotów i modelu odpowiedzi na pytania tabeli TAPAS. Rurociąg wykorzystuje możliwości zero-shot istniejących modeli, a wszystkie modele używane w rurociągu nie wymagają dodatkowych szkoleń. Nasz system otrzymał FEVEROUS wynik 0.06 i dokładność etykiety 0.39 w FEVEROUS challenge.</abstract_pl>
      <abstract_no>I denne papiret foreslår vi eit nytt faktisk kontrollsystem og kontrollsystem for å sjekke etterspørsel mot Wikipediainnhaldet. Systemet vårt hentar relevante Wikipedia-sider med Anserini, brukar BERT-stor spørsmønsterelement for å velja korrige beviser, og stadfestar etterspørsmål med XLNET-naturspråk-infeksjonsmodul ved å sammenligne det med bevisene. Tabellcellevidentitet blir henta gjennom å søkja etter cellevidentitet og TAPAS- tabellspørsmønsterelement. Røytlinjen brukar nullstart for eksisterande modeller og alle modelane som brukar i røytlinjen krev ingen ekstra trening. Sistemet vårt fikk ein FEVEROUR PORT av 0,06 og eit merkelapp nøyaktig av 0,39 i FEVEROUR utfordring.</abstract_no>
      <abstract_ro>În această lucrare, propunem un nou sistem de verificare și verificare a faptelor pentru a verifica revendicările împotriva conținutului Wikipedia. Sistemul nostru recuperează paginile Wikipedia relevante folosind Anserini, utilizează modelul BERT de răspuns la întrebări cu cazuri mari pentru a selecta dovezile corecte și verifică afirmațiile folosind modelul XLNET de inferență a limbajului natural prin compararea acestuia cu dovezile. Dovezile celulelor tabelului sunt obținute prin căutarea valorilor celulelor care corespund entităților și modelul TAPAS de răspuns la întrebări tabelului. Conducta utilizează capacitățile zero-shot ale modelelor existente și toate modelele utilizate în conductă nu necesită instruire suplimentară. Sistemul nostru a obținut un scor FEVEROUS de 0.06 și o precizie a etichetelor de 0.39 în proba FEVEROUS.</abstract_ro>
      <abstract_sr>U ovom papiru predlažemo novi sistem provjere i verificije da proveri tvrdnje protiv sadržaja Wikipedije. Naš sistem dobija relevantne Wikipedia stranice koristeći Anserini, koristi model odgovarajućeg pitanja iz BERT-a, kako bi odabrali ispravne dokaze, i potvrdila tvrdnja koristeći model infekcije prirodnog jezika XLNET uspoređujući ga s dokazima. Pronaðeni su dokazi za tablice kroz potragu za vrijednostima stanica koje odgovaraju entiteti i model odgovarajućeg pitanja tablice TAPAS. Naftovna linija koristi sposobnosti postojećih modela bez pucnjave, a svi modeli koji se koriste u kanalizaciji ne zahtevaju dodatnu obuku. Naš sistem je dobio nekoliko rezultata od 0,06 i tačnost etiketa od 0,39 u četvrtom izazovu.</abstract_sr>
      <abstract_mn>Энэ цаасан дээр бид Википедийн хэмжээсүүдийг зөвшөөрөхийн тулд шинэ үнэнийг шалгах, шалгах системийг санал болгож байна. Бидний систем Ансерини ашиглан хамааралтай Wikipedia хуудас гаргадаг. БЕРТ-ын том асуулт асуух загварыг зөв баталгааг сонгоход ашигладаг. XLNET байгалийн хэл халдварын загварыг баталгаатай харьцуулахад хэлбэрийг шалгаж байна. Хүснэгтийн эсийн баталгаа нь нэгж холбоотой эсийн утга болон TAPAS хүснэгтийн асуултын хариултын загварыг хайж олж авдаг. Хөдөлгөөн шугам нь суурилсан загварын 0-шугам чадварыг ашигладаг. Хөдөлгөөн шугам дээр хэрэглэгдсэн бүх загварууд нэмэлт суралцах шаардлагагүй. Бидний систем 0.06 хэмжээний тоо, мөн 0.39 хэмжээний шалгалтын тодорхойлолтой байсан.</abstract_mn>
      <abstract_si>මේ පැත්තට, අපි විකිපිඩියාව සම්බන්ධ විරුද්ධ පරීක්ෂණය සහ පරීක්ෂණ පද්ධතියක් පරීක්ෂා කරනවා. අපේ පද්ධතිය ඇන්සෙරිනි භාවිතා විකිපිඩියා පිටුවන් ප්‍රශ්න ප්‍රශ්නයක් භාවිත කරනවා, සාක්ෂි තෝරාගන්න සඳහා BERT-ලොකු ප්‍රශ්නයක්  Name Name අපේ පද්ධතියට 0.06 වල ස්කෝර් එකක් තියෙනවා ඒ වගේම ලේබල් එකක් හරියට 0.39 වල් අභ්‍යාගයක් තියෙනවා.</abstract_si>
      <abstract_mt>In this paper, we propose a novel fact checking and verification system to check claims against Wikipedia content.  Is-sistema tagħna tiġbor il-paġni rilevanti tal-Wikipedia bl-użu ta’ Anserini, tuża mudell ta’ tweġiba għall-mistoqsijiet b’każijiet kbar BERT biex tagħżel evidenza korretta, u tivverifika l-pretensjonijiet bl-użu tal-mudell ta’ inferenza lingwistika naturali XLNET billi tqabbilha mal-evidenza. L-evidenza taċ-ċelluli tat-tabella tinkiseb billi jiġu mfittxija valuri taċ-ċelluli li jaqblu mal-entità u l-mudell tat-tweġiba għall-mistoqsijiet tat-tabella TAPAS. Il-pajpijiet jużaw il-kapaċitajiet ta’ qtugħ żero ta’ mudelli eżistenti u l-mudelli kollha użati fil-pajpijiet ma jeħtieġu l-ebda taħriġ addizzjonali. Is-sistema tagħna kisbet punteġġ FEVEROUS ta’ 0.06 u preċiżjoni tat-tikketta ta’ 0.39 fl-isfida FEVEROUS.</abstract_mt>
      <abstract_so>Warqadan waxaynu soo jeedaynaa nidaamka warqadda si aan u xaqiijinno iyo xaqiijinno nidaamka warqadda ee ku qoran waxyaabaha Wikipedia. Systemkanagu wuxuu soo celiyaa bogagga Wikipedia ee la isticmaalayo Anserini, wuxuu isticmaalaa qaababka su'aalaha ay ka jawaabayso BERT-large-cash si uu u doorto caddeynta saxda ah, wuxuuna xaqiijiyaa caddeynta isticmaalka sameynta qaababka dhibaatada afka asalka ah ee XLNET. Macluumaadka koobiga waxaa laga helaa marka aad raadineyso qiimaha qoyska ee isku mid ah iyo su'aalaha miiska TAPAS oo ka jawaabaya modelka. Baaloolayaashu wuxuu isticmaalaa awoodda noocyada joogta oo noocyada ah oo uu ku isticmaalo baaritaanka kale looma baahna. Systemkanagu wuxuu helay qiimaha FEVEROUS oo ay tahay 0.06 iyo alaabta saxda 0.39 oo ku qoran dhibaatada FEVEROUS.</abstract_so>
      <abstract_ta>இந்த காகிதத்தில், நாம் விகிபிடியா உள்ளடக்கத்திற்கு எதிராக கூறுகளை சரிபார்க்க ஒரு புதிய உண்மையை பரிந்துரை எங்கள் கணினி விக்கிபிடியா தொடர்பு பக்கங்களை Anserini பயன்படுத்தி திரும்புகிறது, பிரெட்- பெரிய கேள்வியின் பதில் கேட்பு மாதிரியை பயன்படுத்தி சரியான தெளிவாக தே அட்டவணை செல் தெளிவுகள் பொருந்தும் செல் மதிப்புகளைத் தேடும் மற்றும் TAPAS அட்டவணை கேள்வி மாதிரி பதில் கேட்கை இந்த பைப்லைன் தற்போதைய மாதிரிகளின் பூஜ்ஜியத்தை பயன்படுத்துகிறது மற்றும் கூடுதல் பயிற்சி தேவைப்படாத மாதிரிகள். எங்கள் கணினியில் 0.06 பெருக்கிய மதிப்பு கிடைத்தது மற்றும் ஒரு விளக்கச்சீட்டு சரியான 0.39 சவால்வில் உள்ளது.</abstract_ta>
      <abstract_sv>I denna uppsats föreslår vi ett nytt system för faktakontroll och verifiering för att kontrollera påståenden mot Wikipedias innehåll. Vårt system hämtar relevanta Wikipedia-sidor med Anserini, använder BERT-frågesvarsmodell med stora bokstäver för att välja rätt bevis och verifierar påståenden med hjälp av XLNET naturlig språkinferensmodell genom att jämföra den med bevisen. Tabellcellsbevis erhålls genom att söka efter entitetsmatchande cellvärden och TAPAS tabell frågesvarsmodell. Pipeline utnyttjar noll-skott kapacitet hos befintliga modeller och alla modeller som används i pipeline kräver ingen ytterligare utbildning. Vårt system fick en FEVEROUS poäng på 0,06 och en etikettnoggrannhet på 0,39 i FEVEROUS utmaning.</abstract_sv>
      <abstract_ur>اس کاغذ میں، ہم ایک نئی حقیقت کی تصدیق اور تصدیق سیسٹم کی پیشنهاد کریں کہ ویکیپیڈیا کے منصوبات کے خلاف ادعا کریں۔ ہماری سیسٹم نے Anserini کے مطابق ارتباط والکیپیڈیا صفحے اٹھائے ہیں، BERT-بزرگ-cased سوال کی جواب مدل کو درست دلیلیں انتخاب کرنے کے لئے استعمال کرتا ہے، اور XLNET طبیعی زبان انفارنس موڈل کے مطابق تصدیق کرتا ہے، اس کے مطابق ٹیبل سلل شہادت حاصل کی گئی ہے انٹیٹی کے مطابق سلل کے مطابق اور TAPAS ٹیبل سؤال کے جواب موڈل کے لئے۔ پائپ لین موجود موجود موڈلوں کے صفر-شٹ کے قابلیت کو استعمال کرتا ہے اور پائپ لین میں استعمال ہوئے تمام موڈلوں کو اضافہ کی تطارین کی ضرورت نہیں ہے. ہماری سیستم نے 0.06 کی چند سی اسکور اور ایک لیبل دقیق 0.39 کی تھی۔</abstract_ur>
      <abstract_uz>Bu hujjatda, biz Wikipedia tarkibini tekshirish va tasdiqlash tizimini tekshirish va tasdiqlash tizimini tekshiring. Bizning tizimimiz Anserini ishlatilgan muhim Wikipedia sahifalarini aniqlaydi, bu hodisa bilan birga bog'liq maslahat bilan ishlatiladi va xabarlarni tanlash uchun BERT- katta qo'llangan savol modeldan foydalanadi. Name Name Bizning tizimimizda 0.06 qismi 0.06 va FEVEROUSning qiymatiga 0.39 ta'siri davlatda.</abstract_uz>
      <abstract_vi>Trong tờ giấy này, chúng tôi đề xuất một hệ thống kiểm tra và kiểm tra thực tế mới để kiểm tra các yêu cầu dựa trên Wikipedia. Hệ thống của chúng tôi lấy được trang Wikipedia đã sử dụng Anserini, sử dụng kiểu câu hỏi lớn của BERT để tìm cách trả lời câu hỏi đúng để chọn bằng chứng, và xác nhận các yêu cầu sử dụng mô hình nhận ngôn ngữ tự nhiên của XMntnet bằng cách so sánh nó với bằng chứng. Bằng chứng tế bào biểu đồ được lấy bằng cách tìm kiếm các giá trị tế bào khớp với thực thể và kiểu câu hỏi kiểu TAP. Các đường ống sử dụng khả năng bắn không vào các mẫu đã có và tất cả các mẫu được dùng trong đường ống không cần phải luyện thêm. Hệ thống của chúng tôi có một số ít ghi 0.06 và độ chính xác nhãn của 0.39 trong một thách thức khó khăn.</abstract_vi>
      <abstract_bg>В тази статия предлагаме нова система за проверка и проверка на фактите за проверка на твърденията срещу съдържанието на Уикипедия. Системата ни извлича съответните страници на Уикипедия, използвайки модела за отговор на въпроси с големи казуси, за да избере правилни доказателства, и проверява твърденията, използвайки модела за извеждане на естествен език чрез сравняване с доказателствата. Доказателствата за клетките в таблицата се получават чрез търсене на стойности на клетките, съответстващи на обекти, и модел за отговор на въпроси в таблицата. Тръбопроводът използва възможности за нулев изстрел на съществуващите модели и всички модели, използвани в тръбопровода, не изискват допълнително обучение. Нашата система получи оценка от 0.06 и точност на етикета от 0.39 в предизвикателството.</abstract_bg>
      <abstract_da>I denne artikel foreslår vi et nyt system til kontrol og verifikation af fakta til at kontrollere krav mod Wikipedia-indhold. Vores system henter relevante Wikipedia-sider ved hjælp af Anserini, bruger BERT-spørgsmålsbesvarelsesmodel med store cases til at vælge korrekte beviser, og verificerer påstande ved hjælp af XLNET naturlig sprog inference model ved at sammenligne det med beviserne. Tabelcellebeviser opnås ved at søge efter enhedsmatchende celleværdier og TAPAS tabel spørgsmål besvarelse model. Pipeline udnytter nul-skud kapaciteter af eksisterende modeller, og alle de modeller, der anvendes i pipeline, kræver ingen yderligere træning. Vores system fik en FEVEROUS score på 0,06 og en etiket nøjagtighed på 0,39 i FEVEROUS udfordring.</abstract_da>
      <abstract_nl>In dit artikel stellen we een nieuw systeem voor feitencontrole en verificatie voor om claims tegen Wikipedia-inhoud te controleren. Ons systeem haalt relevante Wikipedia-pagina's op met behulp van Anserini, gebruikt BERT-vragenantwoordmodel om correct bewijs te selecteren en verifieert claims met behulp van XLNET natuurlijke taal inference model door het te vergelijken met het bewijs. Tabelcel-bewijs wordt verkregen door te zoeken naar entiteitsovereenkomende celwaarden en TAPAS-tabelvragenantwoordmodel. De pijplijn maakt gebruik van zero-shot mogelijkheden van bestaande modellen en alle modellen die in de pijplijn worden gebruikt, vereisen geen extra training. Ons systeem kreeg een FEVEROUS score van 0.06 en een label nauwkeurigheid van 0.39 in FEVEROUS challenge.</abstract_nl>
      <abstract_hr>U ovom papiru predlažemo novi sistem provjere činjenice i provjere zahtjeva protiv sadržaja Wikipedije. Naš sustav prima relevantne Wikipedijske stranice koristeći Anserini, koristi model odgovarajućeg pitanja iz BERT-a, kako bi odabrali ispravne dokaze, te potvrđuje tvrdnje koristeći model infekcije prirodnog jezika XLNET uspoređujući ga s dokazima. Pronađeni su dokazi tablice stanica tražeći vrijednosti stanica koje odgovaraju entiteti i model odgovarajućeg pitanja tablice TAPAS. Civovoda koristi nulovne mogućnosti postojećih modela i svih modela koji se koriste u cijevi ne zahtijeva dodatnu obuku. Naš sustav je dobio rezultat od 0,06 i tačnost etikete od 0,39 u četvrtom izazovu.</abstract_hr>
      <abstract_de>In diesem Beitrag schlagen wir ein neuartiges Faktenprüfungs- und Verifizierungssystem vor, um Behauptungen gegen Wikipedia-Inhalte zu überprüfen. Unser System ruft relevante Wikipedia-Seiten mit Anserini ab, verwendet BERT-Fragebeantwortungsmodell, um korrekte Beweise auszuwählen, und verifiziert Behauptungen mit dem XLNET Natural Language Inference Model, indem es es mit den Beweisen vergleicht. Tabellenzellnachweis wird durch die Suche nach Entity-übereinstimmenden Zellwerten und TAPAS-Tabellenfragen-Antwortmodell erhalten. Die Pipeline nutzt Zero-Shot-Funktionen bestehender Modelle und alle in der Pipeline verwendeten Modelle erfordern keine zusätzliche Schulung. Unser System erhielt einen FEVEROUS Score von 0.06 und eine Etikettengenauigkeit von 0.39 in FEVEROUS Challenge.</abstract_de>
      <abstract_ko>본고에서 우리는 위키백과 내용을 검사하기 위한 새로운 사실 검사와 검증 시스템을 제시했다.우리 시스템은 Anserini를 사용하여 관련 위키백과 페이지를 검색하고 BERT 대사례 퀴즈 모델을 사용하여 정확한 증거를 선택하고 증거와 비교하여 XLNET 자연 언어 추리 모델로 성명을 검증합니다.셀 값과 일치하는 엔티티와 TAPAS 테이블 Q&amp;amp;A 모델을 찾아 테이블 셀 증거를 가져옵니다.이 파이프라인은 기존 모델의 제로 사격 능력을 활용해 파이프라인에 사용된 모든 모델에 대해 별도의 교육이 필요 없다.우리 시스템은 발열 도전에서 0.06의 발열 점수와 0.39의 라벨 정확도를 얻었다.</abstract_ko>
      <abstract_id>Dalam kertas ini, kami mengusulkan sebuah sistem pemeriksaan fakta baru dan verifikasi untuk memeriksa klaim terhadap isi Wikipedia. Sistem kami mengambil halaman Wikipedia relevan menggunakan Anserini, menggunakan model BERT-besar-cased menjawab pertanyaan untuk memilih bukti yang benar, dan mengkonfirmasi klaim menggunakan model XLNET bahasa alam inferensi dengan membandingkannya dengan bukti. Bukti sel tabel diperoleh melalui mencari nilai sel yang cocok dengan entitas dan model jawaban TAPAS tabel pertanyaan. Pipeline menggunakan kapasitas zero-shot dari model yang ada dan semua model yang digunakan dalam pipeline tidak membutuhkan pelatihan tambahan. Sistem kita mendapat skor FEVEROUS 0.06 dan akurasi label 0.39 dalam tantangan FEVEROUS.</abstract_id>
      <abstract_fa>در این کاغذ، ما یک سیستم بررسی و بررسی روانی را پیشنهاد می‌کنیم تا درباره محتویات ویکیپدیا بررسی کنیم. سیستم ما با استفاده از Anserini صفحه‌های ویکیپیدیا مربوط به استفاده می‌کند، از مدل جواب دادن سوال بزرگ BERT برای انتخاب شواهد درست استفاده می‌کند، و ادعا را با مدل آلودگی زبان طبیعی XLNET با مقایسه کردن آن با شواهد ثابت می‌کند مدرک سلول میز از طریق جستجوی ارزش سلولهای متفاوت به عنوان یک عنوان و مدل جواب سوال میز TAPAS دریافت می شود. خط لوله توانایی‌های صفر تصاویری از مدل‌های موجود است و تمام مدل‌های استفاده از لوله‌های لوله نیاز به تمرین اضافی ندارد. سیستم ما یک امتیاز FEVEROUS از 0.06 و دقیقاً یک نقاشی از 0.39 در چالش چهارپایی دارد.</abstract_fa>
      <abstract_sw>Katika karatasi hii, tunapendekeza mfumo wa riwaya wa kutangaza na kuthibitisha madai dhidi ya maudhui ya Wikipedia. Mfumo wetu unapata kurasa zinazohusiana na Wikipedia kwa kutumia Anserini, inatumia maswali makubwa yanayojibu muundo wa BERT kuchagua ushahidi sahihi, na kuthibitisha madai ya kutumia mtindo wa maambukizi wa lugha asili ya XLNET kwa kulinganisha na ushahidi. ushahidi wa seli za mezani unapatikana kwa kutafuta thamani zinazofanana na vifaa vya viganjani na maswali ya table ya TAPAS yanajibu modeli. Pili hiyo inatumia uwezo wa mifano iliyopo sifuri na mifano yote iliyotumika kwenye pipeline haihitaji mafunzo ya ziada. Mfumo wetu ulipata score ya FEVEROUS 0.06 na alama yenye sahihi ya 0.39 katika changamoto ya FEVEROUS.</abstract_sw>
      <abstract_af>In hierdie papier, voorstel ons 'n nuwe feit om te kontroleer en verifiseer stelsel te bevestig voordele teen Wikipedia inhoud. Ons stelsel ontvang relevante Wikipedia bladsye deur Anserini te gebruik, gebruik BERT-groot-kased vraag antwoord model om korrekte bevestige te kies, en bevestig aanbevestings deur XLNET natuurlike taal inferensie model te gebruik deur dit te vergelyk met die bevestige. Name Die pyplyn gebruik nul-skoot kapasiteite van bestaande modele en al die modele wat in die pyplyn gebruik word, benodig geen addisionele onderwerp nie. Ons stelsel het 'n Uitveerde skakel van 0.06 en 'n etiket presisie van 0.39 in FEVER uitdrukking.</abstract_af>
      <abstract_am>በዚህ ገጾች ላይ Wikipedia ጥያቄን ለመምረጥ እና ለማረጋገጥ የረኀብ ውይይት ማረጋገጫ እና ማረጋገጥን እናዘጋጅታለን፡፡ ሲስተምረታችን የWikipedia ገጾችን Anserini የተጠቃሚ ጥያቄን በመቀበል የBERT-ትልቅ ጥያቄን ለመምረጥ ትክክለኛውን ማስረጃ ለመምረጥ እና ማስረጃዎችን በመቀበል የXLNET ፍጥረታዊ ቋንቋ ውጤት ሞዴል ሲያረጋግጣል፡፡ ሠንጠረዥ የፖሊስ መስኮት የአሁኑ ሞዴላዎችን በ0-shot ኃይል ይጠቅማል፡፡ በፖሊስ ውስጥ የተጠቀሙት ሞዴላዎች ሁሉ የጨዋታ ማስተምር አያስፈልጋቸውም፡፡ ሲስተምረታችን የ0.06 ነጥብ አቀረበ፤ የ.አ.39 የፊዌሮስ ጥያቄ ትክክል ነው፡፡</abstract_am>
      <abstract_hy>Այս թղթի մեջ մենք առաջարկում ենք նոր փաստերի ստուգելու և ստուգելու համակարգ, որպեսզի ստուգենք Վիքիփեդիայի պարունակությունները: Մեր համակարգը վերցնում է համապատասխանատու Վիքիփեդիայի էջերը օգտագործելով Անսերինին, օգտագործում է BER-մեծ հարցերի պատասխանատու մոդելը ճիշտ ապացույցների ընտրելու համար, և ստուգում է հայտարարությունները XLNet-ի բնական լեզվի եզրակացության մոդելի Տեսախցիկի բջիջների ապացույցները ստացվում են առանձնահատուկ բջիջների արժեքների և ՏԱՊԱՍ-ի աղյուսախցիկի հարցերին պատասխանող մոդելի փնտրելով: Գոյություն ունեցող մոդելների զրո-կրակային հնարավորությունները օգտագործվում են խողովակաշարի մեջ օգտագործվող բոլոր մոդելները ոչ մի ավելին վարժություն չեն պահանջում: Մեր համակարգը ստացավ 0.6 ֆեյվերոս գնահատականը և 0.39 ֆեյվերոս մարտահրավերում:</abstract_hy>
      <abstract_tr>Biz bu kagyzda Wikipediýa maksadyna garşy barlamak we barlamak sistemasyny maslahat berýäris. Biziň sistemimiz Anserini ullanýan wajyp Wikipediýa sahypalary almak üçin BERT uly hasaplanýan sorag nusgasyny dogry kanlag saýlamak üçin ullanýar we XLNET tebigy dil hasaplanjak nusgasyny barlaýar. Celsiýa eşleýän häsiýetleri we TAPAS täblisaň soragy nusgala üçin tapylýar. pipeline bar bar modleriň 0-resim ukyplaryny ulanýar we pipeline içinde ullanýan ähli nusgalaryň hiç hili ýeterli eğitim gerek däl. Biziň sistemimiz 0.06-yň düýbüsi we etiket derejesi 0.39-yň düýbüsi bar.</abstract_tr>
      <abstract_bn>এই কাগজটিতে আমরা উইকিপিডিয়ার বিষয়বস্তুর বিরুদ্ধে দাবি পরীক্ষা এবং পরীক্ষা করার একটি উপস্থান প্রস্তাব করছি। আমাদের সিস্টেম অ্যান্সিরিনি ব্যবহার করে উইকিপিডিয়া পাতা পুনরুদ্ধার করে ব্যবহার করে সঠিক প্রমাণ নির্বাচনের জন্য বিবের্ট-ব্যাপক ক্যাসেড প্রশ্নের উত্তর দিয় টেবিল সেলের প্রমাণ পাওয়া যাচ্ছে বস্তুর মান এবং টাপাএস টেবিলের টেবিলের প্রশ্ন মডেলের উত্তরের মাধ্যমে। পাইপেলাইন বিদ্যমান মডেলের শূন্য-শুটের ক্ষমতা ব্যবহার করে এবং পাইপেলাইনে ব্যবহার করা সকল মডেল ব্যবহার করা হয়েছে তাতে আরো প্রশিক আমাদের সিস্টেমের একটি ফেভেরোস স্কোর 0. 06 এবং ফেভেরোস চ্যালেঞ্জের একটি লেবেলেটের সঠিকভাবে 0.39 পেয়েছে।</abstract_bn>
      <abstract_sq>Në këtë letër, propozojmë një sistem të ri të kontrollit dhe verifikimit të fakteve për të kontrolluar pretendimet ndaj përmbajtjes së Wikipedias. Sistemi ynë merr faqet e duhura të Wikipedias duke përdorur Anserini, përdor modelin BERT-të përgjigjet pyetjeve në raste të mëdha për të zgjedhur provat e sakta dhe verifikon pretendimet duke përdorur modelin e inferencës së gjuhës natyrore XLNET duke e krahasuar atë me provat. Prova e qelizave të tabelës merret nëpërmjet kërkimit për vlerat e qelizave që përputhen me njësinë dhe modelit për përgjigjen e pyetjeve të tabelës TAPAS. Tubacioni përdor aftësitë zero-shot të modeleve ekzistuese dhe të gjitha modelet e përdorura në tubacion nuk kërkojnë trajnim shtesë. Sistemi ynë ka një rezultat FEVEROUS 0.06 dhe një saktësi etikete 0.39 në sfidën FEVEROUS.</abstract_sq>
      <abstract_ca>En aquest article, proposem un nou sistema de verificació i verificació de fets per verificar les reclamacions en comparació amb el contingut de Wikipedia. El nostre sistema recupera pàgines pertinents de Wikipedia utilitzant Anserini, utilitza un model BERT de resposta a preguntes en gran cas per seleccionar les proves correctes, i verifica reclamacions utilitzant el model de inferència de llenguatge natural XLNET comparant-lo amb les proves. L'evidència de cèl·lules de taula es obté buscant valors de cèl·lules que s'ajusten a les entitats i model de resposta a preguntes TAPAS. The pipeline utilizes zero-shot capabilities of existing models and all the models used in the pipeline requires no additional training.  El nostre sistema va rebre una puntuació FEVEROUS de 0,06 i una precisió d'etiqueta de 0,39 en FEVEROUS repte.</abstract_ca>
      <abstract_cs>V tomto článku navrhujeme nový systém kontroly a ověřování faktů pro kontrolu tvrzení proti obsahu Wikipedie. Náš systém načítá relevantní stránky Wikipedie pomocí Anserini, používá model odpovědi na otázky BERT s velkými případy pro výběr správných důkazů a ověřuje tvrzení pomocí modelu inference přirozeného jazyka XLNET srovnáním s důkazy. Důkazy o buňce tabulky jsou získány prostřednictvím hledání hodnot buněk odpovídajících entitám a modelu odpovědi na otázky tabulky TAPAS. Potrubí využívá funkce nulového výstřelu stávajících modelů a všechny modely používané v potrubí nevyžadují žádné další školení. Náš systém získal FEVEROUS skóre 0,06 a přesnost etiket 0,39 v FEVEROUS soutěži.</abstract_cs>
      <abstract_az>Bu kağızda, Wikipedia içərisində iddiaları yoxlamaq və təsdiqləmək üçün yeni bir həqiqət sistemini təklif edirik. Bizim sistemimiz Anserini vasitəsilə ilişkili Wikipedia sayfalarını alır, BERT-dən böyük bir sual cavab verən modeli doğru dəlilləri seçmek üçün istifadə edir, və XLNET təbiətli dil infeksiya modeli ilə dəlillərlə karşılaşdırır. Sətir hücresi dəlilləri bir hücre ilə uyuşan qiymətlər və TAPAS səhifə sualına cavab verən modeli araraq tapılır. Şifrə səhifəsi mövcuddur modellərin sıfır-fəsad qabiliyyətlərini və tüm modellərin tükənməsində istifadə edilməsi lazımdır. Sistemimiz 0.06 dəyişikliyi və etiketli dəyişiklik 0.39 dəyişikliyi var.</abstract_az>
      <abstract_fi>Tässä artikkelissa ehdotamme uutta faktojen tarkistus- ja todentamisjärjestelmää Wikipedian sisältöön liittyvien väitteiden tarkistamiseksi. Järjestelmämme hakee asiaankuuluvat Wikipedian sivut Anserinin avulla, käyttää BERT-suuraakkosista kysymysmallia oikean näytön valitsemiseen ja vahvistaa väitteet XLNET-luonnollisen kielen päättelymallin avulla vertaamalla sitä todisteisiin. Taulukkosolunäyttöä saadaan etsimällä kokonaisuuksia vastaavia soluarvoja ja TAPAS-taulukkokysymysmallia. Putkisto hyödyntää olemassa olevien mallien nollashot-ominaisuuksia ja kaikki putkessa käytetyt mallit eivät vaadi lisäkoulutusta. Järjestelmämme sai FEVEROUS-pisteen 0,06 ja etiketin tarkkuuden 0,39 FEVEROUS-haasteessa.</abstract_fi>
      <abstract_bs>U ovom papiru predlažemo novi sistem provjere i verificije da provjeri tvrdnje protiv sadržaja Wikipedije. Naš sistem dobija relevantne Wikipedia stranice koristeći Anserini, koristi model odgovarajućeg pitanja na BERT-u velikom slučaju kako bi odabrali ispravne dokaze, i potvrđuje tvrdnje koristeći model infekcije prirodnog jezika XLNET uspoređujući ga s dokazima. Pronađeni su dokazi tablovih ćelija tražeći vrijednosti stanica koje odgovaraju entiteti i model odgovarajućeg pitanja TAPAS tablovih pitanja. Cijev koristi sposobnosti postojećih modela bez pucnjave i svih modela koji se koriste u cijevi ne zahtijeva dodatnu obuku. Naš sistem je dobio nekoliko rezultata od 0,06 i tačnost etiketa od 0,39 u četvrtom izazovu.</abstract_bs>
      <abstract_et>Käesolevas dokumendis pakume välja uudse faktide kontrollimise ja kontrollimise süsteemi, et kontrollida nõudeid Wikipedia sisu suhtes. Meie süsteem toob Anserini abil kaasa asjakohased Wikipedia leheküljed, kasutab BERT-i suurte tükkidega küsimustele vastamise mudelit õigete tõendite valimiseks ja kontrollib väideid XLNET looduskeele järeldusmudeli abil, võrreldes seda tõenditega. Tabelilahtri tõendusmaterjali saamiseks otsitakse olemiga sobivaid lahtriväärtusi ja TAPAS tabeliküsimustele vastamise mudelit. Torujuhe kasutab olemasolevate mudelite null-shot võimalusi ja kõik torujuhtmes kasutatavad mudelid ei vaja täiendavat koolitust. Meie süsteem sai FEVEROUS skoori 0,06 ja sildi täpsuse 0,39 FEVEROUS väljakutses.</abstract_et>
      <abstract_sk>V tem prispevku predlagamo nov sistem za preverjanje dejstev in preverjanje zahtevkov glede na vsebino Wikipedije. Naš sistem pridobi ustrezne Wikipedijske strani z uporabo Anserinija, uporablja BERT-model za odgovor na vprašanja z velikimi črkami za izbiro pravilnih dokazov in preverja trditve z uporabo modela sklepanja naravnega jezika XLNET s primerjavo z dokazi. Dokazi celic tabele se pridobijo z iskanjem vrednosti celic, ki se ujemajo z entitetami, in model odgovarjanja na vprašanja tabele TAPAS. Cevovod uporablja ničelne zmogljivosti obstoječih modelov in vsi modeli, ki se uporabljajo v cevovodu, ne zahtevajo dodatnega usposabljanja. Naš sistem je dobil FEVEROUS oceno 0,06 in natančnost oznake 0,39 v FEVEROUS izzivu.</abstract_sk>
      <abstract_ha>Ga wannan takardan, Munã buɗa wata matsayi na nowaya, kan jarraba na'ura da gaskiyar da za'a sami sunayen a kan maɓallin Wikimedia. Ana amfani da shiryoyin ayukanmu da ke da takardar Wikimedia masu amfani da Anjerni, yana amfani da shiryoyin maswali mai girma wa masu tambayar BERT-mai motsi dõmin ya zãɓi bayani masu inganci, kuma yana tabbatar da kudai da za'a yi amfani da misãlin abun harshen XLNET na asali, da kuma ya sami shi da dalili. An motsa shaidar jagon cikin katagon, ana neman kima masu daidaita cikin ƙanshi da kuma maswali na jagon TAPAS da mai karɓa wa motel. Piflen na amfani da abincin sifo-shot na masu shiryoyin da ke jira, kuma duk misãlai da ake amfani da cikin piflen ba ya kamata wani tsari na ƙarami. Tsarinmu ya sami nau'in FEFURUS na 0.06 da alama na tsari na 0.39 a cikin FECERU.</abstract_ha>
      <abstract_jv>Nyong ngomong sapir iki, kéné supoyo sistem kanggo nyokak lan nganggo perusahaan anyar tentang kanggo nganggo perusahaan winih Sistem awak dhéwé ngewehke perusahaan wipedipedya sing gambar n' Replarini, iso nggambar BERT-langgar kuwi dianggap modèl kanggo tinguha perusahaan sugian sing wis dipatenno, lan ujaran dhéwé ngerasakno modèl kuwi nggawe perusahaan langkung sampeyan XLNeT. Global Nanging Sistem awak dhéwé entuk sing paling nêmên 0.06 lan etiket sing ngabarêng nêmên 0.49 lan dinong WHANDAR</abstract_jv>
      <abstract_bo>ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་གུས་པེ་ཌི་ཡི་ནང་དོན་དབང་ཆ་ལྟ་ཞིབ་དང་ཞིབ་དག་གི་གོ་སྐབས་གསར་བ ང་ཚོའི་མ་ལག Object-matching cell values and TAPAS table question answering model is obtained through looking for entity-matching cell values and The pipeline utilizes zero-shot capabilities of existing models and all the models used in the pipeline requires no additional training. ང་ཚོའི་མ་ལག་གིས་པར་ཨང་གྲངས་0.06 དང་ཤོག་བྱང་དཀའ་འགྲོ་བཞིན་པའི་གནས་ཚུལ་མང་ཙམ་ཡོད།</abstract_bo>
      <abstract_he>In this paper, we propose a novel fact checking and verification system to check claims against Wikipedia content.  Our system retrieves relevant Wikipedia pages using Anserini, uses BERT-large-cased question answering model to select correct evidence, and verifies claims using XLNET natural language inference model by comparing it with the evidence.  ראיות תאי שולחן מושגות על ידי חיפוש אחר ערכים תאי מתאימים יחידות ומודל עניין לשאלות TAPAS. צינור משתמש בכישורי ירייה אפס של דוגמנים קיימים וכל הדוגמנים המשתמשים בצינור לא דורשים אימונים נוספים. המערכת שלנו קיבלה נקודה FEVEROUS של 0.06 ודיוקת תווית של 0.39 באתגר FEVEROUS.</abstract_he>
      </paper>
  </volume>
</collection>