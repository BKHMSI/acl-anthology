<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.iwslt">
  <volume id="1" ingest-date="2021-07-22">
    <meta>
      <booktitle>Proceedings of the 18th International Conference on Spoken Language Translation (IWSLT 2021)</booktitle>
      <editor><first>Marcello</first><last>Federico</last></editor>
      <editor><first>Alex</first><last>Waibel</last></editor>
      <editor><first>Marta R.</first><last>Costa-jussà</last></editor>
      <editor><first>Jan</first><last>Niehues</last></editor>
      <editor><first>Sebastian</first><last>Stuker</last></editor>
      <editor><first>Elizabeth</first><last>Salesky</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Bangkok, Thailand (online)</address>
      <month>August</month>
      <year>2021</year>
      <url hash="3a0b28e8">2021.iwslt-1</url>
    </meta>
    <frontmatter>
      <url hash="aeeec0cb">2021.iwslt-1.0</url>
      <bibkey>iwslt-2021-international</bibkey>
    </frontmatter>
    <paper id="1">
      <title>FINDINGS OF THE IWSLT 2021 EVALUATION CAMPAIGN<fixed-case>FINDINGS</fixed-case> <fixed-case>OF</fixed-case> <fixed-case>THE</fixed-case> <fixed-case>IWSLT</fixed-case> 2021 <fixed-case>EVALUATION</fixed-case> <fixed-case>CAMPAIGN</fixed-case></title>
      <author><first>Antonios</first><last>Anastasopoulos</last></author>
      <author><first>Ondřej</first><last>Bojar</last></author>
      <author><first>Jacob</first><last>Bremerman</last></author>
      <author><first>Roldano</first><last>Cattoni</last></author>
      <author><first>Maha</first><last>Elbayad</last></author>
      <author><first>Marcello</first><last>Federico</last></author>
      <author><first>Xutai</first><last>Ma</last></author>
      <author><first>Satoshi</first><last>Nakamura</last></author>
      <author><first>Matteo</first><last>Negri</last></author>
      <author><first>Jan</first><last>Niehues</last></author>
      <author><first>Juan</first><last>Pino</last></author>
      <author><first>Elizabeth</first><last>Salesky</last></author>
      <author><first>Sebastian</first><last>Stüker</last></author>
      <author><first>Katsuhito</first><last>Sudoh</last></author>
      <author><first>Marco</first><last>Turchi</last></author>
      <author><first>Alexander</first><last>Waibel</last></author>
      <author><first>Changhan</first><last>Wang</last></author>
      <author><first>Matthew</first><last>Wiesner</last></author>
      <pages>1–29</pages>
      <abstract>The evaluation campaign of the International Conference on Spoken Language Translation (IWSLT 2021) featured this year four shared tasks : (i) Simultaneous speech translation, (ii) Offline speech translation, (iii) Multilingual speech translation, (iv) Low-resource speech translation. A total of 22 teams participated in at least one of the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a>. This paper describes each shared task, data and evaluation metrics, and reports results of the received submissions.</abstract>
      <url hash="d04d3be0">2021.iwslt-1.1</url>
      <doi>10.18653/v1/2021.iwslt-1.1</doi>
      <bibkey>anastasopoulos-etal-2021-findings</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/covost">CoVoST</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/librispeech">LibriSpeech</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/must-c">MuST-C</pwcdataset>
    </paper>
    <paper id="3">
      <title>NAIST English-to-Japanese Simultaneous Translation System for IWSLT 2021 Simultaneous Text-to-text Task<fixed-case>NAIST</fixed-case> <fixed-case>E</fixed-case>nglish-to-<fixed-case>J</fixed-case>apanese Simultaneous Translation System for <fixed-case>IWSLT</fixed-case> 2021 Simultaneous Text-to-text Task</title>
      <author><first>Ryo</first><last>Fukuda</last></author>
      <author><first>Yui</first><last>Oka</last></author>
      <author><first>Yasumasa</first><last>Kano</last></author>
      <author><first>Yuki</first><last>Yano</last></author>
      <author><first>Yuka</first><last>Ko</last></author>
      <author><first>Hirotaka</first><last>Tokuyama</last></author>
      <author><first>Kosuke</first><last>Doi</last></author>
      <author><first>Sakriani</first><last>Sakti</last></author>
      <author><first>Katsuhito</first><last>Sudoh</last></author>
      <author><first>Satoshi</first><last>Nakamura</last></author>
      <pages>39–45</pages>
      <abstract>This paper describes NAIST’s system for the English-to-Japanese Simultaneous Text-to-text Translation Task in IWSLT 2021 Evaluation Campaign. Our primary submission is based on wait-k neural machine translation with sequence-level knowledge distillation to encourage <a href="https://en.wikipedia.org/wiki/Literal_translation">literal translation</a>.</abstract>
      <url hash="1929bf0a">2021.iwslt-1.3</url>
      <doi>10.18653/v1/2021.iwslt-1.3</doi>
      <bibkey>fukuda-etal-2021-naist</bibkey>
    </paper>
    <paper id="7">
      <title>THE IWSLT 2021 BUT SPEECH TRANSLATION SYSTEMS<fixed-case>THE</fixed-case> <fixed-case>IWSLT</fixed-case> 2021 <fixed-case>BUT</fixed-case> <fixed-case>SPEECH</fixed-case> <fixed-case>TRANSLATION</fixed-case> <fixed-case>SYSTEMS</fixed-case></title>
      <author><first>hari Krishna</first><last>Vydana</last></author>
      <author><first>Martin</first><last>Karafiat</last></author>
      <author><first>Lukas</first><last>Burget</last></author>
      <author><first>Jan</first><last>Černocký</last></author>
      <pages>75–83</pages>
      <abstract>The paper describes BUT’s English to German offline speech translation (ST) systems developed for IWSLT2021. They are based on jointly trained Automatic Speech Recognition-Machine Translation models. Their performances is evaluated on MustC-Common test set. In this work, we study their efficiency from the perspective of having a large amount of separate ASR training data and MT training data, and a smaller amount of speech-translation training data. Large amounts of ASR and MT training data are utilized for pre-training the ASR and MT models. Speech-translation data is used to jointly optimize ASR-MT models by defining an end-to-end differentiable path from speech to translations. For this purpose, we use the internal continuous representations from the ASR-decoder as the input to MT module. We show that <a href="https://en.wikipedia.org/wiki/Speech_translation">speech translation</a> can be further improved by training the ASR-decoder jointly with the MT-module using large amount of text-only MT training data. We also show significant improvements by training an ASR module capable of generating punctuated text, rather than leaving the punctuation task to the MT module.</abstract>
      <url hash="5a20ce0f">2021.iwslt-1.7</url>
      <doi>10.18653/v1/2021.iwslt-1.7</doi>
      <bibkey>vydana-etal-2021-iwslt</bibkey>
    </paper>
    <paper id="8">
      <title>Dealing with training and test segmentation mismatch : FBK@IWSLT2021<fixed-case>FBK</fixed-case>@<fixed-case>IWSLT</fixed-case>2021</title>
      <author><first>Sara</first><last>Papi</last></author>
      <author><first>Marco</first><last>Gaido</last></author>
      <author><first>Matteo</first><last>Negri</last></author>
      <author><first>Marco</first><last>Turchi</last></author>
      <pages>84–91</pages>
      <abstract>This paper describes FBK’s system submission to the IWSLT 2021 Offline Speech Translation task. We participated with a direct model, which is a Transformer-based architecture trained to translate English speech audio data into German texts. The training pipeline is characterized by knowledge distillation and a two-step fine-tuning procedure. Both knowledge distillation and the first fine-tuning step are carried out on manually segmented real and synthetic data, the latter being generated with an MT system trained on the available corpora. Differently, the second fine-tuning step is carried out on a random segmentation of the MuST-C v2 En-De dataset. Its main goal is to reduce the performance drops occurring when a <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech translation model</a> trained on manually segmented data (i.e. an ideal, sentence-like segmentation) is evaluated on <a href="https://en.wikipedia.org/wiki/Audio_signal_processing">automatically segmented audio</a> (i.e. actual, more realistic testing conditions). For the same purpose, a custom hybrid segmentation procedure that accounts for both audio content (pauses) and for the length of the produced segments is applied to the test data before passing them to the system. At inference time, we compared this <a href="https://en.wikipedia.org/wiki/Procedure_(term)">procedure</a> with a baseline segmentation method based on Voice Activity Detection (VAD). Our results indicate the effectiveness of the proposed hybrid approach, shown by a reduction of the gap with manual segmentation from 8.3 to 1.4 BLEU points.</abstract>
      <url hash="7f4c6e97">2021.iwslt-1.8</url>
      <doi>10.18653/v1/2021.iwslt-1.8</doi>
      <bibkey>papi-etal-2021-dealing</bibkey>
    </paper>
    <paper id="11">
      <title>End-to-End Speech Translation with Pre-trained Models and Adapters : UPC at IWSLT 2021<fixed-case>UPC</fixed-case> at <fixed-case>IWSLT</fixed-case> 2021</title>
      <author><first>Gerard I.</first><last>Gállego</last></author>
      <author><first>Ioannis</first><last>Tsiamas</last></author>
      <author><first>Carlos</first><last>Escolano</last></author>
      <author><first>José A. R.</first><last>Fonollosa</last></author>
      <author><first>Marta R.</first><last>Costa-jussà</last></author>
      <pages>110–119</pages>
      <abstract>This paper describes the submission to the IWSLT 2021 offline speech translation task by the UPC Machine Translation group. The task consists of building a <a href="https://en.wikipedia.org/wiki/System">system</a> capable of translating <a href="https://en.wikipedia.org/wiki/English_language">English audio recordings</a> extracted from <a href="https://en.wikipedia.org/wiki/TED_(conference)">TED talks</a> into <a href="https://en.wikipedia.org/wiki/German_language">German text</a>. Submitted systems can be either cascade or end-to-end and use a custom or given segmentation. Our submission is an end-to-end speech translation system, which combines pre-trained models (Wav2Vec 2.0 and mBART) with coupling modules between the encoder and decoder, and uses an efficient fine-tuning technique, which trains only 20 % of its total parameters. We show that adding an Adapter to the system and pre-training it, can increase the <a href="https://en.wikipedia.org/wiki/Convergence_rate">convergence speed</a> and the final result, with which we achieve a BLEU score of 27.3 on the MuST-C test set. Our final <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is an <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble</a> that obtains 28.22 BLEU score on the same set. Our submission also uses a custom segmentation algorithm that employs pre-trained Wav2Vec 2.0 for identifying periods of untranscribable text and can bring improvements of 2.5 to 3 BLEU score on the IWSLT 2019 test set, as compared to the result with the given segmentation.</abstract>
      <url hash="31d80234">2021.iwslt-1.11</url>
      <doi>10.18653/v1/2021.iwslt-1.11</doi>
      <bibkey>gallego-etal-2021-end</bibkey>
      <pwccode url="https://github.com/mt-upc/iwslt-2021" additional="false">mt-upc/iwslt-2021</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/covost">CoVoST</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/europarl-st">Europarl-ST</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/iwslt-2019">IWSLT 2019</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/must-c">MuST-C</pwcdataset>
    </paper>
    <paper id="15">
      <title>Maastricht University’s Multilingual Speech Translation System for IWSLT 2021<fixed-case>IWSLT</fixed-case> 2021</title>
      <author><first>Danni</first><last>Liu</last></author>
      <author><first>Jan</first><last>Niehues</last></author>
      <pages>138–143</pages>
      <abstract>This paper describes Maastricht University’s participation in the IWSLT 2021 multilingual speech translation track. The task in this track is to build multilingual speech translation systems in supervised and zero-shot directions. Our primary system is an <a href="https://en.wikipedia.org/wiki/End-to-end_principle">end-to-end model</a> that performs both <a href="https://en.wikipedia.org/wiki/Transcription_(linguistics)">speech transcription</a> and <a href="https://en.wikipedia.org/wiki/Translation">translation</a>. We observe that the joint training for the two tasks is complementary especially when the speech translation data is scarce. On the source and target side, we use <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a> and pseudo-labels respectively to improve the performance of our <a href="https://en.wikipedia.org/wiki/System">systems</a>. We also introduce an ensembling technique that consistently improves the quality of transcriptions and <a href="https://en.wikipedia.org/wiki/Translation">translations</a>. The experiments show that the <a href="https://en.wikipedia.org/wiki/End-to-end_principle">end-to-end system</a> is competitive with its cascaded counterpart especially in zero-shot conditions.</abstract>
      <url hash="dff7b25d">2021.iwslt-1.15</url>
      <doi>10.18653/v1/2021.iwslt-1.15</doi>
      <bibkey>liu-niehues-2021-maastricht</bibkey>
    </paper>
    <paper id="16">
      <title>ZJU’s IWSLT 2021 Speech Translation System<fixed-case>ZJU</fixed-case>’s <fixed-case>IWSLT</fixed-case> 2021 Speech Translation System</title>
      <author><first>Linlin</first><last>Zhang</last></author>
      <pages>144–148</pages>
      <abstract>In this paper, we describe Zhejiang University’s submission to the IWSLT2021 Multilingual Speech Translation Task. This task focuses on speech translation (ST) research across many non-English source languages. Participants can decide whether to work on constrained systems or unconstrained systems which can using external data. We create both cascaded and end-to-end speech translation constrained systems, using the provided data only. In the cascaded approach, we combine Conformer-based automatic speech recognition (ASR) with the Transformer-based neural machine translation (NMT). Our end-to-end direct speech translation systems use ASR pretrained encoder and multi-task decoders. The submitted <a href="https://en.wikipedia.org/wiki/System">systems</a> are ensembled by different cascaded models.</abstract>
      <url hash="244ce8e4">2021.iwslt-1.16</url>
      <doi>10.18653/v1/2021.iwslt-1.16</doi>
      <bibkey>zhang-2021-zjus</bibkey>
    <title_pt>Sistema de tradução de fala IWSLT 2021 da ZJU</title_pt>
      <title_ar>نظام ترجمة الكلام IWSLT 2021 من ZJU</title_ar>
      <title_es>Sistema de traducción de voz IWSLT 2021 de ZJU</title_es>
      <title_ja>ZJUのIWSLT 2021音声翻訳システム</title_ja>
      <title_hi>ZJU की IWSLT 2021 वाक् अनुवाद प्रणाली</title_hi>
      <title_zh>浙江大学IWSLT 2021音译系统</title_zh>
      <title_ga>Córas Aistriúcháin Urlabhra IWSLT 2021 ag ZJU</title_ga>
      <title_hu>A ZKV IWSLT 2021 beszédfordító rendszere</title_hu>
      <title_el>Σύστημα μετάφρασης ομιλίας IWSLT 2021 της ZJU</title_el>
      <title_ka>Comment</title_ka>
      <title_it>Sistema di traduzione vocale IWSLT 2021 della ZJU</title_it>
      <title_kk>ZJU IWSLT 2021 сөз аудару жүйесі</title_kk>
      <title_lt>ZJU 2021 m. IWSLT kalbos vertimo sistema</title_lt>
      <title_mk>Системот за преведување на говорови на ЗЈУ IWSLT 2021</title_mk>
      <title_ms>Sistem Terjemahan Cahaya IWSLT 2021 ZJU</title_ms>
      <title_ml>ZJU's IWSLT 2021 Speech Translation System</title_ml>
      <title_mt>IWSLT 2021 tas-Sistema ta’ Traduzzjoni ta’ Speech ta’ ZJU</title_mt>
      <title_no>ZJU sin IWSLT 2021 taleomsetjingssystem</title_no>
      <title_ro>Sistemul de traducere vocală IWSLT 2021 al ZJU</title_ro>
      <title_sr>ZJU's IWSLT 2021 Speech Translation System</title_sr>
      <title_si>ZJu's IWSLT 2021 කතා අවවාද පද්ධති</title_si>
      <title_pl>System tłumaczenia mowy IWSLT 2021 ZJU</title_pl>
      <title_mn>ZJU's IWSLT 2021 Speech Translation System</title_mn>
      <title_so>ZJU's IWSLT 2021 Speech Translation System</title_so>
      <title_sv>ZJU:s system för talöversättning IWSLT 2021</title_sv>
      <title_ta>ZJU இன் IWSLT 2021 பேச்சு மொழிபெயர்ப்பு அமைப்பு</title_ta>
      <title_ur>ZJU's IWSLT 2021 Speech Translation System</title_ur>
      <title_vi>Hệ thống dịch lời nói của ZJU</title_vi>
      <title_uz>Query</title_uz>
      <title_hr>ZJU's IWSLT 2021</title_hr>
      <title_nl>IWSLT 2021 Spraakvertaalsysteem van ZJU</title_nl>
      <title_da>ZJU's IWSLT 2021 taleoversættelsessystem</title_da>
      <title_id>ZJU's IWSLT 2021 Speech Translation System</title_id>
      <title_de>IWSLT 2021 SprachĂ¼bersetzungssystem des ZJU</title_de>
      <title_bg>Системата за превод на реч на ЗЮ за 2021 г.</title_bg>
      <title_ko>ZJU의 IWSLT 2021 음성 번역 시스템</title_ko>
      <title_sw>IWSLT 2021 Mfumo wa Tafsiri wa Hotuba wa ZJU</title_sw>
      <title_af>ZJU se IWSLT 2021 Spraak Vertaling Stelsel</title_af>
      <title_sq>Sistemi i Trakthimit të Fjalës IWSLT 2021 i ZJU</title_sq>
      <title_fa>سیستم ترجمه سخنرانی ZJU IWSLT 2021</title_fa>
      <title_tr>ZJU ň IWSLT 2021 Dili terjime sistemi</title_tr>
      <title_hy>ZJU-ի IwPLT 2021-ի խոսքի թարգմանման համակարգը</title_hy>
      <title_az>ZJU's IWSLT 2021 Speech Translation System</title_az>
      <title_bn>ZJU's IWSLT 2021 ভাষা অনুবাদ সিস্টেম</title_bn>
      <title_am>የZJU IWSLT 2021 Speech Translation System</title_am>
      <title_ca>El sistema de traducció de discours IWSLT 2021 de la ZJU</title_ca>
      <title_et>ZJU IWSLT 2021 kõne tõlke süsteem</title_et>
      <title_cs>IWSLT 2021 Systém překladu řeči ZJU</title_cs>
      <title_bs>ZJU's IWSLT 2021 Speech Translation System</title_bs>
      <title_fi>ZJU:n IWSLT 2021 puhekäännösjärjestelmä</title_fi>
      <title_jv>IWSLT's IWSLT 2020 1 Terjamahan Sistem</title_jv>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_he>מערכת תרגום נאום IWSLT 2021 של ZJU</title_he>
      <title_sk>ZJU-jev sistem prevajanja govora IWSLT 2021</title_sk>
      <title_bo>ZJU's IWSLT 2021 Speech Translation System</title_bo>
      <abstract_pt>Neste artigo, descrevemos a submissão da Universidade de Zhejiang à Tarefa de Tradução de Fala Multilíngue IWSLT2021. Esta tarefa se concentra na pesquisa de tradução de fala (ST) em muitos idiomas de origem que não o inglês. Os participantes podem decidir se trabalham em sistemas restritos ou sistemas irrestritos que podem usar dados externos. Criamos sistemas restritos de tradução de fala em cascata e de ponta a ponta, usando apenas os dados fornecidos. Na abordagem em cascata, combinamos o reconhecimento automático de fala (ASR) baseado no Conformer com a tradução automática neural baseada no Transformer (NMT). Nossos sistemas de tradução de fala direta de ponta a ponta usam codificador pré-treinado ASR e decodificadores multitarefa. Os sistemas submetidos são agrupados por diferentes modelos em cascata.</abstract_pt>
      <abstract_es>En este artículo, describimos la presentación de la Universidad de Zhejiang a la tarea de traducción de voz multilingüe IWSLT2021. Esta tarea se centra en la investigación de la traducción del habla (ST) en muchos idiomas de origen distintos del inglés. Los participantes pueden decidir si trabajan en sistemas restringidos o en sistemas sin restricciones que pueden usar datos externos. Creamos sistemas restringidos de traducción de voz tanto en cascada como de extremo a extremo, utilizando únicamente los datos proporcionados. En el enfoque en cascada, combinamos el reconocimiento automático de voz (ASR) basado en conformer con la traducción automática neuronal (NMT) basada en transformadores. Nuestros sistemas de traducción de voz directa de extremo a extremo utilizan codificadores ASR preentrenados y decodificadores multitarea Los sistemas presentados están ensamblados por diferentes modelos en cascada.</abstract_es>
      <abstract_ar>في هذه الورقة ، نصف تقديم جامعة Zhejiang لمهمة ترجمة الكلام متعددة اللغات IWSLT2021. تركز هذه المهمة على أبحاث ترجمة الكلام (ST) عبر العديد من اللغات المصدر غير الإنجليزية. يمكن للمشاركين أن يقرروا ما إذا كانوا سيعملون على أنظمة مقيدة أو أنظمة غير مقيدة يمكنها استخدام البيانات الخارجية. نقوم بإنشاء أنظمة مقيدة لترجمة الكلام متتالية ومن طرف إلى طرف ، باستخدام البيانات المقدمة فقط. في النهج المتسلسل ، نجمع بين التعرف التلقائي على الكلام (ASR) المستند إلى المحول والترجمة الآلية العصبية القائمة على المحولات (NMT). تستخدم أنظمة ترجمة الكلام المباشرة من طرف إلى طرف لدينا مشفر ASR مسبق التدريب وأجهزة فك التشفير متعددة المهام. يتم تجميع الأنظمة المقدمة بواسطة نماذج متتالية مختلفة.</abstract_ar>
      <abstract_ja>本稿では、IWSLT 2021多言語音声翻訳タスクへの浙江大学の提出について述べる。このタスクは、多くの非英語ソース言語にわたる音声翻訳（ ST ）研究に焦点を当てています。参加者は、制約されたシステムで作業するか、外部データを使用できる制約されていないシステムで作業するかを決定できます。提供されたデータのみを使用して、カスケードおよびエンドツーエンドの音声翻訳制約システムの両方を作成します。カスケードアプローチでは、コンフォーマーベースの自動音声認識（ ＡＳＲ ）とトランスフォーマーベースのニューラルマシン翻訳（ ＮＭＴ ）を組み合わせる。当社のエンドツーエンドの直接音声翻訳システムは、ASR事前に訓練されたエンコーダーとマルチタスクデコーダーを使用しています。提出されたシステムは、異なるカスケードモデルによってアンサンブルされます。</abstract_ja>
      <abstract_zh>本文中,我们述述了浙江大学向IWSLT2021多语言语音译职的提交。 此侧重于诸非英语言语音译 (ST) 究。 参与者可以外数者,犹无约束也。 创建级联与端到端语音译约束系统,仅用供数。 级联之道,将基于 Conformer 之自音 (ASR) 与 Transformer 之神经机器翻译 (NMT) 合。 端端直语译系统用 ASR 预训练编码器多任务解码器。 提交之统,异级联而成。</abstract_zh>
      <abstract_hi>इस पेपर में, हम IWSLT2021 बहुभाषी भाषण अनुवाद कार्य के लिए Zhejiang University के प्रस्तुतीकरण का वर्णन करते हैं। यह कार्य कई गैर-अंग्रेजी स्रोत भाषाओं में भाषण अनुवाद (एसटी) अनुसंधान पर केंद्रित है। प्रतिभागी यह तय कर सकते हैं कि क्या विवश प्रणालियों या अप्रतिबंधित प्रणालियों पर काम करना है जो बाहरी डेटा का उपयोग कर सकते हैं। हम केवल प्रदान किए गए डेटा का उपयोग करके कैस्केड और एंड-टू-एंड स्पीच ट्रांसलेशन विवश सिस्टम दोनों बनाते हैं। कैस्केड दृष्टिकोण में, हम ट्रांसफॉर्मर-आधारित तंत्रिका मशीन अनुवाद (एनएमटी) के साथ कन्फॉर्मर-आधारित स्वचालित भाषण मान्यता (एएसआर) को जोड़ते हैं। हमारे एंड-टू-एंड डायरेक्ट स्पीच ट्रांसलेशन सिस्टम एएसआर प्रीट्रेन्ड एनकोडर और मल्टी-टास्क डिकोडर का उपयोग करते हैं। प्रस्तुत प्रणालियों को विभिन्न कैस्केड मॉडल द्वारा पहनाया जाता है।</abstract_hi>
      <abstract_ga>Sa pháipéar seo, déanaimid cur síos ar aighneacht Ollscoil Zhejiang chuig Tasc Aistriúcháin Urlabhra Ilteangacha IWSLT2021. Díríonn an tasc seo ar thaighde ar aistriúchán cainte (ST) thar go leor teangacha foinseacha nach Béarla iad. Féadfaidh rannpháirtithe a chinneadh cé acu a n-oibreoidh siad ar chórais shrianta nó ar chórais neamhshrianta ar féidir leo sonraí seachtracha a úsáid. Cruthaímid córais aistrithe cainte cascáideacha agus ceann-go-deireadh araon srianta, ag baint úsáide as na sonraí a chuirtear ar fáil amháin. Sa chur chuige cascáideach, comhcheanglaímid Aitheantas Uathoibríoch Urlabhra (ASR) atá bunaithe ar Chomhfhoirmeoir agus an t-aistriúchán meaisín néar-bhunaithe Trasfhoirmeoir (NMT). Úsáideann ár gcórais aistrithe cainte díreach ó cheann go ceann ionchódóir réamh-oilte ASR agus díchódóirí il-tasc. Déantar na córais a cuireadh isteach a chomhcheangal le samhlacha éagsúla cascáideacha.</abstract_ga>
      <abstract_ka>ამ დოკუნში ჩვენ ჩემი განახსენებთ ზეზიანგის სუნივერტის დამუშაობა IWSLT2021 მრავალენგური საუბრო განახსენის რაოდენობაში. (ST) ბევრი ანგლისური მსოფლიო ენაში. დაწყვეტებელი შეუძლია გადაწყვეტა, თუ არა შესაძლებელია გარეშე მონაცემების გამოყენება შესაძლებელია გარეშე სისტემაში ან გარეშე სისტემაში. ჩვენ შევქმნით კაკადის და ბოლოდან დასრულებული სისტემის გადასრულებას, მხოლოდ დასრულებული მონაცემების გამოყენება. კაკადირებული პროგრამაში, ჩვენ კონფრიგური ავტომატიკური სიტყვების განახლება (ASR) დავყენებთ ტრანფორმების განახლებით ნეიროლური მანქანის განახლებით (NMT). ჩვენი საბოლოო დასასრულებელი სისტემები გამოყენება ASR-ს გამოყენებული კოდირები და მრავალ დავალებელი დეკოდერები. შეტყობინებული სისტემები განსხვავებული კაკაკადირებული მოდელებით დააყენება.</abstract_ka>
      <abstract_el>Σε αυτή την εργασία, περιγράφουμε την υποβολή του Πανεπιστημίου στο έργο της πολύγλωσσης μετάφρασης ομιλίας. Το έργο αυτό επικεντρώνεται στην έρευνα μετάφρασης ομιλίας σε πολλές γλώσσες προέλευσης εκτός Αγγλικής γλώσσας. Οι συμμετέχοντες μπορούν να αποφασίσουν αν θα εργαστούν σε περιορισμένα συστήματα ή σε μη περιοριστικά συστήματα που μπορούν να χρησιμοποιούν εξωτερικά δεδομένα. Δημιουργούμε και συστήματα περιορισμένης μετάφρασης ομιλίας, χρησιμοποιώντας μόνο τα παρεχόμενα δεδομένα. Στη διαδοχική προσέγγιση, συνδυάζουμε την αυτόματη αναγνώριση ομιλίας με βάση τον μετασχηματιστή με τη νευρωνική μηχανική μετάφραση (NMT). Τα ολοκληρωμένα συστήματα άμεσης μετάφρασης ομιλίας μας χρησιμοποιούν προκαθορισμένο κωδικοποιητή και αποκωδικοποιητές πολλαπλών εργασιών. Τα υποβαλλόμενα συστήματα συνδυάζονται από διαφορετικά μοντέλα.</abstract_el>
      <abstract_hu>Ebben a tanulmányban bemutatjuk a Zhejiang Egyetem beadványát az IWSLT201 többnyelvű beszédfordítási feladatra. Ez a feladat a beszédfordítás (ST) kutatására összpontosít számos nem angol nyelven. A résztvevők dönthetnek arról, hogy korlátozott rendszereken vagy korlátlan rendszereken dolgoznak-e, amelyek képesek külső adatokat használni. Mind kaszkádos, mind végpontos beszédfordítási korlátozott rendszereket hozunk létre, kizárólag a megadott adatok felhasználásával. A kaszkádos megközelítésben a Conformer-alapú automatikus beszédfelismerést (ASR) kombináljuk a Transformer-alapú neurális gépi fordítással (NMT). Teljes körű közvetlen beszédfordító rendszereink ASR előképzett kódolót és többfeladatos dekódereket használnak. A benyújtott rendszereket különböző kaszkádos modellek állítják össze.</abstract_hu>
      <abstract_it>In questo articolo, descriviamo la presentazione dell'Università di Zhejiang al compito di traduzione vocale multilingue IWSLT201. Questo compito si concentra sulla ricerca sulla traduzione vocale (ST) in molte lingue di origine non inglesi. I partecipanti possono decidere se lavorare su sistemi vincolati o sistemi non vincolati che possono utilizzare dati esterni. Creiamo sistemi di traduzione vocale a cascata e end-to-end vincolati, utilizzando solo i dati forniti. Nell'approccio a cascata, combiniamo il riconoscimento vocale automatico basato su Conformer (ASR) con la traduzione automatica neurale basata su Transformer (NMT). I nostri sistemi end-to-end di traduzione vocale diretta utilizzano encoder pretrained ASR e decoder multi-task. I sistemi presentati sono assemblati da diversi modelli a cascata.</abstract_it>
      <abstract_kk>Бұл қағазда Жежинг университетінің IWSLT2021 көптілік сөйлі аудару тапсырмасына жіберілгенін таңдаймыз. Бұл тапсырма сөздердің аудармасына (ST) ағылшын емес тілдердің көпшілігін зерттеуде назар аударады. Қатысушылар сыртқы деректерді қолданатын шектелген жүйелер не шектелмеген жүйелерде жұмыс істеуге болады. Біз тек келтірілген деректерді қолдану үшін каскад және соңғы сөздердің аударуын шектелген жүйелерді құрамыз. Каскадтық тәсілінде, Конformer- негіздеген автоматты сөздерді (ASR) түрлендіруші негіздеген невралдық компьютердің аудармасымен (NMT) біріктіреміз. Біздің аяқтау- аяқтау тікелей аудару жүйелеріміз ASR көп тапсырма декодерін және көп тапсырма декодерін қолданады. Келтірілген жүйелер әртүрлі каскадтық үлгілерден қолданылады.</abstract_kk>
      <abstract_lt>Šiame dokumente apibūdiname Zhejiang universiteto pateiktą IWSLT2021 daugiakalbio kalbos vertimo užduotį. Šioje užduotyje daugiausia dėmesio skiriama kalbos vertimo (ST) moksliniams tyrimams daugelyje ne anglų kilmės kalbų. Dalyviai gali nuspręsti, ar dirbti su ribotomis sistemomis ar neribotomis sistemomis, kurios gali naudoti išorinius duomenis. We create both cascaded and end-to-end speech translation constrained systems, using the provided data only.  In the cascaded approach, we combine Conformer-based automatic speech recognition (ASR) with the Transformer-based neural machine translation (NMT).  Mūsų tiesioginio kalbos vertimo sistemos naudoja ASR iš anksto apmokytą kodatorių ir daugelio užduočių dekoderius. Pateiktas sistemas sudaro skirtingi kaskadiniai modeliai.</abstract_lt>
      <abstract_mk>Во овој весник, го опишуваме поднесувањето на Универзитетот Жејанг на IWSLT2021 Мултијазичниот превод на говорот. Оваа задача се фокусира на преведувањето на говорот (СТ) истражување на многу неанглиски јазици. Учесниците можат да одлучат дали да работат на ограничени системи или неограничени системи кои можат да користат надворешни податоци. We create both cascaded and end-to-end speech translation constrained systems, using the provided data only.  Во каскадираниот пристап, ние го комбинираме автоматското препознавање на говорот на основа на Конформер (Conformer-based Automatic Speak Recognition, ASR) со преводот на нервната машина на основа на Трансформер (NMT). Нашите системи за директен превод на говор користат ASR претрениран кодер и мултизадачни декодери. Предложените системи се составени од различни каскадирани модели.</abstract_mk>
      <abstract_ms>Dalam kertas ini, kami menggambarkan penghantaran Universiti Zhejiang kepada Tugas Terjemahan Ucapan Berbahasa IWSLT2021. Tugas ini fokus pada kajian terjemahan ucapan (ST) melalui banyak bahasa sumber bukan bahasa Inggeris. Peserta boleh memutuskan sama ada hendak bekerja pada sistem terhalang atau sistem tidak terhalang yang boleh menggunakan data luaran. Kami mencipta kedua-dua sistem terhalang terjemahan ucapan, dengan menggunakan data yang diberikan sahaja. Dalam pendekatan berkaskad, kita menggabungkan pengenalan pidato automatik berdasarkan Konformor (ASR) dengan terjemahan mesin saraf berdasarkan Transformer (NMT). Sistem terjemahan ucapan langsung akhir-akhir kami menggunakan pengekod terlatih ASR dan pengekod berbilang-tugas. Sistem yang dihantar dikumpulkan oleh model yang berbeza.</abstract_ms>
      <abstract_mn>Энэ цаасан дээр бид Жежиангийн Их Сургуулийн IWSLT2021 оны олон хэл хэлний хөгжлийн хөгжлийн ажлыг тайлбарлаж байна. Энэ ажил илтгэл хөрөнгө хөрөнгө оруулах (ST) судалгаанд англи хэлний бус олон хэл дээр анхаарлаа хандуулдаг. Харин оролцогчид гадаад өгөгдлийг ашиглаж болох хязгаарлагдсан систем эсвэл хязгаарлагдсан систем дээр ажиллах эсэхийг шийдэж болно. Бид дараагийн өгөгдлийг зөвхөн ашиглан каскад болон сүүлийн үеийн ярианы хөрөнгө оруулалт хязгаарлагдсан системүүдийг бүтээж байна. Каскаддын арга хэлбэрээр бид Конformer-д автоматик ярианы танихыг (ASR) Трансфер-д суурилсан мэдрэлийн машины хөгжлийг (NMT) цуглуулдаг. Бидний ярианы төгсгөлд шууд хөрөнгө оруулах системүүд АСР-ын шингээгдсэн коддогч болон олон ажлын шингээгч ашигладаг. Холбогдолтын системүүд өөр каскадтай загварууд байдаг.</abstract_mn>
      <abstract_mt>F'dan id-dokument, aħna niddeskrivu s-sottomissjoni tal-Università Zhejiang lill-IWSLT2021 Multilingual Speech Translation Task. Dan il-kompitu jiffoka fuq ir-riċerka dwar it-traduzzjoni tad-diskors (ST) f’ħafna lingwi tas-sors mhux Ingliż. Il-parteċipanti jistgħu jiddeċiedu jekk jaħdmux fuq sistemi ristretti jew sistemi mhux ristretti li jistgħu jużaw dejta esterna. Aħna nħolqu kemm sistemi ta’ traduzzjoni tad-diskors b’mod konġunt kif ukoll b’mod konġunt, bl-użu tad-dejta pprovduta biss. Fl-approċċ kaskat, aħna ngħaqdu r-rikonoxximent awtomatiku tad-diskors ibbażat fuq il-konformer (ASR) mat-traduzzjoni tal-magna newrali bbażata fuq it-Transformer (NMT). Is-sistemi tagħna ta’ traduzzjoni diretta tad-diskors minn tarf sa tarf jużaw kodifikatur ASR imħarreġ minn qabel u dekodituri multikompiti. Is-sistemi sottomessi huma magħmulin minn mudelli kaskati differenti.</abstract_mt>
      <abstract_ml>ഈ പത്രത്തില്‍ ഞങ്ങള്‍ സെജിയാങ്ങ് യൂണിവേഴ്സിറ്റിയിലേക്ക് വിവരിച്ചുകൊടുക്കുന്നു. IWSLT2021 പല ഭാഷ വായിക്കുന്ന ഇംഗ്ലീഷ് സോര്‍സ്സ് ഭാഷകങ്ങള്‍ക്കുള്ള പല ഭാഷകളിലും സംസാരിക്കുന്നതിന്‍റെ (ST) പരിശോധനത്തിന പുറത്തുള്ള വിവരങ്ങള്‍ ഉപയോഗിക്കാന്‍ സാധിക്കുന്ന സിസ്റ്റങ്ങളില്‍ ജോലി ചെയ്യുമോ എന്നോ പങ്കാളികള്‍ നമ്മള്‍ രണ്ടുപേരും കാസ്കാഡ് ചെയ്തിരിക്കുന്നു, അവസാന സംസാരം അവസാനിപ്പിക്കുന്ന സിസ്റ്റമുകള്‍ നിര്‍ബന കാസ്കേഡ് നടപടിയില്‍ നമ്മള്‍ കോണ്‍ഫോര്‍മാര്‍ അടിസ്ഥാനമായി സംസാരിക്കുന്ന സ്വയമായി സംസാരിക്കുന്ന സ്വഭാഷണത്തിന്റെ തിരിച് നമ്മുടെ അവസാനത്തില്‍ നേരിട്ട് നേരിട്ട് സംസാരിക്കുന്ന പരിഭാഷണ സിസ്റ്റത്തിന്റെ ആസ്ആര്‍ കോഡെര്‍ എന്‍കോഡെ സമര്‍പ്പിക്കപ്പെട്ട സിസ്റ്റമുകള്‍ വ്യത്യസ്ത കാസ്കേഡ് മോഡലുകള്‍ കൊണ്ടാണ്.</abstract_ml>
      <abstract_pl>W niniejszym artykule opisujemy zgłoszenie Uniwersytetu Zhejiang do zadania IWSLT2021 Wielojęzycznego Tłumaczenia Mowy. Zadanie to koncentruje się na badaniach nad tłumaczeniem mowy (ST) w wielu językach źródłowych nieangielskich. Uczestnicy mogą zdecydować, czy chcą pracować nad systemami ograniczonymi czy systemami nieograniczonymi, które mogą korzystać z danych zewnętrznych. Tworzymy zarówno kaskadowe, jak i kompleksowe systemy ograniczone do tłumaczenia mowy, wykorzystując tylko dostarczone dane. W podejściu kaskadowym łączymy automatyczne rozpoznawanie mowy oparte na Conformerze (ASR) z transformatorowym tłumaczeniem maszynowym (NMT). Nasze kompleksowe systemy tłumaczenia mowy bezpośredniej wykorzystują koder ASR i dekodery wielozadaniowe. Przesłane systemy są zestawione przez różne modele kaskadowe.</abstract_pl>
      <abstract_sr>U ovom papiru opisujemo podnošenje Univerziteta Žejijanga na zadatak multijezičkog prevoda govora IWSLT2021. Ovaj zadatak se fokusira na istraživanje govornog prevoda (ST) na mnogim jezicima koje nisu engleski izvori. Učesnici mogu odlučiti da li rade na ograničenim sistemima ili nekonstreniranim sistemima koji mogu koristiti vanjske podatke. Napravili smo ograničene sisteme prevođenja govora i kaskadiranih i konačnih govora, koristeći samo pružene podatke. U kaskadnom pristupu, kombiniramo prepoznavanje automatskog govora na Konformu (ASR) sa prevodom neuralne mašine na transformatoru (NMT). Naši sistemi prevoda izravnog govora koriste ASR pretkišni koder i multi-zadatak dekodere. Predloženi sistemi su uključeni različitim kaskadnim modelima.</abstract_sr>
      <abstract_ro>În această lucrare, descriem depunerea Universității Zhejiang la sarcina de traducere a vorbirii multilingve IWSLT201. Această sarcină se concentrează pe cercetarea traducerii vorbirii (ST) în multe limbi sursă non-engleze. Participanții pot decide dacă să lucreze la sisteme restricționate sau sisteme fără restricții care pot utiliza date externe. Creăm atât sisteme de traducere vocală în cascadă, cât și sisteme cu restricții end-to-end, utilizând numai datele furnizate. În cadrul abordării în cascadă, combinăm recunoașterea automată a vorbirii bazată pe Conformer (ASR) cu traducerea automată neurală bazată pe Transformer (NMT). Sistemele noastre de traducere vocală directă end-to-end utilizează encoder pre-instruit ASR și decodoare multi-task. Sistemele prezentate sunt ansamblate prin diferite modele în cascadă.</abstract_ro>
      <abstract_no>I denne papiret beskriver vi at Zhejiang Universiteten s øker til IWSLT2021 multispråksomsetjinga. Denne oppgåva fokuserer på taleomsetjinga (ST) forskning på mange ikkje- engelske kjeldespråk. Deltakarar kan bestemme om det skal arbeidast på begrensede systemar eller ukonstrurte systemar som kan bruka eksterne data. Vi oppretter både avgrensa taleomsetjingssystemer som er kaskadert og slutt- til- slutt. Berre brukar dei oppgjevne data. I kaskadert tilnærming kombinerer vi automatisk tale- gjenkjenning (ASR) med omsetjinga på transformeringsbasert neuralmaskin (NMT). Våre end- to- end direkte taleomsetjingssystemet brukar ASR- teiknkoder og fleire oppgåver- dekoder. Sistemene som vert sende er markert av ulike kaskade modeller.</abstract_no>
      <abstract_so>Qoraalkan waxaynu ku qoraynaa warqaddan tarjumaadka jaamacadda Zhejiang ee IWSLT2021. Shaqodanu wuxuu ku hagaa tarjumaadda hadalka (ST) baaritaanka luuqado badan oo aan Ingiriis ahayn. Ka qeybqaadayaashu waxay go’aan ka gaari karaan in ay ka shaqeeyaan nidaamka qasabka ah ama nidaamka aan dhisnayn oo isticmaali karo macluumaadka dibada ah. Waxaannu abuurnaa nidaamka turjumidda hadalka ee dhammaadka iyo dhammaadka ugu dambaysta ah, isticmaalka macluumaadka la siiyey oo kaliya. Xaaladaha xadhka ah, waxaynu ku soo bandhignaynaa aqoonsashada hadalka asalka ah ee Conformer (ASR) oo ku qoran turjumidda maskine neural (NMT). Isticmaalaha turjumista hadalka ee ugu dambeeya ee toos-ka ah waxay isticmaalaan ASR-ka-hor-dhigista codcodsiga iyo shaqo badan. Isticmaalka la soo dhiibay waxaa ku yaala muusiko kala duduwan oo lagu sameeyo.</abstract_so>
      <abstract_sv>I den h채r uppsatsen beskriver vi Zhejiang universitets bidrag till IWSLT201s flerspr책kiga spr책k철vers채ttningsuppgift. Denna uppgift fokuserar p책 tal철vers채ttning (ST) forskning 철ver m책nga icke-engelska k채llspr책k. Deltagarna kan besluta om de vill arbeta med begr채nsade system eller obegr채nsade system som kan anv채nda externa data. Vi skapar b책de kaskaderade och helt채ckande system med begr채nsningar f철r tal철vers채ttning, endast med hj채lp av de data som tillhandah책lls. I det kaskadbaserade tillv채gag책ngss채ttet kombinerar vi Conformer-baserad automatisk taligenk채nning (ASR) med Transformer-baserad neural machine translation (NMT). V책ra helt채ckande system f철r direkttal철vers채ttning anv채nder ASR-f철rkl채dd kodare och multi-task avkodare. De inl채mnade systemen 채r sammansatta av olika kaskadmodeller.</abstract_sv>
      <abstract_ur>اس کاغذ میں ہم ججینگ یونیوریوسٹ کی تعلیم IWSLT2021 Multilingual Speech Translation Task کو بیان کرتے ہیں. یہ کام کلام ترجمہ (ST) کی تحقیقات کے لئے بہت سی غیر انگلیسی سراسر زبانوں میں تمرکز کرتا ہے. شرکت کرنے والوں کا فیصلہ کر سکتے ہیں کہ تنگ سیسٹم یا ناتنگریز سیسٹم پر کام کریں جو باہر ڈیٹا استعمال کر سکتے ہیں. ہم نے کاسک ڈیٹا اور آخر پر کلام کی ترجمہ محدود سیستموں کو پیدا کیا ہے، صرف اطلاعات کے مطابق۔ کاسکڈ طریقے میں، ہم Conformer-based automatic speech recognition (ASR) کو ترنسفور-based neural machine translation (NMT) کے ساتھ جمع کرتے ہیں. ہمارے پائین-پائین-پائین صحیح بات کی ترجمہ سیسٹم ASR کی پیٹرینڈ کوڈر اور بہت سے کام ڈکوڈر استعمال کرتے ہیں. تحویل کیے گئے سیستموں کو مختلف کاسک ڈیلڈ کے ذریعے پیدا کیا گیا ہے.</abstract_ur>
      <abstract_si>මේ පත්තරේ අපි ජෙජියාන්ග් විශ්වාසිත්තාවේ IWSLT2021 ගොඩක් භාෂාවක් භාෂාවක් භාෂාවක් කාර්යාලයට පැ (ST) ඉංග්‍රීසිය නොවන භාෂාවක් වලින් මේ වැඩේ සංවේදනය කරනවා. සහයෝජකයෝ තීරණය කරන්න පුළුවන් විශ්වාස කරන්න පුළුවන් ප්‍රධාන පද්ධතියක් නැති පද්ධතියේ වැඩ කරන්න අපි කැස්කේඩ් වලින් අවසානය වලින් අවසානය වලින් කතා පද්ධතිය නිර්මාණය කරනවා, දෙන්න තොරතුරු විතරයි කැස්කේඩ් විදිහට, අපි කොන්ප්‍රේෂ් විදිහට ස්වයංක්‍රීය කතාව අඳුරන්න (ASR) සමග සංවිධානය කරන්නේ න්‍යුරල් යන්ත්‍රය අපේ අන්තිම වාර්තාවක් පද්ධතිය පාවිච්චි කරන්න ASR ප්‍රීට්‍රේන්ඩ් කරුණාකරුවක් සහ ගොඩක් වැඩි වැඩියා පිළිගන්න පද්ධතිය වෙනස් කැස්කේඩ් මොඩේල් වලින් සංවිධානය කරනවා.</abstract_si>
      <abstract_ta>இந்த காகிதத்தில், நாம் ஜெஜியாங் கல்வியூரிக்கு IWSLT2021 பல் மொழி பேச்சு மொழிபெயர்ப்பு பணியை விவரிக்கிறோம். இந்த பணி பேச்சு மொழிபெயர்ப்பு (ST) ஆராய்ச்சியை பல ஆங்கிலத்தின் மூலத்தின் மொழிகளில் குறிப்பி வெளி தரவை பயன்படுத்தும் போது கட்டுப்படுத்தப்பட்ட கணினிகளில் வேலை செய்ய முடியுமா அல்லது நிறுத்தப்படாத அமைப்புகள கொடுக்கப்பட்ட தரவை மட்டும் பயன்படுத்தி பேச்சு மொழிபெயர்ப்பு அமைப்புகளை உருவாக்குகிறோம். நாம் மாற்றும் அடிப்படையில் மாற்றும் அடிப்படையிலான பேச்சு அடிப்படையில் தானாகவே பேச்சு அடிப்படையாக (ASR) மொழிபெயர்ப்பு ப எங்கள் முடிவில் இருந்து நேரடி பேச்சு மொழிபெயர்ப்பு அமைப்புகள் ASR குறிமுறையாக்கி மற்றும் பல பணி குறியீட வழங்கப்பட்ட அமைப்புகள் மாறுபட்ட மாதிரிகளால் உள்ளடக்கப்பட்டுள்ளன.</abstract_ta>
      <abstract_vi>Trong tờ giấy này, chúng tôi mô tả việc trường đại học Chiết Giang chịu trách nhiệm dịch chuyển đa ngôn ngữ: Nhiệm vụ này tập trung vào nghiên cứu dịch thuyết (ST) trên nhiều ngôn ngữ nguồn khác tiếng Anh. Người tham gia có thể quyết định nên làm việc với hệ thống hạn chế hay hệ thống chưa được huấn luyện có thể sử dụng dữ liệu bên ngoài. Chúng tôi tạo ra các hệ thống hạn chế dịch thuyết và kết thúc bằng cách sử dụng các dữ liệu được cung cấp. Trong phương pháp đo ngược, chúng ta kết hợp nhận dạng ngôn ngữ tự động Conformer (ASR) với dịch vụ máy thần kinh Tranformer (NMB). Hệ thống dịch giọng trực tiếp kết thúc của chúng ta dùng mã hóa hình ASR và mã giải đa nhiệm. Các hệ thống được gửi đi được kết hợp với các mô hình phụ khác nhau.</abstract_vi>
      <abstract_uz>Bu hujjatda biz Zhejiang universitetga IWSLT2021 ko'plab tillar tili tarjima vazifasini anglatamiz. This task focuses on speech translation (ST) research across many non-English source languages.  @ info @ info: whatsthis Ko'rsatilgan holatda, biz Transformer asosida yaratilgan neural tarjima (NMT) bilan Avtomatik aytish (ASR) bilan birlashtiramiz. @ info: whatsthis Joʻnatilgan tizimlar boshqa qanday qoʻllangan modellar tomonidan qo'yiladi.</abstract_uz>
      <abstract_nl>In dit artikel beschrijven we de inzending van de Zhejiang Universiteit aan de IWSLT2021 Meertalige Spraakvertaaltaak. Deze taak richt zich op spraakvertaling (ST) onderzoek in vele niet-Engelse brontalen. Deelnemers kunnen beslissen of ze werken aan beperkte systemen of aan ongecomprimeerde systemen die gebruik kunnen maken van externe data. We maken zowel cascade- als end-to-end systemen met beperkingen op spraakvertaling, alleen met behulp van de verstrekte gegevens. In de cascade-benadering combineren we Conformer-gebaseerde automatische spraakherkenning (ASR) met de Transformer-based neural machine translation (NMT). Onze end-to-end directe spraakvertaalsystemen maken gebruik van ASR voorgetrainde encoders en multi-task decoders. De ingediende systemen worden samengevoegd door verschillende cascademodellen.</abstract_nl>
      <abstract_bg>В тази статия описваме представянето на Университета на Zhejiang към задачата за многоезичен превод на реч. Тази задача се фокусира върху изследване на речния превод (СТ) на много езици, които не са английски източник. Участниците могат да решат дали да работят върху ограничени системи или неограничени системи, които могат да използват външни данни. Създаваме както каскадни, така и системи с ограничен речен превод от край до край, като използваме само предоставените данни. В каскадния подход комбинираме автоматичното разпознаване на речта на базата на Конформер (АСР) с невронния машинен превод на базата на трансформатор (НМТ). Нашите системи за директен речен превод от край до край използват предварително трениран кодер и многофункционални декодери. Представените системи са съставени от различни каскадни модели.</abstract_bg>
      <abstract_da>I denne artikel beskriver vi Zhejiang Universitets indsendelse til IWSLT201s flersprogede tale oversættelse opgave. Denne opgave fokuserer på tale oversættelse (ST) forskning på tværs af mange ikke-engelske kildesprog. Deltagerne kan beslutte, om de vil arbejde på begrænsede systemer eller ubegrænsede systemer, der kan bruge eksterne data. Vi skaber både kaskaderede og end-to-end taleoversættelsesbegrænsede systemer, udelukkende ved hjælp af de leverede data. I den kaskadebaserede tilgang kombinerer vi Conformer-baseret automatisk talegenkendelse (ASR) med Transformer-baseret neural machine translation (NMT). Vores end-to-end direkte tale oversættelsessystemer bruger ASR forudtrænet encoder og multi-task dekodere. De indsendte systemer er sammensat af forskellige kaskademodeller.</abstract_da>
      <abstract_de>In diesem Beitrag beschreiben wir die Einreichung der Zhejiang University an die IWSLT2021 Multilingual Speech Translation Task. Diese Aufgabe konzentriert sich auf Sprachübersetzung (ST) in vielen nicht-englischen Quellsprachen. Die Teilnehmer können entscheiden, ob sie an eingeschränkten Systemen oder an ungehinderten Systemen arbeiten, die externe Daten verwenden können. Wir erstellen sowohl kaskadierte als auch End-to-End-Systeme mit eingeschränkter Sprachübersetzung, wobei nur die bereitgestellten Daten verwendet werden. Im kaskadierten Ansatz kombinieren wir Conformer-basierte automatische Spracherkennung (ASR) mit der Transformer-basierten neuronalen maschinellen Übersetzung (NMT). Unsere End-to-End-Direktsprachübersetzungssysteme verwenden ASR-vortrainierte Encoder und Multi-Task-Decoder. Die eingereichten Systeme werden durch verschiedene kaskadierte Modelle zusammengestellt.</abstract_de>
      <abstract_id>Dalam kertas ini, kami menggambarkan pengiriman Universitas Zhejiang ke Tugas Terjemahan Bicara Berbahasa IWSLT2021. This task focuses on speech translation (ST) research across many non-English source languages.  Peserta dapat memutuskan apakah untuk bekerja pada sistem terbatas atau sistem tidak terbatas yang dapat menggunakan data luar. Kami menciptakan sistem tergantung pidato yang terbatas, menggunakan data yang diberikan saja. Dalam pendekatan berkaskade, kita menggabungkan pengakuan pidato otomatis berdasarkan Conformer (ASR) dengan terjemahan mesin saraf berdasarkan Transformer (NMT). Sistem terjemahan langsung dari akhir ke akhir kita menggunakan pengekoder ASR yang dilatih dan pengekoder multi-tugas. Sistem yang diserahkan disempurnakan oleh model yang berbeda.</abstract_id>
      <abstract_hr>U ovom papiru opisujemo podnošenje Univerziteta Zhejiang na zadatak multijezičkog prevoda govora IWSLT2021. Ovaj zadatak se fokusira na istraživanje govornog prevoda (ST) na mnogim jezicima koje nisu engleski izvori. Učesnici mogu odlučiti da li rade na ograničenim sustavima ili bez ograničenih sustava koji mogu koristiti vanjske podatke. Napravili smo ograničene sustave za prevod kazkade i kraj govora, koristeći samo pružene podatke. U kaskadnom pristupu, kombiniramo priznanje automatskog govora na Conformer-u s prevodom neuralnih strojeva na transformeru (NMT). Naši sustavi za prevod izravnog govora koriste ASR-ove pretkišene kodere i multizadatke dekodere. Predloženi sustavi uključuju različite kaskadne modele.</abstract_hr>
      <abstract_sw>Katika gazeti hili, tunaelezea ujumbe wa Chuo Kikuu cha Zhejiang kwenye kazi ya Tafsiri ya Utafiti wa Lugha za IWSLT2021. Kazi hii inalenga utafiti wa kujieleza (ST) katika lugha nyingi zisizo za Kiingereza. Washiriki wanaweza kuamua ikiwa wanafanya kazi katika mifumo ya vikwazo au mifumo isiyo na mifumo ambayo inaweza kutumia takwimu za nje. Tunaweza kutengeneza mifumo ya kutafsiri hotuba yenye mabadiliko na mwisho, kwa kutumia taarifa zilizotolewa pekee. Katika mbinu za mabadiliko, tunaunganisha kutambua hotuba yenye msingi wa mabadiliko (ASR) kwa utafsiri wa mashine yenye asili ya kibinafsi (NMT). Mfumo wetu wa kutafsiri kwa moja kwa moja wa hotuba unaotumia ASR unaoendelea kupunguza kodi na kupunguza kazi nyingi. The submitted systems are ensembled by different cascaded models.</abstract_sw>
      <abstract_fa>در این کاغذ، ما تحویل دانشگاه ژجیانگ را به تابع تعریف کلمه‌های زیادی زبان IWSLT2021 توصیف می‌کنیم. این وظیفه روی تحقیقات ترجمه سخنرانی (ST) در زبانهای منبع غیر انگلیسی تمرکز می‌کند. شرکتگران می‌توانند تصمیم بگیرند که آیا بر سیستم‌های محدود یا سیستم‌های غیرمحدود کار کنند که می‌توانند از داده‌های خارجی استفاده کنند. ما هم با استفاده از داده‌های داده‌ای داده می‌شود، سیستم‌های محدودیت و ترجمه‌ی گفته‌های کاسکد و پایان‌پایان را ایجاد می‌کنیم. در روش کاسکد، ما با ترجمه‌های ماشین عصبی (NMT) بر اساس ترجمه‌کننده‌ی تبدیل‌کننده‌ها، شناسایی سخنرانی خودکار (ASR) بر اساس کاسکد متحد می‌کنیم. سیستم‌های ترجمه‌ی صحبت مستقیم به پایان پایان ما استفاده می‌کنند از رمز‌کننده‌های ASR و دکوردر‌کننده‌های بسیاری از کار‌ها. سیستم‌های تحویل داده شده توسط مدل‌های کاسکیدی متفاوت مشترک می‌شوند.</abstract_fa>
      <abstract_ko>본고에서 우리는 절강대학이 IWSLT2021 다국어 음성 번역 임무에 제출한 상황을 묘사했다.이 임무의 중점은 많은 비영어 원어와 관련된 음성 번역(ST) 연구에 있다.참여자는 제한된 시스템에서 일하는지 외부 데이터를 사용할 수 있는 무제약 시스템에서 일하는지 결정할 수 있다.우리는 제공된 데이터만 사용하여 단계별 연결과 단계별 음성 번역 제약 시스템을 만듭니다.캐스케이드 방법에서는 이미지 기반 자동음성인식(ASR)과 변환기 기반 신경기계번역(NMT)을 결합한다.우리의 단말기부터 단말기까지 직접 음성 번역 시스템은 ASR 예비 트레이닝 인코더와 다중 임무 인코더를 사용합니다.제출된 시스템은 서로 다른 등급 연결 모델로 통합된다.</abstract_ko>
      <abstract_af>In hierdie papier beskrywe ons Zhejiang Universiteit se onderskrywing aan die IWSLT2021 Multilingual Speech Translation Task. Advanced URLs: description or category Deelnaders kan besluit of werk op beheinde stelsels of onbeheinde stelsels wat eksterne data kan gebruik. Ons skep beide kaskadeerde en einde-na-einde spraak vertaling bevestig stelsels, gebruik slegs die verskaf data. In die kaskadeerde toegang, kombinieer ons Conformer-gebaseerde automatiese spreek herken (ASR) met die Transformer-gebaseerde neurale masjien vertaling (NMT). Ons einde- na- einde direkte woorde vertaling stelsels gebruik ASR-pretrained enkoder en multi- task dekodere. Die voorgestuurde stelsels word deur verskillende kaskadeerde modele ingestel.</abstract_af>
      <abstract_am>በዚህ ገጽ፣ የዚጅang ዩንቨርስቲ ለIWSLT2021 Multiቋንቋ ቋንቋ ትርጉም ስራዎችን አቅርብ እናሳውቃለን፡፡ ይህ ስራ በንግግር ትርጉም (ST) ላይ በብዙ እንግሊዝኛ ቋንቋዎች ያሉትን ትርጓሜዎችን ያስተካክላል፡፡ ተጋሪዎች ውጭ መረጃዎችን ለመጠቀም የሚችሉትን የስርዓት ስርዓቶች ወይም የውጭ መረጃዎችን ለመሥራት ይችላል፡፡ We create both cascaded and end-to-end speech translation constrained systems, using the provided data only.  በተገኘው አካሄድ፣ የኮንፎርማር-based የንግግር አውቶማቲ ማውቀት (ASR) በተመሳሳይ የናውሬል መሣሪያን ትርጓሜ (NMT) እናጋራለን፡፡ መጨረሻ እስከ መጨረሻ ቀጥተኛ ንግግር ትርጉም ሲስተካከላችን ASR የኮድ ኮድዶችን እና ብዙ አድራሻ ኮድዶችን ይጠቅማል፡፡ የተዘጋጁት ስርዓቶች በተለየ ጥቁር ዓይነቶች ውስጥ ናቸው፡፡</abstract_am>
      <abstract_sq>Në këtë letër, ne përshkruajmë paraqitjen e Universitetit Zhejiang në IWSLT2021 Multilingual Speech Translation Task. Kjo detyrë përqëndrohet në kërkimin e përkthimit të fjalës (ST) nëpërmjet shumë gjuhëve jo-angleze burimi. Pjesëmarrësit mund të vendosin nëse duhet të punojnë në sisteme të kufizuara apo në sisteme të pa kufizuara që mund të përdorin të dhëna të jashtme. Ne krijojmë si sisteme të kufizuara të përkthimit të fjalës nga fundi në fund, duke përdorur vetëm të dhënat e dhëna. Në qasjen e kaskaduar, ne kombinojmë njohjen automatike të fjalës bazuar në konformitet (ASR) me përkthimin e makinës nervore bazuar në Transformer (NMT). Sistemet tona të përkthimit të fjalimit të drejtpërdrejtë përdorin koduesin ASR dhe dekoderët me shumë detyra. Sistemet e paraqitura janë mbledhur nga modele të ndryshme të kaskaduara.</abstract_sq>
      <abstract_tr>Bu kagyzda biz Zhejiang Uniwersitetiniň IWSLT2021-iň köp dilli s öz terjime täbligini tassyklaýarys. Bu zady çykyş terjime edilmesine (ST) Iňlisçe-däl dillerden ybarat. Gatnaşmalar çykyş sistemlerde ýa daşary maglumatlary ulanyp biljek ählisini karar berebilir. Biz iki kaskady we soňunda çykyş terjime edilen sistemleri bar diňe berilen maglumatlary ulanýarys. Kakadyň ýalaýyşynda, Konformer-da awtomatik çykyş tanaýmasy (ASR) şeklinde terjime edilen näral maşynyň terjimesini (NMT) bilen birleşýäris Biziň soňunda direkt çykyş sistemlerimiz ASR öňünden kodçylar we köp-täblik kodçularyny ulanýarlar. Mümkin edilen sistemler farklı kaskadly nusgalar tarapyndan ýazylýar.</abstract_tr>
      <abstract_hy>Այս թղթի մեջ մենք նկարագրում ենք Ժեյյանգի համալսարանի ներկայացումը IW-ՍԼԹ2021-ի բազլեզու լեզվի թարգմանման առաջադրանքին: Այս խնդիրը կենտրոնանում է խոսքի թարգմանման (ՍՏ) հետազոտության վրա շատ ոչ անգլերեն լեզուներում: մասնակիցները կարող են որոշել, թե պետք է աշխատել սահմանափակ համակարգերի վրա կամ անսահմանափակ համակարգերի վրա, որոնք կարող են օգտագործել արտաքին տվյալներ: Մենք ստեղծում ենք նաև կասկադի և վերջ-վերջ խոսքի թարգմանման սահմանափակ համակարգեր, միայն օգտագործելով տրամադրված տվյալները: Կասկադի մոտեցում մենք համադրում ենք Կոնֆորմերի հիմնված ավտոմատիկ խոսքի ճանաչման (ASR) և Թանֆորմերի հիմնված նյարդային մեքենայի թարգմանման (NMT) հետ: Մեր անմիջական խոսքի թարգմանման համակարգերը օգտագործում են ASR նախապատրաստված կոդավորիչներ և բազմախնդիրներ: Պատրաստված համակարգերը համակարգված են տարբեր կասկադի մոդելների միջոցով:</abstract_hy>
      <abstract_az>Bu kańüńĪzda, Zhejiang Universitetinin IWSLT2021 √ßoxlu dil √áeviri TaqumlarńĪ Taskinin t…ôsdiql…ônm…ôsini t…ôsdiql…ôyirik. Bu g√∂rev ńįngiliz…ô olmayan √ßoxlu m…ônb…ô dill…ôrind…ô danńĪŇümaq √ľ√ß√ľn danńĪŇüma √ßevirilm…ôsi (ST) araŇütńĪrmasńĪna odaqlanńĪr. Ňě…ôr…ôf…ô√ßil…ôr √ß…ôtin m…ôlumatlarńĪ istifad…ô ed…ô bil…ôc…ôk m√ľ…ôyy…ôn edilmiŇü sisteml…ôrd…ô v…ô ya bańülńĪ sisteml…ôrd…ô √ßalńĪŇüacaqlarńĪna karar verirl…ôr. Biz h…ôr ikisini kascada v…ô sona g…ôl…ôn s√∂zl…ôr t…ôkrarlamasńĪ m√ľ…ôyy…ôn edilmiŇü sisteml…ôri yaratdńĪq, ancaq veril…ôn m…ôlumatlarńĪ istifad…ô edirik. Cascaded t…ôrzind…ô, Conformer-based automatic speech recognition (ASR) transformer-based neural machine translation (NMT) il…ô birl…ôŇüdiririk. Bizim sonumuz dońüru s√∂z √ßeviri sisteml…ôri ASR pretrained kodlayńĪcńĪ v…ô √ßoxlu iŇüin kodlayńĪcńĪlarńĪnńĪ istifad…ô edir. ńįstifad…ô edil…ôn sisteml…ôr m√ľxt…ôlif kaskadlńĪ modell…ôrl…ô m…ôŇüńüul edilir.</abstract_az>
      <abstract_bn>এই কাগজটিতে আমরা জেজিয়াং বিশ্ববিদ্যালয়ের প্রতিষ্ঠানের বর্ণনা করছি আইউএসএলটি২০১১ মাল্টিভাষী ভাষায় ভাষাভাষায় অন এই কাজ অনেক ইংরেজি সোর্স ভাষায় ভাষায় ভাষণ অনুবাদের (ST) গবেষণায় মনোযোগ দিয়েছে। অংশগ্রহণকারীরা সিদ্ধান্ত নিতে পারেন নিয়ন্ত্রিত সিস্টেমে কাজ করবে কিনা বা বাইরের তথ্য ব্যবহার করতে পারে। আমরা ক্যাস্কেড এবং শেষ পর্যন্ত ভাষণের অনুবাদ ব্যবস্থা সৃষ্টি করি, শুধুমাত্র প্রদান করা তথ্য ব্যবহার করে। ক্যাসাডেড প্রযুক্তিতে আমরা স্বয়ংক্রিয় ভিত্তিক বক্তৃতা স্বীকৃতির সাথে ট্রান্সফেক্রান্সভের ভিত্তিক নিউরেল মেশি আমাদের শেষ পর্যন্ত সরাসরি বক্তৃতা অনুবাদ সিস্টেম এসআর এনকোডার এবং বহুকাজের কোডার ব্যবহার করে। জবাব দিয়েছে সিস্টেম বিভিন্ন ক্যাসাডেড মডেল দ্বারা বিভিন্ন ভিন্ন ভিন্ন।</abstract_bn>
      <abstract_ca>En aquest article, descrivim la presentació de la Universitat Zhejiang a la IWSLT2021 Multilingual Speech Translation Task. Aquesta tasca es centra en la recerca de traducció del discurs (ST) en moltes llengües de fonts no angleses. Els participants poden decidir si treballar en sistemes restringits o sistemes no restringits que poden utilitzar dades externes. We create both cascaded and end-to-end speech translation constrained systems, using the provided data only.  En l'enfocament cascadet, combinam el reconeixement automàtic de la vosaltra basat en Conformer (ASR) amb la traducció neuromàtica basada en Transformer (NMT). Els nostres sistemes de traducció directa de vosaltres utilitzen codificadors pré-entrenats ASR i codificadors multitascos. Els sistemes submetits estan agrupats per diferents models cascades.</abstract_ca>
      <abstract_bs>U ovom papiru opisujemo podnošenje Univerziteta Zhejiang na posao multijezičkog prevoda govora IWSLT2021. Ovaj zadatak se fokusira na istraživanje govornog prevoda (ST) na mnogim jezicima koje ne znaju engleski izvori. Učesnici mogu odlučiti da li rade na ograničenim sistemima ili nekonstruovanim sistemima koji mogu koristiti vanjske podatke. Napravili smo ograničene sustave za prevod kazkade i kraj govora, koristeći samo pružene podatke. U kaskadnom pristupu, kombiniramo prepoznavanje automatskog govora na Conformer-u sa prevodom neuralnih strojeva na transformeru (NMT). Naši sistemi prevođenja izravnog govora na kraju koriste ASR-ove pretkišene kodere i multi task dekodere. Predloženi sistemi su uključeni različitim kaskadnim modelima.</abstract_bs>
      <abstract_cs>V tomto článku popisujeme podání Zhejiang University do IWSLT2021 Multilingual Speech Translation Task. Tento úkol se zaměřuje na výzkum překladu řeči (ST) napříč mnoha neanglickými zdrojovými jazyky. Účastníci se mohou rozhodnout, zda budou pracovat na omezených systémech nebo na nekompromisních systémech, které mohou využívat externí data. Vytváříme kaskádové i end-to-end systémy s omezením překladu řeči pouze s využitím poskytnutých dat. V kaskádovém přístupu kombinujeme automatické rozpoznávání řeči založené na Conformeru (ASR) s transformátorovým neuronovým strojovým překladem (NMT). Naše end-to-end systémy přímého překladu řeči používají ASR předtrénovaný kodér a multi-task dekodéry. Předložené systémy jsou sestaveny různými kaskádovými modely.</abstract_cs>
      <abstract_et>Käesolevas töös kirjeldame Zhejiang Ülikooli esitamist IWSLT2021 mitmekeelse kõne tõlke ülesandele. See ülesanne keskendub kõnetõlke (ST) uurimisele paljudes mitte-inglise lähtekeeltes. Osalejad saavad otsustada, kas töötada piiratud või piiramatute süsteemidega, mis võivad kasutada välisandmeid. Loome nii kaskaadi- kui ka otsast otsa kõnetõlke piirangutega süsteeme, kasutades ainult esitatud andmeid. Kaskadeeritud lähenemisviisis kombineerime Conformer-põhise automaatse kõnetuvastuse (ASR) ja Transformer-põhise neuromasintõlke (NMT). Meie otsast otsa otsetõlkesüsteemid kasutavad ASR-i eeltreenitud kodeerijat ja mitmeülesandelisi dekoodreid. Esitatud süsteemid on ühendatud erinevate kaskaadmudelitega.</abstract_et>
      <abstract_fi>T채ss채 artikkelissa kuvailemme Zhejiang Universityn osallistumista IWSLT2021 monikieliseen puheen k채채nt채miseen teht채v채채n. T채m채 teht채v채 keskittyy puheen k채채nt채misen tutkimukseen monilla muilla kuin englanninkielisill채 l채hdekielill채. Osallistujat voivat p채채tt채채, k채ytet채채nk철 rajoitettuja j채rjestelmi채 vai rajattomia j채rjestelmi채, jotka voivat k채ytt채채 ulkoista dataa. Luomme sek채 kaskadi- ett채 end-to-end-puhek채채nn철srajoituksia k채ytt채en vain toimitettua tietoa. Kaskadisessa l채hestymistavassa yhdist채mme Conformer-pohjaisen automaattisen puheentunnistuksen (ASR) muuntajapohjaiseen neurokonek채채nn철kseen (NMT). Suorapuhek채채nn철sj채rjestelm채mme k채ytt채v채t ASR-esiasennettua koodausta ja moniteht채vi채 dekoodereita. Toimitetut j채rjestelm채t on yhdistetty erilaisiin kaskadimalleihin.</abstract_fi>
      <abstract_jv>Nang pepulan iki, kéné ngerasakno nggawe Universite nang IWSLT2020 Multi-lenguang Terjamahan task Gambar-sistem sing isa disimpen dadi kapan nguasar tentang karo sistem sing bisa ditambah dumateng. @item Text character set Nanging dolanan karo kascade, kita ngubah akèh basa nang konex karo terjamahan kelas telas (ASR) nganggep kuwi Manual sing basa gambar na Transformer (NMT). Kita end-to-end kelas telas telas telas sistem digawe ASR supra-pakan koder karo multi-task dekolar Sistem-sistem sing ditambah nyong ngomong sampe model karo akeh-kaset.</abstract_jv>
      <abstract_ha>Ga wannan karatun, Munã bayyana al'amarin na Zahejiang University da aka saka zuwa IWSLT2021 Wannan aikin ya fokus a kan tafarki na fassarar magana (SA) a cikin wasu harshen na'urar Ingiriya ba. Washirin haɗi za'a iya ƙayyade aikin bayani na'ura ko na'urar da ba'a yi amfani da data masu baka. Tuna ƙiƙira fassarar magana da aka ƙara zuwa-ƙari, da kuma za'a yi amfani da data wanda aka ba da shi kawai. In the casaded context, we integre the Conformer-based language as defined (ANR) with the Transformer-based neural system translation (NMT). @ info: whatsthis An shigar da wasu shiryoyin ayuka da aka lissafa su.</abstract_ha>
      <abstract_he>בעיתון הזה, אנחנו מתארים את ההעברה של אוניברסיטת ז'יינג למשימה של IWSLT2021 תרגום דיבורים רבים. המשימה הזאת מתמקדת במחקר התרגום הנאום (ST) ברחבי הרבה שפות מקורות לא אנגליות. השתתפים יכולים להחליט אם לעבוד על מערכות מוגבלות או מערכות ללא מוגבלות שיכולות להשתמש בנתונים חיצוניים. אנו יוצרים מערכות מוגבלות של התרגום הנאום בין סוף לבין סוף, בשימוש במידע הנוסף בלבד. באמצעות הגישה המתוקפת, אנחנו משלבים זיהוי דיבור אוטומטי (Conformer-based Automatic speech recognition - ASR) עם התרגום מכונת העצבית המבוססת על Transformer (NMT). מערכות התרגום הדיבורי ישירות שלנו משתמשות בקודר ASR מאומן מראש וקודרים במשימות רבות. המערכות המועברות מוצגות על ידי דוגמנים שונים.</abstract_he>
      <abstract_sk>V tem prispevku opisujemo predložitev Univerze Zhejiang na nalogo prevajanja večjezičnega govora IWSLT2021. Ta naloga se osredotoča na raziskave govornega prevajanja (ST) v številnih izvornih jezikih, ki niso angleški. Udeleženci se lahko odločijo, ali bodo delali na omejenih sistemih ali neomejenih sistemih, ki lahko uporabljajo zunanje podatke. Ustvarjamo tako kaskadne kot celovite sisteme z omejenim govornim prevajanjem, pri čemer uporabljamo samo navedene podatke. V kaskadnem pristopu združujemo samodejno prepoznavanje govora na podlagi Conformerja (ASR) z nevronskim strojnim prevajanjem na podlagi transformatorja (NMT). Naši sistemi neposrednega govornega prevajanja od konca do konca uporabljajo ASR predtrenirani kodirnik in večopravilne dekoderje. Predloženi sistemi so sestavljeni z različnimi kaskadnimi modeli.</abstract_sk>
      <abstract_bo>ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་ཚོའི་ཉེན་ཁུལ་གྱི་ཆེད་སྨྲ་བརྗོད་ཀྱི་ཆེད་སྐད་ཆ་མང་པོ་ཞིག་ལ་བཤད་བྱེད་ཀྱི་ཡོད། དངོས་ཡིག་ཆ་འདིས་སྐད་ཡིག་ཆ་མིན་པའི་དབྱིན་ཡིག་ཆའི་ནང་དུ་གཏོང་ཞིབ་བྱེད་ཀྱི་ཡོད། Participants can decide whether to work on constrained systems or unconstrained systems which can use external data. ང་ཚོས་ཀྱིས་ཞུགས་ཡུལ་དང་མཐའ་མཇུག་བསྡུ་བའི་སྐད་ཡིག་ཆའི་ནང་དུ་ཡིག་ཆའི་མ་ལག་འཁྱེར་སྐྱོད་བྱེད་དགོས། འོན་ཀྱང་གི་ཐབས་ལམ་ནང་དུ། ང་ཚོས་Conformer་ལ་རང་འགུལ་གྱིས་གཞི་བརྟེན་པའི་སྒྲ་ཚིག་རྟོགས་པ་དང་མཉམ་དུ་བསྡུར་བྱེད་དགོས་པ་ཡིན། ང་ཚོའི་end-to-end ཐད་ཀར་སྐད་འཚོལ་ཞིབ་ཀྱི་མ་ལག་གིས་ASR སྔོན་སྒྲིག་འཛུགས་ཀྱི་གསལ་བཀོད་པ་དང་ལྡན་མང་པོ་ཞིག བྱིས་འཇུག་བྱས་པའི་མ་ལག་དེ་སྙིང་རིས་དབྱིབས་མ་འདྲ་བའི་དཔེ་དབྱིབས་ཡོད་པ</abstract_bo>
      </paper>
    <paper id="17">
      <title>Multilingual Speech Translation with Unified Transformer : Huawei Noah’s Ark Lab at IWSLT 2021<fixed-case>N</fixed-case>oah’s Ark Lab at <fixed-case>IWSLT</fixed-case> 2021</title>
      <author><first>Xingshan</first><last>Zeng</last></author>
      <author><first>Liangyou</first><last>Li</last></author>
      <author><first>Qun</first><last>Liu</last></author>
      <pages>149–153</pages>
      <abstract>This paper describes the system submitted to the IWSLT 2021 Multilingual Speech Translation (MultiST) task from Huawei Noah’s Ark Lab. We use a unified transformer architecture for our MultiST model, so that the data from different modalities (i.e., speech and text) and different <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> (i.e., <a href="https://en.wikipedia.org/wiki/Speech_recognition">Speech Recognition</a>, <a href="https://en.wikipedia.org/wiki/Machine_translation">Machine Translation</a>, and Speech Translation) can be exploited to enhance the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a>’s ability. Specifically, speech and text inputs are firstly fed to different feature extractors to extract acoustic and textual features, respectively. Then, these <a href="https://en.wikipedia.org/wiki/Software_feature">features</a> are processed by a shared encoderdecoder architecture. We apply several training techniques to improve the performance, including <a href="https://en.wikipedia.org/wiki/Multi-task_learning">multi-task learning</a>, task-level curriculum learning, <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a>, etc. Our final system achieves significantly better results than bilingual baselines on supervised language pairs and yields reasonable results on zero-shot language pairs.</abstract>
      <url hash="83dc2a5f">2021.iwslt-1.17</url>
      <doi>10.18653/v1/2021.iwslt-1.17</doi>
      <bibkey>zeng-etal-2021-multilingual</bibkey>
    </paper>
    <paper id="18">
      <title>Multilingual Speech Translation KIT @ IWSLT2021<fixed-case>KIT</fixed-case> @ <fixed-case>IWSLT</fixed-case>2021</title>
      <author><first>Ngoc-Quan</first><last>Pham</last></author>
      <author><first>Tuan Nam</first><last>Nguyen</last></author>
      <author><first>Thanh-Le</first><last>Ha</last></author>
      <author><first>Sebastian</first><last>Stüker</last></author>
      <author><first>Alexander</first><last>Waibel</last></author>
      <author><first>Dan</first><last>He</last></author>
      <pages>154–159</pages>
      <abstract>This paper contains the description for the submission of Karlsruhe Institute of Technology (KIT) for the multilingual TEDx translation task in the IWSLT 2021 evaluation campaign. Our main approach is to develop both cascade and end-to-end systems and eventually combine them together to achieve the best possible results for this extremely low-resource setting. The report also confirms certain consistent architectural improvement added to the Transformer architecture, for all tasks : <a href="https://en.wikipedia.org/wiki/Translation">translation</a>, <a href="https://en.wikipedia.org/wiki/Transcription_(linguistics)">transcription</a> and speech translation.</abstract>
      <url hash="125bdb8e">2021.iwslt-1.18</url>
      <doi>10.18653/v1/2021.iwslt-1.18</doi>
      <bibkey>pham-etal-2021-multilingual</bibkey>
    </paper>
    <paper id="26">
      <title>Between Flexibility and Consistency : Joint Generation of Captions and Subtitles</title>
      <author><first>Alina</first><last>Karakanta</last></author>
      <author><first>Marco</first><last>Gaido</last></author>
      <author><first>Matteo</first><last>Negri</last></author>
      <author><first>Marco</first><last>Turchi</last></author>
      <pages>215–225</pages>
      <abstract>Speech translation (ST) has lately received growing interest for the generation of subtitles without the need for an intermediate source language transcription and timing (i.e. captions). However, the joint generation of source captions and target subtitles does not only bring potential output quality advantages when the two decoding processes inform each other, but it is also often required in multilingual scenarios. In this work, we focus on ST models which generate consistent captions-subtitles in terms of <a href="https://en.wikipedia.org/wiki/Structure">structure</a> and <a href="https://en.wikipedia.org/wiki/Content_(media)">lexical content</a>. We further introduce new <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> for evaluating subtitling consistency. Our findings show that joint decoding leads to increased performance and consistency between the generated captions and <a href="https://en.wikipedia.org/wiki/Subtitle_(titling)">subtitles</a> while still allowing for sufficient flexibility to produce <a href="https://en.wikipedia.org/wiki/Subtitle_(titling)">subtitles</a> conforming to language-specific needs and norms.</abstract>
      <url hash="bc462a33">2021.iwslt-1.26</url>
      <doi>10.18653/v1/2021.iwslt-1.26</doi>
      <bibkey>karakanta-etal-2021-flexibility</bibkey>
      <pwccode url="https://github.com/mgaido91/FBK-fairseq-ST" additional="false">mgaido91/FBK-fairseq-ST</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/must-cinema">MuST-Cinema</pwcdataset>
    </paper>
    <paper id="28">
      <title>Inverted Projection for Robust Speech Translation</title>
      <author><first>Dirk</first><last>Padfield</last></author>
      <author><first>Colin</first><last>Cherry</last></author>
      <pages>236–244</pages>
      <abstract>Traditional translation systems trained on written documents perform well for text-based translation but not as well for speech-based applications. We aim to adapt translation models to speech by introducing actual lexical errors from ASR and segmentation errors from automatic punctuation into our translation training data. We introduce an inverted projection approach that projects automatically detected system segments onto human transcripts and then re-segments the gold translations to align with the projected human transcripts. We demonstrate that this overcomes the train-test mismatch present in other training approaches. The new projection approach achieves gains of over 1 BLEU point over a baseline that is exposed to the human transcripts and segmentations, and these gains hold for both IWSLT data and <a href="https://en.wikipedia.org/wiki/YouTube">YouTube data</a>.</abstract>
      <url hash="cf49d38e">2021.iwslt-1.28</url>
      <doi>10.18653/v1/2021.iwslt-1.28</doi>
      <bibkey>padfield-cherry-2021-inverted</bibkey>
    </paper>
    <paper id="29">
      <title>Towards the evaluation of automatic simultaneous speech translation from a communicative perspective</title>
      <author><first>Claudio</first><last>Fantinuoli</last></author>
      <author><first>Bianca</first><last>Prandi</last></author>
      <pages>245–254</pages>
      <abstract>In recent years, automatic speech-to-speech and speech-to-text translation has gained momentum thanks to advances in <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">artificial intelligence</a>, especially in the domains of <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech recognition</a> and <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>. The quality of such <a href="https://en.wikipedia.org/wiki/Application_software">applications</a> is commonly tested with automatic metrics, such as <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a>, primarily with the goal of assessing improvements of releases or in the context of evaluation campaigns. However, little is known about how the output of such <a href="https://en.wikipedia.org/wiki/System">systems</a> is perceived by end users or how they compare to human performances in similar communicative tasks. In this paper, we present the results of an experiment aimed at evaluating the quality of a real-time speech translation engine by comparing it to the performance of professional simultaneous interpreters. To do so, we adopt a <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> developed for the assessment of <a href="https://en.wikipedia.org/wiki/Language_interpretation">human interpreters</a> and use it to perform a manual evaluation on both <a href="https://en.wikipedia.org/wiki/Human–computer_interaction">human and machine performances</a>. In our sample, we found better performance for the <a href="https://en.wikipedia.org/wiki/Language_interpretation">human interpreters</a> in terms of <a href="https://en.wikipedia.org/wiki/Intelligibility_(communication)">intelligibility</a>, while the <a href="https://en.wikipedia.org/wiki/Machine">machine</a> performs slightly better in terms of <a href="https://en.wikipedia.org/wiki/Informatics">informativeness</a>. The limitations of the study and the possible enhancements of the chosen <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> are discussed. Despite its intrinsic limitations, the use of this <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> represents a first step towards a user-centric and communication-oriented methodology for evaluating real-time automatic speech translation.</abstract>
      <url hash="52d3d64a">2021.iwslt-1.29</url>
      <doi>10.18653/v1/2021.iwslt-1.29</doi>
      <bibkey>fantinuoli-prandi-2021-towards</bibkey>
    </paper>
    </volume>
</collection>