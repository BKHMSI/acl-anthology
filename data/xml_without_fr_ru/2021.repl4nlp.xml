<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.repl4nlp">
  <volume id="1" ingest-date="2021-07-25">
    <meta>
      <booktitle>Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)</booktitle>
      <editor><first>Anna</first><last>Rogers</last></editor>
      <editor><first>Iacer</first><last>Calixto</last></editor>
      <editor><first>Ivan</first><last>Vulić</last></editor>
      <editor><first>Naomi</first><last>Saphra</last></editor>
      <editor><first>Nora</first><last>Kassner</last></editor>
      <editor><first>Oana-Maria</first><last>Camburu</last></editor>
      <editor><first>Trapit</first><last>Bansal</last></editor>
      <editor><first>Vered</first><last>Shwartz</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>August</month>
      <year>2021</year>
      <url hash="ee14b8fa">2021.repl4nlp-1</url>
    </meta>
    <frontmatter>
      <url hash="e0d00975">2021.repl4nlp-1.0</url>
      <bibkey>repl4nlp-2021-representation</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Improving Cross-lingual Text Classification with Zero-shot Instance-Weighting</title>
      <author><first>Irene</first><last>Li</last></author>
      <author><first>Prithviraj</first><last>Sen</last></author>
      <author><first>Huaiyu</first><last>Zhu</last></author>
      <author><first>Yunyao</first><last>Li</last></author>
      <author><first>Dragomir</first><last>Radev</last></author>
      <pages>1–7</pages>
      <abstract>Cross-lingual text classification (CLTC) is a challenging task made even harder still due to the lack of labeled data in low-resource languages. In this paper, we propose zero-shot instance-weighting, a general model-agnostic zero-shot learning framework for improving CLTC by leveraging source instance weighting. It adds a module on top of pre-trained language models for similarity computation of instance weights, thus aligning each source instance to the target language. During <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training</a>, the framework utilizes <a href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a> that is weighted by instance weights to update parameters. We evaluate this <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> over seven target languages on three fundamental tasks and show its effectiveness and extensibility, by improving on F1 score up to 4 % in single-source transfer and 8 % in multi-source transfer. To the best of our knowledge, our method is the first to apply instance weighting in zero-shot CLTC. It is simple yet effective and easily extensible into multi-source transfer.</abstract>
      <url hash="504832bc">2021.repl4nlp-1.1</url>
      <doi>10.18653/v1/2021.repl4nlp-1.1</doi>
      <bibkey>li-etal-2021-improving-cross</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/mldoc">MLDoc</pwcdataset>
    </paper>
    <paper id="3">
      <title>Comprehension Based Question Answering using <a href="https://en.wikipedia.org/wiki/Bloom’s_taxonomy">Bloom’s Taxonomy</a></title>
      <author><first>Pritish</first><last>Sahu</last></author>
      <author><first>Michael</first><last>Cogswell</last></author>
      <author><first>Ajay</first><last>Divakaran</last></author>
      <author><first>Sara</first><last>Rutherford-Quach</last></author>
      <pages>20–28</pages>
      <abstract>Current pre-trained language models have lots of knowledge, but a more limited ability to use that knowledge. Bloom’s Taxonomy helps educators teach children how to use knowledge by categorizing comprehension skills, so we use it to analyze and improve the <a href="https://en.wikipedia.org/wiki/Sentence_processing">comprehension skills</a> of large pre-trained language models. Our experiments focus on zero-shot question answering, using the <a href="https://en.wikipedia.org/wiki/Taxonomy_(general)">taxonomy</a> to provide proximal context that helps the model answer questions by being relevant to those questions. We show targeting context in this manner improves performance across 4 popular common sense question answer datasets.</abstract>
      <url hash="11baef0f">2021.repl4nlp-1.3</url>
      <doi>10.18653/v1/2021.repl4nlp-1.3</doi>
      <bibkey>sahu-etal-2021-comprehension</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/copa">COPA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/commonsenseqa">CommonsenseQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/social-iqa">Social IQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/winogrande">WinoGrande</pwcdataset>
    </paper>
    <paper id="5">
      <title>Learning Sparse Sentence Encoding without Supervision : An Exploration of Sparsity in Variational Autoencoders</title>
      <author><first>Victor</first><last>Prokhorov</last></author>
      <author><first>Yingzhen</first><last>Li</last></author>
      <author><first>Ehsan</first><last>Shareghi</last></author>
      <author><first>Nigel</first><last>Collier</last></author>
      <pages>34–46</pages>
      <abstract>It has been long known that sparsity is an effective <a href="https://en.wikipedia.org/wiki/Inductive_bias">inductive bias</a> for learning efficient representation of data in vectors with fixed dimensionality, and it has been explored in many areas of <a href="https://en.wikipedia.org/wiki/Representation_learning">representation learning</a>. Of particular interest to this work is the investigation of the sparsity within the VAE framework which has been explored a lot in the image domain, but has been lacking even a basic level of exploration in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>. Additionally, <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> is also lagging behind in terms of learning sparse representations of large units of text e.g., sentences. We use the VAEs that induce sparse latent representations of large units of text to address the aforementioned shortcomings. First, we move in this direction by measuring the success of unsupervised state-of-the-art (SOTA) and other strong VAE-based sparsification baselines for text and propose a hierarchical sparse VAE model to address the stability issue of SOTA. Then, we look at the implications of sparsity on text classification across 3 datasets, and highlight a link between performance of sparse latent representations on downstream tasks and its ability to encode task-related information.</abstract>
      <url hash="8f51e476">2021.repl4nlp-1.5</url>
      <doi>10.18653/v1/2021.repl4nlp-1.5</doi>
      <bibkey>prokhorov-etal-2021-learning</bibkey>
      <pwccode url="https://github.com/VictorProkhorov/HSVAE" additional="false">VictorProkhorov/HSVAE</pwccode>
    </paper>
    <paper id="6">
      <title>Temporal-aware Language Representation Learning From Crowdsourced Labels</title>
      <author><first>Yang</first><last>Hao</last></author>
      <author><first>Xiao</first><last>Zhai</last></author>
      <author><first>Wenbiao</first><last>Ding</last></author>
      <author><first>Zitao</first><last>Liu</last></author>
      <pages>47–56</pages>
      <abstract>Learning effective language representations from crowdsourced labels is crucial for many real-world machine learning tasks. A challenging aspect of this problem is that the quality of crowdsourced labels suffer high intra- and inter-observer variability. Since the high-capacity deep neural networks can easily memorize all disagreements among crowdsourced labels, directly applying existing supervised language representation learning algorithms may yield suboptimal solutions. In this paper, we propose TACMA, a temporal-aware language representation learning heuristic for crowdsourced labels with multiple annotators. The proposed approach (1) explicitly models the intra-observer variability with attention mechanism ; (2) computes and aggregates per-sample confidence scores from multiple workers to address the inter-observer disagreements. The proposed <a href="https://en.wikipedia.org/wiki/Heuristic_(computer_science)">heuristic</a> is extremely easy to implement in around 5 lines of code. The proposed <a href="https://en.wikipedia.org/wiki/Heuristics_in_judgment_and_decision-making">heuristic</a> is evaluated on four synthetic and four real-world data sets. The results show that our approach outperforms a wide range of state-of-the-art <a href="https://en.wikipedia.org/wiki/Baseline_(medicine)">baselines</a> in terms of <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">prediction accuracy</a> and <a href="https://en.wikipedia.org/wiki/Analysis_of_covariance">AUC</a>. To encourage the reproducible results, we make our code publicly available at.<i>TACMA</i>, a temporal-aware language representation learning heuristic for crowdsourced labels with multiple annotators. The proposed approach (1) explicitly models the intra-observer variability with attention mechanism; (2) computes and aggregates per-sample confidence scores from multiple workers to address the inter-observer disagreements. The proposed heuristic is extremely easy to implement in around 5 lines of code. The proposed heuristic is evaluated on four synthetic and four real-world data sets. The results show that our approach outperforms a wide range of state-of-the-art baselines in terms of prediction accuracy and AUC. To encourage the reproducible results, we make our code publicly available at <url>https://github.com/CrowdsourcingMining/TACMA</url>.</abstract>
      <url hash="4e51af9e">2021.repl4nlp-1.6</url>
      <doi>10.18653/v1/2021.repl4nlp-1.6</doi>
      <bibkey>hao-etal-2021-temporal</bibkey>
      <pwccode url="https://github.com/CrowdsourcingMining/TACMA" additional="false">CrowdsourcingMining/TACMA</pwccode>
    </paper>
    <paper id="12">
      <title>Knodle : Modular Weakly Supervised Learning with PyTorch<fixed-case>P</fixed-case>y<fixed-case>T</fixed-case>orch</title>
      <author><first>Anastasiia</first><last>Sedova</last></author>
      <author><first>Andreas</first><last>Stephan</last></author>
      <author><first>Marina</first><last>Speranskaya</last></author>
      <author><first>Benjamin</first><last>Roth</last></author>
      <pages>100–111</pages>
      <abstract>Strategies for improving the <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training and prediction quality</a> of weakly supervised machine learning models vary in how much they are tailored to a specific task or integrated with a specific model architecture. In this work, we introduce Knodle, a <a href="https://en.wikipedia.org/wiki/Software_framework">software framework</a> that treats weak data annotations, <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning models</a>, and methods for improving weakly supervised training as separate, modular components. This modularization gives the training process access to fine-grained information such as data set characteristics, matches of <a href="https://en.wikipedia.org/wiki/Heuristic_(computer_science)">heuristic rules</a>, or elements of the <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning model</a> ultimately used for prediction. Hence, our framework can encompass a wide range of training methods for improving weak supervision, ranging from methods that only look at correlations of rules and output classes (independently of the <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning model</a> trained with the resulting labels), to those that harness the interplay of <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a> and weakly labeled data. We illustrate the benchmarking potential of the <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> with a performance comparison of several reference implementations on a selection of datasets that are already available in Knodle.</abstract>
      <url hash="c9e270da">2021.repl4nlp-1.12</url>
      <doi>10.18653/v1/2021.repl4nlp-1.12</doi>
      <bibkey>sedova-etal-2021-knodle</bibkey>
      <pwccode url="https://github.com/knodle/knodle" additional="false">knodle/knodle</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sms-spam-collection-data-set">SMS Spam Collection Data Set</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/tacred">TACRED</pwcdataset>
    </paper>
    <paper id="16">
      <title>Probing Cross-Modal Representations in Multi-Step Relational Reasoning</title>
      <author><first>Iuliia</first><last>Parfenova</last></author>
      <author><first>Desmond</first><last>Elliott</last></author>
      <author><first>Raquel</first><last>Fernández</last></author>
      <author><first>Sandro</first><last>Pezzelle</last></author>
      <pages>152–162</pages>
      <abstract>We investigate the <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">representations</a> learned by vision and language models in tasks that require relational reasoning. Focusing on the problem of assessing the relative size of objects in abstract visual contexts, we analyse both one-step and two-step reasoning. For the latter, we construct a new <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> of three-image scenes and define a task that requires <a href="https://en.wikipedia.org/wiki/Reason">reasoning</a> at the level of the individual images and across images in a scene. We probe the learned model representations using diagnostic classifiers. Our experiments show that pretrained multimodal transformer-based architectures can perform higher-level relational reasoning, and are able to learn representations for novel tasks and data that are very different from what was seen in pretraining.</abstract>
      <url hash="2f2181c2">2021.repl4nlp-1.16</url>
      <doi>10.18653/v1/2021.repl4nlp-1.16</doi>
      <bibkey>parfenova-etal-2021-probing</bibkey>
      <pwccode url="https://github.com/jig-san/multi-step-size-reasoning" additional="false">jig-san/multi-step-size-reasoning</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/clevr">CLEVR</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/nlvr">NLVR</pwcdataset>
    <title_pt>Sondando Representações Multimodais no Raciocínio Relacional de Várias Etapas</title_pt>
      <title_ar>التحقق من التمثيلات عبر الوسائط في التفكير العلائقي متعدد الخطوات</title_ar>
      <title_es>Sondeo de representaciones intermodales en el razonamiento relacional de varios pasos</title_es>
      <title_ja>多段階関係推論におけるクロスモーダル表現の探索</title_ja>
      <title_zh>于多步骤推理中探跨模态</title_zh>
      <title_hi>मल्टी-स्टेप रिलेशनल रीजनिंग में क्रॉस-मोडल अभ्यावेदन की जांच करना</title_hi>
      <title_ga>Léirithe Trasmhódúla a Scrúdú i Réasúnaíocht Choibhneasta Ilchéimneach</title_ga>
      <title_ka>მრავალური მოდიალური გამოსახულებების გამოყენება</title_ka>
      <title_el>Δοκιμή διασταυρούμενων αναπαραστάσεων σε πολλαπλά στάδια σχετικής λογικής</title_el>
      <title_hu>Keresztmodális reprezentációk vizsgálata a többlépéses relatív észlelésben</title_hu>
      <title_it>Sondare le rappresentazioni cross-modali nella ragione relazionale multi-step</title_it>
      <title_kk>Көп қадам қатынаслық себептерінде көптеген модельді таңдау</title_kk>
      <title_lt>Daugiapakopės santykinės priežasties tarpmodulių atstovavimų bandymas</title_lt>
      <title_mk>Probing Cross-Modal Representations in Multi-Step Relational Reasoning</title_mk>
      <title_ml>Multi- Step Relational Reading</title_ml>
      <title_mt>Probar ta’ Rappreżentazzjonijiet Cross-Modali f’Raġunar Relattiv Multi-Pass</title_mt>
      <title_mn>Олон-Step Relational Reason</title_mn>
      <title_ms>Menguji Perwakilan Salib-Modal dalam Pengiraan Hubungan Berbagai Langkah</title_ms>
      <title_no>Prøver krysmodale representasjonar i fleire steg relasjonsretting</title_no>
      <title_pl>Badanie reprezentacji crossmodalnych w wielostopniowym rozumowaniu relacyjnym</title_pl>
      <title_ro>Proiectarea reprezentărilor cross-modale în raționarea relațională în mai multe etape</title_ro>
      <title_sr>Provjeravanje krstomodalnih predstavljanja u vezanom razlogu višestrukog koraka</title_sr>
      <title_si>ප්‍රශ්නය ක්‍රොස් මොඩාල් ප්‍රතිනිස්ථානය ගොඩක් ස්ටප් සම්බන්ධ කාරණය</title_si>
      <title_sv>Sondera tvärmodala representationer i relationell resonemang i flera steg</title_sv>
      <title_so>Ka baaraandegista wakiilada iskutallada ee jardiinada kala duduwan</title_so>
      <title_ta>Multi- Step Relations Reading</title_ta>
      <title_ur>Multi-Step Relational Reasoning میں Cross-Modal Representations</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>KCharselect unicode block name</title_vi>
      <title_bg>Пробване на кръстосаните модални представи в многостепенно относително разсъждаване</title_bg>
      <title_nl>Onderzoek van crossmodale representaties in multi-step relationele redenering</title_nl>
      <title_hr>Provjeravanje krstomodalnih predstavljanja u mnogim koracima veznih razloga</title_hr>
      <title_de>Untersuchung von crossmodalen Repräsentationen in der mehrstufigen Beziehungsberechnung</title_de>
      <title_ko>다단계 관계 추리에서 다중모드적 표시에 대한 탐구</title_ko>
      <title_da>Undersøgelse af tværmodelle repræsentationer i Multi-Step Relational Reasoning</title_da>
      <title_fa>امتحان نمایش‌های متوسط مدل در دلیل رابطه‌های متوسط قدم‌ها</title_fa>
      <title_af>Probeer kruismodale voorstellings in Multi-Step Relatiewe Redigering</title_af>
      <title_id>Probing Cross-Modal Representations in Multi-Step Relational Reasoning</title_id>
      <title_sq>Duke provuar përfaqësime ndër-modali në arsyetimin e lidhjes me shumë hapa</title_sq>
      <title_sw>Kudhibiti maoni ya Msalaba wa Kusini katika Kusoma hatua nyingi za Kuhusiana</title_sw>
      <title_am>ምርጫዎች</title_am>
      <title_az>Ã‡oxlu-adÄ±m Ä°liÅŸkil ReasonlarÄ±nda Ã§oxlu Modal Ä°ÅŸkilÉ™ri SÉ™xlama</title_az>
      <title_tr>Çoklu-Step Görnöşimleri Derjesi Sebäpli</title_tr>
      <title_bs>Provjeravanje krstomodalnih predstavljanja u multikoracijskom odnosu</title_bs>
      <title_bn>প্রতিনিধি বিভিন্ন সংশ্লিষ্ট কারণে ক্রস-মডেল প্রতিনিধি প্রমাণ করা হচ্ছে</title_bn>
      <title_hy>Probing Cross-Modal Representations in Multi-Step Relational Reasoning</title_hy>
      <title_ca>Probar representacions transmòdiques en una raonació relativa a múltiples etapes</title_ca>
      <title_cs>Snímání cross-modálních reprezentací ve vícestupňovém vztahovém odůvodnění</title_cs>
      <title_et>Modaalsete esinduste uurimine mitmeastmelises suhtelises mõistmises</title_et>
      <title_fi>Modaalisten edustustojen kartoittaminen monivaiheisessa suhteellisessa järkeilyssä</title_fi>
      <title_he>חוקר מייצגים מודיאליים בצעדים רבים בהגיון יחסי</title_he>
      <title_sk>Sondiranje medmodalnih predstavitev v večstopenjskem relativnem razumevanju</title_sk>
      <title_jv>Mbale représane Kros-modal nang Rehasun Multi-Stap Relational</title_jv>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_bo>Probing Cross-Modal Representations in Multi-Step Relational Reasoning</title_bo>
      <abstract_es>Investigamos las representaciones aprendidas por los modelos de visión y lenguaje en tareas que requieren razonamiento relacional. Centrándonos en el problema de evaluar el tamaño relativo de los objetos en contextos visuales abstractos, analizamos tanto el razonamiento de un paso como el de dos pasos. Para esto último, construimos un nuevo conjunto de datos de escenas de tres imágenes y definimos una tarea que requiere razonamiento a nivel de las imágenes individuales y a través de las imágenes de una escena. Sondeamos las representaciones de modelos aprendidas mediante clasificadores de diagnóstico. Nuestros experimentos muestran que las arquitecturas basadas en transformadores multimodales previamente entrenadas pueden realizar un razonamiento relacional de mayor nivel y pueden aprender representaciones de tareas y datos novedosos que son muy diferentes de lo que se vio en la capacitación previa.</abstract_es>
      <abstract_ar>نحن نحقق في التمثيلات التي تعلمتها نماذج الرؤية واللغة في المهام التي تتطلب التفكير العلائقي. بالتركيز على مشكلة تقييم الحجم النسبي للأشياء في السياقات المرئية المجردة ، نقوم بتحليل كل من التفكير المكون من خطوة واحدة وخطوتين. بالنسبة للأخير ، نقوم ببناء مجموعة بيانات جديدة من ثلاث مشاهد للصور وتحديد مهمة تتطلب التفكير على مستوى الصور الفردية وعبر الصور في المشهد. نحن نفحص تمثيلات النموذج المكتسبة باستخدام المصنفات التشخيصية. تُظهر تجاربنا أن البنى القائمة على المحولات متعددة الوسائط المدربة مسبقًا يمكن أن تؤدي تفكيرًا علائقيًا عالي المستوى ، وتكون قادرة على تعلم تمثيلات للمهام الجديدة والبيانات التي تختلف تمامًا عما شوهد في التدريب المسبق.</abstract_ar>
      <abstract_pt>Investigamos as representações aprendidas por modelos de visão e linguagem em tarefas que requerem raciocínio relacional. Concentrando-se no problema de avaliar o tamanho relativo de objetos em contextos visuais abstratos, analisamos o raciocínio de uma e duas etapas. Para este último, construímos um novo conjunto de dados de cenas de três imagens e definimos uma tarefa que requer raciocínio no nível das imagens individuais e entre imagens em uma cena. Analisamos as representações do modelo aprendido usando classificadores de diagnóstico. Nossos experimentos mostram que arquiteturas baseadas em transformadores multimodais pré-treinados podem executar raciocínio relacional de alto nível e são capazes de aprender representações para novas tarefas e dados que são muito diferentes do que foi visto no pré-treinamento.</abstract_pt>
      <abstract_zh>我们研究了视听和言语模样在要推理的事务中学到的。 注于抽象视中评对大小,析一步两步推理。 后来,我们构建了一个新三图像场景数据集,并定义了一个职务,该在场景中的单个图像和图像等级上推理。 吾以诊分类器测学之形。 臣等实验明,先训之基于多模态转换器架构可以行更高层次之理,而能习殊新之任数。</abstract_zh>
      <abstract_hi>हम उन कार्यों में दृष्टि और भाषा मॉडल द्वारा सीखे गए अभ्यावेदनों की जांच करते हैं जिनके लिए संबंधपरक तर्क की आवश्यकता होती है। अमूर्त दृश्य संदर्भों में वस्तुओं के सापेक्ष आकार का आकलन करने की समस्या पर ध्यान केंद्रित करते हुए, हम एक-चरण और दो-चरणीय तर्क दोनों का विश्लेषण करते हैं। उत्तरार्द्ध के लिए, हम तीन-छवि दृश्यों का एक नया डेटासेट बनाते हैं और एक ऐसे कार्य को परिभाषित करते हैं जिसके लिए व्यक्तिगत छवियों के स्तर पर और एक दृश्य में छवियों में तर्क की आवश्यकता होती है। हम नैदानिक क्लासिफायरका उपयोग करके सीखे गए मॉडल अभ्यावेदन की जांच करते हैं। हमारे प्रयोगों से पता चलता है कि प्रीट्रेन्ड मल्टीमॉडल ट्रांसफॉर्मर-आधारित आर्किटेक्चर उच्च-स्तरीय रिलेशनल तर्क कर सकते हैं, और उपन्यास कार्यों और डेटा के लिए अभ्यावेदन सीखने में सक्षम हैं जो प्रीट्रेनिंग में जो देखा गया था उससे बहुत अलग हैं।</abstract_hi>
      <abstract_ja>私たちは、人間関係の推論を必要とするタスクにおいて、ビジョンと言語モデルによって学習された表現を調査します。抽象的な視覚的文脈における物体の相対的な大きさを評価する問題に焦点を当て、一段階と二段階の推論の両方を分析する。後者では、3つの画像シーンの新しいデータセットを構築し、個々の画像のレベルとシーン内の画像間で推論を必要とするタスクを定義します。診断分類子を使用して学習されたモデル表現を探索します。私たちの実験では、事前に訓練されたマルチモーダル変圧器ベースのアーキテクチャは、より高いレベルの関係推論を実行でき、事前訓練で見られたものとは大きく異なる新規のタスクとデータの表現を学ぶことができることが示されています。</abstract_ja>
      <abstract_ga>Fiosraíonn muid na hléirithe a d’fhoghlaimíonn fís agus samhlacha teanga i dtascanna a éilíonn réasúnaíocht choibhneasta. Ag díriú ar an bhfadhb a bhaineann le measúnú a dhéanamh ar mhéid choibhneasta rudaí i gcomhthéacsanna teibí amhairc, déanaimid anailís ar réasúnaíocht aonchéime agus dhá chéim. Maidir leis an dara ceann, tógaimid tacar sonraí nua de radhairc trí-íomhá agus sainímid tasc a éilíonn réasúnú ag leibhéal na n-íomhánna aonair agus trasna na n-íomhánna i radharc. Déanaimid iniúchadh ar léiriú na samhla foghlamtha ag baint úsáide as aicmitheoirí diagnóiseacha. Léiríonn ár dturgnaimh gur féidir le hailtireachtaí ilmhódacha atá bunaithe ar chlaochladán réamhoiliúint réasúnaíocht choibhneasta ardleibhéil a dhéanamh, agus go bhfuil siad in ann uiríll a fhoghlaim le haghaidh tascanna agus sonraí núíosacha atá an-difriúil ón méid a chonacthas i réamhoiliúint.</abstract_ga>
      <abstract_ka>ჩვენ განსხვავებთ მონაცემებები, რომლებიც შეგვიძლია დაკავშირებული პარამეტრებების შესახებ და ენის მოდელების შესახებ. აბსტრაქტური ვიზუალური კონტექსტში პრობლემების შესაბამისი ზომის შესაბამისი პრობლემებზე, ჩვენ ანალიზაცით ერთ-კვადი და ორ-კვადი პარამენტი. შემდეგ, ჩვენ სამი გამოსახულების ახალი მონაცემების კონფიგურაციას შევქმნით და განსახულებთ რაოდენობა, რომელიც განსახულებელია განსახულების დონეზე და გამოსახულების დონეში. ჩვენ დავიწყებთ მოდელური გამოყენება დიაგონტიკური კლასიფიკაციების გამოყენებით. ჩვენი ექსპერიმენტები აჩვენებენ, რომ მლიტიმოდიალური ტრანფორმენტების აქტიქტიქტურები შეუძლიათ გავაკეთოთ უფრო მეტი დონე შესაბამისი პარამენტი, და შეუძლიათ ვისწავლოთ პრომენტური და</abstract_ka>
      <abstract_hu>Megvizsgáljuk a látásmód és a nyelvi modellek által tanult reprezentációkat olyan feladatokban, amelyek kapcsolati érvelést igényelnek. Az objektumok relatív méretének értékelésének problémájára összpontosítva absztrakt vizuális kontextusokban, egylépéses és kétlépéses érvelést egyaránt elemzünk. Ez utóbbi esetében háromképes jelenetekből álló új adatkészletet építünk fel, és olyan feladatot határozunk meg, amely az egyes képek szintjén és egy jelenet képein keresztül érvelést igényel. Diagnosztikai osztályozók segítségével vizsgáljuk a tanult modell reprezentációit. Kísérleteink azt mutatják, hogy az előkészített multimodális transzformátor alapú architektúrák képesek magasabb szintű relációs érvelést végezni, és képesek olyan új feladatok és adatok reprezentációit tanulni, amelyek nagyon különböznek attól, amit az előkészítés során tapasztaltak.</abstract_hu>
      <abstract_el>Ερευνούμε τις αναπαραστάσεις που μαθαίνονται από το όραμα και τα γλωσσικά μοντέλα σε εργασίες που απαιτούν σχεσιακό συλλογισμό. Εστιάζοντας στο πρόβλημα της αξιολόγησης του σχετικού μεγέθους των αντικειμένων σε αφηρημένα οπτικά πλαίσια, αναλύουμε τη λογική ενός και δύο βημάτων. Για το τελευταίο, κατασκευάζουμε ένα νέο σύνολο δεδομένων σκηνών τριών εικόνων και καθορίζουμε μια εργασία που απαιτεί συλλογισμό στο επίπεδο των μεμονωμένων εικόνων και μεταξύ των εικόνων σε μια σκηνή. Εξετάζουμε τις μαθημένες αναπαραστάσεις μοντέλων χρησιμοποιώντας διαγνωστικούς ταξινομητές. Τα πειράματά μας δείχνουν ότι οι προ-εκπαιδευμένες πολυπροπικές αρχιτεκτονικές με βάση μετασχηματιστή μπορούν να εκτελέσουν ανώτερο επίπεδο σχεσιακής σκέψης, και είναι σε θέση να μάθουν αναπαραστάσεις για νέες εργασίες και δεδομένα που είναι πολύ διαφορετικές από ό, τι παρατηρήθηκε στην προεπιλογή.</abstract_el>
      <abstract_it>Investighiamo le rappresentazioni apprese dai modelli di visione e linguaggio in compiti che richiedono ragionamento relazionale. Concentrandoci sul problema della valutazione della dimensione relativa degli oggetti in contesti visivi astratti, analizziamo sia il ragionamento in uno stadio che in due fasi. Per quest'ultimo, costruiamo un nuovo dataset di scene a tre immagini e definiamo un compito che richiede ragionamenti a livello delle singole immagini e attraverso le immagini in una scena. Sondiamo le rappresentazioni dei modelli appresi utilizzando classificatori diagnostici. I nostri esperimenti mostrano che architetture multimodali pre-addestrate basate su trasformatori possono eseguire ragionamenti relazionali di livello superiore, e sono in grado di imparare rappresentazioni di nuovi compiti e dati che sono molto diversi da quanto è stato visto nel pre-training.</abstract_it>
      <abstract_kk>Біз көрініс мен тіл үлгілерін үйренген тапсырмалардың қатынастық түсініктемелерін зерттейміз. Абстракты визуалдық контексттерде нысандардың қатынастық өлшемін оқу мәселесіне қарсы болып, бір қадам мен екі қадам сезімін анализирақ. Соңғылардың үш кескіндегі жаңа деректер жиынын құрып, әрбір кескіндердің деңгейінде және кескіндердің арасындағы бақылау керек тапсырманы анықтаймыз. Біз диагностикалық классификацияларды қолдану үлгілерін тексереміз. Біздің тәжірибеміздің көп модельді түрлендіруші архитектураларының көп деңгейіндегі қатынастық түсініктері жоғары деңгейінде жұмыс істеуге болады, және өзгертілген жаңа тапсырмалар мен деректерінің тү</abstract_kk>
      <abstract_lt>Mes tiriame vizijos ir kalbos modelių įgytus atstovavimus užduotyse, kurioms reikalingas santykinis pagrindimas. Pagrindinę problem ą vertinant santykinį objektų dydį abstrakčiose vizualinėse aplinkybėse analizuojame tiek vieno, tiek dviejų etapų pagrįstumą. Pastaruoju atveju sukuriame naują trijų vaizdų scenų duomenų rinkinį ir apibrėžiame užduotį, kuri reikalauja pagrįsti atskirų vaizdų lygiu ir įvairiuose vaizduose scenoje. Ištiriame išmoktus modelius naudojant diagnostinius klasifikatorius. Mūsų eksperimentai rodo, kad iš anksto parengtos daugiarūšio modelio transformatorių grindžiamos architektūros gali atlikti aukštesnio lygio santykinius motyvus ir sugebėti išmokti naujų užduočių ir duomenų, kurie labai skiriasi nuo to, ką buvo matyti iš anksto rengiant mokymus, atstovavimus.</abstract_lt>
      <abstract_mk>Ги истражуваме претставувањата научени со визија и јазички модели во задачите кои бараат релативно размислување. Кога се фокусираме на проблемот со проценката на релативната големина на објектите во апстрактни визуелни контексти, анализираме размислување во еден и два чекори. За последните, конструираме нов набор на податоци од три слики и дефинираме задача која бара размислување на нивото на индивидуалните слики и преку слики на една сцена. Ги проверуваме научените модели користејќи дијагностички класификатори. Нашите експерименти покажуваат дека претренираните мултимодилни трансформаторски архитектури можат да извршат врска на повисоко ниво размислување и можат да научат претставувања за нови задачи и податоци кои се многу различни од она што беше видено во претренирањето.</abstract_mk>
      <abstract_ml>കാഴ്ചകളും ഭാഷ മോഡലുകളും പഠിച്ച പ്രതിനിധികളെ ഞങ്ങള്‍ അന്വേഷിക്കുന്നു. ബന്ധപൂര്‍വ്വം കാരണങ്ങള്‍ ആവശ്യമുള് അബ്ബ്രാക്ട്രാക്റ്റ് കാഴ്ചകളില്‍ വസ്തുക്കളുടെ വലിപ്പത്തിന്റെ വലിപ്പം വിശദീകരിക്കുന്നതിന്റെ പ്രശ്നത്തില്‍ ശ്രദ്ധിച അവസാനം, നമ്മള്‍ മൂന്നു ഇമേജ് സീനുകളുടെ പുതിയ ഡാറ്റാസേറ്റ് നിര്‍മ്മിക്കുകയും, ഒരു ജോലി നിര്‍ണ്ണയിക്കുകയും ചെയ്യുന്നു. അത് സ്വക ഞങ്ങള്‍ പഠിച്ച മോഡല്‍ പ്രതിനിധികളെ പരിശോധിക്കുക നമ്മുടെ പരീക്ഷണങ്ങള്‍ കാണിച്ചു കൊണ്ടിരിക്കുന്നു പല്ലിമോഡാല്‍ മാറ്റങ്ങള്‍ അടിസ്ഥാനമാക്കിയിരിക്കുന്ന സ്ഥാനങ്ങള്‍ക്ക് ഉയരത്തിലെ ബന്ധപൂര്‍ണ്</abstract_ml>
      <abstract_mn>Бид харилцааны урьдчилан шаардлагатай зүйлсийн даалгаврууд болон хэл загвараар сурсан илтгэлийг судалж байна. Объектуудын харьцаатай хэмжээг abstract visual нөхцөлд тодорхойлох асуудалд бид нэг алхам болон хоёр алхам шинжилгээ хийдэг. Сүүлийн үед бид гурван зураг хувилбарын шинэ өгөгдлийн хэлбэрийг бүтээж, хувилбарын хэмжээнд бодлого шаардлагатай ажил тодорхойлдог. Бид шинжлэх ухааны хэлбэрийг ашиглан сурсан загварын үзүүлэлтийг судалж байна. Бидний туршилтууд олон төрлийн шилжүүлэгчийн архитектурууд өндөр төрлийн харилцааны урьдчилан хийж чадна гэдгийг харуулж чадна. Мөн урьдчилан харагдаж байгаа шинэ ажил, өгөгдлийг сурах боломжтой.</abstract_mn>
      <abstract_no>Vi undersøker representasjonane lærte av vising og språk-modeller i oppgåver som krev relasjonell motivering. Fokuserer vi på problemet for å vurdere relativt storleik på objektar i abstrakt visuelle kontekstar, så analyserer vi både ein steg og to steg. For dei siste, konstruerer vi ei ny dataset med tre bilete scenar og definerer ei oppgåve som krev å forstørre på nivået av dei individuelle bileta og gjennom bileta i eit scene. Vi prøver dei lærte modellerepresentasjonane med diagnostiske klassifikatorar. Eksperimentane våre viser at multimodal transformeringsarkitekturar kan utføre høgare nivå relasjonell rasjon, og kan lære representasjonar for novel oppgåver og data som er svært ulike frå det som er vist i trekking.</abstract_no>
      <abstract_pl>Badamy reprezentacje nauczane przez modele wizji i językowe w zadaniach wymagających rozumowania relacyjnego. Koncentrując się na problemie oceny względnej wielkości obiektów w abstrakcyjnych kontekstach wizualnych, analizujemy zarówno jednostopniowe, jak i dwustopniowe rozumowanie. Dla tych ostatnich budujemy nowy zestaw danych scen trójobrazowych i definiujemy zadanie, które wymaga rozumowania na poziomie poszczególnych obrazów i między obrazami w scenie. Badamy nauczone reprezentacje modeli za pomocą klasyfikatorów diagnostycznych. Nasze eksperymenty pokazują, że wstępnie trenowane multimodalne architektury oparte na transformatorach mogą wykonywać rozumowanie relacyjne wyższego poziomu i są w stanie uczyć się reprezentacji dla nowych zadań i danych, które są bardzo różne od tego, co widziano w treningu wstępnym.</abstract_pl>
      <abstract_ro>Investigăm reprezentările învățate de viziune și modele lingvistice în sarcini care necesită raționament relațional. Concentrandu-ne pe problema evaluării dimensiunii relative a obiectelor în contexte vizuale abstracte, analizăm atât raționamentul într-un singur pas, cât și cel în doi pași. Pentru aceasta din urmă, construim un nou set de date de scene cu trei imagini și definim o sarcină care necesită raționament la nivelul imaginilor individuale și peste imagini dintr-o scenă. Sondăm reprezentările modelului învăţat folosind clasificatoare de diagnosticare. Experimentele noastre arată că arhitecturile multimodale pre-instruite bazate pe transformatori pot efectua raționamente relaționale de nivel superior și sunt capabile să învețe reprezentări pentru sarcini și date noi care sunt foarte diferite de ceea ce a fost văzut în pre-instruire.</abstract_ro>
      <abstract_sr>Istražujemo predstave naučene vizijskim i jezičkim modelima u zadatkima koji zahtevaju vezano razumljivanje. Fokusirajući se na problem procjene relativne veličine objekata u apstraktivnim vizualnim kontekstima, analiziramo i jednu korak i dva koraka razgovora. Za poslednje, izgradimo novi set podataka o scenama tri slike i definišemo zadatak koji zahteva razmišljanje na nivou individualnih slika i preko slika na sceni. Provjeravamo naučene predstave modela koristeći dijagnostičke klasifikacije. Naši eksperimenti pokazuju da pretkivne multimodalne arhitekture bazirane na transformaciji mogu izvršiti povezane razine na višem nivou i da mogu naučiti predstave za nove zadatke i podatke koje su veoma različite od onoga što je viđeno u pretkivanju.</abstract_sr>
      <abstract_ms>Kami menyelidiki perwakilan yang dipelajari oleh penglihatan dan model bahasa dalam tugas yang memerlukan alasan relatif. Berfokus pada masalah penilaian saiz relatif objek dalam konteks visual abstrak, kita menganalisis satu-langkah dan dua-langkah alasan. For the latter, we construct a new dataset of three-image scenes and define a task that requires reasoning at the level of the individual images and across images in a scene.  We probe the learned model representations using diagnostic classifiers.  Eksperimen kami menunjukkan bahawa arkitektur berasaskan pengubah multimodal yang dilatih dahulu boleh melakukan alasan relatif tinggi, dan mampu belajar perwakilan untuk tugas baru dan data yang sangat berbeza dari apa yang dilihat dalam latihan dahulu.</abstract_ms>
      <abstract_si>අපි දර්ශනය සහ භාෂා මොඩල් වලින් ඉගෙන ගත්ත ප්‍රතිනිධානය පරීක්ෂණය කරනවා ඒ වැඩේ සම්බන්ධ ප්‍රත ප්‍රශ්නයක් විශ්වාස කරන්නේ ප්‍රශ්නයක් විශ්වාස කරන්නේ ප්‍රශ්නයක් විශ්වාස කරන්න, අපි ප්‍රශ්නයක් එක පැත්ත සහ පැත් අන්තිමට, අපි පින්තූර තුන් පින්තූර ස්ථානයක් නිර්මාණය කරනවා වගේම පින්තූර තුන් පින්තූර ස්ථානයක් සහ පින්තූර ව අපි පරීක්ෂණය කරන්නේ ඉගෙන ගත්ත මොඩල් ප්‍රතිනිධානය ප්‍රතිනිධානය ප්‍රයෝජනය කරන්න. අපේ පරීක්ෂණය පෙන්වන්න පුළුවන් විදිහට ප්‍රමාණ විදිහට ස්ථාපනය වෙන්න පුළුවන් විදිහට වඩා ස්ථාපනය සම්බන්ධ විදිහට ප්‍රමාණය කරන්න</abstract_si>
      <abstract_so>Waxaannu baaraynaa noocyada muuqashada iyo tusaalaha afka lagu baray shaqada u baahan yahay sabab xiriir ah. Iska fiirsanaynaa dhibaatada qiimeynta qiyaastii la xiriira alaabta aragga ee ka mid ah, waxaynu baaraynaa sababta hal qadood iyo laba qadood. Marka ugu dambeyso, waxaynu dhisnaa sawir cusub oo saddex sawir ah, waxaana qoraynaa shaqo looga baahan yahay si looga hadlo darajada sawirada gaarka ah iyo sawirada gaarka ah. Waxaynu tijaabin karnaa noocyada barashada oo isticmaalaya fasaxyada yaqaanada. Imtixaanadayada waxay muuqan karaan in layaasha beddelka oo badan lagu soo hor jeeday ay ay sameyn karaan sababaha aad u sarreeya, waxayna baran karaan noocyo ka mid ah shaqooyinka warqada iyo macluumaadyo aad u kala duwan yihiin waxa lagu arkay wakhtiga hore.</abstract_so>
      <abstract_mt>Aħna ninvestigaw ir-rappreżentazzjonijiet imgħallma permezz ta’ viżjoni u mudelli lingwistiċi f’kompiti li jeħtieġu raġunament relattiv. Filwaqt li niffokaw fuq il-problema tal-valutazzjoni tad-daqs relattiv tal-oġġetti f’kuntesti viżwali astratti, nagħmlu analiżi kemm tar-raġunament f’pass wieħed kif ukoll ta’ żewġ passi. For the latter, we construct a new dataset of three-image scenes and define a task that requires reasoning at the level of the individual images and across images in a scene.  Aħna nistudjaw ir-rappreżentazzjonijiet tal-mudell imgħallem bl-użu ta’ klassifikaturi dijanjostiċi. L-esperimenti tagħna juru li arkitetturi multimodali mħarrġa minn qabel ibbażati fuq trasformaturi jistgħu jwettqu raġunament relattiv ta’ livell ogħla, u jistgħu jitgħallmu rappreżentazzjonijiet għal kompiti u dejta ġodda li huma differenti ħafna minn dak li deher fit-taħriġ minn qabel.</abstract_mt>
      <abstract_sv>Vi undersöker de representationer som lärts av visioner och språkmodeller i uppgifter som kräver relationellt resonemang. Med fokus på problemet med att bedöma objektens relativa storlek i abstrakta visuella sammanhang analyserar vi både ett- och tvåstegs resonemang. För det senare konstruerar vi en ny datauppsättning av tre-bildsscener och definierar en uppgift som kräver resonemang på nivå av enskilda bilder och över bilder i en scen. Vi undersöker de lärda modellrepresentationerna med hjälp av diagnostiska klassificerare. Våra experiment visar att förövade multimodala transformatorbaserade arkitekturer kan utföra relationella resonemang på högre nivå, och kan lära sig representationer för nya uppgifter och data som skiljer sig mycket från vad som sågs i förövande.</abstract_sv>
      <abstract_ta>நாம் தொடர்பு காரணங்கள் தேவைப்படும் பணிகளில் பார்வையும் மொழி மாதிரிகளாலும் கற்றுக் கொண்டிருக்க நாம் ஒரு படி மற்றும் இரண்டு படி காரணங்களையும் ஆய்வு செய்கிறோம். அடுத்தத்திற்கு, நாம் மூன்று பிம்பத்தின் காட்சிகளின் புதிய தகவல் அமைப்பை உருவாக்கி ஒரு செயலை வரையறுக்கிறோம். இது தனிப்பட்ட உருவங்களி நாங்கள் கண்டறிவு வகுப்பாளர்களை பயன்படுத்தி கற்ற மாதிரி பிரதிநிதிகளை கண்டறியும். நம்முடைய சோதனைகள் பல மாற்றங்களை மாற்றும் அடிப்படையிலுள்ள அடிப்படைகளை மாற்றி வைத்துள்ளார்கள் என்பதை காட்டுகிறது அதிக நிலையில் தொடர்பு காரணத்தை ச</abstract_ta>
      <abstract_ur>ہم دیکھنے اور زبان مدل کے ذریعے سیکھے ہوئے نمونے کی تحقیق کرتے ہیں جو کاموں میں رابطہ اختلاف کی ضرورت رکھتے ہیں. ہم ایک قدم اور دو قدم رابطہ کرنے کے مشکل پر مشکل کی نسبت سائز کی آزمائش کریں گے۔ آخرین کے لئے ہم تین تصاویر صحیفوں کے ایک نئی ڈیٹ سٹ بناتے ہیں اور ایک کام کی تعریف کرتے ہیں جو شخصی تصاویروں کے سطح اور تصاویروں کے مختلف سطح میں بحث کی ضرورت ہے۔ ہم نے سیکھا ہوا موڈل کی نمونہ کی تصدیق کرتی ہیں جو ڈاگنٹیک کلاسیفوں کے مطابق استعمال کرتے ہیں۔ ہمارے آزمائش دکھاتے ہیں کہ بہت سی موڈال تغییر دینے والی معماری عمارتیں بالاتر سطح کے ارتباط منطق کر سکتی ہیں، اور وہ نئی کاموں اور ڈیٹوں کے لئے نمونات سکھا سکتے ہیں جو ان چیزوں سے بہت مختلف ہیں جن کو پہلے دکھایا گیا تھا۔</abstract_ur>
      <abstract_uz>Biz tashkilotlarda ko'rinish va tillar modellari bilan o'rganish natijalarini o'rganamiz, murakkab sabablar kerak. Biz obʼektlarning qiymatlarini abstract ko'rinish muvaffaqiyatlariga qiymatish muammolari bilan bir qadam va ikki qadam sabablarini bajaramiz. Keyingi uchun biz uch rasm uslublarining yangi maʼlumotlar tarkibini yaratib, va bir vazifani aniqlash kerak. Biz shaxsiy rasmlarning darajada va ko'pchilik rasmlarning hamma darajada murojaat qilish kerak. Biz o'rganilgan modellarni diagnostic klassiplarini ishlatish mumkin. Bizning imtiyozlarimizni ko'pchilik o'zgartirish asosiy maktablari eng darajada munosabatlarni bajarishi mumkin, va yangi vazifalar va maʼlumotlar o'rganish mumkin. Ko'rib chiqishda ko'rinadigan narsalardan juda ajratilgan narsalar va ma'lumotlarni o'rganish mumkin.</abstract_uz>
      <abstract_vi>Chúng tôi điều tra các biểu tượng được học qua các mô hình ngôn ngữ trong các công việc cần lý lẽ liên quan. Tập trung vào vấn đề đánh giá kích thước tương đối của vật thể trong cấu hình ảnh trừu tượng, chúng ta phân tích cả phương trình một bước và hai bước. Với vế sau, chúng tôi xây dựng một tập tin mới về các hiện trường ba ảnh và xác định một nhiệm vụ cần phải lập trình cho mức độ của các ảnh cá nhân và hình ảnh trong một cảnh. Chúng tôi đã dò các mô hình học sử dụng phân loại chẩn đoán. Những thí nghiệm của chúng ta cho thấy các kiến trúc đa chiều được cấu trúc có thể đưa ra quan hệ cấp cao hơn, và có thể học các biểu tượng cho các công việc mới và dữ liệu hoàn to àn khác với những gì đã thấy trong quá trình chờ đợi.</abstract_vi>
      <abstract_bg>Проучваме образите, научени от визионните и езиковите модели в задачи, които изискват релационно разсъждаване. Фокусирайки се върху проблема за оценяване на относителния размер на обектите в абстрактни визуални контексти, анализираме едностепенно и двустепенно разсъждение. За последното конструираме нов набор от данни от триобразни сцени и дефинираме задача, която изисква разсъждаване на нивото на отделните изображения и през изображенията в дадена сцена. Проучваме научените модели с помощта на диагностични класификатори. Нашите експерименти показват, че предварително обучените мултимодални трансформаторни архитектури могат да изпълняват релационни разсъждения на по-високо ниво и са в състояние да научат представяне на нови задачи и данни, които са много различни от това, което се вижда в предтренирането.</abstract_bg>
      <abstract_da>Vi undersøger de repræsentationer, visioner og sprogmodeller lærer i opgaver, der kræver relationel ræsonnement. Med fokus på problemet med at vurdere objekternes relative størrelse i abstrakte visuelle sammenhænge analyserer vi både et- og to-trins ræsonnement. For sidstnævnte konstruerer vi et nyt datasæt af tre-billedscener og definerer en opgave, der kræver ræsonnement på niveau for de enkelte billeder og på tværs af billeder i en scene. Vi undersøger de lærte model repræsentationer ved hjælp af diagnostiske klassifikationer. Vores eksperimenter viser, at forudtrænede multimodale transformer-baserede arkitekturer kan udføre relationelle ræsonnementer på højere niveau, og er i stand til at lære repræsentationer for nye opgaver og data, der er meget forskellige fra, hvad der blev set i forudtræning.</abstract_da>
      <abstract_nl>We onderzoeken de representaties geleerd door visie- en taalmodellen in taken die relationeel redeneren vereisen. We richten ons op het probleem van het beoordelen van de relatieve grootte van objecten in abstracte visuele contexten, analyseren zowel one-step als two-step redenering. Voor dit laatste construeren we een nieuwe dataset van drie-beeldscènes en definiëren we een taak die redenering vereist op het niveau van de individuele beelden en tussen beelden in een scène. We onderzoeken de geleerde modellrepresentaties met behulp van diagnostische classificatoren. Onze experimenten tonen aan dat voorgetrainde multimodale transformatorgebaseerde architecturen relationeel redeneren op hoger niveau kunnen uitvoeren en representaties kunnen leren voor nieuwe taken en gegevens die sterk verschillen van wat werd gezien in pretraining.</abstract_nl>
      <abstract_hr>Istražujemo predstave naučene vizijskim i jezičkim modelima u zadatkima koji zahtijevaju vezano razumjevanje. Fokusirajući se na problem procjene relativne veličine objekata u apstraktivnim vizualnim kontekstima, analiziramo i jednokorak i dvokorak razumljivanja. Za sljedeće, izgradimo novi set podataka o scenama tri slike i definiramo zadatak koji zahtijeva razmišljanje na razini pojedinačnih slika i preko slika na sceni. Istražujemo naučene predstave modela koristeći dijagnostičke klasifikacije. Naši eksperimenti pokazuju da pretkivne multimodalne arhitekture bazirane na transformaciji mogu izvršiti povezane razine na višem nivou, i mogu naučiti zastupanje za nove zadatke i podatke koje su veoma različite od onoga što je vidjelo u pretkivanju.</abstract_hr>
      <abstract_de>Wir untersuchen die Darstellungen, die Vision und Sprachmodelle in Aufgaben erlernen, die relationales Denken erfordern. Wir konzentrieren uns auf das Problem der Beurteilung der relativen Größe von Objekten in abstrakten visuellen Kontexten und analysieren sowohl ein- als auch zweistufiges Denken. Für letztere konstruieren wir einen neuen Datensatz von Drei-Bild-Szenen und definieren eine Aufgabe, die auf Ebene der einzelnen Bilder und über Bilder in einer Szene nachdenken muss. Wir untersuchen die erlernten Modellrepräsentationen mit diagnostischen Klassifikatoren. Unsere Experimente zeigen, dass prätrainierte multimodale Transformatorarchitekturen ein höheres relationales Denken ausführen können und Repräsentationen für neue Aufgaben und Daten lernen können, die sich sehr von dem unterscheiden, was beim Vortraining gesehen wurde.</abstract_de>
      <abstract_fa>ما توسط نمایش‌های دید و مدل‌های زبان یاد گرفته شده را تحقیق می‌کنیم که به دلیل رابطه نیاز دارند. با توجه به مشکل ارزیابی اندازه نسبت به اشیاء در موقعیتهای تصویر مطلق، هر دو مرحله یک مرحله و دو مرحله را تحلیل می کنیم. برای آخرین، ما یک مجموعه داده‌های جدید از صحنه‌های سه تصویر ساخته می‌کنیم و یک کار را تعریف می‌کنیم که نیاز به منطقی در سطح تصویر فردی و در سطح تصویر فردی در صحنه است. ما نمایش‌های مدل یاد گرفته را با استفاده از طریق‌های تشخیص تحقیق می‌کنیم. آزمایشات ما نشان می دهند که معماری بسیار متغیر متغیر مدال‌های زیادی می‌توانند دلیل ارتباطی بالاتر را انجام دهند، و می‌توانند نمایش‌دهندگان برای وظیفه‌های رمانی و داده‌ها یاد بگیرند که بسیار متفاوت هستند از آنچه در پیش‌گیری دیده شده است.</abstract_fa>
      <abstract_id>Kami menyelidiki representati yang belajar oleh penglihatan dan model bahasa dalam tugas yang membutuhkan alasan relatif. Fokus pada masalah penilaian ukuran relatif objek dalam konteks visual abstrak, kami menganalisis alasan satu langkah dan dua langkah. For the latter, we construct a new dataset of three-image scenes and define a task that requires reasoning at the level of the individual images and across images in a scene.  Kami memeriksa representati model belajar menggunakan klasifikasi diagnostik. Eksperimen kami menunjukkan bahwa arsitektur multimodal berdasarkan transformator terlatih dapat melakukan alasan relatif tingkat lebih tinggi, dan dapat belajar representation untuk tugas dan data baru yang sangat berbeda dari apa yang terlihat dalam pelatihan terlatih.</abstract_id>
      <abstract_tr>Biz g철rn체힊 we dil nusgalaryndan 철wrenen suratlaryny g철r채 g철rn체힊 seb채plere gerek zadlarda 챌ykar첵arys. Abstrakt g철rn체힊 durumlarda zady흫 relativ 철l챌체sini 챌철zmek meselesine 체ns berip, we hem bir ad캇m hem iki ad캇m razylygyny 챌철z체r첵채ris. So흫ky 체챌in 체챌 surat sahypalaryny흫 t채ze bir veri setirini in 힊a edip, bir g철rn체힊 sahypalary흫 we suratlary흫 arasynda d체힊체nmek gereken zady takykla첵arys. Biz dijagnostik klasifikat철rleri kullanarak 철휓renmi힊 modelleri tahmin ediyoruz. Bizi흫 deneylerimiz 철흫체nden 철r채n modal transformer arhitekturlarymyz 첵okary derejede g철rn체힊 seb채plerini edip biler we 철n체nde g철r체len t채zeliklerden 철r채n farkl캇 힊ekilleri 철wrenip biler.</abstract_tr>
      <abstract_sq>Ne hetojmë përfaqësimet e mësuara nga vizioni dhe modelet gjuhësore në detyra që kërkojnë arsyetim marrëdhënies. Duke u përqëndruar në problem in e vlerësimit të madhësisë relative të objekteve në kontekste abstrakte vizuale, ne analizojmë si arsyetimin me një hap ashtu edhe dy hapa. Për të fundit, ne ndërtojmë një grup të ri të dhënash me tre imazhe dhe përcaktojmë një detyrë që kërkon arsyetim në nivelin e imazheve individuale dhe nëpër imazhe në një skenë. We probe the learned model representations using diagnostic classifiers.  Eksperimentet tona tregojnë se arkitekturat multimodale të trajnuara me bazë në transformues mund të kryejnë arsyetimin e nivelit të lartë të marrëdhënieve dhe janë në gjendje të mësojnë përfaqësime për detyra dhe të dhëna të reja që janë shumë të ndryshme nga ajo që shihej në paratrajnimin.</abstract_sq>
      <abstract_af>Ons ondersoek die voorstellings wat deur visie en taal modele geleer het in opdragte wat relatiewe redening nodig het. As ons fokus op die probleem van die relatiewe grootte van voorwerpe in abstrakte visuele konteks besluit, analyseer ons beide een-stap en twee-stap redering. Vir die laaste, ons bou 'n nuwe datastel van drie-beeldskene en definieer 'n taak wat benodig redensie op die vlak van die individuele beelde en oor beelde in 'n sken. Ons probeer die geleerde model voorstellings deur diagnosiese klassifiseerders te gebruik. Ons eksperimente wys dat multimodaal transformeerder-gebaseerde arkitekturke hoër vlak relasionele redening kan uitvoer en kan leer voorstellings vir nuwe opdragte en data wat baie anders is van wat gesien is in voorstelling.</abstract_af>
      <abstract_ko>우리는 시각과 언어 모델이 관계 추리가 필요한 임무에서 배운 표징을 연구했다.추상적인 시각 환경에서 물체의 상대적인 크기를 평가하는 문제에 대해 우리는 한 걸음과 두 걸음의 추리를 분석했다.후자에 대해 우리는 세 개의 이미지 장면을 포함하는 새로운 데이터 집합을 구축하고 하나의 임무를 정의했다. 이 임무는 장면의 단일 이미지와 크로스 이미지에서 추리를 해야 한다.우리는 진단 분류기 탐색 학습의 모형 표시를 사용한다.우리의 실험에 의하면 예비 훈련의 다중모드 변환기를 바탕으로 하는 체계 구조는 더욱 높은 수준의 관계 추리를 수행할 수 있고 예비 훈련에서 본 것과 매우 다른 새로운 임무와 데이터의 표시를 학습할 수 있다.</abstract_ko>
      <abstract_am>የራእይና የቋንቋ ምሳሌዎች በሚያስተምሩበት ስራ ውስጥ ተማርተዋል፡፡ የአካባቢዎች ቁጥጥር በሚያሳየው ውጤት ላይ በመቆጣጠር ላይ እናሳውቃለን፣ አንድ ደረጃ እና ሁለት ደረጃ ምክንያት እናስተምር፡፡ ለኋለኛይቱ፣ የሦስት ምስል ዓይነቶች አዲስ ዳታተር መሥራት እና በጣቢያ ምስሎች እና ምስሎችን በተለየ ደረጃ ላይ ማስታወቂያ የሚያስፈልጋቸውን ስራ እናሳውቃለን፡፡ ተማርነው የሞዴል ምሳሌ ምናረጋገጥን በdiagnostic ክፍተቶችን በመጠቀም እንሞክራለን፡፡ Our experiments show that pretrained multimodal transformer-based architectures can perform higher-level relational reasoning, and are able to learn representations for novel tasks and data that are very different from what was seen in pretraining.</abstract_am>
      <abstract_sw>Tunawachunguza uwakilishi waliojifunza kwa maono na mitindo ya lugha katika kazi zinazohitaji sababu za mahusiano. Kuelekea kwenye tatizo la kutathmini ukubwa wa vitu vya karibu katika mikutano ya kuona ya abstract visual, tunachambua sababu za hatua moja na hatua mbili. Kwa mwisho, tunajenga seti mpya ya taarifa za picha tatu na kuelezea juhudi ambalo linahitaji kujadili kiwango cha picha binafsi na katika picha nyingine katika eneo hilo. Tunawajaribu wawakilishaji wa mifano ya kujifunza kwa kutumia wataalamu wa uchunguzi. Majaribio yetu yanaonyesha kuwa majengo ya mabadiliko yanayotokana na mifano mingi yanayoweza kufanya mazingira ya juu ya kiwango cha mahusiano, na wanaweza kujifunza wakilishi katika kazi za riwaya na takwimu ambazo ni tofauti sana na yale yaliyoonekana katika kutengeneza mvua.</abstract_sw>
      <abstract_bn>আমরা দৃষ্টিভঙ্গি এবং ভাষার মডেল দ্বারা প্রতিনিধিদের তদন্ত করি যাদের সম্পর্কের কারণ দরকার। দৃষ্টিভঙ্গি প্রতিযোগিতায় বস্তুর আত্মিক আকার মূল্যের ব্যাপারে মনোযোগ দিয়ে আমরা এক ধাপ ও দুই ধাপের কারণে বিশ্লেষণ করি। পরবর্তীতে আমরা তিন ছবি দৃশ্যের একটি নতুন ডাটাসেট তৈরি করি এবং একটি কাজ নির্ধারণ করি যা ব্যক্তিগত ছবির স্তরে বিবেচনা করা দরকার এবং একটি দৃশ্যে পার্ আমরা শিক্ষিত মডেলের প্রতিনিধিদের পরীক্ষা করি ডায়াগনিস্টিক ব্যবহার করে। আমাদের পরীক্ষাগুলো দেখাচ্ছে যে মাল্টিমোডাল পরিবর্তনের ভিত্তিক কাঠামো উচ্চ পর্যায়ের সম্পর্কের কারণ প্রকাশ করতে পারে, আর তারা নতুন কাজ এবং তথ্যের প্রতিন</abstract_bn>
      <abstract_hy>Մենք ուսումնասիրում ենք տեսողության և լեզվի մոդելների միջոցով սովորված ներկայացումները այն խնդիրներում, որոնք պահանջում են հարաբերական մտածողություն: Մենք կենտրոնացնում ենք առարկաների հարաբերական չափի գնահատման խնդիրը վերացական տեսողական կոնտեքստում, մենք վերլուծում ենք մեկ քայլ և երկու քայլ մտածողությունները: Վերջիններին մենք կառուցում ենք երեք նկարների նոր տվյալների համակարգ և սահմանում ենք մի առաջադրանք, որը պահանջում է մտածողություն առանձին նկարների մակարդակում և պատկերների միջև: We probe the learned model representations using diagnostic classifiers.  Մեր փորձարկումները ցույց են տալիս, որ նախավարժեցված բազմամոդալ վերափոխողների հիմնված ճարտարապետությունները կարող են կատարել ավելի բարձր մակարդակի հարաբերական մտածողություն և կարող են սովորել նոր առաջադրանքների և տվյալների ներկայացումներ, որոնք շատ տարբերվում են նախավարժեցման ժամանակ</abstract_hy>
      <abstract_az>Biz görünüş və dil modellərinin öyrəndiyi göstəriciləri araşdırırıq ki, əlaqəsiz dəyişiklik lazımdır. Görünüş müxtəliflərdə objektlərin relativ böyüklüyünü müəyyən etmək problem in ə odaklanırsak, hər ikisini bir adım və iki adım razılığını analiz edirik. Sonuncu üçün üç görüntü sahələrinin yeni verilən qurğunu in şa edirik və bir sahədə görüntülərin səviyyəsində dəyişiklik lazımdır. Biz diagnostik klassifikatlarını istifadə edərək öyrənmiş modellərin göstərilmələrini incidirik. Bizim təcrübələrimiz çoxlu modal transformer-tabanlı arhitektürlər yüksək seviyyətli müxtəlif fikirləşdirmək və yeni işlər və məlumatları öyrənə bilərlər ki, əvvəlcə gördüyünüz şeylərdən çox farklı olduğunu öyrənə bilərlər.</abstract_az>
      <abstract_ca>Investiguem les representacions aprendes per la visió i els models lingüístics en tasques que requereixen raonament relacional. En centrar-nos en el problema de valorar la mida relativa dels objectes en contextes visuals abstracts, analitzem el raonament en un pas i en dos pas. Per a aquesta última, construïm un nou conjunt de dades d'escenes de tres imatges i definim una tasca que requereix raonament a nivell de les imatges individuals i a través d'imatges d'una escena. Investiguem les representacions del model aprengut fent servir classificadors diagnòstics. Els nostres experiments demostren que arquitectures basades en transformadors multimodals pré-treinades poden fer raonament relacional de nivell superior i poden aprendre representacions per noves tasques i dades que són molt diferents del que es va veure en pré-treinar.</abstract_ca>
      <abstract_et>Uurime nägemus- ja keelemudelitega õppitud representatsioone ülesannetes, mis nõuavad suhtelist mõtlemist. Keskendudes objektide suhtelise suuruse hindamise probleemile abstraktses visuaalses kontekstis analüüsime nii ühe- kui ka kaheastmelist arutlust. Viimase jaoks ehitame uue andmekogumi kolmest pildist stseenist ja määratleme ülesande, mis nõuab arutlemist üksikute piltide tasandil ja stseeni piltide vahel. Me uurime õppitud mudeli esitusi diagnostiliste klassifikaatorite abil. Meie eksperimendid näitavad, et eeltreenitud multimodaalsed transformaatoripõhised arhitektuurid suudavad teostada kõrgema taseme relatsioonilist arutlust ja õppida esitusi uudsete ülesannete ja andmete kohta, mis erinevad väga sellest, mida nähti eeltreeningus.</abstract_et>
      <abstract_bs>Istražujemo predstave naučene vizijskim i jezičkim modelima u zadatkima koji zahtijevaju vezano razumjanje. Fokusirajući se na problem procjene relativne veličine objekata u apstraktivnim vizualnim kontekstima, analiziramo i jednokorak i dvokorak razgovora. Za poslednje, izgradimo novi set podataka o scenama tri slike i definiramo zadatak koji zahtijeva razmišljanje na nivou individualnih slika i preko slika na sceni. Provjeravamo naučene predstave modela koristeći dijagnostičke klasifikacije. Naši eksperimenti pokazuju da pretkivne multimodalne arhitekture bazirane na transformaciji mogu izvršiti povezane razine na višem nivou, i mogu naučiti predstave za nove zadatke i podatke koje su veoma različite od onoga što je viđeno u pretkivanju.</abstract_bs>
      <abstract_cs>Zkoumáme reprezentace získané vizí a jazykovými modely v úkolech, které vyžadují relační uvažování. Zaměřujeme se na problematiku hodnocení relativní velikosti objektů v abstraktních vizuálních kontextech a analyzujeme jednostupňové i dvoustupňové uvažování. Pro druhé vytvoříme novou datovou sadu tříobrazových scén a definujeme úkol, který vyžaduje uvažování na úrovni jednotlivých snímků a napříč obrazy ve scéně. Naučené modelové reprezentace zkoumáme pomocí diagnostických klasifikátorů. Naše experimenty ukazují, že předtrénované multimodální transformátorové architektury mohou provádět vyšší úroveň relačního uvažování a jsou schopny se naučit reprezentace nových úkolů a dat, které se velmi liší od toho, co bylo vidět v předtréninku.</abstract_cs>
      <abstract_fi>Tutkimme näkemys- ja kielimallien oppimia representaatioita suhteessa päättelyä vaativissa tehtävissä. Keskitymme objektien suhteellisen koon arviointiin abstraktissa visuaalisissa konteksteissa ja analysoimme sekä yhden- että kaksivaiheista päättelyä. Jälkimmäistä varten rakennamme uuden kolmikuvamaisen kohtauksen aineiston ja määrittelemme tehtävän, joka vaatii järkeilyä yksittäisten kuvien tasolla ja kohtauksen kuvien välillä. Tutkimme opittuja malliesityksiä käyttäen diagnostisia luokittelijoita. Kokeemme osoittavat, että esikoulutetut multimodaaliset muuntajapohjaiset arkkitehtuurit pystyvät suorittamaan korkeamman tason relaatiopäättelyä, ja pystyvät oppimaan representaatioita uusista tehtävistä ja datasta, jotka ovat hyvin erilaisia kuin esikoulutuksessa nähtiin.</abstract_fi>
      <abstract_ha>Munã jãyayya misãlai da aka sanar da idãnun da harshe cikin aikin da ke da muhimmada masu husũma. Fokus kan masu zartar da kure ga girmar abubuwa cikin muhimman abubuwa na kanana, za'a yi anarwa ga kwanza ta guda da taki biyu. Ganin da ya ƙara, muna samar da wani tsari na zane-surar uku kuma munãƙayyade wani aikin da za'a buƙata yin magana a tsakanin zanen guda da bayan zane-zane cikin wani fili. Ina jarraba misalin da aka sanar da su a yi amfani da wasu fassarai. Kayan jarrabõnmu na nũna cewa misalin multi-multiodal da aka danne shi, yana iya iya karatun matsayin masu sarrafa a matsayin mazaɓa, kuma sunã iya karatun masu tsari ga aikin kwanan da aka samu da data waɗanda ke sãɓã wa abin da aka gan shi a bakin matuƙar.</abstract_ha>
      <abstract_sk>Raziskujemo reprezentacije, ki se jih naučijo vizijski in jezikovni modeli v nalogah, ki zahtevajo relacijsko razmišljanje. S poudarkom na problemu ocenjevanja relativne velikosti objektov v abstraktnih vizualnih kontekstih analiziramo enostopenjsko in dvokostopenjsko razmišljanje. Za slednje gradimo nov nabor podatkov trislikovnih prizorov in opredelimo nalogo, ki zahteva razmišljanje na ravni posameznih slik in med slikami v prizoru. S pomočjo diagnostičnih klasifikatorjev preiskujemo znane predstavitve modela. Naši eksperimenti kažejo, da lahko predtrenirane multimodalne transformatorske arhitekture izvajajo relacijsko razmišljanje na višji ravni in se naučijo reprezentacij za nove naloge in podatke, ki so zelo različni od tistega, kar je bilo videno v predtreningu.</abstract_sk>
      <abstract_he>אנחנו חוקרים את היציגות שלמדו על ידי חזון ודוגמנים לשפה במשימות שדורשות הגיון יחסי. מתמקדת בבעיה של הערכה של גודל יחסי של אובייקטים בקשר ויזואלי אסטרקטי, אנו מנתחים את ההיגיון צעד אחד ושני צעדים. עבור האחרון, אנחנו בונים קבוצת מידע חדשה של סצנות שלושה תמונות ולהגדיר משימה שדורשת הגיון ברמה של התמונות הפרטיות ובדרך תמונות בסצנה. אנו חוקרים את התצגות המודל למדות באמצעות מערכות אבחנה. הניסויים שלנו מראים שהארכיטקטורות המולטומודליות המבוססות מראש יכולות לבצע הגיון מערכי יחסים ברמה גבוהה יותר, ויכולות ללמוד מייצגים למשימות חדשות ומידע שונים מאד ממה שנראה בהימון מראש.</abstract_he>
      <abstract_jv>Awak dhéwé nyulung perusahaan repréntasi dipunangé karo tindang karo perusahaan langgar nganggep nggawe barang nggawe string" in "context_BAR_stringLink Sampeyan XMPP Kernel Awak dhéwé éntuk perbudhakan karo akeh multimodal sing bisa dianggawe akeh perusahaan langgar sampek luwih, lan ijol-ijolan iso nggambar tarjamahan kanggo nganggo perusahaan karo nganggo dolanan sing paling dhéwé lan data sing wis diparahak sak titimbang langgar-itimbang langgar.</abstract_jv>
      <abstract_bo>ང་ཚོས་མཐོང་ནི་ལྟ་བ་དང་སྐད་ཡིག་ཆ་རྣམས་ལས་རྟོགས་པའི་གསལ་བཤད་ལ་བཙལ་ཞིབ་བྱེད་ཀྱི་ཡོད། ང་ཚོས་མཐོང་བའི་གནས་ཚུལ་ནང་གི་དངོས་པོ་ཡི་ཆེ་ཆུང་ལ་བསམ་བློ་གཏོང་བའི་དཀའ་ངལ འཛམ་གླིང་གི་ལྟ་བུའི་ནང་དུ་ང་ཚོས་བརྙན་རིས་གསུམ་ཀྱི་གནད་སྡུད་གསར་བ་ཞིག་འཛུགས་བྱས་ནས་སྤྱོད་ཐོག་ཅིག་ངེས་འཛིན་བྱེད་དགོ ང་ཚོས་དབྱེ་རིག་གི་མ་དབྱིབས་དཔྱད་འཛིན་བྱེད་པའི་རྣམ་པ་གྱི་གསལ་བཤད་དག་ལ་ཞིབ ང་ཚོའི་བརྟག་ཞིག་བྱས་ནས་བཟོ་བཅོས་ཐབས་བྱུང་བའི་སྒྲིག་ཆ་རྩལ་གཞི་བརྟེན་ནས་མཐུན་གྱི་མཐུན་རིམ་མཐུན་ཚད་མཐོ་ཤོས་བྱེད་སྲིད། བྱས་ཙང་གསར་འགུལ་གྱི་བྱ་བ</abstract_bo>
      </paper>
    <paper id="21">
      <title>Predicting the Success of <a href="https://en.wikipedia.org/wiki/Domain_adaptation">Domain Adaptation</a> in Text Similarity</title>
      <author><first>Nick</first><last>Pogrebnyakov</last></author>
      <author><first>Shohreh</first><last>Shaghaghian</last></author>
      <pages>206–212</pages>
      <abstract>Transfer learning methods, and in particular domain adaptation, help exploit labeled data in one domain to improve the performance of a certain task in another domain. However, it is still not clear what factors affect the success of <a href="https://en.wikipedia.org/wiki/Adaptation_(biology)">domain adaptation</a>. This paper models <a href="https://en.wikipedia.org/wiki/Adaptation">adaptation</a> success and selection of the most suitable source domains among several candidates in <a href="https://en.wikipedia.org/wiki/Similarity_measure">text similarity</a>. We use descriptive domain information and cross-domain similarity metrics as <a href="https://en.wikipedia.org/wiki/Predictive_analytics">predictive features</a>. While mostly positive, the results also point to some domains where <a href="https://en.wikipedia.org/wiki/Adaptation">adaptation</a> success was difficult to predict.</abstract>
      <url hash="0ad1ab71">2021.repl4nlp-1.21</url>
      <doi>10.18653/v1/2021.repl4nlp-1.21</doi>
      <bibkey>pogrebnyakov-shaghaghian-2021-predicting</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/mrpc">MRPC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/paws">PAWS</pwcdataset>
    </paper>
    <paper id="26">
      <title>Deriving Contextualised Semantic Features from BERT (and Other Transformer Model) Embeddings<fixed-case>BERT</fixed-case> (and Other Transformer Model) Embeddings</title>
      <author><first>Jacob</first><last>Turton</last></author>
      <author><first>Robert Elliott</first><last>Smith</last></author>
      <author><first>David</first><last>Vinson</last></author>
      <pages>248–262</pages>
      <abstract>Models based on the transformer architecture, such as BERT, have marked a crucial step forward in the field of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a>. Importantly, they allow the creation of <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> that capture important semantic information about words in context. However, as single entities, these <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> are difficult to interpret and the <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> used to create them have been described as opaque. Binder and colleagues proposed an intuitive embedding space where each dimension is based on one of 65 core semantic features. Unfortunately, the <a href="https://en.wikipedia.org/wiki/Space_(mathematics)">space</a> only exists for a small data-set of 535 words, limiting its uses. Previous work (Utsumi, 2018, 2020 ; Turton et al., 2020) has shown that Binder features can be derived from static embeddings and successfully extrapolated to a large new vocabulary. Taking the next step, this paper demonstrates that Binder features can be derived from the BERT embedding space. This provides two things ; (1) semantic feature values derived from contextualised word embeddings and (2) insights into how semantic features are represented across the different layers of the BERT model.</abstract>
      <url hash="eea0ed24">2021.repl4nlp-1.26</url>
      <doi>10.18653/v1/2021.repl4nlp-1.26</doi>
      <bibkey>turton-etal-2021-deriving</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/billion-word-benchmark">Billion Word Benchmark</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wic">WiC</pwcdataset>
    </paper>
    <paper id="29">
      <title>An Overview of Uncertainty Calibration for <a href="https://en.wikipedia.org/wiki/Text_classification">Text Classification</a> and the Role of Distillation</title>
      <author><first>Han</first><last>Guo</last></author>
      <author><first>Ramakanth</first><last>Pasunuru</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>289–306</pages>
      <abstract>Recent advances in NLP systems, notably the pretraining-and-finetuning paradigm, have achieved great success in predictive accuracy. However, these <a href="https://en.wikipedia.org/wiki/System">systems</a> are usually not well calibrated for uncertainty out-of-the-box. Many recalibration methods have been proposed in the literature for quantifying predictive uncertainty and calibrating model outputs, with varying degrees of <a href="https://en.wikipedia.org/wiki/Complexity">complexity</a>. In this work, we present a systematic study of a few of these <a href="https://en.wikipedia.org/wiki/Methodology">methods</a>. Focusing on the text classification task and finetuned large pretrained language models, we first show that many of the finetuned models are not well calibrated out-of-the-box, especially when the data come from out-of-domain settings. Next, we compare the effectiveness of a few widely-used recalibration methods (such as <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensembles</a>, temperature scaling). Then, we empirically illustrate a connection between <a href="https://en.wikipedia.org/wiki/Distillation">distillation</a> and <a href="https://en.wikipedia.org/wiki/Calibration">calibration</a>. We view <a href="https://en.wikipedia.org/wiki/Distillation">distillation</a> as a regularization term encouraging the student model to output uncertainties that match those of a teacher model. With this insight, we develop simple recalibration methods based on <a href="https://en.wikipedia.org/wiki/Distillation">distillation</a> with no additional inference-time cost. We show on the GLUE benchmark that our simple methods can achieve competitive out-of-domain (OOD) calibration performance w.r.t. more expensive approaches. Finally, we include <a href="https://en.wikipedia.org/wiki/Ablation">ablations</a> to understand the usefulness of components of our proposed method and examine the transferability of <a href="https://en.wikipedia.org/wiki/Calibration">calibration</a> via <a href="https://en.wikipedia.org/wiki/Distillation">distillation</a>.</abstract>
      <url hash="2dd50aa0">2021.repl4nlp-1.29</url>
      <doi>10.18653/v1/2021.repl4nlp-1.29</doi>
      <bibkey>guo-etal-2021-overview</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cola">CoLA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/qnli">QNLI</pwcdataset>
    </paper>
    <paper id="32">
      <title>Direction is what you need : Improving Word Embedding Compression in Large Language Models</title>
      <author><first>Klaudia</first><last>Bałazy</last></author>
      <author><first>Mohammadreza</first><last>Banaei</last></author>
      <author><first>Rémi</first><last>Lebret</last></author>
      <author><first>Jacek</first><last>Tabor</last></author>
      <author><first>Karl</first><last>Aberer</last></author>
      <pages>322–330</pages>
      <abstract>The adoption of Transformer-based models in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing (NLP)</a> has led to great success using a massive number of parameters. However, due to deployment constraints in <a href="https://en.wikipedia.org/wiki/Edge_device">edge devices</a>, there has been a rising interest in the <a href="https://en.wikipedia.org/wiki/Data_compression">compression</a> of these models to improve their inference time and memory footprint. This paper presents a novel loss objective to compress token embeddings in the Transformer-based models by leveraging an AutoEncoder architecture. More specifically, we emphasize the importance of the direction of compressed embeddings with respect to original uncompressed embeddings. The proposed method is task-agnostic and does not require further language modeling pre-training. Our method significantly outperforms the commonly used SVD-based matrix-factorization approach in terms of initial language model Perplexity. Moreover, we evaluate our proposed approach over SQuAD v1.1 dataset and several downstream tasks from the GLUE benchmark, where we also outperform the baseline in most scenarios. Our code is public.</abstract>
      <url hash="400009e5">2021.repl4nlp-1.32</url>
      <doi>10.18653/v1/2021.repl4nlp-1.32</doi>
      <bibkey>balazy-etal-2021-direction</bibkey>
      <revision id="1" href="2021.repl4nlp-1.32v1" hash="445056a2" />
      <revision id="2" href="2021.repl4nlp-1.32v2" hash="400009e5" date="2021-08-12">Added a sponsor</revision>
      <pwccode url="https://github.com/MohammadrezaBanaei/orientation_based_embedding_compression" additional="false">MohammadrezaBanaei/orientation_based_embedding_compression</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mrpc">MRPC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
  </volume>
</collection>