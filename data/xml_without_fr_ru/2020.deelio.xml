<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.deelio">
  <volume id="1" ingest-date="2020-11-06">
    <meta>
      <booktitle>Proceedings of Deep Learning Inside Out (DeeLIO): The First Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</booktitle>
      <editor><first>Eneko</first><last>Agirre</last></editor>
      <editor><first>Marianna</first><last>Apidianaki</last></editor>
      <editor><first>Ivan</first><last>Vulić</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>November</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="ebbcf132">2020.deelio-1.0</url>
      <bibkey>deelio-2020-deep</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Generalization to Mitigate Synonym Substitution Attacks</title>
      <author><first>Basemah</first><last>Alshemali</last></author>
      <author><first>Jugal</first><last>Kalita</last></author>
      <pages>20–28</pages>
      <abstract>Studies have shown that deep neural networks (DNNs) are vulnerable to adversarial examples   perturbed inputs that cause DNN-based models to produce incorrect results. One robust adversarial attack in the NLP domain is the synonym substitution. In attacks of this variety, the adversary substitutes words with <a href="https://en.wikipedia.org/wiki/Synonym">synonyms</a>. Since synonym substitution perturbations aim to satisfy all lexical, grammatical, and semantic constraints, they are difficult to detect with automatic syntax check as well as by humans. In this paper, we propose a structure-free defensive method that is capable of improving the performance of DNN-based models with both clean and adversarial data. Our findings show that replacing the embeddings of the important words in the input samples with the average of their synonyms’ embeddings can significantly improve the generalization of DNN-based classifiers. By doing so, we reduce <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">model sensitivity</a> to particular words in the input samples. Our results indicate that the proposed defense is not only capable of defending against adversarial attacks, but is also capable of improving the performance of DNN-based models when tested on benign data. On average, the proposed defense improved the classification accuracy of the CNN and Bi-LSTM models by 41.30 % and 55.66 %, respectively, when tested under adversarial attacks. Extended investigation shows that our defensive method can improve the robustness of nonneural models, achieving an average of 17.62 % and 22.93 % classification accuracy increase on the SVM and XGBoost models, respectively. The proposed defensive method has also shown an average of 26.60 % <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification accuracy</a> improvement when tested with the infamous BERT model.</abstract>
      <url hash="d831f583">2020.deelio-1.3</url>
      <doi>10.18653/v1/2020.deelio-1.3</doi>
      <video href="https://slideslive.com/38939726" />
      <bibkey>alshemali-kalita-2020-generalization</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
    <title_ar>التعميم للتخفيف من هجمات استبدال المرادفات</title_ar>
      <title_es>Generalización para mitigar los ataques de sustitución de sinónimos</title_es>
      <title_pt>Generalização para mitigar ataques de substituição de sinônimos</title_pt>
      <title_ja>代名詞置換攻撃を軽減するための一般化</title_ja>
      <title_hi>समानार्थी प्रतिस्थापन हमलों को कम करने के लिए सामान्यीकरण</title_hi>
      <title_zh>泛化以轻同义词代攻</title_zh>
      <title_ga>Ginearálú chun Ionsaithe Ionadaithe Comhchiallacha a Mhaolú</title_ga>
      <title_ka>სინონიმის გადაყენება დაკავშირებებისთვის გენერალაცია</title_ka>
      <title_hu>Általánosítás a szinonim helyettesítő támadások enyhítésére</title_hu>
      <title_el>Γενικοποίηση για την άμβλυνση των επιθέσεων υποκατάστασης συνονόμων</title_el>
      <title_lt>Generalizacija siekiant sumažinti sinonimų pakeitimo atakus</title_lt>
      <title_kk>Синонимді алмастыру тіркемелерін шектеу үшін жасау</title_kk>
      <title_it>Generalizzazione per mitigare gli attacchi di sostituzione sinonimi</title_it>
      <title_mk>Generalization to Mitigate Synonym Substitution Attacks</title_mk>
      <title_mt>Ġeneralizzazzjoni biex jittaffew attakki ta’ sostituzzjoni tas-Sinonimu</title_mt>
      <title_ml>സങ്കീര്‍ണ്ണത്തിന്റെ അടിസ്ഥാനത്തിന്റെ പൊതുവാക്കുക</title_ml>
      <title_mn>Хэрэглэгчийн хамгаалалтын хамгаалалтуудыг багасгах</title_mn>
      <title_ms>Jeneralisasi untuk Melawankan Serangan Ganti Sinonim</title_ms>
      <title_no>Generalisering for å gjennomføra synonymisk substitusjonsvedlegg</title_no>
      <title_pl>Uogólnienie w celu ograniczenia ataków zastępczych synonimów</title_pl>
      <title_ro>Generalizarea pentru atenuarea atacurilor de substituție sinonime</title_ro>
      <title_sr>Generalizacija za ukljuèivanje sinonièkih napada za zamjenu</title_sr>
      <title_si>සාමාන්‍ය වෙනුවෙන් සමාන්‍ය වෙනුවෙන් සමාන්‍ය වෙනුවෙන් සැකසුම</title_si>
      <title_so>Jaamar u sameeya</title_so>
      <title_sv>Generalisering för att mildra synonym substitutionsattacker</title_sv>
      <title_ta>ஒத்திசைப்படுத்தல் அடிக்குகளை கலக்கு செய்</title_ta>
      <title_ur>Synonym Substitution Attacks</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Chế độ giết người Thần thoại</title_vi>
      <title_hr>Generalizacija za uključivanje napada za zamjenu sinonima</title_hr>
      <title_bg>Обобщение за смекчаване на атаките за заместване на синонимите</title_bg>
      <title_nl>Generalisering om synoniem vervangingsaanvallen te verminderen</title_nl>
      <title_da>Generalisering til at mindske synonym substitutionsangreb</title_da>
      <title_de>Generalisierung zur Abschwächung von Angriffen auf Synonyme-Substitution</title_de>
      <title_id>Generalisasi untuk Mitigasi Serangan Substitusi Sinonim</title_id>
      <title_fa>ژنرال برای تغییر حمله‌های همگانی</title_fa>
      <title_ko>공통화하여 동의어 교체 공격을 경감시키다</title_ko>
      <title_sq>Gjeneralizimi për të lehtësuar sulmet e zëvendësimit të sinonimit</title_sq>
      <title_af>Generalisasie na verklein sinoniem substitusie aanhegsels</title_af>
      <title_sw>Umoja wa kushambuliwa kwa Uunganishaji</title_sw>
      <title_tr>Synonym Gaýd Edilmelerini Azdyrmak üçin döredilme</title_tr>
      <title_az>Sinonim 쿮lav톛 쿮lav톛l톛rini Q캼d캼rmaq 칲칞칲n Generalizasyon</title_az>
      <title_hy>Comment</title_hy>
      <title_am>ምስሉን በሌላ ስም አስቀምጥ</title_am>
      <title_bn>সিনোনিম সাবস্টিউটেশন আক্রমণের জন্য সাধারণ</title_bn>
      <title_cs>Všeobecnění pro zmírnění synonymních náhradních útoků</title_cs>
      <title_ca>Generalització per mitigar els atacs de substitució de sinònims</title_ca>
      <title_bs>Generalizacija za uključivanje sinonima zamjene napada</title_bs>
      <title_et>Üldine sünonüümi asendamise rünnakute leevendamine</title_et>
      <title_fi>Yleistäminen synonyymien korvaavien hyökkäysten lieventämiseksi</title_fi>
      <title_jv>structural navigation</title_jv>
      <title_ha>@ action</title_ha>
      <title_he>הגנרליזציה כדי להקל תקיפות תחליפות סינונים</title_he>
      <title_sk>Generalizacija za ublažitev napadov nadomestitve sinonimov</title_sk>
      <title_bo>ཆ་མཚོན་རྟགས་ལ་ཚབ་སྒྲིག་མཐུད་སྒྲིག་འགོད་བྱེད་པར་བཟོ་བཅོས</title_bo>
      <abstract_ar>أظهرت الدراسات أن الشبكات العصبية العميقة (DNNs) معرضة لأمثلة متعارضة - مدخلات مضطربة تتسبب في إنتاج النماذج المستندة إلى DNN لنتائج غير صحيحة. أحد الهجمات العدائية القوية في مجال البرمجة اللغوية العصبية هو استبدال المرادف. في هجمات من هذا النوع ، يستبدل الخصم الكلمات بمرادفات. نظرًا لأن اضطرابات استبدال المرادفات تهدف إلى تلبية جميع القيود المعجمية والنحوية والدلالية ، فمن الصعب اكتشافها من خلال التحقق التلقائي من بناء الجملة وكذلك من قبل البشر. في هذه الورقة ، نقترح طريقة دفاعية خالية من البنية قادرة على تحسين أداء النماذج المستندة إلى DNN مع كل من البيانات النظيفة والمتعارضة. تظهر النتائج التي توصلنا إليها أن استبدال تضمين الكلمات المهمة في عينات الإدخال بمتوسط زخارف مرادفاتها يمكن أن يحسن بشكل كبير تعميم المصنفات المستندة إلى DNN. من خلال القيام بذلك ، نقوم بتقليل حساسية النموذج لكلمات معينة في عينات الإدخال. تشير نتائجنا إلى أن الدفاع المقترح ليس فقط قادرًا على الدفاع ضد الهجمات العدائية ، ولكنه قادر أيضًا على تحسين أداء النماذج المستندة إلى DNN عند اختبارها على بيانات حميدة. في المتوسط ، حسّن الدفاع المقترح دقة التصنيف لنماذج CNN و Bi-LSTM بنسبة 41.30٪ و 55.66٪ على التوالي ، عند اختباره في ظل هجمات معادية. يُظهر التحقيق الموسع أن طريقتنا الدفاعية يمكن أن تحسن متانة النماذج غير العصبية ، محققة متوسط 17.62٪ و 22.93٪
زيادة دقة التصنيف في طرازي SVM و XGBoost ، على التوالي. أظهرت الطريقة الدفاعية المقترحة أيضًا تحسنًا في دقة التصنيف بمعدل 26.60٪ عند اختبارها باستخدام نموذج BERT سيئ السمعة. تعد الخوارزمية الخاصة بنا عامة بما يكفي ليتم تطبيقها في أي مجال من مجالات البرمجة اللغوية العصبية وعلى أي نموذج يتم تدريبه على أي لغة طبيعية.</abstract_ar>
      <abstract_ja>研究によると、深層ニューラルネットワーク（ DNN ）は、DNNベースのモデルが誤った結果を生み出す原因となる摂動的な入力の対立例に脆弱であることが示されています。 NLPドメインにおける堅牢な対抗攻撃の1つは、代名詞置換である。 この種の攻撃では、敵対者は単語を代名詞に置き換えます。 代名詞置換摂動は、すべての語彙的、文法的、および意味的制約を満たすことを目的としているため、人間だけでなく自動構文チェックでも検出することは困難である。 本稿では、クリーンデータと対抗データの両方でDNNベースのモデルのパフォーマンスを向上させることができる構造フリーの防御方法を提案する。 我々の調査結果は、入力サンプル内の重要な単語の埋め込みを同義語の埋め込みの平均に置き換えることで、DNNベースの分類子の一般化を大幅に改善できることを示しています。 これにより、入力サンプルの特定の単語に対するモデル感度を低下させます。 我々の結果は、提案された防御は、敵対的な攻撃から防御することができるだけでなく、良性データでテストされたときにDNNベースのモデルのパフォーマンスを向上させることができることを示しています。 平均して、提案された防御は、対抗攻撃下で試験された場合、CNNモデルとBi - LSTMモデルの分類精度をそれぞれ41.30%と55.66%改善した。 拡張調査では、当社の防御方法は非神経モデルの堅牢性を向上させることができ、平均17.62 ％および22.93 ％を達成することが示されています。
sVMモデルとXGBoostモデルでそれぞれ分類精度が向上します。提案された防御方法はまた、悪名高いBERTモデルで試験した場合、平均26.60 ％の分類精度向上を示しています。当社のアルゴリズムは、あらゆるNLPドメインおよびあらゆる自然言語でトレーニングされたあらゆるモデルに適用できるほど一般的です。</abstract_ja>
      <abstract_es>Los estudios han demostrado que las redes neuronales profundas (DNN) son vulnerables a ejemplos contradictorios, entradas perturbadas que hacen que los modelos basados en DNN produzcan resultados incorrectos. Un ataque contundente de confrontación en el dominio de la PNL es la sustitución de sinónimos. En ataques de esta variedad, el adversario sustituye palabras por sinónimos. Dado que las perturbaciones de sustitución de sinónimos tienen como objetivo satisfacer todas las restricciones léxicas, gramaticales y semánticas, son difíciles de detectar con la verificación automática de la sintaxis, así como por parte de los humanos. En este artículo, proponemos un método defensivo sin estructura que es capaz de mejorar el rendimiento de los modelos basados en DNN con datos limpios y contradictorios. Nuestros hallazgos muestran que reemplazar las incrustaciones de las palabras importantes en las muestras de entrada con el promedio de incrustaciones de sus sinónimos puede mejorar significativamente la generalización de los clasificadores basados en DNN. Al hacerlo, reducimos la sensibilidad del modelo a palabras particulares en las muestras de entrada. Nuestros resultados indican que la defensa propuesta no solo es capaz de defenderse de ataques adversarios, sino que también es capaz de mejorar el rendimiento de los modelos basados en DNN cuando se prueban con datos benignos. En promedio, la defensa propuesta mejoró la precisión de clasificación de los modelos CNN y Bi-LSTM en un 41,30% y 55,66%, respectivamente, cuando se probó bajo ataques adversarios. La investigación extendida muestra que nuestro método defensivo puede mejorar la robustez de los modelos no neuronales, logrando un promedio de 17,62% y 22,93%
aumento de la precisión de la clasificación en los modelos SVM y XGBoost, respectivamente. El método defensivo propuesto también ha mostrado una mejora promedio de la precisión de la clasificación del 26.60% cuando se prueba con el infame modelo BERT. Nuestro algoritmo es lo suficientemente genérico como para ser aplicado en cualquier dominio de la PNL y en cualquier modelo entrenado en cualquier lenguaje natural.</abstract_es>
      <abstract_pt>Estudos mostraram que redes neurais profundas (DNNs) são vulneráveis a exemplos adversários – entradas perturbadas que fazem com que modelos baseados em DNN produzam resultados incorretos. Um ataque adversário robusto no domínio da PNL é a substituição de sinônimos. Em ataques dessa variedade, o adversário substitui palavras por sinônimos. Como as perturbações de substituição de sinônimos visam satisfazer todas as restrições lexicais, gramaticais e semânticas, elas são difíceis de detectar com verificação automática de sintaxe, bem como por humanos. Neste artigo, propomos um método defensivo sem estrutura capaz de melhorar o desempenho de modelos baseados em DNN com dados limpos e adversários. Nossas descobertas mostram que substituir os embeddings das palavras importantes nas amostras de entrada pela média dos embeddings de seus sinônimos pode melhorar significativamente a generalização de classificadores baseados em DNN. Ao fazer isso, reduzimos a sensibilidade do modelo a palavras específicas nas amostras de entrada. Nossos resultados indicam que a defesa proposta não é apenas capaz de se defender contra ataques adversários, mas também é capaz de melhorar o desempenho de modelos baseados em DNN quando testados em dados benignos. Em média, a defesa proposta melhorou a precisão de classificação dos modelos CNN e Bi-LSTM em 41,30% e 55,66%, respectivamente, quando testados sob ataques adversários. Investigação estendida mostra que nosso método defensivo pode melhorar a robustez de modelos não neurais, alcançando uma média de 17,62% e 22,93%
aumento da precisão de classificação nos modelos SVM e XGBoost, respectivamente. O método defensivo proposto também mostrou uma melhoria média de 26,60% na precisão da classificação quando testado com o infame modelo BERT. Nosso algoritmo é genérico o suficiente para ser aplicado em qualquer domínio de PNL e em qualquer modelo treinado em qualquer linguagem natural.</abstract_pt>
      <abstract_zh>论深神经网络(DNN)易对抗性示例,对抗性示例生于DNN。 NLP域中一强对抗性攻者,同义词代也。 凡此诸攻,敌以同义词易单词。 以同义词代扰足词汇、语法、语义约束,难以自语法检查和人工检之。 本文中,设无结构守御之法,所以崇DNN之性,洁对抗性之数也。 臣等考结果表明,将输样本要单词者嵌替为其同义词嵌者平均值可以显DNN分类器之泛化。 因此,我们降了模样对输入样本中特定单词的敏感性。 吾之的结果表明,非徒能守御对抗性攻也,且试之良性数,犹足以崇DNN之性也。 平均言之,对抗性攻而试之,所谓守御将CNN与Bi-LSTM模形之类准确性各崇41.30%55.66%。 广之以明,吾守以崇非神经模之鲁棒性,均致17.62%和22.93%
SVM 与 XGBoost 形之分益高。 所陈守御之法犹见,当试以臭名昭着BERT,类准确性均升26.60%。 算法足以通用,可以NLP域,可以练自然语言。</abstract_zh>
      <abstract_hi>अध्ययनों से पता चला है कि गहरे तंत्रिका नेटवर्क (डीएनएन) प्रतिकूल उदाहरणों के लिए कमजोर हैं - परेशान इनपुट जो डीएनएन-आधारित मॉडल को गलत परिणाम उत्पन्न करने का कारण बनते हैं। एनएलपी डोमेन में एक मजबूत प्रतिकूल हमला समानार्थी प्रतिस्थापन है। इस किस्म के हमलों में, विरोधी शब्दों को पर्यायवाची शब्दों के साथ प्रतिस्थापित करता है। चूंकि पर्यायवाची प्रतिस्थापन का उद्देश्य सभी लेक्सिकल, व्याकरणिक और शब्दार्थ बाधाओं को संतुष्ट करना है, इसलिए उन्हें स्वचालित वाक्यविन्यास जांच के साथ-साथ मनुष्यों द्वारा भी पता लगाना मुश्किल है। इस पेपर में, हम एक संरचना-मुक्त रक्षात्मक विधि का प्रस्ताव करते हैं जो स्वच्छ और प्रतिकूल डेटा दोनों के साथ डीएनएन-आधारित मॉडल के प्रदर्शन में सुधार करने में सक्षम है। हमारे निष्कर्ष ों से पता चलता है कि इनपुट नमूनों में महत्वपूर्ण शब्दों के एम्बेडिंग को उनके पर्यायवाची शब्दों के एम्बेडिंग के औसत के साथ बदलने से डीएनएन-आधारित क्लासिफायरके सामान्यीकरण में काफी सुधार हो सकता है। ऐसा करने से, हम इनपुट नमूनों में विशेष शब्दों के लिए मॉडल संवेदनशीलता को कम करते हैं। हमारे परिणामों से संकेत मिलता है कि प्रस्तावित रक्षा न केवल प्रतिकूल हमलों के खिलाफ बचाव करने में सक्षम है, बल्कि सौम्य डेटा पर परीक्षण किए जाने पर डीएनएन-आधारित मॉडल के प्रदर्शन में सुधार करने में भी सक्षम है। औसतन, प्रस्तावित रक्षा ने सीएनएन और बी-एलएसटीएम मॉडल की वर्गीकरण सटीकता में क्रमशः 41.30% और 55.66% तक सुधार किया, जब प्रतिकूल हमलों के तहत परीक्षण किया गया। विस्तारित जांच से पता चलता है कि हमारी रक्षात्मक विधि गैर-तंत्रिका मॉडल की मजबूती में सुधार कर सकती है, 17.62% और 22.93% की औसत प्राप्त कर सकती है।
वर्गीकरण सटीकता क्रमशः SVM और XGBoost मॉडल पर वृद्धि. प्रस्तावित रक्षात्मक विधि ने कुख्यात BERT मॉडल के साथ परीक्षण किए जाने पर 26.60% वर्गीकरण सटीकता सुधार का औसत भी दिखाया है। हमारा एल्गोरिथ्म किसी भी एनएलपी डोमेन में और किसी भी प्राकृतिक भाषा पर प्रशिक्षित किसी भी मॉडल पर लागू होने के लिए पर्याप्त सामान्य है।</abstract_hi>
      <abstract_ga>Tá sé léirithe ag staidéir go bhfuil líonraí néaracha doimhne (DNNanna) i mbaol samplaí sáraíochta - ionchuir suaite a fhágann go mbíonn torthaí míchearta ag samhlacha DNN-bhunaithe. Ionsaí sáraíochta láidir amháin san fhearann NLP is ea an t-ionadú comhchiallach. In ionsaithe den éagsúlacht seo, ionadaíonn an namhaid focail le comhchiallaigh. Ós rud é go bhfuil sé mar aidhm ag suaitheadh ar ionadú comhchiallach gach srian foclóireachta, gramadaí agus séimeantach a shásamh, is deacair iad a bhrath le seiceáil comhréire uathoibríoch agus ag daoine freisin. Sa pháipéar seo, molaimid modh cosanta saor ó struchtúir atá in ann feidhmíocht samhlacha atá bunaithe ar DNN a fheabhsú le sonraí glan agus sáraíochta araon. Léiríonn ár dtorthaí gur féidir feabhas suntasach a chur ar ghinearálú na n-aicmitheoirí atá bunaithe ar DNN trí mheán leabaithe a gcomhchiallaigh a chur in ionad leabú na bhfocal tábhachtach sna samplaí ionchuir. Trí sin a dhéanamh, laghdaítear íogaireacht na samhla i leith focail ar leith sna samplaí ionchuir. Tugann ár dtorthaí le fios go bhfuil an chosaint atá beartaithe ní hamháin in ann cosaint a dhéanamh ar ionsaithe sáraíochta, ach go bhfuil sé in ann freisin feidhmíocht na samhlacha atá bunaithe ar DNN a fheabhsú nuair a dhéantar tástáil ar shonraí neamhurchóideacha. Ar an meán, d'fheabhsaigh an chosaint bheartaithe cruinneas aicmithe na samhlacha CNN agus Bi-LSTM 41.30% agus 55.66%, faoi seach, nuair a tástáladh faoi ionsaithe sáraíochta. Léiríonn imscrúdú leathnaithe gur féidir lenár modh cosanta feabhas a chur ar stóinseacht na múnlaí neamhneuracha, ag baint amach meán de 17.62% agus 22.93%
méadú ar chruinneas aicmithe ar na samhlacha SVM agus XGBoost, faoi seach. Tá sé léirithe ag an modh cosanta atá beartaithe freisin go raibh feabhas ar chruinneas aicmithe 26.60% ar an meán nuair a thástáiltear é leis an tsamhail BERT míchlúiteach. Tá ár n-algartam cineálach go leor le cur i bhfeidhm in aon fhearann NLP agus le haon mhúnla atá oilte ar aon teanga nádúrtha.</abstract_ga>
      <abstract_ka>SVM და XGBoost მოდელში კლასიფიკაციის წესიერება გაზრდება. პროგრამის შესაძლებელი გამოყენება ასევე 26.60% კლასიფიკაციის კონფიკაციის წარმოდგენება, როდესაც გამოცნობა ბერტის მოდელზე. ჩვენი ალგორიტიმ უფრო დინარიფური იქნება, რომელიც NLP დომინში და ყველა მოდელში, რომელიც მორცემულია ნებისმიერი ნაირადი ენაზე.</abstract_ka>
      <abstract_hu>Az SVM és XGBoost modellek osztályozási pontosságának növekedése. A javasolt védekezési módszer átlagosan 26,60%-os osztályozási pontosságot mutatott a hírhedt BERT modellel történő tesztelés során. Algoritmusunk elég általános ahhoz, hogy bármilyen NLP tartományban és bármilyen természetes nyelven képzett modellre alkalmazhassuk.</abstract_hu>
      <abstract_el>Αύξηση της ακρίβειας ταξινόμησης στα μοντέλα SVM και XGBoost αντίστοιχα. Η προτεινόμενη αμυντική μέθοδος έχει επίσης δείξει μια μέση βελτίωση της ακρίβειας ταξινόμησης 26,60% όταν δοκιμαστεί με το διαβόητο μοντέλο BERT. Ο αλγόριθμος μας είναι αρκετά γενικός ώστε να εφαρμοστεί σε οποιοδήποτε τομέα και σε οποιοδήποτε μοντέλο εκπαιδευμένο σε οποιαδήποτε φυσική γλώσσα.</abstract_el>
      <abstract_it>aumento della precisione di classificazione sui modelli SVM e XGBoost, rispettivamente. Il metodo difensivo proposto ha anche mostrato un miglioramento medio dell'accuratezza della classificazione del 26,60% se testato con il famigerato modello BERT. Il nostro algoritmo è abbastanza generico da essere applicato in qualsiasi dominio NLP e a qualsiasi modello addestrato su qualsiasi linguaggio naturale.</abstract_it>
      <abstract_ms>peningkatan ketepatan klasifikasi pada model SVM dan XGBoost, sama ada. Kaedah pertahanan yang diusulkan juga menunjukkan rata-rata 26.60% peningkatan ketepatan klasifikasi apabila diuji dengan model BERT yang terkenal. Algoritma kita cukup generik untuk dilaksanakan dalam mana-mana domain NLP dan kepada mana-mana model yang dilatih dalam mana-mana bahasa alam.</abstract_ms>
      <abstract_lt>SVM ir XGBoost modelių klasifikacijos tikslumo padidėjimas. Siūlomas gynybos metodas taip pat parodė 26,60 % klasifikacijos tikslumo pagerėjimą, kai bandoma naudojant žymią BERT model į. Mūsų algoritmas yra pakankamai generinis, kad jis būtų taikomas bet kurioje NLP srityse ir bet kuriam modeliui, mokomam bet kokia natūralia kalba.</abstract_lt>
      <abstract_ml>എസ്‌വിഎം, എക്സ്‌ജിബൂസ്റ്റ് മോഡലുകളിലും ക്ലാസ്ഫിക്കല്‍ ക്ലാസ്റ്റിഫിക്കല്‍ തെളിഞ്ഞിട്ടുണ പ്രൊദ്ദേശിക്കപ്പെട്ട പ്രതിരോധ രീതിയും 26.60% ക്ലാസ്ഫിക്കല്‍ കൃത്രിമ മ മെച്ചപ്പോള്‍ പരീക്ഷിക്കപ്പെട്ട ബെര്‍ട്ടി മ നമ്മുടെ ആല്‍ഗോരിതം സാധാരണ പ്രയോഗപ്പെടുത്താന്‍ പോകുന്നത് എംഎല്‍പി ഡൊമെയിനിലും സ്വാഭാവിക ഭാഷയില്‍ പഠിപ്പിക</abstract_ml>
      <abstract_mk>зголемување на точноста на класификацијата на моделите SVM и XGBoost, односно. Предложениот одбранбен метод, исто така, покажа просечно подобрување на прецизноста на класификацијата од 26,60 отсто кога се тестира со познатиот модел БЕРТ. Нашиот алгоритм е доволно генеричен за да се примени во било кој домен на НЛП и во било кој модел обучен на било кој природен јазик.</abstract_mk>
      <abstract_kk>SVM және XGBoost үлгілерінде классификациялық дұрыстығын өзгерту. Келтірілген қорғау әдісі сондай-ақ BERT үлгісімен тексергенде орташа 26,60% классификациялық дұрыстығын жақсарту көрсетілді. Алгоритміз NLP доменінде және кез-келген табиғи тілде оқылған кез-келген үлгі үлгілеріне қолданылатын жалпы.</abstract_kk>
      <abstract_mn>SVM болон XGBoost загварын тодорхойлолт нь нэмэгддэг. Өөрчлөлтийн хамгаалах арга нь мөн хэмжээний БЕРТ загвартай шалгаж буй үед дундаж 26.60% хувь хуваалцааны тодорхойлолтын тодорхойлолтыг харуулсан байна. Бидний алгоритм нь ямар ч NLP холбоонд, ямар ч байгалийн хэл дээр сургалтын загварт хэрэглэгдэхэд хангалттай ерөнхий хэлбэртэй.</abstract_mn>
      <abstract_pl>Zwiększenie dokładności klasyfikacji odpowiednio w modelach SVM i XGBoost. Proponowana metoda obronna wykazała również średnią poprawę dokładności klasyfikacji 26,60% podczas testowania z niesławnym modelem BERT. Nasz algorytm jest wystarczająco ogólny, aby być stosowany w dowolnej domenie NLP i w każdym modelu przeszkolonym na dowolnym języku naturalnym.</abstract_pl>
      <abstract_ro>creșterea preciziei clasificării pe modelele SVM și, respectiv, XGBoost. Metoda defensivă propusă a arătat, de asemenea, o îmbunătățire medie de 26,60% a preciziei clasificării atunci când a fost testată cu infamul model BERT. Algoritmul nostru este suficient de generic pentru a fi aplicat în orice domeniu NLP și oricărui model instruit pe orice limbă naturală.</abstract_ro>
      <abstract_mt>żieda fil-preċiżjoni tal-klassifikazzjoni fuq il-mudelli SVM u XGBoost, rispettivament. Il-metodu difensiv propost wera wkoll medja ta’ titjib fil-preċiżjoni tal-klassifikazzjoni ta’ 26.60% meta ttestjat bil-mudell magħruf BERT. L-algoritmu tagħna huwa ġeneriku biżżejjed biex jiġi applikat fi kwalunkwe qasam NLP u għal kwalunkwe mudell imħarreġ fuq kwalunkwe lingwa naturali.</abstract_mt>
      <abstract_no>øk klassifikasjons akkurat på SVM- og XGBoost- modellen, respectivt. Den foreslåde defensivmetoden har også vist gjennomsnittlig forbedring av klassifikasjonsnøyaktighet på 26,60 % når testet er med den infamous BERT-modellen. Algoritmen vårt er generelt nok for å bruka i alle NLP- domene og i alle modelane som treng på alle naturspråk.</abstract_no>
      <abstract_so>Tilmaamaha SVM iyo XGBoost waxaa ku kordhiya fasax rasmi ah. Midabka defence ee la soo jeeday wuxuu sidoo kale tusay abbaaraha 26.60% oo fasax kordhin koritaanka saxda ah marka lagu imtixaamo modelka BERT ee la yaqaan. Algoritnagu waa wax caadi ah oo ku filan in lagu codsado deegaan kasta oo NLP ah iyo tusaale kasta oo lagu baro luqad dabiiciga ah.</abstract_so>
      <abstract_sv>Klassificeringsnoggrannheten ökar på SVM- respektive XGBoost-modellerna. Den föreslagna defensiva metoden har också visat en genomsnittlig förbättring av klassificeringsnoggrannheten på 26,60% när den testas med den ökända BERT-modellen. Vår algoritm är tillräckligt generisk för att användas i alla NLP-domäner och för alla modeller som är utbildade på något naturligt språk.</abstract_sv>
      <abstract_sr>povećanje točnosti klasifikacije na modele SVM i XGBoost, odnosno. Predložena odbrambena metoda je takođe pokazala prosječno poboljšanje tačnosti klasifikacije 26,60% kada se testira sa nepoznatim BERT modelom. Naš algoritam je dovoljno generičan da se primjenjuje u bilo kojem domenu NLP-a i na bilo koji model obučen na bilo kojem prirodnom jeziku.</abstract_sr>
      <abstract_si>@ info: whatsthis පරීක්ෂණය කරන්න පුළුවන් ආරක්ෂා විධානය පෙන්වන්න පුළුවන් විධානයක් 26.60% විශේෂණ විශේෂණය සමාන්‍ය විශ අපේ ඇල්ගෝරිතම් සාමාන්‍ය භාෂාවට ඇතුලත් ඇති NLP ඩෝමින් වලට ඇතුලත් වෙන්න පුළුවන් ඇති.</abstract_si>
      <abstract_ta>SVM மற்றும் XGBoost மாதிரிகளில் வகுப்பு சரியான திட்டம் அதிகரிக்கும். பரிந்துரைக்கப்பட்ட பிரெட் மாதிரியால் சராசரி 26.60% வகுப்பு சரியான மேம்படுத்தலை காட்டியுள்ளது. எங்கள் ஆல்gorithm பொதுவான போதுமானது எந்த NLP தளத்திலும் எந்த இயற்கை மொழியிலும் பயிற்சிக்கப்பட்ட மாதிரி</abstract_ta>
      <abstract_ur>SVM اور XGBoost موڈلوں پر کلاسپیٹ دقیق اضافہ ہوتا ہے۔ پیغمبر کی محافظت طریقہ نے 26.60% کلاسپیٹ کی دقیقیت کے متوسط سفارش کو بھی دکھایا ہے جب کمزور BERT موڈل کے ساتھ آزمائش کی جاتی ہے۔ ہمارا الگوریٹم ہر NLP ڈومین میں اور ہر طبیعی زبان پر آموزش کی مدل پر کافی عمدہ ہے۔</abstract_ur>
      <abstract_uz>@ info: whatsthis Name Bizning algoritmiz - NLP domenni qo'llashga yetarli narsa va tabiiy tilda ta'minlovchi modelga.</abstract_uz>
      <abstract_vi>Độ chính xác phân loại tăng liên quan đến mẫu SVM và XGBust. Cách phòng thủ đề nghị cũng cho thấy mức độ chính xác trung bình 26.60 khi được thử nghiệm với mô hình BERT nổi tiếng. Thuật to án của chúng tôi đủ đa dạng để được áp dụng trong bất kỳ miền Njala hay bất cứ mẫu nào được đào tạo trên bất kỳ ngôn ngữ tự nhiên.</abstract_vi>
      <abstract_bg>повишаване на точността на класификацията при моделите съответно SVM и XGBoost. Предложеният отбранителен метод също показва средно 26,60% подобрение на точността на класификацията при тестване с скандалния модел. Нашият алгоритъм е достатъчно генеричен, за да се прилага във всяка област на НЛП и във всеки модел, обучен на всеки естествен език.</abstract_bg>
      <abstract_hr>povećanje točnosti klasifikacije na modele SVM i XGBoost, odnosno. Predložena odbrambena metoda također pokazala je prosječan poboljšanje točnosti klasifikacije 26,60% kada se testira s nepoznatim BERT modelom. Naš algoritam je dovoljno generičan da se primjenjuje u bilo kojem domenu NLP-a i na bilo koji model obučen na bilo kojem prirodnom jeziku.</abstract_hr>
      <abstract_nl>De classificatienauwkeurigheid wordt verhoogd op respectievelijk de SVM- en XGBoost-modellen. De voorgestelde defensieve methode heeft ook een gemiddelde verbetering van 26,60% classificatie nauwkeurigheid aangetoond wanneer getest met het beruchte BERT model. Ons algoritme is generiek genoeg om toegepast te worden in elk NLP domein en op elk model getraind op elke natuurlijke taal.</abstract_nl>
      <abstract_de>Zunahme der Klassifikationsgenauigkeit bei den Modellen SVM und XGBoost. Die vorgeschlagene defensive Methode hat auch eine durchschnittliche Verbesserung der Klassifikationsgenauigkeit von 26,60% gezeigt, wenn sie mit dem berüchtigten BERT-Modell getestet wurde. Unser Algorithmus ist generisch genug, um in jeder NLP-Domäne und auf jedem Modell angewendet zu werden, das auf jeder natürlichen Sprache trainiert ist.</abstract_de>
      <abstract_da>klassificeringsnøjagtighed stigning på henholdsvis SVM- og XGBoost-modellerne. Den foreslåede defensive metode har også vist en gennemsnitlig forbedring af klassificeringsnøjagtigheden på 26,60%, når den testes med den berygtede BERT-model. Vores algoritme er generisk nok til at blive anvendt i ethvert NLP domæne og til enhver model trænet i ethvert naturligt sprog.</abstract_da>
      <abstract_fa>دقیقات classification increase on the SVM and XGBoost models respectively. این روش دفاع پیشنهاد همچنین در حالی که با مدل بدبخت BERT آزمایش می‌شود، در میانگین دفاع دفاع دفاع ۲۶.۶۰ درصد را نشان داده است. الگوریتم ما به اندازه کافی معمولی است که در هر دامنی NLP و به هر مدل که روی هر زبان طبیعی آموزش داده شده است.</abstract_fa>
      <abstract_id>peningkatan akurasi klasifikasi pada model SVM dan XGBoost, respektif. Metode pertahanan yang diusulkan juga menunjukkan rata-rata dari 26,60% peningkatan akurasi klasifikasi ketika diuji dengan model BERT terkenal. Algoritma kita cukup generik untuk dipakai dalam domain NLP apapun dan pada model apapun yang dilatih dalam bahasa alami apapun.</abstract_id>
      <abstract_ko>SVM과 XGBoost 모델의 분류 정밀도가 각각 향상되었습니다.악명 높은 베르토 모형을 사용하여 테스트를 진행할 때 제시된 방어 방법도 평균 26.60%의 분류 정밀도가 높아진 것으로 나타났다.우리의 알고리즘은 모든 NLP 분야와 자연 언어 훈련의 모델에 적용될 수 있는 충분한 통용성을 가지고 있다.</abstract_ko>
      <abstract_tr>Sınıfta derejesi SVM we XGBoost nusgalarynda artýar. Önerlenen savunmasyn yöntemi hem 26.60% klasifikasyň derejesi ýüze bardygynda test edilen BERT nusga bilen ortalamasyny görkezildi. Biziň algoritmimiz NLP domaýynda we her täbiň dilinde bilinmeli bir nusga ýeterlik ýagdaýdyr.</abstract_tr>
      <abstract_sw>kuongezeka kwa uhakika wa usawa katika mifano ya SVM na XGBoost, kwa namna fulani. Utawala wa ulinzi unapendekezwa pia umeonyesha wastani wa asilimia 26.60 ya kutangaza maendeleo ya sahihi pale yalipojaribiwa kwa mtindo maarufu wa BERT. Ualgorithi wetu ni wa kawaida wa kutosha kutumika katika maeneo yoyote ya NLP na kwa mtindo wowote wa mafunzo katika lugha yoyote ya asili.</abstract_sw>
      <abstract_af>klasifikasie-presies vergroot op die SVM en XGBoost-modele, respektief. Die voorgestelde verdedingsmetode het ook 'n gemiddelde van 26. 60% klassifikasie presies verbetering vertoon wanneer deur die verstandige BERT model te testeer. Ons algoritme is generiek genoeg om in enige NLP domein te gebruik en aan enige model wat op enige natuurlike taal opgelei word.</abstract_af>
      <abstract_am>የኩነቶች መረጃዎች የተዘጋጀው የጠበቀ ሥርዓት በተፈተናው ጊዜ የBERT ሞዴል በተፈተና ጊዜ በቁጥጥር 26.60 በመቶ ክፍተቱን የሚያሳየው፡፡ አሌጎራይማችን በNLP ዶሜን እና በአካባቢው ቋንቋ ማንኛውም ሞዴል ለመጠቀም ይበቃል፡፡</abstract_am>
      <abstract_sq>rritja e saktësisë së klasifikimit në modelet SVM dhe XGBoost respektivisht. Metoda e propozuar mbrojtëse ka treguar gjithashtu një përmirësim mesatar prej 26.60% të saktësisë së klasifikimit kur është testuar me modelin e famshëm BERT. Algoritmi ynë është mjaft gjenerik për t'u aplikuar në çdo domeni NLP dhe në çdo model të trajnuar në çdo gjuhë natyrore.</abstract_sq>
      <abstract_hy>դասակարգման ճշգրիտության աճը համեմատաբար ՎԻՄ-ի և XԳԲուստ-ի մոդելների վրա: Պատրաստված պաշտպանական մեթոդը ցույց է տալիս նաև 26.60 տոկոսի միջին դասակարգման ճշգրտության բարելավումը, երբ փորձարկվում է հայտնի BER մոդելի օգնությամբ: Մեր ալգորիթմը բավականաչափ ընդհանուր է, որպեսզի կիրառվի ցանկացած ՆԼՊ ոլորտում և ցանկացած բնական լեզվի վրա վարժեցված մոդելի վրա:</abstract_hy>
      <abstract_az>SVM və XGBoost modellərində klasifikasiya doğruluğu artır. Bu təbliğ edilən müdafiə metodu, həmçinin sınaqlarında BERT modeli ilə imtahana çəkildikdə ortalama 26,60% klasifikasiya doğruluğunun düzəltməsini göstərdi. Algoritimiz hər NLP domeində və hər təbiətli dildə təhsil edilən modellərə kifayət qədər generikdir.</abstract_az>
      <abstract_bn>SVM এবং XGBoost মডেলগুলোতে শ্রেণীকরণের সঠিকভাবে বৃদ্ধি করা হয়েছে। প্রস্তাবিত প্রতিরক্ষার পদ্ধতি ২৬. আমাদের অ্যালগরিদম এনএলপি ডোমেইনে প্রয়োগ করার জন্য যথেষ্ট সৌন্দর্য এবং প্রাকৃতিক ভাষায় যে কোন মডেল প্রশিক্ষণ করা হয় ত</abstract_bn>
      <abstract_et>Klassifikatsioonitäpsus suureneb vastavalt SVM ja XGBoost mudelitel. Kavandatud kaitsemeetod on näidanud ka keskmiselt 26,60% klassifikatsioonitäpsuse paranemist kurikuulsa BERT mudeliga testimisel. Meie algoritm on piisavalt üldine, et seda rakendada mis tahes NLP domeenis ja mis tahes mudelile, mis on koolitatud mis tahes looduskeeles.</abstract_et>
      <abstract_ca>augmenta la precisió de classificació dels models SVM i XGBoost, respectivament. El mètode defensiu proposat també ha demostrat una mitjana de 26,60% de millora de la precisió de la classificació quan s'ha provat amb el famós model BERT. El nostre algoritme és prou genèric per aplicar-se en qualsevol domini NLP i en qualsevol model entrenat en qualsevol llenguatge natural.</abstract_ca>
      <abstract_bs>povećanje točnosti klasifikacije na modele SVM i XGBoost, odnosno. Predložena odbrambena metoda je također pokazala prosječan poboljšanje tačnosti klasifikacije 26,60% kada je testirano s nepoznatim BERT modelom. Naš algoritam je dovoljno generičan da se primjenjuje u bilo kojem domenu NLP-a i na bilo koji model obučen na bilo kojem prirodnom jeziku.</abstract_bs>
      <abstract_cs>Zvýšení přesnosti klasifikace u modelů SVM a XGBoost. Navržená obranná metoda rovněž prokázala průměrné zlepšení přesnosti klasifikace 26,60% při testování s nechvalně proslulým modelem BERT. Náš algoritmus je dostatečně obecný, aby byl aplikován v jakékoliv NLP doméně a na jakýkoliv model trénovaný na libovolném přirozeném jazyce.</abstract_cs>
      <abstract_fi>SVM- ja XGBoost-malleissa luokitustarkkuus paranee. Ehdotettu puolustusmenetelmä on myös osoittanut keskimääräisen 26,60%:n parannuksen luokituksen tarkkuudelle, kun sitä on testattu pahamaineisella BERT-mallilla. Algoritmimme on riittävän yleinen käytettäväksi missä tahansa NLP-alueella ja missä tahansa luonnollisella kielellä koulutetussa mallissa.</abstract_fi>
      <abstract_he>מחקרים הראו כי רשתות עצביות עמוקות (DNN) פגיעות לדוגמאות נוגדיות – כניסות מופרעות שגורמות לדוגמאות מבוססות על DNN לייצר תוצאות לא נכונות. התקפה יריבית חזקה אחת בתחום NLP היא ההחלפה הסינונימית. In attacks of this variety, the adversary substitutes words with synonyms.  Since synonym substitution perturbations aim to satisfy all lexical, grammatical, and semantic constraints, they are difficult to detect with automatic syntax check as well as by humans.  בעיתון הזה, אנו מציעים שיטה הגנה ללא מבנה שיכולה לשפר את ההופעה של דוגמנים מבוססים בדנ.אן.אן עם נתונים נקיים ויריבים. הממצאים שלנו מראים שהתחליף של המילים החשובות בדגימות הכניסה עם הממוצע של ההתחליפות של הסינונימים שלהם יכול לשפר באופן משמעותי את הגנרליזציה של מסמכים מבוססים על DNN. על ידי כך, אנחנו מפחידים את רגישות המודל למילים מסויימות בדגימות הכניסה. התוצאות שלנו מצביעות שההגנה המוצעת לא רק מסוגלת להגן נגד תקיפות יריבות, אלא גם מסוגלת לשפר את ההפעלה של דוגמנים מבוססים בדנ"א כשנבחנים על נתונים טובים. בממוצע, ההגנה המוצעת שידרה את מדויקת הסיווג של דוגמני CNN ובי-LSTM ב-41.30% ו-55.66%, בהתאם, כאשר ניסו תחת התקפים יריביים. חקירה מורחבת מראה ששיטת ההגנה שלנו יכולה לשפר את החזקה של דוגמנים לא עצביים, להשיג ממוצע של 17.62% ו-22.93%
הגידול בדיקת הסווג על דוגמנים SVM ו XGBoost, בהתאם. שיטת ההגנה המוצעת הראה גם ממוצע של 26.60% שיפור מדויק מסווג כאשר נבחן עם מודל BERT המפורסם. האלגוריתם שלנו הוא מספיק גנרני כדי שימשיך בכל תחום NLP וכל מודל מאומן על כל שפה טבעית.</abstract_he>
      <abstract_jv>Iwurung wis nambah karo hal-hal nganggep didalat seneng pisan Neral One bot hostary effect in the NLP domain is the sinanym replaced. Nanging panganan karo perkara-perkara iki, pakan-pakan iki bakal terusah pawaran karo sinanan. Taning Nang kuwi iki, kita supoyo sistem-perusahaan uwis wis dianggap banjure nggawe barang nggawe modèl dadi DNN sing basa dadi wis dianggap karo perusahaan karo perusahaan karo paké. Find and find out that Ngawe Perintah pengguna perusahaan Sensitif kanggo Kemerdekaan kuwi model nang sampulan input Rejalaké awak dhéwé ngerngerti barang nggawe aturan aturan dipunangé ora iso ngubah perusahaan winih kanggo atak omongé, macem iso ngubah dhéwé ngerasakno perusahaan model sing isiné DNN-usul kanggo bisa teka data bendhuwur. Tanggal, supoyo nggunakake perusahaan kanggo ngerasakno dadi angan kelas nang dadi MT karo model bi-LTT, gawe lan 10.30% lan 5.6%, mengko iso disenyakake sak pangan negoro atake opo-terasi. Awakdhéwé éntuk perusahaan anyar tentang dipunangé awak dhéwé iso nggawe barang nggawe model sing gak ngéwé, sampeyan ngono kalaayéh sabên tanggal 18.00% lan 22.9%
--strikethrough Wis Algorithm dhéwé bukane kadaterangan tanggal kanggo aplikasi ning sakjane NLP lan sakjane model sing ditambah ning saben lenggal pribadi.</abstract_jv>
      <abstract_bo>Studies have shown that deep neural networks (DNNs) are vulnerable to adversarial examples – perturbed inputs that cause DNN-based models to produce incorrect results. NLP domain ནང་དུ་སྤྱི་ཚོགས་པའི་གནད་དོན་ཡུལ་གྱི་འགའ་བ་གཅིག་ནི་synonym substitution རེད། གདོང་རིས་འདིའི་དབྱེ་བ་ནང་གི་བརྗོད་མཁན་གྱི་གཞས་ཚིག་དང་འདྲ་མི་མཚོན་པ་ཚོ་ཚབ་བཅུག་གི་ཡོད། Since synonym substitution perturbations aim to satisfy all lexical, grammatical, and semantic constraints, they are difficult to detect with automatic syntax check as well as by humans. འུ་ཅག་གིས་ཤོག་བྱང་འདིའི་ནང་དུ་རང་དབང་གི་སྒྲིག་འགོད་མིན་ཐང་བའི་ཐབས་ལམ་ཞིག་སྔར་སྤྲོད་ཡོད། དེ་ནི་DNN གཙང་དག་དང་གདོང་ཉེ ང་ཚོའི་findings show that replacing the embeddings of the important words in the input samples with the average of their synonyms' embeddings can significantly improve the generalization of DNN-based classifiers. བྱས་ཙང་བྱས་ན་འོད་ཀྱིས་དབྱིབས་མཐུན་རྐྱེན་བྱས་པར་ངེས་པར་དབྱིབས་ ང་ཚོའི་འབྲུག སྤྱིར་བཏང་བའི་ཉེན་ཁ་བརྗོད་ཀྱིས་རྒྱབ་སྐྱོར་གྱི་དབྱིབས་ཆོས་ཉིད་དེ་གོང་ཡར་རྒྱས་གཏོང་། extended investigation shows that our defensive method can improve the robustness of non-neural models, achieving an average of 17.62% and 22.93%
SVM དང་XGBoost མིག་དཔེ་དབྱིབས་བདེ་སྟངས་ལ་ཆེ་རུ་གཏོང་བ། དམིགས་འཛུགས་ཀྱི་སྲུང་སྐྱོབ་ཐབས་ལམ་ལ་ཞིབ་པས་(BERT)མིག་དཔྱད་དང་བརྟག ང་ཚོའི་སྒྲིག་སྟངས་རྒྱལ་ཁབ་ཡིན་ན་NLP domain་གང་རུང་ནང་དུ་སྤྱོད་བཏང་ན་ཕན་འབྲས་ཡོད་པ</abstract_bo>
      <abstract_ha>Haƙĩƙa, akadi sun nuna cewa zanen tarakin neural (DNNs) sun kasance masu haske a kan misãlai masu motsi - perturated inputi da ke saba da misãlai na DNN-da za'a zartar da matsalan makosa. Babu wani shawarar motsi da aka yi kuskure a cikin NLP's Domen na musanya sunonim. Daga shawarar wannan daban, mai motsi yana musanya magana da sunonim. Tana da musanya surori na synonim don ya yi nufin ya cika duk taurãri, grammati da kuma na sakanti, sai ya yi nau'i a gane su da checkin kowace farat ɗaya da kuma mutum. Ga wannan takardan, Munã buɗa wata shirin tsari wanda ba ta koma ba da komai ba, wanda yana iya iya ƙaranci cikakken misãlai-danne-danne na DNN da duk masu tsari da motsi. FayiyinMu na nuna cewa musanya masu muhimma cikin misãlai da aka shigar a cikin shirin ayuka, yana iya ƙaranci ƙidãya da suka samu'anta na sammakon da suka samu'anta. Kayya, ko da haka, za mu ƙara masu saniya ga misãlai da ke cikin shirin ayuka. Our results indicate that the proposed defense is not only capable of defending against adversarial attacks, but is also capable of improving the performance of DNN-based models when tested on benign data.  Gansa da kamma, tsarin da aka gozartar da shi, ya improve tsari ga sifilafin na CNN da Bi-LSM da shekara 41.30% da 55.66%, a lokacin da aka jarraba wajen aikin bayani. Ana nuna cewa, hanyoyinmu na tsari yana iya ƙara tufãfin misalin misalin na'ura, kuma yana sãmu a tsakanin 17,65% da 22,93
QScriptBreakpointsModel Tsarin tsari da aka rufe shi, ya nuna mai tsakanin daraja na 26,60% sifikanci da aka jarraba shi da misalin BERT. Algorityinmu yana da kawaici wanda za'a amfani da shi cikin duk wuyan NLP da zuwa wani misali wanda aka sanar da shi kan wani harshe na asili.</abstract_ha>
      <abstract_sk>Študije so pokazale, da so globoka nevronska omrežja (DNN) občutljiva na kontradikcijske primere – motene vhode, ki povzročajo, da modeli, ki temeljijo na DNN, proizvajajo napačne rezultate. En robustni kontradikcijski napad v domeni NLP je sinonimska nadomestitev. V napadih te sorte nasprotnik nadomesti besede s sinonimi. Ker je namen motenj zamenjave sinonimov zadovoljiti vse leksikalne, slovnične in semantične omejitve, jih je težko zaznati s samodejnim preverjanjem sintakse in tudi s strani ljudi. V prispevku predlagamo obrambno metodo brez strukture, ki je sposobna izboljšati zmogljivost modelov, ki temeljijo na DNN, tako s čistimi kot kontrastnimi podatki. Naše ugotovitve kažejo, da lahko zamenjava vdelav pomembnih besed v vhodnih vzorcih s povprečjem vdelav njihovih sinonimov bistveno izboljša generalizacijo klasifikatorjev na osnovi DNN. S tem zmanjšamo občutljivost modela na določene besede v vhodnih vzorcih. Naši rezultati kažejo, da predlagana obramba ni sposobna samo braniti pred kontradikcijskimi napadi, temveč je sposobna tudi izboljšati učinkovitost modelov, ki temeljijo na DNN, pri testiranju na benignih podatkih. Predlagana obramba je v povprečju izboljšala klasifikacijsko natančnost modelov CNN in Bi-LSTM za 41,30% oziroma 55,66%, ko je bila testirana pod kontrastnimi napadi. Razširjena raziskava kaže, da lahko naša obrambna metoda izboljša robustnost nevronskih modelov in doseže povprečno 17,62% in 22,93%.
Povečanje natančnosti klasifikacije pri modelih SVM oziroma XGBoost. Predlagana obrambna metoda je pokazala tudi povprečno 26,60% izboljšanje natančnosti klasifikacije pri testiranju z zloglasnim BERT modelom. Naš algoritem je dovolj generičen za uporabo v kateri koli domeni NLP in v katerem koli modelu, usposobljenem za kateri koli naravni jezik.</abstract_sk>
      </paper>
    </volume>
</collection>