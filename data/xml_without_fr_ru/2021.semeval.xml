<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.semeval">
  <volume id="1" ingest-date="2021-07-25">
    <meta>
      <booktitle>Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)</booktitle>
      <editor><first>Alexis</first><last>Palmer</last></editor>
      <editor><first>Nathan</first><last>Schneider</last></editor>
      <editor><first>Natalie</first><last>Schluter</last></editor>
      <editor><first>Guy</first><last>Emerson</last></editor>
      <editor><first>Aurelie</first><last>Herbelot</last></editor>
      <editor><first>Xiaodan</first><last>Zhu</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>August</month>
      <year>2021</year>
      <url hash="01d5d604">2021.semeval-1</url>
    </meta>
    <frontmatter>
      <url hash="404ba67b">2021.semeval-1.0</url>
      <bibkey>semeval-2021-international</bibkey>
    </frontmatter>
    <paper id="1">
      <title>SemEval-2021 Task 1 : Lexical Complexity Prediction<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 1: Lexical Complexity Prediction</title>
      <author><first>Matthew</first><last>Shardlow</last></author>
      <author><first>Richard</first><last>Evans</last></author>
      <author><first>Gustavo Henrique</first><last>Paetzold</last></author>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <pages>1–16</pages>
      <abstract>This paper presents the results and main findings of SemEval-2021 Task 1-Lexical Complexity Prediction. We provided participants with an augmented version of the CompLex Corpus (Shardlow et al. CompLex is an English multi-domain corpus in which words and multi-word expressions (MWEs) were annotated with respect to their complexity using a five point Likert scale. SemEval-2021 Task 1 featured two Sub-tasks : Sub-task 1 focused on single words and Sub-task 2 focused on MWEs. The competition attracted 198 teams in total, of which 54 teams submitted official runs on the test data to <a href="https://en.wikipedia.org/wiki/Task_(computing)">Sub-task 1</a> and 37 to <a href="https://en.wikipedia.org/wiki/Task_(computing)">Sub-task 2</a>.</abstract>
      <url hash="026e0c42">2021.semeval-1.1</url>
      <doi>10.18653/v1/2021.semeval-1.1</doi>
      <bibkey>shardlow-etal-2021-semeval</bibkey>
    </paper>
    <paper id="7">
      <title>SemEval-2021 Task 6 : Detection of Persuasion Techniques in Texts and Images<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 6: Detection of Persuasion Techniques in Texts and Images</title>
      <author><first>Dimitar</first><last>Dimitrov</last></author>
      <author><first>Bishr</first><last>Bin Ali</last></author>
      <author><first>Shaden</first><last>Shaar</last></author>
      <author><first>Firoj</first><last>Alam</last></author>
      <author><first>Fabrizio</first><last>Silvestri</last></author>
      <author><first>Hamed</first><last>Firooz</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <author><first>Giovanni</first><last>Da San Martino</last></author>
      <pages>70–98</pages>
      <abstract>We describe SemEval-2021 task 6 on Detection of Persuasion Techniques in Texts and Images : the data, the annotation guidelines, the evaluation setup, the results, and the participating systems. The task focused on <a href="https://en.wikipedia.org/wiki/Meme">memes</a> and had three subtasks : (i) detecting the techniques in the <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">text</a>, (ii) detecting the text spans where the techniques are used, and (iii) detecting techniques in the entire meme, i.e., both in the text and in the image. It was a popular <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, attracting 71 registrations, and 22 teams that eventually made an official submission on the test set. The evaluation results for the third subtask confirmed the importance of both <a href="https://en.wikipedia.org/wiki/Modality_(semiotics)">modalities</a>, the <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">text</a> and the image. Moreover, some teams reported benefits when not just combining the two modalities, e.g., by using early or late fusion, but rather modeling the interaction between them in a joint model.</abstract>
      <url hash="7fb48942">2021.semeval-1.7</url>
      <doi>10.18653/v1/2021.semeval-1.7</doi>
      <bibkey>dimitrov-etal-2021-semeval</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hateful-memes">Hateful Memes</pwcdataset>
    </paper>
    <paper id="8">
      <title>Alpha at SemEval-2021 Task 6 : Transformer Based Propaganda Classification<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 6: Transformer Based Propaganda Classification</title>
      <author><first>Zhida</first><last>Feng</last></author>
      <author><first>Jiji</first><last>Tang</last></author>
      <author><first>Jiaxiang</first><last>Liu</last></author>
      <author><first>Weichong</first><last>Yin</last></author>
      <author><first>Shikun</first><last>Feng</last></author>
      <author><first>Yu</first><last>Sun</last></author>
      <author><first>Li</first><last>Chen</last></author>
      <pages>99–104</pages>
      <abstract>This paper describes our system participated in Task 6 of SemEval-2021 : the task focuses on multimodal propaganda technique classification and it aims to classify given image and text into 22 classes. In this paper, we propose to use transformer based architecture to fuse the clues from both image and text. We explore two branches of techniques including fine-tuning the text pretrained transformer with extended visual features, and fine-tuning the multimodal pretrained transformers. For the visual features, we have tested both grid features based on <a href="https://en.wikipedia.org/wiki/ResNet">ResNet</a> and salient region features from pretrained object detector. Among the pretrained multimodal transformers, we choose ERNIE-ViL, a two-steam cross-attended transformers pretrained on large scale image-caption aligned data. Fine-tuing ERNIE-ViL for our task produce a better performance due to general joint multimodal representation for <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">text</a> and image learned by ERNIE-ViL. Besides, as the distribution of the classification labels is very unbalanced, we also make a further attempt on the <a href="https://en.wikipedia.org/wiki/Loss_function">loss function</a> and the experiment result shows that focal loss would perform better than cross entropy loss. Last we have won first for subtask C in the final competition.</abstract>
      <url hash="a6f72adf">2021.semeval-1.8</url>
      <doi>10.18653/v1/2021.semeval-1.8</doi>
      <bibkey>feng-etal-2021-alpha</bibkey>
    </paper>
    <paper id="9">
      <title>SemEval 2021 Task 7 : HaHackathon, Detecting and Rating Humor and Offense<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val 2021 Task 7: <fixed-case>H</fixed-case>a<fixed-case>H</fixed-case>ackathon, Detecting and Rating Humor and Offense</title>
      <author><first>J. A.</first><last>Meaney</last></author>
      <author><first>Steven</first><last>Wilson</last></author>
      <author><first>Luis</first><last>Chiruzzo</last></author>
      <author><first>Adam</first><last>Lopez</last></author>
      <author><first>Walid</first><last>Magdy</last></author>
      <pages>105–119</pages>
      <abstract>SemEval 2021 Task 7, HaHackathon, was the first shared task to combine the previously separate domains of humor detection and offense detection. We collected 10,000 texts from <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> and the Kaggle Short Jokes dataset, and had each annotated for humor and offense by 20 annotators aged 18-70. Our subtasks were binary humor detection, prediction of humor and offense ratings, and a novel controversy task : to predict if the variance in the humor ratings was higher than a specific threshold. The subtasks attracted 36-58 submissions, with most of the participants choosing to use pre-trained language models. Many of the highest performing teams also implemented additional optimization techniques, including task-adaptive training and adversarial training. The results suggest that the participating <a href="https://en.wikipedia.org/wiki/System">systems</a> are well suited to humor detection, but that humor controversy is a more challenging task. We discuss which <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> excel in this task, which auxiliary techniques boost their performance, and analyze the errors which were not captured by the best <a href="https://en.wikipedia.org/wiki/System">systems</a>.</abstract>
      <url hash="4c2e27ab">2021.semeval-1.9</url>
      <doi>10.18653/v1/2021.semeval-1.9</doi>
      <bibkey>meaney-etal-2021-semeval</bibkey>
    </paper>
    <paper id="11">
      <title>Complex words identification using word-level features for SemEval-2020 Task 1<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 1</title>
      <author><first>Jenny A.</first><last>Ortiz-Zambrano</last></author>
      <author><first>Arturo</first><last>Montejo-Ráez</last></author>
      <pages>126–129</pages>
      <abstract>This article describes a system to predict the complexity of words for the Lexical Complexity Prediction (LCP) shared task hosted at SemEval 2021 (Task 1) with a new annotated English dataset with a <a href="https://en.wikipedia.org/wiki/Likert_scale">Likert scale</a>. Located in the Lexical Semantics track, the task consisted of predicting the complexity value of the words in context. A machine learning approach was carried out based on the frequency of the words and several characteristics added at word level. Over these <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>, a supervised random forest regression algorithm was trained. Several runs were performed with different values to observe the performance of the <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a>. For the <a href="https://en.wikipedia.org/wiki/Evaluation">evaluation</a>, our best results reported a M.A.E score of 0.07347, M.S.E. of 0.00938, and R.M.S.E. of 0.096871. Our experiments showed that, with a greater number of <a href="https://en.wikipedia.org/wiki/Phenotypic_trait">characteristics</a>, the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a> of the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> increases.</abstract>
      <url hash="d0b886d4">2021.semeval-1.11</url>
      <doi>10.18653/v1/2021.semeval-1.11</doi>
      <bibkey>ortiz-zambrano-montejo-raez-2021-complex</bibkey>
    </paper>
    <paper id="15">
      <title>Uppsala NLP at SemEval-2021 Task 2 : Multilingual Language Models for Fine-tuning and Feature Extraction in Word-in-Context Disambiguation<fixed-case>U</fixed-case>ppsala <fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 2: Multilingual Language Models for Fine-tuning and Feature Extraction in Word-in-Context Disambiguation</title>
      <author><first>Huiling</first><last>You</last></author>
      <author><first>Xingran</first><last>Zhu</last></author>
      <author><first>Sara</first><last>Stymne</last></author>
      <pages>150–156</pages>
      <abstract>We describe the Uppsala NLP submission to SemEval-2021 Task 2 on multilingual and cross-lingual word-in-context disambiguation. We explore the usefulness of three pre-trained multilingual language models, XLM-RoBERTa (XLMR), Multilingual BERT (mBERT) and multilingual distilled BERT (mDistilBERT). We compare these three <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> in two setups, <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a> and as <a href="https://en.wikipedia.org/wiki/Software_feature">feature extractors</a>. In the second case we also experiment with using dependency-based information. We find that <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a> is better than <a href="https://en.wikipedia.org/wiki/Feature_extraction">feature extraction</a>. XLMR performs better than mBERT in the cross-lingual setting both with <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a> and <a href="https://en.wikipedia.org/wiki/Feature_extraction">feature extraction</a>, whereas these two models give a similar performance in the multilingual setting. mDistilBERT performs poorly with <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a> but gives similar results to the other <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> when used as a feature extractor. We submitted our two best <a href="https://en.wikipedia.org/wiki/System">systems</a>, fine-tuned with XLMR and mBERT.</abstract>
      <url hash="b663aee7">2021.semeval-1.15</url>
      <doi>10.18653/v1/2021.semeval-1.15</doi>
      <bibkey>you-etal-2021-uppsala</bibkey>
    </paper>
    <paper id="16">
      <title>SkoltechNLP at SemEval-2021 Task 2 : Generating Cross-Lingual Training Data for the Word-in-Context Task<fixed-case>S</fixed-case>koltech<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 2: Generating Cross-Lingual Training Data for the Word-in-Context Task</title>
      <author><first>Anton</first><last>Razzhigaev</last></author>
      <author><first>Nikolay</first><last>Arefyev</last></author>
      <author><first>Alexander</first><last>Panchenko</last></author>
      <pages>157–162</pages>
      <abstract>In this paper, we present a <a href="https://en.wikipedia.org/wiki/System">system</a> for the solution of the cross-lingual and multilingual word-in-context disambiguation task. Task organizers provided monolingual data in several languages, but no cross-lingual training data were available. To address the lack of the officially provided cross-lingual training data, we decided to generate such <a href="https://en.wikipedia.org/wiki/Data">data</a> ourselves. We describe a simple yet effective approach based on <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> and back translation of the lexical units to the original language used in the context of this shared task. In our experiments, we used a neural system based on the XLM-R, a pre-trained transformer-based masked language model, as a baseline. We show the effectiveness of the proposed approach as it allows to substantially improve the performance of this strong neural baseline model. In addition, in this study, we present multiple types of the XLM-R based classifier, experimenting with various ways of mixing information from the first and second occurrences of the target word in two samples.</abstract>
      <url hash="3345619c">2021.semeval-1.16</url>
      <doi>10.18653/v1/2021.semeval-1.16</doi>
      <bibkey>razzhigaev-etal-2021-skoltechnlp</bibkey>
    </paper>
    <paper id="17">
      <title>Zhestyatsky at SemEval-2021 Task 2 : ReLU over Cosine Similarity for BERT Fine-tuning<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 2: <fixed-case>R</fixed-case>e<fixed-case>LU</fixed-case> over Cosine Similarity for <fixed-case>BERT</fixed-case> Fine-tuning</title>
      <author><first>Boris</first><last>Zhestiankin</last></author>
      <author><first>Maria</first><last>Ponomareva</last></author>
      <pages>163–168</pages>
      <abstract>This paper presents our contribution to SemEval-2021 Task 2 : Multilingual and Cross-lingual Word-in-Context Disambiguation (MCL-WiC). Our experiments cover English (EN-EN) sub-track from the multilingual setting of the task. We experiment with several pre-trained language models and investigate an impact of different top-layers on <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a>. We find the combination of <a href="https://en.wikipedia.org/wiki/Cosine_similarity">Cosine Similarity</a> and ReLU activation leading to the most effective fine-tuning procedure. Our best <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> results in <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> 92.7 %, which is the fourth-best score in EN-EN sub-track.</abstract>
      <url hash="855da59b">2021.semeval-1.17</url>
      <doi>10.18653/v1/2021.semeval-1.17</doi>
      <bibkey>zhestiankin-ponomareva-2021-zhestyatsky</bibkey>
      <pwccode url="https://github.com/zhestyatsky/MCL-WiC" additional="false">zhestyatsky/MCL-WiC</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/superglue">SuperGLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wic">WiC</pwcdataset>
    </paper>
    <paper id="18">
      <title>SzegedAI at SemEval-2021 Task 2 : Zero-shot Approach for Multilingual and Cross-lingual Word-in-Context Disambiguation<fixed-case>S</fixed-case>zeged<fixed-case>AI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 2: Zero-shot Approach for Multilingual and Cross-lingual Word-in-Context Disambiguation</title>
      <author><first>Gábor</first><last>Berend</last></author>
      <pages>169–174</pages>
      <abstract>In this paper, we introduce our <a href="https://en.wikipedia.org/wiki/System">system</a> that we participated with at the multilingual and cross-lingual word-in-context disambiguation SemEval 2021 shared task. In our experiments, we investigated the possibility of using an all-words fine-grained word sense disambiguation system trained purely on sense-annotated data in English and draw predictions on the semantic equivalence of words in context based on the similarity of the ranked lists of the (English) WordNet synsets returned for the target words decisions had to be made for. We overcame the multi,-and cross-lingual aspects of the shared task by applying a multilingual transformer for encoding the texts written in either <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a>, <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/French_language">French</a>, <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a> and <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a>. While our results lag behind top scoring submissions, it has the benefit that it not only provides a binary flag whether two words in their context have the same meaning, but also provides a more tangible output in the form of a ranked list of (English) WordNet synsets irrespective of the language of the input texts. As our framework is designed to be as generic as possible, it can be applied as a baseline for basically any language (supported by the multilingual transformed architecture employed) even in the absence of any additional form of language specific training data.</abstract>
      <url hash="b7e1ca58">2021.semeval-1.18</url>
      <doi>10.18653/v1/2021.semeval-1.18</doi>
      <bibkey>berend-2021-szegedai</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wic">WiC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/word-sense-disambiguation-a-unified">Word Sense Disambiguation: a Unified Evaluation Framework and Empirical Comparison</pwcdataset>
    <title_ar>SzegedAI في SemEval-2021 المهمة 2: أسلوب اللقطة الصفرية لتوضيح الكلمات في السياق متعدد اللغات وعبر اللغات</title_ar>
      <title_es>SzegeDai en la Tarea 2 de SemEval-2021: enfoque cero para la desambiguación de palabras en contexto multilingüe y multilingüe</title_es>
      <title_pt>SzegedAI no SemEval-2021 Tarefa 2: Abordagem de tiro zero para desambiguação de palavras em contexto multilíngue e multilíngue</title_pt>
      <title_ja>SemEval -2021のSegedAIタスク2 ：多言語およびクロスリンガルWord - in - Contextの曖昧さ解消のためのゼロショットアプローチ</title_ja>
      <title_zh>SzegedAI在SemEval-2021务2:多语言、跨语境消歧之术镜头</title_zh>
      <title_hi>SemEval-2021 कार्य 2 पर SzegedAI: बहुभाषी और क्रॉस-भाषी वर्ड-इन-कॉन्टेक्स्ट डिसकम्पिगेशन के लिए शून्य-शॉट दृष्टिकोण</title_hi>
      <title_ga>SzegedAI ag SemEval-2021 Tasc 2: Cur Chuige Zero-shot for Multilingual and Traslingual Word-in-Context Disathmbiuation</title_ga>
      <title_el>Καθήκον 2: Προσέγγιση μηδενικού πυροβολισμού για την πολυγλωσσική και διαγώνια αποσαφήνιση λέξεων στο πλαίσιο</title_el>
      <title_hu>SzegedAI a SemEval-2021 2. feladat: Zéró lövéses megközelítés a többnyelvű és többnyelvű szó-a-kontextusban szétbontáshoz</title_hu>
      <title_ka>Name</title_ka>
      <title_it>SzegedAI al SemEval-2021 Task 2: approccio a scatto zero per la disambiguazione di parole in contesto multilingue e multilingue</title_it>
      <title_kk>SzegedAI 2- талық- 2021 тапсырмасында: көп тілді және көп тілді сөзді контексті бұғаттау үшін нөл- түрлендіру жағдайы</title_kk>
      <title_lt>SzegedAI programos „SemEval-2021“ 2 užduotis: nulinis požiūris į daugiakalbį ir tarpkalbinį žodžių nedviprasmiškumą kontekste</title_lt>
      <title_mk>SzegedAI на SemEval-2021 задача 2: Нуличен пристап за мултијазичка и меѓујазична дебагигуација на зборовите во контекст</title_mk>
      <title_ml>സെമ്എവാല്‍- 2021 ടാസ്ക് 2: പല ഭാഷകള്‍ക്കും ക്രോസ്- ഭാഷ വാക്കുകള്‍</title_ml>
      <title_mt>SzegedAI f’SemEval-2021 Kompitu 2: Approċċ żero-shot għal Diżambigwazzjoni Multilingwali u Cross-lingual Word-in-Context</title_mt>
      <title_mn>SzegedAI at SemEval-2021 Task 2: Zero-shot Approach for Multilingual and Cross-Language Word-in-Context Disambiguation</title_mn>
      <title_no>SzegedAI ved semiEval-2021 oppgåve 2: Nullshot-tilgang for fleirspråk og krysspråk ord-i-kontekst-disambiguasjon</title_no>
      <title_pl>SzegedAI w SemEval-2021 Zadanie 2: Zero-shot podejście do wielojęzycznej i międzyjęzycznej dyambiguacji słowa w kontekście</title_pl>
      <title_sr>SzegedAI na pola evala-2021 zadatak 2: pristup nulom snimanju za multijezičku i krstojezičku reč u kontekstu dezambiguaciju</title_sr>
      <title_ro>SzegedAI la SemEval-2021 Sarcina 2: Abordare zero pentru dezambiguizarea cuvântului în context multilingv și translingv</title_ro>
      <title_si>Name</title_si>
      <title_so>SzegedAI at SemEval-2021 Task 2: Zero-shot Approach for Multilingual and Cross-lingual Word-in-Context Disambiguation</title_so>
      <title_ms>SzegedAI di SemEval-2021 Tugas 2: Pendekatan Zero-shot untuk Pengambiguasi Perkataan-dalam-Konteks Berbahasa Berberbilang dan Berbahasa</title_ms>
      <title_ur>SzegedAI at SemEval-2021 Task 2: Zero-shot Approach for Multilingual and Cross-Language Word-in-Context Disambiguation</title_ur>
      <title_sv>SzegedAI på SemEval-2021 Uppgift 2: Nollskottsmetod för flerspråkig och tvärspråkig ordnedbrytning</title_sv>
      <title_ta>செம்Eval- 2021 பணி 2: பல மொழிகளுக்கும் மற்றும் கிராஸ்- மொழிகளுக்கும் செர்ஜெட்AI செர்ஜெட்</title_ta>
      <title_uz>Name</title_uz>
      <title_vi>Băng đảng SzegedAI tại SemEvl-2021 Task 2: Tiếp cận bắn không cho phát ngôn ngữ đa và xuyên chữ trong ngữ rộng</title_vi>
      <title_hr>SzegedAI na pola evaluacije 2021. zadatak 2: pristup nulom snimanju za multijezičku i krstojezičku riječ u kontekstu disambigaciju</title_hr>
      <title_bg>Задача 2: Нулев подход за многоезично и междуезично разграничаване на думите в контекста</title_bg>
      <title_nl>SzegedAI bij SemEval-2021 Taak 2: Zero-shot aanpak voor meertalige en meertalige woord-in-context disambiguatie</title_nl>
      <title_da>SzegedAI på SemEval-2021 Opgave 2: Zero-shot tilgang til flersproget og tværsproget ord-i-kontekst Disambiguation</title_da>
      <title_fa>SzegedAI در ماموریت ۲۰۱۲: دسترسی صفر فشار برای کلمه‌های زیادی و زبان‌های زیادی در محیط</title_fa>
      <title_id>SzegedAI di SemEval-2021 Tugas 2: Pendekatan Zero-shot untuk Pengambiguasi Perkataan Dalam Konteks Berbahasa Berbahasa dan Berbahasa Berbahasa</title_id>
      <title_ko>SemEval-21의 Szeged AI 작업 2: 문맥 인식 다국어 및 다국어 단어의 제로 사격 방법</title_ko>
      <title_de>SzegedAI bei SemEval-2021 Aufgabe 2: Zero-Shot Ansatz für mehrsprachige und crosslinguale Wort-in-Kontext Disambiguation</title_de>
      <title_tr>SzegedAI at SemEval-2021 Task 2: Zero-shot Approach for Multilingual and Cross-Language Word-in-Context Disambiguation</title_tr>
      <title_af>SzegedAI by SemEval-2021 Opdrag 2: Nuwe-skoot toegang vir Multilingual en Cross-Language Woord-in-Context Disambiguation</title_af>
      <title_sw>SzegedAI kwenye kazi ya SemEval-2021 2: Kupigwa risasi zisizo na risasi kwa lugha nyingi na lugha-ya-Cross</title_sw>
      <title_sq>SzegedAI në SemEval-2021 Task 2: Zero-shot Approach for Multilingual and Cross-lingual Word-in-Context Disambiguation</title_sq>
      <title_am>ስzegedAI በSemEval-2021 ስራ 2: Zero-shot Approach for Multilingual and Cross-language Word-in-Context Disambition</title_am>
      <title_hy>Սեգեդալ 2021-ի "Սեմեվալ-2021"-ի 2. հանձնարարությունը՝ բազմալեզու և փոխլեզու բառերի բառերի բացահայտումների զրո մոտեցում</title_hy>
      <title_az>SzegedAI 2-ci İş: çoxlu dil və çoxlu dil Söz-in-Context Disambiguation üçün 0-shot Approach</title_az>
      <title_bn>সেমভাল-২০২১ কাজের সেজেদএআই: মাল্টিভাষা এবং ক্রস-ভাষার শব্দ বিভিন্ন ভাষার বিভিন্ন বিভিন্ন ভাষার বিভ্রান্তির জন্য শূণ্য-</title_bn>
      <title_bs>SzegedAI na pola evaluacije 2021. zadatak 2: pristup nulom snimanju za multijezičku i krstojezičku riječ u kontekstu dezambiguaciju</title_bs>
      <title_ca>SzegedAI a SemEval-2021 Task 2: Zero-shot Approach for Multilingual and Cross-lingual Word-in-Context Disambiguation</title_ca>
      <title_et>SzegedAI SemEval-2021 Ülesanne 2: Nullshot lähenemisviis mitmekeelsele ja keeleülesele sõnale kontekstis disambiguatsioonile</title_et>
      <title_cs>SzegedAI na SemEval-2021 Úkol 2: Zero-shot přístup pro vícejazyčné a křížjazyčné slovo-v-kontextu disambiguace</title_cs>
      <title_fi>SzegedAI SemEval-2021 Tehtävä 2: Zero-shot lähestymistapa monikieliseen ja monikieliseen Word-in-Context Disambiguation</title_fi>
      <title_jv>scegadAI nang semi-2020 task 2: 0-shot Method for Multilanguage and Kr-language Word-in-context disabled</title_jv>
      <title_he>SzegedAI ב SemEval-2021 משימה 2: גישה אפס לירות עבור ניתוח מילים רבות ושפתיים</title_he>
      <title_sk>SzegedAI na SemEval-2021 Naloga 2: Ničelni pristop za večjezično in medjezično razočaranje besed v kontekstu</title_sk>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_bo>SzegedAI at SemEval-2021 Task 2: Zero-shot Approach for Multilingual and Cross-lingual Word-in-Context Disambiguation</title_bo>
      <abstract_ar>في هذه الورقة ، نقدم نظامنا الذي شاركنا به في مهمة SemEval 2021 المشتركة متعددة اللغات والمتعددة اللغات لإزالة الغموض في السياق. في تجاربنا ، قمنا بالتحقيق في إمكانية استخدام نظام إزالة الغموض الدقيق للكلمات والمُدرَّب تمامًا على البيانات المشروحة بالمعنى باللغة الإنجليزية ورسم تنبؤات حول التكافؤ الدلالي للكلمات في السياق بناءً على تشابه القوائم المصنفة لـ تم إرجاع مجموعات WordNet (باللغة الإنجليزية) للكلمات المستهدفة التي يجب اتخاذ القرارات بشأنها. لقد تغلبنا على الجوانب متعددة اللغات وعبر اللغات للمهمة المشتركة من خلال تطبيق محول متعدد اللغات لتشفير النصوص المكتوبة باللغات العربية والإنجليزية والفرنسية والروسية والصينية. على الرغم من أن نتائجنا متأخرة عن عمليات تقديم أعلى الدرجات ، إلا أنها لا توفر فقط علمًا ثنائيًا ما إذا كانت كلمتان في سياقهما لها نفس المعنى ، ولكنها توفر أيضًا ناتجًا ملموسًا بشكل أكبر في شكل قائمة مرتبة (الإنجليزية) مزامنة WordNet بغض النظر عن لغة نصوص الإدخال. نظرًا لأن إطار العمل الخاص بنا مصمم ليكون عامًا قدر الإمكان ، فيمكن تطبيقه كخط أساس لأي لغة (مدعومًا بالبنية المحولة متعددة اللغات المستخدمة) حتى في حالة عدم وجود أي شكل إضافي من بيانات التدريب الخاصة باللغة.</abstract_ar>
      <abstract_pt>Neste artigo, apresentamos nosso sistema com o qual participamos da tarefa compartilhada de desambiguação de palavras em contexto multilíngue e multilíngue SemEval 2021. Em nossos experimentos, investigamos a possibilidade de usar um sistema de desambiguação de sentido de palavras de grão fino de todas as palavras treinado puramente em dados anotados de sentido em inglês e desenhar previsões sobre a equivalência semântica de palavras no contexto com base na semelhança das listas classificadas de os synsets WordNet (inglês) retornados para as palavras-alvo tiveram que ser tomadas decisões. Superamos os aspectos multilíngues e multilíngues da tarefa compartilhada aplicando um transformador multilíngue para codificar os textos escritos em árabe, inglês, francês, russo e chinês. Embora nossos resultados fiquem atrás dos envios de pontuação mais alta, ele tem o benefício de não apenas fornecer um sinalizador binário se duas palavras em seu contexto têm o mesmo significado, mas também fornecer uma saída mais tangível na forma de uma lista classificada de (inglês) Synsets WordNet independentemente do idioma dos textos de entrada. Como nosso framework foi projetado para ser o mais genérico possível, ele pode ser aplicado como uma linha de base para basicamente qualquer idioma (suportado pela arquitetura transformada multilíngue empregada), mesmo na ausência de qualquer forma adicional de dados de treinamento específicos do idioma.</abstract_pt>
      <abstract_es>En este artículo, presentamos nuestro sistema con el que participamos en la tarea compartida de desambiguación multilingüe y multilingüe de palabras en contexto SemEval 2021. En nuestros experimentos, investigamos la posibilidad de utilizar un sistema de desambiguación del sentido de las palabras de grano fino entrenado exclusivamente en datos anotados con sentido en inglés y hacer predicciones sobre la equivalencia semántica de las palabras en contexto basadas en la similitud de las listas clasificadas de WordNet (en inglés) synsets devueltos para las palabras objetivo para las que se tuvieron que tomar decisiones. Superamos los aspectos multilingües y multilingües de la tarea compartida mediante la aplicación de un transformador multilingüe para codificar los textos escritos en árabe, inglés, francés, ruso y chino. Si bien nuestros resultados van por detrás de los envíos con mejores puntuaciones, tiene la ventaja de que no solo proporciona una bandera binaria de si dos palabras en su contexto tienen el mismo significado, sino que también proporciona una salida más tangible en forma de una lista clasificada de synsets de WordNet (en inglés), independientemente del idioma de la entrada. textos. Como nuestro marco está diseñado para ser lo más genérico posible, se puede aplicar como base para básicamente cualquier idioma (respaldado por la arquitectura transformada multilingüe empleada) incluso en ausencia de cualquier forma adicional de datos de capacitación específicos del idioma.</abstract_es>
      <abstract_ja>本稿では，多言語およびクロスリンガル・ワード・イン・コンテキストの曖昧性解消SemEval 2021の共有タスクで参加したシステムを紹介する． 私たちの実験では、英語のセンスアノテーションされたデータに基づいて純粋に訓練された全単語の細かい単語センスの曖昧さ解消システムを使用し、対象単語の意思決定のために返される（英語） WordNetシンセットのランク付けされたリストの類似性に基づいて、文脈内の単語の意味的等価性に関する予測を描画する可能性を調査しました。 私たちは、アラビア語、英語、フランス語、ロシア語、中国語で書かれたテキストをエンコードするための多言語変換器を適用して、共有タスクの多言語、およびクロスリンガルの側面を克服しました。 私たちの結果はトップスコアの提出物よりも遅れていますが、コンテキスト内の2つの単語が同じ意味を持つかどうかのバイナリフラグを提供するだけでなく、入力テキストの言語に関係なく、（英語） WordNetシンセットのランク付けリストの形でより具体的な出力を提供するという利点があります。 当社のフレームワークは可能な限り汎用的に設計されているため、追加の形式の言語固有のトレーニングデータがない場合でも、基本的にあらゆる言語（採用されている多言語変換アーキテクチャによってサポートされている）にベースラインとして適用することができます。</abstract_ja>
      <abstract_zh>本文中,我们介绍了我们在多言语和跨话单词上下文中消除歧义SemEval 2021共享职务中参与的系统。 于我实验中,研用纯粹英语义注数全单词细粒度词义消歧义统之可能,因其所必为单词决策还(英语)WordNet synset之相似性,占上下文之语义等效性。 共事者多言语跨语,宜多言转换器对用阿拉伯语,英语法语,俄语与中文编本编码之。 虽后于得分,其利一二进制表,两单词同义于上下文,以(英语)WordNet synset为名,不论输本之言。 以吾框架之设尽可用,故虽无他文特定训练数据,亦可以为大言基线(而多言转架构支)。</abstract_zh>
      <abstract_hi>इस पेपर में, हम अपनी प्रणाली का परिचय देते हैं कि हमने बहुभाषी और क्रॉस-लिंगुअल वर्ड-इन-कॉन्टेक्स्ट डिसएम्बिगेशन सेमइवल 2021 साझा कार्य में भाग लिया। हमारे प्रयोगों में, हमने अंग्रेजी में अर्थ-एनोटेट डेटा पर विशुद्ध रूप से प्रशिक्षित सभी शब्दों के ठीक-दाने वाले शब्द अर्थ बहुविकल्पी प्रणाली का उपयोग करने की संभावना की जांच की और (अंग्रेजी) वर्डनेट सिंसेट की रैंक की गई सूचियों की समानता के आधार पर संदर्भ में शब्दों की शब्दार्थ तुल्यता पर भविष्यवाणियां आकर्षित कीं लक्ष्य शब्दों के लिए वापस किए गए निर्णयों के लिए वापस आ गए। हमने अरबी, अंग्रेजी, फ्रेंच, रूसी और चीनी में लिखे गए ग्रंथों को एन्कोडिंग करने के लिए एक बहुभाषी ट्रांसफार्मर लागू करके साझा कार्य के बहु-और क्रॉस-लिंगुअल पहलुओं पर काबू पा लिया। जबकि हमारे परिणाम शीर्ष स्कोरिंग प्रस्तुतियों के पीछे हैं, इसका लाभ यह है कि यह न केवल एक बाइनरी ध्वज प्रदान करता है कि क्या उनके संदर्भ में दो शब्दों का एक ही अर्थ है, बल्कि इनपुट ग्रंथों की भाषा के बावजूद (अंग्रेजी) वर्डनेट सिंसेट की रैंक सूची के रूप में अधिक मूर्त आउटपुट भी प्रदान करता है। जैसा कि हमारे ढांचे को यथासंभव सामान्य होने के लिए डिज़ाइन किया गया है, इसे मूल रूप से किसी भी भाषा के लिए एक आधार रेखा के रूप में लागू किया जा सकता है (बहुभाषी रूपांतरित वास्तुकला द्वारा समर्थित) यहां तक कि भाषा विशिष्ट प्रशिक्षण डेटा के किसी भी अतिरिक्त रूप की अनुपस्थिति में भी।</abstract_hi>
      <abstract_ga>Sa pháipéar seo, tugaimid ár gcóras isteach a raibh muid rannpháirteach ann ag an tasc roinnte ilteangach agus tras-teangach focal-i-comhthéacs SemEval 2021. Inár dturgnaimh, rinneamar imscrúdú ar an bhféidearthacht go n-úsáidfí córas mínghlanadh uile-focal de réir bhrí na bhfocal atá oilte go hiomlán ar shonraí ciall-anótáilte i mBéarla agus tarraingíomar tuar ar choibhéis shéimeantach na bhfocal i gcomhthéacs bunaithe ar chosúlacht na liostaí rangaithe de. bhí na synsets WordNet (Béarla) a cuireadh ar ais do na spriocfhocail a bhí le déanamh acu. Sháraigh muid na gnéithe iltheangacha agus tras-teangacha den tasc roinnte trí chlaochladán ilteangach a chur i bhfeidhm chun na téacsanna a scríobhtar in Araibis, Béarla, Fraincis, Rúisis agus Sínis a ionchódú. Cé go bhfuil ár dtorthaí taobh thiar de na haighneachtaí is airde scórála, tá sé de bhuntáiste aige, ní hamháin go soláthraíonn sé bratach dhénártha an bhfuil an bhrí chéanna ag dhá fhocal ina gcomhthéacs, ach go soláthraíonn sé aschur níos inláimhsithe freisin i bhfoirm liosta rangaithe de (Béarla). Synsets WordNet beag beann ar theanga na dtéacsanna ionchuir. Toisc go bhfuil ár gcreat deartha le bheith chomh cineálach agus is féidir, is féidir é a chur i bhfeidhm mar bhonnlíne d’aon teanga go bunúsach (le tacaíocht ón ailtireacht ilteangach chlaochlaithe a úsáidtear) fiú in éagmais aon chineál sonraí oiliúna a bhaineann go sonrach le teanga.</abstract_ga>
      <abstract_el>Στην παρούσα εργασία, παρουσιάζουμε το σύστημά μας με το οποίο συμμετείχαμε στην πολυγλωσσική και διγλωσσική αποσαφήνιση λέξης-σε-περιβάλλοντος κοινή εργασία. Στα πειράματά μας, διερευνήσαμε τη δυνατότητα χρήσης ενός λεπτόκοκκου συστήματος διασφάλισης λέξεων με όλες τις λέξεις εκπαιδευμένου καθαρά σε δεδομένα με σημειώσεις αισθήσεων στα αγγλικά και σχεδιάσαμε προβλέψεις για τη σημασιολογική ισοδυναμία των λέξεων στο πλαίσιο με βάση την ομοιότητα των ταξινομημένων καταλόγων των (αγγλικών) συνόδων που επιστρέφονται για τις λέξεις-στόχους που έπρεπε να ληφθούν αποφάσεις. Υπερνικήσαμε τις πολυγλωσσικές πτυχές του κοινού έργου εφαρμόζοντας έναν πολύγλωσσο μετασχηματιστή για την κωδικοποίηση των κειμένων που γράφονται είτε στα αραβικά, αγγλικά, γαλλικά, ρωσικά και κινέζικα. Ενώ τα αποτελέσματά μας υστερούν πίσω από τις αιτήσεις κορυφαίας βαθμολογίας, έχει το πλεονέκτημα ότι όχι μόνο παρέχει μια δυαδική σημαία εάν δύο λέξεις στο πλαίσιο τους έχουν την ίδια σημασία, αλλά παρέχει επίσης μια πιο απτή παραγωγή με τη μορφή μιας ταξινομημένης λίστας (Αγγλικών) συνόδων ανεξάρτητα από τη γλώσσα των κειμένων εισαγωγής. Δεδομένου ότι το πλαίσιο μας έχει σχεδιαστεί για να είναι όσο το δυνατόν πιο γενικό, μπορεί να εφαρμοστεί ως βάση για βασικά οποιαδήποτε γλώσσα (υποστηριζόμενη από την πολυγλωσσική μετασχηματισμένη αρχιτεκτονική που χρησιμοποιείται) ακόμη και αν δεν υπάρχουν πρόσθετα δεδομένα κατάρτισης ειδικά για τη γλώσσα.</abstract_el>
      <abstract_hu>Ebben a tanulmányban bemutatjuk rendszerünket, amellyel részt vettünk a SemEval 2021 többnyelvű és többnyelvű szó-a-kontextus egyértelműsítésében. Kísérleteinkben azt vizsgáltuk, hogy a kizárólag angol nyelvű érzékeléssel ellátott adatokra képzett, finomszemcsés szóérzékeléssel rendelkező egyértelműsítő rendszer alkalmazásával lehetséges-e, és előrejelzéseket rajzoltunk a szavak szemantikai egyenértékűségéről kontextusban, a célszavak döntéséhez visszaadott (angol) WordNet szinkronkészletek rangsorolt listáinak hasonlósága alapján. Az arab, angol, francia, orosz és kínai nyelvű szövegek kódolásához többnyelvű transzformátor segítségével győztük le a megosztott feladat többnyelvű és többnyelvű aspektusait. Bár eredményeink elmaradnak a legmagasabb pontszámú beadványok mögött, annak az előnye, hogy nem csak bináris jelzést nyújt, hogy a kontextusban két szó ugyanolyan jelentéssel rendelkezik-e, hanem kézzelfoghatóbb kimenetet is nyújt (angol) WordNet szinkronkészletek rangsorolt listájának formájában, függetlenül a beviteli szövegek nyelvétől. Mivel a keretrendszerünket úgy terveztük, hogy a lehető legáltalánosabb legyen, alapként alkalmazható alapvetően bármilyen nyelvre (az alkalmazott többnyelvű átalakított architektúra segítségével), még akkor is, ha nem állnak rendelkezésre további nyelvspecifikus képzési adatok.</abstract_hu>
      <abstract_ka>ამ დომენტში ჩვენ ჩვენი სისტემის გადავიყენებთ, რომელიც ჩვენ მრავალენგური და მრავალენგური სიტყვები-კონტექსტური განამბიგუაცია SemEval 2021-ის გაყოფილი საქმე. ჩვენი ექსპერიმენტებში, ჩვენ შეგვიძლია გამოყენოთ ყველა სიტყვების სიტყვების სისტემას გამოყენება განსხვავებული სიტყვების სისტემა, რომელიც განსხვავებული სიტყვების სიტყვების განსხვავებულია ანგლისურად განსხვავებული სიტყვების განსხვავება და გამოყენება სიმპანტიკურ ჩვენ გავაკეთებეთ მრავალენგური და მრავალენგური აპექტირების განმავლობას, რომელიც მრავალენგური ტრანფორმეტრის გამოყენებით, რომელიც აპაბური, ანგლისური, ფრანგური, პირუსი და მაგრამ ჩვენი წარმოდგენები უფრო მარტივი სკონტექტის შესახებ, მაგრამ იქნება გამოსახულება, რომ ის არა მხოლოდ ბინარი ტლაგექტის, თუ ორი სიტყვის იგივე სიტყვის, მაგრამ იქნება უფრო მარტივი გამოსახულება სინგექტის როგორც ჩვენი ფრამეტრი შეიძლება უფრო გენერიკური იყოს, ეს შეიძლება იყენება, როგორც ფესტრიქტიკური ყველა ენაზე (მრავალენგური გარგებული აქტიქტრიქტიკური დამუშავებული) თუმცა ყველა და</abstract_ka>
      <abstract_it>In questo articolo, presentiamo il nostro sistema con cui abbiamo partecipato al compito condiviso SemEval 2021 di disambiguazione word-in-context multilingue e multilingue. Nei nostri esperimenti, abbiamo indagato la possibilità di utilizzare un sistema di disambiguazione del senso delle parole a grana fine di tutte le parole addestrato esclusivamente su dati annotati in inglese e disegnare previsioni sull'equivalenza semantica delle parole nel contesto in base alla somiglianza delle liste classificate dei sinonimi WordNet restituiti per le parole target che dovevano essere prese. Abbiamo superato gli aspetti multilingue e multilingue del compito condiviso applicando un trasformatore multilingue per la codifica dei testi scritti in arabo, inglese, francese, russo e cinese. Anche se i nostri risultati sono in ritardo rispetto ai punteggi più alti, ha il vantaggio che non solo fornisce un flag binario se due parole nel loro contesto hanno lo stesso significato, ma fornisce anche un output più tangibile sotto forma di una lista classificata di sintesi WordNet (inglese) indipendentemente dalla lingua dei testi di input. Poiché il nostro framework è stato progettato per essere il più generico possibile, può essere applicato come base di riferimento per praticamente qualsiasi lingua (supportata dall'architettura trasformata multilingue utilizzata) anche in assenza di qualsiasi forma aggiuntiva di dati formativi specifici per la lingua.</abstract_it>
      <abstract_lt>Šiame dokumente pristatome savo sistemą, su kuria dalyvavome daugiakalbėje ir daugiakalbėje žodžių nedviprasmijoje SemEval 2021 bendroje užduotyje. Mūsų eksperimentuose ištirėme galimybę panaudoti visus žodžius smulkiai išgrūdintą žodžių supratimo neišaiškinimo sistemą, mokomą vien tik senso anotuotais duomenimis anglų kalba, ir parengėme prognozes dėl semantinio žodžių ekvivalentiškumo kontekste, pagrįstą (anglų) WordNet sintezių, grąžintų tiksliniams žodžiams priimti, sąrašų panašumu. Mes įveikėme daugiakalbius bendros užduoties aspektus taikant daugiakalbį transformatorių, koduojantį tekstus arabų, anglų, prancūzų, rusų ir kinų kalbomis. Nors mūsų rezultatai atsilieka nuo aukščiausio lygio rezultatų, naudinga, kad jame ne tik pateikiama dviguba vėliava, ar dvi žodžiai jų kontekste turi tą pačią reikšmę, bet ir pateikiamas apčiuopiamesnis išėjimas, sudarytas pagal rankingą (anglų) WordNet sintezių sąrašą, nepriklausomai nuo įvestų tekstų kalbos. As our framework is designed to be as generic as possible, it can be applied as a baseline for basically any language (supported by the multilingual transformed architecture employed) even in the absence of any additional form of language specific training data.</abstract_lt>
      <abstract_kk>Бұл қағазда біз көп тілді және көп тілді сөздерді бағыттау көптеген уақытта 2021 жылы ортақ тапсырмасына қатысу жүйесімізді таңдаймыз. Біздің тәжірибемдерімізде біз бүкіл сөздерді дұрыс сөздердің сезімділігін қолдану мүмкіндігін тек ағылшын тілінде түсінікті мәліметті түсінікті берілген және мәліметті ағылшын тіліндегі сөздердің семантикалық эквивалентті мәліметтерді жасап, мәліметті Біз ортақтастырылған тапсырманың көптеген және бірнеше тілді аспекттерін көптеген түрлендірушілерді араб, ағылшын, француз, руссия және қытайша жазылған мәтіндерді кодтамыз үшін қолданды Біздің нәтижелеріміз жоғары сұрау жіберіліміздің артында қалдырылғанда, ол тек екі сөздің контекстесінде бір мағынасы бар екенін, бірақ сондай-ақ WordNet тізімінің (ағылшын тізімінің) жоғары тізіміне қарай- қарай қарай, бірақ бі Біздің фрейміміз мүмкіндігінше жалпы болу үшін құрылған сияқты, ол негізгі тіл үшін қолданылады (көптілік аударылған архитектура қолданылады) тілдердің қосымша тәжірибе деректері жоқ болмаса да.</abstract_kk>
      <abstract_mk>Во овој документ, го воведуваме нашиот систем со кој учествувавме на мултијазичката и прекујазичната раздвојувачка задача SemEval 2021. Во нашите експерименти, ја истражувавме можноста да се користи систем за раздвојување на смислата на сите зборови со фини зборови трениран чисто на смислени податоци на англиски и да се нацртаат предвидувања за семантичната еквивалентност на зборови во контекст базирана на сличноста на рангираните листи на (англиски) WordNet синсетите вратени за одлуките на метните зборови. Ги надминавме мултијазичните и прекујазичните аспекти на заедничката задача со апликација на мултијазичен трансформатор за кодирање на текстите напишани на арапски, англиски, француски, руски и кинески јазик. И покрај тоа што нашите резултати се задржуваат зад највисоките поднесувања на оценки, има корист што не само обезбедува бинарно знаме дали два збора во нивниот контекст имаат истиот значење, туку и обезбедува пореална излез во форма на рангирана листа на (англиски) WordNet синсети без оглед на јазикот на вводните тексти. Бидејќи нашата рамка е дизајнирана да биде што е можно поширока, може да се примени како основа за секој јазик (поддржан од користена мултијазичка трансформирана архитектура) дури и во отсуството на какви било дополнителни форма на податоци за јазик специфични обуки.</abstract_mk>
      <abstract_mt>F’dan id-dokument, aħna nintroduċu s-sistema tagħna li pparteċipajna magħha fid-diżambigwazzjoni multilingwi u translingwi tal-kelma fil-kuntest SemEval 2021. Fl-esperimenti tagħna, investigajna l-possibbiltà li tuża sistema ta’ diżambiguazzjoni tas-sens tal-kliem imqabbel fin bil-kliem imħarrġa purament fuq dejta annotata bis-sens bl-Ingliż u nġibdu tbassir dwar l-ekwivalenza semantika tal-kliem fil-kuntest ibbażat fuq is-similarità tal-listi kklassifikati tas-sinsetti WordNet (Ingliż) ritornati għad-deċiżjonijiet tal-kliem fil-mira kellhom isiru. Aħna qabżuna l-aspetti multilingwi tal-kompitu komuni billi applikajna trasformatur multilingwi għall-kodifikazzjoni tat-testi miktuba jew bl-Għarab, bl-Ingliż, bil-Franċiż, bir-Russu u biċ-Ċiniż. Filwaqt li r-riżultati tagħna qegħdin lura wara s-sottomissjonijiet tal-ogħla punteġġ, għandu l-benefiċċju li mhux biss jipprovdi bandiera binarja jekk żewġ kliem fil-kuntest tagħhom għandhomx l-istess tifsira, iżda jipprovdi wkoll output aktar tanġibbli fil-form a ta’ lista kklassifikata ta’ (Ingliż) WordNet synsets irrispettivament mil-lingwa tat-testi input. Peress li l-qafas tagħna huwa mfassal biex ikun kemm jista’ jkun ġeneriku, jista’ jiġi applikat bħala linja bażi għal kwalunkwe lingwa bażikament (appoġġjata mill-arkitettura trasformata multilingwi użata) anke fin-nuqqas ta’ kwalunkwe form a addizzjonali ta’ dejta ta’ taħriġ speċifiku għall-lingwa.</abstract_mt>
      <abstract_mn>Энэ цаасан дээр бид олон хэл болон хэл хэлний хэлний тухай хамааралтай ажил дээр оролцсон системийг танилцуулж байна. Бидний туршилтанд бид англи хэлний мэдрэмжтэй өгөгдлийн талаар суралцагдсан бүх үгнүүдийг ашиглах боломжтой байдлыг судалсан. Үүний тулд зориулагдсан үгнүүдийн төстэй тэнцүү байдлын талаар дүгнэлт зурах боломжтой. Бид хуваалцагдсан ажлын олон, олон хэл шилжүүлэгчдийг Араб, Англи, Француз, Орос, Хятадад бичигдсэн текстүүдийг кодлохын тулд ашигласан. Бидний үр дүн нь дээд нь сүлжээний дамжуулалтын ард үлдсэн ч, энэ нь зөвхөн хоёр үг адилхан утгатай эсвэл хоёр үг гэсэн үг биш ч, мөн WordNet-ийн хэлбэрээс илүү бодит үр дүн гаргадаг. Бидний үйл ажиллагаа магадгүй ерөнхий хэлбэртэй байхад зориулагдсан учраас энэ нь үндсэн хэл болгон ашиглаж болно (олон хэл өөрчлөгдсөн архитектур ажилладаг) хэлний тодорхойлолтын өгөгдлийн нэмэлт хэлбэрээс ч байхгүй.</abstract_mn>
      <abstract_pl>W niniejszym artykule przedstawiamy nasz system, z którym uczestniczyliśmy w wielojęzycznej i wielojęzycznej dyskryminacji słowa w kontekście SemEval 2021 wspólnego zadania. W naszych eksperymentach zbadaliśmy możliwość wykorzystania w języku angielskim precyzyjnego systemu dyskryminacji słowa z wyłącznie admowanymi zmysłowymi danymi oraz narysowania przewidywań dotyczących równoważności semantycznej słów w kontekście opartych na podobieństwie listy rankingowych (angielskich) zestawów WordNet zwracanych dla słów docelowych decyzji. Przezwyciężyliśmy wielojęzyczne i wielojęzyczne aspekty wspólnego zadania, stosując wielojęzyczny transformator do kodowania tekstów napisanych w języku arabskim, angielskim, francuskim, rosyjskim i chińskim. Chociaż nasze wyniki pozostają za zgłoszeniami z najwyższą oceną, ma to tę zaletę, że nie tylko zapewnia flagę binarną, czy dwa słowa w ich kontekście mają to samo znaczenie, ale także zapewnia bardziej namacalny wynik w postaci rankingowej listy (angielskiej) zestawów WordNet niezależnie od języka tekstów wejściowych. Ponieważ nasze ramy są zaprojektowane tak, aby były jak najbardziej ogólne, można je zastosować jako baza podstawowa dla zasadniczo każdego języka (wspieranego przez zastosowaną wielojęzyczną transformowaną architekturę) nawet przy braku jakiejkolwiek dodatkowej formy danych szkoleniowych specyficznych dla języka.</abstract_pl>
      <abstract_no>I denne papiret introduserer vi systemet vårt som vi delta med på den delte oppgåva i multispråk og krysspråk ord-in-context-disambiguation semiEval 2021. I eksperimentene våre har vi undersøkt muligheten for å bruka eit fil-ord-sens-disambiguasjonssystem som trengte purt på sentralannotaterte data i engelsk og tegne foregåver om semantiske ekvivalens av ord i kontekst basert på liknande av dei rangerte listene i (engelsk) WordNet-synsettene som returnerte for målordbeslutningane måtte gjerast for. Vi overvinner dei fleire og krysspråksaspektane av den delte oppgåva ved å bruka ein fleirspråkstransformering for koding av tekstane skrevene på enten arabisk, engelsk, fransk, russisk og kinesisk. Mens resultatet våre ligg bak oppløysingar av oppløysingar, har det nyttig at det ikkje berre gjev ein binærflagg om to ord i konteksten har det same mening, men også gjev ein mer tangabel utdata i form av ei rankert liste over WordNet- synkronisering uavhengig av språket på innskriftstekstane. Som rammeverket vårt er utforma til å vera så generiske som mulig, kan det brukast som baseline for kvar språk (støtta av den fleirspråksomformerte arkitekturen arbeida) sjølv om det ikkje finst andre form av språksområde-data.</abstract_no>
      <abstract_ro>În această lucrare, prezentăm sistemul nostru cu care am participat la sarcina comună SemEval 2021 privind dezambiguizarea cuvânt în context multilingvă și interlingvă. În experimentele noastre, am investigat posibilitatea utilizării unui sistem de dezambiguizare a sensului cuvintelor cu granule fine, instruit exclusiv pe date adnotate cu sensuri în limba engleză și am tras predicții privind echivalența semantică a cuvintelor în context bazate pe similitudinea listelor clasate ale sinteturilor WordNet (engleză) returnate pentru deciziile cuvintelor țintă trebuiau luate. Am depășit aspectele multilingve și translingve ale sarcinii comune prin aplicarea unui transformator multilingv pentru codificarea textelor scrise în arabă, engleză, franceză, rusă și chineză. În timp ce rezultatele noastre rămân în urma celor mai bune punctaje trimise, are avantajul că nu numai că oferă un semnal binar dacă două cuvinte din contextul lor au același sens, ci oferă, de asemenea, un rezultat mai tangibil sub forma unei liste clasate de Synseturi WordNet (în engleză) indiferent de limba textelor de intrare. Deoarece cadrul nostru este conceput pentru a fi cât mai generic posibil, acesta poate fi aplicat ca bază pentru practic orice limbă (susținută de arhitectura transformată multilingvă utilizată) chiar și în absența oricărei forme suplimentare de date de formare lingvistică specifică.</abstract_ro>
      <abstract_ml>ഈ പത്രത്തില്‍ ഞങ്ങള്‍ ഞങ്ങളുടെ സിസ്റ്റത്തെ പരിചയപ്പെടുത്തുന്നു. ഞങ്ങള്‍ പല ഭാഷകങ്ങളിലും ക്രിസ്ലിങ്ങ് വാക്കുകളിലും പങ്കെടുത്തിരിക് നമ്മുടെ പരീക്ഷണങ്ങളില്‍ നമ്മള്‍ എല്ലാ വാക്കുകളും നല്ല വാക്കുകളുടെ വിശ്വാസത്തിന്റെ അസാധ്യതയും ഉപയോഗിക്കുന്നത് അന്വേഷിക്കുകയാണ്. ഇംഗ്ലീഷിലെ വാക്കുകളുടെ സാമാന്തികമായ വിവരങ്ങള്‍ പരിശീലിക്കുകയും ച പങ്കാളിയുള്ള ജോലിയുടെ കാര്യങ്ങളില്‍ ഞങ്ങള്‍ പല ഭാഷ മാറ്റങ്ങള്‍ പ്രയോഗിക്കുകയാണ്, നമ്മുടെ ഫലങ്ങള്‍ മുകളില്‍ സ്കോര്‍ട്ട് ചെയ്യുന്ന വിവരങ്ങളുടെ പിന്നില്‍ ശേഷിച്ചിരിക്കുമ്പോള്‍ അതിന്റെ രണ്ടു വാക്കുകള്‍ ഒരേ അര്‍ത്ഥമുണ്ടോ എന്ന് ബൈനറി ഫ്ലാഗ് മാത്രമല്ല, പക്ഷെ ഇന നമ്മുടെ ഫ്രെയിമ്പുകള്‍ സാധാരണമായിരിക്കുന്നത് പോലെ സാധാരണ ഭാഷയ്ക്കുള്ള അടിസ്ഥാനമായി പ്രയോഗിക്കാന്‍ സാധിക്കുന്നത് പോലെയാണ്, അത് പ്രയോഗിക്കാന്‍ സാധ്യ</abstract_ml>
      <abstract_sr>U ovom papiru predstavljamo naš sistem s kojim smo učestvovali na delovanju multijezičkih i krstojezičkih reèi u kontekstu disambiguacije semiEval 2021. U našim eksperimentima, istražili smo mogućnost da koristimo sistem disambiguacije sa svim rečima koji su izraženi čisto na značajnim podacima na engleskom jeziku i da izvučemo predviđanja o semantičkoj ekvivalenciji reči u kontekstu na temelju sličnosti redovih listova sinkronizacija WordNet-a koji su se vratili za ciljne reči koje su trebale donijeti. Prešli smo multijezičke aspekte zajedničkog zadatka primjenjivanjem multijezičkog transformer a za kodiranje teksta napisanih na arapskom, engleskom, francuskom, ruskom i kineskom jeziku. Dok naši rezultati ostaju iza podataka vrhunskih osvajanja, imaju korist da ne samo obezbedi binarnu zastavu da li dvije reči u njihovom kontekstu imaju isto značenje, nego takođe pružaju i materijalniji izlaz u obliku redovanog list a (engleski) WordNet sinteta bez obzira na jezik tekstova. Pošto je naš okvir dizajniran da bude najgeneričniji što je moguće, može se primjenjivati kao osnovna linija za bilo koji jezik (podržavan od strane multijezičke transformirane arhitekture zaposlene) čak i u odsustvu bilo kojeg dodatnog oblika podataka o određenom treningu jezika.</abstract_sr>
      <abstract_ms>Dalam kertas ini, kami memperkenalkan sistem kami yang kami berpartisipasi dengan dalam tugas berkongsi SemEval 2021 perkataan berbilang bahasa dan saling bahasa dalam konteks. Dalam eksperimen kami, kami menyelidiki kemungkinan menggunakan sistem penyelesaian kata-kata yang bersih-bersih-bersih-bersih dilatih secara pura-pura pada data yang dicatat-sensi dalam bahasa Inggeris dan melukis ramalan tentang persamaan semantik perkataan dalam konteks berdasarkan persamaan senarai tertinggi sinset WordNet (Inggeris) yang dikembalikan untuk keputusan perkataan sasaran perlu dibuat. Kami mengatasi aspek berbilang dan saling bahasa tugas berkongsi dengan menggunakan pengubah berbilang bahasa untuk mengekodkan teks yang ditulis dalam bahasa Arab, Inggeris, Perancis, Rusia dan Cina. Sementara hasil kita tertinggal di belakang pengiriman skor atas, ia mempunyai keuntungan bahawa ia tidak hanya menyediakan bendera binari sama ada dua perkataan dalam konteks mereka mempunyai makna yang sama, tetapi juga menyediakan output yang lebih nyata dalam bentuk senarai tertinggi sinset WordNet (Inggeris) tidak kira-kira bahasa teks input. Kerana kerangka kami direka untuk menjadi sebaik mungkin generik, ia boleh dilaksanakan sebagai dasar untuk pada dasarnya mana-mana bahasa (disokong oleh arkitektur berubah berbilang bahasa yang digunakan) walaupun tidak ada sebarang bentuk tambahan data latihan khusus bahasa.</abstract_ms>
      <abstract_so>Qoraalkan waxaynu ku soo bandhignaa nidaamka aan ka qeybqaadanay hadalka luuqadaha kala duduwan oo luuqadaha kala duduwan oo kala duduwan oo kala duduwan SemEval 2021. Imtixaanadeena, waxaynu baaraynay suurtagalka isticmaalka nidaamka hadalka oo dhan oo si fiican u kala duwan oo kaliya lagu baray macluumaadka ingiriisiga, waxaana soo tegnay warqado u eg hadallada marka loo dhigo si siman oo lagu qoro liiska afka Ingiriiska (Ingiriis) ee loo soo celiyey qoraalka qoraalka ee loogu talagalay. Waxaannu ka adkaynay qeybaha luuqadaha kala duduwan ee shaqada la qaybsan, waxaana lagu codsanaa isbedelka luuqadaha kala duduwan si aan ugu qorno qoraalka afka Carabi, Ingiriis, Faraansiis, Ruush iyo Shiino. While our results lag behind top scoring submissions, it has the benefit that it not only provides a binary flag whether two words in their context have the same meaning, but also provides a more tangible output in the form of a ranked list of (English) WordNet synsets irrespective of the language of the input texts.  Sida aan qorsheynta loo qoray inuu ahaan karo sida caadiga ah, waxaa lagu codsan karaa qoraal hoose ahaan luqad kasta (kaas oo lagu caawiyey dhismaha la beddelay oo luuqadaha kala duduwan) xataa haddii aysan jirin macluumaad dheeraad ah oo ku qoran waxbarasho cayiman oo luuqad ah.</abstract_so>
      <abstract_sv>I denna uppsats introducerar vi vårt system som vi deltog med vid SemEval 2021 delade uppgift. I våra experiment undersökte vi möjligheten att använda ett finkornigt ordförnimmelsesystem som enbart tränats på engelska och rita förutsägelser på ordens semantiska ekvivalens i kontext baserat på likheten mellan de rangordnade listorna för de (engelska) WordNet-synuppsättningar som returnerats för målordsbeslut. Vi klarade de flerspråkiga aspekterna av den gemensamma uppgiften genom att använda en flerspråkig transformator för kodning av texter skrivna på antingen arabiska, engelska, franska, ryska och kinesiska. Även om våra resultat ligger efter inlämningar med toppbetyg, har det fördelen att det inte bara ger en binär flagga om två ord i deras sammanhang har samma innebörd, utan också ger en mer påtaglig utmatning i form av en rangordnad lista över (engelska) WordNet synsets oberoende av språket i inmatningstexterna. Eftersom vårt ramverk är utformat för att vara så generellt som möjligt kan det tillämpas som utgångspunkt för i princip alla språk (med stöd av den flerspråkiga transformerade arkitekturen som används) även i avsaknad av ytterligare form av språkspecifika utbildningsdata.</abstract_sv>
      <abstract_si>මේ පත්තරේ අපි අපේ පද්ධතිය පෙන්වන්නේ අපි ගොඩක් භාෂාවක් සහ ප්‍රශ්ණ භාෂාවක් වචන වචන සම්බන්ධතාවක් සෙම්වල් 2021 කියල අපේ පරීක්ෂණයේ අපි පරීක්ෂණය කළා හැම වචනයක්ම සම්පූර්ණ වචනයක්ම භාවිත කරන්න පුළුවන් විදිහට පරීක්ෂණය කරලා ඉංග්‍රීසියේ සැමැන්තික සම්පූර්ණයේ වචනයක් සඳහා සම්පූර්ණ වචනයේ  අපි බොහොම භාෂාවක් ප්‍රශ්නයක් විශේෂ කරනවා, අරාබික්, ඉංග්‍රීසි, ෆ්‍රෑන්ස්, රුසියානු සහ චීනි වල ලියපු පත්තු කොඩිය අපේ ප්‍රතිචාර පස්සේ ඉහළ ස්කෝරින්ග් ප්‍රතිචාරය පිටිපස්සේ වෙලා තියෙනවා නමුත් එයාලගේ ප්‍රතිචාරයේ වචන දෙකක් එකම අදහසක් තියෙන්නේ නැත්නම්, ඒ වගේම වචන දෙකක අපේ ක්‍රියාමාර්ගයක් පුළුවන් තරම් සාමාන්‍ය විදියට හැකි විදියට හැකි භාෂාවක් විදියට ප්‍රයෝජනයක් වෙන්න පුළුවන්, ඒක ප්‍රමාණයෙන්ම</abstract_si>
      <abstract_ta>இந்த காகிதத்தில், நாம் பல மொழியில் மற்றும் மொழியில் பகிர்ந்த செம்வால் 2021 பகிர்ந்த பணியில் பங்கிடப்பட்டுள்ளோம் என்று எங்கள் அமைப் எங்கள் சோதனைகளில், நாங்கள் அனைத்து வார்த்தைகளையும் புரிந்த சொல்லும் பாதுகாப்பு முறைமையையும் பயிற்சி செய்துள்ளோம் முறைமையை பயன்படுத்தி புரிந்து அறிவிக்கப்பட்ட தகவல் மூலம் பயிற்சி செய்த பங்கிடப்பட்ட பணியின் பல மொழி பாகங்களை நாம் வெற்றி பெற்றோம் மற்றும் பல மொழி மாற்றம் பயன்படுத்தி எழுதப்பட்டுள்ள குறியீடுகளை அரபி , ஆங்கிலத்து, ப While our results lag behind top scoring submissions, it has the benefit that it not only provides a binary flag whether two words in their context have the same meaning, but also provides a more tangible output in the form of a ranked list of (English) WordNet synsets irrespective of the language of the input texts.  எங்கள் சட்டத்தை பொதுவான முறையாக வடிவமைக்கப்பட்டுள்ளது, அடிப்படையில் எந்த மொழிக்கும் அடிப்படையாக பயன்படுத்தலாம் (பல மொழி மாற்றப்பட்ட கட்டுப்பாட்டு பணியாளரால்) க</abstract_ta>
      <abstract_ur>ہم اس کاغذ میں اپنے سیستم کو معلوم کرتے ہیں جس سے ہم ملتی زبان اور کریز زبان کی بات-in-context نامبوغی SemEval 2021 کے شریک کام میں مشارک کرتے تھے. ہمارے آزمائش میں، ہم نے تحقیق کی امکان کی کہ تمام کلمات کے مطابق ایک پاکیزہ کلمات کا احساس غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر ہم نے مشترک کام کی بہت سی اور بہت سی زبان کی نسبتوں پر غالب رہے ہیں اور ایک متعدد زبان تغییر کرنے والے کو اس طرح لکھا رہا ہے جو عربی, انگلیسی, فرانسوی, روسی اور چینی میں لکھی ہوئی پیغام کے لئے لکھی جاتی ہے۔ اگرچہ ہمارے نتیجے بالای اسکورینگ مسلمانوں کے پیچھے چھوڑ رہے ہیں، اس کے لئے فائدہ ہے کہ یہ نہ صرف ایک دوسرے پرچم دیتا ہے خواہ دو کلمات ان کے متعلق ایک ہی معنی رکھتے ہیں، بلکہ اس سے بھی زیادہ مشکل اثبات دیتا ہے جو (انگلیسی) WordNet کی ایک صف لکھی ہوئی لکھی کی صورت میں (انگلیسی جس طرح ہمارا فرمود جتنی ممکن ہو سکتا ہے جتنی عمومی ہو سکتا ہے، اسے بنیادی سے ہر زبان کے لئے (متعدد زبان کی تغییر معماری معماری کے ذریعہ مدد کی گئی) پکارا جا سکتا ہے، اگرچہ زبان کے مطابق تعلیم دیٹے کے اضافہ فرمود کے بغیر</abstract_ur>
      <abstract_uz>Bu qogʻozda biz bir tillar va har xil tillarda qismi qo'shilgan so'zni o'zgartirib turgan tizimimizni anglatamiz. SemEval 2021 bir qanday ishni qayta qilish. In our experiments, we investigated the possibility of using an all-words fine-grained word sense disambiguation system trained purely on sense-annotated data in English and draw predictions on the semantic equivalence of words in context based on the similarity of the ranked lists of the (English) WordNet synsets returned for the target words decisions had to be made for.  Biz bir necha tillar bilan bir necha bo'lgan vazifaning boshqa gaplarini ko'pchilik o'zgarishni qoʻllash uchun, arab, ingliz, Fransuzcha, Ruscha va Xitoycha tilida yozilgan matnlarni kodi. @ info: whatsthis Bizning freymimiz umumiy bo'lishi mumkin bo'lganda, bu asosiy tilga qoʻllaniladi (muloqali o'zgartirilgan arxituvni ishlab chiqarishga qoʻllaniladi) xato qoʻshimcha qoʻshimcha foydalanuvchi foydalanuvchi maʼlumot maʼlumot mavjud emas.</abstract_uz>
      <abstract_vi>Trong tờ giấy này, chúng tôi giới thiệu hệ thống mà chúng tôi đã tham gia tại các nhiệm vụ chia sẻ ngôn ngữ chung và ngôn ngữ chung. Trong các thí nghiệm của chúng tôi, chúng tôi đã điều tra khả năng sử dụng một hệ thống phân biến dạng từ ngữ hoàn hảo được đào tạo chỉ dựa trên dữ liệu ghi chú giác quan bằng tiếng Anh và những dự đoán về độ đồng nghĩa của từ ngữ cảnh dựa trên điểm giống nhau. dựa trên điểm giống nhau của các danh sách được xếp hạng của các cấu trúc (Anh) WordNet quay về vì những từ đích cần phải quyết định. Chúng tôi đã vượt qua các khía cạnh đa ngữ và ngôn ngữ khác nhau của việc chia sẻ bằng cách áp dụng một máy biến đổi đa dạng để mã hóa các văn bản được viết bằng tiếng Ả Rập, Anh, Pháp, Nga và Trung Quốc. Mặc dù kết quả của chúng ta chậm sau những ghi điểm cao, nhưng nó có lợi là nó không chỉ cung cấp một cờ nhị phân nếu hai từ trong ngữ cảnh của chúng có cùng ý nghĩa, mà còn cung cấp một kết quả hữu hình hơn dưới hình dạng một danh sách thứ hạng của các cấu trúc (Anh) WordNet bất kể ngôn ngữ của các văn bản nhập. Vì cơ sở của chúng ta được thiết kế để có thể là một cơ sở chung, nó có thể được áp dụng như một cơ sở cho bất kỳ ngôn ngữ nào (được hỗ trợ bởi kiến trúc chế biến đổi đa dạng được sử dụng) dù không có bất kỳ hình thức đào tạo ngôn ngữ cụ thể nào khác.</abstract_vi>
      <abstract_da>I denne artikel introducerer vi vores system, som vi deltog med ved den flersprogede og tværsprogede ord-i-kontekst forståelse SemEval 2021 delte opgave. I vores eksperimenter undersøgte vi muligheden for at bruge et system med finkornet ordsans, der udelukkende er trænet på sanseanmærkede data på engelsk, og tegnede forudsigelser om den semantiske ækvivalens af ord i sammenhæng baseret på ligheden af de rangerede lister af (engelske) WordNet synsæt returneret for målordsbeslutningerne skulle træffes. Vi overvandt de flersprogede og tværsprogede aspekter af den fælles opgave ved at anvende en flersproget transformator til kodning af tekster skrevet på enten arabisk, engelsk, fransk, russisk og kinesisk. Selvom vores resultater ligger bagud for topscoring indsendelser, har det den fordel, at det ikke kun giver et binært flag, om to ord i deres sammenhæng har samme betydning, men også giver et mere håndgribeligt output i form af en rangeret liste over (engelsk) WordNet synsets uanset sproget i input tekster. Da vores ramme er designet til at være så generisk som muligt, kan den anvendes som grundlæggende for stort set ethvert sprog (understøttet af den anvendte flersprogede transformerede arkitektur), selv uden yderligere form for sprogspecifikke uddannelsesdata.</abstract_da>
      <abstract_nl>In dit artikel introduceren we ons systeem waarmee we deelnamen aan de meertalige en meertalige woord-in-context discambiguation SemEval 2021 gedeelde taak. In onze experimenten onderzochten we de mogelijkheid om een all-words fine-granined word sense disambiguation systeem te gebruiken dat puur is getraind op zintuiggeannoteerde gegevens in het Engels en voorspellingen te trekken over de semantische equivalentie van woorden in context gebaseerd op de gelijkenis van de gerangschikte lijsten van de (Engelse) WordNet synsets die werden geretourneerd voor de doelwoorden waarvoor beslissingen moesten worden genomen. We overwonnen de meertalige en meertalige aspecten van de gedeelde taak door een meertalige transformator toe te passen voor het coderen van de teksten geschreven in Arabisch, Engels, Frans, Russisch en Chinees. Hoewel onze resultaten achterblijven achter de best scorende inzendingen, heeft het als voordeel dat het niet alleen een binaire vlag geeft of twee woorden in hun context dezelfde betekenis hebben, maar ook een meer tastbare output biedt in de vorm van een gerangschikte lijst van (Engelse) WordNet synsets ongeacht de taal van de invoerteksten. Omdat ons raamwerk zo generiek mogelijk is ontworpen, kan het worden toegepast als basis voor vrijwel elke taal (ondersteund door de gebruikte meertalige getransformeerde architectuur) zelfs zonder enige extra vorm van taalspecifieke trainingsgegevens.</abstract_nl>
      <abstract_bg>В тази статия представяме нашата система, с която участвахме в споделената задача за многоезично и междуезично разясняване на думата в контекста. В нашите експерименти изследвахме възможността за използване на система за изясняване на всички думи, обучена изцяло върху обозначени със смисъл данни на английски език и изготвяме прогнози за семантичната еквивалентност на думите в контекста въз основа на сходството на класираните списъци на синтезите (английски) върнати за решенията за целевите думи. Ние преодоляхме многоезичните аспекти на споделената задача чрез прилагане на многоезичен трансформатор за кодиране на текстовете, написани на арабски, английски, френски, руски и китайски. Въпреки че нашите резултати изостават от най-добрите резултати, това има ползата, че не само осигурява двоичен флаг дали две думи в техния контекст имат едно и също значение, но и осигурява по-осезаем изход под формата на класиран списък от (английски) синсети независимо от езика на входящите текстове. Тъй като нашата рамка е проектирана да бъде възможно най-обща, тя може да бъде приложена като база за основно всеки език (подкрепена от многоезичната трансформирана архитектура), дори и при липса на допълнителна форма на специфични езикови данни за обучение.</abstract_bg>
      <abstract_hr>U ovom papiru predstavljamo naš sustav s kojim smo učestvovali na zajedničkom zadatku za disambigaciju višejezičkih i međujezičkih riječi u kontekstu. U našim eksperimentima, istražili smo mogućnost upotrebe sustava disambiguacije svih riječi, koji su obučeni čisto na osjećajnim annotiranim podacima na engleskom jeziku i nacrtali predviđanja o semantičkoj ekvivalenciji riječi u kontekstu na temelju sličnosti redovih listova sinkronizacija WordNet-a koji su se vratili za ciljne riječi koje su trebale donijeti. Preživjeli smo multijezičke aspekte zajedničkog zadatka primjenjivanjem multijezičkog transformer a za kodiranje teksta napisanih na arapskom, engleskom, francuskom, ruskom i kineskom jeziku. Iako naši rezultati ostaju iza najviših podataka, imaju korist da ne samo pruža binarnu zastavu da li dvije riječi u njihovom kontekstu imaju isto značenje, nego također pružaju materijalniji izlaz u obliku rankiranog popisa (engleski) WordNet sinteta bez obzira na jezik tekstova. Budući da je naš okvir dizajniran da bude što je moguće generični, može se primjenjivati kao početnu liniju za bilo koji jezik (podržavan od višejezičkih transformiranih arhitektura zaposlenih) čak i u odsustvu bilo kojeg dodatnog oblika podataka o određenom treningu jezika.</abstract_hr>
      <abstract_ko>본고에서 우리는 상하문 분기 제거SemEval 2021 공유 임무에 참여한 다국어와 다국어 단어 분기 제거 시스템을 소개했다.우리의 실험에서 우리는 전체 단어의 세립도 의미 분리 시스템을 사용할 가능성을 연구했다. 이 시스템은 순전히 영어의 의미 주석 데이터를 바탕으로 훈련을 하고 목표어로 되돌아오는 (영어)WordNet 문법집의 정렬 목록의 유사성에 따라 상하문 중어의 의미 등가성을 예측했다.우리는 임무를 공유하는 다언어와 다언어의 문제를 극복하고 다언어 변환기를 사용하여 아랍어, 영어, 프랑스어, 러시아어와 중국어로 쓴 텍스트를 인코딩했다.비록 우리의 결과는 득점률이 가장 높은 제출에 뒤떨어졌지만, 그 장점은 상하문에 있는 두 단어가 같은 의미를 가지고 있는지를 나타내는 2진법 표지판을 제공할 뿐만 아니라, 텍스트를 입력하는 언어가 어떻든지 간에 더욱 구체적인 출력, 즉 워드넷 문법집의 순위 목록을 제공한다는 것이다.우리의 프레임워크는 가능한 한 통용될 수 있도록 설계되었기 때문에 기본적으로 모든 언어의 기선(채택된 다중 언어 변환 체계 구조에서 지원), 언어에 대한 특정한 교육 데이터가 없어도 된다.</abstract_ko>
      <abstract_de>In diesem Beitrag stellen wir unser System vor, mit dem wir an der mehrsprachigen und mehrsprachigen Wort-in-Kontext-Disambiguation SemEval 2021 teilgenommen haben. In unseren Experimenten untersuchten wir die Möglichkeit, ein rein auf sense-annotierten Daten trainiertes Ganzwortdifferenzierungssystem zu verwenden und Vorhersagen über die semantische Äquivalenz von Wörtern im Kontext basierend auf der Ähnlichkeit der Ranglisten der (englischen) WordNet-Synsets zu erstellen, die für die Zielwortentscheidungen zurückgegeben werden mussten. Wir haben die Mehrsprachigkeit und die Mehrsprachigkeit der gemeinsamen Aufgabe überwunden, indem wir einen mehrsprachigen Transformator zur Kodierung der Texte in Arabisch, Englisch, Französisch, Russisch und Chinesisch anwenden. Während unsere Ergebnisse hinter den Top-Scoring-Einreichungen zurückbleiben, hat es den Vorteil, dass es nicht nur eine Binärflagge liefert, ob zwei Wörter in ihrem Kontext die gleiche Bedeutung haben, sondern auch eine greifbare Ausgabe in Form einer Rangliste von (englischen) WordNet-Synsets unabhängig von der Sprache der Eingabetexte liefert. Da unser Framework so generisch wie möglich gestaltet ist, kann es als Basis für praktisch jede Sprache verwendet werden (unterstützt durch die verwendete mehrsprachige transformierte Architektur), selbst wenn keine zusätzliche Form von sprachspezifischen Trainingsdaten vorliegt.</abstract_de>
      <abstract_id>Dalam kertas ini, kami memperkenalkan sistem kami yang kami berpartisipasi dengan dalam misi berbagai bahasa dan saling bahasa-dalam-konteks disambiguasi SemEval 2021 berbagi. Dalam eksperimen kami, kami menyelidiki kemungkinan menggunakan semua kata-kata sistem penyelesaian sensor kata-kata yang sempurna-sempurna dilatih pada data sensor-annotasi dalam bahasa Inggris dan menggambar prediksi tentang persamaan semantis kata-kata dalam konteks berdasarkan persamaan daftar peringkat dari (Inggris) WordNet sinset yang dikembalikan untuk keputusan kata-kata sasaran harus dibuat. Kami mengatasi aspek multi lingual dari tugas bersama dengan menggunakan transformator multilingual untuk mengekodikan teks yang ditulis dalam bahasa Arab, Inggris, Perancis, Rusia dan Cina. Sementara hasil kami tertinggal di belakang pengiriman skor atas, itu memiliki keuntungan bahwa tidak hanya menyediakan bendera binari apakah dua kata dalam konteks mereka memiliki arti yang sama, tetapi juga menyediakan output yang lebih tangguh dalam bentuk daftar rangkaian dari (Inggris) WordNet sinset tidak peduli bahasa teks masukan. Karena cadangan kami dirancang untuk menjadi sebaik mungkin umum, dapat diaplikasikan sebagai dasar untuk bahasa apapun (didukung oleh arsitektur berubah berbagai bahasa yang digunakan) bahkan tanpa bentuk tambahan data pelatihan spesifik bahasa.</abstract_id>
      <abstract_fa>در این کاغذ، سیستم خودمان را معرفی می کنیم که ما با آن در کار مشترک کلمه‌های متعدد زبان و متعدد زبان‌ها و متعدد زبان‌ها مشترک کردیم. در آزمایش های ما، ما در مورد احتمال استفاده از یک سیستم ناپدید کردن کلمه‌های مثبت به کلمه‌ها تحقیق کردیم که تنها بر روی داده‌های ناپدید شده به انگلیسی آموزش می‌دهند و پیش‌بینی‌ها بر روی تعادل semantic equivalence کلمه‌ها در محیط بر اساس شبیه‌سازی لیست‌های صف‌زده‌های تفسیر WordNet برای تصمیم‌های هدف باید برای آن ما از طریق تغییر دهنده‌ی چند زبان و متوسط زبان‌های مشترک پیروز شدیم با استفاده از یک تغییر دهنده‌ی متوسط زبان‌های متوسط برای رمزبندی textهای نوشته به زبان عربی، انگلیسی، فرانسوی، روسی و چینی. در حالی که نتیجه‌های ما پشت سر تسلیم کردن اسکورینگ بالا باقی می‌ماند، سودی دارد که نه تنها یک پرچم دویینی را پیشنهاد می‌دهد که آیا دو کلمه در محیط آنها معنی مشابه دارند، بلکه همچنین یک نتیجه مشابه‌تری را در شکل یک فهرست صفحه‌ای از (انگلیسی) WordNet به ناحیه زبان همانطور که چهارچوب ما به اندازه‌ی توانایی عمومی طراحی شده است، می‌تواند به عنوان یک خط بنیادی برای هر زبانی (که توسط معماری متغیر زبانی استخدام می‌شود) حتی در وجود هیچ شکل اضافه‌ای از داده‌های آموزش ویژه زبان استفاده شود.</abstract_fa>
      <abstract_tr>Bu kagyzda biziň sistemamyzy çykyp diller we çerçe-diller bardaky sözlerimizi çykarmak üçin 2021-nji ýyldan bölegi bilen goşulýardyklaryny tanyşdyrýarys. Biziň deneylerimizde, biz hemme sözlerimiz gowy görkezilýän söz duýgulanmasy sistemasyny Iňlis dilinde ýazylan hasaplanýan maglumaty üçin ullanyp bardyk we semantik sözlerin etkinlik baglanmasynyň (Iňlis dilinde) düzülen sözleriň meňzeşligine daýan ýan ýagdaýynda çykyp bardyk. Biz bu işiň birnäçe dilli, birnäçe dilli aspektlerini arap, iňlisçe, fransuzça, Rusça we Çin çe dilinde ýazylan tekstleri kodlamak üçin üstüne getirdik. netijelerimiz üst atlama göndermeleriniň arkasynda geçirilýän bolsa üçin bu ýerde diňe binary flag diňe iki sözleriniň bir a ňladygyny üýtgetmeli däldir, emma WordNet-iň satyrly sözleriniň (iňlisçe) düzümlenmegi bilen tanyş edilmegi üçin bir faydaly bar. Biziň çerýämiz mümkin döwletli bolmagy üçin tasarlanýar. Bu aslynda islendik diller üçin baseline bolup biler (köp dilli üýtgedilen arhitektura tarapyndan gollanýar) diller takyk bilim maglumatynyň ýok bolsa hem.</abstract_tr>
      <abstract_sw>Katika karatasi hii, tunaonyesha mfumo wetu ambao tulishiriki katika neno la lugha mbalimbali na katika muktadha wa tofauti wa lugha SemEval 2021. Katika majaribio yetu, tulichunguza uwezekano wa kutumia mfumo wa maneno mzuri wa kutofautisha maneno yaliyofanana na maneno yaliyofundishwa tu kwa taarifa zenye maana yanayoelezwa kwa Kiingereza na kuchora kutabiri kuhusu usawa wa maneno yanayofanana na mukhtadha katika muktadha unaofanana na orodha za rangi zilizopangwa katika orodha za WordNet zilizorudishwa kwa ajili ya maamuzi ya maneno yanayopaswa kufanyika. Tumeshinda mambo mengi ya lugha, na mambo mengi yanayoshirikiana kwa kutumia mabadiliko ya lugha mbalimbali kwa ajili ya kuandika maandishi yaliyoandikwa kwa lugha ya Kiarabu, Kiingereza, Kifaransa, Urusi na Kichina. Wakati matokeo yetu yanabaki nyuma ya matamshi ya juu yanayotumiwa, ni faida kwamba si tu hutoa bendera ya binadamu ikiwa maneno mawili katika muktadha wao una maana sawa, lakini pia inatoa matokeo yanayofanana zaidi katika mtindo wa orodha ya rangi (Kiingereza) WordNet ikitengeneza bila kujali lugha ya maandishi ya maandishi ya input. Kama mfumo wetu unavyolengwa kuwa wa kawaida kama inavyowezekana, inaweza kutumika kama msingi wa lugha yoyote (inayosaidiwa na majengo ya mabadiliko ya lugha mbalimbali) hata kutokuwepo na a in a yoyote ya mafunzo maalum ya lugha.</abstract_sw>
      <abstract_af>In hierdie papier, ons introduseer ons stelsel wat ons gedeel het by die multitaalske en kruistale woord-in-context-disambiguasie SemEval 2021 gedeelde taak. In ons eksperimente het ons ondersoek die moontlikheid van gebruik van 'n alle woorde fyn-kornerede woord sens ondersoek stelsel wat suiwer op sens-annotateerde data in Engels opgevoer is en voorsoek van die semantiese gelykenis van woorde in konteks gebaseer op die gelykenis van die rangeerde lyste van die (Engels) WordNet-sinkronisasie wat teruggegaan het vir die doel woorde besluit moet wees. Ons het die veelvuldige, en kruistale aspekte van die gedeelde taak oorweldig deur 'n veelvuldige transformeerder te wend vir kodering van die teks geskrywe in óf Arabs, Engels, Frans, Russies en Sjinees. Terwyl ons resultate agter boonste skoring onderstellings, het dit die voordeel dat dit nie net 'n binêre vlaggie verskaf of twee woorde in hul konteks dieselfde betekening het, maar ook verskaf 'n meer tangible uitvoer in die vorm van 'n rangeerde lys van (Engels) WordNet sinkroniseer ongeag van die taal van die invoer teks. Soos ons raamwerk ontwerp is om so genereek as moontlik te wees, kan dit as 'n basislin aanwend word vir basies enige taal (ondersteun deur die multitaalske transformeerde arkitektuur wat gebruik is) selfs in die absence van enige addisionele vorm van taal spesifieke onderwerking data.</abstract_af>
      <abstract_sq>Në këtë letër, ne prezantojmë sistemin tonë me të cilin morëm pjesë në detyrën e përbashkët të fjalës në kontekst të shumëgjuhësisë dhe ndërgjuhësisë SemEval 2021. Në eksperimentet tona, ne hetuam mundësinë e përdorimit të një sistemi të zhdukjes së kuptimit të të gjitha fjalëve me kokrra të holla të kuptimit të fjalëve të trajnuar thjesht në të dhënat e anotuara me kuptim në anglisht dhe të vizatojmë parashikime mbi ekuivalencën semantike të fjalëve në kontekst bazuar në ngjashmërinë e listave të renditura të sintezave (anglisht) WordNet të kthyera për fjalët objektive për të cilat duhej të merreshin vendi Ne kapërcyem aspektet shumëgjuhësore të detyrës së përbashkët duke aplikuar një transformues shumëgjuhësor për kodimin e teksteve të shkruara në arabisht, anglisht, francez, rus dhe kinez. Ndërsa rezultatet tona mbeten prapa paraqitjeve kryesore, ajo ka përfitim që jo vetëm ofron një flamur binar nëse dy fjalë në kontekstin e tyre kanë të njëjtën kuptim, por gjithashtu ofron një dalje më të prekshme në form ën e një liste të renditur të sintezave (angleze) WordNet pavarësisht nga gjuha e teksteve të hyrjes. Ndërsa kuadri ynë është dizajnuar për të qenë sa më gjenerik që të jetë e mundur, ai mund të aplikohet si bazë për çdo gjuhë (mbështetur nga arkitektura shumëgjuhëse e transformuar e punësuar) edhe në mungesën e çdo forme shtesë të të dhënave të trainimit specifik gjuhës.</abstract_sq>
      <abstract_hy>Այս թղթի մեջ մենք ներկայացնում ենք մեր համակարգը, որի հետ մենք մասնակցել էինք բառերի բառերի բառերի բառերի բառերի բառերի բառերի բառերի բառերի բառերի բառերի բառերի բառերի բառերի բառերի բառերի բառերի բառերի բառերի բառերի բառ In our experiments, we investigated the possibility of using an all-words fine-grained word sense disambiguation system trained purely on sense-annotated data in English and draw predictions on the semantic equivalence of words in context based on the similarity of the ranked lists of the (English) WordNet synsets returned for the target words decisions had to be made for.  Մենք հաղթահարեցինք ընդհանուր խնդրի բազմալեզվով և փոխլեզվով ասպեկտները, կիրառելով բազլեզվով վերափոխողը՝ գրված տեքստերի կոդավորման համար արաբերեն, անգլերեն, ֆրանսիացեն, ռուս և չինարեն: Մինչդեռ մեր արդյունքները մնում են ամենաբարձր գնահատականների ներկայացումների ետևում, այն առավելություն ունի այն, որ այն ոչ միայն տրամադրում է երկու դրոշ, թե արդյոք երկու բառ իրենց կոնտեքստում ունեն նույն իմաստը, այլ նաև տրամադրում է ավելի շոշափելի արտադրություն (անգլերեն) WordNet սինսետի դասակարգ Քանի որ մեր կառուցվածքը այնքան ընդհանուր է, որքան հնարավոր է, այն կարող է կիրառվել որպես հիմք ցանկացած լեզվի համար (աջակցված բազլեզու վերափոխված ճարտարապետության կողմից), նույնիսկ լեզվի մասնավոր ուսուցման տվյալների բացակայության դեպքում:</abstract_hy>
      <abstract_am>በዚህ ፕሮግራም፣ የብዙ ቋንቋ እና የቋንቋ ቋንቋ-ቋንቋ ቃሎችን በተካፈሉት ስርዓታችንን እናሳውቃለን፡፡ በፈተናዎቻችን ውስጥ፣ የቃላትን ሁሉ የተመሳሳይ ቃላት አካባቢ ስርዓት በንግግሊዝኛ ቃላት የተጠቃሚ ዳታዎችን በተለየን እና በይንግሊዝኛ የተለየ እና በተለያዩ ቃላት (እንግሊዝኛ) የተመሳሳይ ዝርዝሮች (እንግሊዝኛ) የተደረገውን የቃላት ዝርዝሮች በመስጠት የተመሳሳይ የቃላትን አስተያየት ስርዓት ማቀናቀል እና ለመፈለግ እንዲያስፈልጋል፡፡ We overcame the multi,-and cross-lingual aspects of the shared task by applying a multilingual transformer for encoding the texts written in either Arabic, English, French, Russian and Chinese.  ፍሬዎቻችን በላይ አቀማመጥ ጥቅም ሲቀሩ፣ ሁለት ቃላት በአካባቢቸው አንድ ማህበረት ቢኖሩ ብቻ ሳይሆን፣ ነገር ግን በንግግሊዝና (እንግሊዝኛ) የቃላት ጽሑፎች ቢሆን ከንግግር ቋንቋ ምንም እንኳ ቢሆን ቃሌን ድምፅ ማሰናከል ይችላል፡፡ የፊደላችን ሥርዓት እንደ ጠቃሚ ሆኖ እንደሚቻል፣ በአዲስ ቋንቋ (በብዙ ቋንቋ የተለወጠው የመዝገብ ግንኙነት የተደገመ)፣ ምንም ምሳሌ የቋንቋ የተለወጠውን የድምፅ መረጃዎች ባይኖር እንኳ ቢሆንም፡፡</abstract_am>
      <abstract_az>Bu kağıtda, çoxlu dil və çoxlu dil sözlərin-in-context disambiguation semiEval 2021 paylaşılan işdə olan sistemimizi tanıdırıq. Bizim təcrübələrimizdə, bütün sözləri istifadə etmək mümkünlüyünü təhsil etdik və məqsəd sözlərin çəkilməsi üçün qaytarılmış WordNet synsets listlərinin bənzərinə dayanan semantik məlumatların bərabər sistemini təhsil etdik. Biz paylaşılmış işin çoxlu, çoxlu dilli aspektlərini ərəbcə, İngilizce, Fransız, Rus və Çincə yazılmış məktubları kodlamaq üçün çoxlu dilli transformatör uygulayıb üstün etdik. Sonuçlarımız yuxarı gözləmə müsəlmanlarının arxasında qalaraq, bunun faydası ancaq iki sözlərin məsəlinə eyni məsəli olmadığı üçün binar bayrağını sağlamaq üçün istifadə edir, lakin daxilində də WordNet sinsets dilinin dərəcəli dərəcəli bir listesinin məsəlinə baxmayaraq daha münasibdir. Bizim qurğumuz mümkün olduğu qədər generik olmaq üçün müəyyən edildiyi kimi, bu qurğumuz hər dil üçün (çoxlu dil dəyişdirilmiş arhitektura dəstəklənmiş) hətta dil təhsil məlumatlarının əlavə edilməsi üçün istifadə edilə bilər.</abstract_az>
      <abstract_bn>In this paper, we introduce our system that we participated with at the multilingual and cross-lingual word-in-context disambiguation SemEval 2021 shared task.  আমাদের পরীক্ষার মধ্যে আমরা অনুসন্ধান করেছি যে সকল শব্দের ভালোভাবে গুরুত্বপূর্ণ বিভ্রান্তির মান ব্যবস্থা ব্যবহার করার সম্ভাবনা কেবল ইংরেজী ভাষায় পরিচিত তথ্য প্রশিক্ষণ প্রদান করা হয়েছে এবং তাদের প্রেক্ আমরা বহুভাষায় প্রতিযোগিতায় জয়ী হয়েছি- এবং শেয়ার কর্মকাণ্ডের ক্ষেত্রে বিভিন্ন ভাষার ক্ষেত্রে একটি বহুভাষায় পরিবর্তনের প্রয়োগ করেছি আরবী, ইং যখন আমাদের ফলাফল শীর্ষ সংক্রান্ত প্রদানের পেছনে রাখে, তখন এটি কেবল একটি বাইনারী পতাকা প্রদান করে না যে তাদের প্রেক্ষাপটে দুই শব্দের একই মানে আছে কিনা, কিন্তু তারা ইনপুট ট টেক্সটের ভাষার যেহেতু আমাদের ফ্রেম পরিকল্পনা যেমন সম্ভব তা সাধারণ ভাষার জন্য একটি বেসেলাইন হিসেবে প্রয়োগ করা যাবে (মাল্টিভাষায় পরিবর্তিত কাঠামোর দ্বারা সমর্থিত) এমনকি ভাষার</abstract_bn>
      <abstract_bs>U ovom papiru predstavljamo naš sistem s kojim smo učestvovali na delovanju multijezičkih i međujezičkih riječi u kontekstu disambiguacije polovine Evala 2021. U našim eksperimentima, istražili smo mogućnost da koristimo sistem disambiguacije sa svim riječima koji su izraženi čisto na osjećajnim notiranim podacima na engleskom jeziku i nacrtamo predviđanja o semantičkoj ekvivalenciji riječi u kontekstu na temelju sličnosti redovih listova sinkronizacija WordNet-a koji su se vratili za ciljne reči koje su trebale donijeti. Preživjeli smo multijezičke aspekte zajedničkog zadatka primjenjivanjem multijezičkog transformer a za kodiranje teksta napisanih na arapskom, engleskom, francuskom, ruskom i kineskom jeziku. Dok naši rezultati ostaju iza najviših podataka, imaju korist da ne samo pruža binarnu zastavu da li dvije riječi u njihovom kontekstu imaju isto značenje, već i pružaju materijalniji izlaz u obliku redovne liste WordNet-a bez obzira na jezik tekstova. Pošto je naš okvir dizajniran da bude najgeneričniji što je moguće, može se primjenjivati kao osnovna linija za bilo koji jezik (podržavan od strane multijezičke transformirane arhitekture zaposlene) čak i u odsustvu bilo kojeg dodatnog oblika podataka o određenom treningu jezika.</abstract_bs>
      <abstract_ca>En aquest paper, introduïm el nostre sistema amb el qual vam participar en la tasca compartida SemEval 2021 de desambiguació de paraules multilingües i translingües. In our experiments, we investigated the possibility of using an all-words fine-grained word sense disambiguation system trained purely on sense-annotated data in English and draw predictions on the semantic equivalence of words in context based on the similarity of the ranked lists of the (English) WordNet synsets returned for the target words decisions had to be made for.  Vam superar els aspectes multilingües de la tasca compartida aplicant un transformador multilingüe per codificar els textos escrits en àrab, anglès, francès, rus i xinès. While our results lag behind top scoring submissions, it has the benefit that it not only provides a binary flag whether two words in their context have the same meaning, but also provides a more tangible output in the form of a ranked list of (English) WordNet synsets irrespective of the language of the input texts.  Com que el nostre marc està dissenyat per ser el més genèric possible, pot ser aplicat com a base per a qualsevol llenguatge bàsicament (suportat per l'arquitectura transformada multilingüe empregada) fins i tot en ausencia de qualsevol forma adicional de dades de formació específica.</abstract_ca>
      <abstract_et>Käesolevas dokumendis tutvustame oma süsteemi, millega osalesime mitmekeelsel ja keeleülesel sõna-kontekstis selgitamisel SemEval 2021 jagatud ülesandel. Oma eksperimentides uurisime võimalust kasutada kõigi sõnadega peeneteralist sõnade eristamise süsteemi, mis on koolitatud puhtalt inglise keelsetel tähendustega andmetel ning joonistasime prognoose sõnade semantilise samaväärsuse kohta kontekstis, lähtudes (inglise) WordNeti sündmuste järjestatud nimekirjade sarnasusest, mis olid tagastatud sihtsõnade otsuste tegemiseks. Ühise ülesande mitmekeelsetest aspektidest ületasime, rakendades mitmekeelset muundurit araabia, inglise, prantsuse, vene ja hiina keeles kirjutatud tekstide kodeerimiseks. Kuigi meie tulemused jäävad kõige paremini hinnatud esitustest maha, on see eelis, et see mitte ainult ei paku binaarlipp, kas kaks sõna oma kontekstis on sama tähendus, vaid pakub ka käegakatsutavamat väljundit (inglise) WordNeti sündmuste järjestatud nimekirja vormis olenemata sisendtekstide keelest. Kuna meie raamistik on loodud nii üldiseks kui võimalik, võib seda rakendada põhimõtteliselt mis tahes keele puhul (mida toetab kasutatud mitmekeelne muundatud arhitektuur), isegi kui puuduvad täiendavad keelespetsiifilised koolitusandmed.</abstract_et>
      <abstract_cs>V tomto článku představujeme náš systém, se kterým jsme se podíleli na vícejazyčném a vícejazyčném rozjasňování slova v kontextu SemEval 2021 sdíleném úkolu. V našich experimentech jsme zkoumali možnost použití celoslovně jemnozrnného rozjasňovacího systému slovních smyslů trénovaného čistě na smyslových anotovaných datech v angličtině a nakreslit predikce sémantické ekvivalence slov v kontextu na základě podobnosti hodnocených seznamů (anglických) WordNet synsetů vrácených pro cílová slova. Překonali jsme vícejazyčné aspekty společného úkolu aplikací vícejazyčného transformátoru pro kódování textů napsaných v arabštině, angličtině, francouzštině, ruštině a čínštině. Zatímco naše výsledky zaostávají za nejlepšími bodovými příspěvky, má to tu výhodu, že nejen poskytuje binární příznak, zda dvě slova v jejich kontextu mají stejný význam, ale také poskytuje hmatatelnější výstup v podobě hodnoceného seznamu (anglických) WordNet synsetů bez ohledu na jazyk vstupních textů. Vzhledem k tomu, že náš rámec je navržen tak, aby byl co nejobecnější, může být použit jako základní základ pro v podstatě jakýkoli jazyk (podporovaný použitým vícejazyčným transformovaným architekturám) i v případě neexistence jakékoli další formy údajů o výcviku specifickém pro jazyky.</abstract_cs>
      <abstract_fi>Tässä artikkelissa esittelemme järjestelmämme, jolla osallistuimme monikieliseen ja monikieliseen sana-in-konteksti-erotteluun SemEval 2021 jaettuun tehtävään. Tutkimme kokeiluissamme mahdollisuutta käyttää pelkkää englanninkielistä merkityihin tietoihin perustuvaa sanaaistin hienojakoista erottelujärjestelmää ja piirsimme ennusteita sanojen semanttisesta vastaavuudesta kontekstissa niiden (englanninkielisten) WordNet-synzettien pistelistojen samankaltaisuuden perusteella, jotka palautettiin kohdesanapäätöksiin. Ylitimme yhteisen tehtävän monikielisyyden ja monikielisyyden soveltamalla monikielistä muuntajaa arabiaksi, englanniksi, ranskaksi, venäjäksi ja kiinaksi kirjoitettujen tekstien koodaamiseen. Vaikka tuloksemme ovat jäljessä top scoring submissions, se on etu, että se ei vain tarjoa binary lippu, onko kaksi sanaa kontekstissa sama merkitys, mutta myös tarjoaa konkreettisemman tuotoksen muodossa muodossa ranking luettelo (Englanti) WordNet synsets riippumatta kieli syöttötekstejä. Koska viitekehyksemme on suunniteltu mahdollisimman yleisluonteiseksi, sitä voidaan soveltaa lähtökohtana periaatteessa mille tahansa kielelle (jota tukee käytetty monikielinen muunnettu arkkitehtuuri), vaikka mitään muuta kielikohtaista koulutustietoa ei olisikaan.</abstract_fi>
      <abstract_jv>Nan pentungkat iki, kita nggunakake sistem awak dhéwé ngejaraké karo multilenguang lan kelangan-langa-lan-kontext dismbigasi semebal 2020 1 nggawe gerakan bantuan. Nang dhéwé éntuk éntukno, awak dhéwé nggunian perusahaan kelas-kelas coral sistem sing beraksi dadi nyong ngregani soko dolanan ingles karo perusahaan karo perusahaan sematik dhéwé lan tambah kuwi nggunian sing dibutuhé perusahaan karo perusahaan langgar sampek podho akhar ngregani soko perusahaan kelas-word Awak dhéwé wis mbukakipun ajeng-ajeng langgar sampek karo nggawe lan ijol-ijol kuwi nggawe ngubah sing karo akeh banter nggawe ngubah akeh lan ujol-ijolan karo akeh rambarat, Inggris, Perancis, Russisak lan Cino kuwi. politenessoffpolite"), and when there is a change ("assertivepoliteness Awak dhéwé éntuk sistem sing disenyarno kanggo tinggal gawe jeneng, iso disenyongno ngono nggawe alêng (supoyata karo akeh multilanggar alêng nggawe arêtati cara-cara nggawe gerakan) segala macem kuwi dianggap akeh perusahaan anyari dadi kapan banget.</abstract_jv>
      <abstract_sk>V tem prispevku predstavljamo naš sistem, s katerim smo sodelovali pri večjezični in medjezični razločitvi besed v kontekstu SemEval 2021 skupni nalogi. V naših eksperimentih smo raziskovali možnost uporabe vseh besednih drobnozrnatega sistema za razjasnitev besednih pomenov, usposobljenega zgolj na podlagi podatkov s pomenom v angleškem jeziku, in pripravili napovedi o semantični enakovrednosti besed v kontekstu na podlagi podobnosti razvrščenih seznamov (angleških) WordNet sinov, vrnjenih za odločitve o ciljnih besedah. Večjezične in večjezične vidike skupne naloge smo premagali z uporabo večjezičnega transformatorja za kodiranje besedil, napisanih v arabščini, angleščini, francoščini, ruščini in kitajščini. Čeprav naši rezultati zaostajajo za najboljšimi rezultati, ima to prednost, da ne le zagotavlja binarno zastavo, ali imata dve besedi v svojem kontekstu enak pomen, temveč zagotavlja tudi bolj oprijemljiv rezultat v obliki razvrščenega seznama (angleških) WordNetovih sklopov ne glede na jezik vhodnih besedil. Ker je naš okvir zasnovan tako, da je čim bolj generičen, ga je mogoče uporabiti kot osnovno osnovo za vsak jezik (ki ga podpira uporabljena večjezična preoblikovana arhitektura), tudi če ni nobene dodatne oblike podatkov o usposabljanju, specifičnih za jezik.</abstract_sk>
      <abstract_ha>Ga wannan takardan, za mu ƙara da fasalinmu wanda muka yi musunsa da shi a cikin maganar mulki-lugha da ke cikin-context-rabo na SemEal 2021. Daga jarrabõyinmu, mun yi ƙidãya a kan ka yi amfani da tsarin maganar cewa na cikakken duk magana mai kyau na tsari da aka yi wa tsari kawai a kan data masu hankali da aka yi wa Ingiriya kuma mu nuna wani littafa masu daidaita da maganar idan an daidaita ko da misãlin takardar maganar (Ingiriya) da aka canza a koma zuwa ga kalmõmin da za'a yi amfani da shi. Tuna rinjãya masu mulki -kuma masu ƙaranci cikin aikin da aka raba shi, da kuma mu yi amfani da wata shigetarwa na mulki-lingui dõmin mu kodi littãfin da aka rubũta cikin harshe, Kiarabu, Kifaransa, Ruushi da Kiniya. A lokacin da matsalayinmu ke ƙara bakin fili masu ƙari da akan ƙanshi, sai yana da amfani da ya ba ta ƙayyade flage biyu kawai, ko da maganar biyu a cikin mazaɓa guda, kuma amma yana da wani ƙari mai bayani cikin tsarin wani jerin ranked (Ingiriya) Tsarinsa na Tsariya Kama da aka designe firam masu iya kima kamar iya iya yiwuwa, za'a iya amfani da shi kamar bango wa lugha masu bastarwa (ana ƙarfafa da bakin muhimman na musamman da mulki-lingui wanda aka yi wa aikin shi) kõ dã ba'a sami wani tsari na ƙarami ko wani tsari na tsarin mutane na lugha.</abstract_ha>
      <abstract_bo>ང་ཚོའི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོའི་མ་ལག་གི་སྣ་སྐད་ཡིག་དང་སྐད་ཡིག་གཟུགས་པའི་ནང་དུ་རྒྱལ་སྤྲོད་ཀྱི་ལས་འགུལ་འདོགས་པ་ལྟར་ ཨ In our experiments, we investigated the possibility of using an all-words fine-grained word sense disambiguation system trained purely on sense-annotated data in English and draw predictions on the semantic equivalence of words in context based on the similarity of the ranked lists of the ང་ཚོས་དབར་གཅིག་གི་སྣ་ཚོགས་དང་སྐད་ཡིག་ཆ་འདྲ་བར་མཉམ་དུ་བཏང་བ་ཡིན་པའི་འཇུག་སྣོད་ཀྱི་རྣམ་པ་ཞིག་སྤྱོད་བཞིན་པའི་འགྱུར་བ་ཞིག་བྱས་ནས While our results lag behind top scoring submissions, it has the benefit that it has not only provides a binary flag whether two words in their context have the same meaning, but also provides a more tangible output in the form of a ranked list of (English) WordNet synsets irrespective of the language of the input texts. ང་ཚོའི་གཞུང་སྒྲིག་ལ་ཆ་རྐྱེན་གྱིས་ཕན་ཆེར་བ་བཟོས་ཡོད་པ་ལས། སྐད་ཡིག་ཅིག་གཙོ་རིམ་ལ་ཉེར་སྤྱོད་ཐུབ་པས།</abstract_bo>
      <abstract_he>In this paper, we introduce our system that we participated with at the multilingual and cross-lingual word-in-context disambiguation SemEval 2021 shared task.  בניסויים שלנו, חקרנו את האפשרות להשתמש במערכת ניתוח ביטוי מילים עם כל מילים מוגזמות מוגזמות, מאומנת טהור על נתונים מוגזמים באנגלית, ולצייר צפיות על השוואה סמנטית של מילים בקונקסט מבוססת על הדומה של רשימות המדרגות של סינסטים (אנגלית) WordNet שנחזרו עבור המילים המטרה החלטות היו צריכות לקבל. We overcame the multi,-and cross-lingual aspects of the shared task by applying a multilingual transformer for encoding the texts written in either Arabic, English, French, Russian and Chinese.  While our results lag behind top scoring submissions, it has the benefit that it not only provides a binary flag whether two words in their context have the same meaning, but also provides a more tangible output in the form of a ranked list of (English) WordNet synsets irrespective of the language of the input texts.  כיוון שהמסגרת שלנו מתוכננת כדי להיות גנרלית ככל האפשר, היא יכולה להיות מתוכננת כבסיסית לכל שפה (תומכת על ידי הארכיטקטורה המפורסמת רבות שפות שמשתמשת) אפילו בהיעדרות כל צורה נוספת של נתוני אימון ספציפי לשפה.</abstract_he>
      </paper>
    <paper id="20">
      <title>ECNU_ICA_1 SemEval-2021 Task 4 : Leveraging Knowledge-enhanced Graph Attention Networks for Reading Comprehension of Abstract Meaning<fixed-case>ECNU</fixed-case>_<fixed-case>ICA</fixed-case>_1 <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 4: Leveraging Knowledge-enhanced Graph Attention Networks for Reading Comprehension of Abstract Meaning</title>
      <author><first>Pingsheng</first><last>Liu</last></author>
      <author><first>Linlin</first><last>Wang</last></author>
      <author><first>Qian</first><last>Zhao</last></author>
      <author><first>Hao</first><last>Chen</last></author>
      <author><first>Yuxi</first><last>Feng</last></author>
      <author><first>Xin</first><last>Lin</last></author>
      <author><first>Liang</first><last>He</last></author>
      <pages>183–188</pages>
      <abstract>This paper describes our <a href="https://en.wikipedia.org/wiki/System">system</a> for SemEval-2021 Task 4 : Reading Comprehension of Abstract Meaning. To accomplish this task, we utilize the Knowledge-Enhanced Graph Attention Network (KEGAT) architecture with a novel semantic space transformation strategy. It leverages heterogeneous knowledge to learn adequate evidences, and seeks for an effective semantic space of abstract concepts to better improve the ability of a machine in understanding the abstract meaning of natural language. Experimental results show that our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves strong performance on this task in terms of both <a href="https://en.wikipedia.org/wiki/Perception">imperceptibility</a> and <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">nonspecificity</a>.</abstract>
      <url hash="f5eeda12">2021.semeval-1.20</url>
      <doi>10.18653/v1/2021.semeval-1.20</doi>
      <bibkey>liu-etal-2021-ecnu</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
    </paper>
    <paper id="21">
      <title>LRG at SemEval-2021 Task 4 : Improving Reading Comprehension with Abstract Words using Augmentation, Linguistic Features and Voting<fixed-case>LRG</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 4: Improving Reading Comprehension with Abstract Words using Augmentation, Linguistic Features and Voting</title>
      <author><first>Abheesht</first><last>Sharma</last></author>
      <author><first>Harshit</first><last>Pandey</last></author>
      <author><first>Gunjan</first><last>Chhablani</last></author>
      <author><first>Yash</first><last>Bhartia</last></author>
      <author><first>Tirtharaj</first><last>Dash</last></author>
      <pages>189–198</pages>
      <abstract>We present our approaches and methods for SemEval-2021 Task-4 Reading Comprehension of Abstract Meaning. Given a question with a fill-in-the-blank, and a corresponding context, the task is to predict the most suitable word from a list of 5 options. There are three subtasks : Imperceptibility, Non-Specificity and <a href="https://en.wikipedia.org/wiki/Intersection">Intersection</a>. We use encoders of transformers-based models pretrained on the MLM task to build our Fill-in-the-blank (FitB) models. Moreover, to model imperceptibility, we define certain linguistic features, and to model non-specificity, we leverage information from <a href="https://en.wikipedia.org/wiki/Hypernymy">hypernyms</a> and <a href="https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy">hyponyms</a> provided by a <a href="https://en.wikipedia.org/wiki/Lexical_database">lexical database</a>. Specifically, for non-specificity, we try out augmentation techniques, and other <a href="https://en.wikipedia.org/wiki/Statistics">statistical techniques</a>. We also propose variants, namely Chunk Voting and Max Context, to take care of input length restrictions for BERT, etc. Additionally, we perform a thorough ablation study, and use Integrated Gradients to explain our predictions on a few samples. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> achieve accuracies of 75.31 % and 77.84 %, on the test sets for subtask-I and subtask-II, respectively. For subtask-III, we achieve accuracies of 65.64 % and 64.27 %.</abstract>
      <url hash="57a8c4f6">2021.semeval-1.21</url>
      <doi>10.18653/v1/2021.semeval-1.21</doi>
      <bibkey>sharma-etal-2021-lrg</bibkey>
      <pwccode url="https://github.com/gchhablani/ReCAM" additional="false">gchhablani/ReCAM</pwccode>
    </paper>
    <paper id="23">
      <title>NLP-IIS@UT at SemEval-2021 Task 4 : Machine Reading Comprehension using the Long Document Transformer<fixed-case>NLP</fixed-case>-<fixed-case>IIS</fixed-case>@<fixed-case>UT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 4: Machine Reading Comprehension using the Long Document Transformer</title>
      <author><first>Hossein</first><last>Basafa</last></author>
      <author><first>Sajad</first><last>Movahedi</last></author>
      <author><first>Ali</first><last>Ebrahimi</last></author>
      <author><first>Azadeh</first><last>Shakery</last></author>
      <author><first>Heshaam</first><last>Faili</last></author>
      <pages>205–210</pages>
      <abstract>This paper presents a technical report of our submission to the 4th task of SemEval-2021, titled : Reading Comprehension of Abstract Meaning. In this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, we want to predict the correct answer based on a question given a context. Usually, contexts are very lengthy and require a large <a href="https://en.wikipedia.org/wiki/Receptive_field">receptive field</a> from the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a>. Thus, common contextualized language models like BERT miss fine representation and performance due to the limited capacity of the input tokens. To tackle this problem, we used the longformer model to better process the sequences. Furthermore, we utilized the <a href="https://en.wikipedia.org/wiki/Methodology">method</a> proposed in the longformer benchmark on wikihop dataset which improved the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> on our <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task data</a> from (23.01 % and 22.95 %) achieved by the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baselines</a> for subtask 1 and 2, respectively, to (70.30 % and 64.38 %).</abstract>
      <url hash="cba6750a">2021.semeval-1.23</url>
      <doi>10.18653/v1/2021.semeval-1.23</doi>
      <bibkey>basafa-etal-2021-nlp</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wikihop">WikiHop</pwcdataset>
    </paper>
    <paper id="31">
      <title>HamiltonDinggg at SemEval-2021 Task 5 : Investigating Toxic Span Detection using RoBERTa Pre-training<fixed-case>H</fixed-case>amilton<fixed-case>D</fixed-case>inggg at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 5: Investigating Toxic Span Detection using <fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a Pre-training</title>
      <author><first>Huiyang</first><last>Ding</last></author>
      <author><first>David</first><last>Jurgens</last></author>
      <pages>263–269</pages>
      <abstract>This paper presents our system submission to task 5 : Toxic Spans Detection of the SemEval-2021 competition. The <a href="https://en.wikipedia.org/wiki/Competition">competition</a> aims at detecting the spans that make a toxic span toxic. In this paper, we demonstrate our system for detecting toxic spans, which includes expanding the toxic training set with Local Interpretable Model-Agnostic Explanations (LIME), fine-tuning RoBERTa model for detection, and error analysis. We found that feeding the model with an expanded training set using Reddit comments of polarized-toxicity and labeling with LIME on top of logistic regression classification could help RoBERTa more accurately learn to recognize toxic spans. We achieved a span-level F1 score of 0.6715 on the testing phase. Our quantitative and qualitative results show that the predictions from our <a href="https://en.wikipedia.org/wiki/System">system</a> could be a good supplement to the gold training set’s annotations.</abstract>
      <url hash="cea17923">2021.semeval-1.31</url>
      <attachment type="OptionalSupplementaryMaterial" hash="38840fbc">2021.semeval-1.31.OptionalSupplementaryMaterial.zip</attachment>
      <doi>10.18653/v1/2021.semeval-1.31</doi>
      <bibkey>ding-jurgens-2021-hamiltondinggg</bibkey>
    </paper>
    <paper id="32">
      <title>WVOQ at SemEval-2021 Task 6 : BART for Span Detection and Classification<fixed-case>WVOQ</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 6: <fixed-case>BART</fixed-case> for Span Detection and Classification</title>
      <author><first>Cees</first><last>Roele</last></author>
      <pages>270–274</pages>
      <abstract>Simultaneous span detection and classification is a <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> not currently addressed in standard NLP frameworks. The present paper describes why and how an EncoderDecoder model was used to combine span detection and <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> to address subtask 2 of SemEval-2021 Task 6.</abstract>
      <url hash="c1c2908b">2021.semeval-1.32</url>
      <doi>10.18653/v1/2021.semeval-1.32</doi>
      <bibkey>roele-2021-wvoq</bibkey>
      <pwccode url="https://github.com/ceesroele/SemEval-2021-Task-6" additional="false">ceesroele/SemEval-2021-Task-6</pwccode>
    </paper>
    <paper id="33">
      <title>HumorHunter at SemEval-2021 Task 7 : Humor and Offense Recognition with Disentangled Attention<fixed-case>H</fixed-case>umor<fixed-case>H</fixed-case>unter at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 7: Humor and Offense Recognition with Disentangled Attention</title>
      <author><first>Yubo</first><last>Xie</last></author>
      <author><first>Junze</first><last>Li</last></author>
      <author><first>Pearl</first><last>Pu</last></author>
      <pages>275–280</pages>
      <abstract>In this paper, we describe our system submitted to SemEval 2021 Task 7 : HaHackathon : Detecting and Rating Humor and Offense. The task aims at predicting whether the given text is humorous, the average humor rating given by the annotators, and whether the humor rating is controversial. In addition, the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> also involves predicting how offensive the text is. Our approach adopts the DeBERTa architecture with disentangled attention mechanism, where the attention scores between words are calculated based on their content vectors and relative position vectors. We also took advantage of the pre-trained language models and fine-tuned the DeBERTa model on all the four subtasks. We experimented with several BERT-like structures and found that the large DeBERTa model generally performs better. During the evaluation phase, our system achieved an <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> of 0.9480 on subtask 1a, an RMSE of 0.5510 on subtask 1b, an <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> of 0.4764 on subtask 1c, and an RMSE of 0.4230 on subtask 2a (rank 3 on the leaderboard).</abstract>
      <url hash="8eed6474">2021.semeval-1.33</url>
      <doi>10.18653/v1/2021.semeval-1.33</doi>
      <bibkey>xie-etal-2021-humorhunter</bibkey>
    </paper>
    <paper id="34">
      <title>Grenzlinie at SemEval-2021 Task 7 : Detecting and Rating Humor and Offense<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 7: Detecting and Rating Humor and Offense</title>
      <author><first>Renyuan</first><last>Liu</last></author>
      <author><first>Xiaobing</first><last>Zhou</last></author>
      <pages>281–285</pages>
      <abstract>This paper introduces the result of Team Grenzlinie’s experiment in SemEval-2021 task 7 : HaHackathon : Detecting and Rating Humor and Offense. This <a href="https://en.wikipedia.org/wiki/Task_(computing)">task</a> has two <a href="https://en.wikipedia.org/wiki/Task_(computing)">subtasks</a>. Subtask1 includes the humor detection task, the humor rating prediction task, and the humor controversy detection task. Subtask2 is an offensive rating prediction task. Detection task is a binary classification task, and the rating prediction task is a regression task between 0 to 5. 0 means the task is not humorous or not offensive, 5 means the task is very humorous or very offensive. For all the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a>, this paper chooses RoBERTa as the pre-trained model. In classification tasks, Bi-LSTM and <a href="https://en.wikipedia.org/wiki/Adversarial_learning">adversarial training</a> are adopted. In the <a href="https://en.wikipedia.org/wiki/Regression_analysis">regression task</a>, the Bi-LSTM is also adopted. And then we propose a new <a href="https://en.wikipedia.org/wiki/Methodology">approach</a> named compare method. Finally, our system achieves an <a href="https://en.wikipedia.org/wiki/F-number">F1-score</a> of 95.05 % in the humor detection task, <a href="https://en.wikipedia.org/wiki/F-number">F1-score</a> of 61.74 % in the humor controversy detection task, 0.6143 RMSE in humor rating task, 0.4761 RMSE in the offensive rating task on the test datasets.</abstract>
      <url hash="7ea7f0d2">2021.semeval-1.34</url>
      <doi>10.18653/v1/2021.semeval-1.34</doi>
      <bibkey>liu-zhou-2021-grenzlinie</bibkey>
    </paper>
    <paper id="36">
      <title>Humor@IITK at SemEval-2021 Task 7 : Large Language Models for Quantifying Humor and Offensiveness<fixed-case>IITK</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 7: Large Language Models for Quantifying Humor and Offensiveness</title>
      <author><first>Aishwarya</first><last>Gupta</last></author>
      <author><first>Avik</first><last>Pal</last></author>
      <author><first>Bholeshwar</first><last>Khurana</last></author>
      <author><first>Lakshay</first><last>Tyagi</last></author>
      <author><first>Ashutosh</first><last>Modi</last></author>
      <pages>290–296</pages>
      <abstract>Humor and Offense are highly subjective due to multiple <a href="https://en.wikipedia.org/wiki/Word_sense">word senses</a>, <a href="https://en.wikipedia.org/wiki/Cultural_knowledge">cultural knowledge</a>, and pragmatic competence. Hence, accurately detecting humorous and offensive texts has several compelling use cases in <a href="https://en.wikipedia.org/wiki/Recommender_system">Recommendation Systems</a> and Personalized Content Moderation. However, due to the lack of an extensive labeled dataset, most prior works in this domain have n’t explored large neural models for subjective humor understanding. This paper explores whether large neural models and their ensembles can capture the intricacies associated with humor / offense detection and rating. Our experiments on the SemEval-2021 Task 7 : HaHackathon show that we can develop reasonable humor and offense detection systems with such models. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> are ranked 3rd in subtask 1b and consistently ranked around the top 33 % of the leaderboard for the remaining subtasks.</abstract>
      <url hash="3e4a4e46">2021.semeval-1.36</url>
      <doi>10.18653/v1/2021.semeval-1.36</doi>
      <bibkey>gupta-etal-2021-humor</bibkey>
      <pwccode url="https://github.com/aishgupta/Quantifying-Humor-Offensiveness" additional="false">aishgupta/Quantifying-Humor-Offensiveness</pwccode>
    </paper>
    <paper id="37">
      <title>RoMa at SemEval-2021 Task 7 : A Transformer-based Approach for Detecting and Rating Humor and Offense<fixed-case>R</fixed-case>o<fixed-case>M</fixed-case>a at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 7: A Transformer-based Approach for Detecting and Rating Humor and Offense</title>
      <author><first>Roberto</first><last>Labadie</last></author>
      <author><first>Mariano Jason</first><last>Rodriguez</last></author>
      <author><first>Reynier</first><last>Ortega</last></author>
      <author><first>Paolo</first><last>Rosso</last></author>
      <pages>297–305</pages>
      <abstract>In this paper we describe the systems used by the RoMa team in the shared task on Detecting and Rating Humor and Offense (HaHackathon) at SemEval 2021. Our systems rely on data representations learned through fine-tuned neural language models. Particularly, we explore two distinct <a href="https://en.wikipedia.org/wiki/Computer_architecture">architectures</a>. The first one is based on a Siamese Neural Network (SNN) combined with a graph-based clustering method. The SNN model is used for learning a latent space where instances of <a href="https://en.wikipedia.org/wiki/Humour">humor</a> and non-humor can be distinguished. The clustering method is applied to build prototypes of both classes which are used for training and classifying new messages. The second one combines neural language model representations with a <a href="https://en.wikipedia.org/wiki/Linear_regression">linear regression model</a> which makes the final ratings. Our systems achieved the best results for humor classification using <a href="https://en.wikipedia.org/wiki/Conceptual_model">model one</a>, whereas for offensive and humor rating the second <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> obtained better performance. In the case of the controversial humor prediction, the most significant improvement was achieved by a <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a> of the neural language model. In general, the results achieved are encouraging and give us a starting point for further improvements.</abstract>
      <url hash="0edd40af">2021.semeval-1.37</url>
      <doi>10.18653/v1/2021.semeval-1.37</doi>
      <bibkey>labadie-etal-2021-roma</bibkey>
    </paper>
    <paper id="43">
      <title>BLCUFIGHT at SemEval-2021 Task 10 : Novel Unsupervised Frameworks For Source-Free Domain Adaptation<fixed-case>BLCUFIGHT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 10: Novel Unsupervised Frameworks For Source-Free Domain Adaptation</title>
      <author><first>Weikang</first><last>Wang</last></author>
      <author><first>Yi</first><last>Wu</last></author>
      <author><first>Yixiang</first><last>Liu</last></author>
      <author><first>Pengyuan</first><last>Liu</last></author>
      <pages>357–363</pages>
      <abstract>Domain adaptation assumes that samples from source and target domains are freely accessible during a training phase. However, such assumption is rarely plausible in the real-world and may causes data-privacy issues, especially when the label of the source domain can be a sensitive attribute as an identifier. SemEval-2021 task 10 focuses on these issues. We participate in the task and propose novel <a href="https://en.wikipedia.org/wiki/Conceptual_framework">frameworks</a> based on self-training method. In our <a href="https://en.wikipedia.org/wiki/System">systems</a>, two different <a href="https://en.wikipedia.org/wiki/Software_framework">frameworks</a> are designed to solve <a href="https://en.wikipedia.org/wiki/Text_classification">text classification</a> and <a href="https://en.wikipedia.org/wiki/Sequence_labeling">sequence labeling</a>. These approaches are tested to be effective which ranks the third among all system in subtask A, and ranks the first among all system in subtask B.</abstract>
      <url hash="7ca9e8b8">2021.semeval-1.43</url>
      <doi>10.18653/v1/2021.semeval-1.43</doi>
      <bibkey>wang-etal-2021-blcufight</bibkey>
    </paper>
    <paper id="52">
      <title>BOUN at SemEval-2021 Task 9 : Text Augmentation Techniques for Fact Verification in Tabular Data<fixed-case>BOUN</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 9: Text Augmentation Techniques for Fact Verification in Tabular Data</title>
      <author><first>Abdullatif</first><last>Köksal</last></author>
      <author><first>Yusuf</first><last>Yüksel</last></author>
      <author><first>Bekir</first><last>Yıldırım</last></author>
      <author><first>Arzucan</first><last>Özgür</last></author>
      <pages>431–437</pages>
      <abstract>In this paper, we present our text augmentation based approach for the Table Statement Support Subtask (Phase A) of SemEval-2021 Task 9. We experiment with different text augmentation techniques such as <a href="https://en.wikipedia.org/wiki/Back_translation">back translation</a> and synonym swapping using Word2Vec and <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a>. We show that text augmentation techniques lead to 2.5 % improvement in F1 on the test set. Further, we investigate the impact of <a href="https://en.wikipedia.org/wiki/Domain_adaptation">domain adaptation</a> and joint learning on fact verification in tabular data by utilizing the SemTabFacts and TabFact datasets. We observe that joint learning improves the F1 scores on the SemTabFacts and TabFact test sets by 3.31 % and 0.77 %, respectively.</abstract>
      <url hash="a1b607d1">2021.semeval-1.52</url>
      <doi>10.18653/v1/2021.semeval-1.52</doi>
      <bibkey>koksal-etal-2021-boun</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/superglue">SuperGLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/tabfact">TabFact</pwcdataset>
    </paper>
    <paper id="53">
      <title>IITK at SemEval-2021 Task 10 : Source-Free Unsupervised Domain Adaptation using Class Prototypes<fixed-case>IITK</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 10: Source-Free Unsupervised Domain Adaptation using Class Prototypes</title>
      <author id="harshit-kumar-iit"><first>Harshit</first><last>Kumar</last></author>
      <author><first>Jinang</first><last>Shah</last></author>
      <author><first>Nidhi</first><last>Hegde</last></author>
      <author><first>Priyanshu</first><last>Gupta</last></author>
      <author><first>Vaibhav</first><last>Jindal</last></author>
      <author><first>Ashutosh</first><last>Modi</last></author>
      <pages>438–444</pages>
      <abstract>Recent progress in <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> has primarily been fueled by the availability of large amounts of annotated data that is obtained from highly expensive manual annotating pro-cesses. To tackle this issue of availability of annotated data, a lot of research has been done on unsupervised domain adaptation that tries to generate systems for an unlabelled target domain data, given labeled source domain data. However, the availability of annotated or labelled source domain dataset ca n’t always be guaranteed because of <a href="https://en.wikipedia.org/wiki/Data_privacy">data-privacy issues</a>. This is especially the case with medical data, as <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> may contain sensitive information of the patients. Source-free domain adaptation (SFDA) aims to resolve this issue by us-ing <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> trained on the <a href="https://en.wikipedia.org/wiki/Data">source data</a> instead of using the original annotated source data. In this work, we try to build SFDA systems for <a href="https://en.wikipedia.org/wiki/Semantic_processing">semantic processing</a> by specifically focusing on the negation detection subtask of the SemEval2021 Task 10. We propose two approaches -ProtoAUGandAdapt-ProtoAUGthat use the idea of <a href="https://en.wikipedia.org/wiki/Self-entropy">self-entropy</a> to choose reliable and high confidence samples, which are then used for <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a> and subsequent training of the models. Our methods report an improvement of up to 7 % in <a href="https://en.wikipedia.org/wiki/F1_score">F1 score</a> over the <a href="https://en.wikipedia.org/wiki/Baseline_(medicine)">baseline</a> for the Negation Detection subtask.</abstract>
      <url hash="55a7d74a">2021.semeval-1.53</url>
      <doi>10.18653/v1/2021.semeval-1.53</doi>
      <bibkey>kumar-etal-2021-iitk</bibkey>
    </paper>
    <paper id="54">
      <title>PTST-UoM at SemEval-2021 Task 10 : Parsimonious Transfer for Sequence Tagging<fixed-case>PTST</fixed-case>-<fixed-case>U</fixed-case>o<fixed-case>M</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 10: Parsimonious Transfer for Sequence Tagging</title>
      <author><first>Kemal</first><last>Kurniawan</last></author>
      <author><first>Lea</first><last>Frermann</last></author>
      <author><first>Philip</first><last>Schulz</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <pages>445–451</pages>
      <abstract>This paper describes PTST, a source-free unsupervised domain adaptation technique for sequence tagging, and its application to the SemEval-2021 Task 10 on time expression recognition. PTST is an extension of the cross-lingual parsimonious parser transfer framework, which uses high-probability predictions of the source model as a supervision signal in self-training. We extend the <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> to a sequence prediction setting, and demonstrate its applicability to unsupervised domain adaptation. PTST achieves F1 score of 79.6 % on the official test set, with the <a href="https://en.wikipedia.org/wiki/Precision_(statistics)">precision</a> of 90.1 %, the highest out of 14 submissions.</abstract>
      <url hash="915e1901">2021.semeval-1.54</url>
      <doi>10.18653/v1/2021.semeval-1.54</doi>
      <bibkey>kurniawan-etal-2021-ptst</bibkey>
    </paper>
    <paper id="55">
      <title>Self-Adapter at SemEval-2021 Task 10 : Entropy-based Pseudo-Labeler for Source-free Domain Adaptation<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 10: Entropy-based Pseudo-Labeler for Source-free Domain Adaptation</title>
      <author><first>Sangwon</first><last>Yoon</last></author>
      <author><first>Yanghoon</first><last>Kim</last></author>
      <author><first>Kyomin</first><last>Jung</last></author>
      <pages>452–457</pages>
      <abstract>Source-free domain adaptation is an emerging line of work in deep learning research since it is closely related to the real-world environment. We study the domain adaption in the sequence labeling problem where the <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> trained on the source domain data is given. We propose two <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> : Self-Adapter and Selective Classifier Training. Self-Adapter is a <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training method</a> that uses sentence-level pseudo-labels filtered by the <a href="https://en.wikipedia.org/wiki/Self-entropy">self-entropy threshold</a> to provide supervision to the whole model. Selective Classifier Training uses token-level pseudo-labels and supervises only the classification layer of the model. The proposed <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">methods</a> are evaluated on data provided by SemEval-2021 task 10 and Self-Adapter achieves 2nd rank performance.</abstract>
      <url hash="88ffffc2">2021.semeval-1.55</url>
      <doi>10.18653/v1/2021.semeval-1.55</doi>
      <bibkey>yoon-etal-2021-self</bibkey>
    </paper>
    <paper id="56">
      <title>The University of Arizona at SemEval-2021 Task 10 : Applying Self-training, Active Learning and Data Augmentation to Source-free Domain Adaptation<fixed-case>U</fixed-case>niversity of <fixed-case>A</fixed-case>rizona at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 10: Applying Self-training, Active Learning and Data Augmentation to Source-free Domain Adaptation</title>
      <author><first>Xin</first><last>Su</last></author>
      <author><first>Yiyun</first><last>Zhao</last></author>
      <author><first>Steven</first><last>Bethard</last></author>
      <pages>458–466</pages>
      <abstract>This paper describes our systems for negation detection and time expression recognition in SemEval 2021 Task 10, Source-Free Domain Adaptation for Semantic Processing. We show that self-training, <a href="https://en.wikipedia.org/wiki/Active_learning_(machine_learning)">active learning</a> and data augmentation techniques can improve the generalization ability of the model on the unlabeled target domain data without accessing source domain data. We also perform detailed ablation studies and error analyses for our time expression recognition systems to identify the source of the performance improvement and give constructive feedback on the temporal normalization annotation guidelines.</abstract>
      <url hash="9f8b87dd">2021.semeval-1.56</url>
      <doi>10.18653/v1/2021.semeval-1.56</doi>
      <bibkey>su-etal-2021-university</bibkey>
    </paper>
    <paper id="58">
      <title>YNU-HPCC at SemEval-2021 Task 11 : Using a BERT Model to Extract Contributions from NLP Scholarly Articles<fixed-case>YNU</fixed-case>-<fixed-case>HPCC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 11: Using a <fixed-case>BERT</fixed-case> Model to Extract Contributions from <fixed-case>NLP</fixed-case> Scholarly Articles</title>
      <author><first>Xinge</first><last>Ma</last></author>
      <author><first>Jin</first><last>Wang</last></author>
      <author><first>Xuejie</first><last>Zhang</last></author>
      <pages>478–484</pages>
      <abstract>This paper describes the system we built as the YNU-HPCC team in the SemEval-2021 Task 11 : NLPContributionGraph. This task involves first identifying sentences in the given natural language processing (NLP) scholarly articles that reflect research contributions through binary classification ; then identifying the core scientific terms and their relation phrases from these contribution sentences by sequence labeling ; and finally, these scientific terms and relation phrases are categorized, identified, and organized into subject-predicate-object triples to form a <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graph</a> with the help of <a href="https://en.wikipedia.org/wiki/Multiclass_classification">multiclass classification</a> and <a href="https://en.wikipedia.org/wiki/Multi-label_classification">multi-label classification</a>. We developed a system for this task using a pre-trained language representation model called BERT that stands for Bidirectional Encoder Representations from Transformers, and achieved good results. The average F1-score for Evaluation Phase 2, Part 1 was 0.4562 and ranked 7th, and the average F1-score for Evaluation Phase 2, Part 2 was 0.6541, and also ranked 7th.</abstract>
      <url hash="066f21ba">2021.semeval-1.58</url>
      <doi>10.18653/v1/2021.semeval-1.58</doi>
      <bibkey>ma-etal-2021-ynu</bibkey>
    </paper>
    <paper id="59">
      <title>ITNLP at SemEval-2021 Task 11 : Boosting BERT with Sampling and Adversarial Training for Knowledge Extraction<fixed-case>ITNLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 11: Boosting <fixed-case>BERT</fixed-case> with Sampling and Adversarial Training for Knowledge Extraction</title>
      <author><first>Genyu</first><last>Zhang</last></author>
      <author><first>Yu</first><last>Su</last></author>
      <author><first>Changhong</first><last>He</last></author>
      <author><first>Lei</first><last>Lin</last></author>
      <author><first>Chengjie</first><last>Sun</last></author>
      <author><first>Lili</first><last>Shan</last></author>
      <pages>485–489</pages>
      <abstract>This paper describes the winning system in the End-to-end Pipeline phase for the NLPContributionGraph task. The system is composed of three BERT-based models and the three <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> are used to extract sentences, entities and triples respectively. Experiments show that sampling and adversarial training can greatly boost the <a href="https://en.wikipedia.org/wiki/System">system</a>. In End-to-end Pipeline phase, our <a href="https://en.wikipedia.org/wiki/System">system</a> got an average F1 of 0.4703, significantly higher than the second-placed system which got an average F1 of 0.3828.</abstract>
      <url hash="c9400786">2021.semeval-1.59</url>
      <doi>10.18653/v1/2021.semeval-1.59</doi>
      <bibkey>zhang-etal-2021-itnlp</bibkey>
    </paper>
    <paper id="60">
      <title>Duluth at SemEval-2021 Task 11 : Applying DeBERTa to Contributing Sentence Selection and Dependency Parsing for Entity Extraction<fixed-case>D</fixed-case>uluth at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 11: Applying <fixed-case>D</fixed-case>e<fixed-case>BERT</fixed-case>a to Contributing Sentence Selection and Dependency Parsing for Entity Extraction</title>
      <author><first>Anna</first><last>Martin</last></author>
      <author><first>Ted</first><last>Pedersen</last></author>
      <pages>490–501</pages>
      <abstract>This paper describes the Duluth system that participated in SemEval-2021 Task 11, NLP Contribution Graph. It details the extraction of contribution sentences and scientific entities and their relations from scholarly articles in the domain of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a>. Our solution uses deBERTa for multi-class sentence classification to extract the contributing sentences and their type, and dependency parsing to outline each sentence and extract subject-predicate-object triples. Our system ranked fifth of seven for Phase 1 : end-to-end pipeline, sixth of eight for Phase 2 Part 1 : phrases and triples, and fifth of eight for Phase 2 Part 2 : triples extraction.</abstract>
      <url hash="4963cbad">2021.semeval-1.60</url>
      <doi>10.18653/v1/2021.semeval-1.60</doi>
      <bibkey>martin-pedersen-2021-duluth</bibkey>
    </paper>
    <paper id="61">
      <title>INNOVATORS at SemEval-2021 Task-11 : A Dependency Parsing and BERT-based model for Extracting Contribution Knowledge from Scientific Papers<fixed-case>INNOVATORS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task-11: A Dependency Parsing and <fixed-case>BERT</fixed-case>-based model for Extracting Contribution Knowledge from Scientific Papers</title>
      <author><first>Hardik</first><last>Arora</last></author>
      <author><first>Tirthankar</first><last>Ghosal</last></author>
      <author><first>Sandeep</first><last>Kumar</last></author>
      <author><first>Suraj</first><last>Patwal</last></author>
      <author><first>Phil</first><last>Gooch</last></author>
      <pages>502–510</pages>
      <abstract>In this work, we describe our system submission to the SemEval 2021 Task 11 : NLP Contribution Graph Challenge. We attempt all the three sub-tasks in the challenge and report our results. Subtask 1 aims to identify the contributing sentences in a given publication. Subtask 2 follows from Subtask 1 to extract the scientific term and predicate phrases from the identified contributing sentences. The final Subtask 3 entails extracting triples (subject, predicate, object) from the phrases and categorizing them under one or more defined information units. With the NLPContributionGraph Shared Task, the organizers formalized the building of a scholarly contributions-focused graph over NLP scholarly articles as an automated task. Our approaches include a BERT-based classification model for identifying the contributing sentences in a research publication, a rule-based dependency parsing for phrase extraction, followed by a CNN-based model for information units classification, and a set of rules for triples extraction. The quantitative results show that we obtain the 5th, 5th, and 7th rank respectively in three evaluation phases. We make our codes available at https://github.com/HardikArora17/SemEval-2021-INNOVATORS.<i>triples</i> (subject, predicate, object) from the phrases and categorizing them under one or more defined information units. With the NLPContributionGraph Shared Task, the organizers formalized the building of a scholarly contributions-focused graph over NLP scholarly articles as an automated task. Our approaches include a BERT-based classification model for identifying the contributing sentences in a research publication, a rule-based dependency parsing for phrase extraction, followed by a CNN-based model for information units classification, and a set of rules for triples extraction. The quantitative results show that we obtain the 5th, 5th, and 7th rank respectively in three evaluation phases. We make our codes available at https://github.com/HardikArora17/SemEval-2021-INNOVATORS.</abstract>
      <url hash="7d66a138">2021.semeval-1.61</url>
      <doi>10.18653/v1/2021.semeval-1.61</doi>
      <bibkey>arora-etal-2021-innovators</bibkey>
    </paper>
    <paper id="63">
      <title>HITSZ-HLT at SemEval-2021 Task 5 : Ensemble Sequence Labeling and Span Boundary Detection for Toxic Span Detection<fixed-case>HITSZ</fixed-case>-<fixed-case>HLT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 5: Ensemble Sequence Labeling and Span Boundary Detection for Toxic Span Detection</title>
      <author><first>Qinglin</first><last>Zhu</last></author>
      <author><first>Zijie</first><last>Lin</last></author>
      <author><first>Yice</first><last>Zhang</last></author>
      <author><first>Jingyi</first><last>Sun</last></author>
      <author><first>Xiang</first><last>Li</last></author>
      <author><first>Qihui</first><last>Lin</last></author>
      <author><first>Yixue</first><last>Dang</last></author>
      <author><first>Ruifeng</first><last>Xu</last></author>
      <pages>521–526</pages>
      <abstract>This paper presents the winning <a href="https://en.wikipedia.org/wiki/System">system</a> that participated in SemEval-2021 Task 5 : Toxic Spans Detection. This task aims to locate those spans that attribute to the text’s toxicity within a text, which is crucial for semi-automated moderation in online discussions. We formalize this task as the Sequence Labeling (SL) problem and the Span Boundary Detection (SBD) problem separately and employ three state-of-the-art models. Next, we integrate predictions of these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> to produce a more credible and complement result. Our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves a char-level score of 70.83 %, ranking 1/91. In addition, we also explore the lexicon-based method, which is strongly interpretable and flexible in practice.</abstract>
      <url hash="55d83b70">2021.semeval-1.63</url>
      <doi>10.18653/v1/2021.semeval-1.63</doi>
      <bibkey>zhu-etal-2021-hitsz</bibkey>
    </paper>
    <paper id="65">
      <title>UPB at SemEval-2021 Task 8 : Extracting Semantic Information on Measurements as Multi-Turn Question Answering<fixed-case>UPB</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 8: Extracting Semantic Information on Measurements as Multi-Turn Question Answering</title>
      <author><first>Andrei-Marius</first><last>Avram</last></author>
      <author><first>George-Eduard</first><last>Zaharia</last></author>
      <author><first>Dumitru-Clementin</first><last>Cercel</last></author>
      <author><first>Mihai</first><last>Dascalu</last></author>
      <pages>534–540</pages>
      <abstract>Extracting semantic information on measurements and counts is an important topic in terms of analyzing scientific discourses. The 8th task of SemEval-2021 : Counts and Measurements (MeasEval) aimed to boost research in this direction by providing a new dataset on which participants train their models to extract meaningful information on measurements from scientific texts. The competition is composed of five subtasks that build on top of each other : (1) quantity span identification, (2) unit extraction from the identified quantities and their value modifier classification, (3) span identification for measured entities and measured properties, (4) qualifier span identification, and (5) relation extraction between the identified quantities, measured entities, measured properties, and qualifiers. We approached these challenges by first identifying the quantities, extracting their units of measurement, classifying them with corresponding modifiers, and afterwards using them to jointly solve the last three subtasks in a multi-turn question answering manner. Our best performing <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> obtained an overlapping F1-score of 36.91 % on the test set.</abstract>
      <url hash="a4fc652d">2021.semeval-1.65</url>
      <doi>10.18653/v1/2021.semeval-1.65</doi>
      <bibkey>avram-etal-2021-upb</bibkey>
    </paper>
    <paper id="66">
      <title>IITK@LCP at SemEval-2021 Task 1 : Classification for Lexical Complexity Regression Task<fixed-case>IITK</fixed-case>@<fixed-case>LCP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 1: Classification for Lexical Complexity Regression Task</title>
      <author><first>Neil</first><last>Shirude</last></author>
      <author><first>Sagnik</first><last>Mukherjee</last></author>
      <author><first>Tushar</first><last>Shandhilya</last></author>
      <author><first>Ananta</first><last>Mukherjee</last></author>
      <author><first>Ashutosh</first><last>Modi</last></author>
      <pages>541–547</pages>
      <abstract>This paper describes our contribution to SemEval 2021 Task 1 (Shardlow et al., 2021): Lexical Complexity Prediction. In our approach, we leverage the ELECTRA model and attempt to mirror the data annotation scheme. Although the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> is a <a href="https://en.wikipedia.org/wiki/Regression_analysis">regression task</a>, we show that we can treat it as an aggregation of several <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification and regression models</a>. This somewhat counter-intuitive approach achieved an MAE score of 0.0654 for Sub-Task 1 and MAE of 0.0811 on Sub-Task 2. Additionally, we used the concept of weak supervision signals from Gloss-BERT in our work, and it significantly improved the MAE score in Sub-Task 1.</abstract>
      <url hash="9b430f68">2021.semeval-1.66</url>
      <doi>10.18653/v1/2021.semeval-1.66</doi>
      <bibkey>shirude-etal-2021-iitk</bibkey>
    </paper>
    <paper id="67">
      <title>LCP-RIT at SemEval-2021 Task 1 : Exploring Linguistic Features for Lexical Complexity Prediction<fixed-case>LCP</fixed-case>-<fixed-case>RIT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 1: Exploring Linguistic Features for Lexical Complexity Prediction</title>
      <author><first>Abhinandan Tejalkumar</first><last>Desai</last></author>
      <author><first>Kai</first><last>North</last></author>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <author><first>Christopher</first><last>Homan</last></author>
      <pages>548–553</pages>
      <abstract>This paper describes team LCP-RIT’s submission to the SemEval-2021 Task 1 : Lexical Complexity Prediction (LCP). The task organizers provided participants with an augmented version of CompLex (Shardlow et al., 2020), an English multi-domain dataset in which words in context were annotated with respect to their <a href="https://en.wikipedia.org/wiki/Complexity">complexity</a> using a five point Likert scale. Our system uses <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a> and a wide range of <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">linguistic features</a> (e.g. psycholinguistic features, <a href="https://en.wikipedia.org/wiki/N-gram">n-grams</a>, <a href="https://en.wikipedia.org/wiki/Word_frequency">word frequency</a>, POS tags) to predict the complexity of single words in this dataset. We analyze the impact of different linguistic features on the classification performance and we evaluate the results in terms of <a href="https://en.wikipedia.org/wiki/Mean_absolute_error">mean absolute error</a>, <a href="https://en.wikipedia.org/wiki/Mean_squared_error">mean squared error</a>, <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson correlation</a>, and <a href="https://en.wikipedia.org/wiki/Spearman_correlation">Spearman correlation</a>.</abstract>
      <url hash="23186590">2021.semeval-1.67</url>
      <doi>10.18653/v1/2021.semeval-1.67</doi>
      <bibkey>desai-etal-2021-lcp</bibkey>
    </paper>
    <paper id="69">
      <title>CompNA at SemEval-2021 Task 1 : Prediction of lexical complexity analyzing heterogeneous features<fixed-case>C</fixed-case>omp<fixed-case>NA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 1: Prediction of lexical complexity analyzing heterogeneous features</title>
      <author><first>Giuseppe</first><last>Vettigli</last></author>
      <author><first>Antonio</first><last>Sorgente</last></author>
      <pages>560–564</pages>
      <abstract>This paper describes the CompNa model that has been submitted to the Lexical Complexity Prediction (LCP) shared task hosted at SemEval 2021 (Task 1). The solution is based on combining features of different nature through an ensambling method based on <a href="https://en.wikipedia.org/wiki/Decision_tree_learning">Decision Trees</a> and trained using <a href="https://en.wikipedia.org/wiki/Gradient_boosting">Gradient Boosting</a>. We discuss the results of the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> and highlight the <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> with more predictive capabilities.</abstract>
      <url hash="17f6d7f7">2021.semeval-1.69</url>
      <doi>10.18653/v1/2021.semeval-1.69</doi>
      <bibkey>vettigli-sorgente-2021-compna</bibkey>
    </paper>
    <paper id="73">
      <title>CS-UM6P at SemEval-2021 Task 1 : A Deep Learning Model-based Pre-trained Transformer Encoder for Lexical Complexity<fixed-case>CS</fixed-case>-<fixed-case>UM</fixed-case>6<fixed-case>P</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 1: A Deep Learning Model-based Pre-trained Transformer Encoder for Lexical Complexity</title>
      <author><first>Nabil</first><last>El Mamoun</last></author>
      <author><first>Abdelkader</first><last>El Mahdaouy</last></author>
      <author><first>Abdellah</first><last>El Mekki</last></author>
      <author><first>Kabil</first><last>Essefar</last></author>
      <author><first>Ismail</first><last>Berrada</last></author>
      <pages>585–589</pages>
      <abstract>Lexical Complexity Prediction (LCP) involves assigning a difficulty score to a particular word or expression, in a text intended for a target audience. In this paper, we introduce a new deep learning-based system for this challenging <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. The proposed system consists of a <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning model</a>, based on pre-trained transformer encoder, for word and Multi-Word Expression (MWE) complexity prediction. First, on top of the encoder’s contextualized word embedding, our model employs an attention layer on the input context and the complex word or MWE. Then, the <a href="https://en.wikipedia.org/wiki/Attentional_control">attention output</a> is concatenated with the pooled output of the <a href="https://en.wikipedia.org/wiki/Encoder">encoder</a> and passed to a <a href="https://en.wikipedia.org/wiki/Regression_analysis">regression module</a>. We investigate both single-task and joint training on both Sub-Tasks data using multiple pre-trained transformer-based encoders. The obtained results are very promising and show the effectiveness of fine-tuning pre-trained transformers for LCP task.</abstract>
      <url hash="a0998ad5">2021.semeval-1.73</url>
      <doi>10.18653/v1/2021.semeval-1.73</doi>
      <bibkey>el-mamoun-etal-2021-cs</bibkey>
    </paper>
    <paper id="79">
      <title>RG PA at SemEval-2021 Task 1 : A Contextual Attention-based Model with RoBERTa for Lexical Complexity Prediction<fixed-case>RG</fixed-case> <fixed-case>PA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 1: A Contextual Attention-based Model with <fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a for Lexical Complexity Prediction</title>
      <author><first>Gang</first><last>Rao</last></author>
      <author><first>Maochang</first><last>Li</last></author>
      <author><first>Xiaolong</first><last>Hou</last></author>
      <author><first>Lianxin</first><last>Jiang</last></author>
      <author><first>Yang</first><last>Mo</last></author>
      <author><first>Jianping</first><last>Shen</last></author>
      <pages>623–626</pages>
      <abstract>In this paper we propose a contextual attention based model with two-stage fine-tune training using RoBERTa. First, we perform the first-stage fine-tune on corpus with RoBERTa, so that the <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> can learn some prior <a href="https://en.wikipedia.org/wiki/Domain_knowledge">domain knowledge</a>. Then we get the contextual embedding of context words based on the token-level embedding with the fine-tuned model. And we use Kfold cross-validation to get K models and ensemble them to get the final result. Finally, we attain the 2nd place in the final evaluation phase of sub-task 2 with <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">pearson correlation</a> of 0.8575.</abstract>
      <url hash="4b389693">2021.semeval-1.79</url>
      <doi>10.18653/v1/2021.semeval-1.79</doi>
      <bibkey>rao-etal-2021-rg</bibkey>
    </paper>
    <paper id="81">
      <title>CLULEX at SemEval-2021 Task 1 : A Simple System Goes a Long Way<fixed-case>CLULEX</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 1: A Simple System Goes a Long Way</title>
      <author><first>Greta</first><last>Smolenska</last></author>
      <author><first>Peter</first><last>Kolb</last></author>
      <author><first>Sinan</first><last>Tang</last></author>
      <author><first>Mironas</first><last>Bitinis</last></author>
      <author><first>Héctor</first><last>Hernández</last></author>
      <author><first>Elin</first><last>Asklöv</last></author>
      <pages>632–639</pages>
      <abstract>This paper presents the <a href="https://en.wikipedia.org/wiki/System">system</a> we submitted to the first Lexical Complexity Prediction (LCP) Shared Task 2021. The Shared Task provides participants with a new English dataset that includes context of the target word. We participate in the single-word complexity prediction sub-task and focus on <a href="https://en.wikipedia.org/wiki/Feature_engineering">feature engineering</a>. Our best system is trained on <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">linguistic features</a> and <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> (Pearson’s score of 0.7942). We demonstrate, however, that a simpler <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">feature set</a> achieves comparable results and submit a <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> trained on 36 <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">linguistic features</a> (Pearson’s score of 0.7925).</abstract>
      <url hash="15a0b21e">2021.semeval-1.81</url>
      <doi>10.18653/v1/2021.semeval-1.81</doi>
      <bibkey>smolenska-etal-2021-clulex</bibkey>
    </paper>
    <paper id="83">
      <title>UNBNLP at SemEval-2021 Task 1 : Predicting lexical complexity with masked language models and character-level encoders<fixed-case>UNBNLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 1: Predicting lexical complexity with masked language models and character-level encoders</title>
      <author><first>Milton</first><last>King</last></author>
      <author><first>Ali</first><last>Hakimi Parizi</last></author>
      <author><first>Samin</first><last>Fakharian</last></author>
      <author><first>Paul</first><last>Cook</last></author>
      <pages>650–654</pages>
      <abstract>In this paper, we present three <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised systems</a> for English lexical complexity prediction of single and multiword expressions for SemEval-2021 Task 1. We explore the use of statistical baseline features, masked language models, and character-level encoders to predict the complexity of a target token in context. Our best <a href="https://en.wikipedia.org/wiki/System">system</a> combines information from these three sources. The results indicate that information from masked language models and <a href="https://en.wikipedia.org/wiki/Character_encoding">character-level encoders</a> can be combined to improve lexical complexity prediction.</abstract>
      <url hash="598f4b0c">2021.semeval-1.83</url>
      <doi>10.18653/v1/2021.semeval-1.83</doi>
      <bibkey>king-etal-2021-unbnlp</bibkey>
    </paper>
    <paper id="92">
      <title>GX at SemEval-2021 Task 2 : BERT with Lemma Information for MCL-WiC Task<fixed-case>GX</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 2: <fixed-case>BERT</fixed-case> with Lemma Information for <fixed-case>MCL</fixed-case>-<fixed-case>W</fixed-case>i<fixed-case>C</fixed-case> Task</title>
      <author><first>Wanying</first><last>Xie</last></author>
      <pages>706–712</pages>
      <abstract>This paper presents the GX system for the Multilingual and Cross-lingual Word-in-Context Disambiguation (MCL-WiC) task. The purpose of the MCL-WiC task is to tackle the challenge of capturing the polysemous nature of words without relying on a fixed sense inventory in a multilingual and cross-lingual setting. To solve the problems, we use context-specific word embeddings from BERT to eliminate the ambiguity between words in different contexts. For languages without an available training corpus, such as <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a>, we use neuron machine translation model to translate the English data released by the organizers to obtain available pseudo-data. In this paper, we apply our <a href="https://en.wikipedia.org/wiki/System">system</a> to the English and Chinese multilingual setting and the experimental results show that our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> has certain advantages.</abstract>
      <url hash="90b58e2c">2021.semeval-1.92</url>
      <doi>10.18653/v1/2021.semeval-1.92</doi>
      <bibkey>xie-2021-gx-semeval</bibkey>
      <pwccode url="https://github.com/yingwaner/bert4wic" additional="false">yingwaner/bert4wic</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wic">WiC</pwcdataset>
    </paper>
    <paper id="93">
      <title>PALI at SemEval-2021 Task 2 : Fine-Tune XLM-RoBERTa for Word in Context Disambiguation<fixed-case>PALI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 2: Fine-Tune <fixed-case>XLM</fixed-case>-<fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a for Word in Context Disambiguation</title>
      <author><first>Shuyi</first><last>Xie</last></author>
      <author><first>Jian</first><last>Ma</last></author>
      <author><first>Haiqin</first><last>Yang</last></author>
      <author><first>Lianxin</first><last>Jiang</last></author>
      <author><first>Yang</first><last>Mo</last></author>
      <author><first>Jianping</first><last>Shen</last></author>
      <pages>713–718</pages>
      <abstract>This paper presents the PALI team’s winning system for SemEval-2021 Task 2 : Multilingual and Cross-lingual Word-in-Context Disambiguation. We fine-tune XLM-RoBERTa model to solve the task of word in context disambiguation, i.e., to determine whether the target word in the two contexts contains the same meaning or not. In implementation, we first specifically design an input tag to emphasize the target word in the contexts. Second, we construct a new vector on the fine-tuned embeddings from XLM-RoBERTa and feed it to a fully-connected network to output the probability of whether the target word in the context has the same meaning or not. The new <a href="https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics)">vector</a> is attained by concatenating the embedding of the [ CLS ] token and the embeddings of the target word in the contexts. In training, we explore several tricks, such as the Ranger optimizer, <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a>, and adversarial training, to improve the <a href="https://en.wikipedia.org/wiki/Prediction">model prediction</a>. Consequently, we attain the first place in all four cross-lingual tasks.</abstract>
      <url hash="607fa0d2">2021.semeval-1.93</url>
      <doi>10.18653/v1/2021.semeval-1.93</doi>
      <bibkey>xie-etal-2021-pali</bibkey>
    </paper>
    <paper id="96">
      <title>Cambridge at SemEval-2021 Task 2 : Neural WiC-Model with Data Augmentation and Exploration of Representation<fixed-case>C</fixed-case>ambridge at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 2: Neural <fixed-case>W</fixed-case>i<fixed-case>C</fixed-case>-Model with Data Augmentation and Exploration of Representation</title>
      <author><first>Zheng</first><last>Yuan</last></author>
      <author><first>David</first><last>Strohmaier</last></author>
      <pages>730–737</pages>
      <abstract>This paper describes the system of the Cambridge team submitted to the SemEval-2021 shared task on Multilingual and Cross-lingual Word-in-Context Disambiguation. Building on top of a pre-trained masked language model, our system is first pre-trained on out-of-domain data, and then fine-tuned on in-domain data. We demonstrate the effectiveness of the proposed two-step training strategy and the benefits of <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a> from both existing examples and new resources. We further investigate different <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">representations</a> and show that the addition of distance-based features is helpful in the word-in-context disambiguation task. Our system yields highly competitive results in the cross-lingual track without training on any cross-lingual data ; and achieves state-of-the-art results in the multilingual track, ranking first in two languages (Arabic and Russian) and second in <a href="https://en.wikipedia.org/wiki/French_language">French</a> out of 171 submitted systems.</abstract>
      <url hash="adbc63b4">2021.semeval-1.96</url>
      <doi>10.18653/v1/2021.semeval-1.96</doi>
      <bibkey>yuan-strohmaier-2021-cambridge</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wic">WiC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/xl-wic">XL-WiC</pwcdataset>
    </paper>
    <paper id="103">
      <title>LIORI at SemEval-2021 Task 2 : Span Prediction and Binary Classification approaches to Word-in-Context Disambiguation<fixed-case>LIORI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 2: Span Prediction and Binary Classification approaches to Word-in-Context Disambiguation</title>
      <author><first>Adis</first><last>Davletov</last></author>
      <author><first>Nikolay</first><last>Arefyev</last></author>
      <author><first>Denis</first><last>Gordeev</last></author>
      <author><first>Alexey</first><last>Rey</last></author>
      <pages>780–786</pages>
      <abstract>This paper presents our approaches to SemEval-2021 Task 2 : Multilingual and Cross-lingual Word-in-Context Disambiguation task. The first approach attempted to reformulate the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> as a <a href="https://en.wikipedia.org/wiki/Question_answering">question answering problem</a>, while the second one framed it as a binary classification problem. Our best system, which is an ensemble of XLM-R based binary classifiers trained with data augmentation, is among the 3 best-performing systems for <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a>, <a href="https://en.wikipedia.org/wiki/French_language">French</a> and <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a> in the multilingual subtask. In the post-evaluation period, we experimented with <a href="https://en.wikipedia.org/wiki/Batch_normalization">batch normalization</a>, subword pooling and target word occurrence aggregation methods, resulting in further performance improvements.</abstract>
      <url hash="cf75609c">2021.semeval-1.103</url>
      <doi>10.18653/v1/2021.semeval-1.103</doi>
      <bibkey>davletov-etal-2021-liori</bibkey>
    </paper>
    <paper id="104">
      <title>FII_CROSS at SemEval-2021 Task 2 : Multilingual and Cross-lingual Word-in-Context Disambiguation<fixed-case>FII</fixed-case>_<fixed-case>CROSS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 2: Multilingual and Cross-lingual Word-in-Context Disambiguation</title>
      <author><first>Ciprian</first><last>Bodnar</last></author>
      <author><first>Andrada</first><last>Tapuc</last></author>
      <author><first>Cosmin</first><last>Pintilie</last></author>
      <author><first>Daniela</first><last>Gifu</last></author>
      <author><first>Diana</first><last>Trandabat</last></author>
      <pages>787–792</pages>
      <abstract>This paper presents a word-in-context disambiguation system. The task focuses on capturing the polysemous nature of words in a multilingual and cross-lingual setting, without considering a strict inventory of word meanings. The system applies Natural Language Processing algorithms on datasets from SemEval 2021 Task 2, being able to identify the meaning of words for the languages <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a>, <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a>, <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/French_language">French</a> and <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a>, without making use of any additional mono- or multilingual resources.</abstract>
      <url hash="e84b5e15">2021.semeval-1.104</url>
      <doi>10.18653/v1/2021.semeval-1.104</doi>
      <bibkey>bodnar-etal-2021-fii</bibkey>
    </paper>
    <paper id="106">
      <title>UoR at SemEval-2021 Task 4 : Using Pre-trained BERT Token Embeddings for Question Answering of Abstract Meaning<fixed-case>U</fixed-case>o<fixed-case>R</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 4: Using Pre-trained <fixed-case>BERT</fixed-case> Token Embeddings for Question Answering of Abstract Meaning</title>
      <author><first>Thanet</first><last>Markchom</last></author>
      <author><first>Huizhi</first><last>Liang</last></author>
      <pages>799–804</pages>
      <abstract>Most <a href="https://en.wikipedia.org/wiki/Question_answering">question answering tasks</a> focuses on <a href="https://en.wikipedia.org/wiki/Prediction">predicting concrete answers</a>, e.g., <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entities</a>. These <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> can be normally achieved by understanding the contexts without additional information required. In Reading Comprehension of Abstract Meaning (ReCAM) task, the abstract answers are introduced. To understand <a href="https://en.wikipedia.org/wiki/Abstract_and_concrete">abstract meanings</a> in the context, additional knowledge is essential. In this paper, we propose an approach that leverages the pre-trained BERT Token embeddings as a prior knowledge resource. According to the results, our approach using the pre-trained BERT outperformed the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baselines</a>. It shows that the pre-trained BERT token embeddings can be used as additional knowledge for understanding abstract meanings in <a href="https://en.wikipedia.org/wiki/Question_answering">question answering</a>.</abstract>
      <url hash="821c685a">2021.semeval-1.106</url>
      <doi>10.18653/v1/2021.semeval-1.106</doi>
      <bibkey>markchom-liang-2021-uor</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/recam">ReCAM</pwcdataset>
    </paper>
    <paper id="107">
      <title>Noobs at Semeval-2021 Task 4 : Masked Language Modeling for abstract answer prediction<fixed-case>S</fixed-case>emeval-2021 Task 4: Masked Language Modeling for abstract answer prediction</title>
      <author><first>Shikhar</first><last>Shukla</last></author>
      <author><first>Sarthak</first><last>Sarthak</last></author>
      <author><first>Karm Veer</first><last>Arya</last></author>
      <pages>805–809</pages>
      <abstract>This paper presents the <a href="https://en.wikipedia.org/wiki/System">system</a> developed by our team for Semeval 2021 Task 4 : Reading Comprehension of Abstract Meaning. The aim of the task was to benchmark the NLP techniques in understanding the abstract concepts present in a passage, and then predict the missing word in a human written summary of the passage. We trained a Roberta-Large model trained with a masked language modeling objective. In cases where this <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> failed to predict one of the available options, another Roberta-Large model trained as a <a href="https://en.wikipedia.org/wiki/Binary_classifier">binary classifier</a> was used to predict correct and incorrect options. We used passage summary generated by Pegasus model and question as inputs. Our best solution was an ensemble of these 2 systems. We achieved an accuracy of 86.22 % on subtask 1 and 87.10 % on subtask 2.</abstract>
      <url hash="6377373b">2021.semeval-1.107</url>
      <doi>10.18653/v1/2021.semeval-1.107</doi>
      <bibkey>shukla-etal-2021-noobs</bibkey>
    </paper>
    <paper id="109">
      <title>PINGAN Omini-Sinitic at SemEval-2021 Task 4 : Reading Comprehension of Abstract Meaning<fixed-case>PINGAN</fixed-case> Omini-Sinitic at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 4:Reading Comprehension of Abstract Meaning</title>
      <author><first>Ye</first><last>Wang</last></author>
      <author><first>Yanmeng</first><last>Wang</last></author>
      <author><first>Haijun</first><last>Zhu</last></author>
      <author><first>Bo</first><last>Zeng</last></author>
      <author><first>Zhenghong</first><last>Hao</last></author>
      <author><first>Shaojun</first><last>Wang</last></author>
      <author><first>Jing</first><last>Xiao</last></author>
      <pages>820–826</pages>
      <abstract>This paper describes the winning system for subtask 2 and the second-placed system for subtask 1 in SemEval 2021 Task 4 : ReadingComprehension of Abstract Meaning. We propose to use pre-trianed Electra discriminator to choose the best abstract word from five candidates. An upper attention and auto denoising mechanism is introduced to process the long sequences. The experiment results demonstrate that this contribution greatly facilitatesthe contextual language modeling in <a href="https://en.wikipedia.org/wiki/Reading_comprehension">reading comprehension task</a>. The ablation study is also conducted to show the validity of our proposed methods.</abstract>
      <url hash="5a5b7796">2021.semeval-1.109</url>
      <doi>10.18653/v1/2021.semeval-1.109</doi>
      <bibkey>wang-etal-2021-pingan</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/recam">ReCAM</pwcdataset>
    </paper>
    <paper id="114">
      <title>GHOST at SemEval-2021 Task 5 : Is explanation all you need?<fixed-case>GHOST</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 5: Is explanation all you need?</title>
      <author><first>Kamil</first><last>Pluciński</last></author>
      <author><first>Hanna</first><last>Klimczak</last></author>
      <pages>852–859</pages>
      <abstract>This paper discusses different approaches to the Toxic Spans Detection task. The problem posed by the task was to determine which words contribute mostly to recognising a document as toxic. As opposed to <a href="https://en.wikipedia.org/wiki/Binary_classification">binary classification</a> of entire texts, word-level assessment could be of great use during <a href="https://en.wikipedia.org/wiki/Moderation_system">comment moderation</a>, also allowing for a more in-depth comprehension of the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>’s predictions. As the main goal was to ensure transparency and understanding, this paper focuses on the current state-of-the-art approaches based on the explainable AI concepts and compares them to a supervised learning solution with word-level labels. The work consists of two xAI approaches that automatically provide the explanation for models trained for binary classification of toxic documents : an LSTM model with attention as a model-specific approach and the Shapley values for interpreting BERT predictions as a model-agnostic method. The competing approach considers this <a href="https://en.wikipedia.org/wiki/Problem_solving">problem</a> as supervised token classification, where models like BERT and its modifications were tested. The paper aims to explore, compare and assess the quality of predictions for different <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> on the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. The advantages of each <a href="https://en.wikipedia.org/wiki/Scientific_method">approach</a> and further research direction are also discussed.</abstract>
      <url hash="631440f7">2021.semeval-1.114</url>
      <doi>10.18653/v1/2021.semeval-1.114</doi>
      <bibkey>plucinski-klimczak-2021-ghost</bibkey>
    </paper>
    <paper id="115">
      <title>GoldenWind at SemEval-2021 Task 5 : Orthrus-An Ensemble Approach to Identify Toxicity<fixed-case>G</fixed-case>olden<fixed-case>W</fixed-case>ind at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 5: Orthrus - An Ensemble Approach to Identify Toxicity</title>
      <author><first>Marco</first><last>Palomino</last></author>
      <author><first>Dawid</first><last>Grad</last></author>
      <author><first>James</first><last>Bedwell</last></author>
      <pages>860–864</pages>
      <abstract>Many new developments to detect and mitigate <a href="https://en.wikipedia.org/wiki/Toxicity">toxicity</a> are currently being evaluated. We are particularly interested in the correlation between <a href="https://en.wikipedia.org/wiki/Toxicity">toxicity</a> and the <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a> expressed in online posts. While <a href="https://en.wikipedia.org/wiki/Toxicity">toxicity</a> may be disguised by amending the wording of posts, <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a> will not. Therefore, we describe here an ensemble method to identify toxicity and classify the emotions expressed on a corpus of annotated posts published by Task 5 of SemEval 2021our analysis shows that the majority of such posts express <a href="https://en.wikipedia.org/wiki/Anger">anger</a>, sadness and <a href="https://en.wikipedia.org/wiki/Fear">fear</a>. Our method to identify <a href="https://en.wikipedia.org/wiki/Toxicity">toxicity</a> combines a lexicon-based approach, which on its own achieves an F1 score of 61.07 %, with a <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning approach</a>, which on its own achieves an F1 score of 60 %. When both <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> are combined, the <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble</a> achieves an F1 score of 66.37 %.</abstract>
      <url hash="c1d1b952">2021.semeval-1.115</url>
      <doi>10.18653/v1/2021.semeval-1.115</doi>
      <bibkey>palomino-etal-2021-goldenwind</bibkey>
    </paper>
    <paper id="119">
      <title>NLP_UIOWA at Semeval-2021 Task 5 : Transferring Toxic Sets to Tag Toxic Spans<fixed-case>NLP</fixed-case>_<fixed-case>UIOWA</fixed-case> at <fixed-case>S</fixed-case>emeval-2021 Task 5: Transferring Toxic Sets to Tag Toxic Spans</title>
      <author><first>Jonathan</first><last>Rusert</last></author>
      <pages>881–887</pages>
      <abstract>We leverage a BLSTM with <a href="https://en.wikipedia.org/wiki/Attention">attention</a> to identify toxic spans in texts. We explore different <a href="https://en.wikipedia.org/wiki/Dimension">dimensions</a> which affect the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>’s performance. The first dimension explored is the toxic set the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is trained on. Besides the provided <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>, we explore the transferability of 5 different toxic related sets, including offensive, toxic, abusive, and hate sets. We find that the solely offensive set shows the highest promise of transferability. The second dimension we explore is <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a>, including leveraging <a href="https://en.wikipedia.org/wiki/Attention">attention</a>, employing a greedy remove method, using a <a href="https://en.wikipedia.org/wiki/Frequency_ratio">frequency ratio</a>, and examining hybrid combinations of multiple methods. We conduct an error analysis to examine which types of toxic spans were missed and which were wrongly inferred as toxic along with the main reasons why they occurred. Finally, we extend our method via ensembles, which achieves our highest F1 score of 55.1.</abstract>
      <url hash="d3fd46e9">2021.semeval-1.119</url>
      <doi>10.18653/v1/2021.semeval-1.119</doi>
      <bibkey>rusert-2021-nlp</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/olid">OLID</pwcdataset>
    </paper>
    <paper id="120">
      <title>S-NLP at SemEval-2021 Task 5 : An Analysis of Dual Networks for Sequence Tagging<fixed-case>S</fixed-case>-<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 5: An Analysis of Dual Networks for Sequence Tagging</title>
      <author><first>Viet Anh</first><last>Nguyen</last></author>
      <author><first>Tam Minh</first><last>Nguyen</last></author>
      <author><first>Huy</first><last>Quang Dao</last></author>
      <author><first>Quang</first><last>Huu Pham</last></author>
      <pages>888–897</pages>
      <abstract>The SemEval 2021 task 5 : Toxic Spans Detection is a task of identifying considered-toxic spans in text, which provides a valuable, automatic tool for moderating online contents. This paper represents the second-place method for the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, an ensemble of two <a href="https://en.wikipedia.org/wiki/Methodology">approaches</a>. While one approach relies on combining different embedding methods to extract diverse semantic and syntactic representations of words in context ; the other utilizes extra data with a slightly customized Self-training, a semi-supervised learning technique, for sequence tagging problems. Both of our <a href="https://en.wikipedia.org/wiki/Software_architecture">architectures</a> take advantage of a strong <a href="https://en.wikipedia.org/wiki/Language_model">language model</a>, which was fine-tuned on a toxic classification task. Although experimental evidence indicates higher effectiveness of the first approach than the second one, combining them leads to our best results of 70.77 F1-score on the test dataset.</abstract>
      <url hash="663ddfda">2021.semeval-1.120</url>
      <doi>10.18653/v1/2021.semeval-1.120</doi>
      <bibkey>nguyen-etal-2021-nlp</bibkey>
    </paper>
    <paper id="124">
      <title>MIPT-NSU-UTMN at SemEval-2021 Task 5 : Ensembling Learning with Pre-trained Language Models for Toxic Spans Detection<fixed-case>MIPT</fixed-case>-<fixed-case>NSU</fixed-case>-<fixed-case>UTMN</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 5: Ensembling Learning with Pre-trained Language Models for Toxic Spans Detection</title>
      <author><first>Mikhail</first><last>Kotyushev</last></author>
      <author><first>Anna</first><last>Glazkova</last></author>
      <author><first>Dmitry</first><last>Morozov</last></author>
      <pages>913–918</pages>
      <abstract>This paper describes our <a href="https://en.wikipedia.org/wiki/System">system</a> for SemEval-2021 Task 5 on Toxic Spans Detection. We developed ensemble models using BERT-based neural architectures and post-processing to combine tokens into spans. We evaluated several pre-trained language models using various ensemble techniques for toxic span identification and achieved sizable improvements over our baseline fine-tuned BERT models. Finally, our <a href="https://en.wikipedia.org/wiki/System">system</a> obtained a F1-score of 67.55 % on test data.</abstract>
      <url hash="3cd22cfb">2021.semeval-1.124</url>
      <doi>10.18653/v1/2021.semeval-1.124</doi>
      <bibkey>kotyushev-etal-2021-mipt</bibkey>
      <pwccode url="https://github.com/morozowdmitry/semeval21" additional="false">morozowdmitry/semeval21</pwccode>
    </paper>
    <paper id="125">
      <title>UIT-E10dot3 at SemEval-2021 Task 5 : Toxic Spans Detection with Named Entity Recognition and Question-Answering Approaches<fixed-case>UIT</fixed-case>-E10dot3 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 5: Toxic Spans Detection with Named Entity Recognition and Question-Answering Approaches</title>
      <author><first>Phu</first><last>Gia Hoang</last></author>
      <author><first>Luan</first><last>Thanh Nguyen</last></author>
      <author><first>Kiet</first><last>Nguyen</last></author>
      <pages>919–926</pages>
      <abstract>The increment of toxic comments on online space is causing tremendous effects on other vulnerable users. For this reason, considerable efforts are made to deal with this, and SemEval-2021 Task 5 : Toxic Spans Detection is one of those. This task asks competitors to extract spans that have <a href="https://en.wikipedia.org/wiki/Toxicity">toxicity</a> from the given texts, and we have done several analyses to understand its structure before doing experiments. We solve this task by two approaches, <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">Named Entity Recognition</a> with spaCy’s library and <a href="https://en.wikipedia.org/wiki/Question_answering">Question-Answering</a> with RoBERTa combining with ToxicBERT, and the former gains the highest <a href="https://en.wikipedia.org/wiki/F-number">F1-score</a> of 66.99 %.</abstract>
      <url hash="2224d5c1">2021.semeval-1.125</url>
      <doi>10.18653/v1/2021.semeval-1.125</doi>
      <bibkey>gia-hoang-etal-2021-uit</bibkey>
    </paper>
    <paper id="130">
      <title>YoungSheldon at SemEval-2021 Task 5 : Fine-tuning Pre-trained Language Models for Toxic Spans Detection using Token classification Objective<fixed-case>Y</fixed-case>oung<fixed-case>S</fixed-case>heldon at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 5: Fine-tuning Pre-trained Language Models for Toxic Spans Detection using Token classification Objective</title>
      <author><first>Mayukh</first><last>Sharma</last></author>
      <author><first>Ilanthenral</first><last>Kandasamy</last></author>
      <author><first>W.b.</first><last>Vasantha</last></author>
      <pages>953–959</pages>
      <abstract>In this paper, we describe our <a href="https://en.wikipedia.org/wiki/System">system</a> used for SemEval 2021 Task 5 : Toxic Spans Detection. Our proposed <a href="https://en.wikipedia.org/wiki/System">system</a> approaches the <a href="https://en.wikipedia.org/wiki/Problem_solving">problem</a> as a token classification task. We trained our model to find toxic words and concatenate their spans to predict the toxic spans within a sentence. We fine-tuned Pre-trained Language Models (PLMs) for identifying the toxic words. For fine-tuning, we stacked the classification layer on top of the PLM features of each word to classify if it is toxic or not. PLMs are pre-trained using different objectives and their performance may differ on downstream tasks. We, therefore, compare the performance of BERT, ELECTRA, RoBERTa, XLM-RoBERTa, T5, XLNet, and MPNet for identifying toxic spans within a sentence. Our best performing <a href="https://en.wikipedia.org/wiki/System">system</a> used RoBERTa. It performed well, achieving an F1 score of 0.6841 and secured a rank of 16 on the official leaderboard.</abstract>
      <url hash="5dc2313f">2021.semeval-1.130</url>
      <doi>10.18653/v1/2021.semeval-1.130</doi>
      <bibkey>sharma-etal-2021-youngsheldon</bibkey>
      <pwccode url="https://github.com/04mayukh/YoungSheldon-at-SemEval-2021-Task-5-Toxic-Spans-Detection" additional="false">04mayukh/YoungSheldon-at-SemEval-2021-Task-5-Toxic-Spans-Detection</pwccode>
    </paper>
    <paper id="134">
      <title>SINAI at SemEval-2021 Task 5 : Combining Embeddings in a BiLSTM-CRF model for Toxic Spans Detection<fixed-case>SINAI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 5: Combining Embeddings in a <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case>-<fixed-case>CRF</fixed-case> model for Toxic Spans Detection</title>
      <author><first>Flor Miriam</first><last>Plaza-del-Arco</last></author>
      <author><first>Pilar</first><last>López-Úbeda</last></author>
      <author><first>L. Alfonso</first><last>Ureña-López</last></author>
      <author><first>M. Teresa</first><last>Martín-Valdivia</last></author>
      <pages>984–989</pages>
      <abstract>This paper describes the participation of SINAI team at Task 5 : Toxic Spans Detection which consists of identifying spans that make a text toxic. Although several resources and systems have been developed so far in the context of <a href="https://en.wikipedia.org/wiki/Profanity">offensive language</a>, both <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a> and tasks have mainly focused on classifying whether a text is offensive or not. However, detecting toxic spans is crucial to identify why a text is toxic and can assist human moderators to locate this type of content on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. In order to accomplish the task, we follow a deep learning-based approach using a Bidirectional variant of a Long Short Term Memory network along with a stacked Conditional Random Field decoding layer (BiLSTM-CRF). Specifically, we test the performance of the combination of different pre-trained word embeddings for recognizing toxic entities in text. The results show that the combination of word embeddings helps in detecting offensive content. Our team ranks 29th out of 91 participants.</abstract>
      <url hash="00e3f120">2021.semeval-1.134</url>
      <doi>10.18653/v1/2021.semeval-1.134</doi>
      <bibkey>plaza-del-arco-etal-2021-sinai</bibkey>
    </paper>
    <paper id="135">
      <title>CSECU-DSG at SemEval-2021 Task 5 : Leveraging Ensemble of Sequence Tagging Models for Toxic Spans Detection<fixed-case>CSECU</fixed-case>-<fixed-case>DSG</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 5: Leveraging Ensemble of Sequence Tagging Models for Toxic Spans Detection</title>
      <author><first>Tashin</first><last>Hossain</last></author>
      <author><first>Jannatun</first><last>Naim</last></author>
      <author><first>Fareen</first><last>Tasneem</last></author>
      <author><first>Radiathun</first><last>Tasnia</last></author>
      <author><first>Abu Nowshed</first><last>Chy</last></author>
      <pages>990–994</pages>
      <abstract>The upsurge of prolific <a href="https://en.wikipedia.org/wiki/Blog">blogging</a> and <a href="https://en.wikipedia.org/wiki/Microblogging">microblogging platforms</a> enabled the abusers to spread negativity and <a href="https://en.wikipedia.org/wiki/Threat">threats</a> greater than ever. Detecting the toxic portions substantially aids to moderate or exclude the abusive parts for maintaining sound online platforms. This paper describes our participation in the SemEval 2021 toxic span detection task. The <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> requires detecting spans that convey toxic remarks from the given text. We explore an ensemble of sequence labeling models including the BiLSTM-CRF, spaCy NER model with custom toxic tags, and fine-tuned BERT model to identify the toxic spans. Finally, a majority voting ensemble method is used to determine the unified toxic spans. Experimental results depict the competitive performance of our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> among the participants.</abstract>
      <url hash="fddb0463">2021.semeval-1.135</url>
      <doi>10.18653/v1/2021.semeval-1.135</doi>
      <bibkey>hossain-etal-2021-csecu</bibkey>
    </paper>
    <paper id="140">
      <title>AIMH at SemEval-2021 Task 6 : Multimodal Classification Using an Ensemble of Transformer Models<fixed-case>AIMH</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 6: Multimodal Classification Using an Ensemble of Transformer Models</title>
      <author><first>Nicola</first><last>Messina</last></author>
      <author><first>Fabrizio</first><last>Falchi</last></author>
      <author><first>Claudio</first><last>Gennaro</last></author>
      <author><first>Giuseppe</first><last>Amato</last></author>
      <pages>1020–1026</pages>
      <abstract>This paper describes the <a href="https://en.wikipedia.org/wiki/System">system</a> used by the AIMH Team to approach the SemEval Task 6. We propose an approach that relies on an architecture based on the transformer model to process multimodal content (text and images) in memes. Our architecture, called DVTT (Double Visual Textual Transformer), approaches Subtasks 1 and 3 of Task 6 as multi-label classification problems, where the text and/or images of the meme are processed, and the probabilities of the presence of each possible persuasion technique are returned as a result. DVTT uses two complete networks of transformers that work on text and images that are mutually conditioned. One of the two <a href="https://en.wikipedia.org/wiki/Methodology">modalities</a> acts as the main one and the second one intervenes to enrich the first one, thus obtaining two distinct ways of operation. The two transformers outputs are merged by averaging the inferred probabilities for each possible label, and the overall <a href="https://en.wikipedia.org/wiki/Neural_network">network</a> is trained end-to-end with a binary cross-entropy loss.</abstract>
      <url hash="b93fad50">2021.semeval-1.140</url>
      <doi>10.18653/v1/2021.semeval-1.140</doi>
      <bibkey>messina-etal-2021-aimh</bibkey>
      <pwccode url="https://github.com/mesnico/memepersuasiondetection" additional="false">mesnico/memepersuasiondetection</pwccode>
    </paper>
    <paper id="142">
      <title>1213Li at SemEval-2021 Task 6 : Detection of Propaganda with Multi-modal Attention and Pre-trained Models<fixed-case>L</fixed-case>i at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 6: Detection of Propaganda with Multi-modal Attention and Pre-trained Models</title>
      <author><first>Peiguang</first><last>Li</last></author>
      <author><first>Xuan</first><last>Li</last></author>
      <author><first>Xian</first><last>Sun</last></author>
      <pages>1032–1036</pages>
      <abstract>This paper presents the solution proposed by the 1213Li team for subtask 3 in SemEval-2021 Task 6 : identifying the multiple persuasion techniques used in the multi-modal content of the meme. We explored various approaches in <a href="https://en.wikipedia.org/wiki/Feature_extraction">feature extraction</a> and the detection of persuasion labels. Our final model employs pre-trained models including RoBERTa and ResNet-50 as a feature extractor for texts and images, respectively, and adopts a label embedding layer with multi-modal attention mechanism to measure the similarity of labels with the multi-modal information and fuse features for label prediction. Our proposed method outperforms the provided baseline method and achieves 3rd out of 16 participants with 0.54860/0.22830 for Micro / Macro F1 scores.</abstract>
      <url hash="80a3f25e">2021.semeval-1.142</url>
      <doi>10.18653/v1/2021.semeval-1.142</doi>
      <bibkey>li-etal-2021-1213li</bibkey>
    </paper>
    <paper id="143">
      <title>NLyticsFKIE at SemEval-2021 Task 6 : Detection of Persuasion Techniques In Texts And Images<fixed-case>NL</fixed-case>ytics<fixed-case>FKIE</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 6: Detection of Persuasion Techniques In Texts And Images</title>
      <author><first>Albert</first><last>Pritzkau</last></author>
      <pages>1037–1044</pages>
      <abstract>The following system description presents our approach to the detection of persuasion techniques in <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">texts</a> and <a href="https://en.wikipedia.org/wiki/Digital_image">images</a>. The given <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> has been framed as a multi-label classification problem with the different techniques serving as class labels. The multi-label classification problem is one in which a list of target variables such as our class labels is associated with every input chunk and assumes that a document can simultaneously and independently be assigned to multiple labels or classes. In order to assign class labels to the given memes, we opted for RoBERTa (A Robustly Optimized BERT Pretraining Approach) as a neural network architecture for token and sequence classification. Starting off with a pre-trained model for language representation we fine-tuned this <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> on the given classification task with the provided annotated data in supervised training steps. To incorporate image features in the multi-modal setting, we rely on the pre-trained VGG-16 model architecture.</abstract>
      <url hash="169b5893">2021.semeval-1.143</url>
      <doi>10.18653/v1/2021.semeval-1.143</doi>
      <bibkey>pritzkau-2021-nlyticsfkie</bibkey>
    </paper>
    <paper id="144">
      <title>YNU-HPCC at SemEval-2021 Task 6 : Combining ALBERT and Text-CNN for Persuasion Detection in Texts and Images<fixed-case>YNU</fixed-case>-<fixed-case>HPCC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 6: Combining <fixed-case>ALBERT</fixed-case> and Text-<fixed-case>CNN</fixed-case> for Persuasion Detection in Texts and Images</title>
      <author><first>Xingyu</first><last>Zhu</last></author>
      <author><first>Jin</first><last>Wang</last></author>
      <author><first>Xuejie</first><last>Zhang</last></author>
      <pages>1045–1050</pages>
      <abstract>In recent years, <a href="https://en.wikipedia.org/wiki/Meme">memes</a> combining image and text have been widely used in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>, and <a href="https://en.wikipedia.org/wiki/Meme">memes</a> are one of the most popular types of content used in online disinformation campaigns. In this paper, our study on the detection of persuasion techniques in <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">texts</a> and <a href="https://en.wikipedia.org/wiki/Image">images</a> in SemEval-2021 Task 6 is summarized. For propaganda technology detection in text, we propose a combination model of both ALBERT and Text CNN for text classification, as well as a BERT-based multi-task sequence labeling model for propaganda technology coverage span detection. For the meme classification task involved in text understanding and visual feature extraction, we designed a parallel channel model divided into text and image channels. Our <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">method</a> achieved a good performance on subtasks 1 and 3. The micro F1-scores of 0.492, 0.091, and 0.446 achieved on the test sets of the three subtasks ranked 12th, 7th, and 11th, respectively, and all are higher than the baseline model.</abstract>
      <url hash="2c64dfa5">2021.semeval-1.144</url>
      <doi>10.18653/v1/2021.semeval-1.144</doi>
      <bibkey>zhu-etal-2021-ynu</bibkey>
    </paper>
    <paper id="147">
      <title>NLPIITR at SemEval-2021 Task 6 : RoBERTa Model with Data Augmentation for Persuasion Techniques Detection<fixed-case>NLPIITR</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 6: <fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a Model with Data Augmentation for Persuasion Techniques Detection</title>
      <author><first>Vansh</first><last>Gupta</last></author>
      <author><first>Raksha</first><last>Sharma</last></author>
      <pages>1061–1067</pages>
      <abstract>This paper describes and examines different systems to address Task 6 of SemEval-2021 : Detection of Persuasion Techniques In Texts And Images, Subtask 1. The task aims to build a model for identifying rhetorical and psycho- logical techniques (such as causal oversimplification, name-calling, smear) in the textual content of a meme which is often used in a disinformation campaign to influence the users. The paper provides an extensive comparison among various <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning systems</a> as a solution to the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. We elaborate on the pre-processing of the <a href="https://en.wikipedia.org/wiki/Text_file">text data</a> in favor of the task and present ways to overcome the class imbalance. The results show that fine-tuning a RoBERTa model gave the best results with an <a href="https://en.wikipedia.org/wiki/F-number">F1-Micro score</a> of 0.51 on the development set.</abstract>
      <url hash="df07c2ca">2021.semeval-1.147</url>
      <doi>10.18653/v1/2021.semeval-1.147</doi>
      <bibkey>gupta-sharma-2021-nlpiitr</bibkey>
    </paper>
    <paper id="150">
      <title>MinD at SemEval-2021 Task 6 : Propaganda Detection using Transfer Learning and Multimodal Fusion<fixed-case>M</fixed-case>in<fixed-case>D</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 6: Propaganda Detection using Transfer Learning and Multimodal Fusion</title>
      <author><first>Junfeng</first><last>Tian</last></author>
      <author><first>Min</first><last>Gui</last></author>
      <author><first>Chenliang</first><last>Li</last></author>
      <author><first>Ming</first><last>Yan</last></author>
      <author><first>Wenming</first><last>Xiao</last></author>
      <pages>1082–1087</pages>
      <abstract>We describe our systems of subtask1 and subtask3 for SemEval-2021 Task 6 on Detection of Persuasion Techniques in Texts and Images. The purpose of subtask1 is to identify <a href="https://en.wikipedia.org/wiki/Propaganda_techniques">propaganda techniques</a> given textual content, and the goal of subtask3 is to detect them given both textual and visual content. For subtask1, we investigate <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> based on pre-trained language models (PLMs) such as <a href="https://en.wikipedia.org/wiki/BERT">BERT</a>, RoBERTa to solve data sparsity problems. For subtask3, we extract <a href="https://en.wikipedia.org/wiki/Homogeneity_and_heterogeneity">heterogeneous visual representations</a> (i.e., face features, <a href="https://en.wikipedia.org/wiki/Optical_character_recognition">OCR features</a>, and multimodal representations) and explore various multimodal fusion strategies to combine the textual and visual representations. The official evaluation shows our ensemble model ranks 1st for subtask1 and 2nd for subtask3.</abstract>
      <url hash="11e6eb23">2021.semeval-1.150</url>
      <doi>10.18653/v1/2021.semeval-1.150</doi>
      <bibkey>tian-etal-2021-mind</bibkey>
    </paper>
    <paper id="151">
      <title>CSECU-DSG at SemEval-2021 Task 6 : Orchestrating Multimodal Neural Architectures for Identifying Persuasion Techniques in Texts and Images<fixed-case>CSECU</fixed-case>-<fixed-case>DSG</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 6: Orchestrating Multimodal Neural Architectures for Identifying Persuasion Techniques in Texts and Images</title>
      <author><first>Tashin</first><last>Hossain</last></author>
      <author><first>Jannatun</first><last>Naim</last></author>
      <author><first>Fareen</first><last>Tasneem</last></author>
      <author><first>Radiathun</first><last>Tasnia</last></author>
      <author><first>Abu Nowshed</first><last>Chy</last></author>
      <pages>1088–1095</pages>
      <abstract>Inscribing persuasion techniques in <a href="https://en.wikipedia.org/wiki/Meme">memes</a> is the most impactful way to influence peoples’ mindsets. People are more inclined to memes as they are more stimulating and convincing and hence <a href="https://en.wikipedia.org/wiki/Meme">memes</a> are often exploited by tactfully engraving propaganda in its context with the intent of attaining specific agenda. This paper describes our participation in the three subtasks featured by SemEval 2021 task 6 on the detection of persuasion techniques in <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">texts</a> and <a href="https://en.wikipedia.org/wiki/Image">images</a>. We utilize a fusion of <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a>, <a href="https://en.wikipedia.org/wiki/Decision_tree_learning">decision tree</a>, and fine-tuned DistilBERT for tackling subtask 1. As for subtask 2, we propose a system that consolidates a span identification model and a multi-label classification model based on pre-trained BERT. We address the multi-modal multi-label classification of memes defined in subtask 3 by utilizing a ResNet50 based image model, DistilBERT based text model, and a multi-modal architecture based on multikernel CNN+LSTM and MLP model. The outcomes illustrated the competitive performance of our <a href="https://en.wikipedia.org/wiki/System">systems</a>.</abstract>
      <url hash="4fbd2a9b">2021.semeval-1.151</url>
      <doi>10.18653/v1/2021.semeval-1.151</doi>
      <bibkey>hossain-etal-2021-csecu-dsg</bibkey>
    </paper>
    <paper id="152">
      <title>UMUTeam at SemEval-2021 Task 7 : Detecting and Rating Humor and Offense with Linguistic Features and Word Embeddings<fixed-case>UMUT</fixed-case>eam at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 7: Detecting and Rating Humor and Offense with Linguistic Features and Word Embeddings</title>
      <author><first>José Antonio</first><last>García-Díaz</last></author>
      <author><first>Rafael</first><last>Valencia-García</last></author>
      <pages>1096–1101</pages>
      <abstract>In writing, <a href="https://en.wikipedia.org/wiki/Humour">humor</a> is mainly based on <a href="https://en.wikipedia.org/wiki/Literal_and_figurative_language">figurative language</a> in which words and expressions change their conventional meaning to refer to something without saying it directly. This flip in the meaning of the words prevents <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a> from revealing the real intention of a communication and, therefore, reduces the effectiveness of tasks such as <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> or <a href="https://en.wikipedia.org/wiki/Emotion_detection">Emotion Detection</a>. In this manuscript we describe the participation of the UMUTeam in HaHackathon 2021, whose objective is to detect and rate humorous and controversial content. Our proposal is based on the combination of <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">linguistic features</a> with contextual and non-contextual word embeddings. We participate in all the proposed subtasks achieving our best result in the controversial humor subtask.</abstract>
      <url hash="74fe961f">2021.semeval-1.152</url>
      <doi>10.18653/v1/2021.semeval-1.152</doi>
      <bibkey>garcia-diaz-valencia-garcia-2021-umuteam</bibkey>
      <pwccode url="https://github.com/smolky/hahackathon-2021" additional="false">smolky/hahackathon-2021</pwccode>
    </paper>
    <paper id="153">
      <title>ES-JUST at SemEval-2021 Task 7 : Detecting and Rating Humor and Offensive Text Using <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a><fixed-case>ES</fixed-case>-<fixed-case>JUST</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 7: Detecting and Rating Humor and Offensive Text Using Deep Learning</title>
      <author><first>Emran</first><last>Al Bashabsheh</last></author>
      <author><first>Sanaa</first><last>Abu Alasal</last></author>
      <pages>1102–1107</pages>
      <abstract>This research presents the work of the team’s ES-JUST at semEval-2021 task 7 for detecting and rating humor and offensive text using <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a>. The team evaluates several approaches (i.e. Bert, Roberta, XLM-Roberta, and Bert embedding + Bi-LSTM) that employ in four sub-tasks. The first sub-task deal with whether the text is humorous or not. The second sub-task is the degree of <a href="https://en.wikipedia.org/wiki/Humour">humor</a> in the text if the first <a href="https://en.wikipedia.org/wiki/Task_(project_management)">sub-task</a> is humorous. The third sub-task represents the text is controversial or not if it is humorous. While in the last task is the degree of an offensive in the text. However, Roberta pre-trained model outperforms other approaches and score the highest in all sub-tasks. We rank on the leader board at the evaluation phase are 14, 15, 20, and 5 through 0.9564 <a href="https://en.wikipedia.org/wiki/F-score">F-score</a>, 0.5709 <a href="https://en.wikipedia.org/wiki/Randomized_controlled_trial">RMSE</a>, 0.4888 <a href="https://en.wikipedia.org/wiki/F-score">F-score</a>, and 0.4467 RMSE results, respectively, for each of the first, second, third, and fourth sub-task, respectively.<i>i.e.Bert, Roberta, XLM-Roberta, and Bert embedding + Bi-LSTM</i>) that employ in four sub-tasks. The first sub-task deal with whether the text is humorous or not. The second sub-task is the degree of humor in the text if the first sub-task is humorous. The third sub-task represents the text is controversial or not if it is humorous. While in the last task is the degree of an offensive in the text. However, Roberta pre-trained model outperforms other approaches and score the highest in all sub-tasks. We rank on the leader board at the evaluation phase are 14, 15, 20, and 5 through 0.9564 F-score, 0.5709 RMSE, 0.4888 F-score, and 0.4467 RMSE results, respectively, for each of the first, second, third, and fourth sub-task, respectively.</abstract>
      <url hash="77c8076d">2021.semeval-1.153</url>
      <doi>10.18653/v1/2021.semeval-1.153</doi>
      <bibkey>al-bashabsheh-abu-alasal-2021-es</bibkey>
    </paper>
    <paper id="154">
      <title>Tsia at SemEval-2021 Task 7 : Detecting and Rating Humor and Offense<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 7: Detecting and Rating Humor and Offense</title>
      <author><first>Zhengyi</first><last>Guan</last></author>
      <author><first>Xiaobing ZXB</first><last>Zhou</last></author>
      <pages>1108–1113</pages>
      <abstract>This paper describes our contribution to SemEval-2021 Task 7 : Detecting and Rating Humor and Of-fense. This task contains two sub-tasks, sub-task 1and sub-task 2. Among them, sub-task 1 containsthree <a href="https://en.wikipedia.org/wiki/Task_(project_management)">sub-tasks</a>, sub-task 1a, sub-task 1b and sub-task 1c. Sub-task 1a is to predict if the text would beconsidered humorous. Sub-task 1c is described asfollows : if the text is classed as humorous, predictif the humor rating would be considered controver-sial, i.e. the variance of the rating between annota-tors is higher than the median.we combined threepre-trained model with CNN to complete these twoclassification sub-tasks. Sub-task 1b is to judge thedegree of <a href="https://en.wikipedia.org/wiki/Humour">humor</a>. Sub-task 2 aims to predict how of-fensive a text would be with values between 0 and5.We use the idea of <a href="https://en.wikipedia.org/wiki/Regression_analysis">regression</a> to deal with thesetwo sub-tasks. We analyze the performance of ourmethod and demonstrate the contribution of eachcomponent of our architecture. We have achievedgood results under the combination of multiple pre-training models and optimization methods.</abstract>
      <url hash="e4e56018">2021.semeval-1.154</url>
      <doi>10.18653/v1/2021.semeval-1.154</doi>
      <bibkey>guan-zhou-2021-tsia</bibkey>
    </paper>
    <paper id="169">
      <title>DuluthNLP at SemEval-2021 Task 7 : Fine-Tuning RoBERTa Model for Humor Detection and Offense Rating<fixed-case>D</fixed-case>uluth<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 7: Fine-Tuning <fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a Model for Humor Detection and Offense Rating</title>
      <author><first>Samuel</first><last>Akrah</last></author>
      <pages>1196–1203</pages>
      <abstract>This paper presents the DuluthNLP submission to Task 7 of the SemEval 2021 competition on Detecting and Rating Humor and Offense. In it, we explain the approach used to train the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> together with the process of fine-tuning our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> in getting the results. We focus on humor detection, rating, and of-fense rating, representing three out of the four subtasks that were provided. We show that optimizing hyper-parameters for learning rate, batch size and number of epochs can increase the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and <a href="https://en.wikipedia.org/wiki/F-number">F1 score</a> for humor detection</abstract>
      <url hash="43c79325">2021.semeval-1.169</url>
      <doi>10.18653/v1/2021.semeval-1.169</doi>
      <bibkey>akrah-2021-duluthnlp</bibkey>
      <pwccode url="https://github.com/akrahdan/semeval2021" additional="false">akrahdan/semeval2021</pwccode>
    </paper>
    <paper id="172">
      <title>EndTimes at SemEval-2021 Task 7 : Detecting and Rating Humor and Offense with BERT and Ensembles<fixed-case>E</fixed-case>nd<fixed-case>T</fixed-case>imes at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 7: Detecting and Rating Humor and Offense with <fixed-case>BERT</fixed-case> and Ensembles</title>
      <author><first>Chandan Kumar</first><last>Pandey</last></author>
      <author><first>Chirag</first><last>Singh</last></author>
      <author><first>Karan</first><last>Mangla</last></author>
      <pages>1215–1220</pages>
      <abstract>This paper describes Humor-BERT, a set of BERT Large based models that we used in the SemEval-2021 Task 7 : Detecting and Rating Humor and Offense. It presents pre and post processing techniques, variable threshold learning, meta learning and Ensemble approach to solve various sub-tasks that were part of the challenge. We also present a comparative analysis of various <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> we tried. Our method was ranked 4th in Humor Controversy Detection, 8th in Humor Detection, 19th in Average Offense Score prediction and 40th in Average Humor Score prediction globally. F1 score obtained for <a href="https://en.wikipedia.org/wiki/Humorism">Humor classification</a> was 0.9655 and for Controversy detection it was 0.6261. Our user name on the leader board is ThisIstheEnd and team name is EndTimes.</abstract>
      <url hash="ef655998">2021.semeval-1.172</url>
      <doi>10.18653/v1/2021.semeval-1.172</doi>
      <bibkey>pandey-etal-2021-endtimes</bibkey>
    </paper>
    <paper id="173">
      <title>IIITH at SemEval-2021 Task 7 : Leveraging transformer-based humourous and offensive text detection architectures using lexical and hurtlex features and task adaptive pretraining<fixed-case>IIITH</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 7: Leveraging transformer-based humourous and offensive text detection architectures using lexical and hurtlex features and task adaptive pretraining</title>
      <author><first>Tathagata</first><last>Raha</last></author>
      <author><first>Ishan Sanjeev</first><last>Upadhyay</last></author>
      <author><first>Radhika</first><last>Mamidi</last></author>
      <author><first>Vasudeva</first><last>Varma</last></author>
      <pages>1221–1225</pages>
      <abstract>This paper describes our approach (IIITH) for SemEval-2021 Task 5 : HaHackathon : Detecting and Rating Humor and Offense. Our results focus on two major objectives : (i) Effect of task adaptive pretraining on the performance of transformer based models (ii) How does lexical and hurtlex features help in quantifying humour and offense. In this paper, we provide a detailed description of our approach along with comparisions mentioned above.</abstract>
      <url hash="f0067e0d">2021.semeval-1.173</url>
      <doi>10.18653/v1/2021.semeval-1.173</doi>
      <bibkey>raha-etal-2021-iiith</bibkey>
    </paper>
    <paper id="180">
      <title>Volta at SemEval-2021 Task 9 : Statement Verification and Evidence Finding with Tables using TAPAS and Transfer Learning<fixed-case>V</fixed-case>olta at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 9: Statement Verification and Evidence Finding with Tables using <fixed-case>TAPAS</fixed-case> and Transfer Learning</title>
      <author><first>Devansh</first><last>Gautam</last></author>
      <author><first>Kshitij</first><last>Gupta</last></author>
      <author><first>Manish</first><last>Shrivastava</last></author>
      <pages>1262–1270</pages>
      <abstract>Tables are widely used in various kinds of documents to present information concisely. Understanding tables is a challenging problem that requires an understanding of language and table structure, along with numerical and logical reasoning. In this paper, we present our systems to solve Task 9 of SemEval-2021 : Statement Verification and Evidence Finding with Tables (SEM-TAB-FACTS). The task consists of two subtasks : (A) Given a table and a statement, predicting whether the table supports the statement and (B) Predicting which cells in the table provide evidence for / against the statement. We fine-tune TAPAS (a model which extends BERT’s architecture to capture tabular structure) for both the subtasks as it has shown state-of-the-art performance in various table understanding tasks. In subtask A, we evaluate how <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> and standardizing tables to have a single header row improves TAPAS’ performance. In subtask B, we evaluate how different fine-tuning strategies can improve TAPAS’ performance. Our systems achieve an <a href="https://en.wikipedia.org/wiki/International_Federation_of_the_Phonographic_Industry">F1 score</a> of 67.34 in subtask A three-way classification, 72.89 in subtask A <a href="https://en.wikipedia.org/wiki/International_Federation_of_the_Phonographic_Industry">two-way classification</a>, and 62.95 in subtask B.</abstract>
      <url hash="7cb9f3e6">2021.semeval-1.180</url>
      <doi>10.18653/v1/2021.semeval-1.180</doi>
      <bibkey>gautam-etal-2021-volta</bibkey>
      <pwccode url="https://github.com/devanshg27/sem-tab-fact" additional="false">devanshg27/sem-tab-fact</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/sqa">SQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/tabfact">TabFact</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikisql">WikiSQL</pwcdataset>
    </paper>
    <paper id="184">
      <title>YNU-HPCC at SemEval-2021 Task 10 : Using a Transformer-based Source-Free Domain Adaptation Model for Semantic Processing<fixed-case>YNU</fixed-case>-<fixed-case>HPCC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 10: Using a Transformer-based Source-Free Domain Adaptation Model for Semantic Processing</title>
      <author><first>Zhewen</first><last>Yu</last></author>
      <author><first>Jin</first><last>Wang</last></author>
      <author><first>Xuejie</first><last>Zhang</last></author>
      <pages>1289–1294</pages>
      <abstract>Data sharing restrictions are common in NLP datasets. The purpose of this task is to develop a <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> trained in a source domain to make predictions for a target domain with related domain data. To address the issue, the organizers provided the <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> that fine-tuned a large number of source domain data on pre-trained models and the dev data for participants. But the source domain data was not distributed. This paper describes the provided <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> to the NER (Name entity recognition) task and the ways to develop the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>. As a little data provided, pre-trained models are suitable to solve the cross-domain tasks. The models fine-tuned by large number of another domain could be effective in new domain because the task had no change.</abstract>
      <url hash="6d99ab08">2021.semeval-1.184</url>
      <doi>10.18653/v1/2021.semeval-1.184</doi>
      <bibkey>yu-etal-2021-ynu</bibkey>
    </paper>
    <paper id="186">
      <title>UOR at SemEval-2021 Task 12 : On Crowd Annotations ; Learning with Disagreements to optimise crowd truth<fixed-case>UOR</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2021 Task 12: On Crowd Annotations; Learning with Disagreements to optimise crowd truth</title>
      <author><first>Emmanuel</first><last>Osei-Brefo</last></author>
      <author><first>Thanet</first><last>Markchom</last></author>
      <author><first>Huizhi</first><last>Liang</last></author>
      <pages>1303–1309</pages>
      <abstract>Crowdsourcing has been ubiquitously used for annotating enormous collections of data. However, the major obstacles to using crowd-sourced labels are <a href="https://en.wikipedia.org/wiki/Noise_(signal_processing)">noise</a> and errors from non-expert annotations. In this work, two approaches dealing with the <a href="https://en.wikipedia.org/wiki/Noise">noise</a> and errors in crowd-sourced labels are proposed. The first approach uses Sharpness-Aware Minimization (SAM), an optimization technique robust to noisy labels. The other approach leverages a neural network layer called softmax-Crowdlayer specifically designed to learn from crowd-sourced annotations. According to the results, the proposed approaches can improve the performance of the Wide Residual Network model and Multi-layer Perception model applied on crowd-sourced datasets in the image processing domain. It also has similar and comparable results with the majority voting technique when applied to the sequential data domain whereby the Bidirectional Encoder Representations from Transformers (BERT) is used as the base model in both instances.</abstract>
      <url hash="2fd78e6c">2021.semeval-1.186</url>
      <doi>10.18653/v1/2021.semeval-1.186</doi>
      <bibkey>osei-brefo-etal-2021-uor</bibkey>
    </paper>
  </volume>
</collection>