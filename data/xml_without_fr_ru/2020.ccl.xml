<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.ccl">
  <volume id="1" ingest-date="2020-10-25">
    <meta>
      <booktitle>Proceedings of the 19th Chinese National Conference on Computational Linguistics</booktitle>
      <editor><first>Maosong</first><last>Sun</last><variant script="hani"><first>茂松</first><last>孙</last></variant></editor>
      <editor><first>Sujian</first><last>Li</last><variant script="hani"><first>素建</first><last>李</last></variant></editor>
      <editor><first>Yue</first><last>Zhang</last><variant script="hani"><first>岳</first><last>张</last></variant></editor>
      <editor id="yang-liu-ict"><first>Yang</first><last>Liu</last><variant script="hani"><first>洋</first><last>刘</last></variant></editor>
      <publisher>Chinese Information Processing Society of China</publisher>
      <address>Haikou, China</address>
      <month>October</month>
      <year>2020</year>
      <url hash="77087a9d">2020.ccl-1</url>
    </meta>
    <frontmatter>
      <url hash="40669208">2020.ccl-1.0</url>
      <bibkey>ccl-2020-chinese</bibkey>
    </frontmatter>
    <paper id="76">
      <title>A Joint Model for Graph-based Chinese Dependency Parsing<fixed-case>C</fixed-case>hinese Dependency Parsing</title>
      <author><first>Xingchen</first><last>Li</last></author>
      <author><first>Mingtong</first><last>Liu</last></author>
      <author><first>Yujie</first><last>Zhang</last></author>
      <author><first>Jinan</first><last>Xu</last></author>
      <author><first>Yufeng</first><last>Chen</last></author>
      <pages>820–830</pages>
      <abstract>In Chinese dependency parsing, the joint model of <a href="https://en.wikipedia.org/wiki/Word_segmentation">word segmentation</a>, POS tagging and dependency parsing has become the mainstream framework because it can eliminate error propagation and share knowledge, where the transition-based model with feature templates maintains the best performance. Recently, the graph-based joint model (Yan et al., 2019) on <a href="https://en.wikipedia.org/wiki/Word_segmentation">word segmentation</a> and dependency parsing has achieved better performance, demonstrating the advantages of the graph-based models. However, this work can not provide POS information for downstream tasks, and the POS tagging task was proved to be helpful to the dependency parsing according to the research of the transition-based model. Therefore, we propose a graph-based joint model for <a href="https://en.wikipedia.org/wiki/Chinese_word_segmentation">Chinese word segmentation</a>, <a href="https://en.wikipedia.org/wiki/Tag_(metadata)">POS tagging</a> and dependency parsing. We designed a charater-level POS tagging task, and then train it jointly with the model of Yan et al. We adopt two methods of joint POS tagging task, one is by sharing parameters, the other is by using tag attention mechanism, which enables the three tasks to better share intermediate information and improve each other’s performance. The experimental results on the Penn Chinese treebank (CTB5) show that our proposed joint model improved by 0.38 % on dependency parsing than the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> of Yan et al. Compared with the best transition-based joint model, our <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> improved by 0.18 %, 0.35 % and 5.99 % respectively in terms of <a href="https://en.wikipedia.org/wiki/Word_segmentation">word segmentation</a>, <a href="https://en.wikipedia.org/wiki/Tag_(metadata)">POS tagging</a> and dependency parsing.</abstract>
      <url hash="e94ecd79">2020.ccl-1.76</url>
      <language>eng</language>
      <bibkey>li-etal-2020-joint</bibkey>
    </paper>
    <paper id="77">
      <title>Semantic-aware Chinese Zero Pronoun Resolution with Pre-trained Semantic Dependency Parser<fixed-case>C</fixed-case>hinese Zero Pronoun Resolution with Pre-trained Semantic Dependency Parser</title>
      <author><first>Lanqiu</first><last>Zhang</last></author>
      <author><first>Zizhuo</first><last>Shen</last></author>
      <author><first>Yanqiu</first><last>Shao</last></author>
      <pages>831–841</pages>
      <abstract>Deep learning-based Chinese zero pronoun resolution model has achieved better performance than traditional machine learning-based model. However, the existing work related to Chinese zero pronoun resolution has not yet well integrated linguistic information into the deep learningbased Chinese zero pronoun resolution model. This paper adopts the idea based on the pre-trained model, and integrates the semantic representations in the pre-trained Chinese semantic dependency graph parser into the Chinese zero pronoun resolution model. The experimental results on OntoNotes-5.0 dataset show that our proposed Chinese zero pronoun resolution model with pretrained Chinese semantic dependency parser improves the F-score by 0.4 % compared with our baseline model, and obtains better results than other deep learning-based Chinese zero pronoun resolution models. In addition, we integrate the BERT representations into our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> so that the performance of our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> was improved by 0.7 % compared with our baseline model.</abstract>
      <url hash="d997d211">2020.ccl-1.77</url>
      <language>eng</language>
      <bibkey>zhang-etal-2020-semantic</bibkey>
    </paper>
    <paper id="82">
      <title>Refining Data for <a href="https://en.wikipedia.org/wiki/Text-based_user_interface">Text Generation</a></title>
      <author><first>Wenyu</first> <last>Guan</last></author>
      <author><first>Qianying</first> <last>Liu</last></author>
      <author><first>Tianyi</first> <last>Li</last></author>
      <author><first>Sujian</first><last>Li</last></author>
      <pages>881–891</pages>
      <abstract>Recent work on data-to-text generation has made progress under the neural encoder-decoder architectures. However, the data input size is often enormous, while not all data records are important for text generation and inappropriate input may bring noise into the final output. To solve this problem, we propose a two-step approach which first selects and orders the important data records and then generates text from the noise-reduced data. Here we propose a learning to rank model to rank the importance of each record which is supervised by a relation extractor. With the noise-reduced data as input, we implement a <a href="https://en.wikipedia.org/wiki/Text_generator">text generator</a> which sequentially models the input data records and emits a summary. Experiments on the ROTOWIRE dataset verifies the effectiveness of our proposed method in both performance and efficiency.</abstract>
      <url hash="61f213b9">2020.ccl-1.82</url>
      <language>eng</language>
      <bibkey>guan-etal-2020-refining</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/rotowire">RotoWire</pwcdataset>
    </paper>
    <paper id="86">
      <title>Chinese Named Entity Recognition via Adaptive Multi-pass Memory Network with Hierarchical Tagging Mechanism<fixed-case>C</fixed-case>hinese Named Entity Recognition via Adaptive Multi-pass Memory Network with Hierarchical Tagging Mechanism</title>
      <author><first>Pengfei</first><last>Cao</last></author>
      <author><first>Yubo</first><last>Chen</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <pages>927–938</pages>
      <abstract>Named entity recognition (NER) aims to identify text spans that mention named entities and classify them into pre-defined categories. For Chinese NER task, most of the existing methods are character-based sequence labeling models and achieve great success. However, these methods usually ignore <a href="https://en.wikipedia.org/wiki/Lexical_analysis">lexical knowledge</a>, which leads to false prediction of entity boundaries. Moreover, these <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">methods</a> have difficulties in capturing tag dependencies. In this paper, we propose an Adaptive Multi-pass Memory Network with Hierarchical Tagging Mechanism (AMMNHT) to address all above problems. Specifically, to reduce the errors of predicting entity boundaries, we propose an adaptive multi-pass memory network to exploit lexical knowledge. In addition, we propose a hierarchical tagging layer to learn tag dependencies. Experimental results on three widely used Chinese NER datasets demonstrate that our proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> significantly outperforms other state-of-the-art methods.</abstract>
      <url hash="d79ac63c">2020.ccl-1.86</url>
      <language>eng</language>
      <bibkey>cao-etal-2020-chinese</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/weibo-ner">Weibo NER</pwcdataset>
    </paper>
    <paper id="89">
      <title>Entity Relative Position Representation based Multi-head Selection for Joint Entity and Relation Extraction</title>
      <author><first>Tianyang</first><last>Zhao</last></author>
      <author><first>Zhao</first><last>Yan</last></author>
      <author><first>Yunbo</first><last>Cao</last></author>
      <author><first>Zhoujun</first><last>Li</last></author>
      <pages>962–973</pages>
      <abstract>Joint entity and relation extraction has received increasing interests recently, due to the capability of utilizing the interactions between both steps. Among existing studies, the Multi-Head Selection (MHS) framework is efficient in extracting entities and relations simultaneously. However, the method is weak for its limited performance. In this paper, we propose several effective insights to address this problem. First, we propose an entity-specific Relative Position Representation (eRPR) to allow the model to fully leverage the distance information between entities and context tokens. Second, we introduce an auxiliary Global Relation Classification (GRC) to enhance the learning of local contextual features. Moreover, we improve the semantic representation by adopting a pre-trained language model BERT as the feature encoder. Finally, these new keypoints are closely integrated with the multi-head selection framework and optimized jointly. Extensive experiments on two benchmark datasets demonstrate that our approach overwhelmingly outperforms previous works in terms of all evaluation metrics, achieving significant improvements for relation F1 by +2.40 % on CoNLL04 and +1.90 % on ACE05, respectively.</abstract>
      <url hash="c7b42b94">2020.ccl-1.89</url>
      <language>eng</language>
      <bibkey>zhao-etal-2020-entity</bibkey>
    </paper>
    <paper id="92">
      <title>Low-Resource Text Classification via Cross-lingual Language Model Fine-tuning</title>
      <author><first>Xiuhong</first><last>Li</last></author>
      <author><first>Zhe</first><last>Li</last></author>
      <author><first>Jiabao</first><last>Sheng</last></author>
      <author><first>Wushour</first><last>Slamu</last></author>
      <pages>994–1005</pages>
      <abstract>Text classification tends to be difficult when data are inadequate considering the amount of manually labeled text corpora. For low-resource agglutinative languages including <a href="https://en.wikipedia.org/wiki/Uyghur_language">Uyghur</a>, <a href="https://en.wikipedia.org/wiki/Kazakh_language">Kazakh</a>, and Kyrgyz (UKK languages), in which words are manufactured via <a href="https://en.wikipedia.org/wiki/Word_stem">stems</a> concatenated with several suffixes and <a href="https://en.wikipedia.org/wiki/Word_stem">stems</a> are used as the representation of text content, this feature allows infinite derivatives vocabulary that leads to high uncertainty of writing forms and huge redundant features. There are major challenges of low-resource agglutinative text classification the lack of labeled data in a target domain and morphologic diversity of derivations in language structures. It is an effective solution which fine-tuning a pre-trained language model to provide meaningful and favorable-to-use <a href="https://en.wikipedia.org/wiki/Feature_extraction">feature extractors</a> for downstream text classification tasks. To this end, we propose a low-resource agglutinative language model fine-tuning AgglutiFiT, specifically, we build a low-noise fine-tuning dataset by morphological analysis and stem extraction, then fine-tune the cross-lingual pre-training model on this dataset. Moreover, we propose an attention-based fine-tuning strategy that better selects relevant semantic and syntactic information from the pre-trained language model and uses those <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> on downstream text classification tasks. We evaluate our methods on nine Uyghur, Kazakh, and Kyrgyz classification datasets, where they have significantly better performance compared with several strong baselines.</abstract>
      <url hash="7f9095fc">2020.ccl-1.92</url>
      <language>eng</language>
      <bibkey>li-etal-2020-low</bibkey>
    <title_ar>تصنيف نص منخفض الموارد عبر ضبط نموذج اللغة عبر اللغات بدقة</title_ar>
      <title_pt>Classificação de texto de poucos recursos por meio de ajuste fino do modelo de linguagem multilíngue</title_pt>
      <title_es>Clasificación de textos con pocos recursos mediante el ajuste del modelo lingüístico multilingüe</title_es>
      <title_ja>クロスリンガルモデルファインチューニングによる低リソーステキスト分類</title_ja>
      <title_zh>语言微调者低资源文本分类</title_zh>
      <title_hi>क्रॉस-भाषाई भाषा मॉडल ठीक ट्यूनिंग के माध्यम से कम संसाधन पाठ वर्गीकरण</title_hi>
      <title_ga>Aicmiú Téacs Íseal-Acmhainne trí Mhionchoigeartú Samhail Teanga Trastheangach</title_ga>
      <title_el>Ταξινόμηση κειμένου χαμηλής περιεκτικότητας σε πόρους μέσω της διακρατικής γλωσσικής μοντελοποίησης</title_el>
      <title_hu>Alacsony erőforrású szövegosztályozás a többnyelvű nyelvű modell segítségével Finomhangolás</title_hu>
      <title_ka>Name</title_ka>
      <title_it>Classificazione del testo a basso contenuto di risorse tramite modello linguistico multilingue</title_it>
      <title_lt>Mažai išteklių turintis teksto klasifikavimas naudojant tarpkalbinį kalbos modelį</title_lt>
      <title_kk>Төмен ресурс мәтін классификациясы тіл үлгісін таңдау үшін</title_kk>
      <title_mk>Класификација на текст со ниски ресурси преку промена на моделот на меѓујазик</title_mk>
      <title_ms>Klasifikasi Teks Sumber Terrendah melalui Penyesuaian Model Bahasa Sembahasa</title_ms>
      <title_mt>Klassifikazzjoni tat-Test b’Riżorsi Bażi permezz ta’ Aġġustament Irfinat tal-Mudell tal-Lingwa Translingwi</title_mt>
      <title_ml>ക്രോസ്- ഭാഷ മോഡില്‍ കുറഞ്ഞ വിഭവങ്ങളുടെ പദാവലി ക്ലാസ്സിഷന്‍</title_ml>
      <title_mn>Төвөрмөц хэл загвараар бага боловсруулагч текст хэлбэрээр хуваалцах</title_mn>
      <title_pl>Klasyfikacja tekstu niskich zasobów poprzez dostosowanie modelu języka wielojęzycznego</title_pl>
      <title_ro>Clasificarea textului cu resurse reduse prin intermediul modelului de limbă translingvistică</title_ro>
      <title_sr>Klasifikacija teksta niskog resursa preko prekršnog jezičkog modela fino podešavanje</title_sr>
      <title_no>Name</title_no>
      <title_sv>Klassificering av text med låg resurs via flerspråkig språkmodell Finjustering</title_sv>
      <title_so>Fine-tuning</title_so>
      <title_si>Name</title_si>
      <title_ta>கிராஸ்- மொழி மொழி மாதிரி மூலம் குறைந்த மூலம் உரை வகைப்படுத்தல்</title_ta>
      <title_ur>Name</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>KCharselect unicode block name</title_vi>
      <title_bg>Класификация на текста с нисък ресурс чрез фина настройка на междуезичния езиков модел</title_bg>
      <title_da>Klassificering af tekst med lav ressource via tværsproget sprogmodel Finjustering</title_da>
      <title_nl>Classificatie van tekst met weinig hulpbronnen via aanpassing van het meertalige taalmodel</title_nl>
      <title_hr>Klasificija teksta niskog resursa preko prekršnog jezičkog modela fino prilagođenja</title_hr>
      <title_de>Ressourcenarme Textklassifikation durch Feinabstimmung des sprachübergreifenden Modells</title_de>
      <title_ko>다중 언어 모델을 바탕으로 미세하게 조정된 저자원 텍스트 분류</title_ko>
      <title_fa>کلاس‌سازی متن کم منبع از طریق مدل زبان‌های زیادی</title_fa>
      <title_id>Klasifikasi Teks Sumber Terrendah melalui Penyesuaian Model Bahasa Selata Bahasa</title_id>
      <title_tr>Çot Diller modi Fin-tuning</title_tr>
      <title_af>Name</title_af>
      <title_sq>Klasifikimi i tekstit me burime të ulta nëpërmjet rregullimit të modelit të gjuhës ndërgjuhësore</title_sq>
      <title_sw>Usalama wa maandishi ya chini ya rasilimali kupitia Modeli ya Lugha yenye lugha</title_sw>
      <title_am>ቋንቋ</title_am>
      <title_hy>Նվագ ռեսուրսների տեքստի դասակարգման միջոցով լեզվի միջոցով</title_hy>
      <title_az>T톛k-Kaynakl캼 Metin S캼n캼fland캼rmas캼 칂톛rz dil Modeli 캻yi-Yap캼land캼rmas캼 vasit톛sil톛</title_az>
      <title_bn>Low-Resource Text Classification via Cross-lingual Language Model Fine-tuning</title_bn>
      <title_ca>Classificació de text de baix recursos mitjançant ajustament del model de llenguatge translingüístic</title_ca>
      <title_cs>Klasifikace textu s nízkými zdroji prostřednictvím jemného ladění modelu mezi jazyky</title_cs>
      <title_bs>Klasifikacija teksta s niskim resursima preko prekršnog jezičkog modela fino podešavanje</title_bs>
      <title_et>Vähese ressursiga teksti klassifitseerimine keeleülese keele mudeli peenhäälestuse kaudu</title_et>
      <title_fi>Vähävaraisen tekstin luokittelu monikielisen kielimallin hienosäätön avulla</title_fi>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_sk>Klasifikacija besedila z nizkimi viri prek medjezičnega jezikovnega modela finega nastavitve</title_sk>
      <title_jv>undo-type</title_jv>
      <title_bo>Low-Resource Text Classification via Cross-lingual Language Model Fine-tuning</title_bo>
      <title_he>שימוש טקסט משאבים נמוכים באמצעות שיפות מסוימות</title_he>
      <abstract_ar>يميل تصنيف النص إلى أن يكون صعبًا عندما تكون البيانات غير كافية مع الأخذ في الاعتبار مقدار مجموعة النص المصنفة يدويًا. بالنسبة للغات التراصية منخفضة الموارد بما في ذلك الأويغور والكازاخستانية والقيرغيزية (لغات UKK) ، حيث يتم تصنيع الكلمات عبر السيقان المتسلسلة مع العديد من اللواحق والسيقان المستخدمة لتمثيل محتوى النص ، تسمح هذه الميزة بمشتقات لا حصر لها من المفردات التي تؤدي إلى ارتفاع عدم اليقين في أشكال الكتابة والسمات الزائدة الضخمة. هناك تحديات كبيرة لتصنيف النص التراصي منخفض الموارد ونقص البيانات المصنفة في المجال المستهدف والتنوع المورفولوجي للاشتقاقات في الهياكل اللغوية. إنه حل فعال يقوم بضبط نموذج لغة مُدرَّب مسبقًا لتوفير مستخلصات ميزات هادفة ومواتية للاستخدام لمهام تصنيف النص النهائي. تحقيقا لهذه الغاية ، نقترح نموذج لغة تراصية منخفضة الموارد لضبط AgglutiFiT ، على وجه التحديد ، نقوم ببناء مجموعة بيانات ضبط دقيق منخفضة الضوضاء عن طريق التحليل الصرفي واستخراج الجذع ، ثم ضبط نموذج التدريب المسبق متعدد اللغات على مجموعة البيانات هذه. علاوة على ذلك ، نقترح استراتيجية ضبط دقيقة قائمة على الانتباه والتي تختار بشكل أفضل المعلومات الدلالية والنحوية ذات الصلة من نموذج اللغة المدربة مسبقًا وتستخدم هذه الميزات في مهام تصنيف النص النهائي. نقوم بتقييم أساليبنا على تسعة مجموعات بيانات تصنيفية من الأويغور والكازاخستانية والقرغيزية ، حيث تتمتع بأداء أفضل بكثير مقارنة بالعديد من مجموعات البيانات القوية.
خطوط الأساس.</abstract_ar>
      <abstract_pt>A classificação de texto tende a ser difícil quando os dados são inadequados considerando a quantidade de corpora de texto rotulados manualmente. Para idiomas aglutinantes de poucos recursos, incluindo uigur, cazaque e quirguiz (línguas do Reino Unido), em que as palavras são fabricadas por meio de radicais concatenados com vários sufixos e os radicais são usados como representação do conteúdo do texto, esse recurso permite um vocabulário de derivados infinitos que leva a incerteza de escrever formas e enormes recursos redundantes. Existem grandes desafios de classificação de texto aglutinativo de baixo recurso a falta de dados rotulados em um domínio de destino e diversidade morfológica de derivações em estruturas de linguagem. É uma solução eficaz que ajusta um modelo de linguagem pré-treinado para fornecer extratores de recursos significativos e favoráveis ao uso para tarefas de classificação de texto downstream. Para este fim, propomos um modelo de linguagem aglutinativa de baixo recurso que ajusta o AglutiFiT, especificamente, construímos um conjunto de dados de ajuste fino de baixo ruído por análise morfológica e extração de haste, depois ajustamos o modelo de pré-treinamento linguístico em este conjunto de dados. Além disso, propomos uma estratégia de ajuste fino baseada na atenção que seleciona melhor as informações semânticas e sintáticas relevantes do modelo de linguagem pré-treinado e usa esses recursos em tarefas de classificação de texto a jusante. Avaliamos nossos métodos em nove conjuntos de dados de classificação uigur, cazaque e quirguiz, onde eles têm um desempenho significativamente melhor em comparação com vários conjuntos de dados fortes.
linhas de base.</abstract_pt>
      <abstract_ja>手動でラベル付けされたテキストコーラの量を考慮すると、データが不十分な場合、テキスト分類は難しい傾向があります。 ウイグル語、カザフ語、キルギス語（ UKK言語）を含む低資源の集約言語では、複数の接尾辞とステムで連結されたステムを介して単語が製造され、テキストコンテンツの表現として使用されるため、この機能は、書き込みフォームの不確実性の高さと巨大な冗長機能につながる無限の派生語彙を可能にします。 低資源凝集性テキスト分類の主要な課題は、標的ドメインにおける標識データの欠如及び言語構造における派生の形態学的多様性である。 これは、事前にトレーニングされた言語モデルを微調整して、下流のテキスト分類タスクに有意義で使いやすい機能抽出を提供する効果的なソリューションです。 この目的のために、私たちは低リソースの凝集性言語モデルを提案し、AgglutiFiTを微調整します。具体的には、形態分析とステム抽出によって低ノイズの微調整データセットを構築し、このデータセット上のクロスリンガル事前トレーニングモデルを微調整します。 さらに、事前にトレーニングされた言語モデルから関連する意味情報と構文情報をより適切に選択し、それらの機能を下流のテキスト分類タスクに使用する、注意に基づく微調整戦略を提案します。 私たちは、9つのウイグル語、カザフ語、キルギス語の分類データセットで方法を評価します。これらのデータセットは、いくつかの強力なデータセットと比較して有意に優れたパフォーマンスを持っています。
ベースライン。</abstract_ja>
      <abstract_es>La clasificación del texto tiende a ser difícil cuando los datos son inadecuados, teniendo en cuenta la cantidad de cuerpos de texto etiquetados manualmente. Para los idiomas aglutinantes de pocos recursos, incluidos el uigur, el kazajo y el kirguís (idiomas del Reino Unido), en los que las palabras se fabrican a través de raíces concatenadas con varios sufijos y se utilizan raíces como representación del contenido del texto, esta característica permite un vocabulario derivado infinito que conduce a una alta incertidumbre de escribir formularios y enormes funciones redundantes. Existen grandes desafíos en la clasificación de textos aglutinantes de bajos recursos, la falta de datos etiquetados en un dominio objetivo y la diversidad morfológica de las derivaciones en las estructuras del lenguaje. Es una solución eficaz que ajusta un modelo de lenguaje previamente entrenado para proporcionar extractores de funciones significativos y favorables para las tareas de clasificación de texto posteriores. Con este fin, proponemos un modelo de lenguaje aglutinativo de bajos recursos que afine AgglutiFit, específicamente, construimos un conjunto de datos de ajuste fino de bajo ruido mediante análisis morfológico y extracción de tallos, luego ajustamos el modelo de preentrenamiento multilingüe en este conjunto de datos. Además, proponemos una estrategia de ajuste de precisión basada en la atención que selecciona mejor la información semántica y sintáctica relevante del modelo de lenguaje previamente entrenado y utiliza esas características en las tareas de clasificación de textos posteriores. Evaluamos nuestros métodos en nueve conjuntos de datos de clasificación uigur, kazajo y kirguís, donde tienen un rendimiento significativamente mejor en comparación con varios
líneas de base.</abstract_es>
      <abstract_zh>及念手动所记文本语料库数不足,文本分类往往为难。 维吾尔语、哈萨克语、吉尔吉斯语(UKK语)内低资源凝集性语,其中单词因数后缀之词干为之,而词干以文本者,许衍生词汇,而书高不确定性巨冗余也。 低资源凝性文本分类存大挑战,即域中乏标记数据及语言结构中派生之形多样性。 有效之解决方案,微调预训之语,为下流文本分类之义而易用之提取器。 为发微调AgglutiFiT低资源凝言具体来说,以形析词干,取一低噪声微调数集,然后集上于跨语预练之。 此外立微策,择语义、句法信息,施于下流文本之类。 吾于九维吾尔族、哈萨克族、吉尔吉斯族之类集上论吾法,比于强数,其有明善矣。
基线。</abstract_zh>
      <abstract_hi>पाठ वर्गीकरण तब मुश्किल होता है जब डेटा मैन्युअल रूप से लेबल किए गए टेक्स्ट कॉर्पोरेट की मात्रा पर विचार करते हुए अपर्याप्त होता है। उइघुर, कजाख, और किर्गिज़ (यूकेके भाषाओं) सहित कम-संसाधन एग्लूटीनेटिव भाषाओं के लिए, जिसमें शब्दों को कई प्रत्ययों के साथ संयोजित तने के माध्यम से निर्मित किया जाता है और उपजी का उपयोग पाठ सामग्री के प्रतिनिधित्व के रूप में किया जाता है, यह सुविधा अनंत डेरिवेटिव शब्दावली की अनुमति देती है जो लेखन रूपों और विशाल अनावश्यक सुविधाओं की उच्च अनिश्चितता की ओर जाता है। कम संसाधन agglutinative पाठ वर्गीकरण की प्रमुख चुनौतियां हैं एक लक्ष्य डोमेन में लेबल किए गए डेटा की कमी और भाषा संरचनाओं में व्युत्पत्ति की आकृति विज्ञान विविधता। यह एक प्रभावी समाधान है जो डाउनस्ट्रीम पाठ वर्गीकरण कार्यों के लिए सार्थक और अनुकूल-से-उपयोग सुविधा एक्सट्रैक्टर्स प्रदान करने के लिए एक पूर्व-प्रशिक्षित भाषा मॉडल को ठीक-ठीक ट्यूनिंग करता है। इस अंत के लिए, हम एक कम-संसाधन agglutinative भाषा मॉडल ठीक ट्यूनिंग AgglutiFiT का प्रस्ताव, विशेष रूप से, हम रूपात्मक विश्लेषण और स्टेम निष्कर्षण द्वारा एक कम शोर ठीक ट्यूनिंग डेटासेट का निर्माण, तो ठीक धुन इस डेटासेट पर पार-भाषाई पूर्व प्रशिक्षण मॉडल. इसके अलावा, हम एक ध्यान-आधारित ठीक-ट्यूनिंग रणनीति का प्रस्ताव करते हैं जो पूर्व-प्रशिक्षित भाषा मॉडल से प्रासंगिक शब्दार्थ और वाक्यात्मक जानकारी का बेहतर चयन करता है और डाउनस्ट्रीम पाठ वर्गीकरण कार्यों पर उन सुविधाओं का उपयोग करता है। हम नौ उइघुर, कजाख और किर्गिज़ वर्गीकरण डेटासेट पर अपने तरीकों का मूल्यांकन करते हैं, जहां उनके पास कई मजबूत की तुलना में काफी बेहतर प्रदर्शन है
बेसलाइन।</abstract_hi>
      <abstract_ga>Is gnách go mbíonn sé deacair téacs a rangú nuair nach leor na sonraí ag cur san áireamh an méid corpora téacs a lipéadaítear de láimh. I gcás teangacha comhglutineacha íseal-acmhainne lena n-áirítear Uyghur, Kazakh, agus Cirgisis (teangacha UKK), ina ndéantar focail a mhonarú trí ghais atá comhcheangailte le roinnt iarmhíreanna agus ina n-úsáidtear gais mar léiriú ar ábhar téacs, ceadaíonn an ghné seo díorthaigh gan teorainn stór focal a eascraíonn as ard. éiginnteacht foirmeacha scríbhneoireachta agus gnéithe iomarcacha ollmhóra. Tá dúshláin mhóra ann maidir le haicmiú téacs comhglutineach ar acmhainní íseal, easpa sonraí lipéadaithe i spriocfhearann agus éagsúlacht mhoirfeolaíoch díorthach i struchtúir teanga. Is réiteach éifeachtach é a dhéanann mionchoigeartú ar mhúnla teanga réamhoilte chun sainfháiscirí a bhfuil brí agus fabhrach le húsáid a sholáthar do thascanna aicmithe téacs iartheachtacha. Chuige sin, molaimid múnla teanga glutinative íseal-acmhainní a mhionchoigeartú AgglutiFiT, go sonrach, tógaimid tacar sonraí mionchoigeartaithe íseal-torainn trí anailís mhoirfeolaíoch agus asbhaint gas, ansin mionchoigeartú ar an tsamhail réamh-oiliúna tras-teangach ar. an tacar sonraí seo. Ina theannta sin, molaimid straitéis mhionchoigeartaithe aird-bhunaithe a roghnaíonn faisnéis shéimeantach agus chomhréire ábhartha ón tsamhail teanga réamhoilte agus a úsáideann na gnéithe sin ar thascanna iartheachtacha aicmithe téacs. Déanaimid luacháil ar ár modhanna ar naoi dtacar sonraí aicmithe Uyghur, Kazakh, agus Cirgisis, áit a bhfuil feidhmíocht i bhfad níos fearr acu i gcomparáid le roinnt tacar sonraí láidre.
bunlínte.</abstract_ga>
      <abstract_ka>ტექსტის კლასიფიკაცია უფრო რთული იქნება, როცა მონაცემები არაფექტი იქნება, როცა ტექსტის კოპორაციის მარტივი მარტივი მარტივი მარტივი ზ მარტივი რესურსების ადგლუტინატიური ენებისთვის, რომლებიც სიგური, კაზაკი და კურგიზი (UKK ენები), რომლებიც სიტყვებების გამოყენება, რამდენიმე სუფიქსის და სტექსის გამოყენება, რომლებიც ტექსტის შემდგომარების გამოყენებაში გამოყენებულია, ეს ფუნქცია უნ არსებობს მნიშვნელოვანი გამოცდილებები მარტივი რესურსების ადგლუტინატიური ტექსტიკის კლასიფიკაციაში მარტივი დიომინში და მორფოლოგიური განსხვავებების განსხვავება ენის სტრ ეს ეფექტიური პასუხი, რომელიც წინ განაკეთებული ენის მოდელის შესაძლებელი და მნიშვნელოვანი გამოყენებელი ფუნქტურების ექსტრეკტორები ტექსტის კლასიფიკაციის დავალებებისთვის დაა ამ მიზეზისთვის, ჩვენ მინდომარესური ადლუტინატიური ენის მოდელის წარმოდგლუტიფიფიT, განსაკუთრებით, ჩვენ მოპოროლოგიური ანალიზაციის და სტემი ექსტრექციის მანძილური მოდელის შესახებ დავკეთებთ ამ მონაცემების საშუალოდ დამატებით, ჩვენ დავწყვებთ ინტერნეციის დასაწყებული კონტაქტიური სტრატიგია, რომელიც უფრო უფრო უკეთესი სმენტიური და სინტაქტიური ინფორმაციის მოდულიდან წინაწყებული ენის მოდელ ჩვენ ჩვენი მეტოვები 9 სიგური, კაზაკური და კურგიზი კლასიფიკაციის მონაცემების შესახებ გავაკეთებთ, სადაც ისინი მნიშვნელოვანია უკეთესი კონფიკაცია
ბაზიანი.</abstract_ka>
      <abstract_it>La classificazione del testo tende ad essere difficile quando i dati sono inadeguati considerando la quantità di corpi di testo etichettati manualmente. Per le lingue agglutinative a basso contenuto di risorse, tra cui uiguro, kazako e kirghizista (lingue UKK), in cui le parole sono prodotte tramite steli concatenati con diversi suffissi e steli sono utilizzati come rappresentazione del contenuto del testo, questa caratteristica consente infiniti vocaboli derivati che portano ad un'elevata incertezza delle forme di scrittura e enormi funzionalità ridondanti. Ci sono grandi sfide legate alla classificazione dei testi agglutinanti a basso contenuto di risorse, alla mancanza di dati etichettati in un dominio target e alla diversità morfologica delle derivazioni nelle strutture linguistiche. È una soluzione efficace che perfeziona un modello linguistico pre-addestrato per fornire estrattori di funzionalità significativi e favorevoli all'uso per le attività di classificazione del testo a valle. A tal fine, proponiamo un modello di linguaggio agglutinativo a basso contenuto di risorse che perfeziona AgglutiFiT, nello specifico, costruiamo un set di dati a basso rumore di fine-tuning mediante analisi morfologica ed estrazione dello stel, quindi perfezionamo il modello di pre-formazione cross-lingual su questo set di dati. Inoltre, proponiamo una strategia di fine-tuning basata sull'attenzione che seleziona meglio le informazioni semantiche e sintattiche rilevanti dal modello linguistico pre-addestrato e utilizza tali funzionalità nelle attività di classificazione del testo a valle. Valutiamo i nostri metodi su nove set di dati di classificazione uiguri, kazaki e kirghizi, dove hanno prestazioni significativamente migliori rispetto a diversi
linee di base.</abstract_it>
      <abstract_hu>A szövegosztályozás általában nehéz, ha az adatok nem megfelelőek, tekintettel a manuálisan feliratozott szövegkorpuszok mennyiségére. Az alacsony erőforrású agglutinált nyelvek esetében, beleértve az ujgur, kazah és kirgiz nyelveket (UKK nyelveket), amelyekben a szavak több utótaggal és szárral összekapcsolt száron keresztül készülnek a szövegtartalom ábrázolására, ez a funkció végtelen származékos szókincset tesz lehetővé, ami nagy bizonytalanságot eredményez az írási formák és hatalmas redundáns funkciók. Az alacsony erőforrású agglutinált szövegosztályozás jelentős kihívásokkal jár, a céltartományban megjelölt adatok hiánya és a nyelvi struktúrák származékainak morfológiai sokfélesége. Ez egy hatékony megoldás, amely finomhangolja az előre képzett nyelvi modellt, hogy értelmes és kedvezően használható funkciókivonókat biztosítson a downstream szövegosztályozási feladatokhoz. Ennek érdekében egy alacsony erőforrású agglutinatív nyelvi modellt javasolunk, amely finomhangolja AgglutiFiT-t, konkrétan alacsony zajszintű finomhangoló adatkészletet építünk morfológiai elemzéssel és szárkinyeréssel, majd finomhangoljuk ezen adatkészleten a keresztnyelvű előképzési modellt. Emellett egy figyelem alapú finomhangolási stratégiát javasolunk, amely jobban kiválasztja a releváns szemantikai és szintaktikai információkat az előképzett nyelvi modellből, és ezeket a funkciókat a downstream szövegosztályozási feladatokhoz használja. Módszereinket kilenc ujgur, kazah és kirgiz osztályozási adatkészleten értékeljük, ahol jelentősen jobb teljesítménnyel rendelkeznek több erős adathoz képest.
alapvető vonalak.</abstract_hu>
      <abstract_el>Η ταξινόμηση κειμένου τείνει να είναι δύσκολη όταν τα δεδομένα είναι ανεπαρκή λαμβάνοντας υπόψη την ποσότητα των χειροκίνητα επισημασμένων σωμάτων κειμένου. Για τις χαμηλής περιεκτικότητας σε συγκολλητικές γλώσσες, συμπεριλαμβανομένων των Ουιγούρων, των Καζακικών και των Κιργιζικών (γλώσσες UKK), στις οποίες οι λέξεις κατασκευάζονται μέσω στελεχών που αλληλοσυνδέονται με διάφορα επιθήματα και οι μίσχοι χρησιμοποιούνται ως αναπαράσταση του περιεχομένου κειμένου, αυτό το χαρακτηριστικό επιτρέπει άπειρα παράγωγα λεξιλόγιο που οδηγεί σε υψηλή αβεβαιότητα των μορφών γραφής και τεράστια περιττά χαρακτηριστικά. Υπάρχουν μεγάλες προκλήσεις της ταξινόμησης κολλητικών κειμένων χαμηλής περιεκτικότητας σε πόρους, η έλλειψη επισημασμένων δεδομένων σε έναν τομέα-στόχο και η μορφολογική ποικιλομορφία παραγώγων στις γλωσσικές δομές. Είναι μια αποτελεσματική λύση που ρυθμίζει ένα προ-εκπαιδευμένο γλωσσικό μοντέλο για να παρέχει ουσιαστικές και ευνοϊκές εξαγωγές χαρακτηριστικών για μεταγενέστερες εργασίες ταξινόμησης κειμένου. Για το σκοπό αυτό, προτείνουμε ένα μοντέλο χαμηλής περιεκτικότητας σε συγκολλητική γλώσσα, το οποίο συντονίζει το AgglutiFiT, συγκεκριμένα, χτίζουμε ένα σύνολο δεδομένων χαμηλού θορύβου με μορφολογική ανάλυση και εξαγωγή στελεχών, και στη συνέχεια συντονίζουμε το δισγλωσσικό μοντέλο προεκπαίδευσης σε αυτό το σύνολο δεδομένων. Επιπλέον, προτείνουμε μια στρατηγική συντονισμού βασισμένη στην προσοχή που επιλέγει καλύτερα σχετικές σημασιολογικές και συντακτικές πληροφορίες από το προ-εκπαιδευμένο γλωσσικό μοντέλο και χρησιμοποιεί αυτά τα χαρακτηριστικά σε μεταγενέστερες εργασίες ταξινόμησης κειμένου. Αξιολογούμε τις μεθόδους μας σε εννέα σύνολα δεδομένων ταξινόμησης Ουιγούρων, Καζακστάν και Κιργιζίας, όπου έχουν σημαντικά καλύτερη απόδοση σε σύγκριση με αρκετά ισχυρά
Βασικές γραμμές.</abstract_el>
      <abstract_kk>Мәтін klassifikaциясы, деректер қолмен жарлық мәтін корпорасының қаншасын қарастыруға мүмкіндік емес болғанда қиын болады. Уигур, Казах және Кыргыз тілдері (UKK тілдері) үшін төмен ресурстар аглутизациялық тілдер үшін сөздерді бірнеше жұрнақтар және стимлер мәтін мазмұнын көрсету үшін қолданылады. Бұл мүмкіндік жазу пішімдері мен үлкен қалқымалы мүмкіндіктер үшін шектелмеген дерективтер сөздер Мақсатты доменде жарлықталған деректер жоқ және тіл құрылғыларындағы морфологиялық түрлі түрлі құрылғылардың маңызды мәтін бағыттауының негізгі өзгерістері бар. Мәтін классификациялау тапсырмалары үшін мәліметті және қолданатын мүмкіндіктерді қолдану үшін алдыңғы тіл үлгісін баптау эффективні шешімі. Бұл үшін біз мәліметтің артық ресурстар аглутизациялық тіл үлгісін таңдау үлгісін таңдаймыз. Мәлімет, морфологиялық анализ және стим тарқату арқылы тыс дыбыс түзету деректерін құрамыз, сондықтан мәліметтің алдын- тілікті алды Сонымен қатар, біз бақылау тәртіпке негізделген тәртіпке баптау стратегиясын таңдаймыз. Алдын- ала оқылған тіл үлгісінен қатынау және синтактикалық мәліметтерді таңдап, оларды төменгі мәтін кл Біз 9 Uyghur, Kazakh және Кыргыз классификациялық деректер қорларында тәртіптерімізді оқу үшін, олар бірнеше күшті жұмыс салыстырып тұрады.
негізгі жолдар.</abstract_kk>
      <abstract_lt>Teksto klasifikavimas paprastai yra sudėtingas, kai duomenų nepakanka, atsižvelgiant į rankiniu būdu pažymėto teksto korpuso kiekį. Nedidelių išteklių aglutinatyvių kalbų, įskaitant Uyghur ą, Kazachą ir Kirgiziją (UKK kalbas), kuriose žodžiai gaminami naudojant stiebus, sutvirtintus keliais stiebliais ir stiebliais, naudojami kaip teksto turinio reprezentacija, šis požymis leidžia neribotą išvestinių medžiagų žodyną, dėl kurio kyla didelis rašymo formų neapibrėžtumas ir dideli pertekliniai požymiai. There are major challenges of low-resource agglutinative text classification the lack of labeled data in a target domain and morphologic diversity of derivations in language structures.  Tai veiksmingas sprendimas, kuriuo tiksliai pritaikomas iš anksto parengtas kalbų model is, siekiant suteikti prasmingus ir palankius naudojimo savybių ekstraktorius tolesnėms teksto klasifikavimo užduotims. Šiuo tikslu siūlome mažai išteklių aglutinacinį kalbos model į, tiksliai tikslinantį AgglutiFiT, kuriame mažo triukšmo tikslinimo duomenų rinkinį atliekant morfologinę analizę ir kamieno ekstrakciją, o vėliau tikslinantį šio duomenų rinkinio tarpkalbinį pasirengimo mokymui modelį. Be to, siūlome dėmesio pagrindu pagrįstą patobulinimo strategiją, kuri geriau atrinktų svarbią semantinę ir sintaksinę informaciją iš iš anksto parengto kalbos modelio ir panaudotų šias charakteristikas tolesnio teksto klasifikavimo užduotims. Vertiname savo metodus devyniuose Uyghuro, Kazacho ir Kirgizijos klasifikavimo duomenų rinkiniuose, kuriuose jie gerokai geresni, palyginti su keliomis stipriomis
bazinės linijos.</abstract_lt>
      <abstract_mk>Класификацијата на текстот е тешка кога податоците не се доволни со оглед на количината на рачно означени текстови. За јазици со ниски ресурси, вклучително и Уигур, Казах и Киргиз (јазици на УКК), во кои зборовите се произведуваат преку столбови со неколку суфикси и столбови се користат како претставување на текстова содржина, оваа карактеристика овозможува бесконечен резултат на дерибутиви што води до висока несигурност на формуларите за пишување и огромни претер Постојат големи предизвици од класификацијата на ниските ресурси на аглутинативниот текст, недостатокот на означени податоци во целна домена и морфолошката различност на деринациите во јазичните структури. Тоа е ефективно решение кое финетизира предобучен јазички модел за да обезбеди значајни и поволни екстрактори на карактеристики за понатамошна класификација на текстот. За оваа цел, предложуваме мало ресурсно аглутинативен јазички модел за финетизирање на AgglutiFiT, специфично, ние изградуваме ниско звукно финетизирање на податоците со морфолошка анализа и екстракција на стомак, а потоа финетизирање на крстојазичниот модел за предобука на овој податок. Покрај тоа, предложуваме стратегија за финетизирање базирана на вниманието која подобро ги избира релевантните семантични и синтактички информации од предобучениот јазички модел и ги користи овие карактеристики на задачите за класификација на текстот. Ги проценуваме нашите методи на девет податоци за класификација на Уигур, Казах и Киргиз, каде што тие имаат значително подобра резултат во споредба со неколку силни
Основни линии.</abstract_mk>
      <abstract_ms>Klasifikasi teks cenderung menjadi sukar bila data tidak cukup mengingat jumlah teks yang ditabel secara manual. Untuk bahasa agglutinatif sumber rendah termasuk Uyghur, Kazakh, dan Kyrgyz (bahasa UKK), di mana perkataan dihasilkan melalui stem yang bersamaan dengan beberapa suffiks dan stem digunakan sebagai perwakilan kandungan teks, ciri ini membolehkan vocabulari derivatif tak terbatas yang membawa kepada ketidakpastian tinggi bagi bentuk tulisan dan ciri-ciri yang berlebihan besar. Terdapat cabaran utama bagi klasifikasi teks agglutinatif sumber rendah kekurangan data labeled dalam domain sasaran dan pelbagai morfologi derivasi dalam struktur bahasa. Ia adalah penyelesaian yang berkesan yang menyesuaikan model bahasa pra-dilatih untuk menyediakan pengekstraktor ciri-ciri yang bermakna dan berguna untuk digunakan untuk tugas klasifikasi teks turun. Untuk tujuan ini, kami cadangkan model bahasa yang rendah-sumber agglutinatif penyesuaian AgglutiFiT, secara khusus, kami membina set data penyesuaian rendah-bunyi dengan analisis morfologik dan ekstraksi stem, kemudian penyesuaian model praselatihan saling bahasa pada set data ini. Lagipun, kami cadangkan strategi penyesuaian yang berdasarkan perhatian yang lebih baik memilih maklumat semantik dan sintaktik yang relevan dari model bahasa yang dilatih-dilatih dan menggunakan ciri-ciri tersebut pada tugas kelasukan teks turun. Kami menilai kaedah kami pada sembilan set data klasifikasi Uyghur, Kazakh, dan Kyrgyz, di mana mereka mempunyai prestasi yang jauh lebih baik dibandingkan dengan beberapa kuat
garis dasar.</abstract_ms>
      <abstract_ml>വിവരങ്ങള്‍ കൈയ്യില്‍ ലേബിള്‍ ചെയ്ത ടെക്സ്റ്റ് കോര്‍പ്പോരിയുടെ എണ്ണം കാണാന്‍ ആവശ്യമില്ലെങ്കില്‍ പദാവലി ക്ല കുറഞ്ഞ വിഭവങ്ങള്‍ക്ക്, ഉഗ്ഗുര്‍, കസാഖ്, കിര്‍ഗ്ഗിസ് എന്നിവയുള്ള ഭാഷകള്‍ക്കും, വാക്കുകള്‍ ഉണ്ടാക്കിയിരിക്കുന്നു. വാക്കുകള്‍ കൂടുതല്‍ സ്റ്റേജുകള്‍ കൂട്ടിചേര്‍ക്കുന്ന സ്റ്റേജുകള്‍ക്കും സ്റ്റേഡുകള്‍ക്കും വ ലക്ഷ്യസ്ഥാനത്തില്‍ ലേബിള്‍ ഡേറ്റായിട്ടുള്ള വിവരങ്ങളുടെ കുറഞ്ഞ വിഭവങ്ങളുടെ വിവിധ വ്യത്യാസങ്ങളുണ്ട്. ഭാഷയുടെ അടിസ്ഥാനങ്ങളില്‍ മോര്‍ പ്രധാനപ്പെട്ട ഭാഷയുടെ മോഡല്‍ മുമ്പ് പരിശീലിക്കപ്പെട്ട ഭാഷയുടെ പ്രധാനപ്പെടുത്തുന്ന ഒരു പ്രധാനപ്പെട്ട തീരുമാനമാണിത്. ഡെസ ഈ അവസാനത്തിനു വേണ്ടി ഞങ്ങള്‍ ഒരു കുറഞ്ഞ വിഭവങ്ങള്‍ ആഗ്ലുട്ടിയിട്ടുള്ള ഭാഷ മോഡല്‍ പ്രൊദ്ദേശിപ്പിക്കുന്നു. പ്രത്യേകിച്ച്, നമ്മള്‍ മോര്‍ഫോളജിക്കല്‍ അന്വേഷണവും സ്റ്റേമിക്കല്‍ പു അതുകൊണ്ട്, നമ്മള്‍ ശ്രദ്ധിക്കുന്ന ഒരു നല്ല തിരഞ്ഞെടുക്കാനുള്ള ഗുണപൂര്‍ണ്ണമായ വിവരങ്ങള്‍ മുന്‍പരിശീലന ഭാഷ മോഡലില്‍ നിന്നും ഉത്തരവാദിത്തം തെരഞ ഞങ്ങള്‍ നമ്മുടെ രീതികളെ വിലാസപ്പെടുത്തുന്നു. നമ്മുടെ രീതികള്‍ ഒമ്പതു ഉഗ്ഹുര്‍, കസാഖ്, കിര്‍ഗിസ് ക്ലാസ്ഫിക്കല്‍ ഡാറ്റാസറ്റുകള
അടിസ്ഥാനങ്ങള്‍.</abstract_ml>
      <abstract_mt>Il-klassifikazzjoni tat-test għandha t-tendenza li tkun diffiċli meta d-dejta ma tkunx adegwata meta jitqies l-ammont ta’ korpura tat-test ittikkettat manwalment. Għall-lingwi agglutinattivi b’riżorsi baxxi inklużi l-Uyghur, il-Każak, u l-Kirgiż (lingwi UKK), li fihom il-kliem jiġu manifatturati permezz ta’ stems konċinatati b’diversi suffissi u stems jintużaw bħala r-rappreżentazzjoni tal-kontenut tat-test, din il-karatteristika tippermetti vokabulari tad-derivattivi infiniti li jwassal għal in ċertezza għolja tal-formoli tal-kitba u karatteristiċi kbar żejda. Hemm sfidi ewlenin tal-klassifikazzjoni tat-test agglutinattiv b’riżorsi baxxi n-nuqqas ta’ dejta ttikkettata f’dominju fil-mira u d-diversità morfoloġika tad-derivazzjonijiet fl-istrutturi lingwistiċi. Hija soluzzjoni effettiva li tiffina mudell lingwistiku mħarreġ minn qabel biex tipprovdi estratturi ta’ karatteristiċi sinifikanti u favorevoli għall-użu għal kompiti ta’ klassifikazzjoni tat-test downstream. Għal dan il-għan, qed nipproponu mudell lingwistiku agglutinattiv b’riżorsi baxxi li jaġġusta l-AgglutiFiT, speċifikament, a ħna nibnu sett ta’ dejta ta’ aġġustament fin b’ħoss baxx permezz ta’ analiżi morfoloġika u estrazzjoni tal-istokk, u mbagħad naġġustaw il-mudell ta’ qabel it-taħriġ translingwistiku fuq dan is-sett ta’ dejta. Barra minn hekk, qed nipproponu strateġija ta’ rfinar ibbażata fuq l-attenzjoni li tagħżel aħjar informazzjoni semantika u sintattika rilevanti mill-mudell lingwistiku mħarreġ minn qabel u tuża dawk il-karatteristiċi fuq kompiti ta’ klassifikazzjoni tat-test downstream. Aħna jevalwaw il-metodi tagħna fuq disa' settijiet ta' dejta tal-klassifikazzjoni Uyghur, Każak u Kirgiż, fejn għandhom prestazzjoni sinifikanti aħjar meta mqabbla ma' diversi settijiet qawwija
linji bażi.</abstract_mt>
      <abstract_mn>Текст хуваалтын хэмжээ нь өгөгдлийн хуваалтын хэмжээ гараар нэрлэгдсэн текст корпора гэдгийг ойлгож чадахгүй байхад хэцүү байдаг. Уйгур, Казах, Киргиз (УKK хэл) гэх мэт бага нөөцийн аглуктив хэл дээр хэлбэрээр хэлбэрээр хэлбэрээр хэлбэрээр бүтээж, хэд хэдэн давхар, стэмс нь текст бүтээгдэхүүний төлөвлөгөө болгон ашигладаг. Энэ төлөвлөгөө нь бичиж буй хэлбэрээс маш их тодорхойгүй байдлыг болон маш их Холбооны бүтээгдэхүүн дээр нэрлэгдсэн өгөгдлийн байдал болон хэлний бүтээгдэхүүний морфологик олон төрлийн төлөвлөгөөс бага багасгах мөнгө бүтээгдэхүүний төлөвлөгөөний асуудал бий. Энэ бол сургалтын өмнө сургалтын хэл загварыг тодорхойлж, утгатай, ашиглах хэрэгтэй өргөмжийг ашиглах боломжтой арга загваруудыг дамжуулах эффективны шийдэл юм. Энэ төгсгөлд бид бага боломжтой аглутинацийн хэл загварыг аглутифифиT тодорхойлж, ялангуяа бид морфологик шинжилгээ, стэм татаж бага чимээгүй өгөгдлийн санг бүтээж, дараа нь энэ өгөгдлийн сангийн аль хэлний сургалтын загварыг тодорхойлж чадна. Дараа нь бид анхаарлын төвөгтэй сайжруулах стратегийг илүү сайжруулдаг бөгөөд урьд сургалтын хэл загвараас хамааралтай семантик болон синтактик мэдээллийг сонгож, тэдгээрийг доорх текст хуваалтын ажил дээр ашигладаг. Бид 9 Уйгур, Казах, Киргиз хуваалтын өгөгдлийн сангийн аргыг үнэлгээж байна. Тэд хэдэн хүчтэй харьцуулахад илүү сайн үйл ажиллагаатай байдаг.
суурь шугам.</abstract_mn>
      <abstract_no>Tekstklassifikasjonen er vanskeleg når data er ikkje tilstrekkeleg ved å sjekke kor mange manuelt merket tekstkorpora. For låg ressursaglutinativ språk, inkludert Uyghur, Kazakh, og Kyrgyz (UKK-språk), der ord vert produsert via stemmer samsvara med fleire suffiksar og stemmer brukt som representasjonen av tekstinnhaldet, kan denne funksjonen tillata uendelige deriverte ordbokstavar som fører til høg usikkerhet på skriveform og store redundant funksjonar. Det finst store utfordringar i låg ressursaglutinativt tekstklassifikasjon for mangling av merkelige data i eit måldområde og morfologisk mangfolding av derivasjonar i språkstrukturer. Det er ein effektiv løysing som finn opp eit før- treng språk- modell for å gje meningsverdiar og favoritt- bruk- funksjonsekstraktorar for understremde tekstklassifikasjonar. I denne slutten foreslår vi ein låg ressurs agglutinativ språk modell for fin-tuning av AgglutiFiT, spesifikke, bygger vi ei låg lys fin-tuning dataset ved morfologisk analyse og stem-ekstraksjon, og så finn opp den krysspråk føreøvingsmodellen på denne datasettet. I tillegg foreslår vi ein oppmerksbasert finnstillingsstrategi som betre veljer relevante semantiske og syntaktiske informasjon frå den først trengte språk-modellen og brukar dei funksjonane på understremde tekstklassifikasjonar. Vi evaluerer metodane våre på ni Uyghur, Kazakh og Kyrgyz-klassifikasjonsdata, der dei har mykje bedre utvikling samanlikna med fleire sterke
baseline.</abstract_no>
      <abstract_pl>Klasyfikacja tekstu jest zwykle trudna, gdy dane są niewystarczające biorąc pod uwagę ilość ręcznie oznaczonych korpusów tekstowych. W przypadku języków aglutynatywnych o niskich zasobach, w tym języków ujgurskich, kazachskich i kirgiskich (języków UKK), w których słowa produkowane są za pomocą łodyg połączonych z kilkoma przyrostkami i łodyg są używane jako reprezentacja treści tekstowej, funkcja ta pozwala na nieskończone pochodne słownictwo, co prowadzi do wysokiej niepewności form pisania i ogromnych nadmiernych cech. Istnieją poważne wyzwania związane z klasyfikacją tekstu o niskich zasobach aglutynacyjnych braku oznaczonych danych w domenie docelowej oraz różnorodnością morfologiczną pochodnych struktur językowych. Jest to skuteczne rozwiązanie, które dostosowuje wstępnie przeszkolony model językowy, aby zapewnić znaczące i korzystne w użyciu ekstraktory funkcji do dalszych zadań klasyfikacji tekstu. W tym celu proponujemy mało zasobowy model AgglutiFiT dostrajający AgglutiFiT, w szczególności zbudowujemy zbiór danych o niskim poziomie szumu poprzez analizę morfologiczną i ekstrakcję macierzy, a następnie dostrajamy model przedszkoleniowy między językami na tym zbiorze danych. Ponadto proponujemy strategię dopracowania opartą na uwadze, która lepiej wybiera istotne informacje semantyczne i składniowe z przeszkolonego modelu językowego i wykorzystuje te cechy w dalszych zadaniach klasyfikacji tekstu. Nasze metody oceniamy na dziewięciu uzgurskich, kazachskich i kirgiskich zestawach danych klasyfikacyjnych, gdzie mają one znacznie lepszą wydajność w porównaniu z kilkoma silnymi
Podstawowe linie.</abstract_pl>
      <abstract_ro>Clasificarea textului tinde să fie dificilă atunci când datele sunt inadecvate având în vedere cantitatea de corpuri text etichetate manual. Pentru limbile aglutinative cu resurse reduse, inclusiv uigură, kazahă și kârgâză (limbile UKK), în care cuvintele sunt fabricate prin tulpini concatenate cu mai multe sufixe și tulpini sunt utilizate ca reprezentare a conținutului text, această caracteristică permite vocabularul derivat infinit care duce la incertitudine ridicată a formelor de scriere și caracteristici redundante uriașe. Există provocări majore legate de clasificarea textelor aglutinative cu resurse reduse, lipsa datelor etichetate într-un domeniu țintă și diversitatea morfologică a derivațiilor în structurile lingvistice. Este o soluție eficientă care reglează fin un model lingvistic pre-instruit pentru a oferi extractoare de caracteristici semnificative și favorabile utilizării pentru sarcinile de clasificare a textului în aval. În acest scop, propunem un model de limbă aglutinativă cu resurse reduse care reglează fin AgglutiFiT, în special, construim un set de date de reglare fină cu zgomot redus prin analiza morfologică și extracția tulpinilor, apoi reglăm fin modelul de pre-formare translingvistică pe acest set de date. În plus, propunem o strategie de reglare fină bazată pe atenție, care selectează mai bine informațiile semantice și sintactice relevante din modelul lingvistic pre-instruit și utilizează aceste caracteristici în sarcinile de clasificare a textului în aval. Evaluăm metodele noastre pe nouă seturi de date de clasificare uigură, kazahă și kârgâză, unde acestea au performanțe semnificativ mai bune comparativ cu mai multe seturi de date puternice
liniile de bază.</abstract_ro>
      <abstract_sv>Textklassificering tenderar att vara svår när data är otillräckliga med tanke på mängden manuellt märkta textkorpor. För lågresursagglutinerande språk inklusive uiguriska, kazakiska och kirgiziska (UKK-språk), där ord tillverkas via stammar sammankopplade med flera suffix och stammar används som representation av textinnehåll, möjliggör denna funktion oändliga derivat ordförråd som leder till hög osäkerhet i skrivande former och enorma redundanta funktioner. Det finns stora utmaningar med agglutinerande textklassificering med låg resurs, bristen på märkta data inom en måldomän och morfologisk mångfald av härledningar i språkstrukturer. Det är en effektiv lösning som finjusterar en färdigutbildad språkmodell för att ge meningsfulla och gynnsamma funktionsextraktorer för efterföljande textklassificeringsuppgifter. För detta ändamål föreslår vi en lågresurs agglutinative språkmodell som finjusterar AgglutiFiT, specifikt bygger vi ett lågbrusigt finjusterande dataset genom morfologisk analys och stamextraktion, och finjusterar sedan den tvärspråkliga pre-training modellen på denna datauppsättning. Dessutom föreslår vi en uppmärksamhetsbaserad finjusteringsstrategi som bättre väljer relevant semantisk och syntaktisk information från den förberedda språkmodellen och använder dessa funktioner i efterföljande textklassificeringsuppgifter. Vi utvärderar våra metoder på nio uiguriska, kazakiska och kirgiziska klassificeringsdataset, där de har betydligt bättre prestanda jämfört med flera starka
baslinjer.</abstract_sv>
      <abstract_si>පණිවිඩය පරීක්ෂණය අමාරුයි. දත්ත නැති වෙලාවට පණිවිඩය පණිවිඩය ලේබ් කරලා තියෙන්න පුළුවන් පරීක් For low-source agglutinative language comprises UYGUR, KAZAHK, and Kyrgy (UKK language), in where Words are Maded by stems Concathed with Severous suffixes and stems are Used as the reposition of text continence, this character allows Infinit Darwin Vocatives Vocativery that lead to high uncerity of write form and great red undiundint Featurals. අඩු සම්බන්ධ ප්‍රශ්නයක් සම්බන්ධ පැත්තක් විශේෂණයේ ප්‍රධාන අවශ්‍යය තියෙනවා ඉලක්ෂාත්මක ප්‍රශ්නයක් සහ භා ඒක ප්‍රයෝජනය විසඳීමක් වෙන්න පුළුවන් භාෂාව ප්‍රයෝජනය කරන්න පුළුවන් භාෂාව ප්‍රයෝජනය සහ ප්‍රයෝජනය කරන්න පුළු මේ අවසානයෙන්, අපි ප්‍රශ්නයක් කරනවා low-source agglutinative language Model Fin-tuning AgglitiFiT, විශේෂයෙන්, අපි මොර්ෆෝලෝගික විශ්ලේෂණය සහ ස්ටීම් ප්‍රශ්නයක් නිර්මාණය කරනවා, ඊට පස්සේ ප තවත්, අපි අවධානය අධ්‍යාත්මක විශ්වාස කරන්න පුළුවන් සැමැන්ටික් සහ සංකේතික තොරතුරු තෝරාගන්න පුළුවන් භාෂා මොඩේලයෙන අපි උයිගුර්, කාසාක්, කිර්ගිස් විශේෂ දත්ත සේට් එක්ක අපේ විධානය අවශ්‍ය කරනවා, ඔවුන් ගොඩක් හොඳ විධානය තියෙනව
ප්‍රධාන ප්‍රමාණය.</abstract_si>
      <abstract_sr>Klasifikacija teksta je često teška kada podaci nisu dovoljni s obzirom na količinu ručno označene tekstne korpore. Za jezike niskih resursa, uključujući Uyghur, Kazakh i Kirgiz (UKK jezika), u kojima se reči proizvode putem stazama povezanih sa nekoliko sufiksa i stazama koriste kao predstavljanje sadržaja teksta, ta karakteristika omogućava beskonačnu derivativsku rečenicu koja dovodi do visoke nesigurnosti oblika pisanja i ogromnih redundantnih karakteristika. Postoje veliki izazovi takve klasifikacije teksta sa niskim resursima, nedostatak označenih podataka u ciljnom domenu i morfološkom raznolikosti derivacija u jezičkim strukturama. To je efikasno rješenje koje ispravlja predobučeni jezički model kako bi pružilo smislene i favorilne ekstraktore funkcija za klasifikaciju teksta. Za taj cilj predlažemo model AgglutiFiT-a sa niskim resursima aglutinativnim jezikom, posebno, izgradimo nizak zvuk fino-tuniranje podataka morfološkom analizu i ekstrakcijom matičnih izvora, zatim sredimo preko jezika pre-obuku modela na ovom setu podataka. Osim toga, predlažemo strategiju za finaliziranje pažnje koja bolje odabere relevantne semantičke i sintaktičke informacije iz predobučenog jezičkog modela i koristi te karakteristike na zadacima klasifikacije teksta. Procjenjujemo naše metode na devet Uyghura, Kazakha i Kirgijskih klasifikacijskih podataka, gde imaju značajno bolje izvedbe u usporedbi sa nekoliko jakih
osnovne linije.</abstract_sr>
      <abstract_so>Text classification tends to be difficult when data are inadequate considering the amount of manually labeled text corpora.  Luqadaha hoose ee luqadaha agglutinatida ee ku qoran luqadaha Uyghur, Kazakh iyo Kyrgyz (luqadaha UKK), kuwaas oo lagu sameeyo hadal lagu qoro kooxaha kala duwan iyo kooxaha ay ku qoran yihiin, waxaa loo isticmaalaa sida loo qeybeeyo macluumaadka qoraalka, kaasi waxyaabaha aan la’aanta aheyn wuxuu ka heli karaa hadal aan la’aanta ah oo ka soo jeeda foomka qorniinka iyo tababaro aad u weyn. Waxaa jira dhibaatooyin badan oo ku saabsan qoraalka hoose-resource agglutinative, baahida macluumaadka la qoray oo ku qoran meelaha lagu qoray iyo kala duduwan dhaqdhaqaaqa oo afka lagu qoray. Waa xal faa’iido ah oo ku hagaajinta model afka hore oo la tababaray, in lagu siiyo guryaha isticmaalka oo faa’iido leh oo loo jecel yahay isticmaalka shaqooyinka fasaxa qoraalka hoose-bannaanta. Taas darteed waxaynu soo jeedaynaa model afka agglutinati oo aad u qoran tahay AgglutiFiT, si gaar ah, waxaynu dhisaynaa macluumaad aad u sameyneyso baaritaanka morphologiga iyo soo bixinta, kadibna waxaynu sameynaa modelka hore-tababarida ee afka kala baxa, taasoo ku qoran taariikhdan. Sidoo kale waxaynu horumarinaynaa qoraal aad u fiirsan karto, taasoo si wanaagsan u doorta macluumaad la xiriira semantic iyo syntactic oo ka mid ah modelka afka hore lagu baray, waxaas oo lagu isticmaalaa shaqooyinkaas ku saabsan shaqooyinka tababarida qoraalka hoose. Waxaynu qiimeynaynaa qaababkayaga ku qoran sagaal Uyghur, Kazakh iyo kooxaha fasalka Kirgyz, kuwaas oo ay ka fiican tahay tababar sameynta qaar xoog badan.
aasaasyo.</abstract_so>
      <abstract_ta>Text classification tends to be difficult when data are inadequate considering the amount of manually labeled text corpora.  @ info: whatsthis குறைந்த வளங்கள் agglutinative text வகைப்பாட்டின் மிகப்பெரிய சவால்கள் இருக்கிறது மொழி அமைப்புகளில் உள்ள குறிப்பிடப்பட்ட தரவுகளின் குறைவான தகவல் கு இது ஒரு விருப்பமான தீர்வு தான் முன் பயிற்சி மொழி மாதிரியை சரியாக முடிக்கும் முன்பு பயிற்சி மாதிரியை பயன்படுத்துவதற்காக சரியான இந்த முடிவிற்கு, நாம் ஒரு குறைந்த மூலத்தின் agglutinative மொழி மாதிரி பரிந்துரைக்கிறோம் குறிப்பிட்டு, குறிப்பிட்டு, நாம் ஒரு குறைந்த ஒலி நன்று தூண்டும் தகவல் அமைப்பை மார்போலியல மேலும், நாம் முன்பயிற்சி மொழி மாதிரியிலிருந்து தேர்ந்தெடுக்கும் பொருத்தமான பாமான்டிக் மற்றும் ஒத்திசைக்கும் தகவலை தேர்ந்தெடுக் நாங்கள் எங்கள் முறைகளை எடுத்துக் கொள்கிறோம் ஒன்பது உக்குர், கஜக், மற்றும் கிரிக்கிஸ் வகுப்பு தரவுத்தளங்களில், அதிகமாக சிறந்த செ
அடிப்படை கோடுகள்.</abstract_ta>
      <abstract_ur>جب ڈیٹا ناپاکیزہ ہوتے ہیں تو متن کلاسپیٹ کا ذریعہ اپنے ہاتھ سے لکھا ہوا متن کرپورا کا ذریعہ سمجھتے ہیں۔ یوگھر، کازاق اور کرجیز (UKK زبان) کے شامل کم منبع کے گلوٹینٹیوں زبانوں کے لئے، جہاں کلمات لکھنے کے مطابق بہت سی سوفکس اور استمز کے مطابق استعمال کئے جاتے ہیں، یہ فائدہ ایک حد سے زیادہ غیر منبع لکھنے کی اجازت دیتا ہے کہ لکھنے کے فرموں اور بہت زیادہ غیر معلومات کی وجہ سے بہت بڑی غیر معلوما نیچے رسورسوس اگلوٹینٹیو ٹیکسٹ کلاسپیٹ کی بہترین چالوں ہیں کہ ایک ٹیکسٹ ڈومین میں لابلیٹ ڈیٹ کی ناکامی اور زبان ساختاروں میں دریافت کی مورپولوژیکی مختلفیت ہے. یہ ایک اثرات حل ہے جو ایک پیش آموزش کی زبان موڈل کو مطلوب اور پسندیدہ استعمال کرنے کے لئے ڈونسٹریم ٹیکسٹ کلاسیفون کے کاموں کے لئے استعمال کرنے کے لئے اضافہ کرتا ہے. اس کے لئے ہم ایک کم منبع آگلوٹینٹی زبان کی موڈل اگلوٹی فیٹ کو پیشنهاد کرتے ہیں، مخصوصاً ہم ایک کم آواز پاکیزگی ٹونڈ ڈیٹ سٹ بناتے ہیں morfological analysis اور stem extraction کے ذریعہ، پھر اس ڈیٹ سٹ پر cross-lingual pre-training موڈل کو ٹھیک ٹھیک کر دیتے ہیں۔ اور اس کے علاوہ، ہم ایک توجه کی بنیاد پاکیزہ تنظیم استراتژی پیشنهاد کرتے ہیں جو اچھا معاملہ سیمانٹیکی اور سینٹکتیک معلومات کو پیش آموزش کی زبان موڈل سے انتخاب کرتا ہے اور ان فرصت کو نیچے سینٹریم ٹکس کلاسیفون کے کاموں پر است ہم نے نو Uyghur, Kazakh اور Kyrgyz classification datasets کے ذریعے اپنے طریقے کا ارزش کیا ہے جہاں وہ بہت زیادہ اچھی عملکرد رکھتے ہیں
بنیاس لین.</abstract_ur>
      <abstract_uz>Ma ľlumotlar qo Ľlbola qo Ľlbola yordamida qo Ľlbola belgilangan matn kompaniyasini aniqlashda matn darajalashtirish juda qiyin edi. Name There are major challenges of low-resource agglutinative text classification the lack of labeled data in a target domain and morphologic diversity of derivations in language structures.  Name Mana shu paytda, biz yaxshi manba agglutinativ tilning modeli AgglutiFiT'ni yaxshi ko'rinishimizni talab qilamiz. Hullas, biz morfological analyysi va tizimni chiqarish orqali yaratib, keyin bu ma ľlumotlarning bir necha tillar oldini ta ľminlovchi modelini yaramiz. Ko'rib, biz birinchi ta ľminlovchi tillar modelidan muhim semantik va syntactic ma ľlumotini tanlashni istaysizmi, va bu tashkilotlarni quyidagi matn classification vazifalardan foydalanamiz. Biz 9 Uyghur, Kazakh va Kyrgyz klassifik ma ľlumotlar tarkibini qiymatmiz. Bu yerda ularning ko'plab ko'pchilik bir qanchalik ko'plab bajarishiga juda yaxshi
asboblar.</abstract_uz>
      <abstract_vi>Đoạn phân loại có xu hướng khó khăn khi dữ liệu chưa đủ so với lượng chữ viết bằng nhãn bằng tay Hạ sĩ. Đối với các ngôn ngữ đậm chất thấp, bao gồm Uyghur, Kazak, và Kyrgyz (ngôn ngữ UKK), nơi mà từ được tạo ra qua các gốc được kết hợp bằng các dòng đủ và các dòng chảy được dùng làm đại diện cho nội dung văn bản, tính năng này cho phép nhiều từ dẫn tới sự mơ hồ của chữ viết và những tính năng thừa thải khổng lồ. Có những thách thức lớn của việc phân loại văn bản đậm đặc với nguồn thấp kém. sự thiếu dữ liệu được đánh dấu trong một miền đích và sự đa dạng hoá học của chế độ phân phát trong cấu trúc ngôn ngữ. Đây là một giải pháp hiệu quả tinh chỉnh mô hình ngôn ngữ được đào tạo sẵn để cung cấp các còn lại đặc trưng có ý nghĩa và thuận lợi cho các nhiệm vụ phân loại văn bản xuôi dòng. Chúng tôi đề xuất một kiểu ngôn ngữ đậm đặc biệt phức tạp, tinh chỉnh thấp độ của AglutiFiT, cụ thể, chúng tôi xây dựng dữ liệu độ âm thanh âm thanh thấp bằng cách phân tích lịch học và chiết xuất gốc, rồi chỉnh lại mô hình tiền đào tạo xuyên ngôn ngữ trên bộ dữ liệu này. Hơn nữa, chúng tôi đề nghị một chiến lược thúc-tinh chỉnh tập trung để chọn thông tin ngữ pháp và pháp liên quan tốt hơn từ mô hình ngôn ngữ được đào tạo trước và sử dụng những tính năng đó trong các nhiệm vụ phân loại văn bản xuôi dòng. Chúng tôi đánh giá các phương pháp của chúng tôi về chín trường dữ liệu phân loại Uthế, Kazak, và Kyrgyz, nơi chúng có hiệu quả tốt hơn nhiều so với một số lượng lớn.
tầng hầm.</abstract_vi>
      <abstract_nl>Tekstklassificatie is vaak moeilijk wanneer gegevens onvoldoende zijn gezien de hoeveelheid handmatig gelabelde tekstcorpora's. Voor agglutinatieve talen met weinig bronnen, waaronder Oeigoers, Kazachst en Kirgizisch (UKK-talen), waarin woorden worden vervaardigd via stengels die zijn verbonden met verschillende achtervoegsels en stelen worden gebruikt als de weergave van tekstinhoud, maakt deze functie oneindige afgeleide woordenschat mogelijk die leidt tot een hoge onzekerheid van schrijfvormen en enorme overbodige kenmerken. Er zijn grote uitdagingen van agglutinatieve tekstclassificatie met lage resources, het ontbreken van gelabelde gegevens in een doeldomein en morfologische diversiteit van afgeleidingen in taalstructuren. Het is een effectieve oplossing die een vooraf getraind taalmodel verfijnt om betekenisvolle en gunstig te gebruiken feature extractors te bieden voor downstream tekstclassificatietaken. Om dit doel te bereiken stellen we een agglutinatieve taalmodel voor dat AgglutiFiT verfijnt, specifiek bouwen we een low-noise fine-tuning dataset door morfologische analyse en stamextractie, en verfijnen vervolgens het cross-lingual pre-training model op deze dataset. Bovendien stellen we een attentie-based fine-tuning strategie voor die relevante semantische en syntactische informatie beter selecteert uit het voorgetrainde taalmodel en die functies gebruikt bij downstream tekstclassificatietaken. We evalueren onze methoden op negen Oeigoerse, Kazachstaanse en Kirgizische classificatiedatasets, waar ze aanzienlijk betere prestaties hebben vergeleken met verschillende sterke
basislijnen.</abstract_nl>
      <abstract_de>Die Textklassifizierung ist in der Regel schwierig, wenn Daten angesichts der Menge der manuell markierten Textkorpora unzureichend sind. Für ressourcenarme agglutinative Sprachen wie Uigurisch, Kasachisch und Kirgisisch (UKK-Sprachen), in denen Wörter über Stämme hergestellt werden, die mit mehreren Suffixen verkettet sind und als Darstellung von Textinhalten verwendet werden, ermöglicht diese Funktion unendliche Ableitungen von Vokabeln, die zu einer hohen Unsicherheit der Schreibformen und riesigen redundanten Merkmalen führen. Es gibt große Herausforderungen bei der ressourcenarmen agglutinativen Textklassifizierung, das Fehlen markierter Daten in einer Zieldomäne und die morphologische Vielfalt der Ableitungen in Sprachstrukturen. Es ist eine effektive Lösung, die ein vortrainiertes Sprachmodell verfeinert, um aussagekräftige und benutzerfreundliche Feature Extractor für nachgelagerte Textklassifizierungsaufgaben bereitzustellen. Zu diesem Zweck schlagen wir ein ressourcenarmes AgglutiFiT-Modell vor, das AgglutiFiT feinabstimmt. Insbesondere bauen wir einen rauscharmen Feinstimmungsdatensatz durch morphologische Analyse und Stammextraktion auf und verfeinern dann das sprachübergreifende Vortrainingsmodell auf diesem Datensatz. Darüber hinaus schlagen wir eine aufmerksamkeitsbasierte Fine-Tuning-Strategie vor, die relevante semantische und syntaktische Informationen aus dem vortrainierten Sprachmodell besser auswählt und diese Funktionen für nachgelagerte Textklassifizierungsaufgaben nutzt. Wir evaluieren unsere Methoden auf neun uigurischen, kasachischen und kirgisischen Klassifizierungsdatensätzen, wo sie im Vergleich zu mehreren starken
Grundlinien.</abstract_de>
      <abstract_bg>Класификацията на текста обикновено е трудна, когато данните са недостатъчни, като се има предвид количеството ръчно обозначени текстови корпуси. За аглутинационни езици с нисък ресурс, включително уйгурски, казахски и киргизки (езици на УКК), в които думите се произвеждат чрез стъбла, обвързани с няколко наставки и стъбла се използват като представяне на текстово съдържание, тази функция позволява безкрайни производни речник, който води до висока несигурност на писмените форми и огромни излишни характеристики. Съществуват големи предизвикателства при класификацията на аглутинационния текст с нисък ресурс, липсата на етикетирани данни в целевата област и морфологичното разнообразие на дериватите в езиковите структури. Това е ефективно решение, което фино настройва предварително обучен езиков модел, за да осигури смислени и благоприятни за използване екстрактори за задачи по класификация на текста надолу по веригата. За тази цел предлагаме модел на аглутинационен език с нисък ресурс, който фино настройва по-специално изграждаме набор от данни за фино настройване с нисък шум чрез морфологичен анализ и екстракция на стъблото, след което фино настройваме междуезичния модел на предобучение на този набор от данни. Освен това предлагаме стратегия за фино настройване, основана на вниманието, която по-добре избира съответната семантична и синтактична информация от предварително обучения езиков модел и използва тези функции при задачите за класификация на текста надолу по веригата. Ние оценяваме нашите методи на девет уйгурски, казакски и киргизки класификационни набора данни, където те имат значително по-добри резултати в сравнение с няколко силни
базови линии.</abstract_bg>
      <abstract_da>Tekstklassifikation har tendens til at være vanskelig, når data er utilstrækkelige i betragtning af mængden af manuelt mærkede tekstkorpora. For lav ressource agglutinative sprog, herunder uigurisk, kasakhsisk og kirgisisk (UKK sprog), hvor ord fremstilles via stængler sammenkoblet med flere suffikser og stængler bruges som repræsentation af tekstindhold, denne funktion tillader uendelige derivater ordforråd, der fører til høj usikkerhed i skrivning formularer og enorme overflødige funktioner. Der er store udfordringer ved agglutitiv tekstklassifikation med lav ressource, manglen på mærkede data i et måldomæne og morfologisk mangfoldighed af derivater i sprogstrukturer. Det er en effektiv løsning, der finjusterer en forududdannet sprogmodel for at give meningsfulde og gunstige-til-brug feature extractors til downstream tekst klassifikationsopgaver. Til dette formål foreslår vi en lav ressource agglutinative sprogmodel, der finjusterer AgglutiFiT, specifikt bygger vi et støjsvagt finjusterende datasæt ved morfologisk analyse og stamekstraktion, og finjusterer derefter den tværsprogede pre-training model på dette datasæt. Desuden foreslår vi en opmærksomhedsbaseret finjusterende strategi, der bedre vælger relevante semantiske og syntaktiske oplysninger fra den forudgående sprogmodel og bruger disse funktioner på downstream tekstklassifikationsopgaver. Vi evaluerer vores metoder på ni ugguriske, kasakhsiske og kirgisiske klassificeringsdatasæt, hvor de har betydeligt bedre performance sammenlignet med flere stærke
basislinjer.</abstract_da>
      <abstract_hr>Klasifikacija teksta je često teško kad podaci nisu dovoljni s obzirom na količinu ručno označenog tekstnog tijela. Za manje resurse agglutinativne jezike uključujući Uyghur, Kazakh i Kirgiz (UKK jezike), u kojima se riječi proizvode putem stakla povezanih s nekoliko sufiksa i stakla koriste kao predstavljanje sadržaja teksta, ta osobina omogućava beskonačnu riječ derivata koji dovodi do visoke nesigurnosti oblika pisanja i ogromnih redundantnih funkcija. Postoje veliki izazovi klasifikacije teksta s niskim resursima aglutinativnih teksta nedostatak označenih podataka u ciljnom domenu i morfološkom raznolikosti derivacija u jezičkim strukturama. To je učinkovito rješenje koje ispravlja predobučeni jezički model za pružanje značajnih i favorilnih ekstraktora funkcija za klasifikaciju teksta. Za taj cilj predlažemo model AgglutiFiT-a s niskim resursima agglutinativnim jezikom, posebno, izgradimo nizak zvuk fino-prilagođavanje podataka morfološkom analizu i ekstrakcijom matičnih izvora, zatim srediti preko jezika predobučeni model na ovom setu podataka. Osim toga, predlažemo strategiju za finaliziranje pažnje koja bolje odabere relevantne semantičke i sintaktičke informacije iz predobučenog jezičkog modela i koristi te karakteristike na zadatkima klasifikacije teksta. Procjenjujemo naše metode na devet Uyghura, Kazakha i kirgijskih klasifikacijskih podataka, gdje imaju značajno bolje učinkovitosti u usporedbi s nekoliko jakih
osnovne linije.</abstract_hr>
      <abstract_id>Klasifikasi teks cenderung menjadi sulit ketika data tidak cukup mempertimbangkan jumlah teks yang ditabel secara manual corpora. Untuk bahasa agglutinatif sumber daya rendah termasuk Uyghur, Kazakh, dan Kyrgyz (bahasa UKK), di mana kata-kata diproduksi melalui stem yang dikoncatenasi dengan beberapa suffix dan stem digunakan sebagai perwakilan konten teks, fitur ini memungkinkan vocabulari derivat yang tidak terbatas yang mengarah ke ketidakpastian tinggi bentuk menulis dan fitur-fitur redundant besar. Ada tantangan utama dari klasifikasi teks agglutinatif sumber rendah kekurangan data yang ditabel dalam domain target dan diversitas morfologi dari derivasi dalam struktur bahasa. Ini adalah solusi efektif yang menyesuaikan model bahasa yang terlatih untuk menyediakan ekstraktor fitur yang berguna dan berguna untuk menggunakan untuk tugas klasifikasi teks turun. Untuk tujuan ini, kami mengusulkan model bahasa AgglutiFiT dengan sumber daya rendah memperbaiki AgglutiFiT, secara spesifik, kami membangun set data memperbaiki suara rendah dengan analisis morfologi dan ekstraksi stem, kemudian memperbaiki model prapelatihan salib bahasa pada set data ini. Selain itu, kami mengusulkan strategi penyesuaian yang berdasarkan perhatian yang lebih baik memilih informasi semantis dan sintaksi relevan dari model bahasa yang dilatih-dilatih dan menggunakan fitur-fitur tersebut pada tugas klasifikasi teks turun. Kami mengevaluasi metode kami pada sembilan dataset klasifikasi Uyghur, Kazakh dan Kyrgyz, di mana mereka memiliki prestasi yang jauh lebih baik dibandingkan dengan beberapa kuat
garis dasar.</abstract_id>
      <abstract_sw>Utawala wa maandishi unakuwa vigumu pale taarifa hazitafaa kuzingatia kiasi cha makampuni ya maandishi yaliyoandikwa kwa mikononi. Kwa lugha za asili za chini za rasilimali ikiwa ni pamoja na Uyghur, Kazakh, na Kyrgyz (lugha za Uingereza), ambazo maneno yanatengenezwa kupitia vituo vinavyohusiana na viungo kadhaa vinatumika kama uwakilishi wa maudhui ya maandishi, kipengele hiki kinaruhusu lugha isiyo na ujuzi ambao hupelekea usio na uhakika mkubwa wa aina za kuandika na vipengele vikubwa vinavyopungua. Kuna changamoto kubwa za usambazaji wa maandishi yenye rasilimali ya chini kwa kutangaza ukosefu wa taarifa zilizowekwa katika maeneo yanayolenga na utofauti wa viwanda vya kimaadili katika miundombinu ya lugha. Ni suluhisho yenye ufanisi ambalo hutumia mwelekeo wa lugha iliyoelekezwa kabla wa kutoa wataalamu wenye maana na wanaopendwa kwa ajili ya kazi za usambazaji wa maandishi ya chini. Kwa mwisho huu, tunapendekeza modeli ya lugha yenye asili ya kibaguzi mzuri AgglutiFiT, hususani, tunajenga taarifa zilizotengenezwa vizuri vya sauti kwa uchambuzi wa kimaadilojia na utekelezaji wa vigogo, kisha tunatumia modeli ya mafunzo ya kabla ya lugha katika seti hii ya data. Zaidi ya hayo, tunapendekeza mkakati wa mafunzo mzuri ambao unachagua taarifa zinazohusiana na kimapenzi kutoka katika mtindo wa lugha iliyoendelea na kutumia hizo vipengele kwenye kazi za usambazaji wa maandishi. Tutathmini mbinu zetu kuhusu takwimu za usambazaji tisa za Uyghur, Kazakh na Kyrgyz, ambazo zina ufanisi bora zaidi ukilinganishwa na baadhi ya nguvu
mistari ya msingi.</abstract_sw>
      <abstract_tr>Metin sahypalary elimden etilen metin corpora hasaplamak üçin kynçylyk däldir. Uygur, Kazakh we Kirghiz dilleri (UKK dilleri) içinde kelimeler birnäçe sufiks we süzmeler bilen meňzeş sözler bilen üretilýär. Açyk ressurs aglumatçy metin klasifikasynda hasaplanýan maglumat domaýynda we dil strukturlarynda näçe görnüşler bar. Bu ýer täsirli çözüm. Bir öňünden eğlenen dil nusgasyny a şmaly metin klasifikasyonaty üçin möhüm we gowymy üçin ullanjak täsirlere süýtgetmek üçin janlaşdyrylýan çözüm. Bu üçin biz esasy üçin iň derejede agglutinatçy dil nusgasyny AgglutiFiT'i suýlaýarys. Şüphesiz morfolojik analiziýa we استm ekstrasyona görä düşük sesli hasaplanjak düzgün hasaplanjak düzgün hasaplanjak üçin gurnuyoruz we soňra bu data düzgünde cross-dil öň-okuwçy nusgasyny çykarýarys. Mundan hem, biz üns altynda nämli taýýarlama stratejiýasyny gowy görkezýäris we ol semantik we sintaktik maglumatlary öňünden eğlenen dil nusgadan saýlaýar we ol özellikleri aşaky tekst klasifikasynda ullanýar. Biz öz ýürlerimizi 9 Uýgur, Kazakh we Kirgiz klasifikasyýasynda deňleýäris. Bu ýerde birnäçe güýçli ukyplaryň bilen görä has gowy hereketlerimiz bar.
üýtgeşik</abstract_tr>
      <abstract_sq>Klasifikimi i tekstit ka tendencë të jetë i vështirë kur të dhënat janë të papërshtatshme duke konsideruar sasinë e korprave teksti të etiketuara manualisht. Për gjuhët aglutinative me burime të ulëta duke përfshirë Uyghur, Kazakh dhe Kirgizën (gjuhët UKK), në të cilat fjalët prodhohen nëpërmjet shtyllave të bashkangjitura me disa shtylla dhe shtylla përdoren si përfaqësim i përmbajtjes së tekstit, kjo funksion lejon fjalorin e përcaktuar të derivateve që shpie në pasiguri të lartë të formulave të shkrimit dhe karakteristikave të mëdha të tepërta. Ka sfida të mëdha të klasifikimit të tekstit aglutinativ me burime të ulta mungesën e të dhënave të etiketuara në një domeni objektiv dhe diversitetin morfologjik të derivatave në strukturat gjuhësore. Ky është një zgjidhje efektive që rregullon një model gjuhësh të paratrajnuar për të siguruar nxjerrës të kuptueshëm dhe të favorshëm për përdorim për detyrat e klasifikimit të tekstit në vazhdim. Për këtë qëllim, ne propozojmë një model gjuhësh aglutinative me burime të ulëta të rregullimit të AgglutiFiT, veçanërisht, ne ndërtojmë një set të dhënash të rregullimit të ulëtë të zhurmës me analizë morfologjike dhe nxjerrje të shtyllës, pastaj të rregullojmë modelin ndërgjuhësor të paratrajnimit në këtë set të dhënash. Përveç kësaj, ne propozojmë një strategji mirërregullimi bazuar në vëmendje që zgjedh më mirë informacionin e duhur semantik dhe sintaktik nga modeli i gjuhës së paratrajnuar dhe përdor këto elemente në detyrat e klasifikimit të tekstit poshtë. Ne vlerësojmë metodat tona në nëntë grupe të dhënash klasifikuese Uyghur, Kazakh dhe Kirgiz, ku ato kanë performancë më të mirë në krahasim me disa të forta
linjat bazë.</abstract_sq>
      <abstract_fa>زمانی که داده‌ها با توجه به اندازه مقدار جسد متن به دستی برگزیده شده‌اند، محدودیت متن سخت می‌شود. برای زبانهای کمترین منبع آغاز کننده‌ای که شامل ویگور، Kazakh و کیرگیز (زبانهای UKK) می‌باشند، در آن کلمات‌ها از طریق استخوان‌های متعدد و استخوان‌ها به عنوان نمایش محتوای متن استفاده می‌شوند، این ویژگی اجازه می‌دهد کلمات ناپدید آغاز‌کننده‌های بی‌نهایی که به شکل‌های نوشتن و ویژه‌های بزرگی ناپدید می‌ چالش‌های بزرگی از ترکیب متن‌های کم منبع آلوده‌کننده‌ای وجود دارد که ناتوانی داده‌های نقاشی در یک دامنه هدف و مختلف متنوع مورفولوژیک از تولید‌ها در ساختارهای زبان وجود دارد. این یک راه حل موثری است که یک مدل پیش از آموزش زبان را تغییر می دهد تا استفاده کنندگان ویژه‌های معنی و مناسب برای استفاده از ویژه‌های ویژه‌های مختصات متن پایین استفاده کند. برای این قسمت، ما یک مدل زبان آگلوتیفیت را پیشنهاد می‌کنیم که یک مدل آگلوتیفیت با کمترین منابع آگلوتیفیت را تنظیم کنیم، مخصوصا، یک مجموعه اطلاعات نیکو تنظیم صدا را با تحلیل مورفیک و استخراج استم بسازیم، سپس مدل پیش آموزشی متوسط زبان را بر این مجموعه داده‌ ما پیشنهاد می کنیم استراتژی اصلاح توجه بر اساس توجه که بهتر اطلاعات semantic و syntactic مربوط به عنوان مدل زبان پیش آموزش شده را انتخاب کند و از این ویژگی ها در مسائل جدایی متن پایین استفاده می کند. ما روش‌هایمان را در مورد نو اویگور، کازاک و داده‌های مختصات کرگی ارزیابی می‌کنیم، جایی که آنها عملکرد بسیار بهتر در مقایسه با چندین قوی دارند
خط پایین</abstract_fa>
      <abstract_ko>인공적으로 표시된 텍스트 자료 라이브러리의 수량을 고려하면 데이터가 부족할 때 텍스트 분류는 비교적 어렵다.위구르어, 카자흐어, 키르기스어 (UKK 언어) 를 포함한 저자원 접착성 언어의 경우, 이들 언어의 단어는 어간과 몇 개의 접미사를 통해 연결되고, 어간은 작문본 내용의 표시로 사용되며, 이 기능은 무제한 파생 어휘를 허용하여 쓰기 형식의 높은 불확실성과 대량의 불필요한 기능을 초래한다.저자원 접착성 텍스트 분류가 직면한 주요 도전은 목표역에서 표기된 데이터의 부족과 언어 구조에서 파생된 단어의 형태의 다양성이다.미리 훈련된 언어 모델을 미세하게 조정하여 후속 텍스트 분류 임무에 의미 있고 유리한 특징 추출기를 제공하는 것은 효과적인 해결 방안이다.이를 위해 우리는 저자원 응집 언어 모델인 마이크로스피커 응집 의합을 제시했다. 즉, 형태학 분석과 어간 추출을 통해 저소음 마이크로스피커 데이터 집합을 구축하고 이 데이터 집합에서 마이크로스피커 크로스 언어 예훈련 모델을 구축했다.그 밖에 우리는 주의를 바탕으로 하는 마이크로 조정 전략을 제시하여 미리 훈련된 언어 모델에서 관련 의미와 문법 정보를 더욱 잘 선택하고 이러한 특징을 하위 텍스트 분류 임무에 사용할 수 있다.우리는 9개의 위구르족, 카자흐족, 키르기스족 분류 데이터 집합에서 우리의 방법을 평가했다. 이런 데이터 집합에서 몇 개의 강력한 분류 데이터 집합에 비해 그들의 성능이 현저히 좋다.
베이스라인.</abstract_ko>
      <abstract_af>Teks klassifikasie het gevaal om moeilik te wees wanneer data is onvoldoende onderwerp van die hoeveelheid van handgemerkte teks korpora. Vir lae-hulpbron aglutinatiewe tale insluitend Uyghur, Kazakh, en Kyrgyz (UKK tale), waarin woorde deur stamme geproduseer word deur stamme wat verskeie aglutiefasiliteite en stamme gebruik word as die voorstelling van teks inhoud, hierdie funksie laat onbepaalde afgeleide woordeboek toe wat lei na hoë onbevestigheid van skryfvorms en groot onbevestigheid funksies. Daar is groot uitdagings van lae-hulpbron aglutinatiewe teks klassifikasie die ontbreek van gemerkte data in 'n doel domein en morfologiese verskeidigheid van afgeleide in taal strukture. Dit is 'n effektief oplossing wat fyn- tuning van 'n vooraf- opgelei taal model om betekenlike en gunsbaarde funksie-uitvoerders te verskaf vir onderstreem teks klassifikasie taak. Op hierdie einde voorstel ons 'n lae hulpbron aglutinatiewe taal model fin-tuning AgglutiFiT, spesifieke, bou ons 'n lae-ruis fin-tuning datastel deur morfologiese analisie en stam-uittrekking, dan fin-tuning die kruislinglike voor-onderwerking model op hierdie datastel. Ook, ons voorstel 'n aandag-gebaseerde fyn-tuning strategie wat beter relevante semantiese en sintaktieke inligting kies van die voorafgevorderde taal model en gebruik daardie funksies op onderstreem teks klasifikasie taak. Ons evalueer ons metodes op nege Uyghur, Kazakh en Kyrgyz klassifikasie datastelle waar hulle betekeurig beter prestasie het vergelyk met verskeie sterk
baseline.</abstract_af>
      <abstract_hy>Տեքստի դասակարգումը հակված է դժվար լինել, երբ տվյալները բավարար են, հաշվի առնելով ձեռքով նշված տեքստի մարմնի քանակը: Այս հատկությունը թույլ է տալիս անսահմանափակ ծառայությունների բառարան, որը հանգեցնում է գրողական ձևերի մեծ անորոշությունը և հսկայական անհնար հատկություններին: Նվագ ռեսուրսների ագլուտիվ տեքստի դասակարգման մեծ մարտահրավերներ կան նպատակային ոլորտում նշանակված տվյալների բացակայությունը և լեզվի կառուցվածքների մորֆոլոգիական բազմազանությունը: Դա արդյունավետ լուծում է, որը վերափոխում է նախապատրաստված լեզվի մոդելը, որպեսզի տրամադրի իմաստալից և օգտագործելի առանձնահատկությունների վերացուցիչներ ներքևի տեքստի դասակարգումների համար: Այս նպատակով, մենք առաջարկում ենք ցածր ռեսուրսներով ագլյուտինատիվ լեզվի մոդել, որը կազմակերպում է ագգլյուտիֆիթ, հատկապես, մենք կառուցում ենք ցածր աղմուկի ագլյուտիզացիոն տվյալների համակարգ՝ մորֆոլոգիական վերլուծությամբ և ստորաձև վերացնելով, հետո Ավելին, մենք առաջարկում ենք ուշադրության վրա հիմնված բարելավման ռազմավարություն, որն ավելի լավ ընտրում է նշանակալի սեմանտիկ և սինտակտիկ տեղեկատվություն նախապատրաստված լեզվի մոդելի միջոցով և օգտագործում է այդ հատկությունները հետագա տեքստի դասա Մենք գնահատում ենք մեր մեթոդները 9 Ոյգուրի, Կազախի և Կիրգիզի դասակարգման տվյալների համակարգերի վրա, որտեղ դրանք շատ ավելի լավ արդյունք ունեն, համեմատած մի քանի ուժեղ
հիմնական գծերը:</abstract_hy>
      <abstract_am>የጽሑፍ መግለጫ የጽሑፍ ክፍተት ቁጥር በጨዋታ አይበቃም፡፡ ለጥቂት resource agglutinative ቋንቋዎች ጉጉጉር፣ ካዛክ እና ቂርጊዝ (የዩኩክ ቋንቋ) ያሉ ቃላት በብዙ ጉዳይ እና ድምጾች በተገኘ ድምፅ እና ድምፅ በተለየ ድምፅ ማቀናቀል ይደረጋሉ፡፡ በቋንቋዎች አካባቢ እና የሞፎሎጂ ልዩ ልዩ ልዩነት የጽሑፍ መክፈቻ የጎግሎት የጽሑፍ መግለጫ የሚያስፈልገው የድምፅ መረጃዎች በቋንቋ አካባቢዎች ውስጥ የጽሑፍ ጥያቄዎች አለባቸው፡፡ በጽሑፍ መክፈቻ ስራዎችን ለመስጠት የሚታይ እና የተወደደ የፊደል ቋንቋ ሞዴል በመጠቀም የሚያስፈልገው የጽሑፍ መክፈቻ ስርዓት የሚያስፈልገውን ማቀናጃ ያስተካክላል፡፡ ለዚህ ምክንያት የጎግሎቲዊ ቋንቋ ምሳሌ አግglutiFiT የተመሳሳይ እናስጀራለን፡፡ በተጨማሪም፣ ደግሞም የተጠቃሚ የቋንቋ ምሳሌ የተለየውን የጽሑፍ ትክክለኛ ስርዓት ለመምረጥ እና የተጠቃሚ መረጃዎችን ለመምረጥ እና እነዚህን ምርጫዎች በበታችኛው ጽሑፍ መግለጫ ስራዎችን ለመጠቀም እናስጠጋለን፡፡ የዘጠኝ ዩጉር፣ ካዛክ እና ቂርጊስ የክፍላጻ ዳታዎችን እናስተምርላቸዋለን፡፡
መሀከል መስመር</abstract_am>
      <abstract_ca>La classificació del text tendeix a ser difícil quan les dades són insuficients considerant la quantitat de corpores de text etiquetats manualment. Per a llengües aglutinatives de baix recursos, incloent Uyghur, Kazakh i Kirguis (llengües UKK), en les quals les paraules es fabriquen a través de troncs concatenats amb diversos sufixxos i troncs s'utilitzen com a representació del contingut de text, aquesta característica permet un vocabulari infinit de derivats que porta a una gran incertitud de formes d'escriptura i grans característiques redundants. Hi ha els principals reptes de la classificació del text aglutinatiu de baix recursos la falta de dades etiquetades en un domini d'objectiu i la diversitat morfològica de derivacions en les estructures lingüístices. És una solució eficaç que ajusta un model de llenguatge pré-entrenat per proporcionar extractors de característiques significatius i favorables a l'ús per a tasques de classificació de textos a avall. Per això, proposem un model de llenguatge aglutinatiu de baix recursos que ajuste AgglutiFiT, específicament, construïm un conjunt de dades d'ajuste baix soroll mitjançant anàlisi morfològica i extracció de troncs, i després ajustem el model de pré-entrenament translingüístic d'aquest conjunt de dades. A més, proposem una estratègia d'ajustament basada en l'atenció que seleccioni millor la informació semàntica i sinàctica pertinent del model de llenguatge pré-entrenat i utilitza aquestes característiques en tasques de classificació de textos avall. Evaluam els nostres mètodes en nou conjunts de dades de classificació d'Uyghur, Kazakh i Kirguis, on tenen un rendiment significativament millor comparat amb diverses fortes
línies de base.</abstract_ca>
      <abstract_az>Mətn klasifikasiyası, məlumat əl etiketli mətn korporasının dəyişikliyini düşünməyə kifayət olduğunda çətin olar. Uyghur, Kazakh və Kirgiz dilləri (UKK dilləri) içərisində düşük kaynaqlar agglutinativ dillər üçün, sözləri bir neçə suffiks və stems ilə birləşdirilmiş stems vasitəsilə təhsil edilir, bu özellik mətn məlumatının göstəricisi olaraq istifadə edilir. Bu təhsil yazmaq formların və böyük qüvvətli özelliklərin təhsil edilməsini sağlar. Tək ressurs agglutinativ metin klasifikasyonun böyük çətinlikləri var ki, məqsəd domeində etiket edilmiş məlumatların yoxdur və dil strukturlarında dəyişiklik məlumatların çoxluğunu. Bu, əvvəlcə təhsil edilmiş dil modelini təmizləmək üçün mənfəətli və faydalı istifadə etmək üçün fərqli çətinlikdir. Bu səbəbdə, düşük ressurs agglutinativ dil modeli AgglutiFiT'i təsdiqləyirik, əlbəttə ki, morfolojik analizi və stem ekstraksiyası ilə düşük səslər tədricləyici verilər qurduq, sonra bu verilər qutusunda çoxlu dil əvvəl tədricləyici modeli tədricləyirik. Daha sonra, biz təhsil edilmiş dil modelindən daha yaxşı olan semantik və sintaktik məlumatları seçən, təhsil edilən təhsil-təhsil təhsil-təhsil stratejisini təklif edirik. Biz doqquz Uyghur, Kazakh və Kirgiz klasifikasyonu verilən tərzlərimizi değerləşdiririk. Onlar çoxlu güclü tərzlər ilə müqayisədə daha xeyirli performanslar var.
baselines.</abstract_az>
      <abstract_bn>টেক্সট ক্লাস্ফিকেশন ব্যবহার করে যখন ডাটা হাতে লেবেল করা টেক্সট কর্পোরার পরিমাণ যথেষ্ট না থাকে। লেখার প্রতিনিধি হিসেবে ব্যবহার করা হয়েছে যার মধ্যে উগুর, কাজাক এবং কিরগিজ (যুক্তরাজ্য ভাষা), যেখানে শব্দ উৎপাদন করা হয়েছে বেশ কয়েকটি ভক্স এবং স্টেমের মাধ্যমে, এই বৈশিষ্ট্যের বৈশিষ্ট্যের প্রতিনিধিত্ব হিসে টার্গেট ডোমেইনে লেবেলেড ডাটার অভাব এবং ভাষার কাঠামোর বৈচিত্র্যের বৈচিত্র্যের প্রধান চ্যালেঞ্জ রয়েছে। এটা একটি কার্যকর সমাধান যা পূর্ব প্রশিক্ষিত ভাষার মডেলের সুন্দর প্রদান করা যায় যাতে অর্থহীন এবং পছন্দ করা ব্যবহারের বৈশিষ্ট্য বিশেষ বিনি এই পর্যন্ত আমরা একটি নিম্ন সম্পদ গ্লুগুটিভ ভ ভাষার মডেল প্রস্তাব করি, বিশেষ করে আমরা মোরফোলিক্যালিকাল বিশ্লেষণ এবং স্টেম বের করে নির্মাণ করি, তারপর এই ডাটাসেটে ক্রিভাষাভাষার প্রেক্ষাপটে এছাড়াও, আমরা একটি মনোযোগ প্রস্তাব করি ভিত্তিক ভিত্তিক ভিত্তিক ভিত্তিক সুন্দর কৌশল যা পূর্ববর্তী প্রশিক্ষিত ভাষার মডেল থেকে সামান্যিক এবং সিন্ আমরা নয়টি ইউগুর, কাজাক এবং কিরগিজের ক্লাসাফিকেশন ডাটাসেটে আমাদের পদ্ধতি মূল্যায়ন করি, যেখানে তাদের বেশ কয়েকটি শক্তিশালী প্রদর্
বেসেলাইন।</abstract_bn>
      <abstract_bs>Klasifikacija teksta često je teško kad podaci nisu dovoljni s obzirom na količinu ručno označene tekstne korpore. Za manje resurse agglutinativne jezike uključujući Uyghur, Kazakh i Kirgiz (UKK jezike), u kojima se riječi proizvode putem stazama povezanih sa nekoliko sufiksa i stazama koriste kao predstavljanje sadržaja teksta, ta karakteristika omogućava beskonačnu derivativnu rečenicu koja dovodi do visoke nesigurnosti oblika pisanja i ogromnih redundantnih karakteristika. Postoje veliki izazovi takve klasifikacije teksta s niskim resursima, nedostatak označenih podataka u ciljnom domenu i morfološkom raznolikosti derivacija u jezičkim strukturama. To je učinkovito rješenje koje ispravlja predobučeni jezički model kako bi omogućilo smislene i favorilne ekstraktore karakteristike za klasifikaciju teksta. Za taj cilj predlažemo model AgglutiFiT-a koji finalizira s niskim resursima agglutinativnim jezikom, posebno, izgradimo nizak zvuk finalizirajući podatke sa morfološkom analizom i ekstrakcijom matičnih izvora, a zatim finaliziramo preko jezika predobuku na ovom setu podataka. Osim toga, predlažemo strategiju za finaliziranje pažnje koja bolje odabere relevantne semantičke i sintaktičke informacije iz predobučenog jezičkog modela i koristi te karakteristike na zadacima klasifikacije teksta. Procjenjujemo naše metode na devet Uyghura, Kazakha i Kirgijskih klasifikacijskih podataka, gdje imaju značajno bolje izvedbe u usporedbi s nekoliko jakih
osnovne linije.</abstract_bs>
      <abstract_cs>Klasifikace textu bývá obtížná, pokud jsou data nedostatečná vzhledem k množství ručně označených textových korpusů. U agglutinativních jazyků s nízkými zdroji včetně Ujgurštiny, Kazaštiny a Kyrgyzštiny (jazyků UKK), ve kterých jsou slova vytvářena pomocí stonků spojených s několika příponami a stonky se používají jako reprezentace textového obsahu, tato funkce umožňuje nekonečné odvození slovní zásoby, která vede k vysoké nejistotě psaní forem a obrovským nadbytečným rysům. Hlavní výzvy klasifikace aglutinativních textů s nízkými zdroji jsou nedostatek označených dat v cílové doméně a morfologická diverzita odvození jazykových struktur. Jedná se o efektivní řešení, které jemně ladí předškolený jazykový model tak, aby poskytovalo smysluplné a příznivé extraktory funkcí pro následné úlohy klasifikace textu. Za tímto účelem navrhujeme model AgglutiFiT s nízkými zdroji, konkrétně vytvoříme datovou sadu s nízkým šumem pomocí morfologické analýzy a extrakce kmenů, poté doladíme model předškolení mezi jazyky na této sadě. Navíc navrhujeme strategii jemného ladění založenou na pozornosti, která lépe vybírá relevantní sémantické a syntaktické informace z předškoleného jazykového modelu a využívá tyto funkce při následných úlohách klasifikace textu. Naše metody hodnotíme na devíti ujgurských, kazašských a kyrgyzských klasifikačních datových sadách, kde mají výrazně lepší výkon ve srovnání s několika silnými daty.
základní linie.</abstract_cs>
      <abstract_et>Teksti klassifitseerimine kipub olema keeruline, kui andmed on käsitsi märgistatud tekstikorpuste hulka arvestades ebapiisavad. Vähese ressursiga aglutineeritud keelte puhul, sealhulgas uõguuri, kasahhi ja kirgiisi keeled (UKK keeled), kus sõnu valmistatakse mitme sufiksiga seotud varre kaudu ning tekstisisu esitamiseks kasutatakse varre kaudu, võimaldab see funktsioon lõputult tuletisi sõnavara, mis toob kaasa kirjutamisvormide suure ebakindluse ja tohutute üleliigsete omaduste. Vähese ressursiga aglutinaatilise teksti klassifitseerimisel on suured probleemid, märgistatud andmete puudumine sihtvaldkonnas ja tuletiste morfoloogiline mitmekesisus keelestruktuurides. Tegemist on tõhusa lahendusega, mis täpsustab eelõpetatud keelemudelit, et pakkuda sisukaid ja soodsaid funktsioonide ekstraktoreid teksti klassifitseerimise ülesannete jaoks. Selleks pakume välja madala ressursiga aglutinaatse keele mudeli AgglutiFiT täpsustamiseks, täpsemalt ehitame morfoloogilise analüüsi ja tüve ekstraheerimise abil madala müraga peenhäälestuse andmekogumi, seejärel häälestame selle andmekogumi keeleülese eelkoolituse mudeli. Lisaks pakume välja tähelepanupõhise peenhäälestusstrateegia, mis valib eelõpetatud keelemudelist paremini asjakohase semantilise ja süntaktilise teabe ning kasutab neid funktsioone teksti järgmise klassifitseerimise ülesannetes. Hindame oma meetodeid üheksa Uõguuri, Kasahhi ja Kõrgõisi klassifikatsiooni andmekogumi põhjal, kus need on oluliselt paremad kui mitmed tugevad
lähtejooned.</abstract_et>
      <abstract_fi>Tekstin luokittelu on yleensä vaikeaa, kun tiedot ovat puutteellisia, kun otetaan huomioon manuaalisesti merkittyjen tekstikorpusten määrä. Vähävaraisten agglutinaattien kielten, kuten uyguurin, kazakin ja kirgisian (UKK-kielet), joissa sanoja valmistetaan varren kautta, jotka on yhdistetty useisiin sufixeihin ja varret käytetään tekstin sisällön esittämiseen, tämä ominaisuus mahdollistaa loputtoman johdannaissanaston, joka johtaa kirjoitusmuotojen korkeaan epävarmuuteen ja valtaviin tarpeettomiin ominaisuuksiin. Vähävaraisen agglutinaattisen tekstin luokitteluun liittyy suuria haasteita, sillä kohdealueella ei ole merkittyä tietoa ja kielirakenteiden johdannaisten morfologinen monimuotoisuus. Se on tehokas ratkaisu, joka hienosäätää ennalta koulutettua kielimallia tuottamaan mielekkäitä ja käyttökelpoisia ominaisuusuuttimia loppupään tekstiluokitustehtäviin. Tätä varten ehdotamme AgglutiFiT:n hienosäätöä hyödyntävää agglutinatiivista kielimallia, erityisesti rakennamme hiljaisen hienosäätöaineiston morfologisella analyysillä ja varrenpoistolla, minkä jälkeen hienosäädämme monikielisen esikoulutusmallin tähän aineistoon. Lisäksi ehdotamme huomiota perustuvaa hienosäätöstrategiaa, joka valitsee paremmin relevantin semanttisen ja syntaktisen tiedon esikoulutetusta kielimallista ja käyttää näitä ominaisuuksia loppupään tekstiluokittelutehtävissä. Arvioimme menetelmiämme yhdeksästä uiguurin, Kazakstanin ja Kirgisian luokitusaineistosta, joissa niiden suorituskyky on huomattavasti parempi verrattuna useisiin vahvoihin luokituksiin.
peruslinjat.</abstract_fi>
      <abstract_jv>email-custom-header-Security Perusahaan langgambar kelas karo akeh-Ressource error message It is an Effect Resolution Fine Label Awak dh챕w챕 챕ntuk dh챕w챕 챕ntuk ak챕w챕 ning ngerasai liyane UYhur, Kasakh karo data seneng kerghiz, kawur dh챕w챕 wis ana luwih operasi sing gak dh챕w챕 karo ngono sing paling dh챕w챕
vertical-aligntextattr</abstract_jv>
      <abstract_sk>Klasifikacija besedila je težka, kadar so podatki nezadostni glede na količino ročno označenih korpusov besedila. Za aglutinativne jezike z nizkimi viri, vključno z ujgurščino, kazaščino in kirgiščino (UKK jeziki), v katerih se besede izdelujejo preko stebel, povezanih z več priponami in stebel se uporabljajo kot predstavitev besedilne vsebine, ta funkcija omogoča neskončno izpeljano besedišče, ki vodi do visoke negotovosti pisanih oblik in ogromnih odvečnih značilnosti. Obstajajo veliki izzivi pri klasifikaciji aglutinacijskega besedila z nizkimi viri, pomanjkanje označenih podatkov v ciljni domeni in morfološka raznolikost derivacij v jezikovnih strukturah. Je učinkovita rešitev, ki natančno nastavi vnaprej usposobljen jezikovni model, da zagotovi smiselne in ugodne izvlečke funkcij za opravila klasifikacije besedila v nadaljnji fazi. V ta namen predlagamo model aglutinacijskega jezika z nizkimi viri za fino nastavitev AgglutiFiT, natančneje, z morfološko analizo in ekstrakcijo stebla zgradimo nizko-hrupni fini nastavitveni nabor podatkov, nato na tem naboru podatkov natančno nastavimo medjezični model predusposabljanja. Poleg tega predlagamo na pozornosti temelječo strategijo finega uravnavanja, ki bolje izbira relevantne semantične in sintaktične informacije iz vnaprej usposobljenega jezikovnega modela in uporablja te funkcije pri opravilih klasifikacije besedila po koncu toka. Naše metode ocenjujemo na devetih ujgurskih, kazahskanskih in kirgiških klasifikacijskih zbirkah podatkov, kjer imajo bistveno boljšo učinkovitost v primerjavi z več močnimi klasifikacijskimi zbirkami.
osnovne linije.</abstract_sk>
      <abstract_ha>Tsarin matsayi ya zama mai tsanani idan data ba su isa daidai ba, idan ana ƙayyade girmar matsayin da hannayen aka rubũta. @ info: whatsthis Kuna da masu girma wa classified matsayin na wuri-resource agagagutinative na ƙaranci da danne da aka rubũta shi a lokacin da aka yi amfani da shi, da diffai masu motsi cikin tsarin harshe. @ action: button Ga wannan, Munã buɗa wani misali na aggliutinative lugha mai kyau-tuning AggliutiFiT, kuma da ƙayyade, muna sami wani danne mai sauri-sauni da ake samun rarraba fasalin morfologi da kuma za'a yi amfani da shi, sa'an nan kuma muna sami misãlin mai amfani da ke kan wannan dataset. Za kuma, za mu buɗa wani akan tunkuɗe wa masu fasahan aikin da aka samar da aikin muhimmi da masu husika na semantic da syntactic daga misalin harshen da aka yi wa zaman-wa'anar na samu kuma Muke amfani da su masu tsari kan aikin classified matsayin da ke ƙarƙashe. Tuna ƙaddara hanyoyinmu a kan masaluman tara na Uighur, Kazakh da kyrgiz, inda sun sami mafiya kyakkyawan fasarin da wasu mãsu ƙarfi
asalin.</abstract_ha>
      <abstract_bo>Text classification tends to be difficult when data are inadequate considering the amount of manually labeled text corpora. For low-resource agglutinative languages including Uyghur, Kazakh, and Kyrgyz (UKK languages), in which words are manufactured via stems concatenated with several suffixes and stems are used as the representation of text content, this feature allows infinite derivatives vocabulary that leads to high uncertainty of writing forms and huge redundant features. There are major challenges of low-resource agglutinative text classification the lack of labeled data in a target domain and morphologic diversity of derivations in language structures. It is an effective solution which fine-tuning a pre-trained language model to provide meaningful and favorable-to-use feature extractors for downstream text classification tasks. To this end, we propose a low-resource agglutinative language model fine-tuning AgglutiFiT, specifically, we build a low-noise fine-tuning dataset by morphological analysis and stem extraction, then fine-tune the cross-lingual pre-training model on this dataset. Moreover, we propose an attention-based fine-tuning strategy that better selects relevant semantic and syntactic information from the pre-trained language model and uses those features on downstream text classification tasks. ང་ཚོའི་ཐབས་ལམ་དེ་ཚོ་ནི་ཡུ་གུ་རུ་(Uyghur)ཀཛུཀ་དང་། ཀར་གྲུ་ཛུང་གི་དབྱེ་སྟངས་ཆ་འཕྲིན་ཡིག་ཆ་ལྟར་ཞིབ་བྱེད་ཀྱི་ཡོད།
རྨང་གཞི་ཚོགས་རེད།</abstract_bo>
      <abstract_he>מסווג טקסט נוטה להיות קשה כאשר נתונים אינם מספיקים בהתחשב בכמות של גופורה טקסט מסוימת ידנית. עבור שפות אגלוטינציות נמוכות כוללות אויגור, קזאק, וקירגיז (שפות UKK), שבהן מילים יוצרות באמצעות גזעים משותפים עם מספר ספיקסים וסטים משתמשים כמייצג של תוכן טקסט, התחום הזה מאפשר מילון הנגזרים אינסופיים שמוביל לאי-בטוחות גבוהה של צורות כתיבות ומיוחדים ענקים. ישנם אתגרים גדולים של מסווג טקסט אגלוטינטיבי משאבים נמוכים, חוסר נתונים מסומנים בתחום המטרה, ומגווון מורפולוגי של התוצאות במבני שפה. זה פתרון יעיל שמתאים את דוגמנית שפת מאומנת מראש כדי לספק משמעותיים וחוברים לשימוש מחלקי תכונות עבור משימות מסווג טקסט למטה. למטרה זו, אנו מציעים מודל שפה אגלוטינטיבי עם משאבים נמוכים מתאים גבוה AgglutiFiT, במיוחד, אנו בונים קבוצת נתונים מתאים גבוה עם רעש נמוך על ידי ניתוח מורפולוגי וחילוץ סטם, ואז מתאים את מודל התאמה לפני השפה הצלבית על קבוצת נתונים זו. בנוסף, אנו מציעים אסטרטגיה מתאימה מבוססת תשומת לב שמבוחרת יותר מידע סמנטי וסינטקטי רלוונטי ממודל השפה המאמן מראש We evaluate our methods on nine Uyghur, Kazakh, and Kyrgyz classification datasets, where they have significantly better performance compared with several strong
קווי הבסיס.</abstract_he>
      </paper>
    <paper id="93">
      <title>Constructing Uyghur Name Entity Recognition System using Neural Machine Translation Tag Projection<fixed-case>U</fixed-case>yghur Name Entity Recognition System using Neural Machine Translation Tag Projection</title>
      <author><first>Anwar</first><last>Azmat</last></author>
      <author><first>Li</first><last>Xiao</last></author>
      <author><first>Yang</first><last>Yating</last></author>
      <author><first>Dong</first><last>Rui</last></author>
      <author><first>Osman</first><last>Turghun</last></author>
      <pages>1006–1016</pages>
      <abstract>Although <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a> achieved great success by introducing the <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a>, it is challenging to apply these models to low resource languages including <a href="https://en.wikipedia.org/wiki/Uyghur_language">Uyghur</a> while it depends on a large amount of annotated training data. Constructing a well-annotated named entity corpus manually is very time-consuming and labor-intensive. Most existing methods based on the <a href="https://en.wikipedia.org/wiki/Parallel_corpus">parallel corpus</a> combined with the word alignment tools. However, word alignment methods introduce alignment errors inevitably. In this paper, we address this problem by a named entity tag transfer method based on the common neural machine translation. The proposed method marks the entity boundaries in Chinese sentence and translates the sentences to <a href="https://en.wikipedia.org/wiki/Uyghur_language">Uyghur</a> by <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation system</a>, hope that <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> will align the source and target entity by the self-attention mechanism. The experimental results show that the Uyghur named entity recognition system trained by the constructed corpus achieve good performance on the test set, with 73.80 % F1 score(3.79 % improvement by baseline)</abstract>
      <url hash="f94148a5">2020.ccl-1.93</url>
      <language>eng</language>
      <bibkey>azmat-etal-2020-constructing</bibkey>
    </paper>
    <paper id="95">
      <title>Mongolian Questions Classification Based on Mulit-Head Attention<fixed-case>M</fixed-case>ongolian Questions Classification Based on Mulit-Head Attention</title>
      <author><first>Guangyi</first><last>Wang</last></author>
      <author><first>Feilong</first><last>Bao</last></author>
      <author><first>Weihua</first><last>Wang</last></author>
      <pages>1026–1034</pages>
      <abstract>Question classification is a crucial subtask in <a href="https://en.wikipedia.org/wiki/Question_answering">question answering system</a>. Mongolian is a kind of few resource language. It lacks public labeled corpus. And the complex morphological structure of <a href="https://en.wikipedia.org/wiki/Mongolian_language">Mongolian vocabulary</a> makes the data-sparse problem. This paper proposes a <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification model</a>, which combines the Bi-LSTM model with the Multi-Head Attention mechanism. The Multi-Head Attention mechanism extracts relevant information from different dimensions and representation subspace. According to the characteristics of Mongolian word-formation, this paper introduces Mongolian morphemes representation in the embedding layer. Morpheme vector focuses on the <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> of the Mongolian word. In this paper, character vector and morpheme vector are concatenated to get <a href="https://en.wikipedia.org/wiki/Word_vector">word vector</a>, which sends to the Bi-LSTM getting context representation. Finally, the Multi-Head Attention obtains global information for <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a>. The <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> experimented on the <a href="https://en.wikipedia.org/wiki/Mongolian_writing_systems">Mongolian corpus</a>. Experimental results show that our proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> significantly outperforms baseline systems.</abstract>
      <url hash="6a38d06a">2020.ccl-1.95</url>
      <language>eng</language>
      <bibkey>wang-etal-2020-mongolian</bibkey>
    </paper>
    <paper id="97">
      <title>Categorizing Offensive Language in <a href="https://en.wikipedia.org/wiki/Social_network">Social Networks</a> : A Chinese Corpus, Systems and an Explainable Tool<fixed-case>C</fixed-case>hinese Corpus, Systems and an Explainable Tool</title>
      <author><first>Xiangru</first><last>Tang</last></author>
      <author><first>Xianjun</first><last>Shen</last></author>
      <pages>1045–1056</pages>
      <abstract>Recently, more and more data have been generated in the online world, filled with <a href="https://en.wikipedia.org/wiki/Profanity">offensive language</a> such as <a href="https://en.wikipedia.org/wiki/Threat">threats</a>, <a href="https://en.wikipedia.org/wiki/Profanity">swear words</a> or straightforward insults. It is disgraceful for a progressive society, and then the question arises on how language resources and technologies can cope with this challenge. However, previous work only analyzes the problem as a whole but fails to detect particular types of offensive content in a more fine-grained way, mainly because of the lack of annotated data. In this work, we present a densely annotated data-set COLA</abstract>
      <url hash="479b95bc">2020.ccl-1.97</url>
      <language>eng</language>
      <bibkey>tang-shen-2020-categorizing</bibkey>
    </paper>
    <paper id="98">
      <title>LiveQA : A Question Answering Dataset over Sports Live<fixed-case>L</fixed-case>ive<fixed-case>QA</fixed-case>: A Question Answering Dataset over Sports Live</title>
      <author><first>Liu</first><last>Qianying</last></author>
      <author><first>Jiang</first><last>Sicong</last></author>
      <author><first>Wang</first><last>Yizhong</last></author>
      <author><first>Li</first><last>Sujian</last></author>
      <pages>1057–1067</pages>
      <abstract>In this paper, we introduce LiveQA, a new question answering dataset constructed from play-by-play live broadcast. It contains 117k multiple-choice questions written by human commentators for over 1,670 NBA games, which are collected from the Chinese Hupu1 website. Derived from the characteristics of <a href="https://en.wikipedia.org/wiki/Sports_game">sports games</a>, LiveQA can potentially test the reasoning ability across timeline-based live broadcasts, which is challenging compared to the existing <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a>. In LiveQA, the questions require understanding the <a href="https://en.wikipedia.org/wiki/Timeline">timeline</a>, tracking events or doing <a href="https://en.wikipedia.org/wiki/Computation">mathematical computations</a>. Our preliminary experiments show that the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> introduces a challenging problem for <a href="https://en.wikipedia.org/wiki/Question_answering">question answering models</a>, and a strong baseline model only achieves the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 53.1 % and can not beat the dominant option rule. We release the code and data of this paper for future research.</abstract>
      <url hash="b9bbb95e">2020.ccl-1.98</url>
      <language>eng</language>
      <bibkey>qianying-etal-2020-liveqa</bibkey>
      <pwccode url="https://github.com/PKU-TANGENT/LiveQA" additional="true">PKU-TANGENT/LiveQA</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/liveqa">LiveQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/cbt">CBT</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ms-marco">MS MARCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/race">RACE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="102">
      <title>CAN-GRU : a Hierarchical Model for Emotion Recognition in Dialogue<fixed-case>CAN</fixed-case>-<fixed-case>GRU</fixed-case>: a Hierarchical Model for Emotion Recognition in Dialogue</title>
      <author><first>Ting</first><last>Jiang</last></author>
      <author><first>Bing</first><last>Xu</last></author>
      <author><first>Tiejun</first><last>Zhao</last></author>
      <author><first>Sheng</first><last>Li</last></author>
      <pages>1101–1111</pages>
      <abstract>Emotion recognition in dialogue systems has gained attention in the field of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> recent years, because it can be applied in <a href="https://en.wikipedia.org/wiki/Opinion_mining">opinion mining</a> from public conversational data on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. In this paper, we propose a <a href="https://en.wikipedia.org/wiki/Hierarchical_model">hierarchical model</a> to recognize <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a> in the <a href="https://en.wikipedia.org/wiki/Dialogue">dialogue</a>. In the first layer, in order to extract textual features of utterances, we propose a convolutional self-attention network(CAN). Convolution is used to capture <a href="https://en.wikipedia.org/wiki/N-gram">n-gram information</a> and attention mechanism is used to obtain the relevant semantic information among words in the utterance. In the second layer, a GRU-based network helps to capture <a href="https://en.wikipedia.org/wiki/Context_(language_use)">contextual information</a> in the conversation. Furthermore, we discuss the effects of unidirectional and bidirectional networks. We conduct experiments on Friends dataset and EmotionPush dataset. The results show that our proposed model(CAN-GRU) and its variants achieve better performance than <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baselines</a>.</abstract>
      <url hash="1cf91179">2020.ccl-1.102</url>
      <language>eng</language>
      <bibkey>jiang-etal-2020-gru</bibkey>
    </paper>
    <paper id="103">
      <title>A Joint Model for Aspect-Category Sentiment Analysis with Shared Sentiment Prediction Layer</title>
      <author><first>Yuncong</first><last>Li</last></author>
      <author><first>Zhe</first><last>Yang</last></author>
      <author><first>Cunxiang</first><last>Yin</last></author>
      <author><first>Xu</first><last>Pan</last></author>
      <author><first>Lunan</first><last>Cui</last></author>
      <author><first>Qiang</first><last>Huang</last></author>
      <author><first>Ting</first><last>Wei</last></author>
      <pages>1112–1121</pages>
      <abstract>Aspect-category sentiment analysis (ACSA) aims to predict the <a href="https://en.wikipedia.org/wiki/Aspect_(grammar)">aspect categories</a> mentioned in texts and their corresponding <a href="https://en.wikipedia.org/wiki/Sentimentality">sentiment polarities</a>. Some joint models have been proposed to address this task. Given a text, these joint models detect all the <a href="https://en.wikipedia.org/wiki/Grammatical_aspect">aspect categories</a> mentioned in the text and predict the <a href="https://en.wikipedia.org/wiki/Sentimentality">sentiment polarities</a> toward them at once. Although these joint models obtain promising performances, they train separate parameters for each aspect category and therefore suffer from data deficiency of some aspect categories. To solve this problem, we propose a novel joint model which contains a shared sentiment prediction layer. The shared sentiment prediction layer transfers <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment knowledge</a> between aspect categories and alleviates the problem caused by data deficiency. Experiments conducted on SemEval-2016 Datasets demonstrate the effectiveness of our <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a>.</abstract>
      <url hash="b76189da">2020.ccl-1.103</url>
      <language>eng</language>
      <bibkey>li-etal-2020-joint-model</bibkey>
    </paper>
    <paper id="106">
      <title>Clickbait Detection with Style-aware Title Modeling and Co-attention</title>
      <author><first>Chuhan</first><last>Wu</last></author>
      <author><first>Fangzhao</first><last>Wu</last></author>
      <author><first>Tao</first><last>Qi</last></author>
      <author><first>Yongfeng</first><last>Huang</last></author>
      <pages>1143–1154</pages>
      <abstract>Clickbait is a form of <a href="https://en.wikipedia.org/wiki/Web_content">web content</a> designed to attract attention and entice users to click on specific hyperlinks. The detection of clickbaits is an important task for online platforms to improve the quality of web content and the satisfaction of users. Clickbait detection is typically formed as a binary classification task based on the title and body of a webpage, and existing methods are mainly based on the content of title and the relevance between title and body. However, these methods ignore the stylistic patterns of titles, which can provide important clues on identifying <a href="https://en.wikipedia.org/wiki/Clickbait">clickbaits</a>. In addition, they do not consider the interactions between the contexts within title and body, which are very important for measuring their <a href="https://en.wikipedia.org/wiki/Relevance">relevance</a> for clickbait detection. In this paper, we propose a clickbait detection approach with style-aware title modeling and co-attention. Specifically, we use Transformers to learn content representations of title and body, and respectively compute two content-based clickbait scores for title and body based on their <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">representations</a>. In addition, we propose to use a character-level Transformer to learn a style-aware title representation by capturing the stylistic patterns of title, and we compute a title stylistic score based on this representation. Besides, we propose to use a co-attention network to model the relatedness between the contexts within title and body, and further enhance their representations by encoding the interaction information. We compute a title-body matching score based on the representations of title and body enhanced by their interactions. The final clickbait score is predicted by a weighted summation of the aforementioned four kinds of scores.</abstract>
      <url hash="66e0883f">2020.ccl-1.106</url>
      <language>eng</language>
      <bibkey>wu-etal-2020-clickbait</bibkey>
    </paper>
    </volume>
</collection>