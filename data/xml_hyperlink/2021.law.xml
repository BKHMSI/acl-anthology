<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.law">
  <volume id="1" ingest-date="2021-10-28">
    <meta>
      <booktitle>Proceedings of The Joint 15th Linguistic Annotation Workshop (LAW) and 3rd Designing Meaning Representations (DMR) Workshop</booktitle>
      <editor><first>Claire</first><last>Bonial</last></editor>
      <editor><first>Nianwen</first><last>Xue</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Punta Cana, Dominican Republic</address>
      <month>November</month>
      <year>2021</year>
    </meta>
    <frontmatter>
      <url hash="45004721">2021.law-1.0</url>
      <bibkey>law-2021-joint</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Representing Implicit Positive Meaning of Negated Statements in AMR<fixed-case>AMR</fixed-case></title>
      <author><first>Katharina</first><last>Stein</last></author>
      <author><first>Lucia</first><last>Donatelli</last></author>
      <pages>23–35</pages>
      <abstract>Abstract Meaning Representation (AMR) has become popular for representing the meaning of natural language in <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph structures</a>. However, AMR does not represent scope information, posing a problem for its overall expressivity and specifically for drawing inferences from negated statements. This is the case with so-called positive interpretations of negated statements, in which implicit positive meaning is identified by inferring the opposite of the negation’s focus. In this work, we investigate how potential positive interpretations (PPIs) can be represented in AMR. We propose a logically motivated AMR structure for PPIs that makes the focus of negation explicit and sketch an initial proposal for a systematic methodology to generate this more expressive structure.</abstract>
      <url hash="375da95b">2021.law-1.3</url>
      <bibkey>stein-donatelli-2021-representing</bibkey>
      <doi>10.18653/v1/2021.law-1.3</doi>
    </paper>
    <paper id="5">
      <title>Can predicate-argument relationships be extracted from UD trees?<fixed-case>UD</fixed-case> trees?</title>
      <author><first>Adam</first><last>Ek</last></author>
      <author><first>Jean-Philippe</first><last>Bernardy</last></author>
      <author><first>Stergios</first><last>Chatzikyriakidis</last></author>
      <pages>46–55</pages>
      <abstract>In this paper we investigate the possibility of extracting predicate-argument relations from UD trees (and enhanced UD graphs). Con- cretely, we apply UD parsers on an En- glish question answering / semantic-role label- ing data set (FitzGerald et al., 2018) and check if the annotations reflect the relations in the resulting parse trees, using a small number of rules to extract this information. We find that 79.1 % of the <a href="https://en.wikipedia.org/wiki/Argument_of_a_function">argument-predicate pairs</a> can be found in this way, on the basis of Ud- ify (Kondratyuk and Straka, 2019). Error anal- ysis reveals that half of the error cases are at- tributable to shortcomings in the dataset. The remaining errors are mostly due to predicate- argument relations not being extractible algo- rithmically from the UD trees (requiring se- mantic reasoning to be resolved). The <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> itself is only responsible for a small portion of errors. Our analysis suggests a number of improvements to the UD annotation schema : we propose to enhance the <a href="https://en.wikipedia.org/wiki/Database_schema">schema</a> in four ways, in order to capture argument-predicate relations. Additionally, we propose improve- ments regarding <a href="https://en.wikipedia.org/wiki/Data_collection">data collection</a> for question answering / semantic-role labeling data.</abstract>
      <url hash="37166656">2021.law-1.5</url>
      <bibkey>ek-etal-2021-predicate</bibkey>
      <doi>10.18653/v1/2021.law-1.5</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/qa-srl">QA-SRL</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="6">
      <title>Classifying Divergences in Cross-lingual AMR Pairs<fixed-case>AMR</fixed-case> Pairs</title>
      <author><first>Shira</first><last>Wein</last></author>
      <author><first>Nathan</first><last>Schneider</last></author>
      <pages>56–65</pages>
      <abstract>Translation divergences are varied and widespread, challenging approaches that rely on <a href="https://en.wikipedia.org/wiki/Parallel_text">parallel text</a>. To annotate translation divergences, we propose a schema grounded in the Abstract Meaning Representation (AMR), a sentence-level semantic framework instantiated for a number of languages. By comparing parallel AMR graphs, we can identify specific points of divergence. Each <a href="https://en.wikipedia.org/wiki/Divergence">divergence</a> is labeled with both a type and a cause. We release a small corpus of annotated English-Spanish data, and analyze the annotations in our <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>.</abstract>
      <url hash="375d34f8">2021.law-1.6</url>
      <bibkey>wein-schneider-2021-classifying</bibkey>
      <doi>10.18653/v1/2021.law-1.6</doi>
      <pwccode url="https://github.com/shirawein/spanish-english-amr-corpus" additional="false">shirawein/spanish-english-amr-corpus</pwccode>
    </paper>
    <paper id="10">
      <title>Subcategorizing Adverbials in Universal Conceptual Cognitive Annotation<fixed-case>U</fixed-case>niversal <fixed-case>C</fixed-case>onceptual <fixed-case>C</fixed-case>ognitive <fixed-case>A</fixed-case>nnotation</title>
      <author><first>Zhuxin</first><last>Wang</last></author>
      <author><first>Jakob</first><last>Prange</last></author>
      <author><first>Nathan</first><last>Schneider</last></author>
      <pages>96–105</pages>
      <abstract>Universal Conceptual Cognitive Annotation (UCCA) is a semantic annotation scheme that organizes texts into coarse predicate-argument structure, offering broad coverage of semantic phenomena. At the same time, there is still need for a finer-grained treatment of many of the <a href="https://en.wikipedia.org/wiki/Categorization">categories</a>. The Adverbial category is of special interest, as it covers a wide range of fundamentally different meanings such as <a href="https://en.wikipedia.org/wiki/Affirmation_and_negation">negation</a>, <a href="https://en.wikipedia.org/wiki/Causality">causation</a>, <a href="https://en.wikipedia.org/wiki/Grammatical_aspect">aspect</a>, and event quantification. In this paper we introduce a refinement annotation scheme for UCCA’s Adverbial category, showing that UCCA Adverbials can indeed be subcategorized into at least 7 semantic types, and doing so can help clarify and disambiguate the otherwise coarse-grained labels. We provide a preliminary set of annotation guidelines, as well as pilot annotation experiments with high inter-annotator agreement, confirming the validity of the scheme.</abstract>
      <url hash="b9971d4a">2021.law-1.10</url>
      <bibkey>wang-etal-2021-subcategorizing</bibkey>
      <doi>10.18653/v1/2021.law-1.10</doi>
    </paper>
    <paper id="18">
      <title>WikiGUM : Exhaustive Entity Linking for <a href="https://en.wikipedia.org/wiki/Wikification">Wikification</a> in 12 Genres<fixed-case>W</fixed-case>iki<fixed-case>GUM</fixed-case>: Exhaustive Entity Linking for Wikification in 12 Genres</title>
      <author><first>Jessica</first><last>Lin</last></author>
      <author><first>Amir</first><last>Zeldes</last></author>
      <pages>170–175</pages>
      <abstract>Previous work on <a href="https://en.wikipedia.org/wiki/Entity_Linking">Entity Linking</a> has focused on resources targeting non-nested proper named entity mentions, often in data from <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a>, i.e. Wikification. In this paper, we present and evaluate WikiGUM, a fully wikified dataset, covering all mentions of named entities, including their non-named and pronominal mentions, as well as mentions nested within other mentions. The dataset covers a broad range of 12 written and spoken genres, most of which have not been included in Entity Linking efforts to date, leading to poor performance by a pretrained SOTA system in our evaluation. The availability of a variety of other annotations for the same data also enables further research on entities in context.</abstract>
      <url hash="a46c418a">2021.law-1.18</url>
      <bibkey>lin-zeldes-2021-wikigum</bibkey>
      <doi>10.18653/v1/2021.law-1.18</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/gum">GUM</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ipm-nel">IPM NEL</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/nne">NNE</pwcdataset>
    </paper>
  </volume>
</collection>