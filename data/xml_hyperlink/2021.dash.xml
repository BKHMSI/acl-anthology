<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.dash">
  <volume id="1" ingest-date="2021-05-24">
    <meta>
      <booktitle>Proceedings of the Second Workshop on Data Science with Human in the Loop: Language Advances</booktitle>
      <editor><first>Eduard</first><last>Dragut</last></editor>
      <editor><first>Yunyao</first><last>Li</last></editor>
      <editor><first>Lucian</first><last>Popa</last></editor>
      <editor><first>Slobodan</first><last>Vucetic</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>June</month>
      <year>2021</year>
      <url hash="85c83d62">2021.dash-1</url>
    </meta>
    <frontmatter>
      <url hash="0f20b02d">2021.dash-1.0</url>
      <bibkey>dash-2021-data</bibkey>
    </frontmatter>
    <paper id="3">
      <title>ViziTex : Interactive Visual Sense-Making of Text Corpora<fixed-case>V</fixed-case>izi<fixed-case>T</fixed-case>ex: Interactive Visual Sense-Making of Text Corpora</title>
      <author><first>Natraj</first><last>Raman</last></author>
      <author><first>Sameena</first><last>Shah</last></author>
      <author><first>Tucker</first><last>Balch</last></author>
      <author><first>Manuela</first><last>Veloso</last></author>
      <pages>16–23</pages>
      <abstract>Information visualization is critical to <a href="https://en.wikipedia.org/wiki/Analytical_reasoning">analytical reasoning</a> and <a href="https://en.wikipedia.org/wiki/Epistemology">knowledge discovery</a>. We present an interactive studio that integrates perceptive visualization techniques with powerful text analytics algorithms to assist humans in sense-making of large complex text corpora. The novel visual representations introduced here encode the features delivered by modern text mining models using advanced metaphors such as <a href="https://en.wikipedia.org/wiki/Hypergraph">hypergraphs</a>, nested topologies and <a href="https://en.wikipedia.org/wiki/Tessellation">tessellated planes</a>. They enhance human-computer interaction experience for various tasks such as summarization, exploration, organization and labeling of documents. We demonstrate the ability of the visuals to surface the structure, relations and concepts from documents across different domains.</abstract>
      <url hash="0f1aede9">2021.dash-1.3</url>
      <doi>10.18653/v1/2021.dash-1.3</doi>
      <bibkey>raman-etal-2021-vizitex</bibkey>
    </paper>
    <paper id="7">
      <title>Bridging Multi-disciplinary Collaboration Challenges in ML Development via Domain Knowledge Elicitation<fixed-case>ML</fixed-case> Development via Domain Knowledge Elicitation</title>
      <author><first>Soya</first><last>Park</last></author>
      <pages>44–46</pages>
      <abstract>Building a <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning model</a> in a sophisticated domain is a time-consuming process, partially due to the steep learning curve of <a href="https://en.wikipedia.org/wiki/Domain_knowledge">domain knowledge</a> for <a href="https://en.wikipedia.org/wiki/Data_science">data scientists</a>. We introduce Ziva, an interface for supporting <a href="https://en.wikipedia.org/wiki/Domain_knowledge">domain knowledge</a> from domain experts to data scientists in two ways : (1) a concept creation interface where domain experts extract important concept of the domain and (2) five kinds of justification elicitation interfaces that solicit elicitation how the domain concept are expressed in data instances.</abstract>
      <url hash="e64d6360">2021.dash-1.7</url>
      <doi>10.18653/v1/2021.dash-1.7</doi>
      <bibkey>park-2021-bridging</bibkey>
    </paper>
    <paper id="9">
      <title>Towards integrated, interactive, and extensible text data analytics with Leam</title>
      <author><first>Peter</first><last>Griggs</last></author>
      <author><first>Cagatay</first><last>Demiralp</last></author>
      <author><first>Sajjadur</first><last>Rahman</last></author>
      <pages>52–58</pages>
      <abstract>From <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> to <a href="https://en.wikipedia.org/wiki/Review">product reviews</a>, <a href="https://en.wikipedia.org/wiki/Plain_text">text</a> is ubiquitous on the web and often contains valuable information for both enterprises and consumers. However, the online text is generally noisy and incomplete, requiring users to process and analyze the data to extract insights. While there are systems effective for different stages of <a href="https://en.wikipedia.org/wiki/Text_mining">text analysis</a>, users lack extensible platforms to support interactive text analysis workflows end-to-end. To facilitate integrated text analytics, we introduce LEAM, which aims at combining the strengths of <a href="https://en.wikipedia.org/wiki/Spreadsheet">spreadsheets</a>, <a href="https://en.wikipedia.org/wiki/Computational_notebook">computational notebooks</a>, and interactive visualizations. LEAM supports interactive analysis via GUI-based interactions and provides a declarative specification language, implemented based on a visual text algebra, to enable user-guided analysis. We evaluate LEAM through two <a href="https://en.wikipedia.org/wiki/Case_study">case studies</a> using two popular Kaggle text analytics workflows to understand the strengths and weaknesses of the <a href="https://en.wikipedia.org/wiki/System">system</a>.</abstract>
      <url hash="17014bf7">2021.dash-1.9</url>
      <doi>10.18653/v1/2021.dash-1.9</doi>
      <bibkey>griggs-etal-2021-towards</bibkey>
    </paper>
    <paper id="10">
      <title>Data Cleaning Tools for Token Classification Tasks</title>
      <author><first>Karthik</first><last>Muthuraman</last></author>
      <author><first>Frederick</first><last>Reiss</last></author>
      <author><first>Hong</first><last>Xu</last></author>
      <author><first>Bryan</first><last>Cutler</last></author>
      <author><first>Zachary</first><last>Eichenberger</last></author>
      <pages>59–61</pages>
      <abstract>Human-in-the-loop systems for cleaning NLP training data rely on automated sieves to isolate potentially-incorrect labels for manual review. We have developed a novel technique for flagging potentially-incorrect labels with high sensitivity in named entity recognition corpora. We incorporated our <a href="https://en.wikipedia.org/wiki/Sieve_theory">sieve</a> into an end-to-end system for cleaning NLP corpora, implemented as a modular collection of Jupyter notebooks built on extensions to the Pandas DataFrame library. We used this system to identify incorrect labels in the CoNLL-2003 corpus for English-language named entity recognition (NER), one of the most influential corpora for NER model research. Unlike previous work that only looked at a subset of the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>’s validation fold, our automated sieve enabled us to examine the entire corpus in depth. Across the entire CoNLL-2003 corpus, we identified over 1300 incorrect labels (out of 35089 in the corpus). We have published our corrections, along with the code we used in our experiments. We are developing a repeatable version of the process we used on the CoNLL-2003 corpus as an open-source library.</abstract>
      <url hash="3b9c164d">2021.dash-1.10</url>
      <doi>10.18653/v1/2021.dash-1.10</doi>
      <bibkey>muthuraman-etal-2021-data</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
    </paper>
    <paper id="11">
      <title>Building Low-Resource NER Models Using Non-Speaker Annotations<fixed-case>NER</fixed-case> Models Using Non-Speaker Annotations</title>
      <author><first>Tatiana</first><last>Tsygankova</last></author>
      <author><first>Francesca</first><last>Marini</last></author>
      <author><first>Stephen</first><last>Mayhew</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>62–69</pages>
      <abstract>In low-resource natural language processing (NLP), the key problems are a lack of target language training data, and a lack of native speakers to create it. Cross-lingual methods have had notable success in addressing these concerns, but in certain common circumstances, such as insufficient pre-training corpora or languages far from the source language, their performance suffers. In this work we propose a complementary approach to building low-resource Named Entity Recognition (NER) models using non-speaker (NS) annotations, provided by annotators with no prior experience in the target language. We recruit 30 participants in a carefully controlled annotation experiment with <a href="https://en.wikipedia.org/wiki/Indonesian_language">Indonesian</a>, <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a>, and <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a>. We show that use of NS annotators produces results that are consistently on par or better than cross-lingual methods built on modern contextual representations, and have the potential to outperform with additional effort. We conclude with observations of common annotation patterns and recommended implementation practices, and motivate how NS annotations can be used in addition to prior methods for improved performance.</abstract>
      <url hash="b6fee22a">2021.dash-1.11</url>
      <doi>10.18653/v1/2021.dash-1.11</doi>
      <bibkey>tsygankova-etal-2021-building</bibkey>
    </paper>
    <paper id="13">
      <title>CrossCheck : Rapid, Reproducible, and Interpretable Model Evaluation<fixed-case>C</fixed-case>ross<fixed-case>C</fixed-case>heck: Rapid, Reproducible, and Interpretable Model Evaluation</title>
      <author><first>Dustin</first><last>Arendt</last></author>
      <author><first>Zhuanyi</first><last>Shaw</last></author>
      <author><first>Prasha</first><last>Shrestha</last></author>
      <author><first>Ellyn</first><last>Ayton</last></author>
      <author><first>Maria</first><last>Glenski</last></author>
      <author><first>Svitlana</first><last>Volkova</last></author>
      <pages>79–85</pages>
      <abstract>Evaluation beyond aggregate performance metrics, e.g. F1-score, is crucial to both establish an appropriate level of trust in <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning models</a> and identify avenues for future <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> improvements. In this paper we demonstrate CrossCheck, an interactive capability for rapid cross-model comparison and reproducible error analysis. We describe the tool, discuss design and implementation details, and present three NLP use cases   named entity recognition, <a href="https://en.wikipedia.org/wiki/Reading_comprehension">reading comprehension</a>, and clickbait detection that show the benefits of using the tool for model evaluation. CrossCheck enables users to make informed decisions when choosing between multiple models, identify when the models are correct and for which examples, investigate whether the models are making the same mistakes as humans, evaluate models’ generalizability and highlight models’ limitations, strengths and weaknesses. Furthermore, CrossCheck is implemented as a <a href="https://en.wikipedia.org/wiki/Jupyter">Jupyter widget</a>, which allows for rapid and convenient integration into existing model development workflows.</abstract>
      <url hash="b2a2930a">2021.dash-1.13</url>
      <doi>10.18653/v1/2021.dash-1.13</doi>
      <bibkey>arendt-etal-2021-crosscheck</bibkey>
      <pwccode url="https://github.com/pnnl/crosscheck" additional="false">pnnl/crosscheck</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="14">
      <title>TopGuNN : Fast NLP Training Data Augmentation using Large Corpora<fixed-case>T</fixed-case>op<fixed-case>G</fixed-case>u<fixed-case>NN</fixed-case>: Fast <fixed-case>NLP</fixed-case> Training Data Augmentation using Large Corpora</title>
      <author><first>Rebecca</first><last>Iglesias-Flores</last></author>
      <author><first>Megha</first><last>Mishra</last></author>
      <author><first>Ajay</first><last>Patel</last></author>
      <author><first>Akanksha</first><last>Malhotra</last></author>
      <author><first>Reno</first><last>Kriz</last></author>
      <author><first>Martha</first><last>Palmer</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <pages>86–101</pages>
      <abstract>Acquiring training data for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing systems</a> can be expensive and time-consuming. Given a few training examples crafted by experts, large corpora can be mined for thousands of semantically similar examples that provide useful variability to improve model generalization. We present TopGuNN, a fast contextualized k-NN retrieval system that can efficiently index and search over contextual embeddings generated from large corpora. TopGuNN is demonstrated for a training data augmentation use case over the Gigaword corpus. Using approximate k-NN and an efficient <a href="https://en.wikipedia.org/wiki/Computer_architecture">architecture</a>, TopGuNN performs queries over an <a href="https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms">embedding space</a> of 4.63 TB (approximately 1.5B embeddings) in less than a day.</abstract>
      <url hash="5da64775">2021.dash-1.14</url>
      <doi>10.18653/v1/2021.dash-1.14</doi>
      <bibkey>iglesias-flores-etal-2021-topgunn</bibkey>
      <pwccode url="https://github.com/penn-topgunn/topgunn" additional="false">penn-topgunn/topgunn</pwccode>
    </paper>
    <paper id="16">
      <title>A <a href="https://en.wikipedia.org/wiki/Computational_model">Computational Model</a> for Interactive Transcription</title>
      <author><first>William</first><last>Lane</last></author>
      <author><first>Mat</first><last>Bettinson</last></author>
      <author><first>Steven</first><last>Bird</last></author>
      <pages>105–111</pages>
      <abstract>Transcribing low resource languages can be challenging in the absence of a good lexicon and trained transcribers. Accordingly, we seek a way to enable interactive transcription whereby the machine amplifies human efforts. This paper presents a <a href="https://en.wikipedia.org/wiki/Data_model">data model</a> and a <a href="https://en.wikipedia.org/wiki/Systems_architecture">system architecture</a> for interactive transcription, supporting multiple modes of <a href="https://en.wikipedia.org/wiki/Interactivity">interactivity</a>, increasing the likelihood of finding tasks that engage local participation in language work. The approach also supports other <a href="https://en.wikipedia.org/wiki/Application_software">applications</a> which are useful in our context, including spoken document retrieval and <a href="https://en.wikipedia.org/wiki/Language_acquisition">language learning</a>.</abstract>
      <url hash="f740e892">2021.dash-1.16</url>
      <doi>10.18653/v1/2021.dash-1.16</doi>
      <bibkey>lane-etal-2021-computational</bibkey>
    </paper>
  </volume>
</collection>