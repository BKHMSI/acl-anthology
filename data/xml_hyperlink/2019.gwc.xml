<?xml version='1.0' encoding='utf-8'?>
<collection id="2019.gwc">
  <volume id="1" ingest-date="2021-02-07">
    <meta>
      <booktitle>Proceedings of the 10th Global Wordnet Conference</booktitle>
      <editor><first>Piek</first><last>Vossen</last></editor>
      <editor><first>Christiane</first><last>Fellbaum</last></editor>
      <publisher>Global Wordnet Association</publisher>
      <address>Wroclaw, Poland</address>
      <month>July</month>
      <year>2019</year>
      <url hash="b9a36b9f">2019.gwc-1</url>
    </meta>
    <frontmatter>
      <url hash="15aafacc">2019.gwc-1.0</url>
      <bibkey>gwc-2019-global</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Making Sense of schema.org with <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a><fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et</title>
      <author><first>Csaba</first><last>Veres</last></author>
      <pages>1–9</pages>
      <abstract>The <a href="https://en.wikipedia.org/wiki/Schema.org">schema.org initiative</a> was designed to introduce machine readable metadata into the <a href="https://en.wikipedia.org/wiki/World_Wide_Web">World Wide Web</a>. This paper investigates conceptual biases in the schema through a mapping exercise between schema.org types and WordNet synsets. We create a <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">mapping ontology</a> which establishes the relationship between schema metadata types and the corresponding everyday concepts. This in turn can be used to enhance metadata annotation to include a more complete description of knowledge on the Web of data.</abstract>
      <url hash="3b98056b">2019.gwc-1.1</url>
      <bibkey>veres-2019-making</bibkey>
    </paper>
    <paper id="4">
      <title>Including Swiss Standard German in GermaNet<fixed-case>S</fixed-case>wiss Standard <fixed-case>G</fixed-case>erman in <fixed-case>G</fixed-case>erma<fixed-case>N</fixed-case>et</title>
      <author><first>Eva</first><last>Huber</last></author>
      <author><first>Erhard</first><last>Hinrichs</last></author>
      <pages>24–32</pages>
      <abstract>GermaNet (Henrich and Hinrichs, 2010 ; Hamp and Feldweg, 1997) is a comprehensive wordnet of Standard German spoken in the Federal Republic of Germany. The GermaNet team aims at modelling the basic vocabulary of the <a href="https://en.wikipedia.org/wiki/Language">language</a>. German is an official language or a minority language in many countries. It is an official language in <a href="https://en.wikipedia.org/wiki/Austria">Austria</a>, <a href="https://en.wikipedia.org/wiki/Germany">Germany</a> and <a href="https://en.wikipedia.org/wiki/Switzerland">Switzerland</a>, each with its own codified standard variety (Auer, 2014, p. 21), and also in <a href="https://en.wikipedia.org/wiki/Belgium">Belgium</a>, Liechtenstein, and Luxemburg. German is recognized as a minority language in thirteen additional countries, including <a href="https://en.wikipedia.org/wiki/Brazil">Brasil</a>, <a href="https://en.wikipedia.org/wiki/Italy">Italy</a>, <a href="https://en.wikipedia.org/wiki/Poland">Poland</a>, and <a href="https://en.wikipedia.org/wiki/Russia">Russia</a>. However, the different standard varieties of <a href="https://en.wikipedia.org/wiki/German_language">German</a> are currently not represented in <a href="https://en.wikipedia.org/wiki/GermaNet">GermaNet</a>. With this project, we make a start on changing this by including one <a href="https://en.wikipedia.org/wiki/Variety_(linguistics)">variety</a>, namely <a href="https://en.wikipedia.org/wiki/Swiss_Standard_German">Swiss Standard German</a>, into <a href="https://en.wikipedia.org/wiki/GermaNet">GermaNet</a>. This shall give a more inclusive perspective on the <a href="https://en.wikipedia.org/wiki/German_language">German language</a>. We will argue that Swiss Standard German words, Helvetisms, are best included into the already existing wordnet GermaNet, rather than creating them as a separate wordnet.</abstract>
      <url hash="3bce8e57">2019.gwc-1.4</url>
      <bibkey>huber-hinrichs-2019-including</bibkey>
    </paper>
    <paper id="5">
      <title>Danish in Wikidata lexemes<fixed-case>D</fixed-case>anish in <fixed-case>W</fixed-case>ikidata lexemes</title>
      <author><first>Finn Årup</first><last>Nielsen</last></author>
      <pages>33–38</pages>
      <abstract>Wikidata introduced support for lexicographic data in 2018. Here we describe the lexicographic part of <a href="https://en.wikipedia.org/wiki/Wikidata">Wikidata</a> as well as experiences with setting up <a href="https://en.wikipedia.org/wiki/Lexeme">lexemes</a> for the <a href="https://en.wikipedia.org/wiki/Danish_language">Danish language</a>. We note various possible annotations for <a href="https://en.wikipedia.org/wiki/Lexeme">lexemes</a> as well as discuss various choices made.</abstract>
      <url hash="f6a92f6d">2019.gwc-1.5</url>
      <bibkey>nielsen-2019-danish</bibkey>
    </paper>
    <paper id="12">
      <title>Towards interpretable, data-derived distributional meaning representations for <a href="https://en.wikipedia.org/wiki/Reason">reasoning</a> : A dataset of properties and concepts</title>
      <author><first>Pia</first><last>Sommerauer</last></author>
      <author><first>Antske</first><last>Fokkens</last></author>
      <author><first>Piek</first><last>Vossen</last></author>
      <pages>85–98</pages>
      <abstract>This paper proposes a <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> for investigating which types of <a href="https://en.wikipedia.org/wiki/Semantic_property">semantic properties</a> are represented by <a href="https://en.wikipedia.org/wiki/Distribution_(mathematics)">distributional data</a>. The core of our <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> consists of relations between concepts and properties. We provide hypotheses on which <a href="https://en.wikipedia.org/wiki/Property_(philosophy)">properties</a> are reflected in <a href="https://en.wikipedia.org/wiki/Distribution_(mathematics)">distributional data</a> or not based on the type of relation. We outline strategies for creating a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> of positive and negative examples for various semantic properties, which can not easily be separated on the basis of general similarity (e.g. fly : seagull, penguin). This way, a <a href="https://en.wikipedia.org/wiki/Distribution_(mathematics)">distributional model</a> can only distinguish between positive and negative examples through evidence for a target property. Once completed, this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> can be used to test our hypotheses and work towards data-derived interpretable representations.</abstract>
      <url hash="891ae9b6">2019.gwc-1.12</url>
      <bibkey>sommerauer-etal-2019-towards</bibkey>
    </paper>
    <paper id="13">
      <title>Connections between the semantic layer of Walenty valency dictionary and <a href="https://en.wikipedia.org/wiki/PlWordNet">PlWordNet</a><fixed-case>P</fixed-case>l<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et</title>
      <author><first>Elzbieta</first><last>Hajnicz</last></author>
      <author><first>Tomasz</first><last>Bartosiak</last></author>
      <pages>99–107</pages>
      <abstract>In this paper we discuss how <a href="https://en.wikipedia.org/wiki/Walenty">Walenty</a> is using PLWORDNET to represent <a href="https://en.wikipedia.org/wiki/Semantic_Web">semantic information</a>. We decided to use PLWORDNET lexical units and synsets to describe both the predicate meaning and the semantic fields of its arguments. The original design decision required some further refinement caused by the structure of PLWORDNET and complex relations between arguments.</abstract>
      <url hash="187c4ba0">2019.gwc-1.13</url>
      <bibkey>hajnicz-bartosiak-2019-connections</bibkey>
    </paper>
    <paper id="14">
      <title>Sense Vocabulary Compression through the Semantic Knowledge of <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a> for Neural Word Sense Disambiguation<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et for Neural Word Sense Disambiguation</title>
      <author><first>Loïc</first><last>Vial</last></author>
      <author><first>Benjamin</first><last>Lecouteux</last></author>
      <author><first>Didier</first><last>Schwab</last></author>
      <pages>108–117</pages>
      <abstract>In this article, we tackle the issue of the limited quantity of manually sense annotated corpora for the task of <a href="https://en.wikipedia.org/wiki/Word_sense_disambiguation">word sense disambiguation</a>, by exploiting the semantic relationships between senses such as <a href="https://en.wikipedia.org/wiki/Synonym">synonymy</a>, <a href="https://en.wikipedia.org/wiki/Hypernymy">hypernymy</a> and <a href="https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy">hyponymy</a>, in order to compress the sense vocabulary of <a href="https://en.wikipedia.org/wiki/Princeton_WordNet">Princeton WordNet</a>, and thus reduce the number of different sense tags that must be observed to disambiguate all words of the lexical database. We propose two different methods that greatly reduce the size of neural WSD models, with the benefit of improving their coverage without additional <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training data</a>, and without impacting their <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a>. In addition to our methods, we present a WSD system which relies on pre-trained BERT word vectors in order to achieve results that significantly outperforms the state of the art on all WSD evaluation tasks.</abstract>
      <url hash="7eb838b3">2019.gwc-1.14</url>
      <bibkey>vial-etal-2019-sense</bibkey>
      <pwccode url="https://github.com/getalp/disambiguate" additional="true">getalp/disambiguate</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2013">SemEval 2013</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/word-sense-disambiguation-a-unified">Word Sense Disambiguation: a Unified Evaluation Framework and Empirical Comparison</pwcdataset>
    </paper>
    <paper id="16">
      <title>Merging DanNet with Princeton Wordnet<fixed-case>D</fixed-case>an<fixed-case>N</fixed-case>et with <fixed-case>P</fixed-case>rinceton <fixed-case>W</fixed-case>ordnet</title>
      <author><first>Bolette Sandford</first><last>Pedersen</last></author>
      <author><first>Sanni</first><last>Nimb</last></author>
      <author><first>Ida Rørmann</first><last>Olsen</last></author>
      <author><first>Sussi</first><last>Olsen</last></author>
      <pages>125–134</pages>
      <abstract>In this paper we describe the merge of the Danish wordnet, DanNet, with <a href="https://en.wikipedia.org/wiki/Princeton_Wordnet">Princeton Wordnet</a> applying a two-step approach. We first link from the <a href="https://en.wikipedia.org/wiki/English_language">English Princeton core</a> to <a href="https://en.wikipedia.org/wiki/Danish_language">Danish</a> (5,000 base concepts) and then proceed to linking the rest of the <a href="https://en.wikipedia.org/wiki/Danish_language">Danish vocabulary</a> to <a href="https://en.wikipedia.org/wiki/English_language">English</a>, thus going from <a href="https://en.wikipedia.org/wiki/Danish_language">Danish</a> to <a href="https://en.wikipedia.org/wiki/English_language">English</a>. Since the Danish wordnet is built bottom-up from Danish lexica and corpora, all taxonomies are monolingually based and thus not necessarily directly compatible with the coverage and structure of the Princeton WordNet. This fact proves to pose some challenges to the linking procedure since a considerable number of the links can not be realised via the preferred cross-language synonym link which implies a more or less precise correlation between the two concepts. Instead, a subpart of the links are realised through near synonym or hyponymy links to compensate for the fact that no precise translation can be found in the target resource. The tool WordnetLoom is currently used for manual linking but procedures for a more automatic procedure in future is discussed. We conclude that the two resources actually differ from each other quite more than expected, both vocabulary and structure-wise.</abstract>
      <url hash="52cc903c">2019.gwc-1.16</url>
      <bibkey>pedersen-etal-2019-merging</bibkey>
    </paper>
    <paper id="18">
      <title>Synthetic, yet natural : Properties of WordNet random walk corpora and the impact of rare words on embedding performance<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et random walk corpora and the impact of rare words on embedding performance</title>
      <author><first>Filip</first><last>Klubička</last></author>
      <author><first>Alfredo</first><last>Maldonado</last></author>
      <author><first>Abhijit</first><last>Mahalunkar</last></author>
      <author><first>John</first><last>Kelleher</last></author>
      <pages>140–150</pages>
      <abstract>Creating <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> that reflect semantic relationships encoded in lexical knowledge resources is an open challenge. One approach is to use a random walk over a <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graph</a> to generate a pseudo-corpus and use this <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> to train embeddings. However, the effect of the shape of the <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graph</a> on the generated pseudo-corpora, and on the resulting <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>, has not been studied. To explore this, we use <a href="https://en.wikipedia.org/wiki/WordNet">English WordNet</a>, constrained to the taxonomic (tree-like) portion of the <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph</a>, as a case study. We investigate the properties of the generated pseudo-corpora, and their impact on the resulting <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a>. We find that the distributions in the psuedo-corpora exhibit properties found in natural corpora, such as Zipf’s and Heaps’ law, and also observe that the proportion of rare words in a pseudo-corpus affects the performance of its embeddings on word similarity.</abstract>
      <url hash="664ac0d4">2019.gwc-1.18</url>
      <bibkey>klubicka-etal-2019-synthetic</bibkey>
    </paper>
    <paper id="20">
      <title>Visualising WordNet Embeddings : some preliminary results<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et Embeddings: some preliminary results</title>
      <author><first>Csaba</first><last>Veres</last></author>
      <pages>160–165</pages>
      <abstract>AutoExtend is a method for learning unambiguous vector embeddings for <a href="https://en.wikipedia.org/wiki/Word_sense">word senses</a>. We visualise these <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> with <a href="https://en.wikipedia.org/wiki/T-SNE">t-SNE</a>, which further compresses the vectors to the x, y plane. We show that the t-SNE co-ordinates can be used to reveal interesting semantic relations between word senses, and propose a new method that uses the simple x, y coordinates to compute semantic similarity. This can be used to propose new links and alterations to existing ones in <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a>. We plan to add this approach to the existing toolbox of methods in an attempt to understand learned semantic relations in <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>.</abstract>
      <url hash="6c821842">2019.gwc-1.20</url>
      <bibkey>veres-2019-visualising</bibkey>
    </paper>
    <paper id="22">
      <title>Evaluating the <a href="https://en.wikipedia.org/wiki/Wordnet">Wordnet</a> and CoRoLa-based Word Embedding Vectors for <a href="https://en.wikipedia.org/wiki/Romanian_language">Romanian</a> as Resources in the Task of Microworlds Lexicon Expansion<fixed-case>W</fixed-case>ordnet and <fixed-case>C</fixed-case>o<fixed-case>R</fixed-case>o<fixed-case>L</fixed-case>a-based Word Embedding Vectors for <fixed-case>R</fixed-case>omanian as Resources in the Task of Microworlds Lexicon Expansion</title>
      <author><first>Elena</first><last>Irimia</last></author>
      <author><first>Maria</first><last>Mitrofan</last></author>
      <author><first>Verginica</first><last>Mititelu</last></author>
      <pages>176–184</pages>
      <abstract>Within a larger frame of facilitating <a href="https://en.wikipedia.org/wiki/Human–robot_interaction">human-robot interaction</a>, we present here the creation of a <a href="https://en.wikipedia.org/wiki/Core_vocabulary">core vocabulary</a> to be learned by a robot. It is extracted from two tokenised and lemmatized scenarios pertaining to two imagined microworlds in which the robot is supposed to play an assistive role. We also evaluate two <a href="https://en.wikipedia.org/wiki/Resource_(computer_science)">resources</a> for their utility for expanding this <a href="https://en.wikipedia.org/wiki/Vocabulary">vocabulary</a> so as to better cope with the robot’s communication needs. The language under study is <a href="https://en.wikipedia.org/wiki/Romanian_language">Romanian</a> and the resources used are the <a href="https://en.wikipedia.org/wiki/Romanian_language">Romanian wordnet</a> and word embedding vectors extracted from the large representative corpus of contemporary Romanian, CoRoLa. The evaluation is made for two situations : one in which the words are not semantically disambiguated before expanding the lexicon, and another one in which they are disambiguated with senses from the Romanian wordnet. The appropriateness of each resource is discussed.</abstract>
      <url hash="9b9c07ac">2019.gwc-1.22</url>
      <bibkey>irimia-etal-2019-evaluating</bibkey>
    </paper>
    <paper id="24">
      <title>Thinking globally, acting locally   Progress in the African Wordnet Project<fixed-case>A</fixed-case>frican <fixed-case>W</fixed-case>ordnet Project</title>
      <author><first>Marissa</first><last>Griesel</last></author>
      <author><first>Sonja</first><last>Bosch</last></author>
      <author><first>Mampaka Lydia</first><last>Mojapelo</last></author>
      <pages>191–196</pages>
      <abstract>The African Wordnet Project (AWN) includes all nine indigenous South African languages, namely <a href="https://en.wikipedia.org/wiki/Zulu_language">isiZulu</a>, <a href="https://en.wikipedia.org/wiki/Xhosa_language">isiXhosa</a>, <a href="https://en.wikipedia.org/wiki/Tswana_language">Setswana</a>, Sesotho sa Leboa, Tshivenda, <a href="https://en.wikipedia.org/wiki/Sotho_language">Siswati</a>, <a href="https://en.wikipedia.org/wiki/Sotho_language">Sesotho</a>, <a href="https://en.wikipedia.org/wiki/Southern_Ndebele_language">isiNdebele</a> and <a href="https://en.wikipedia.org/wiki/Tsonga_language">Xitsonga</a>. The AWN currently includes 61 000 synsets as well as definitions and usage examples for a large part of the synsets. The project recently received extended funding from the South African Centre for Digital Language Resources (SADiLaR) and aims to update all aspects of the current resource, including the seed list used for new development, software tools used and mapping the AWN to the latest version of PWN 3.1. As with any resource development project, it is essential to also include phases of focused quality assurance and updating of the basis on which the resource is built. The <a href="https://en.wikipedia.org/wiki/Languages_of_Africa">African languages</a> remain under-resourced. This paper describes progress made in the development of the <a href="https://en.wikipedia.org/wiki/AWN">AWN</a> as well as recent technical improvements.</abstract>
      <url hash="3354369e">2019.gwc-1.24</url>
      <bibkey>griesel-etal-2019-thinking</bibkey>
    </paper>
    <paper id="25">
      <title>Commonsense Reasoning Using <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a> and SUMO : a Detailed Analysis<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et and <fixed-case>SUMO</fixed-case>: a Detailed Analysis</title>
      <author><first>Javier</first><last>Álvez</last></author>
      <author><first>Itziar</first><last>Gonzalez-Dios</last></author>
      <author><first>German</first><last>Rigau</last></author>
      <pages>197–205</pages>
      <abstract>We describe a detailed analysis of a sample of large benchmark of commonsense reasoning problems that has been automatically obtained from <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a>, SUMO and their mapping. The objective is to provide a better assessment of the quality of both the <a href="https://en.wikipedia.org/wiki/Benchmarking">benchmark</a> and the involved knowledge resources for advanced commonsense reasoning tasks. By means of this analysis, we are able to detect some knowledge misalignments, mapping errors and lack of knowledge and resources. Our final objective is the extraction of some guidelines towards a better exploitation of this commonsense knowledge framework by the improvement of the included resources.</abstract>
      <url hash="2665f7f4">2019.gwc-1.25</url>
      <bibkey>alvez-etal-2019-commonsense</bibkey>
    </paper>
    <paper id="26">
      <title>Building the Cantonese Wordnet<fixed-case>C</fixed-case>antonese <fixed-case>W</fixed-case>ordnet</title>
      <author><first>Joanna Ut-Seong</first><last>Sio</last></author>
      <author><first>Luis Morgado Da</first><last>Costa</last></author>
      <pages>206–215</pages>
      <abstract>This paper reports on the development of the Cantonese Wordnet, a new wordnet project based on <a href="https://en.wikipedia.org/wiki/Hong_Kong_Cantonese">Hong Kong Cantonese</a>. It is built using the expansion approach, leveraging on the existing Chinese Open Wordnet, and the Princeton Wordnet’s semantic hierarchy. The main goal of our project was to produce a high quality, human-curated resource   and this paper reports on the initial efforts and steady progress of our building method. It is our belief that the lexical data made available by this <a href="https://en.wikipedia.org/wiki/Wordnet">wordnet</a>, including Jyutping romanization, will be useful for a variety of future uses, including many language processing tasks and linguistic research on <a href="https://en.wikipedia.org/wiki/Cantonese">Cantonese</a> and its interactions with other <a href="https://en.wikipedia.org/wiki/Varieties_of_Chinese">Chinese dialects</a>.</abstract>
      <url hash="44dd4b0e">2019.gwc-1.26</url>
      <bibkey>sio-costa-2019-building</bibkey>
      <pwccode url="https://github.com/lmorgadodacosta/cantonesewn" additional="false">lmorgadodacosta/cantonesewn</pwccode>
    </paper>
    <paper id="29">
      <title>Fitting Semantic Relations to Word Embeddings</title>
      <author><first>Eric</first><last>Kafe</last></author>
      <pages>228–237</pages>
      <abstract>We fit WordNet relations to word embeddings, using 3CosAvg and LRCos, two set-based methods for analogy resolution, and introduce 3CosWeight, a new, weighted variant of 3CosAvg. We test the performance of the resulting semantic vectors in lexicographic semantics tests, and show that none of the tested classifiers can learn symmetric relations like <a href="https://en.wikipedia.org/wiki/Synonym">synonymy</a> and <a href="https://en.wikipedia.org/wiki/Opposite_(semantics)">antonymy</a>, since the source and target words of these relations are the same set. By contrast, with the asymmetric relations (hyperonymy / hyponymy and meronymy), both 3CosAvg and LRCos clearly outperform the baseline in all cases, while 3CosWeight attained the best scores with hyponymy and meronymy, suggesting that this new method could provide a useful alternative to previous approaches.</abstract>
      <url hash="af0e5d73">2019.gwc-1.29</url>
      <bibkey>kafe-2019-fitting</bibkey>
    </paper>
    <paper id="34">
      <title>OntoLex as a possible Bridge between <a href="https://en.wikipedia.org/wiki/WordNet">WordNets</a> and full lexical Descriptions<fixed-case>O</fixed-case>nto<fixed-case>L</fixed-case>ex as a possible Bridge between <fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>ets and full lexical Descriptions</title>
      <author><first>Thierry</first><last>Declerck</last></author>
      <author><first>Melanie</first><last>Siegel</last></author>
      <pages>264–271</pages>
      <abstract>In this paper we describe our current work on representing a recently created German lexical semantics resource in OntoLex-Lemon and in conformance with WordNet specifications. Besides presenting the representation effort, we show the utilization of OntoLex-Lemon to bridge from WordNet-like resources to full lexical descriptions and extend the coverage of WordNets to other types of lexical data, such as decomposition results, exemplified for German data, and inflectional phenomena, here outlined for English data.</abstract>
      <url hash="0cd59942">2019.gwc-1.34</url>
      <bibkey>declerck-siegel-2019-ontolex</bibkey>
    </paper>
    <paper id="36">
      <title>Enhancing Conceptual Description through Resource Linking and Exploration of Semantic Relations</title>
      <author><first>Ivelina</first><last>Stoyanova</last></author>
      <author><first>Svetlozara</first><last>Leseva</last></author>
      <pages>280–289</pages>
      <abstract>The paper presents current efforts towards linking two large lexical semantic resources   <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a> and <a href="https://en.wikipedia.org/wiki/FrameNet">FrameNet</a>   to the end of their mutual enrichment and the facilitation of the access, extraction and analysis of various types of semantic and syntactic information. In the second part of the paper, we go on to examine the relation of <a href="https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)">inheritance</a> and other semantic relations as represented in <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a> and <a href="https://en.wikipedia.org/wiki/FrameNet">FrameNet</a> and how they correspond to each other when the resources are aligned. We discuss the implications with respect to the enhancement of the two resources through the definition of new relations and the detailisation of conceptual frames.</abstract>
      <url hash="d49eab51">2019.gwc-1.36</url>
      <bibkey>stoyanova-leseva-2019-enhancing</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
    </paper>
    <paper id="41">
      <title>A collaborative system for building and maintaining <a href="https://en.wikipedia.org/wiki/Wordnet">wordnets</a>.</title>
      <author><first>Tomasz</first><last>Naskręt</last></author>
      <pages>323–328</pages>
      <abstract>A collaborative system for wordnet construction and maintenance is presented. Its key modules include WordnetLoom editor, Wordnet Tracker and JavaScript Graph. They offer a number of functionalities that allow solving problems on every stage of building, editing and aligning wordnets by teams of lexicographers working in parallel. The experience collected in recent years has allowed us to refine <a href="https://en.wikipedia.org/wiki/Application_software">applications</a> and add new <a href="https://en.wikipedia.org/wiki/Modular_programming">modules</a> to provide the best user experience in a reliable and easily maintainable way.</abstract>
      <url hash="b1302c5a">2019.gwc-1.41</url>
      <bibkey>naskret-2019-collaborative</bibkey>
    </paper>
    <paper id="42">
      <title>Enriching Keywords Database UsingWordnets   a Case Study<fixed-case>U</fixed-case>sing<fixed-case>W</fixed-case>ordnets – a Case Study</title>
      <author><first>Tomasz</first><last>Jastrząb</last></author>
      <author><first>Grzegorz</first><last>Kwiatkowski</last></author>
      <pages>329–335</pages>
      <abstract>In the paper, we study the case of building a keywords database related to the Polish Classification of Activities (PKD 2007). The <a href="https://en.wikipedia.org/wiki/Database">database</a> enables automatic classification of the companies to the industry branches. The <a href="https://en.wikipedia.org/wiki/Taxonomy_(biology)">classification</a> is performed based on the company’s activity description. We present the initial design of the keywords database and the ways in which <a href="https://en.wikipedia.org/wiki/Wordnet">wordnets</a> were used to enrich it. Finally, we present the preliminary statistical evaluation of the produced resource.</abstract>
      <url hash="050feaa2">2019.gwc-1.42</url>
      <bibkey>jastrzab-kwiatkowski-2019-enriching</bibkey>
    </paper>
    <paper id="44">
      <title>Testing Zipf’s meaning-frequency law with wordnets as sense inventories<fixed-case>Z</fixed-case>ipf’s meaning-frequency law with wordnets as sense inventories</title>
      <author><first>Francis</first><last>Bond</last></author>
      <author><first>Arkadiusz</first><last>Janz</last></author>
      <author><first>Marek</first><last>Maziarz</last></author>
      <author><first>Ewa</first><last>Rudnicka</last></author>
      <pages>342–352</pages>
      <abstract>According to George K. Zipf, more frequent words have more senses. We have tested this law using corpora and wordnets of <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a>, <a href="https://en.wikipedia.org/wiki/French_language">French</a>, <a href="https://en.wikipedia.org/wiki/Polish_language">Polish</a>, <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese</a>, <a href="https://en.wikipedia.org/wiki/Indonesian_language">Indonesian</a> and <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a>. We have proved that the law works pretty well for all of these languages if we take-as Zipf did-mean values of meaning count and averaged ranks. On the other hand, the <a href="https://en.wikipedia.org/wiki/Scientific_law">law</a> disastrously fails in predicting the number of senses for a single lemma. We have also provided the evidence that slope coefficients of Zipfian log-log linear model may vary from language to language.</abstract>
      <url hash="392284b7">2019.gwc-1.44</url>
      <bibkey>bond-etal-2019-testing</bibkey>
    </paper>
    <paper id="45">
      <title>plWordNet 4.1-a Linguistically Motivated, Corpus-based Bilingual Resource<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et 4.1 - a Linguistically Motivated, Corpus-based Bilingual Resource</title>
      <author><first>Agnieszka</first><last>Dziob</last></author>
      <author><first>Maciej</first><last>Piasecki</last></author>
      <author><first>Ewa</first><last>Rudnicka</last></author>
      <pages>353–362</pages>
      <abstract>The paper presents the latest release of the Polish WordNet, namely plWordNet 4.1. The most significant developments since 3.0 version include new relations for <a href="https://en.wikipedia.org/wiki/Noun">nouns</a> and <a href="https://en.wikipedia.org/wiki/Verb">verbs</a>, mapping semantic role-relations from the valency lexicon Walenty onto the plWordNet structure and sense-level inter-lingual mapping. Several statistics are presented in order to illustrate the development and contemporary state of the <a href="https://en.wikipedia.org/wiki/Wordnet">wordnet</a>.</abstract>
      <url hash="a74c9915">2019.gwc-1.45</url>
      <bibkey>dziob-etal-2019-plwordnet</bibkey>
    </paper>
    <paper id="47">
      <title>Portuguese Manners of Speaking<fixed-case>P</fixed-case>ortuguese Manners of Speaking</title>
      <author><first>Valeria</first><last>de Paiva</last></author>
      <author><first>Alexandre</first><last>Rademaker</last></author>
      <pages>373–377</pages>
      <abstract>Lexical resources need to be as complete as possible. Very little work seems to have been done on <a href="https://en.wikipedia.org/wiki/Adverb">adverbs</a>, the smallest part of speech class in <a href="https://en.wikipedia.org/wiki/Princeton_WordNet">Princeton WordNet</a> counting the number of synsets. Amongst <a href="https://en.wikipedia.org/wiki/Adverb">adverbs</a>, manner adverbs ending in ‘-ly’ seem the easiest to work with, as their meaning is almost the same as the one of the associated adjective. This phenomenon seems to be parallel in <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a>, where these <a href="https://en.wikipedia.org/wiki/Manner_of_articulation">manner adverbs</a> finish in the suffix ‘-mente’. We use this correspondence to improve the coverage of <a href="https://en.wikipedia.org/wiki/Adverb">adverbs</a> in the lexical resource OpenWordNet-PT, a <a href="https://en.wikipedia.org/wiki/WordNet">wordnet</a> for <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a>.</abstract>
      <url hash="bc373684">2019.gwc-1.47</url>
      <bibkey>de-paiva-rademaker-2019-portuguese</bibkey>
    </paper>
    <paper id="49">
      <title>GeoNames Wordnet (geown): extracting wordnets from <a href="https://en.wikipedia.org/wiki/GeoNames">GeoNames</a><fixed-case>G</fixed-case>eo<fixed-case>N</fixed-case>ames <fixed-case>W</fixed-case>ordnet (geown): extracting wordnets from <fixed-case>G</fixed-case>eo<fixed-case>N</fixed-case>ames</title>
      <author><first>Francis</first><last>Bond</last></author>
      <author><first>Arthur</first><last>Bond</last></author>
      <pages>387–393</pages>
      <abstract>This paper introduces a new multilingual lexicon of geographical place names. The <a href="https://en.wikipedia.org/wiki/Toponymy">names</a> are based on (and linked to) the GeoNames collection. Each location is treated as a new synset, which is linked by instance_hypernym to a small set of supertypes. These supertypes are linked to the collaborative interlingual index, based on mappings from GeoDomainWordnet. If a location is already in the interlingual index, then it is also linked to the entry, using <a href="https://en.wikipedia.org/wiki/Map_(mathematics)">mappings</a> from the Geo-Wordnet. Finally, if <a href="https://en.wikipedia.org/wiki/GeoNames">GeoNames</a> places the location in a larger location, this is linked using the mero_location link. Wordnets can be built for any language in <a href="https://en.wikipedia.org/wiki/GeoNames">GeoNames</a>, we give results for those wordnets in the Open Multilingual Wordnet. We discuss how <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> is mapped and the characteristics of the extracted <a href="https://en.wikipedia.org/wiki/Wordnet">wordnets</a>.</abstract>
      <url hash="62cfadab">2019.gwc-1.49</url>
      <bibkey>bond-bond-2019-geonames</bibkey>
    </paper>
    <paper id="50">
      <title>New Polysemy Structures in Wordnets Induced by Vertical Polysemy</title>
      <author><first>Ahti</first><last>Lohk</last></author>
      <author><first>Heili</first><last>Orav</last></author>
      <author><first>Kadri</first><last>Vare</last></author>
      <author><first>Francis</first><last>Bond</last></author>
      <author><first>Rasmus</first><last>Vaik</last></author>
      <pages>394–403</pages>
      <abstract>This paper aims to study auto-hyponymy and auto-troponymy relations (or vertical polysemy) in 11 wordnets uploaded into the new Open Multilingual Wordnet (OMW) webpage. We investigate how vertical polysemy forms <a href="https://en.wikipedia.org/wiki/Polysemy">polysemy structures</a> (or sense clusters) in semantic hierarchies of the <a href="https://en.wikipedia.org/wiki/Wordnet">wordnets</a>. Our main results and discoveries are new polysemy structures that have not previously been associated with vertical polysemy, along with some inconsistencies of semantic relations analysis in the studied wordnets, which should not be there. In the case study, we turn attention to polysemy structures in the Estonian Wordnet (version 2.2.0), analyzing <a href="https://en.wikipedia.org/wiki/Estonian_language">them</a> and giving the lexicographers comments. In addition, we describe the detection algorithm of <a href="https://en.wikipedia.org/wiki/Polysemy">polysemy structures</a> and an overview of the state of <a href="https://en.wikipedia.org/wiki/Polysemy">polysemy structures</a> in 11 <a href="https://en.wikipedia.org/wiki/Wordnet">wordnets</a>.</abstract>
      <url hash="2b4daefe">2019.gwc-1.50</url>
      <bibkey>lohk-etal-2019-new</bibkey>
    </paper>
    </volume>
</collection>