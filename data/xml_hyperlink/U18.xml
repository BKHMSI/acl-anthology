<?xml version='1.0' encoding='utf-8'?>
<collection id="U18">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the Australasian Language Technology Association Workshop 2018</booktitle>
      <url hash="d16bf8c3">U18-1</url>
      <editor><first>Sunghwan Mac</first><last>Kim</last></editor>
      <editor><first>Xiuzhen (Jenny)</first><last>Zhang</last></editor>
      <address>Dunedin, New Zealand</address>
      <month>December</month>
      <year>2018</year>
    </meta>
    <frontmatter>
      <url hash="5802d99e">U18-1000</url>
      <bibkey>alta-2018-australasian</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Improved Neural Machine Translation using Side Information</title>
      <author><first>Cong Duy Vu</first><last>Hoang</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <pages>6–16</pages>
      <url hash="46593160">U18-1001</url>
      <abstract>In this work, we investigate whether side information is helpful in neural machine translation (NMT). We study various kinds of side information, including topical information, <a href="https://en.wikipedia.org/wiki/Trait_theory">personal trait</a>, then propose different ways of incorporating them into the existing NMT models. Our experimental results show the benefits of side information in improving the NMT models.</abstract>
      <bibkey>hoang-etal-2018-improved</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/pattr">PatTR</pwcdataset>
    </paper>
    <paper id="3">
      <title>Development of Natural Language Processing Tools for <a href="https://en.wikipedia.org/wiki/Cook_Islands">Cook Islands</a> Mori<fixed-case>C</fixed-case>ook <fixed-case>I</fixed-case>slands <fixed-case>M</fixed-case>āori</title>
      <author><first>Rolando Coto</first><last>Solano</last></author>
      <author><first>Sally Akevai</first><last>Nicholas</last></author>
      <author><first>Samantha</first><last>Wray</last></author>
      <pages>26–33</pages>
      <url hash="f4845959">U18-1003</url>
      <abstract>This paper presents three ongoing projects for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> in <a href="https://en.wikipedia.org/wiki/Cook_Islands_Māori">Cook Islands Maori</a> : Untrained Forced Alignment (approx. 9 % error when detecting the center of words), speech-to-text (37 % WER in the best trained models) and POS tagging (92 % accuracy for the best performing model). Included as part of these projects are new resources filling in a gap in Australasian languages, including gold standard POS-tagged written corpora, transcribed speech corpora, time-aligned corpora down to the level of <a href="https://en.wikipedia.org/wiki/Phoneme">phonemes</a>. These are part of efforts to accelerate the documentation of <a href="https://en.wikipedia.org/wiki/Cook_Islands_Māori">Cook Islands Maori</a> and to increase its vitality amongst its users.</abstract>
      <bibkey>solano-etal-2018-development</bibkey>
    </paper>
    <paper id="5">
      <title>Specifying Conceptual Models Using Restricted Natural Language</title>
      <author><first>Bayzid Ashik</first><last>Hossain</last></author>
      <author><first>Rolf</first><last>Schwitter</last></author>
      <pages>44–52</pages>
      <url hash="5269a4f3">U18-1005</url>
      <abstract>The key activity to design an <a href="https://en.wikipedia.org/wiki/Information_system">information system</a> is <a href="https://en.wikipedia.org/wiki/Conceptual_model_(computer_science)">conceptual modelling</a> which brings out and describes the general knowledge that is required to build a <a href="https://en.wikipedia.org/wiki/System">system</a>. In this paper we propose a novel approach to <a href="https://en.wikipedia.org/wiki/Conceptual_model_(computer_science)">conceptual modelling</a> where the domain experts will be able to specify and construct a <a href="https://en.wikipedia.org/wiki/Conceptual_model_(computer_science)">model</a> using a restricted form of natural language. A restricted natural language is a subset of a <a href="https://en.wikipedia.org/wiki/Natural_language">natural language</a> that has well-defined computational properties and therefore can be translated unambiguously into a <a href="https://en.wikipedia.org/wiki/Formal_language">formal notation</a>. We will argue that a restricted natural language is suitable for writing precise and consistent specifications that lead to executable <a href="https://en.wikipedia.org/wiki/Conceptual_model_(computer_science)">conceptual models</a>. Using a restricted natural language will allow the domain experts to describe a scenario in the terminology of the application domain without the need to formally encode this scenario. The resulting textual specification can then be automatically translated into the language of the desired <a href="https://en.wikipedia.org/wiki/Conceptual_model_(computer_science)">conceptual modelling framework</a>.</abstract>
      <bibkey>hossain-schwitter-2018-specifying</bibkey>
    </paper>
    <paper id="8">
      <title>Cluster Labeling by Word Embeddings and WordNet’s Hypernymy<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et's Hypernymy</title>
      <author><first>Hanieh</first><last>Poostchi</last></author>
      <author><first>Massimo</first><last>Piccardi</last></author>
      <pages>66–70</pages>
      <url hash="e98a71c5">U18-1008</url>
      <abstract>Cluster labeling is the assignment of representative labels to <a href="https://en.wikipedia.org/wiki/Cluster_analysis">clusters</a> obtained from the organization of a <a href="https://en.wikipedia.org/wiki/Document_management_system">document collection</a>. Once assigned, the labels can play an important role in applications such as <a href="https://en.wikipedia.org/wiki/Navigation">navigation</a>, <a href="https://en.wikipedia.org/wiki/Web_search_engine">search</a> and <a href="https://en.wikipedia.org/wiki/Document_classification">document classification</a>. However, finding appropriately descriptive labels is still a challenging task. In this paper, we propose various approaches for assigning labels to word clusters by leveraging <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> and the <a href="https://en.wikipedia.org/wiki/Synonym">synonymity</a> and hypernymy relations in the WordNet lexical ontology. Experiments carried out using the WebAP document dataset have shown that one of the approaches stand out in the comparison and is capable of selecting labels that are reasonably aligned with those chosen by a pool of four human annotators.</abstract>
      <bibkey>poostchi-piccardi-2018-cluster</bibkey>
    </paper>
    <paper id="9">
      <title>A Comparative Study of Embedding Models in Predicting the Compositionality of Multiword Expressions</title>
      <author><first>Navnita</first><last>Nandakumar</last></author>
      <author><first>Bahar</first><last>Salehi</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <pages>71–76</pages>
      <url hash="3d7aad37">U18-1009</url>
      <abstract>In this paper, we perform a comparative evaluation of off-the-shelf embedding models over the task of compositionality prediction of multiword expressions(MWEs). Our experimental results suggest that character- and document-level models capture knowledge of MWE compositionality and are effective in modelling varying levels of <a href="https://en.wikipedia.org/wiki/Compositionality">compositionality</a>, with the advantage over word-level models that they do not require token-level identification of MWEs in the training corpus.</abstract>
      <bibkey>nandakumar-etal-2018-comparative</bibkey>
    </paper>
    <paper id="11">
      <title>Overview of the 2018 ALTA Shared Task : Classifying Patent Applications<fixed-case>ALTA</fixed-case> Shared Task: Classifying Patent Applications</title>
      <author><first>Diego</first><last>Mollá</last></author>
      <author><first>Dilesha</first><last>Seneviratne</last></author>
      <pages>84–88</pages>
      <url hash="b16206b8">U18-1011</url>
      <abstract>We present an overview of the 2018 ALTA shared task. This is the 9th of the series of shared tasks organised by ALTA since 2010. The task was to classify Australian patent classifications following the sections defined by the International Patient Classification (IPC), using data made available by <a href="https://en.wikipedia.org/wiki/IP_Australia">IP Australia</a>. We introduce the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, describe the data and present the results of the participating teams. Some of the participating teams outperformed state of the art.</abstract>
      <bibkey>molla-seneviratne-2018-overview</bibkey>
    </paper>
    <paper id="12">
      <title>Classifying Patent Applications with Ensemble Methods</title>
      <author><first>Fernando</first><last>Benites</last></author>
      <author><first>Shervin</first><last>Malmasi</last></author>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <pages>89–92</pages>
      <url hash="fe24ec3a">U18-1012</url>
      <abstract>We present methods for the automatic classification of patent applications using an annotated dataset provided by the organizers of the ALTA 2018 shared task-Classifying Patent Applications. The goal of the task is to use computational methods to categorize patent applications according to a coarse-grained taxonomy of eight classes based on the International Patent Classification (IPC). We tested a variety of approaches for this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> and the best results, 0.778 micro-averaged F1-Score, were achieved by SVM ensembles using a combination of <a href="https://en.wikipedia.org/wiki/Word">words</a> and characters as <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>. Our team, BMZ, was ranked first among 14 teams in the competition.</abstract>
      <bibkey>benites-etal-2018-classifying</bibkey>
    </paper>
    <paper id="13">
      <title>Universal Language Model Fine-tuning for Patent Classification</title>
      <author><first>Jason</first><last>Hepburn</last></author>
      <pages>93–96</pages>
      <url hash="5e044eeb">U18-1013</url>
      <abstract>This paper describes the <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> used for the 2018 ALTA Shared Task. The task this year was to automatically classify <a href="https://en.wikipedia.org/wiki/Australian_patent_law">Australian patents</a> into their main International Patent Classification section. Our final submission used a Support Vector Machine (SVM) and Universal Language Model with Fine-tuning (ULMFiT). Our <a href="https://en.wikipedia.org/wiki/System">system</a> achieved the best results in the student category.</abstract>
      <bibkey>hepburn-2018-universal</bibkey>
    </paper>
  </volume>
</collection>