<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.onion">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of LREC2020 Workshop "People in language, vision and the mind" (ONION2020)</booktitle>
      <editor><first>Patrizia</first><last>Paggio</last></editor>
      <editor><first>Albert</first><last>Gatt</last></editor>
      <editor><first>Roman</first><last>Klinger</last></editor>
      <publisher>European Language Resources Association (ELRA)</publisher>
      <address>Marseille, France</address>
      <month>May</month>
      <year>2020</year>
      <isbn>979-10-95546-70-2</isbn>
    </meta>
    <frontmatter>
      <url hash="d9186cde">2020.onion-1.0</url>
      <bibkey>onion-2020-lrec2020</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Analysis of Body Behaviours in Human-Human and Human-Robot Interactions</title>
      <author><first>Taiga</first><last>Mori</last></author>
      <author><first>Kristiina</first><last>Jokinen</last></author>
      <author><first>Yasuharu</first><last>Den</last></author>
      <pages>7–14</pages>
      <abstract>We conducted preliminary comparison of human-robot (HR) interaction with human-human (HH) interaction conducted in <a href="https://en.wikipedia.org/wiki/English_language">English</a> and in <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese</a>. As the result, body gestures increased in <a href="https://en.wikipedia.org/wiki/Human_factors_and_ergonomics">HR</a>, while hand and head gestures decreased in <a href="https://en.wikipedia.org/wiki/Human_factors_and_ergonomics">HR</a>. Concerning <a href="https://en.wikipedia.org/wiki/List_of_gestures">hand gesture</a>, they were composed of more diverse and complex forms, trajectories and functions in HH than in HR. Moreover, <a href="https://en.wikipedia.org/wiki/English_language">English speakers</a> produced 6 times more <a href="https://en.wikipedia.org/wiki/List_of_gestures">hand gestures</a> than <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese speakers</a> in HH. Regarding head gesture, even though there was no difference in the frequency of head gestures between <a href="https://en.wikipedia.org/wiki/English_language">English speakers</a> and <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese speakers</a> in HH, <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese speakers</a> produced slightly more nodding during the robot’s speaking than <a href="https://en.wikipedia.org/wiki/English_language">English speakers</a> in HR. Furthermore, positions of nod were different depending on the language. Concerning <a href="https://en.wikipedia.org/wiki/Gesture">body gesture</a>, participants produced <a href="https://en.wikipedia.org/wiki/Gesture">body gestures</a> mostly to regulate appropriate distance with the robot in <a href="https://en.wikipedia.org/wiki/Human_resources">HR</a>. Additionally, <a href="https://en.wikipedia.org/wiki/English_language">English speakers</a> produced slightly more <a href="https://en.wikipedia.org/wiki/List_of_gestures">body gestures</a> than <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese speakers</a>.</abstract>
      <url hash="29b6f4db">2020.onion-1.2</url>
      <language>eng</language>
      <bibkey>mori-etal-2020-analysis</bibkey>
    </paper>
    <paper id="5">
      <title>Improving <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> with Biofeedback Data</title>
      <author><first>Daniel</first><last>Schlör</last></author>
      <author><first>Albin</first><last>Zehe</last></author>
      <author><first>Konstantin</first><last>Kobs</last></author>
      <author><first>Blerta</first><last>Veseli</last></author>
      <author><first>Franziska</first><last>Westermeier</last></author>
      <author><first>Larissa</first><last>Brübach</last></author>
      <author><first>Daniel</first><last>Roth</last></author>
      <author><first>Marc Erich</first><last>Latoschik</last></author>
      <author><first>Andreas</first><last>Hotho</last></author>
      <pages>28–33</pages>
      <abstract>Humans frequently are able to read and interpret emotions of others by directly taking verbal and non-verbal signals in human-to-human communication into account or to infer or even experience <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a> from mediated stories. For <a href="https://en.wikipedia.org/wiki/Computer">computers</a>, however, <a href="https://en.wikipedia.org/wiki/Emotion_recognition">emotion recognition</a> is a complex problem : Thoughts and feelings are the roots of many <a href="https://en.wikipedia.org/wiki/Behavior">behavioural responses</a> and they are deeply entangled with <a href="https://en.wikipedia.org/wiki/Neurophysiology">neurophysiological changes</a> within humans. As such, <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a> are very subjective, often are expressed in a subtle manner, and are highly depending on context. For example, machine learning approaches for text-based sentiment analysis often rely on incorporating sentiment lexicons or <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> to capture the contextual meaning. This paper explores if and how we further can enhance <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> using <a href="https://en.wikipedia.org/wiki/Biofeedback">biofeedback</a> of humans which are experiencing <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a> while reading texts. Specifically, we record the <a href="https://en.wikipedia.org/wiki/Heart_rate">heart rate</a> and <a href="https://en.wikipedia.org/wiki/Neural_oscillation">brain waves</a> of readers that are presented with short texts which have been annotated with the emotions they induce. We use these <a href="https://en.wikipedia.org/wiki/Physiology">physiological signals</a> to improve the performance of a lexicon-based sentiment classifier. We find that the combination of several <a href="https://en.wikipedia.org/wiki/Biosignal">biosignals</a> can improve the ability of a text-based classifier to detect the presence of a sentiment in a text on a per-sentence level.</abstract>
      <url hash="1b303c6b">2020.onion-1.5</url>
      <language>eng</language>
      <bibkey>schlor-etal-2020-improving</bibkey>
    </paper>
  </volume>
</collection>