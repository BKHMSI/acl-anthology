<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.scai">
  <volume id="1" ingest-date="2020-11-06">
    <meta>
      <booktitle>Proceedings of the 5th International Workshop on Search-Oriented Conversational AI (SCAI)</booktitle>
      <editor><first>Jeff</first><last>Dalton</last></editor>
      <editor><first>Aleksandr</first><last>Chuklin</last></editor>
      <editor><first>Julia</first><last>Kiseleva</last></editor>
      <editor><first>Mikhail</first><last>Burtsev</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>November</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="6d144a1a">2020.scai-1.0</url>
      <bibkey>scai-2020-international</bibkey>
    </frontmatter>
    <paper id="2">
      <title>A Wrong Answer or a Wrong Question? An Intricate Relationship between Question Reformulation and Answer Selection in Conversational Question Answering</title>
      <author><first>Svitlana</first><last>Vakulenko</last></author>
      <author><first>Shayne</first><last>Longpre</last></author>
      <author><first>Zhucheng</first><last>Tu</last></author>
      <author><first>Raviteja</first><last>Anantha</last></author>
      <pages>7â€“16</pages>
      <abstract>The dependency between an adequate question formulation and correct answer selection is a very intriguing but still underexplored area. In this paper, we show that question rewriting (QR) of the conversational context allows to shed more light on this phenomenon and also use it to evaluate <a href="https://en.wikipedia.org/wiki/Robustness_(computer_science)">robustness</a> of different answer selection approaches. We introduce a simple framework that enables an automated analysis of the conversational question answering (QA) performance using question rewrites, and present the results of this analysis on the TREC CAsT and QuAC (CANARD) datasets. Our experiments uncover sensitivity to question formulation of the popular state-of-the-art question answering approaches. Our results demonstrate that the reading comprehension model is insensitive to question formulation, while the passage ranking changes dramatically with a little variation in the input question. The benefit of <a href="https://en.wikipedia.org/wiki/QR_code">QR</a> is that it allows us to pinpoint and group such cases automatically. We show how to use this <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> to verify whether QA models are really learning the task or just finding shortcuts in the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>, and better understand the frequent types of error they make.</abstract>
      <url hash="0042df23">2020.scai-1.2</url>
      <doi>10.18653/v1/2020.scai-1.2</doi>
      <video href="https://slideslive.com/38940062" />
      <bibkey>vakulenko-etal-2020-wrong</bibkey>
      <pwccode url="https://github.com/svakulenk0/QRQA" additional="false">svakulenk0/QRQA</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/canard">CANARD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ms-marco">MS MARCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/quac">QuAC</pwcdataset>
    </paper>
    </volume>
</collection>