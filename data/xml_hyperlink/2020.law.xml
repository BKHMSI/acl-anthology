<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.law">
  <volume id="1" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the 14th Linguistic Annotation Workshop</booktitle>
      <editor><first>Stefanie</first><last>Dipper</last></editor>
      <editor><first>Amir</first><last>Zeldes</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Barcelona, Spain</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="9dfacf09">2020.law-1.0</url>
      <bibkey>law-2020-linguistic</bibkey>
    </frontmatter>
    <paper id="8">
      <title>Cookpad Parsed Corpus : Linguistic Annotations of Japanese Recipes<fixed-case>J</fixed-case>apanese Recipes</title>
      <author><first>Jun</first><last>Harashima</last></author>
      <author><first>Makoto</first><last>Hiramatsu</last></author>
      <pages>87–92</pages>
      <abstract>It has become increasingly common for people to share <a href="https://en.wikipedia.org/wiki/Recipe">cooking recipes</a> on the Internet. Along with the increase in the number of shared recipes, there have been corresponding increases in recipe-related studies and <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a>. However, there are still few <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> that provide linguistic annotations for the recipe-related studies even though such <a href="https://en.wikipedia.org/wiki/Annotation">annotations</a> should form the basis of the studies. This paper introduces a novel recipe-related dataset, named Cookpad Parsed Corpus, which contains linguistic annotations for Japanese recipes. We randomly extracted 500 recipes from the largest recipe-related dataset, the Cookpad Recipe Dataset, and annotated 4 ; 738 sentences in the <a href="https://en.wikipedia.org/wiki/Recipe">recipes</a> with morphemes, named entities, and dependency relations. This paper also reports benchmark results on our <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> for Japanese morphological analysis, <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>, and dependency parsing. We show that there is still room for improvement in the analyses of recipes.</abstract>
      <url hash="e48d0c1d">2020.law-1.8</url>
      <bibkey>harashima-hiramatsu-2020-cookpad</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/microsoft-research-multimodal-aligned-recipe">Microsoft Research Multimodal Aligned Recipe Corpus</pwcdataset>
    </paper>
    <paper id="10">
      <title>PASTRIE : A Corpus of Prepositions Annotated with Supersense Tags in Reddit International English<fixed-case>PASTRIE</fixed-case>: A Corpus of Prepositions Annotated with Supersense Tags in <fixed-case>R</fixed-case>eddit International <fixed-case>E</fixed-case>nglish</title>
      <author><first>Michael</first><last>Kranzlein</last></author>
      <author><first>Emma</first><last>Manning</last></author>
      <author><first>Siyao</first><last>Peng</last></author>
      <author><first>Shira</first><last>Wein</last></author>
      <author><first>Aryaman</first><last>Arora</last></author>
      <author><first>Nathan</first><last>Schneider</last></author>
      <pages>105–116</pages>
      <abstract>We present the Prepositions Annotated with Supsersense Tags in Reddit International English (PASTRIE) corpus, a new dataset containing manually annotated preposition supersenses of English data from presumed speakers of four L1s : <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/French_language">French</a>, <a href="https://en.wikipedia.org/wiki/German_language">German</a>, and <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>. The <a href="https://en.wikipedia.org/wiki/Annotation">annotations</a> are comprehensive, covering all preposition types and tokens in the sample. Along with the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>, we provide analysis of distributional patterns across the included <a href="https://en.wikipedia.org/wiki/Corpus_linguistics">L1s</a> and a discussion of the influence of <a href="https://en.wikipedia.org/wiki/Corpus_linguistics">L1s</a> on L2 preposition choice.</abstract>
      <url hash="0eaf4d40">2020.law-1.10</url>
      <bibkey>kranzlein-etal-2020-pastrie</bibkey>
      <pwccode url="https://github.com/nert-nlp/pastrie" additional="false">nert-nlp/pastrie</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/pastrie">PASTRIE</pwcdataset>
    </paper>
    <paper id="13">
      <title>Querent Intent in Multi-Sentence Questions</title>
      <author><first>Laurie</first><last>Burchell</last></author>
      <author><first>Jie</first><last>Chi</last></author>
      <author><first>Tom</first><last>Hosking</last></author>
      <author><first>Nina</first><last>Markl</last></author>
      <author><first>Bonnie</first><last>Webber</last></author>
      <pages>138–147</pages>
      <abstract>Multi-sentence questions (MSQs) are sequences of questions connected by relations which, unlike sequences of standalone questions, need to be answered as a unit. Following Rhetorical Structure Theory (RST), we recognise that different question discourse relations between the subparts of MSQs reflect different speaker intents, and consequently elicit different answering strategies. Correctly identifying these <a href="https://en.wikipedia.org/wiki/Binary_relation">relations</a> is therefore a crucial step in automatically answering MSQs. We identify five different types of MSQs in <a href="https://en.wikipedia.org/wiki/English_language">English</a>, and define five novel <a href="https://en.wikipedia.org/wiki/Binary_relation">relations</a> to describe them. We extract over 162,000 MSQs from <a href="https://en.wikipedia.org/wiki/Stack_Exchange">Stack Exchange</a> to enable future research. Finally, we implement a high-precision baseline classifier based on <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">surface features</a>.</abstract>
      <url hash="28023456">2020.law-1.13</url>
      <bibkey>burchell-etal-2020-querent</bibkey>
      <pwccode url="https://github.com/laurieburchell/multi-sentence-questions" additional="false">laurieburchell/multi-sentence-questions</pwccode>
    </paper>
    <paper id="17">
      <title>Annotating Coherence Relations for Studying Topic Transitions in Social Talk</title>
      <author><first>Alex</first><last>Luu</last></author>
      <author><first>Sophia A.</first><last>Malamud</last></author>
      <pages>174–179</pages>
      <abstract>This study develops the strand of research on topic transitions in social talk which aims to gain a better understanding of interlocutors’ conversational goals. Lu and Malamud (2020) proposed that one way to identify such transitions is to annotate coherence relations, and then to identify utterances potentially expressing new topics as those that fail to participate in these relations. This work validates and refines their suggested annotation methodology, focusing on annotating most prominent <a href="https://en.wikipedia.org/wiki/Coherence_(linguistics)">coherence relations</a> in <a href="https://en.wikipedia.org/wiki/Face-to-face_interaction">face-to-face social dialogue</a>. The result is a publicly accessible gold standard corpus with efficient and reliable <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a>, whose broad coverage provides a foundation for future steps of identifying and classifying new topic utterances.</abstract>
      <url hash="1576a7ca">2020.law-1.17</url>
      <bibkey>luu-malamud-2020-annotating</bibkey>
    </paper>
  </volume>
</collection>