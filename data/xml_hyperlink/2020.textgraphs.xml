<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.textgraphs">
  <volume id="1" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the Graph-based Methods for Natural Language Processing (TextGraphs)</booktitle>
      <editor><first>Dmitry</first><last>Ustalov</last></editor>
      <editor><first>Swapna</first><last>Somasundaran</last></editor>
      <editor><first>Alexander</first><last>Panchenko</last></editor>
      <editor><first>Fragkiskos D.</first><last>Malliaros</last></editor>
      <editor><first>Ioana</first><last>Hulpuș</last></editor>
      <editor><first>Peter</first><last>Jansen</last></editor>
      <editor><first>Abhik</first><last>Jana</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Barcelona, Spain (Online)</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="00d04105">2020.textgraphs-1.0</url>
      <bibkey>textgraphs-2020-graph</bibkey>
    </frontmatter>
    <paper id="1">
      <title>A survey of embedding models of entities and relationships for knowledge graph completion</title>
      <author><first>Dat Quoc</first><last>Nguyen</last></author>
      <pages>1–14</pages>
      <abstract>Knowledge graphs (KGs) of real-world facts about entities and their relationships are useful resources for a variety of natural language processing tasks. However, because <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graphs</a> are typically incomplete, it is useful to perform knowledge graph completion or link prediction, i.e. predict whether a relationship not in the <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graph</a> is likely to be true. This paper serves as a comprehensive survey of embedding models of entities and relationships for knowledge graph completion, summarizing up-to-date experimental results on standard benchmark datasets and pointing out potential future research directions.</abstract>
      <url hash="645a9fe7">2020.textgraphs-1.1</url>
      <attachment type="OptionalSupplementaryMaterial" hash="c48b2a8f">2020.textgraphs-1.1.OptionalSupplementaryMaterial.pdf</attachment>
      <bibkey>nguyen-2020-survey</bibkey>
      <doi>10.18653/v1/2020.textgraphs-1.1</doi>
      <pwccode url="" additional="true" />
      <pwcdataset url="https://paperswithcode.com/dataset/fb15k">FB15k</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/fb15k-237">FB15k-237</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/nell">NELL</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wn18">WN18</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wn18rr">WN18RR</pwcdataset>
    </paper>
    <paper id="5">
      <title>Contextual BERT : Conditioning the <a href="https://en.wikipedia.org/wiki/Language_model">Language Model</a> Using a Global State<fixed-case>BERT</fixed-case>: Conditioning the Language Model Using a Global State</title>
      <author><first>Timo I.</first><last>Denk</last></author>
      <author><first>Ana</first><last>Peleteiro Ramallo</last></author>
      <pages>46–50</pages>
      <abstract>BERT is a popular <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> whose main pre-training task is to fill in the blank, i.e., predicting a word that was masked out of a sentence, based on the remaining words. In some applications, however, having an additional context can help the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> make the right prediction, e.g., by taking the domain or the time of writing into account. This motivates us to advance the BERT architecture by adding a <a href="https://en.wikipedia.org/wiki/State_(computer_science)">global state</a> for conditioning on a fixed-sized context. We present our two novel approaches and apply them to an industry use-case, where we complete fashion outfits with missing articles, conditioned on a specific customer. An experimental comparison to other <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> from the literature shows that our <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> improve <a href="https://en.wikipedia.org/wiki/Personalization">personalization</a> significantly.</abstract>
      <url hash="20609025">2020.textgraphs-1.5</url>
      <bibkey>denk-peleteiro-ramallo-2020-contextual</bibkey>
      <doi>10.18653/v1/2020.textgraphs-1.5</doi>
    </paper>
    <paper id="13">
      <title>Explanation Regeneration via Multi-Hop ILP Inference over Knowledge Base<fixed-case>ILP</fixed-case> Inference over Knowledge Base</title>
      <author><first>Aayushee</first><last>Gupta</last></author>
      <author><first>Gopalakrishnan</first><last>Srinivasaraghavan</last></author>
      <pages>109–114</pages>
      <abstract>Textgraphs 2020 Workshop organized a shared task on ‘Explanation Regeneration’ that required reconstructing gold explanations for elementary science questions. This work describes our submission to the task which is based on multiple components : a BERT baseline ranking, an Integer Linear Program (ILP) based re-scoring and a regression model for re-ranking the explanation facts. Our <a href="https://en.wikipedia.org/wiki/System">system</a> achieved a Mean Average Precision score of 0.3659.</abstract>
      <url hash="41fbef76">2020.textgraphs-1.13</url>
      <attachment type="OptionalSupplementaryMaterial" hash="20936250">2020.textgraphs-1.13.OptionalSupplementaryMaterial.pdf</attachment>
      <bibkey>gupta-srinivasaraghavan-2020-explanation</bibkey>
      <doi>10.18653/v1/2020.textgraphs-1.13</doi>
    </paper>
    </volume>
</collection>