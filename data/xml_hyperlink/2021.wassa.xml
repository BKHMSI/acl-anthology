<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.wassa">
  <volume id="1" ingest-date="2021-04-19">
    <meta>
      <booktitle>Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</booktitle>
      <editor><first>Orphee</first><last>De Clercq</last></editor>
      <editor><first>Alexandra</first><last>Balahur</last></editor>
      <editor><first>Joao</first><last>Sedoc</last></editor>
      <editor><first>Valentin</first><last>Barriere</last></editor>
      <editor><first>Shabnam</first><last>Tafreshi</last></editor>
      <editor><first>Sven</first><last>Buechel</last></editor>
      <editor><first>Veronique</first><last>Hoste</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>April</month>
      <year>2021</year>
    </meta>
    <frontmatter>
      <url hash="142fa187">2021.wassa-1.0</url>
      <bibkey>wassa-2021-approaches</bibkey>
    </frontmatter>
    <paper id="5">
      <title>Emotion Ratings : How Intensity, Annotation Confidence and Agreements are Entangled</title>
      <author><first>Enrica</first><last>Troiano</last></author>
      <author><first>Sebastian</first><last>Padó</last></author>
      <author><first>Roman</first><last>Klinger</last></author>
      <pages>40–49</pages>
      <abstract>When humans judge the affective content of texts, they also implicitly assess the correctness of such judgment, that is, their <a href="https://en.wikipedia.org/wiki/Confidence">confidence</a>. We hypothesize that people’s (in)confidence that they performed well in an annotation task leads to (dis)agreements among each other. If this is true, <a href="https://en.wikipedia.org/wiki/Confidence">confidence</a> may serve as a diagnostic tool for systematic differences in annotations. To probe our assumption, we conduct a study on a subset of the Corpus of Contemporary American English, in which we ask raters to distinguish neutral sentences from emotion-bearing ones, while scoring the confidence of their answers. Confidence turns out to approximate inter-annotator disagreements. Further, we find that <a href="https://en.wikipedia.org/wiki/Confidence">confidence</a> is correlated to emotion intensity : perceiving stronger affect in text prompts annotators to more certain <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> performances. This insight is relevant for modelling studies of intensity, as it opens the question wether automatic regressors or <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> actually predict intensity, or rather human’s self-perceived confidence.</abstract>
      <url hash="69836997">2021.wassa-1.5</url>
      <bibkey>troiano-etal-2021-emotion</bibkey>
    </paper>
    <paper id="6">
      <title>Disentangling Document Topic and Author Gender in Multiple Languages : Lessons for Adversarial Debiasing</title>
      <author><first>Erenay</first><last>Dayanik</last></author>
      <author><first>Sebastian</first><last>Padó</last></author>
      <pages>50–61</pages>
      <abstract>Text classification is a central tool in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>. However, when the target classes are strongly correlated with other textual attributes, text classification models can pick up wrong <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>, leading to bad generalization and biases. In <a href="https://en.wikipedia.org/wiki/Social_media_analytics">social media analysis</a>, this problem surfaces for demographic user classes such as language, topic, or gender, which influence the generate text to a substantial extent. Adversarial training has been claimed to mitigate this problem, but thorough evaluation is missing. In this paper, we experiment with <a href="https://en.wikipedia.org/wiki/Text_classification">text classification</a> of the correlated attributes of document topic and author gender, using a novel multilingual parallel corpus of TED talk transcripts. Our findings are : (a) individual classifiers for topic and author gender are indeed biased ; (b) <a href="https://en.wikipedia.org/wiki/Debiasing">debiasing</a> with adversarial training works for topic, but breaks down for author gender ; (c) gender debiasing results differ across languages. We interpret the result in terms of feature space overlap, highlighting the role of linguistic surface realization of the target classes.</abstract>
      <url hash="e5197f67">2021.wassa-1.6</url>
      <bibkey>dayanik-pado-2021-disentangling</bibkey>
    </paper>
    <paper id="7">
      <title>Universal Joy A Data Set and Results for Classifying Emotions Across Languages</title>
      <author><first>Sotiris</first><last>Lamprinidis</last></author>
      <author><first>Federico</first><last>Bianchi</last></author>
      <author><first>Daniel</first><last>Hardt</last></author>
      <author><first>Dirk</first><last>Hovy</last></author>
      <pages>62–75</pages>
      <abstract>While <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a> are universal aspects of <a href="https://en.wikipedia.org/wiki/Psychology">human psychology</a>, <a href="https://en.wikipedia.org/wiki/They_(2017_film)">they</a> are expressed differently across different languages and cultures. We introduce a new <a href="https://en.wikipedia.org/wiki/Data_set">data set</a> of over 530k anonymized public Facebook posts across 18 languages, labeled with five different <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a>. Using multilingual BERT embeddings, we show that <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a> can be reliably inferred both within and across languages. Zero-shot learning produces promising results for low-resource languages. Following established theories of basic emotions, we provide a detailed analysis of the possibilities and limits of cross-lingual emotion classification. We find that structural and typological similarity between languages facilitates cross-lingual learning, as well as linguistic diversity of training data. Our results suggest that there are commonalities underlying the expression of emotion in different languages. We publicly release the <a href="https://en.wikipedia.org/wiki/Data_anonymization">anonymized data</a> for future research.</abstract>
      <url hash="7bbb2112">2021.wassa-1.7</url>
      <bibkey>lamprinidis-etal-2021-universal</bibkey>
    </paper>
    <paper id="9">
      <title>An End-to-End Network for Emotion-Cause Pair Extraction</title>
      <author><first>Aaditya</first><last>Singh</last></author>
      <author><first>Shreeshail</first><last>Hingane</last></author>
      <author><first>Saim</first><last>Wani</last></author>
      <author><first>Ashutosh</first><last>Modi</last></author>
      <pages>84–91</pages>
      <abstract>The task of Emotion-Cause Pair Extraction (ECPE) aims to extract all potential clause-pairs of emotions and their corresponding causes in a document. Unlike the more well-studied task of Emotion Cause Extraction (ECE), ECPE does not require the emotion clauses to be provided as annotations. Previous works on ECPE have either followed a multi-stage approach where emotion extraction, cause extraction, and <a href="https://en.wikipedia.org/wiki/Pairing">pairing</a> are done independently or use complex architectures to resolve its limitations. In this paper, we propose an <a href="https://en.wikipedia.org/wiki/End-to-end_principle">end-to-end model</a> for the ECPE task. Due to the unavailability of an English language ECPE corpus, we adapt the NTCIR-13 ECE corpus and establish a baseline for the ECPE task on this dataset. On this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>, the proposed <a href="https://en.wikipedia.org/wiki/Methodology">method</a> produces significant performance improvements (6.5 % increase in F1 score) over the multi-stage approach and achieves comparable performance to the <a href="https://en.wikipedia.org/wiki/Methodology">state-of-the-art methods</a>.</abstract>
      <url hash="9c5ec302">2021.wassa-1.9</url>
      <bibkey>singh-etal-2021-end</bibkey>
      <pwccode url="https://github.com/Aaditya-Singh/E2E-ECPE" additional="false">Aaditya-Singh/E2E-ECPE</pwccode>
    </paper>
    <paper id="11">
      <title>PVG at WASSA 2021 : A Multi-Input, Multi-Task, Transformer-Based Architecture for Empathy and Distress Prediction<fixed-case>PVG</fixed-case> at <fixed-case>WASSA</fixed-case> 2021: A Multi-Input, Multi-Task, Transformer-Based Architecture for Empathy and Distress Prediction</title>
      <author><first>Atharva</first><last>Kulkarni</last></author>
      <author><first>Sunanda</first><last>Somwase</last></author>
      <author><first>Shivam</first><last>Rajput</last></author>
      <author><first>Manisha</first><last>Marathe</last></author>
      <pages>105–111</pages>
      <abstract>Active research pertaining to the affective phenomenon of empathy and <a href="https://en.wikipedia.org/wiki/Distress_(medicine)">distress</a> is invaluable for improving <a href="https://en.wikipedia.org/wiki/Human–computer_interaction">human-machine interaction</a>. Predicting intensities of such complex emotions from textual data is difficult, as these <a href="https://en.wikipedia.org/wiki/Construct_(philosophy)">constructs</a> are deeply rooted in the <a href="https://en.wikipedia.org/wiki/Psychology">psychological theory</a>. Consequently, for better prediction, it becomes imperative to take into account ancillary factors such as the psychological test scores, demographic features, underlying latent primitive emotions, along with the text’s undertone and its psychological complexity. This paper proffers team PVG’s solution to the WASSA 2021 Shared Task on Predicting Empathy and Emotion in Reaction to News Stories. Leveraging the textual data, demographic features, psychological test score, and the intrinsic interdependencies of primitive emotions and <a href="https://en.wikipedia.org/wiki/Empathy">empathy</a>, we propose a multi-input, multi-task framework for the task of <a href="https://en.wikipedia.org/wiki/Empathy">empathy score prediction</a>. Here, the empathy score prediction is considered the primary task, while emotion and empathy classification are considered secondary auxiliary tasks. For the distress score prediction task, the <a href="https://en.wikipedia.org/wiki/System">system</a> is further boosted by the addition of lexical features. Our submission ranked 1st based on the average correlation (0.545) as well as the distress correlation (0.574), and 2nd for the empathy Pearson correlation (0.517).</abstract>
      <url hash="a7e600c1">2021.wassa-1.11</url>
      <bibkey>kulkarni-etal-2021-pvg</bibkey>
      <pwccode url="https://github.com/mr-atharva-kulkarni/EACL-WASSA-2021-Empathy-Distress" additional="false">mr-atharva-kulkarni/EACL-WASSA-2021-Empathy-Distress</pwccode>
    </paper>
    <paper id="12">
      <title>WASSA@IITK at WASSA 2021 : Multi-task Learning and Transformer Finetuning for Emotion Classification and Empathy Prediction<fixed-case>WASSA</fixed-case>@<fixed-case>IITK</fixed-case> at <fixed-case>WASSA</fixed-case> 2021: Multi-task Learning and Transformer Finetuning for Emotion Classification and Empathy Prediction</title>
      <author><first>Jay</first><last>Mundra</last></author>
      <author><first>Rohan</first><last>Gupta</last></author>
      <author><first>Sagnik</first><last>Mukherjee</last></author>
      <pages>112–116</pages>
      <abstract>This paper describes our contribution to the WASSA 2021 shared task on Empathy Prediction and <a href="https://en.wikipedia.org/wiki/Emotion_classification">Emotion Classification</a>. The broad goal of this task was to model an empathy score, a distress score and the overall level of emotion of an essay written in response to a newspaper article associated with harm to someone. We have used the ELECTRA model abundantly and also advanced deep learning approaches like <a href="https://en.wikipedia.org/wiki/Multi-task_learning">multi-task learning</a>. Additionally, we also leveraged standard machine learning techniques like ensembling. Our system achieves a <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson Correlation Coefficient</a> of 0.533 on <a href="https://en.wikipedia.org/wiki/Task_(project_management)">sub-task</a> I and a macro F1 score of 0.5528 on sub-task II. We ranked 1st in <a href="https://en.wikipedia.org/wiki/Emotion_classification">Emotion Classification sub-task</a> and 3rd in Empathy Prediction sub-task.</abstract>
      <url hash="9a2eaece">2021.wassa-1.12</url>
      <attachment type="OptionalSupplementaryMaterial" hash="9586d646">2021.wassa-1.12.OptionalSupplementaryMaterial.zip</attachment>
      <bibkey>mundra-etal-2021-wassa</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/goemotions">GoEmotions</pwcdataset>
    </paper>
    <paper id="16">
      <title>Exploring Stylometric and Emotion-Based Features for Multilingual Cross-Domain Hate Speech Detection</title>
      <author><first>Ilia</first><last>Markov</last></author>
      <author><first>Nikola</first><last>Ljubešić</last></author>
      <author><first>Darja</first><last>Fišer</last></author>
      <author><first>Walter</first><last>Daelemans</last></author>
      <pages>149–159</pages>
      <abstract>In this paper, we describe experiments designed to evaluate the impact of stylometric and emotion-based features on hate speech detection : the task of classifying textual content into hate or non-hate speech classes. Our experiments are conducted for three languages   English, <a href="https://en.wikipedia.org/wiki/Slovene_language">Slovene</a>, and <a href="https://en.wikipedia.org/wiki/Dutch_language">Dutch</a>   both in in-domain and cross-domain setups, and aim to investigate <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a> using features that model two linguistic phenomena : the writing style of hateful social media content operationalized as function word usage on the one hand, and emotion expression in hateful messages on the other hand. The results of experiments with <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> that model different combinations of these phenomena support our hypothesis that stylometric and emotion-based features are robust indicators of <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a>. Their contribution remains persistent with respect to <a href="https://en.wikipedia.org/wiki/Variation_(linguistics)">domain and language variation</a>. We show that the combination of <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> that model the targeted phenomena outperforms words and character n-gram features under cross-domain conditions, and provides a significant boost to <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning models</a>, which currently obtain the best results, when combined with them in an <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble</a>.</abstract>
      <url hash="f428f44d">2021.wassa-1.16</url>
      <bibkey>markov-etal-2021-exploring</bibkey>
    </paper>
    <paper id="20">
      <title>Creating and Evaluating Resources for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> in the Low-resource Language : Sindhi<fixed-case>S</fixed-case>indhi</title>
      <author><first>Wazir</first><last>Ali</last></author>
      <author><first>Naveed</first><last>Ali</last></author>
      <author><first>Yong</first><last>Dai</last></author>
      <author><first>Jay</first><last>Kumar</last></author>
      <author><first>Saifullah</first><last>Tumrani</last></author>
      <author><first>Zenglin</first><last>Xu</last></author>
      <pages>188–194</pages>
      <abstract>In this paper, we develop Sindhi subjective lexicon using a merger of existing English resources : NRC lexicon, list of opinion words, SentiWordNet, Sindhi-English bilingual dictionary, and collection of Sindhi modifiers. The positive or negative sentiment score is assigned to each <a href="https://en.wikipedia.org/wiki/Sindhi_language">Sindhi opinion word</a>. Afterwards, we determine the coverage of the proposed <a href="https://en.wikipedia.org/wiki/Lexicon">lexicon</a> with subjectivity analysis. Moreover, we crawl multi-domain tweet corpus of news, sports, and finance. The crawled corpus is annotated by experienced annotators using the Doccano text annotation tool. The sentiment annotated corpus is evaluated by employing <a href="https://en.wikipedia.org/wiki/Support_vector_machine">support vector machine (SVM)</a>, <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network (RNN) variants</a>, and <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network (CNN)</a>.</abstract>
      <url hash="32aae211">2021.wassa-1.20</url>
      <bibkey>ali-etal-2021-creating</bibkey>
    </paper>
    <paper id="23">
      <title>L3CubeMahaSent : A Marathi Tweet-based Sentiment Analysis Dataset<fixed-case>L</fixed-case>3<fixed-case>C</fixed-case>ube<fixed-case>M</fixed-case>aha<fixed-case>S</fixed-case>ent: A <fixed-case>M</fixed-case>arathi Tweet-based Sentiment Analysis Dataset</title>
      <author><first>Atharva</first><last>Kulkarni</last></author>
      <author><first>Meet</first><last>Mandhane</last></author>
      <author><first>Manali</first><last>Likhitkar</last></author>
      <author><first>Gayatri</first><last>Kshirsagar</last></author>
      <author><first>Raviraj</first><last>Joshi</last></author>
      <pages>213–220</pages>
      <abstract>Sentiment analysis is one of the most fundamental tasks in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a>. Popular languages like <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a>, <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a>, <a href="https://en.wikipedia.org/wiki/Mandarin_Chinese">Mandarin</a>, and also Indian languages such as <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a>, <a href="https://en.wikipedia.org/wiki/Bengali_language">Bengali</a>, <a href="https://en.wikipedia.org/wiki/Tamil_language">Tamil</a> have seen a significant amount of work in this area. However, the <a href="https://en.wikipedia.org/wiki/Marathi_language">Marathi language</a> which is the third most popular language in India still lags behind due to the absence of proper datasets. In this paper, we present the first major publicly available Marathi Sentiment Analysis Dataset-L3CubeMahaSent. It is curated using tweets extracted from various Maharashtrian personalities’ Twitter accounts. Our <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> consists of ~16,000 distinct tweets classified in three broad classes viz. positive, negative, and neutral. We also present the guidelines using which we annotated the tweets. Finally, we present the statistics of our dataset and baseline classification results using CNN, LSTM, ULMFiT, and BERT based models.</abstract>
      <url hash="08200ad2">2021.wassa-1.23</url>
      <bibkey>kulkarni-etal-2021-l3cubemahasent</bibkey>
      <pwccode url="https://github.com/l3cube-pune/MarathiNLP" additional="false">l3cube-pune/MarathiNLP</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/l3cubemahasent">L3CubeMahaSent</pwcdataset>
    </paper>
    <paper id="26">
      <title>Me, myself, and ire : Effects of automatic transcription quality on <a href="https://en.wikipedia.org/wiki/Emotion">emotion</a>, <a href="https://en.wikipedia.org/wiki/Sarcasm">sarcasm</a>, and personality detection</title>
      <author><first>John</first><last>Culnan</last></author>
      <author><first>Seongjin</first><last>Park</last></author>
      <author><first>Meghavarshini</first><last>Krishnaswamy</last></author>
      <author><first>Rebecca</first><last>Sharp</last></author>
      <pages>250–256</pages>
      <abstract>In deployment, <a href="https://en.wikipedia.org/wiki/System">systems</a> that use <a href="https://en.wikipedia.org/wiki/Speech">speech</a> as input must make use of <a href="https://en.wikipedia.org/wiki/Transcription_(linguistics)">automated transcriptions</a>. Yet, typically when these <a href="https://en.wikipedia.org/wiki/System">systems</a> are evaluated, gold transcriptions are assumed. We explicitly examine the impact of transcription errors on the downstream performance of a multi-modal system on three related tasks from three datasets : <a href="https://en.wikipedia.org/wiki/Emotion">emotion</a>, <a href="https://en.wikipedia.org/wiki/Sarcasm">sarcasm</a>, and <a href="https://en.wikipedia.org/wiki/Personality_test">personality detection</a>. We include three separate transcription tools and show that while all automated transcriptions propagate errors that substantially impact downstream performance, the open-source tools fair worse than the paid tool, though not always straightforwardly, and word error rates do not correlate well with downstream performance. We further find that the inclusion of <a href="https://en.wikipedia.org/wiki/Audio_signal">audio features</a> partially mitigates <a href="https://en.wikipedia.org/wiki/Transcription_error">transcription errors</a>, but that a naive usage of a multi-task setup does not.</abstract>
      <url hash="cb4743b9">2021.wassa-1.26</url>
      <bibkey>culnan-etal-2021-ire</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/librispeech">LibriSpeech</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/meld">MELD</pwcdataset>
    </paper>
    <paper id="27">
      <title>Emotional RobBERT and Insensitive BERTje : Combining Transformers and Affect Lexica for Dutch Emotion Detection<fixed-case>R</fixed-case>ob<fixed-case>BERT</fixed-case> and Insensitive <fixed-case>BERT</fixed-case>je: Combining Transformers and Affect Lexica for <fixed-case>D</fixed-case>utch Emotion Detection</title>
      <author><first>Luna</first><last>De Bruyne</last></author>
      <author><first>Orphee</first><last>De Clercq</last></author>
      <author><first>Veronique</first><last>Hoste</last></author>
      <pages>257–263</pages>
      <abstract>In a first step towards improving Dutch emotion detection, we try to combine the Dutch transformer models BERTje and RobBERT with lexicon-based methods. We propose two architectures : one in which lexicon information is directly injected into the transformer model and a meta-learning approach where predictions from transformers are combined with lexicon features. The models are tested on 1,000 Dutch tweets and 1,000 captions from <a href="https://en.wikipedia.org/wiki/Television_show">TV-shows</a> which have been manually annotated with <a href="https://en.wikipedia.org/wiki/Emotion">emotion categories</a> and dimensions. We find that RobBERT clearly outperforms BERTje, but that directly adding lexicon information to transformers does not improve performance. In the meta-learning approach, lexicon information does have a positive effect on BERTje, but not on RobBERT. This suggests that more emotional information is already contained within this latter <a href="https://en.wikipedia.org/wiki/Language_model">language model</a>.</abstract>
      <url hash="41d89002">2021.wassa-1.27</url>
      <bibkey>de-bruyne-etal-2021-emotional</bibkey>
    </paper>
    <paper id="28">
      <title>EmpNa at WASSA 2021 : A Lightweight Model for the Prediction of <a href="https://en.wikipedia.org/wiki/Empathy">Empathy</a>, <a href="https://en.wikipedia.org/wiki/Psychological_stress">Distress</a> and <a href="https://en.wikipedia.org/wiki/Emotion">Emotions</a> from Reactions to News Stories<fixed-case>E</fixed-case>mp<fixed-case>N</fixed-case>a at <fixed-case>WASSA</fixed-case> 2021: A Lightweight Model for the Prediction of Empathy, Distress and Emotions from Reactions to News Stories</title>
      <author><first>Giuseppe</first><last>Vettigli</last></author>
      <author><first>Antonio</first><last>Sorgente</last></author>
      <pages>264–268</pages>
      <abstract>This paper describes our submission for the WASSA 2021 shared task regarding the prediction of empathy, distress and emotions from news stories. The solution is based on combining the frequency of words, lexicon-based information, demographics of the annotators and personality of the annotators into a <a href="https://en.wikipedia.org/wiki/Linear_model">linear model</a>. The prediction of empathy and distress is performed using <a href="https://en.wikipedia.org/wiki/Linear_regression">Linear Regression</a> while the prediction of emotions is performed using <a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic Regression</a>. Both <a href="https://en.wikipedia.org/wiki/Task_(computing)">tasks</a> are performed using the same <a href="https://en.wikipedia.org/wiki/Software_feature">features</a>. Our models rank 4th for the prediction of emotions and 2nd for the prediction of empathy and distress. These results are particularly interesting when considered that the computational requirements of the <a href="https://en.wikipedia.org/wiki/Solution">solution</a> are minimal.</abstract>
      <url hash="8c2cdbc4">2021.wassa-1.28</url>
      <attachment type="OptionalSupplementaryMaterial" hash="cf823096">2021.wassa-1.28.OptionalSupplementaryMaterial.html</attachment>
      <bibkey>vettigli-sorgente-2021-empna</bibkey>
    </paper>
    </volume>
</collection>