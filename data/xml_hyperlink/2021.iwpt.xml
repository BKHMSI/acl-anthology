<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.iwpt">
  <volume id="1" ingest-date="2021-07-25">
    <meta>
      <booktitle>Proceedings of the 17th International Conference on Parsing Technologies and the IWPT 2021 Shared Task on Parsing into Enhanced Universal Dependencies (IWPT 2021)</booktitle>
      <editor><first>Stephan</first><last>Oepen</last></editor>
      <editor><first>Kenji</first><last>Sagae</last></editor>
      <editor><first>Reut</first><last>Tsarfaty</last></editor>
      <editor><first>Gosse</first><last>Bouma</last></editor>
      <editor><first>Djamé</first><last>Seddah</last></editor>
      <editor><first>Daniel</first><last>Zeman</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>August</month>
      <year>2021</year>
      <url hash="05bb805f">2021.iwpt-1</url>
    </meta>
    <frontmatter>
      <url hash="bbff3db1">2021.iwpt-1.0</url>
      <bibkey>iwpt-2021-international</bibkey>
    </frontmatter>
    <paper id="8">
      <title>A Falta de Pan, Buenas Son Tortas : The Efficacy of Predicted UPOS Tags for Low Resource UD Parsing<fixed-case>UPOS</fixed-case> Tags for Low Resource <fixed-case>UD</fixed-case> Parsing</title>
      <author><first>Mark</first><last>Anderson</last></author>
      <author><first>Mathieu</first><last>Dehouck</last></author>
      <author><first>Carlos</first><last>Gómez-Rodríguez</last></author>
      <pages>78–83</pages>
      <abstract>We evaluate the efficacy of predicted UPOS tags as input features for dependency parsers in lower resource settings to evaluate how treebank size affects the impact tagging accuracy has on parsing performance. We do this for real low resource universal dependency treebanks, artificially low resource data with varying treebank sizes, and for very small treebanks with varying amounts of augmented data. We find that predicted UPOS tags are somewhat helpful for low resource treebanks, especially when fewer fully-annotated trees are available. We also find that this positive impact diminishes as the amount of data increases.</abstract>
      <url hash="dbd1e8db">2021.iwpt-1.8</url>
      <doi>10.18653/v1/2021.iwpt-1.8</doi>
      <bibkey>anderson-etal-2021-falta</bibkey>
    </paper>
    <paper id="9">
      <title>Multilingual Dependency Parsing for Low-Resource African Languages : Case Studies on <a href="https://en.wikipedia.org/wiki/Bambara_language">Bambara</a>, <a href="https://en.wikipedia.org/wiki/Wolof_language">Wolof</a>, and <a href="https://en.wikipedia.org/wiki/Yoruba_language">Yoruba</a><fixed-case>A</fixed-case>frican Languages: Case Studies on <fixed-case>B</fixed-case>ambara, <fixed-case>W</fixed-case>olof, and <fixed-case>Y</fixed-case>oruba</title>
      <author><first>Cheikh M. Bamba</first><last>Dione</last></author>
      <pages>84–92</pages>
      <abstract>This paper describes a <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> for syntactic knowledge transfer between high-resource languages to extremely low-resource languages. The methodology consists in leveraging multilingual BERT self-attention model pretrained on large datasets to develop a multilingual multi-task model that can predict Universal Dependencies annotations for three African low-resource languages. The UD annotations include universal part-of-speech, <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological features</a>, <a href="https://en.wikipedia.org/wiki/Lemma_(morphology)">lemmas</a>, and dependency trees. In our experiments, we used multilingual word embeddings and a total of 11 Universal Dependencies treebanks drawn from three high-resource languages (English, French, Norwegian) and three low-resource languages (Bambara, Wolof and Yoruba). We developed various <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> to test specific language combinations involving <a href="https://en.wikipedia.org/wiki/Language_contact">contemporary contact languages</a> or <a href="https://en.wikipedia.org/wiki/Genetic_relationship_(linguistics)">genetically related languages</a>. The results of the experiments show that multilingual models that involve high-resource languages and low-resource languages with contemporary contact between each other can provide better results than combinations that only include unrelated languages. As far genetic relationships are concerned, we could not draw any conclusion regarding the impact of language combinations involving the selected low-resource languages, namely <a href="https://en.wikipedia.org/wiki/Wolof_language">Wolof</a> and <a href="https://en.wikipedia.org/wiki/Yoruba_language">Yoruba</a>.</abstract>
      <url hash="b63a84ca">2021.iwpt-1.9</url>
      <doi>10.18653/v1/2021.iwpt-1.9</doi>
      <bibkey>dione-2021-multilingual</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="16">
      <title>COMBO : A New Module for EUD Parsing<fixed-case>COMBO</fixed-case>: A New Module for <fixed-case>EUD</fixed-case> Parsing</title>
      <author><first>Mateusz</first><last>Klimaszewski</last></author>
      <author><first>Alina</first><last>Wróblewska</last></author>
      <pages>158–166</pages>
      <abstract>We introduce the COMBO-based approach for EUD parsing and its implementation, which took part in the IWPT 2021 EUD shared task. The goal of this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> is to parse raw texts in 17 languages into Enhanced Universal Dependencies (EUD). The proposed approach uses COMBO to predict UD trees and EUD graphs. These <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">structures</a> are then merged into the final EUD graphs. Some EUD edge labels are extended with <a href="https://en.wikipedia.org/wiki/Case_(linguistics)">case information</a> using a single language-independent expansion rule. In the official evaluation, the solution ranked fourth, achieving an average ELAS of 83.79 %. The source code is available at https://gitlab.clarin-pl.eu/syntactic-tools/combo.</abstract>
      <url hash="922fdc8d">2021.iwpt-1.16</url>
      <doi>10.18653/v1/2021.iwpt-1.16</doi>
      <bibkey>klimaszewski-wroblewska-2021-combo</bibkey>
    </paper>
    <paper id="17">
      <title>Splitting EUD Graphs into Trees : A Quick and Clatty Approach<fixed-case>EUD</fixed-case> Graphs into Trees: A Quick and Clatty Approach</title>
      <author><first>Mark</first><last>Anderson</last></author>
      <author><first>Carlos</first><last>Gómez-Rodríguez</last></author>
      <pages>167–174</pages>
      <abstract>We present the system submission from the FASTPARSE team for the EUD Shared Task at IWPT 2021. We engaged in the task last year by focusing on <a href="https://en.wikipedia.org/wiki/Efficiency">efficiency</a>. This year we have focused on experimenting with new ideas on a limited time budget. Our system is based on splitting the EUD graph into several <a href="https://en.wikipedia.org/wiki/Tree_(graph_theory)">trees</a>, based on <a href="https://en.wikipedia.org/wiki/Linguistic_description">linguistic criteria</a>. We predict these <a href="https://en.wikipedia.org/wiki/Tree_(graph_theory)">trees</a> using a sequence-labelling parser and combine them into an EUD graph. The results were relatively poor, although not a total disaster and could probably be improved with some polishing of the system’s rough edges.</abstract>
      <url hash="3798df83">2021.iwpt-1.17</url>
      <doi>10.18653/v1/2021.iwpt-1.17</doi>
      <bibkey>anderson-gomez-rodriguez-2021-splitting</bibkey>
    </paper>
    <paper id="18">
      <title>Graph Rewriting for Enhanced Universal Dependencies<fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies</title>
      <author><first>Bruno</first><last>Guillaume</last></author>
      <author><first>Guy</first><last>Perrier</last></author>
      <pages>175–183</pages>
      <abstract>This paper describes a system proposed for the IWPT 2021 Shared Task on <a href="https://en.wikipedia.org/wiki/Parsing">Parsing</a> into Enhanced Universal Dependencies (EUD). We propose a Graph Rewriting based system for computing Enhanced Universal Dependencies, given the Basic Universal Dependencies (UD).</abstract>
      <url hash="3292791d">2021.iwpt-1.18</url>
      <doi>10.18653/v1/2021.iwpt-1.18</doi>
      <bibkey>guillaume-perrier-2021-graph</bibkey>
    </paper>
    <paper id="19">
      <title>Biaffine Dependency and Semantic Graph Parsing for EnhancedUniversal Dependencies<fixed-case>E</fixed-case>nhanced<fixed-case>U</fixed-case>niversal Dependencies</title>
      <author><first>Giuseppe</first><last>Attardi</last></author>
      <author><first>Daniele</first><last>Sartiano</last></author>
      <author><first>Maria</first><last>Simi</last></author>
      <pages>184–188</pages>
      <abstract>This paper presents the <a href="https://en.wikipedia.org/wiki/System">system</a> used in our submission to the IWPT 2021 Shared Task. This year the official evaluation metrics was <a href="https://en.wikipedia.org/wiki/ELAS">ELAS</a>, therefore dependency parsing might have been avoided as well as other pipeline stages like POS tagging and <a href="https://en.wikipedia.org/wiki/Lemmatization">lemmatization</a>. We nevertheless chose to deploy a combination of a dependency parser and a graph parser. The dependency parser is a biaffine parser, that uses transformers for representing input sentences, with no other feature. The graph parser is a <a href="https://en.wikipedia.org/wiki/Semantic_parser">semantic parser</a> that exploits a similar architecture except for using a sigmoid crossentropy loss function to return multiple values for the predicted arcs. The final output is obtained by merging the output of the two <a href="https://en.wikipedia.org/wiki/Parsing">parsers</a>. The dependency parser achieves top or close to top LAS performance with respect to other systems that report results on such metrics, except on low resource languages (Tamil, Estonian, Latvian).<i>IWPT 2021 Shared Task</i>. This year the official evaluation metrics was ELAS, therefore dependency parsing might have been avoided as well as other pipeline stages like POS tagging and lemmatization. We nevertheless chose to deploy a combination of a dependency parser and a graph parser. The dependency parser is a biaffine parser, that uses transformers for representing input sentences, with no other feature. The graph parser is a semantic parser that exploits a similar architecture except for using a sigmoid crossentropy loss function to return multiple values for the predicted arcs. The final output is obtained by merging the output of the two parsers. The dependency parser achieves top or close to top LAS performance with respect to other systems that report results on such metrics, except on low resource languages (Tamil, Estonian, Latvian).</abstract>
      <url hash="3262b981">2021.iwpt-1.19</url>
      <doi>10.18653/v1/2021.iwpt-1.19</doi>
      <bibkey>attardi-etal-2021-biaffine</bibkey>
    </paper>
    <paper id="21">
      <title>RobertNLP at the IWPT 2021 Shared Task : Simple Enhanced UD Parsing for 17 Languages<fixed-case>R</fixed-case>obert<fixed-case>NLP</fixed-case> at the <fixed-case>IWPT</fixed-case> 2021 Shared Task: Simple Enhanced <fixed-case>UD</fixed-case> Parsing for 17 Languages</title>
      <author><first>Stefan</first><last>Grünewald</last></author>
      <author><first>Frederik Tobias</first><last>Oertel</last></author>
      <author><first>Annemarie</first><last>Friedrich</last></author>
      <pages>196–203</pages>
      <abstract>This paper presents our multilingual dependency parsing system as used in the IWPT 2021 Shared Task on Parsing into Enhanced Universal Dependencies. Our system consists of an unfactorized biaffine classifier that operates directly on fine-tuned XLM-R embeddings and generates enhanced UD graphs by predicting the best dependency label (or absence of a dependency) for each pair of tokens. To avoid sparsity issues resulting from lexicalized dependency labels, we replace lexical items in relations with placeholders at training and prediction time, later retrieving them from the parse via a hybrid rule-based / machine-learning system. In addition, we utilize model ensembling at prediction time. Our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves high parsing accuracy on the <a href="https://en.wikipedia.org/wiki/Blinded_experiment">blind test data</a>, ranking 3rd out of 9 with an average ELAS F1 score of 86.97.</abstract>
      <url hash="477cec25">2021.iwpt-1.21</url>
      <doi>10.18653/v1/2021.iwpt-1.21</doi>
      <bibkey>grunewald-etal-2021-robertnlp</bibkey>
    </paper>
    </volume>
</collection>