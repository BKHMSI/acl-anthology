<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.iwltp">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the 1st International Workshop on Language Technology Platforms</booktitle>
      <editor><first>Georg</first><last>Rehm</last></editor>
      <editor><first>Kalina</first><last>Bontcheva</last></editor>
      <editor><first>Khalid</first><last>Choukri</last></editor>
      <editor><first>Jan</first><last>Hajič</last></editor>
      <editor><first>Stelios</first><last>Piperidis</last></editor>
      <editor><first>Andrejs</first><last>Vasiļjevs</last></editor>
      <publisher>European Language Resources Association</publisher>
      <address>Marseille, France</address>
      <month>May</month>
      <year>2020</year>
      <isbn>979-10-95546-64-1</isbn>
    </meta>
    <frontmatter>
      <url hash="f3e35d43">2020.iwltp-1.0</url>
      <bibkey>iwltp-2020-international</bibkey>
    </frontmatter>
    <paper id="5">
      <title>CLARIN : Distributed Language Resources and Technology in a European Infrastructure<fixed-case>CLARIN</fixed-case>: Distributed Language Resources and Technology in a <fixed-case>E</fixed-case>uropean Infrastructure</title>
      <author><first>Maria</first><last>Eskevich</last></author>
      <author><first>Franciska</first><last>de Jong</last></author>
      <author><first>Alexander</first><last>König</last></author>
      <author><first>Darja</first><last>Fišer</last></author>
      <author><first>Dieter</first><last>Van Uytvanck</last></author>
      <author><first>Tero</first><last>Aalto</last></author>
      <author><first>Lars</first><last>Borin</last></author>
      <author><first>Olga</first><last>Gerassimenko</last></author>
      <author><first>Jan</first><last>Hajic</last></author>
      <author><first>Henk</first><last>van den Heuvel</last></author>
      <author><first>Neeme</first><last>Kahusk</last></author>
      <author><first>Krista</first><last>Liin</last></author>
      <author><first>Martin</first><last>Matthiesen</last></author>
      <author><first>Stelios</first><last>Piperidis</last></author>
      <author><first>Kadri</first><last>Vider</last></author>
      <pages>28–34</pages>
      <abstract>CLARIN is a European Research Infrastructure providing access to digital language resources and tools from across Europe and beyond to researchers in the humanities and social sciences. This paper focuses on <a href="https://en.wikipedia.org/wiki/CLARIN">CLARIN</a> as a platform for the sharing of language resources. It zooms in on the service offer for the aggregation of language repositories and the value proposition for a number of communities that benefit from the enhanced visibility of their data and services as a result of integration in <a href="https://en.wikipedia.org/wiki/CLARIN">CLARIN</a>. The enhanced findability of language resources is serving the social sciences and humanities (SSH) community at large and supports research communities that aim to collaborate based on virtual collections for a specific domain. The paper also addresses the wider landscape of service platforms based on language technologies which has the potential of becoming a powerful set of interoperable facilities to a variety of communities of use.</abstract>
      <url hash="393821fc">2020.iwltp-1.5</url>
      <language>eng</language>
      <bibkey>eskevich-etal-2020-clarin</bibkey>
    </paper>
    <paper id="7">
      <title>Removing European Language Barriers with Innovative Machine Translation Technology<fixed-case>E</fixed-case>uropean Language Barriers with Innovative Machine Translation Technology</title>
      <author><first>Dario</first><last>Franceschini</last></author>
      <author><first>Chiara</first><last>Canton</last></author>
      <author><first>Ivan</first><last>Simonini</last></author>
      <author><first>Armin</first><last>Schweinfurth</last></author>
      <author><first>Adelheid</first><last>Glott</last></author>
      <author><first>Sebastian</first><last>Stüker</last></author>
      <author><first>Thai-Son</first><last>Nguyen</last></author>
      <author><first>Felix</first><last>Schneider</last></author>
      <author><first>Thanh-Le</first><last>Ha</last></author>
      <author><first>Alex</first><last>Waibel</last></author>
      <author><first>Barry</first><last>Haddow</last></author>
      <author><first>Philip</first><last>Williams</last></author>
      <author><first>Rico</first><last>Sennrich</last></author>
      <author><first>Ondřej</first><last>Bojar</last></author>
      <author><first>Sangeet</first><last>Sagar</last></author>
      <author><first>Dominik</first><last>Macháček</last></author>
      <author><first>Otakar</first><last>Smrž</last></author>
      <pages>44–49</pages>
      <abstract>This paper presents our progress towards deploying a versatile communication platform in the task of highly multilingual live speech translation for <a href="https://en.wikipedia.org/wiki/Convention_(meeting)">conferences</a> and remote meetings live subtitling. The <a href="https://en.wikipedia.org/wiki/Computing_platform">platform</a> has been designed with a focus on very low latency and high flexibility while allowing research prototypes of speech and text processing tools to be easily connected, regardless of where they physically run. We outline our architecture solution and also briefly compare it with the ELG platform. Technical details are provided on the most important components and we summarize the test deployment events we ran so far.</abstract>
      <url hash="caf2ba11">2020.iwltp-1.7</url>
      <language>eng</language>
      <bibkey>franceschini-etal-2020-removing</bibkey>
    </paper>
    <paper id="9">
      <title>The Kairntech Sherpa   An ML Platform and <a href="https://en.wikipedia.org/wiki/Application_programming_interface">API</a> for the Enrichment of (not only) Scientific Content<fixed-case>K</fixed-case>airntech <fixed-case>S</fixed-case>herpa – An <fixed-case>ML</fixed-case> Platform and <fixed-case>API</fixed-case> for the Enrichment of (not only) Scientific Content</title>
      <author><first>Stefan</first><last>Geißler</last></author>
      <pages>54–58</pages>
      <abstract>We present an <a href="https://en.wikipedia.org/wiki/Computing_platform">software platform</a> and <a href="https://en.wikipedia.org/wiki/Application_programming_interface">API</a> that combines various ML and NLP approaches for the analysis and enrichment of textual content. The <a href="https://en.wikipedia.org/wiki/Computing_platform">platform</a>’s design and implementation is guided by the goal to allow non-technical users to conduct their own experiments and training runs on their respective data, allowing to test, tune and deploy analysis models for production. Dedicated specific packages for subtasks such as document structure processing, document categorization, annotation with existing thesauri, disambiguation and linking, annotation with newly created entity recognizers and summarization   available as open source components in isolation   are combined into an end-user-facing, collaborative, scalable platform to support large-scale industrial document analysis document analysis. We see the Sherpa’s setup as an answer to the observation that ML has reached a level of maturity that allows to attain useful results in many analysis scenarios today, but that in-depth technical competencies in the required fields of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> and <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">AI</a> is often scarce ; a setup that focusses on non-technical domain-expert end-users can help to bring required analysis functionalities closer to the day-to-day reality in business contexts.</abstract>
      <url hash="95decbaa">2020.iwltp-1.9</url>
      <language>eng</language>
      <bibkey>geissler-2020-kairntech</bibkey>
    </paper>
    <paper id="11">
      <title>NTeALan Dictionaries Platforms : An Example Of Collaboration-Based Model<fixed-case>NT</fixed-case>e<fixed-case>AL</fixed-case>an Dictionaries Platforms: An Example Of Collaboration-Based Model</title>
      <author><first>Elvis</first><last>Mboning</last></author>
      <author><first>Daniel</first><last>Baleba</last></author>
      <author><first>Jean Marc</first><last>Bassahak</last></author>
      <author><first>Ornella</first><last>Wandji</last></author>
      <author><first>Jules</first><last>Assoumou</last></author>
      <pages>66–72</pages>
      <abstract>Nowadays the scarcity and dispersion of open-source NLP resources and tools in and for <a href="https://en.wikipedia.org/wiki/Languages_of_Africa">African languages</a> make it difficult for researchers to truly fit these <a href="https://en.wikipedia.org/wiki/Language">languages</a> into current algorithms of <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">artificial intelligence</a>, resulting in the stagnation of these numerous <a href="https://en.wikipedia.org/wiki/Language">languages</a>, as far as technological progress is concerned. Created in 2017, with the aim of building communities of voluntary contributors around African native and/or national languages, cultures, <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP technologies</a> and <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">artificial intelligence</a>, the NTeALan association has set up a series of web collaborative platforms intended to allow the aforementioned communities to create and manage their own lexicographic and linguistic resources. This paper aims at presenting the first versions of three lexicographic platforms that we developed in and for African languages : the REST / GraphQL API for saving lexicographic resources, the dictionary management platform and the collaborative dictionary platform. We also describe the <a href="https://en.wikipedia.org/wiki/Data_format">data representation format</a> used for these <a href="https://en.wikipedia.org/wiki/Resource_(computer_science)">resources</a>. After experimenting with a few dictionaries and looking at users feedback, we are convinced that only collaboration-based approaches and platforms can effectively respond to challenges of producing quality resources in and for African native and/or national languages.</abstract>
      <url hash="f29bf517">2020.iwltp-1.11</url>
      <language>eng</language>
      <bibkey>mboning-etal-2020-ntealan</bibkey>
    </paper>
    <paper id="12">
      <title>A Workflow Manager for Complex NLP and Content Curation Workflows<fixed-case>NLP</fixed-case> and Content Curation Workflows</title>
      <author><first>Julian</first><last>Moreno-Schneider</last></author>
      <author><first>Peter</first><last>Bourgonje</last></author>
      <author><first>Florian</first><last>Kintzel</last></author>
      <author><first>Georg</first><last>Rehm</last></author>
      <pages>73–80</pages>
      <abstract>We present a <a href="https://en.wikipedia.org/wiki/Workflow_management_system">workflow manager</a> for the flexible creation and customisation of NLP processing pipelines. The workflow manager addresses challenges in <a href="https://en.wikipedia.org/wiki/Interoperability">interoperability</a> across various different NLP tasks and hardware-based resource usage. Based on the four key principles of <a href="https://en.wikipedia.org/wiki/Generality">generality</a>, <a href="https://en.wikipedia.org/wiki/Flexibility_(engineering)">flexibility</a>, <a href="https://en.wikipedia.org/wiki/Scalability">scalability</a> and <a href="https://en.wikipedia.org/wiki/Efficiency">efficiency</a>, we present the first version of the workflow manager by providing details on its custom definition language, explaining the communication components and the general system architecture and setup. We currently implement the <a href="https://en.wikipedia.org/wiki/System">system</a>, which is grounded and motivated by real-world industry use cases in several innovation and transfer projects.</abstract>
      <url hash="07e98d23">2020.iwltp-1.12</url>
      <language>eng</language>
      <bibkey>moreno-schneider-etal-2020-workflow</bibkey>
    </paper>
    </volume>
</collection>