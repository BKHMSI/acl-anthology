<?xml version='1.0' encoding='utf-8'?>
<collection id="N19">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the 2019 Conference of the North <fixed-case>A</fixed-case>merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</booktitle>
      <url hash="edf15e9e">N19-1</url>
      <editor><first>Jill</first><last>Burstein</last></editor>
      <editor><first>Christy</first><last>Doran</last></editor>
      <editor><first>Thamar</first><last>Solorio</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url hash="ee6c72a4">N19-1000</url>
      <bibkey>naacl-2019-2019</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Entity Recognition at First Sight : Improving <a href="https://en.wikipedia.org/wiki/Near-sightedness">NER</a> with Eye Movement Information<fixed-case>I</fixed-case>mproving <fixed-case>NER</fixed-case> with Eye Movement Information</title>
      <author><first>Nora</first><last>Hollenstein</last></author>
      <author><first>Ce</first><last>Zhang</last></author>
      <pages>1–10</pages>
      <abstract>Previous research shows that eye-tracking data contains information about the lexical and syntactic properties of text, which can be used to improve <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language processing models</a>. In this work, we leverage eye movement features from three corpora with recorded gaze information to augment a state-of-the-art neural model for <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition (NER)</a> with gaze embeddings. These <a href="https://en.wikipedia.org/wiki/Corpus_linguistics">corpora</a> were manually annotated with named entity labels. Moreover, we show how gaze features, generalized on word type level, eliminate the need for recorded eye-tracking data at test time. The gaze-augmented models for NER using token-level and type-level features outperform the baselines. We present the benefits of eye-tracking features by evaluating the NER models on both individual datasets as well as in cross-domain settings.</abstract>
      <url hash="29eb9381">N19-1001</url>
      <video href="https://vimeo.com/347364761" />
      <doi>10.18653/v1/N19-1001</doi>
      <bibkey>hollenstein-zhang-2019-entity</bibkey>
      <pwccode url="https://github.com/DS3Lab/ner-at-first-sight" additional="false">DS3Lab/ner-at-first-sight</pwccode>
    </paper>
    <paper id="2">
      <title>The emergence of number and syntax units in LSTM language models<fixed-case>LSTM</fixed-case> language models</title>
      <author><first>Yair</first><last>Lakretz</last></author>
      <author><first>German</first><last>Kruszewski</last></author>
      <author><first>Theo</first><last>Desbordes</last></author>
      <author><first>Dieuwke</first><last>Hupkes</last></author>
      <author><first>Stanislas</first><last>Dehaene</last></author>
      <author><first>Marco</first><last>Baroni</last></author>
      <pages>11–20</pages>
      <abstract>Recent work has shown that LSTMs trained on a generic language modeling objective capture syntax-sensitive generalizations such as long-distance number agreement. We have however no mechanistic understanding of how they accomplish this remarkable feat. Some have conjectured it depends on <a href="https://en.wikipedia.org/wiki/Heuristic">heuristics</a> that do not truly take <a href="https://en.wikipedia.org/wiki/Hierarchical_organization">hierarchical structure</a> into account. We present here a detailed study of the inner mechanics of number tracking in LSTMs at the single neuron level. We discover that long-distance number information is largely managed by two number units. Importantly, the behaviour of these <a href="https://en.wikipedia.org/wiki/Unit_of_measurement">units</a> is partially controlled by other units independently shown to track <a href="https://en.wikipedia.org/wiki/Syntax">syntactic structure</a>. We conclude that LSTMs are, to some extent, implementing genuinely syntactic processing mechanisms, paving the way to a more general understanding of grammatical encoding in LSTMs.</abstract>
      <url hash="4ee63d7e">N19-1002</url>
      <attachment type="supplementary" hash="f6e78112">N19-1002.Supplementary.pdf</attachment>
      <video href="https://vimeo.com/347368203" />
      <doi>10.18653/v1/N19-1002</doi>
      <bibkey>lakretz-etal-2019-emergence</bibkey>
      <pwccode url="https://github.com/FAIRNS/Number_and_syntax_units_in_LSTM_LMs" additional="false">FAIRNS/Number_and_syntax_units_in_LSTM_LMs</pwccode>
    </paper>
    <paper id="4">
      <title>Neural language models as psycholinguistic subjects : Representations of syntactic state</title>
      <author><first>Richard</first><last>Futrell</last></author>
      <author><first>Ethan</first><last>Wilcox</last></author>
      <author><first>Takashi</first><last>Morita</last></author>
      <author><first>Peng</first><last>Qian</last></author>
      <author><first>Miguel</first><last>Ballesteros</last></author>
      <author><first>Roger</first><last>Levy</last></author>
      <pages>32–42</pages>
      <abstract>We investigate the extent to which the behavior of neural network language models reflects incremental representations of syntactic state. To do so, we employ experimental methodologies which were originally developed in the field of <a href="https://en.wikipedia.org/wiki/Psycholinguistics">psycholinguistics</a> to study syntactic representation in the human mind. We examine neural network model behavior on sets of artificial sentences containing a variety of syntactically complex structures. These sentences not only test whether the <a href="https://en.wikipedia.org/wiki/Social_network">networks</a> have a representation of syntactic state, they also reveal the specific lexical cues that <a href="https://en.wikipedia.org/wiki/Social_network">networks</a> use to update these states. We test four models : two publicly available LSTM sequence models of English (Jozefowicz et al., 2016 ; Gulordava et al., 2018) trained on large datasets ; an RNN Grammar (Dyer et al., 2016) trained on a small, parsed dataset ; and an LSTM trained on the same small corpus as the RNNG. We find evidence for basic syntactic state representations in all <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a>, but only the <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> trained on large datasets are sensitive to subtle lexical cues signaling changes in syntactic state.</abstract>
      <url hash="88ac5627">N19-1004</url>
      <video href="https://vimeo.com/347377574" />
      <doi>10.18653/v1/N19-1004</doi>
      <bibkey>futrell-etal-2019-neural</bibkey>
      <pwccode url="https://github.com/langprocgroup/nn_syntactic_state" additional="false">langprocgroup/nn_syntactic_state</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/billion-word-benchmark">Billion Word Benchmark</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="5">
      <title>Understanding language-elicited EEG data by predicting it from a fine-tuned language model<fixed-case>EEG</fixed-case> data by predicting it from a fine-tuned language model</title>
      <author><first>Dan</first><last>Schwartz</last></author>
      <author><first>Tom</first><last>Mitchell</last></author>
      <pages>43–57</pages>
      <abstract>Electroencephalography (EEG) recordings of brain activity taken while participants read or listen to language are widely used within the <a href="https://en.wikipedia.org/wiki/Cognitive_neuroscience">cognitive neuroscience</a> and psycholinguistics communities as a tool to study <a href="https://en.wikipedia.org/wiki/Sentence_processing">language comprehension</a>. Several time-locked stereotyped EEG responses to word-presentations   known collectively as event-related potentials (ERPs)   are thought to be markers for semantic or syntactic processes that take place during comprehension. However, the characterization of each individual <a href="https://en.wikipedia.org/wiki/Enterprise_resource_planning">ERP</a> in terms of what features of a stream of language trigger the response remains controversial. Improving this characterization would make ERPs a more useful tool for studying <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">language comprehension</a>. We take a step towards better understanding the ERPs by finetuning a <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> to predict them. This new approach to analysis shows for the first time that all of the ERPs are predictable from embeddings of a stream of language. Prior work has only found two of the <a href="https://en.wikipedia.org/wiki/Excitatory_postsynaptic_potential">ERPs</a> to be predictable. In addition to this <a href="https://en.wikipedia.org/wiki/Analysis">analysis</a>, we examine which ERPs benefit from sharing parameters during joint training. We find that two pairs of <a href="https://en.wikipedia.org/wiki/Excitatory_postsynaptic_potential">ERPs</a> previously identified in the literature as being related to each other benefit from joint training, while several other pairs of <a href="https://en.wikipedia.org/wiki/Excitatory_postsynaptic_potential">ERPs</a> that benefit from joint training are suggestive of potential relationships. Extensions of this analysis that further examine what kinds of information in the model embeddings relate to each ERP have the potential to elucidate the processes involved in human language comprehension.</abstract>
      <url hash="2cd2eebf">N19-1005</url>
      <video href="https://vimeo.com/347381430" />
      <doi>10.18653/v1/N19-1005</doi>
      <bibkey>schwartz-mitchell-2019-understanding</bibkey>
    </paper>
    <paper id="7">
      <title>Measuring the perceptual availability of <a href="https://en.wikipedia.org/wiki/Phonology">phonological features</a> during <a href="https://en.wikipedia.org/wiki/Language_acquisition">language acquisition</a> using unsupervised binary stochastic autoencoders</title>
      <author><first>Cory</first><last>Shain</last></author>
      <author><first>Micha</first><last>Elsner</last></author>
      <pages>69–85</pages>
      <abstract>In this paper, we deploy binary stochastic neural autoencoder networks as models of infant language learning in two typologically unrelated languages (Xitsonga and English). We show that the drive to model auditory percepts leads to latent clusters that partially align with theory-driven phonemic categories. We further evaluate the degree to which theory-driven phonological features are encoded in the latent bit patterns, finding that some (e.g. [ + -approximant ]), are well represented by the <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">network</a> in both languages, while others (e.g. [ + -spread glottis ]) are less so. Together, these findings suggest that many reliable cues to phonemic structure are immediately available to infants from <a href="https://en.wikipedia.org/wiki/Top-down_and_bottom-up_design">bottom-up perceptual characteristics</a> alone, but that these cues must eventually be supplemented by <a href="https://en.wikipedia.org/wiki/Top-down_and_bottom-up_design">top-down lexical and phonotactic information</a> to achieve adult-like phone discrimination. Our results also suggest differences in degree of perceptual availability between <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">features</a>, yielding testable predictions as to which <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">features</a> might depend more or less heavily on <a href="https://en.wikipedia.org/wiki/Top-down_and_bottom-up_design">top-down cues</a> during child language acquisition.</abstract>
      <url hash="aaeb7416">N19-1007</url>
      <doi>10.18653/v1/N19-1007</doi>
      <video href="https://vimeo.com/353440477" />
      <bibkey>shain-elsner-2019-measuring</bibkey>
    </paper>
    <paper id="8">
      <title>Giving Attention to the Unexpected : Using Prosody Innovations in Disfluency Detection</title>
      <author><first>Vicky</first><last>Zayats</last></author>
      <author><first>Mari</first><last>Ostendorf</last></author>
      <pages>86–95</pages>
      <abstract>Disfluencies in spontaneous speech are known to be associated with prosodic disruptions. However, most <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> for disfluency detection use only <a href="https://en.wikipedia.org/wiki/Transcription_(linguistics)">word transcripts</a>. Integrating prosodic cues has proved difficult because of the many sources of variability affecting the acoustic correlates. This paper introduces a new approach to extracting acoustic-prosodic cues using text-based distributional prediction of acoustic cues to derive vector z-score features (innovations). We explore both early and late fusion techniques for integrating text and prosody, showing gains over a high-accuracy text-only model.</abstract>
      <url hash="df1260be">N19-1008</url>
      <doi>10.18653/v1/N19-1008</doi>
      <video href="https://vimeo.com/353444632" />
      <bibkey>zayats-ostendorf-2019-giving</bibkey>
    </paper>
    <paper id="9">
      <title>Massively Multilingual Adversarial Speech Recognition</title>
      <author><first>Oliver</first><last>Adams</last></author>
      <author><first>Matthew</first><last>Wiesner</last></author>
      <author><first>Shinji</first><last>Watanabe</last></author>
      <author><first>David</first><last>Yarowsky</last></author>
      <pages>96–108</pages>
      <abstract>We report on adaptation of multilingual end-to-end speech recognition models trained on as many as 100 languages. Our findings shed light on the relative importance of similarity between the target and pretraining languages along the dimensions of <a href="https://en.wikipedia.org/wiki/Phonetics">phonetics</a>, <a href="https://en.wikipedia.org/wiki/Phonology">phonology</a>, <a href="https://en.wikipedia.org/wiki/Language_family">language family</a>, geographical location, and <a href="https://en.wikipedia.org/wiki/Orthography">orthography</a>. In this context, experiments demonstrate the effectiveness of two additional pretraining objectives in encouraging language-independent encoder representations : a context-independent phoneme objective paired with a language-adversarial classification objective.</abstract>
      <url hash="da283ebd">N19-1009</url>
      <doi>10.18653/v1/N19-1009</doi>
      <video href="https://vimeo.com/353450338" />
      <bibkey>adams-etal-2019-massively</bibkey>
    </paper>
    <paper id="13">
      <title>Answer-based Adversarial Training for Generating Clarification Questions<fixed-case>A</fixed-case>nswer-based <fixed-case>A</fixed-case>dversarial <fixed-case>T</fixed-case>raining for <fixed-case>G</fixed-case>enerating <fixed-case>C</fixed-case>larification <fixed-case>Q</fixed-case>uestions</title>
      <author><first>Sudha</first><last>Rao</last></author>
      <author><first>Hal</first><last>Daumé III</last></author>
      <pages>143–155</pages>
      <abstract>We present an approach for generating clarification questions with the goal of eliciting new information that would make the given textual context more complete. We propose that modeling hypothetical answers (to clarification questions) as <a href="https://en.wikipedia.org/wiki/Latent_variable">latent variables</a> can guide our approach into generating more useful clarification questions. We develop a Generative Adversarial Network (GAN) where the generator is a sequence-to-sequence model and the discriminator is a utility function that models the value of updating the context with the answer to the clarification question. We evaluate on two datasets, using both automatic metrics and human judgments of usefulness, specificity and relevance, showing that our approach outperforms both a retrieval-based model and ablations that exclude the utility model and the adversarial training.</abstract>
      <url hash="a35dfddf">N19-1013</url>
      <attachment type="supplementary" hash="9e3a40d3">N19-1013.Supplementary.pdf</attachment>
      <doi>10.18653/v1/N19-1013</doi>
      <video href="https://vimeo.com/353418933" />
      <bibkey>rao-daume-iii-2019-answer</bibkey>
      <pwccode url="https://github.com/raosudha89/clarification_question_generation_pytorch" additional="false">raosudha89/clarification_question_generation_pytorch</pwccode>
    </paper>
    <paper id="14">
      <title>Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data</title>
      <author><first>Wei</first><last>Zhao</last></author>
      <author><first>Liang</first><last>Wang</last></author>
      <author><first>Kewei</first><last>Shen</last></author>
      <author><first>Ruoyu</first><last>Jia</last></author>
      <author><first>Jingming</first><last>Liu</last></author>
      <pages>156–165</pages>
      <abstract>Neural machine translation systems have become state-of-the-art approaches for Grammatical Error Correction (GEC) task. In this paper, we propose a copy-augmented architecture for the GEC task by copying the unchanged words from the source sentence to the target sentence. Since the GEC suffers from not having enough labeled training data to achieve high <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>. We pre-train the copy-augmented architecture with a denoising auto-encoder using the unlabeled One Billion Benchmark and make comparisons between the fully pre-trained model and a partially pre-trained model. It is the first time copying words from the source context and fully pre-training a sequence to sequence model are experimented on the GEC task. Moreover, We add token-level and sentence-level multi-task learning for the GEC task. The evaluation results on the CoNLL-2014 test set show that our approach outperforms all recently published state-of-the-art results by a large margin.</abstract>
      <url hash="089daf99">N19-1014</url>
      <doi>10.18653/v1/N19-1014</doi>
      <video href="https://vimeo.com/353425373" />
      <bibkey>zhao-etal-2019-improving</bibkey>
      <pwccode url="https://github.com/zhawe01/fairseq-gec" additional="true">zhawe01/fairseq-gec</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/billion-word-benchmark">Billion Word Benchmark</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2014-shared-task-grammatical-error">CoNLL-2014 Shared Task: Grammatical Error Correction</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/fce">FCE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/jfleg">JFLEG</pwcdataset>
    </paper>
    <paper id="15">
      <title>Topic-Guided Variational Auto-Encoder for Text Generation</title>
      <author><first>Wenlin</first><last>Wang</last></author>
      <author><first>Zhe</first><last>Gan</last></author>
      <author><first>Hongteng</first><last>Xu</last></author>
      <author><first>Ruiyi</first><last>Zhang</last></author>
      <author><first>Guoyin</first><last>Wang</last></author>
      <author><first>Dinghan</first><last>Shen</last></author>
      <author><first>Changyou</first><last>Chen</last></author>
      <author><first>Lawrence</first><last>Carin</last></author>
      <pages>166–177</pages>
      <abstract>We propose a topic-guided variational auto-encoder (TGVAE) model for text generation. Distinct from existing variational auto-encoder (VAE) based approaches, which assume a simple Gaussian prior for latent code, our model specifies the prior as a Gaussian mixture model (GMM) parametrized by a neural topic module. Each mixture component corresponds to a latent topic, which provides a guidance to generate sentences under the topic. The neural topic module and the VAE-based neural sequence module in our model are learned jointly. In particular, a sequence of invertible Householder transformations is applied to endow the approximate posterior of the latent code with high flexibility during the <a href="https://en.wikipedia.org/wiki/Statistical_inference">model inference</a>. Experimental results show that our TGVAE outperforms its competitors on both unconditional and conditional text generation, which can also generate semantically-meaningful sentences with various topics.</abstract>
      <url hash="a40897e3">N19-1015</url>
      <doi>10.18653/v1/N19-1015</doi>
      <video href="https://vimeo.com/353433493" />
      <bibkey>wang-etal-2019-topic</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
    </paper>
    <paper id="18">
      <title>Discontinuous Constituency Parsing with a Stack-Free Transition System and a Dynamic Oracle</title>
      <author><first>Maximin</first><last>Coavoux</last></author>
      <author><first>Shay B.</first><last>Cohen</last></author>
      <pages>204–217</pages>
      <abstract>We introduce a novel <a href="https://en.wikipedia.org/wiki/Transition_system">transition system</a> for discontinuous constituency parsing. Instead of storing subtrees in a <a href="https://en.wikipedia.org/wiki/Stack_(abstract_data_type)">stack</a> i.e. a <a href="https://en.wikipedia.org/wiki/Data_structure">data structure</a> with linear-time sequential access the proposed system uses a set of parsing items, with constant-time random access. This change makes it possible to construct any discontinuous constituency tree in exactly 4n2 transitions for a sentence of length n. At each parsing step, the <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> considers every item in the set to be combined with a focus item and to construct a new constituent in a bottom-up fashion. The parsing strategy is based on the assumption that most syntactic structures can be parsed incrementally and that the set the memory of the <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> remains reasonably small on average. Moreover, we introduce a provably correct dynamic oracle for the new transition system, and present the first experiments in discontinuous constituency parsing using a dynamic oracle. Our <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> obtains state-of-the-art results on three English and German discontinuous treebanks.<tex-math>4n–2</tex-math> transitions for a sentence of length n. At each parsing step, the parser considers every item in the set to be combined with a focus item and to construct a new constituent in a bottom-up fashion. The parsing strategy is based on the assumption that most syntactic structures can be parsed incrementally and that the set –the memory of the parser– remains reasonably small on average. Moreover, we introduce a provably correct dynamic oracle for the new transition system, and present the first experiments in discontinuous constituency parsing using a dynamic oracle. Our parser obtains state-of-the-art results on three English and German discontinuous treebanks.</abstract>
      <url hash="78e32d04">N19-1018</url>
      <doi>10.18653/v1/N19-1018</doi>
      <video href="https://vimeo.com/360494509" />
      <bibkey>coavoux-cohen-2019-discontinuous</bibkey>
      <pwccode url="https://gitlab.com/mcoavoux/discoparset" additional="false">mcoavoux/discoparset</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="20">
      <title>CCG Parsing Algorithm with Incremental Tree Rotation<fixed-case>CCG</fixed-case> Parsing Algorithm with Incremental Tree Rotation</title>
      <author><first>Miloš</first><last>Stanojević</last></author>
      <author><first>Mark</first><last>Steedman</last></author>
      <pages>228–239</pages>
      <abstract>The main obstacle to incremental sentence processing arises from right-branching constituent structures, which are present in the majority of English sentences, as well as optional constituents that adjoin on the right, such as <a href="https://en.wikipedia.org/wiki/Adjunct_(grammar)">right adjuncts</a> and right conjuncts. In CCG, many right-branching derivations can be replaced by semantically equivalent left-branching incremental derivations. The problem of right-adjunction is more resistant to solution, and has been tackled in the past using revealing-based approaches that often rely either on the <a href="https://en.wikipedia.org/wiki/Unification_(computer_science)">higher-order unification</a> over lambda terms (Pareschi and Steedman,1987) or heuristics over dependency representations that do not cover the whole CCGbank (Ambati et al., 2015). We propose a new incremental parsing algorithm for CCG following the same revealing tradition of work but having a purely syntactic approach that does not depend on access to a distinct level of semantic representation. This <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> can cover the whole CCGbank, with greater incrementality and <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> than previous proposals.</abstract>
      <url hash="6cec6c5f">N19-1020</url>
      <doi>10.18653/v1/N19-1020</doi>
      <video href="https://vimeo.com/360516550" />
      <bibkey>stanojevic-steedman-2019-ccg</bibkey>
      <pwccode url="https://github.com/stanojevic/Rotating-CCG" additional="false">stanojevic/Rotating-CCG</pwccode>
    </paper>
    <paper id="21">
      <title>Cyclical Annealing Schedule : A Simple Approach to Mitigating KL Vanishing<fixed-case>KL</fixed-case> Vanishing</title>
      <author><first>Hao</first><last>Fu</last></author>
      <author><first>Chunyuan</first><last>Li</last></author>
      <author><first>Xiaodong</first><last>Liu</last></author>
      <author><first>Jianfeng</first><last>Gao</last></author>
      <author><first>Asli</first><last>Celikyilmaz</last></author>
      <author><first>Lawrence</first><last>Carin</last></author>
      <pages>240–250</pages>
      <abstract>Variational autoencoders (VAE) with an auto-regressive decoder have been applied for many natural language processing (NLP) tasks. VAE objective consists of two terms, the KL regularization term and the reconstruction term, balanced by a weighting hyper-parameter. One notorious training difficulty is that the KL term tends to vanish. In this paper we study different scheduling schemes for, and show that KL vanishing is caused by the lack of good latent codes in training decoder at the beginning of <a href="https://en.wikipedia.org/wiki/Mathematical_optimization">optimization</a>. To remedy the issue, we propose a cyclical annealing schedule, which simply repeats the process of increasing   multiple times. This new procedure allows us to learn more meaningful latent codes progressively by leveraging the results of previous learning cycles as warm re-restart. The effectiveness of cyclical annealing schedule is validated on a broad range of NLP tasks, including <a href="https://en.wikipedia.org/wiki/Language_model">language modeling</a>, dialog response generation and <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning">semi-supervised text classification</a>.<tex-math>\beta</tex-math>. One notorious training difficulty is that the KL term tends to vanish. In this paper we study different scheduling schemes for <tex-math>\beta</tex-math>, and show that KL vanishing is caused by the lack of good latent codes in training decoder at the beginning of optimization. To remedy the issue, we propose a cyclical annealing schedule, which simply repeats the process of increasing <tex-math>\beta</tex-math> multiple times. This new procedure allows us to learn more meaningful latent codes progressively by leveraging the results of previous learning cycles as warm re-restart. The effectiveness of cyclical annealing schedule is validated on a broad range of NLP tasks, including language modeling, dialog response generation and semi-supervised text classification.</abstract>
      <url hash="9d998499">N19-1021</url>
      <attachment type="supplementary" hash="8ff8e511">N19-1021.Supplementary.pdf</attachment>
      <doi>10.18653/v1/N19-1021</doi>
      <bibkey>fu-etal-2019-cyclical</bibkey>
      <pwccode url="https://github.com/haofuml/cyclical_annealing" additional="true">haofuml/cyclical_annealing</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="22">
      <title>Recurrent models and lower bounds for projective syntactic decoding</title>
      <author><first>Natalie</first><last>Schluter</last></author>
      <pages>251–260</pages>
      <abstract>The current state-of-the-art in neural graph-based parsing uses only approximate decoding at the training phase. In this paper aim to understand this result better. We show how recurrent models can carry out projective maximum spanning tree decoding. This result holds for both current state-of-the-art models for shift-reduce and graph-based parsers, projective or not. We also provide the first proof on the <a href="https://en.wikipedia.org/wiki/Upper_and_lower_bounds">lower bounds</a> of projective maximum spanning tree decoding.</abstract>
      <url hash="77133ec9">N19-1022</url>
      <doi>10.18653/v1/N19-1022</doi>
      <bibkey>schluter-2019-recurrent</bibkey>
    </paper>
    <paper id="23">
      <title>Evaluating Composition Models for Verb Phrase Elliptical Sentence Embeddings</title>
      <author><first>Gijs</first><last>Wijnholds</last></author>
      <author><first>Mehrnoosh</first><last>Sadrzadeh</last></author>
      <pages>261–271</pages>
      <abstract>Ellipsis is a natural language phenomenon where part of a sentence is missing and its information must be recovered from its surrounding context, as in Cats chase dogs and so do foxes.. Formal semantics has different methods for resolving <a href="https://en.wikipedia.org/wiki/Ellipsis_(linguistics)">ellipsis</a> and recovering the missing information, but the problem has not been considered for <a href="https://en.wikipedia.org/wiki/Distributional_semantics">distributional semantics</a>, where words have vector embeddings and combinations thereof provide <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> for sentences. In elliptical sentences these combinations go beyond linear as copying of elided information is necessary. In this paper, we develop different <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> for embedding VP-elliptical sentences. We extend existing verb disambiguation and sentence similarity datasets to ones containing elliptical phrases and evaluate our models on these <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> for a variety of non-linear combinations and their linear counterparts. We compare results of these compositional models to state of the art holistic sentence encoders. Our results show that non-linear addition and a non-linear tensor-based composition outperform the naive non-compositional baselines and the linear models, and that sentence encoders perform well on sentence similarity, but not on verb disambiguation.</abstract>
      <url hash="c029f150">N19-1023</url>
      <doi>10.18653/v1/N19-1023</doi>
      <bibkey>wijnholds-sadrzadeh-2019-evaluating</bibkey>
      <pwccode url="https://github.com/gijswijnholds/compdisteval-ellipsis" additional="false">gijswijnholds/compdisteval-ellipsis</pwccode>
    </paper>
    <paper id="25">
      <title>Riemannian Normalizing Flow on Variational Wasserstein Autoencoder for Text Modeling<fixed-case>R</fixed-case>iemannian Normalizing Flow on Variational <fixed-case>W</fixed-case>asserstein Autoencoder for Text Modeling</title>
      <author><first>Prince Zizhuang</first><last>Wang</last></author>
      <author><first>William Yang</first><last>Wang</last></author>
      <pages>284–294</pages>
      <abstract>Recurrent Variational Autoencoder has been widely used for language modeling and text generation tasks. These models often face a difficult optimization problem, also known as KL vanishing, where the <a href="https://en.wikipedia.org/wiki/Posterior_probability">posterior</a> easily collapses to the <a href="https://en.wikipedia.org/wiki/Prior_probability">prior</a> and model will ignore latent codes in generative tasks. To address this problem, we introduce an improved Variational Wasserstein Autoencoder (WAE) with Riemannian Normalizing Flow (RNF) for text modeling. The RNF transforms a <a href="https://en.wikipedia.org/wiki/Latent_variable">latent variable</a> into a space that respects the geometric characteristics of input space, which makes posterior impossible to collapse to the <a href="https://en.wikipedia.org/wiki/Non-informative_prior">non-informative prior</a>. The Wasserstein objective minimizes the distance between <a href="https://en.wikipedia.org/wiki/Marginal_distribution">marginal distribution</a> and the <a href="https://en.wikipedia.org/wiki/Prior_probability">prior</a> directly and therefore does not force the posterior to match the <a href="https://en.wikipedia.org/wiki/Prior_probability">prior</a>. Empirical experiments show that our model avoids KL vanishing over a range of datasets and has better performance in tasks such as <a href="https://en.wikipedia.org/wiki/Language_model">language modeling</a>, <a href="https://en.wikipedia.org/wiki/Likelihood_function">likelihood approximation</a>, and text generation. Through a series of experiments and analysis over latent space, we show that our model learns latent distributions that respect latent space geometry and is able to generate sentences that are more diverse.</abstract>
      <url hash="7216c5ab">N19-1025</url>
      <attachment type="software" hash="c3a301dd">N19-1025.Software.tar</attachment>
      <attachment type="presentation" hash="ba8203a6">N19-1025.Presentation.pptx</attachment>
      <doi>10.18653/v1/N19-1025</doi>
      <bibkey>wang-wang-2019-riemannian</bibkey>
      <pwccode url="https://github.com/kingofspace0wzz/wae-rnf-lm" additional="false">kingofspace0wzz/wae-rnf-lm</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="27">
      <title>ComQA : A Community-sourced Dataset for Complex Factoid Question Answering with Paraphrase Clusters<fixed-case>C</fixed-case>om<fixed-case>QA</fixed-case>: A Community-sourced Dataset for Complex Factoid Question Answering with Paraphrase Clusters</title>
      <author><first>Abdalghani</first><last>Abujabal</last></author>
      <author><first>Rishiraj</first><last>Saha Roy</last></author>
      <author><first>Mohamed</first><last>Yahya</last></author>
      <author><first>Gerhard</first><last>Weikum</last></author>
      <pages>307–317</pages>
      <abstract>To bridge the gap between the capabilities of the state-of-the-art in factoid question answering (QA) and what users ask, we need large datasets of real user questions that capture the various question phenomena users are interested in, and the diverse ways in which these <a href="https://en.wikipedia.org/wiki/Questionnaire">questions</a> are formulated. We introduce ComQA, a large dataset of real user questions that exhibit different challenging aspects such as <a href="https://en.wikipedia.org/wiki/Compositionality">compositionality</a>, temporal reasoning, and comparisons. ComQA questions come from the WikiAnswers community QA platform, which typically contains questions that are not satisfactorily answerable by existing search engine technology. Through a large crowdsourcing effort, we clean the question dataset, group questions into paraphrase clusters, and annotate <a href="https://en.wikipedia.org/wiki/Cluster_analysis">clusters</a> with their answers. ComQA contains 11,214 questions grouped into 4,834 paraphrase clusters. We detail the process of constructing ComQA, including the measures taken to ensure its high quality while making effective use of <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourcing</a>. We also present an extensive analysis of the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and the results achieved by state-of-the-art systems on ComQA, demonstrating that our <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> can be a driver of future research on <a href="https://en.wikipedia.org/wiki/Quality_assurance">QA</a>.</abstract>
      <url hash="72d8a987">N19-1027</url>
      <doi>10.18653/v1/N19-1027</doi>
      <bibkey>abujabal-etal-2019-comqa</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/comqa">ComQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/complexwebquestions">ComplexWebQuestions</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/simplequestions">SimpleQuestions</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/webquestions">WebQuestions</pwcdataset>
    </paper>
    <paper id="30">
      <title>Learning to Attend On Essential Terms : An Enhanced Retriever-Reader Model for Open-domain Question Answering</title>
      <author><first>Jianmo</first><last>Ni</last></author>
      <author><first>Chenguang</first><last>Zhu</last></author>
      <author><first>Weizhu</first><last>Chen</last></author>
      <author><first>Julian</first><last>McAuley</last></author>
      <pages>335–344</pages>
      <abstract>Open-domain question answering remains a challenging task as it requires <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> that are capable of understanding questions and answers, collecting useful information, and reasoning over evidence. Previous work typically formulates this task as a reading comprehension or entailment problem given evidence retrieved from <a href="https://en.wikipedia.org/wiki/Web_search_engine">search engines</a>. However, existing techniques struggle to retrieve indirectly related evidence when no directly related evidence is provided, especially for complex questions where it is hard to parse precisely what the question asks. In this paper we propose a retriever-reader model that learns to attend on essential terms during the <a href="https://en.wikipedia.org/wiki/Question_answering">question answering process</a>. We build (1) an essential term selector which first identifies the most important words in a question, then reformulates the query and searches for related evidence ; and (2) an enhanced reader that distinguishes between essential terms and distracting words to predict the answer. We evaluate our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> on multiple open-domain QA datasets, notably achieving the level of the state-of-the-art on the AI2 Reasoning Challenge (ARC) dataset.</abstract>
      <url hash="469b0748">N19-1030</url>
      <doi>10.18653/v1/N19-1030</doi>
      <bibkey>ni-etal-2019-learning</bibkey>
      <pwccode url="https://github.com/nijianmo/arc-etrr-code" additional="true">nijianmo/arc-etrr-code</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/arc">ARC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/race">RACE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/triviaqa">TriviaQA</pwcdataset>
    </paper>
    <paper id="34">
      <title>Multi-task Learning for Multi-modal Emotion Recognition and <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a></title>
      <author><first>Md Shad</first><last>Akhtar</last></author>
      <author><first>Dushyant</first><last>Chauhan</last></author>
      <author><first>Deepanway</first><last>Ghosal</last></author>
      <author><first>Soujanya</first><last>Poria</last></author>
      <author><first>Asif</first><last>Ekbal</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>370–379</pages>
      <abstract>Related <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> often have inter-dependence on each other and perform better when solved in a joint framework. In this paper, we present a deep multi-task learning framework that jointly performs sentiment and emotion analysis both. The <a href="https://en.wikipedia.org/wiki/Multimodal_interaction">multi-modal inputs</a> (i.e. text, acoustic and visual frames) of a video convey diverse and distinctive information, and usually do not have equal contribution in the <a href="https://en.wikipedia.org/wiki/Decision-making">decision making</a>. We propose a context-level inter-modal attention framework for simultaneously predicting the sentiment and expressed emotions of an utterance. We evaluate our proposed approach on CMU-MOSEI dataset for multi-modal sentiment and emotion analysis. Evaluation results suggest that multi-task learning framework offers improvement over the single-task framework. The proposed approach reports new state-of-the-art performance for both <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> and emotion analysis.</abstract>
      <url hash="86d9b1a3">N19-1034</url>
      <doi>10.18653/v1/N19-1034</doi>
      <bibkey>akhtar-etal-2019-multi</bibkey>
    </paper>
    <paper id="38">
      <title>Learning Interpretable Negation Rules via Weak Supervision at Document Level : A Reinforcement Learning Approach</title>
      <author><first>Nicolas</first><last>Pröllochs</last></author>
      <author><first>Stefan</first><last>Feuerriegel</last></author>
      <author><first>Dirk</first><last>Neumann</last></author>
      <pages>407–413</pages>
      <abstract>Negation scope detection is widely performed as a <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning task</a> which relies upon <a href="https://en.wikipedia.org/wiki/Affirmation_and_negation">negation labels</a> at word level. This suffers from two key drawbacks : (1) such granular annotations are costly and (2) highly subjective, since, due to the absence of explicit linguistic resolution rules, human annotators often disagree in the perceived negation scopes. To the best of our knowledge, our work presents the first approach that eliminates the need for world-level negation labels, replacing it instead with document-level sentiment annotations. For this, we present a novel strategy for learning fully interpretable negation rules via weak supervision : we apply <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> to find a policy that reconstructs negation rules from sentiment predictions at document level. Our experiments demonstrate that our approach for weak supervision can effectively learn negation rules. Furthermore, an <a href="https://en.wikipedia.org/wiki/Sampling_(statistics)">out-of-sample evaluation</a> via <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> reveals consistent improvements (of up to 4.66 %) over both a <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> with (i) no <a href="https://en.wikipedia.org/wiki/Negation">negation handling</a> and (ii) the use of word-level annotations from humans. Moreover, the inferred negation rules are fully interpretable.</abstract>
      <url hash="864c1044">N19-1038</url>
      <attachment type="supplementary" hash="e60df354">N19-1038.Supplementary.pdf</attachment>
      <doi>10.18653/v1/N19-1038</doi>
      <bibkey>prollochs-etal-2019-learning</bibkey>
    </paper>
    <paper id="41">
      <title>ReWE : Regressing Word Embeddings for Regularization of Neural Machine Translation Systems<fixed-case>R</fixed-case>e<fixed-case>WE</fixed-case>: Regressing Word Embeddings for Regularization of Neural Machine Translation Systems</title>
      <author><first>Inigo</first><last>Jauregi Unanue</last></author>
      <author><first>Ehsan</first><last>Zare Borzeshi</last></author>
      <author><first>Nazanin</first><last>Esmaili</last></author>
      <author><first>Massimo</first><last>Piccardi</last></author>
      <pages>430–436</pages>
      <abstract>Regularization of neural machine translation is still a significant problem, especially in <a href="https://en.wikipedia.org/wiki/Computational_complexity_theory">low-resource settings</a>. To mollify this problem, we propose regressing word embeddings (ReWE) as a new regularization technique in a system that is jointly trained to predict the next word in the translation (categorical value) and its word embedding (continuous value). Such a joint training allows the proposed system to learn the distributional properties represented by the <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>, empirically improving the <a href="https://en.wikipedia.org/wiki/Generalization">generalization</a> to unseen sentences. Experiments over three translation datasets have showed a consistent improvement over a strong <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a>, ranging between 0.91 and 2.4 BLEU points, and also a marked improvement over a <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art system</a>.</abstract>
      <url hash="e9c0b717">N19-1041</url>
      <attachment type="supplementary" hash="4e2866e8">N19-1041.Supplementary.pdf</attachment>
      <doi>10.18653/v1/N19-1041</doi>
      <bibkey>jauregi-unanue-etal-2019-rewe</bibkey>
    </paper>
    <paper id="42">
      <title>Lost in <a href="https://en.wikipedia.org/wiki/Machine_translation">Machine Translation</a> : A Method to Reduce Meaning Loss</title>
      <author><first>Reuben</first><last>Cohn-Gordon</last></author>
      <author><first>Noah</first><last>Goodman</last></author>
      <pages>437–441</pages>
      <abstract>A desideratum of high-quality translation systems is that they preserve meaning, in the sense that two sentences with different meanings should not translate to one and the same sentence in another language. However, state-of-the-art systems often fail in this regard, particularly in cases where the source and target languages partition the meaning space in different ways. For instance, I cut my finger. and I cut my finger off. describe different states of the world but are translated to <a href="https://en.wikipedia.org/wiki/French_language">French</a> (by both Fairseq and Google Translate) as Je me suis coup le doigt., which is ambiguous as to whether the finger is detached. More generally, <a href="https://en.wikipedia.org/wiki/Translation">translation systems</a> are typically many-to-one (non-injective) functions from source to target language, which in many cases results in important distinctions in meaning being lost in <a href="https://en.wikipedia.org/wiki/Translation">translation</a>. Building on Bayesian models of informative utterance production, we present a method to define a less ambiguous translation system in terms of an underlying pre-trained neural sequence-to-sequence model. This method increases <a href="https://en.wikipedia.org/wiki/Injectivity">injectivity</a>, resulting in greater preservation of meaning as measured by improvement in cycle-consistency, without impeding translation quality (measured by BLEU score).</abstract>
      <url hash="c9314908">N19-1042</url>
      <doi>10.18653/v1/N19-1042</doi>
      <bibkey>cohn-gordon-goodman-2019-lost</bibkey>
      <pwccode url="https://github.com/reubenharry/pragmatic-translation" additional="false">reubenharry/pragmatic-translation</pwccode>
    </paper>
    <paper id="44">
      <title>Code-Switching for Enhancing <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NMT</a> with Pre-Specified Translation<fixed-case>NMT</fixed-case> with Pre-Specified Translation</title>
      <author><first>Kai</first><last>Song</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <author><first>Heng</first><last>Yu</last></author>
      <author><first>Weihua</first><last>Luo</last></author>
      <author><first>Kun</first><last>Wang</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>449–459</pages>
      <abstract>Leveraging user-provided translation to constrain <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NMT</a> has practical significance. Existing methods can be classified into two main categories, namely the use of <a href="https://en.wikipedia.org/wiki/Tag_(metadata)">placeholder tags</a> for lexicon words and the use of <a href="https://en.wikipedia.org/wiki/Constraint_(mathematics)">hard constraints</a> during decoding. Both methods can hurt translation fidelity for various reasons. We investigate a data augmentation method, making code-switched training data by replacing source phrases with their target translations. Our method does not change the MNT model or decoding algorithm, allowing the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> to learn lexicon translations by copying source-side target words. Extensive experiments show that our method achieves consistent improvements over existing approaches, improving translation of constrained words without hurting unconstrained words.</abstract>
      <url hash="d307cc97">N19-1044</url>
      <doi>10.18653/v1/N19-1044</doi>
      <bibkey>song-etal-2019-code</bibkey>
      <pwccode url="https://github.com/batman2013/e-commerce_test_sets" additional="false">batman2013/e-commerce_test_sets</pwccode>
    </paper>
    <paper id="47">
      <title>Content Differences in Syntactic and Semantic Representation</title>
      <author><first>Daniel</first><last>Hershcovich</last></author>
      <author><first>Omri</first><last>Abend</last></author>
      <author><first>Ari</first><last>Rappoport</last></author>
      <pages>478–488</pages>
      <abstract>Syntactic analysis plays an important role in <a href="https://en.wikipedia.org/wiki/Semantic_parsing">semantic parsing</a>, but the nature of this <a href="https://en.wikipedia.org/wiki/Role">role</a> remains a topic of ongoing debate. The debate has been constrained by the scarcity of empirical comparative studies between syntactic and semantic schemes, which hinders the development of parsing methods informed by the details of target schemes and constructions. We target this gap, and take Universal Dependencies (UD) and <a href="https://en.wikipedia.org/wiki/UCCA">UCCA</a> as a test case. After abstracting away from differences of <a href="https://en.wikipedia.org/wiki/Convention_(norm)">convention</a> or formalism, we find that most content divergences can be ascribed to : (1) UCCA’s distinction between a Scene and a non-Scene ; (2) UCCA’s distinction between primary relations, secondary ones and participants ; (3) different treatment of multi-word expressions, and (4) different treatment of inter-clause linkage. We further discuss the long tail of cases where the two <a href="https://en.wikipedia.org/wiki/Scheme_(mathematics)">schemes</a> take markedly different approaches. Finally, we show that the proposed comparison methodology can be used for fine-grained evaluation of UCCA parsing, highlighting both challenges and potential sources for improvement. The substantial differences between the schemes suggest that semantic parsers are likely to benefit downstream text understanding applications beyond their syntactic counterparts.</abstract>
      <url hash="65fc6a59">N19-1047</url>
      <attachment type="software" hash="e8cf8bd7">N19-1047.Software.zip</attachment>
      <attachment type="supplementary" hash="25f9854c">N19-1047.Supplementary.pdf</attachment>
      <attachment type="poster" hash="5b0a6e1e">N19-1047.Poster.pdf</attachment>
      <doi>10.18653/v1/N19-1047</doi>
      <bibkey>hershcovich-etal-2019-content</bibkey>
      <pwccode url="https://github.com/UniversalConceptualCognitiveAnnotation/UCCA_English-EWT" additional="true">UniversalConceptualCognitiveAnnotation/UCCA_English-EWT</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/english-web-treebank">English Web Treebank</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="48">
      <title>Attentive Mimicking : Better Word Embeddings by Attending to Informative Contexts</title>
      <author><first>Timo</first><last>Schick</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>489–494</pages>
      <abstract>Learning high-quality embeddings for rare words is a hard problem because of sparse context information. Mimicking (Pinter et al., 2017) has been proposed as a solution : given <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> learned by a standard algorithm, a model is first trained to reproduce <a href="https://en.wikipedia.org/wiki/Embedding">embeddings of frequent words</a> from their surface form and then used to compute <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> for rare words. In this paper, we introduce attentive mimicking : the mimicking model is given access not only to a word’s surface form, but also to all available contexts and learns to attend to the most informative and reliable contexts for computing an <a href="https://en.wikipedia.org/wiki/Embedding">embedding</a>. In an evaluation on four tasks, we show that attentive mimicking outperforms previous <a href="https://en.wikipedia.org/wiki/Work_(physics)">work</a> for both rare and medium-frequency words. Thus, compared to previous work, attentive mimicking improves <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> for a much larger part of the vocabulary, including the <a href="https://en.wikipedia.org/wiki/Medium_frequency">medium-frequency range</a>.</abstract>
      <url hash="e3fd68d1">N19-1048</url>
      <attachment type="supplementary" hash="c9162138">N19-1048.Supplementary.pdf</attachment>
      <doi>10.18653/v1/N19-1048</doi>
      <bibkey>schick-schutze-2019-attentive</bibkey>
      <pwccode url="https://github.com/timoschick/form-context-model" additional="false">timoschick/form-context-model</pwccode>
    </paper>
    <paper id="49">
      <title>Evaluating Style Transfer for Text</title>
      <author><first>Remi</first><last>Mir</last></author>
      <author><first>Bjarke</first><last>Felbo</last></author>
      <author><first>Nick</first><last>Obradovich</last></author>
      <author><first>Iyad</first><last>Rahwan</last></author>
      <pages>495–504</pages>
      <abstract>Research in the area of style transfer for <a href="https://en.wikipedia.org/wiki/Writing">text</a> is currently bottlenecked by a lack of standard evaluation practices. This paper aims to alleviate this issue by experimentally identifying best practices with a Yelp sentiment dataset. We specify three aspects of interest (style transfer intensity, content preservation, and naturalness) and show how to obtain more reliable measures of them from human evaluation than in previous work. We propose a set of metrics for automated evaluation and demonstrate that they are more strongly correlated and in agreement with human judgment : direction-corrected Earth Mover’s Distance, Word Mover’s Distance on style-masked texts, and adversarial classification for the respective aspects. We also show that the three examined <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> exhibit tradeoffs between aspects of interest, demonstrating the importance of evaluating style transfer models at specific points of their tradeoff plots. We release software with our evaluation metrics to facilitate research.</abstract>
      <url hash="e75d39b6">N19-1049</url>
      <doi>10.18653/v1/N19-1049</doi>
      <bibkey>mir-etal-2019-evaluating</bibkey>
      <pwccode url="https://github.com/passeul/style-transfer-model-evaluation" additional="false">passeul/style-transfer-model-evaluation</pwccode>
    </paper>
    <paper id="51">
      <title>Outlier Detection for Improved Data Quality and Diversity in Dialog Systems</title>
      <author><first>Stefan</first><last>Larson</last></author>
      <author><first>Anish</first><last>Mahendran</last></author>
      <author><first>Andrew</first><last>Lee</last></author>
      <author><first>Jonathan K.</first><last>Kummerfeld</last></author>
      <author><first>Parker</first><last>Hill</last></author>
      <author><first>Michael A.</first><last>Laurenzano</last></author>
      <author><first>Johann</first><last>Hauswald</last></author>
      <author><first>Lingjia</first><last>Tang</last></author>
      <author><first>Jason</first><last>Mars</last></author>
      <pages>517–527</pages>
      <abstract>In a <a href="https://en.wikipedia.org/wiki/Corpus_linguistics">corpus of data</a>, <a href="https://en.wikipedia.org/wiki/Outlier">outliers</a> are either errors : mistakes in the data that are counterproductive, or are unique : informative samples that improve <a href="https://en.wikipedia.org/wiki/Robust_statistics">model robustness</a>. Identifying outliers can lead to better datasets by (1) removing noise in datasets and (2) guiding collection of additional data to fill gaps. However, the problem of detecting both outlier types has received relatively little attention in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>, particularly for dialog systems. We introduce a simple and effective technique for detecting both erroneous and unique samples in a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus of short texts</a> using neural sentence embeddings combined with distance-based outlier detection. We also present a novel data collection pipeline built atop our detection technique to automatically and iteratively mine unique data samples while discarding erroneous samples. Experiments show that our outlier detection technique is effective at finding errors while our data collection pipeline yields highly diverse corpora that in turn produce more robust intent classification and slot-filling models.</abstract>
      <url hash="31d6b562">N19-1051</url>
      <doi>10.18653/v1/N19-1051</doi>
      <bibkey>larson-etal-2019-outlier</bibkey>
    </paper>
    <paper id="53">
      <title>Seeing Things from a Different Angle : Discovering Diverse Perspectives about Claims</title>
      <author><first>Sihao</first><last>Chen</last></author>
      <author><first>Daniel</first><last>Khashabi</last></author>
      <author><first>Wenpeng</first><last>Yin</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>542–557</pages>
      <abstract>One key consequence of the <a href="https://en.wikipedia.org/wiki/Information_revolution">information revolution</a> is a significant increase and a contamination of our information supply. The practice of <a href="https://en.wikipedia.org/wiki/Fact-checking">fact checking</a> wo n’t suffice to eliminate the biases in text data we observe, as the degree of <a href="https://en.wikipedia.org/wiki/Fact">factuality</a> alone does not determine whether biases exist in the spectrum of opinions visible to us. To better understand controversial issues, one needs to view them from a diverse yet comprehensive set of perspectives. For example, there are many ways to respond to a claim such as animals should have lawful rights, and these responses form a spectrum of perspectives, each with a stance relative to this claim and, ideally, with evidence supporting it. Inherently, this is a <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language understanding task</a>, and we propose to address it as such. Specifically, we propose the task of substantiated perspective discovery where, given a claim, a system is expected to discover a diverse set of well-corroborated perspectives that take a stance with respect to the claim. Each perspective should be substantiated by evidence paragraphs which summarize pertinent results and facts. We construct PERSPECTRUM, a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> of claims, perspectives and evidence, making use of online debate websites to create the initial <a href="https://en.wikipedia.org/wiki/Data_collection">data collection</a>, and augmenting it using <a href="https://en.wikipedia.org/wiki/Web_search_engine">search engines</a> in order to expand and diversify our <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>. We use <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowd-sourcing</a> to filter out noise and ensure high-quality data. Our dataset contains 1k claims, accompanied with pools of 10k and 8k perspective sentences and evidence paragraphs, respectively.</abstract>
      <url hash="c19c2a4c">N19-1053</url>
      <doi>10.18653/v1/N19-1053</doi>
      <bibkey>chen-etal-2019-seeing</bibkey>
      <pwccode url="https://github.com/CogComp/perspectrum" additional="false">CogComp/perspectrum</pwccode>
    </paper>
    <paper id="57">
      <title>Improving Dialogue State Tracking by Discerning the Relevant Context</title>
      <author><first>Sanuj</first><last>Sharma</last></author>
      <author><first>Prafulla Kumar</first><last>Choubey</last></author>
      <author><first>Ruihong</first><last>Huang</last></author>
      <pages>576–581</pages>
      <abstract>A typical conversation comprises of multiple turns between participants where they go back and forth between different topics. At each user turn, dialogue state tracking (DST) aims to estimate user’s goal by processing the current utterance. However, in many turns, users implicitly refer to the previous goal, necessitating the use of relevant dialogue history. Nonetheless, distinguishing relevant history is challenging and a popular method of using dialogue recency for that is inefficient. We, therefore, propose a novel framework for DST that identifies relevant historical context by referring to the past utterances where a particular slot-value changes and uses that together with weighted system utterance to identify the relevant context. Specifically, we use the current user utterance and the most recent system utterance to determine the relevance of a system utterance. Empirical analyses show that our method improves <a href="https://en.wikipedia.org/wiki/Common_cause_and_special_cause_(statistics)">joint goal accuracy</a> by 2.75 % and 2.36 % on WoZ 2.0 and Multi-WoZ restaurant domain datasets respectively over the previous state-of-the-art GLAD model.</abstract>
      <url hash="d3c334e1">N19-1057</url>
      <doi>10.18653/v1/N19-1057</doi>
      <video href="https://vimeo.com/353455637" />
      <bibkey>sharma-etal-2019-improving</bibkey>
    </paper>
    <paper id="60">
      <title>Detection of Abusive Language : the Problem of Biased Datasets<fixed-case>D</fixed-case>etection of <fixed-case>A</fixed-case>busive <fixed-case>L</fixed-case>anguage: the <fixed-case>P</fixed-case>roblem of <fixed-case>B</fixed-case>iased <fixed-case>D</fixed-case>atasets</title>
      <author><first>Michael</first><last>Wiegand</last></author>
      <author><first>Josef</first><last>Ruppenhofer</last></author>
      <author><first>Thomas</first><last>Kleinbauer</last></author>
      <pages>602–608</pages>
      <abstract>We discuss the impact of data bias on abusive language detection. We show that classification scores on popular <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> reported in previous work are much lower under realistic settings in which this bias is reduced. Such biases are most notably observed on <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> that are created by focused sampling instead of <a href="https://en.wikipedia.org/wiki/Simple_random_sample">random sampling</a>. Datasets with a higher proportion of implicit abuse are more affected than <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> with a lower proportion.</abstract>
      <url hash="02619f47">N19-1060</url>
      <video href="https://vimeo.com/347386459" />
      <doi>10.18653/v1/N19-1060</doi>
      <bibkey>wiegand-etal-2019-detection</bibkey>
    </paper>
    <paper id="61">
      <title>Lipstick on a Pig : Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them<fixed-case>D</fixed-case>ebiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them</title>
      <author><first>Hila</first><last>Gonen</last></author>
      <author><first>Yoav</first><last>Goldberg</last></author>
      <pages>609–614</pages>
      <abstract>Word embeddings are widely used in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> for a vast range of tasks. It was shown that <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> derived from <a href="https://en.wikipedia.org/wiki/Text_corpus">text corpora</a> reflect gender biases in society. This phenomenon is pervasive and consistent across different word embedding models, causing serious concern. Several recent works tackle this problem, and propose methods for significantly reducing this gender bias in <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>, demonstrating convincing results. However, we argue that this removal is superficial. While the <a href="https://en.wikipedia.org/wiki/Bias">bias</a> is indeed substantially reduced according to the provided <a href="https://en.wikipedia.org/wiki/Bias">bias definition</a>, the actual effect is mostly hiding the bias, not removing it. The gender bias information is still reflected in the distances between gender-neutralized words in the debiased embeddings, and can be recovered from them. We present a series of experiments to support this claim, for two debiasing methods. We conclude that existing bias removal techniques are insufficient, and should not be trusted for providing gender-neutral modeling.</abstract>
      <url hash="ee985e8b">N19-1061</url>
      <video href="https://vimeo.com/347389631" />
      <doi>10.18653/v1/N19-1061</doi>
      <bibkey>gonen-goldberg-2019-lipstick</bibkey>
      <pwccode url="https://github.com/gonenhila/gender_bias_lipstick" additional="true">gonenhila/gender_bias_lipstick</pwccode>
    </paper>
    <paper id="63">
      <title>On Measuring Social Biases in Sentence Encoders</title>
      <author><first>Chandler</first><last>May</last></author>
      <author><first>Alex</first><last>Wang</last></author>
      <author><first>Shikha</first><last>Bordia</last></author>
      <author><first>Samuel R.</first><last>Bowman</last></author>
      <author><first>Rachel</first><last>Rudinger</last></author>
      <pages>622–628</pages>
      <abstract>The Word Embedding Association Test shows that GloVe and word2vec word embeddings exhibit human-like implicit biases based on gender, race, and other social constructs (Caliskan et al., 2017). Meanwhile, research on learning reusable text representations has begun to explore sentence-level texts, with some sentence encoders seeing enthusiastic adoption. Accordingly, we extend the Word Embedding Association Test to measure bias in sentence encoders. We then test several sentence encoders, including state-of-the-art methods such as ELMo and BERT, for the social biases studied in prior work and two important biases that are difficult or impossible to test at the word level. We observe mixed results including suspicious patterns of sensitivity that suggest the test’s assumptions may not hold in general. We conclude by proposing directions for future work on measuring bias in sentence encoders.</abstract>
      <url hash="c0624e0e">N19-1063</url>
      <attachment type="supplementary" hash="bdfa2d97">N19-1063.Supplementary.pdf</attachment>
      <attachment type="dataset" hash="a966a146">N19-1063.Datasets.zip</attachment>
      <video href="https://vimeo.com/347394290" />
      <doi>10.18653/v1/N19-1063</doi>
      <bibkey>may-etal-2019-measuring</bibkey>
      <pwccode url="https://github.com/W4ngatang/sent-bias" additional="false">W4ngatang/sent-bias</pwccode>
    </paper>
    <paper id="64">
      <title>Gender Bias in Contextualized Word Embeddings</title>
      <author><first>Jieyu</first><last>Zhao</last></author>
      <author><first>Tianlu</first><last>Wang</last></author>
      <author><first>Mark</first><last>Yatskar</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <author><first>Vicente</first><last>Ordonez</last></author>
      <author><first>Kai-Wei</first><last>Chang</last></author>
      <pages>629–634</pages>
      <abstract>In this paper, we quantify, analyze and mitigate <a href="https://en.wikipedia.org/wiki/Gender_bias">gender bias</a> exhibited in ELMo’s contextualized word vectors. First, we conduct several intrinsic analyses and find that (1) training data for ELMo contains significantly more male than female entities, (2) the trained ELMo embeddings systematically encode gender information and (3) ELMo unequally encodes gender information about male and female entities. Then, we show that a state-of-the-art coreference system that depends on ELMo inherits its bias and demonstrates significant bias on the WinoBias probing corpus. Finally, we explore two methods to mitigate such gender bias and show that the bias demonstrated on WinoBias can be eliminated.</abstract>
      <url hash="bdfeb09f">N19-1064</url>
      <video href="https://vimeo.com/347396468" />
      <doi>10.18653/v1/N19-1064</doi>
      <bibkey>zhao-etal-2019-gender</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/winobias">WinoBias</pwcdataset>
    </paper>
    <paper id="65">
      <title>Combining Sentiment Lexica with a Multi-View Variational Autoencoder<fixed-case>C</fixed-case>ombining <fixed-case>S</fixed-case>entiment <fixed-case>L</fixed-case>exica with a <fixed-case>M</fixed-case>ulti-<fixed-case>V</fixed-case>iew <fixed-case>V</fixed-case>ariational <fixed-case>A</fixed-case>utoencoder</title>
      <author><first>Alexander Miserlis</first><last>Hoyle</last></author>
      <author><first>Lawrence</first><last>Wolf-Sonkin</last></author>
      <author><first>Hanna</first><last>Wallach</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <author><first>Isabelle</first><last>Augenstein</last></author>
      <pages>635–640</pages>
      <abstract>When assigning quantitative labels to a dataset, different <a href="https://en.wikipedia.org/wiki/Methodology">methodologies</a> may rely on different scales. In particular, when assigning polarities to words in a sentiment lexicon, annotators may use binary, categorical, or continuous labels. Naturally, it is of interest to unify these labels from disparate scales to both achieve maximal coverage over words and to create a single, more robust sentiment lexicon while retaining scale coherence. We introduce a generative model of sentiment lexica to combine disparate scales into a common latent representation. We realize this <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> with a novel multi-view variational autoencoder (VAE), called SentiVAE. We evaluate our approach via a downstream text classification task involving nine English-Language sentiment analysis datasets ; our representation outperforms six individual sentiment lexica, as well as a straightforward combination thereof.</abstract>
      <url hash="7972698f">N19-1065</url>
      <doi>10.18653/v1/N19-1065</doi>
      <video href="https://vimeo.com/356020948" />
      <bibkey>hoyle-etal-2019-combining</bibkey>
      <pwccode url="https://github.com/ahoho/SentiVAE" additional="false">ahoho/SentiVAE</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
    </paper>
    <paper id="67">
      <title>Frowning Frodo, Wincing Leia, and a Seriously Great Friendship : Learning to Classify Emotional Relationships of Fictional Characters<fixed-case>F</fixed-case>rodo, Wincing <fixed-case>L</fixed-case>eia, and a Seriously Great Friendship: Learning to Classify Emotional Relationships of Fictional Characters</title>
      <author><first>Evgeny</first><last>Kim</last></author>
      <author><first>Roman</first><last>Klinger</last></author>
      <pages>647–653</pages>
      <abstract>The development of a <a href="https://en.wikipedia.org/wiki/Plot_(narrative)">fictional plot</a> is centered around characters who closely interact with each other forming dynamic social networks. In literature analysis, such networks have mostly been analyzed without particular relation types or focusing on roles which the characters take with respect to each other. We argue that an important aspect for the analysis of stories and their development is the emotion between characters. In this paper, we combine these aspects into a unified framework to classify emotional relationships of fictional characters. We formalize it as a new task and describe the <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a> of a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>, based on <a href="https://en.wikipedia.org/wiki/Fan_fiction">fan-fiction short stories</a>. The extraction pipeline which we propose consists of character identification (which we treat as given by an oracle here) and the relation classification. For the latter, we provide results using several approaches previously proposed for relation identification with <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">neural methods</a>. The best result of 0.45 F1 is achieved with a <a href="https://en.wikipedia.org/wiki/Graph_of_a_function">GRU</a> with character position indicators on the task of predicting undirected emotion relations in the associated <a href="https://en.wikipedia.org/wiki/Social_network">social network graph</a>.</abstract>
      <url hash="c34e8e4f">N19-1067</url>
      <attachment type="supplementary" hash="e948c032">N19-1067.Supplementary.pdf</attachment>
      <attachment type="presentation" hash="2928e375">N19-1067.Presentation.pdf</attachment>
      <doi>10.18653/v1/N19-1067</doi>
      <video href="https://vimeo.com/355760337" />
      <bibkey>kim-klinger-2019-frowning</bibkey>
    </paper>
    <paper id="71">
      <title>SEQ3 : Differentiable Sequence-to-Sequence-to-Sequence Autoencoder for Unsupervised Abstractive Sentence Compression<fixed-case>SEQ</fixed-case>ˆ3: Differentiable Sequence-to-Sequence-to-Sequence Autoencoder for Unsupervised Abstractive Sentence Compression</title>
      <author><first>Christos</first><last>Baziotis</last></author>
      <author><first>Ion</first><last>Androutsopoulos</last></author>
      <author><first>Ioannis</first><last>Konstas</last></author>
      <author><first>Alexandros</first><last>Potamianos</last></author>
      <pages>673–681</pages>
      <abstract>Neural sequence-to-sequence models are currently the dominant approach in several natural language processing tasks, but require large parallel corpora. We present a sequence-to-sequence-to-sequence autoencoder (SEQ3), consisting of two chained encoder-decoder pairs, with words used as a sequence of discrete latent variables. We apply the proposed model to unsupervised abstractive sentence compression, where the first and last sequences are the input and reconstructed sentences, respectively, while the middle sequence is the compressed sentence. Constraining the length of the latent word sequences forces the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> to distill important information from the input. A pretrained language model, acting as a prior over the latent sequences, encourages the compressed sentences to be human-readable. Continuous relaxations enable us to sample from <a href="https://en.wikipedia.org/wiki/Categorical_distribution">categorical distributions</a>, allowing gradient-based optimization, unlike alternatives that rely on <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>. The proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> does not require parallel text-summary pairs, achieving promising results in unsupervised sentence compression on benchmark datasets.</abstract>
      <url hash="34013d68">N19-1071</url>
      <attachment type="presentation" hash="23610f8f">N19-1071.Presentation.pdf</attachment>
      <doi>10.18653/v1/N19-1071</doi>
      <video href="https://vimeo.com/353462534" />
      <bibkey>baziotis-etal-2019-seq</bibkey>
    </paper>
    <paper id="72">
      <title>Crowdsourcing Lightweight Pyramids for Manual Summary Evaluation</title>
      <author><first>Ori</first><last>Shapira</last></author>
      <author><first>David</first><last>Gabay</last></author>
      <author><first>Yang</first><last>Gao</last></author>
      <author><first>Hadar</first><last>Ronen</last></author>
      <author><first>Ramakanth</first><last>Pasunuru</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <author><first>Yael</first><last>Amsterdamer</last></author>
      <author><first>Ido</first><last>Dagan</last></author>
      <pages>682–687</pages>
      <abstract>Conducting a manual evaluation is considered an essential part of summary evaluation methodology. Traditionally, the Pyramid protocol, which exhaustively compares system summaries to references, has been perceived as very reliable, providing objective scores. Yet, due to the high cost of the Pyramid method and the required expertise, researchers resorted to cheaper and less thorough manual evaluation methods, such as <a href="https://en.wikipedia.org/wiki/Responsiveness">Responsiveness</a> and <a href="https://en.wikipedia.org/wiki/Pairwise_comparison">pairwise comparison</a>, attainable via <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourcing</a>. We revisit the Pyramid approach, proposing a lightweight sampling-based version that is crowdsourcable. We analyze the performance of our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> in comparison to original expert-based Pyramid evaluations, showing higher <a href="https://en.wikipedia.org/wiki/Correlation_and_dependence">correlation</a> relative to the common Responsiveness method. We release our crowdsourced Summary-Content-Units, along with all crowdsourcing scripts, for future evaluations.</abstract>
      <url hash="9a0fde1b">N19-1072</url>
      <doi>10.18653/v1/N19-1072</doi>
      <video href="https://vimeo.com/353467177" />
      <bibkey>shapira-etal-2019-crowdsourcing</bibkey>
      <pwccode url="https://github.com/OriShapira/LitePyramids" additional="false">OriShapira/LitePyramids</pwccode>
    </paper>
    <paper id="76">
      <title>Left-to-Right Dependency Parsing with Pointer Networks</title>
      <author><first>Daniel</first><last>Fernández-González</last></author>
      <author><first>Carlos</first><last>Gómez-Rodríguez</last></author>
      <pages>710–716</pages>
      <abstract>We propose a novel transition-based algorithm that straightforwardly parses sentences from left to right by building n attachments, with n being the length of the input sentence. Similarly to the recent stack-pointer parser by Ma et al. (2018), we use the pointer network framework that, given a word, can directly point to a position from the sentence. However, our left-to-right approach is simpler than the original top-down stack-pointer parser (not requiring a stack) and reduces transition sequence length in half, from 2n-1 actions to n. This results in a quadratic non-projective parser that runs twice as fast as the original while achieving the best accuracy to date on the English PTB dataset (96.04 % UAS, 94.43 % LAS) among fully-supervised single-model dependency parsers, and improves over the former top-down transition system in the majority of languages tested.</abstract>
      <url hash="970e00a9">N19-1076</url>
      <doi>10.18653/v1/N19-1076</doi>
      <bibkey>fernandez-gonzalez-gomez-rodriguez-2019-left</bibkey>
      <pwccode url="https://github.com/danifg/Left2Right-Pointer-Parser" additional="false">danifg/Left2Right-Pointer-Parser</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="79">
      <title>Better Modeling of Incomplete Annotations for Named Entity Recognition</title>
      <author><first>Zhanming</first><last>Jie</last></author>
      <author><first>Pengjun</first><last>Xie</last></author>
      <author><first>Wei</first><last>Lu</last></author>
      <author><first>Ruixue</first><last>Ding</last></author>
      <author><first>Linlin</first><last>Li</last></author>
      <pages>729–734</pages>
      <abstract>Supervised approaches to named entity recognition (NER) are largely developed based on the assumption that the training data is fully annotated with named entity information. However, in practice, annotated data can often be imperfect with one typical issue being the training data may contain incomplete annotations. We highlight several pitfalls associated with learning under such a setup in the context of <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">NER</a> and identify limitations associated with existing approaches, proposing a novel yet easy-to-implement approach for recognizing named entities with incomplete data annotations. We demonstrate the effectiveness of our <a href="https://en.wikipedia.org/wiki/Scientific_method">approach</a> through extensive experiments.</abstract>
      <url hash="51b678dc">N19-1079</url>
      <attachment type="supplementary" hash="5aeb476f">N19-1079.Supplementary.zip</attachment>
      <doi>10.18653/v1/N19-1079</doi>
      <attachment type="presentation" hash="08a02346">N19-1079.Presentation.pdf</attachment>
      <video href="https://vimeo.com/360565437" />
      <bibkey>jie-etal-2019-better</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2002">CoNLL 2002</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
    </paper>
    <paper id="88">
      <title>Adversarial Decomposition of Text Representation</title>
      <author><first>Alexey</first><last>Romanov</last></author>
      <author><first>Anna</first><last>Rumshisky</last></author>
      <author><first>Anna</first><last>Rogers</last></author>
      <author><first>David</first><last>Donahue</last></author>
      <pages>815–825</pages>
      <abstract>In this paper, we present a <a href="https://en.wikipedia.org/wiki/Methodology">method</a> for adversarial decomposition of text representation. This method can be used to decompose a representation of an input sentence into several independent vectors, each of them responsible for a specific aspect of the input sentence. We evaluate the proposed method on two <a href="https://en.wikipedia.org/wiki/Case_study">case studies</a> : the conversion between different <a href="https://en.wikipedia.org/wiki/Register_(sociolinguistics)">social registers</a> and <a href="https://en.wikipedia.org/wiki/Language_change">diachronic language change</a>. We show that the proposed method is capable of fine-grained controlled change of these aspects of the input sentence. It is also learning a continuous (rather than categorical) representation of the style of the sentence, which is more linguistically realistic. The model uses adversarial-motivational training and includes a special motivational loss, which acts opposite to the discriminator and encourages a better decomposition. Furthermore, we evaluate the obtained meaning embeddings on a downstream task of <a href="https://en.wikipedia.org/wiki/Paraphrase_detection">paraphrase detection</a> and show that they significantly outperform the <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> of a regular autoencoder.</abstract>
      <url hash="fc886825">N19-1088</url>
      <doi>10.18653/v1/N19-1088</doi>
      <bibkey>romanov-etal-2019-adversarial</bibkey>
      <pwccode url="https://github.com/text-machine-lab/adversarial_decomposition" additional="true">text-machine-lab/adversarial_decomposition</pwccode>
    </paper>
    <paper id="95">
      <title>Recovering dropped pronouns in Chinese conversations via modeling their referents<fixed-case>C</fixed-case>hinese conversations via modeling their referents</title>
      <author><first>Jingxuan</first><last>Yang</last></author>
      <author><first>Jianzhuo</first><last>Tong</last></author>
      <author><first>Si</first><last>Li</last></author>
      <author><first>Sheng</first><last>Gao</last></author>
      <author><first>Jun</first><last>Guo</last></author>
      <author><first>Nianwen</first><last>Xue</last></author>
      <pages>892–901</pages>
      <abstract>Pronouns are often dropped in Chinese sentences, and this happens more frequently in conversational genres as their referents can be easily understood from context. Recovering dropped pronouns is essential to applications such as <a href="https://en.wikipedia.org/wiki/Information_extraction">Information Extraction</a> where the referents of these dropped pronouns need to be resolved, or <a href="https://en.wikipedia.org/wiki/Machine_translation">Machine Translation</a> when Chinese is the source language. In this work, we present a novel end-to-end neural network model to recover <a href="https://en.wikipedia.org/wiki/Pronoun">dropped pronouns</a> in <a href="https://en.wikipedia.org/wiki/Conversation">conversational data</a>. Our model is based on a structured attention mechanism that models the referents of dropped pronouns utilizing both sentence-level and word-level information. Results on three different conversational genres show that our approach achieves a significant improvement over the current state of the art.</abstract>
      <url hash="d55e852a">N19-1095</url>
      <doi>10.18653/v1/N19-1095</doi>
      <bibkey>yang-etal-2019-recovering</bibkey>
      <pwccode url="https://github.com/ningningyang/NDPR" additional="false">ningningyang/NDPR</pwccode>
    </paper>
    <paper id="97">
      <title>A Systematic Study of Leveraging Subword Information for Learning Word Representations</title>
      <author><first>Yi</first><last>Zhu</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <pages>912–932</pages>
      <abstract>The use of subword-level information (e.g., <a href="https://en.wikipedia.org/wiki/Character_(symbol)">characters</a>, <a href="https://en.wikipedia.org/wiki/Character_(symbol)">character n-grams</a>, morphemes) has become ubiquitous in modern word representation learning. Its importance is attested especially for <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphologically rich languages</a> which generate a large number of rare words. Despite a steadily increasing interest in such subword-informed word representations, their systematic comparative analysis across typologically diverse languages and different tasks is still missing. In this work, we deliver such a study focusing on the variation of two crucial components required for subword-level integration into word representation models : 1) segmentation of words into subword units, and 2) subword composition functions to obtain final word representations. We propose a general framework for learning subword-informed word representations that allows for easy experimentation with different segmentation and composition components, also including more advanced techniques based on position embeddings and self-attention. Using the unified framework, we run experiments over a large number of subword-informed word representation configurations (60 in total) on 3 tasks (general and rare word similarity, dependency parsing, fine-grained entity typing) for 5 languages representing 3 language types. Our main results clearly indicate that there is no one-size-fits-all configuration, as performance is both language- and task-dependent. We also show that configurations based on unsupervised segmentation (e.g., BPE, Morfessor) are sometimes comparable to or even outperform the ones based on supervised word segmentation.</abstract>
      <url hash="bef62c35">N19-1097</url>
      <doi>10.18653/v1/N19-1097</doi>
      <bibkey>zhu-etal-2019-systematic</bibkey>
      <pwccode url="https://github.com/cambridgeltl/sw_study" additional="false">cambridgeltl/sw_study</pwccode>
    </paper>
    <paper id="99">
      <title>Integration of Knowledge Graph Embedding Into <a href="https://en.wikipedia.org/wiki/Topic_model">Topic Modeling</a> with Hierarchical Dirichlet Process<fixed-case>D</fixed-case>irichlet Process</title>
      <author><first>Dingcheng</first><last>Li</last></author>
      <author><first>Siamak</first><last>Zamani</last></author>
      <author><first>Jingyuan</first><last>Zhang</last></author>
      <author><first>Ping</first><last>Li</last></author>
      <pages>940–950</pages>
      <abstract>Leveraging <a href="https://en.wikipedia.org/wiki/Domain_knowledge">domain knowledge</a> is an effective strategy for enhancing the quality of inferred low-dimensional representations of documents by <a href="https://en.wikipedia.org/wiki/Topic_model">topic models</a>. In this paper, we develop topic modeling with knowledge graph embedding (TMKGE), a Bayesian nonparametric model to employ knowledge graph (KG) embedding in the context of <a href="https://en.wikipedia.org/wiki/Topic_modeling">topic modeling</a>, for extracting more coherent topics. Specifically, we build a hierarchical Dirichlet process (HDP) based model to flexibly borrow information from KG to improve the interpretability of topics. An efficient online variational inference method based on a stick-breaking construction of HDP is developed for TMKGE, making TMKGE suitable for large document corpora and KGs. Experiments on three public datasets illustrate the superior performance of TMKGE in terms of topic coherence and document classification accuracy, compared to state-of-the-art topic modeling methods.<i>topic modeling with knowledge graph embedding</i> (TMKGE), a Bayesian nonparametric model to employ knowledge graph (KG) embedding in the context of topic modeling, for extracting more coherent topics. Specifically, we build a hierarchical Dirichlet process (HDP) based model to flexibly borrow information from KG to improve the interpretability of topics. An efficient online variational inference method based on a stick-breaking construction of HDP is developed for TMKGE, making TMKGE suitable for large document corpora and KGs. Experiments on three public datasets illustrate the superior performance of TMKGE in terms of topic coherence and document classification accuracy, compared to state-of-the-art topic modeling methods.</abstract>
      <url hash="41547526">N19-1099</url>
      <doi>10.18653/v1/N19-1099</doi>
      <bibkey>li-etal-2019-integration</bibkey>
    </paper>
    <paper id="101">
      <title>Generating Token-Level Explanations for Natural Language Inference</title>
      <author><first>James</first><last>Thorne</last></author>
      <author><first>Andreas</first><last>Vlachos</last></author>
      <author><first>Christos</first><last>Christodoulopoulos</last></author>
      <author><first>Arpit</first><last>Mittal</last></author>
      <pages>963–969</pages>
      <abstract>The task of Natural Language Inference (NLI) is widely modeled as supervised sentence pair classification. While there has been a lot of work recently on generating explanations of the predictions of <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> on a single piece of text, there have been no attempts to generate explanations of <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> operating on pairs of sentences. In this paper, we show that it is possible to generate token-level explanations for NLI without the need for training data explicitly annotated for this purpose. We use a simple LSTM architecture and evaluate both LIME and Anchor explanations for this task. We compare these to a Multiple Instance Learning (MIL) method that uses thresholded attention make token-level predictions. The approach we present in this paper is a novel extension of zero-shot single-sentence tagging to sentence pairs for NLI. We conduct our experiments on the well-studied SNLI dataset that was recently augmented with manually annotation of the tokens that explain the <a href="https://en.wikipedia.org/wiki/Logical_consequence">entailment relation</a>. We find that our white-box MIL-based method, while orders of magnitude faster, does not reach the same <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> as the black-box methods.</abstract>
      <url hash="3a30b78a">N19-1101</url>
      <doi>10.18653/v1/N19-1101</doi>
      <bibkey>thorne-etal-2019-generating</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/e-snli">e-SNLI</pwcdataset>
    </paper>
    <paper id="103">
      <title>Adaptive Convolution for Multi-Relational Learning</title>
      <author><first>Xiaotian</first><last>Jiang</last></author>
      <author><first>Quan</first><last>Wang</last></author>
      <author><first>Bin</first><last>Wang</last></author>
      <pages>978–987</pages>
      <abstract>We consider the problem of learning <a href="https://en.wikipedia.org/wiki/Distributed_representation">distributed representations</a> for entities and relations of multi-relational data so as to predict missing links therein. Convolutional neural networks have recently shown their superiority for this <a href="https://en.wikipedia.org/wiki/Problem_solving">problem</a>, bringing increased model expressiveness while remaining parameter efficient. Despite the success, previous convolution designs fail to model full interactions between input entities and relations, which potentially limits the performance of link prediction. In this work we introduce ConvR, an adaptive convolutional network designed to maximize entity-relation interactions in a convolutional fashion. ConvR adaptively constructs convolution filters from <a href="https://en.wikipedia.org/wiki/Binary_relation">relation representations</a>, and applies these filters across <a href="https://en.wikipedia.org/wiki/Binary_relation">entity representations</a> to generate <a href="https://en.wikipedia.org/wiki/Convolution">convolutional features</a>. As such, ConvR enables rich interactions between entity and relation representations at diverse regions, and all the <a href="https://en.wikipedia.org/wiki/Convolution">convolutional features</a> generated will be able to capture such <a href="https://en.wikipedia.org/wiki/Interaction">interactions</a>. We evaluate ConvR on multiple benchmark datasets. Experimental results show that : (1) ConvR performs substantially better than competitive baselines in almost all the metrics and on all the datasets ; (2) Compared with state-of-the-art convolutional models, ConvR is not only more effective but also more efficient. It offers a 7 % increase in MRR and a 6 % increase in Hits@10, while saving 12 % in parameter storage.</abstract>
      <url hash="8f3d2c7b">N19-1103</url>
      <doi>10.18653/v1/N19-1103</doi>
      <video href="https://vimeo.com/353480570" />
      <bibkey>jiang-etal-2019-adaptive</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/fb15k">FB15k</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/fb15k-237">FB15k-237</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wn18">WN18</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wn18rr">WN18RR</pwcdataset>
    </paper>
    <paper id="107">
      <title>Relation Extraction with Temporal Reasoning Based on Memory Augmented Distant Supervision</title>
      <author><first>Jianhao</first><last>Yan</last></author>
      <author><first>Lin</first><last>He</last></author>
      <author><first>Ruqin</first><last>Huang</last></author>
      <author><first>Jian</first><last>Li</last></author>
      <author><first>Ying</first><last>Liu</last></author>
      <pages>1019–1030</pages>
      <abstract>Distant supervision (DS) is an important paradigm for automatically extracting relations. It utilizes existing <a href="https://en.wikipedia.org/wiki/Knowledge_base">knowledge base</a> to collect examples for the relation we intend to extract, and then uses these examples to automatically generate the training data. However, the examples collected can be very noisy, and pose significant challenge for obtaining high quality labels. Previous work has made remarkable progress in predicting the relation from distant supervision, but typically ignores the temporal relations among those supervising instances. This paper formulates the problem of relation extraction with temporal reasoning and proposes a solution to predict whether two given entities participate in a relation at a given time spot. For this purpose, we construct a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> called WIKI-TIME which additionally includes the valid period of a certain relation of two entities in the <a href="https://en.wikipedia.org/wiki/Knowledge_base">knowledge base</a>. We propose a novel neural model to incorporate both the temporal information encoding and sequential reasoning. The experimental results show that, compared with the best of existing models, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves better performance in both WIKI-TIME dataset and the well-studied NYT-10 dataset.</abstract>
      <url hash="a69a5507">N19-1107</url>
      <doi>10.18653/v1/N19-1107</doi>
      <video href="https://vimeo.com/360608466" />
      <bibkey>yan-etal-2019-relation</bibkey>
      <pwccode url="https://github.com/ElliottYan/DS_Temporal" additional="false">ElliottYan/DS_Temporal</pwccode>
    </paper>
    <paper id="108">
      <title>Integrating Semantic Knowledge to Tackle Zero-shot Text Classification</title>
      <author><first>Jingqing</first><last>Zhang</last></author>
      <author><first>Piyawat</first><last>Lertvittayakumjorn</last></author>
      <author><first>Yike</first><last>Guo</last></author>
      <pages>1031–1040</pages>
      <abstract>Insufficient or even unavailable training data of emerging classes is a big challenge of many classification tasks, including <a href="https://en.wikipedia.org/wiki/Text_classification">text classification</a>. Recognising text documents of classes that have never been seen in the learning stage, so-called zero-shot text classification, is therefore difficult and only limited previous works tackled this problem. In this paper, we propose a two-phase framework together with <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a> and feature augmentation to solve this problem. Four kinds of semantic knowledge (word embeddings, class descriptions, class hierarchy, and a general knowledge graph) are incorporated into the proposed framework to deal with instances of unseen classes effectively. Experimental results show that each and the combination of the two phases achieve the best overall accuracy compared with baselines and recent approaches in classifying real-world texts under the zero-shot scenario.</abstract>
      <url hash="e702cbf8">N19-1108</url>
      <attachment type="presentation" hash="08763065">N19-1108.Presentation.pdf</attachment>
      <doi>10.18653/v1/N19-1108</doi>
      <video href="https://vimeo.com/355765532" />
      <bibkey>zhang-etal-2019-integrating</bibkey>
      <pwccode url="https://github.com/JingqingZ/KG4ZeroShotText" additional="true">JingqingZ/KG4ZeroShotText</pwccode>
    </paper>
    <paper id="109">
      <title>Word-Node2Vec : Improving Word Embedding with Document-Level Non-Local Word Co-occurrences<fixed-case>N</fixed-case>ode2<fixed-case>V</fixed-case>ec: Improving Word Embedding with Document-Level Non-Local Word Co-occurrences</title>
      <author><first>Procheta</first><last>Sen</last></author>
      <author><first>Debasis</first><last>Ganguly</last></author>
      <author><first>Gareth</first><last>Jones</last></author>
      <pages>1041–1051</pages>
      <abstract>A standard word embedding algorithm, such as <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> and glove, makes a strong assumption that words are likely to be semantically related only if they co-occur locally within a window of fixed size. However, this strong assumption may not capture the semantic association between words that co-occur frequently but non-locally within documents. In this paper, we propose a graph-based word embedding method, named ‘word-node2vec’. By relaxing the strong constraint of <a href="https://en.wikipedia.org/wiki/Principle_of_locality">locality</a>, our method is able to capture both the local and non-local co-occurrences. Word-node2vec constructs a <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph</a> where every <a href="https://en.wikipedia.org/wiki/Vertex_(graph_theory)">node</a> represents a word and an edge between two nodes represents a combination of both local (e.g. word2vec) and document-level co-occurrences. Our experiments show that word-node2vec outperforms <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> and glove on a range of different tasks, such as predicting word-pair similarity, word analogy and concept categorization.</abstract>
      <url hash="7ad29864">N19-1109</url>
      <doi>10.18653/v1/N19-1109</doi>
      <video href="https://vimeo.com/355773895" />
      <bibkey>sen-etal-2019-word</bibkey>
    </paper>
    <paper id="111">
      <title>What just happened? Evaluating retrofitted distributional word vectors<fixed-case>E</fixed-case>valuating retrofitted distributional word vectors</title>
      <author><first>Dmetri</first><last>Hayes</last></author>
      <pages>1062–1072</pages>
      <abstract>Recent work has attempted to enhance vector space representations using information from structured semantic resources. This process, dubbed <a href="https://en.wikipedia.org/wiki/Retrofitting">retrofitting</a> (Faruqui et al., 2015), has yielded improvements in word similarity performance. Research has largely focused on the retrofitting algorithm, or on the kind of structured semantic resources used, but little research has explored why some <a href="https://en.wikipedia.org/wiki/Resource_(computer_science)">resources</a> perform better than others. We conducted a fine-grained analysis of the original <a href="https://en.wikipedia.org/wiki/Retrofitting">retrofitting process</a>, and found that the utility of different lexical resources for <a href="https://en.wikipedia.org/wiki/Retrofitting">retrofitting</a> depends on two factors : the coverage of the resource and the evaluation metric. Our assessment suggests that the common practice of using correlation measures to evaluate increases in performance against full word similarity benchmarks 1) obscures the benefits offered by smaller resources, and 2) overlooks incremental gains in word similarity performance. We propose root-mean-square error (RMSE) as an alternative evaluation metric, and demonstrate that <a href="https://en.wikipedia.org/wiki/Correlation_and_dependence">correlation measures</a> and RMSE sometimes yield opposite conclusions concerning the efficacy of <a href="https://en.wikipedia.org/wiki/Retrofitting">retrofitting</a>. This point is illustrated by word vectors retrofitted with novel treatments of the FrameNet data (Fillmore and Baker, 2010).</abstract>
      <url hash="319372a4">N19-1111</url>
      <attachment type="software" hash="fc149a7b">N19-1111.Software.txt</attachment>
      <doi>10.18653/v1/N19-1111</doi>
      <video href="https://vimeo.com/356031269" />
      <bibkey>hayes-2019-just</bibkey>
    </paper>
    <paper id="115">
      <title>Cooperative Learning of Disjoint Syntax and Semantics</title>
      <author><first>Serhii</first><last>Havrylov</last></author>
      <author><first>Germán</first><last>Kruszewski</last></author>
      <author><first>Armand</first><last>Joulin</last></author>
      <pages>1118–1128</pages>
      <abstract>There has been considerable attention devoted to <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> that learn to jointly infer an expression’s <a href="https://en.wikipedia.org/wiki/Syntax">syntactic structure</a> and its <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a>. Yet, Nangia and Bowman (2018) has recently shown that the current best systems fail to learn the correct parsing strategy on mathematical expressions generated from a simple <a href="https://en.wikipedia.org/wiki/Context-free_grammar">context-free grammar</a>. In this work, we present a <a href="https://en.wikipedia.org/wiki/Recursion_(computer_science)">recursive model</a> inspired by Choi et al. (2018) that reaches near perfect <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> on this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. Our <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> is composed of two separated <a href="https://en.wikipedia.org/wiki/Modular_programming">modules</a> for syntax and semantics. They are cooperatively trained with standard continuous and discrete optimisation schemes. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> does not require any linguistic structure for <a href="https://en.wikipedia.org/wiki/Supervisor">supervision</a>, and its recursive nature allows for out-of-domain generalisation. Additionally, our approach performs competitively on several <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language tasks</a>, such as <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">Natural Language Inference</a> and <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a>.</abstract>
      <url hash="2f160abc">N19-1115</url>
      <attachment type="presentation" hash="241a4d98">N19-1115.Presentation.pdf</attachment>
      <doi>10.18653/v1/N19-1115</doi>
      <video href="https://vimeo.com/364675378" />
      <bibkey>havrylov-etal-2019-cooperative</bibkey>
      <pwccode url="https://github.com/facebookresearch/latent-treelstm" additional="false">facebookresearch/latent-treelstm</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/listops">ListOps</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="116">
      <title>Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders</title>
      <author><first>Andrew</first><last>Drozdov</last></author>
      <author><first>Patrick</first><last>Verga</last></author>
      <author><first>Mohit</first><last>Yadav</last></author>
      <author><first>Mohit</first><last>Iyyer</last></author>
      <author><first>Andrew</first><last>McCallum</last></author>
      <pages>1129–1141</pages>
      <abstract>We introduce the deep inside-outside recursive autoencoder (DIORA), a fully-unsupervised method for discovering <a href="https://en.wikipedia.org/wiki/Syntax">syntax</a> that simultaneously learns representations for constituents within the induced tree. Our approach predicts each word in an input sentence conditioned on the rest of the sentence. During training we use <a href="https://en.wikipedia.org/wiki/Dynamic_programming">dynamic programming</a> to consider all possible binary trees over the sentence, and for <a href="https://en.wikipedia.org/wiki/Statistical_inference">inference</a> we use the <a href="https://en.wikipedia.org/wiki/CKY_algorithm">CKY algorithm</a> to extract the highest scoring parse. DIORA outperforms previously reported results for unsupervised binary constituency parsing on the benchmark WSJ dataset.</abstract>
      <url hash="ca457e13">N19-1116</url>
      <doi>10.18653/v1/N19-1116</doi>
      <bibkey>drozdov-etal-2019-unsupervised-latent</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="118">
      <title>Syntax-Enhanced Neural Machine Translation with Syntax-Aware Word Representations</title>
      <author><first>Meishan</first><last>Zhang</last></author>
      <author><first>Zhenghua</first><last>Li</last></author>
      <author><first>Guohong</first><last>Fu</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>1151–1161</pages>
      <abstract>Syntax has been demonstrated highly effective in neural machine translation (NMT). Previous NMT models integrate <a href="https://en.wikipedia.org/wiki/Syntax_(programming_languages)">syntax</a> by representing 1-best tree outputs from a well-trained parsing system, e.g., the representative Tree-RNN and Tree-Linearization methods, which may suffer from <a href="https://en.wikipedia.org/wiki/Propagation_of_uncertainty">error propagation</a>. In this work, we propose a novel method to integrate source-side syntax implicitly for <a href="https://en.wikipedia.org/wiki/Network_topology">NMT</a>. The basic idea is to use the intermediate hidden representations of a well-trained end-to-end dependency parser, which are referred to as syntax-aware word representations (SAWRs). Then, we simply concatenate such SAWRs with ordinary <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> to enhance basic NMT models. The <a href="https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations">method</a> can be straightforwardly integrated into the widely-used sequence-to-sequence (Seq2Seq) NMT models. We start with a representative RNN-based Seq2Seq baseline system, and test the effectiveness of our proposed method on two benchmark datasets of the Chinese-English and English-Vietnamese translation tasks, respectively. Experimental results show that the proposed approach is able to bring significant BLEU score improvements on the two <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> compared with the <a href="https://en.wikipedia.org/wiki/Baseline_(medicine)">baseline</a>, 1.74 points for <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese-English translation</a> and 0.80 point for <a href="https://en.wikipedia.org/wiki/Vietnamese_language">English-Vietnamese translation</a>, respectively. In addition, the <a href="https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations">approach</a> also outperforms the explicit Tree-RNN and Tree-Linearization methods.</abstract>
      <url hash="5a9cdffe">N19-1118</url>
      <doi>10.18653/v1/N19-1118</doi>
      <video href="https://vimeo.com/347403902" />
      <bibkey>zhang-etal-2019-syntax-enhanced</bibkey>
    </paper>
    <paper id="119">
      <title>Competence-based Curriculum Learning for Neural Machine Translation</title>
      <author><first>Emmanouil Antonios</first><last>Platanios</last></author>
      <author><first>Otilia</first><last>Stretcu</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <author><first>Barnabas</first><last>Poczos</last></author>
      <author><first>Tom</first><last>Mitchell</last></author>
      <pages>1162–1172</pages>
      <abstract>Current state-of-the-art NMT systems use large neural networks that are not only slow to train, but also often require many <a href="https://en.wikipedia.org/wiki/Heuristic">heuristics</a> and optimization tricks, such as specialized learning rate schedules and large batch sizes. This is undesirable as <a href="https://en.wikipedia.org/wiki/It_(2017_film)">it</a> requires extensive hyperparameter tuning. In this paper, we propose a curriculum learning framework for NMT that reduces training time, reduces the need for specialized heuristics or large batch sizes, and results in overall better performance. Our framework consists of a principled way of deciding which training samples are shown to the <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> at different times during training, based on the estimated difficulty of a sample and the current competence of the <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a>. Filtering training samples in this manner prevents the model from getting stuck in bad local optima, making it converge faster and reach a better solution than the common approach of uniformly sampling training examples. Furthermore, the proposed method can be easily applied to existing NMT models by simply modifying their input data pipelines. We show that our framework can help improve the <a href="https://en.wikipedia.org/wiki/Time_complexity">training time</a> and the performance of both <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network models</a> and Transformers, achieving up to a 70 % decrease in <a href="https://en.wikipedia.org/wiki/Time_complexity">training time</a>, while at the same time obtaining accuracy improvements of up to 2.2 BLEU.</abstract>
      <url hash="1851f7f5">N19-1119</url>
      <doi>10.18653/v1/N19-1119</doi>
      <video href="https://vimeo.com/347406566" />
      <bibkey>platanios-etal-2019-competence</bibkey>
    </paper>
    <paper id="121">
      <title>Consistency by Agreement in Zero-Shot Neural Machine Translation</title>
      <author><first>Maruan</first><last>Al-Shedivat</last></author>
      <author><first>Ankur</first><last>Parikh</last></author>
      <pages>1184–1197</pages>
      <abstract>Generalization and reliability of multilingual translation often highly depend on the amount of available parallel data for each language pair of interest. In this paper, we focus on zero-shot generalizationa challenging setup that tests <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> on translation directions they have not been optimized for at training time. To solve the problem, we (i) reformulate multilingual translation as probabilistic inference, (ii) define the notion of zero-shot consistency and show why standard training often results in models unsuitable for zero-shot tasks, and (iii) introduce a consistent agreement-based training method that encourages the model to produce equivalent translations of parallel sentences in auxiliary languages. We test our multilingual NMT models on multiple public zero-shot translation benchmarks (IWSLT17, UN corpus, Europarl) and show that agreement-based learning often results in 2-3 BLEU zero-shot improvement over strong baselines without any loss in performance on supervised translation directions.</abstract>
      <url hash="90db10e8">N19-1121</url>
      <doi>10.18653/v1/N19-1121</doi>
      <video href="https://vimeo.com/347411013" />
      <bibkey>al-shedivat-parikh-2019-consistency</bibkey>
      <pwccode url="https://github.com/google-research/language/tree/master/language/labs/consistent_zero_shot_nmt" additional="true">google-research/language</pwccode>
    </paper>
    <paper id="123">
      <title>Rethinking Action Spaces for <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement Learning</a> in End-to-end Dialog Agents with Latent Variable Models</title>
      <author><first>Tiancheng</first><last>Zhao</last></author>
      <author><first>Kaige</first><last>Xie</last></author>
      <author><first>Maxine</first><last>Eskenazi</last></author>
      <pages>1208–1218</pages>
      <abstract>Defining action spaces for conversational agents and optimizing their <a href="https://en.wikipedia.org/wiki/Decision-making">decision-making process</a> with <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> is an enduring challenge. Common practice has been to use handcrafted dialog acts, or the output vocabulary, e.g. in neural encoder decoders, as the action spaces. Both have their own limitations. This paper proposes a novel latent action framework that treats the action spaces of an end-to-end dialog agent as <a href="https://en.wikipedia.org/wiki/Latent_variable">latent variables</a> and develops <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised methods</a> in order to induce its own action space from the data. Comprehensive experiments are conducted examining both continuous and discrete action types and two different <a href="https://en.wikipedia.org/wiki/Mathematical_optimization">optimization methods</a> based on stochastic variational inference. Results show that the proposed latent actions achieve superior empirical performance improvement over previous word-level policy gradient methods on both DealOrNoDeal and MultiWoz dialogs. Our detailed analysis also provides insights about various latent variable approaches for <a href="https://en.wikipedia.org/wiki/Policy_learning">policy learning</a> and can serve as a foundation for developing better latent actions in future research.</abstract>
      <url hash="48b2322e">N19-1123</url>
      <doi>10.18653/v1/N19-1123</doi>
      <video href="https://vimeo.com/360620730" />
      <bibkey>zhao-etal-2019-rethinking</bibkey>
      <pwccode url="https://github.com/snakeztc/NeuralDialog-LaRL" additional="true">snakeztc/NeuralDialog-LaRL</pwccode>
    </paper>
    <paper id="128">
      <title>WiC : the Word-in-Context Dataset for Evaluating Context-Sensitive Meaning Representations<fixed-case>W</fixed-case>i<fixed-case>C</fixed-case>: the Word-in-Context Dataset for Evaluating Context-Sensitive Meaning Representations</title>
      <author><first>Mohammad Taher</first><last>Pilehvar</last></author>
      <author><first>Jose</first><last>Camacho-Collados</last></author>
      <pages>1267–1273</pages>
      <abstract>By design, word embeddings are unable to model the <a href="https://en.wikipedia.org/wiki/Semantics">dynamic nature of words’ semantics</a>, i.e., the property of words to correspond to potentially different meanings. To address this limitation, dozens of specialized meaning representation techniques such as sense or contextualized embeddings have been proposed. However, despite the popularity of research on this topic, very few <a href="https://en.wikipedia.org/wiki/Benchmarking">evaluation benchmarks</a> exist that specifically focus on the dynamic semantics of words. In this paper we show that existing <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> have surpassed the performance ceiling of the standard evaluation dataset for the purpose, i.e., Stanford Contextual Word Similarity, and highlight its shortcomings. To address the lack of a suitable <a href="https://en.wikipedia.org/wiki/Benchmark_(computing)">benchmark</a>, we put forward a large-scale Word in Context dataset, called WiC, based on annotations curated by experts, for generic evaluation of context-sensitive representations. WiC is released in https://pilehvar.github.io/wic/.</abstract>
      <url hash="46292ddb">N19-1128</url>
      <doi>10.18653/v1/N19-1128</doi>
      <bibkey>pilehvar-camacho-collados-2019-wic</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wic">WiC</pwcdataset>
    </paper>
    <paper id="130">
      <title>Casting Light on Invisible Cities : Computationally Engaging with Literary Criticism<fixed-case>C</fixed-case>asting <fixed-case>L</fixed-case>ight on <fixed-case>I</fixed-case>nvisible <fixed-case>C</fixed-case>ities: <fixed-case>C</fixed-case>omputationally <fixed-case>E</fixed-case>ngaging with <fixed-case>L</fixed-case>iterary <fixed-case>C</fixed-case>riticism</title>
      <author><first>Shufan</first><last>Wang</last></author>
      <author><first>Mohit</first><last>Iyyer</last></author>
      <pages>1291–1297</pages>
      <abstract>Literary critics often attempt to uncover meaning in a single work of literature through careful reading and analysis. Applying <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing methods</a> to aid in such <a href="https://en.wikipedia.org/wiki/Literary_criticism">literary analyses</a> remains a challenge in <a href="https://en.wikipedia.org/wiki/Digital_humanities">digital humanities</a>. While most previous work focuses on distant reading by algorithmically discovering high-level patterns from large collections of literary works, here we sharpen the focus of our methods to a single <a href="https://en.wikipedia.org/wiki/Literary_theory">literary theory</a> about Italo Calvino’s postmodern novel Invisible Cities, which consists of 55 short descriptions of imaginary cities. Calvino has provided a classification of these <a href="https://en.wikipedia.org/wiki/City">cities</a> into eleven thematic groups, but literary scholars disagree as to how trustworthy his categorization is. Due to the unique structure of this novel, we can computationally weigh in on this debate : we leverage pretrained contextualized representations to embed each city’s description and use <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised methods</a> to cluster these embeddings. Additionally, we compare results of our <a href="https://en.wikipedia.org/wiki/Computational_model">computational approach</a> to similarity judgments generated by <a href="https://en.wikipedia.org/wiki/User_(computing)">human readers</a>. Our work is a first step towards incorporating <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> into <a href="https://en.wikipedia.org/wiki/Literary_criticism">literary criticism</a>.<i>Invisible Cities</i>, which consists of 55 short descriptions of imaginary cities. Calvino has provided a classification of these cities into eleven thematic groups, but literary scholars disagree as to how trustworthy his categorization is. Due to the unique structure of this novel, we can computationally weigh in on this debate: we leverage pretrained contextualized representations to embed each city’s description and use unsupervised methods to cluster these embeddings. Additionally, we compare results of our computational approach to similarity judgments generated by human readers. Our work is a first step towards incorporating natural language processing into literary criticism.</abstract>
      <url hash="9ff317cc">N19-1130</url>
      <doi>10.18653/v1/N19-1130</doi>
      <bibkey>wang-iyyer-2019-casting</bibkey>
    </paper>
    <paper id="131">
      <title>PAWS : Paraphrase Adversaries from Word Scrambling<fixed-case>PAWS</fixed-case>: Paraphrase Adversaries from Word Scrambling</title>
      <author><first>Yuan</first><last>Zhang</last></author>
      <author><first>Jason</first><last>Baldridge</last></author>
      <author><first>Luheng</first><last>He</last></author>
      <pages>1298–1308</pages>
      <abstract>Existing paraphrase identification datasets lack sentence pairs that have high lexical overlap without being <a href="https://en.wikipedia.org/wiki/Paraphrase">paraphrases</a>. Models trained on such data fail to distinguish pairs like flights from New York to Florida and flights from Florida to New York. This paper introduces PAWS (Paraphrase Adversaries from Word Scrambling), a new dataset with 108,463 well-formed paraphrase and non-paraphrase pairs with high lexical overlap. Challenging pairs are generated by controlled word swapping and back translation, followed by fluency and paraphrase judgments by human raters. State-of-the-art models trained on existing datasets have dismal performance on PAWS (40 % accuracy) ; however, including PAWS training data for these models improves their accuracy to 85 % while maintaining performance on existing tasks. In contrast, <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> that do not capture non-local contextual information fail even with PAWS training examples. As such, PAWS provides an effective instrument for driving further progress on <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> that better exploit <a href="https://en.wikipedia.org/wiki/Structure">structure</a>, <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context</a>, and <a href="https://en.wikipedia.org/wiki/Pairwise_comparison">pairwise comparisons</a>.</abstract>
      <url hash="fd99c766">N19-1131</url>
      <doi>10.18653/v1/N19-1131</doi>
      <bibkey>zhang-etal-2019-paws</bibkey>
      <pwccode url="" additional="true" />
      <pwcdataset url="https://paperswithcode.com/dataset/paws">PAWS</pwcdataset>
    </paper>
    <paper id="134">
      <title>Adaptation of Hierarchical Structured Models for <a href="https://en.wikipedia.org/wiki/Speech_recognition">Speech Act Recognition</a> in Asynchronous Conversation</title>
      <author><first>Tasnim</first><last>Mohiuddin</last></author>
      <author><first>Thanh-Tung</first><last>Nguyen</last></author>
      <author><first>Shafiq</first><last>Joty</last></author>
      <pages>1326–1336</pages>
      <abstract>We address the problem of speech act recognition (SAR) in asynchronous conversations (forums, emails). Unlike <a href="https://en.wikipedia.org/wiki/Synchronization">synchronous conversations</a> (e.g., meetings, phone), asynchronous domains lack large labeled datasets to train an effective SAR model. In this paper, we propose methods to effectively leverage abundant unlabeled conversational data and the available labeled data from synchronous domains. We carry out our research in three main steps. First, we introduce a neural architecture based on hierarchical LSTMs and conditional random fields (CRF) for SAR, and show that our method outperforms existing methods when trained on in-domain data only. Second, we improve our initial SAR models by <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning">semi-supervised learning</a> in the form of pretrained word embeddings learned from a large unlabeled conversational corpus. Finally, we employ adversarial training to improve the results further by leveraging the labeled data from synchronous domains and by explicitly modeling the distributional shift in two domains.</abstract>
      <url hash="11d3a4cc">N19-1134</url>
      <doi>10.18653/v1/N19-1134</doi>
      <bibkey>mohiuddin-etal-2019-adaptation</bibkey>
    </paper>
    <paper id="137">
      <title>Multi-Channel Convolutional Neural Network for Twitter Emotion and Sentiment Recognition<fixed-case>T</fixed-case>witter Emotion and Sentiment Recognition</title>
      <author><first>Jumayel</first><last>Islam</last></author>
      <author><first>Robert E.</first><last>Mercer</last></author>
      <author><first>Lu</first><last>Xiao</last></author>
      <pages>1355–1365</pages>
      <abstract>The advent of micro-blogging sites has paved the way for researchers to collect and analyze huge volumes of data in recent years. Twitter, being one of the leading social networking sites worldwide, provides a great opportunity to its users for expressing their states of mind via short messages which are called <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a>. The urgency of identifying emotions and sentiments conveyed through <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> has led to several research works. It provides a great way to understand <a href="https://en.wikipedia.org/wiki/Human_psychology">human psychology</a> and impose a challenge to researchers to analyze their content easily. In this paper, we propose a novel use of a multi-channel convolutional neural architecture which can effectively use different emotion and sentiment indicators such as <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a>, <a href="https://en.wikipedia.org/wiki/Emoticon">emoticons</a> and <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a> that are present in the <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> and improve the performance of emotion and sentiment identification. We also investigate the incorporation of different lexical features in the <a href="https://en.wikipedia.org/wiki/Neural_network">neural network model</a> and its effect on the emotion and sentiment identification task. We analyze our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> on some standard datasets and compare its effectiveness with existing techniques.</abstract>
      <url hash="d4906ef4">N19-1137</url>
      <doi>10.18653/v1/N19-1137</doi>
      <bibkey>islam-etal-2019-multi</bibkey>
    </paper>
    <paper id="138">
      <title>Detecting Cybersecurity Events from Noisy Short Text</title>
      <author><first>Semih</first><last>Yagcioglu</last></author>
      <author><first>Mehmet Saygin</first><last>Seyfioglu</last></author>
      <author><first>Begum</first><last>Citamak</last></author>
      <author><first>Batuhan</first><last>Bardak</last></author>
      <author><first>Seren</first><last>Guldamlasioglu</last></author>
      <author><first>Azmi</first><last>Yuksel</last></author>
      <author><first>Emin Islam</first><last>Tatli</last></author>
      <pages>1366–1372</pages>
      <abstract>It is very critical to analyze messages shared over <a href="https://en.wikipedia.org/wiki/List_of_social_networking_websites">social networks</a> for <a href="https://en.wikipedia.org/wiki/Cyber_threat_intelligence">cyber threat intelligence</a> and cyber-crime prevention. In this study, we propose a method that leverages both domain-specific word embeddings and task-specific features to detect cyber security events from <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a>. Our model employs a convolutional neural network (CNN) and a long short-term memory (LSTM) recurrent neural network which takes word level meta-embeddings as inputs and incorporates contextual embeddings to classify noisy short text. We collected a new dataset of cyber security related tweets from <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> and manually annotated a subset of 2 K of them. We experimented with this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and concluded that the proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms both traditional and neural baselines. The results suggest that our <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">method</a> works well for detecting cyber security events from noisy short text.</abstract>
      <url hash="2146b5d3">N19-1138</url>
      <attachment type="supplementary" hash="515c2c43">N19-1138.Supplementary.pdf</attachment>
      <doi>10.18653/v1/N19-1138</doi>
      <bibkey>yagcioglu-etal-2019-detecting</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-question-answering">Visual Question Answering</pwcdataset>
    </paper>
    <paper id="139">
      <title>White-to-Black : Efficient Distillation of Black-Box Adversarial Attacks</title>
      <author><first>Yotam</first><last>Gil</last></author>
      <author><first>Yoav</first><last>Chai</last></author>
      <author><first>Or</first><last>Gorodissky</last></author>
      <author><first>Jonathan</first><last>Berant</last></author>
      <pages>1373–1379</pages>
      <abstract>Adversarial examples are important for understanding the behavior of neural models, and can improve their <a href="https://en.wikipedia.org/wiki/Robustness_(computer_science)">robustness</a> through adversarial training. Recent work in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> generated adversarial examples by assuming white-box access to the attacked model, and optimizing the input directly against it (Ebrahimi et al., 2018). In this work, we show that the knowledge implicit in the <a href="https://en.wikipedia.org/wiki/Mathematical_optimization">optimization procedure</a> can be distilled into another more efficient <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a>. We train a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> to emulate the behavior of a white-box attack and show that it generalizes well across examples. Moreover, <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> reduces adversarial example generation time by 19x-39x. We also show that our approach transfers to a black-box setting, by attacking The Google Perspective API and exposing its vulnerability. Our attack flips the API-predicted label in 42 % of the generated examples, while humans maintain high-accuracy in predicting the gold label.</abstract>
      <url hash="5d6fde32">N19-1139</url>
      <doi>10.18653/v1/N19-1139</doi>
      <bibkey>gil-etal-2019-white</bibkey>
      <pwccode url="https://github.com/orgoro/white-2-black" additional="false">orgoro/white-2-black</pwccode>
    </paper>
    <paper id="141">
      <title>Fake News Detection using Deep Markov Random Fields<fixed-case>M</fixed-case>arkov Random Fields</title>
      <author><first>Duc Minh</first><last>Nguyen</last></author>
      <author><first>Tien Huu</first><last>Do</last></author>
      <author><first>Robert</first><last>Calderbank</last></author>
      <author><first>Nikos</first><last>Deligiannis</last></author>
      <pages>1391–1400</pages>
      <abstract>Deep-learning-based models have been successfully applied to the problem of <a href="https://en.wikipedia.org/wiki/Fake_news">detecting fake news</a> on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. While the correlations among news articles have been shown to be effective cues for online news analysis, existing deep-learning-based methods often ignore this information and only consider each news article individually. To overcome this limitation, we develop a graph-theoretic method that inherits the power of <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> while at the same time utilizing the correlations among the articles. We formulate fake news detection as an inference problem in a Markov random field (MRF) which can be solved by the iterative mean-field algorithm. We then unfold the mean-field algorithm into hidden layers that are composed of common neural network operations. By integrating these hidden layers on top of a <a href="https://en.wikipedia.org/wiki/Deep_learning">deep network</a>, which produces the MRF potentials, we obtain our deep MRF model for fake news detection. Experimental results on well-known datasets show that the proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> improves upon various <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art models</a>.</abstract>
      <url hash="9488af62">N19-1141</url>
      <doi>10.18653/v1/N19-1141</doi>
      <bibkey>nguyen-etal-2019-fake</bibkey>
    </paper>
    <paper id="143">
      <title>Vector of Locally Aggregated Embeddings for Text Representation</title>
      <author><first>Hadi</first><last>Amiri</last></author>
      <author><first>Mitra</first><last>Mohtarami</last></author>
      <pages>1408–1414</pages>
      <abstract>We present Vector of Locally Aggregated Embeddings (VLAE) for effective and, ultimately, lossless representation of textual content. Our <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> encodes each input text by effectively identifying and integrating the representations of its semantically-relevant parts. The proposed model generates high quality representation of textual content and improves the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> performance of current state-of-the-art deep averaging networks across several text classification tasks.</abstract>
      <url hash="6da911dc">N19-1143</url>
      <doi>10.18653/v1/N19-1143</doi>
      <bibkey>amiri-mohtarami-2019-vector</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
    </paper>
    <paper id="145">
      <title>Biomedical Event Extraction based on Knowledge-driven Tree-LSTM<fixed-case>LSTM</fixed-case></title>
      <author><first>Diya</first><last>Li</last></author>
      <author><first>Lifu</first><last>Huang</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <author><first>Jiawei</first><last>Han</last></author>
      <pages>1421–1430</pages>
      <abstract>Event extraction for the biomedical domain is more challenging than that in the general news domain since it requires broader acquisition of domain-specific knowledge and deeper understanding of complex contexts. To better encode contextual information and external background knowledge, we propose a novel knowledge base (KB)-driven tree-structured long short-term memory networks (Tree-LSTM) framework, incorporating two new types of features : (1) dependency structures to capture wide contexts ; (2) entity properties (types and category descriptions) from external ontologies via entity linking. We evaluate our approach on the BioNLP shared task with Genia dataset and achieve a new state-of-the-art result. In addition, both quantitative and qualitative studies demonstrate the advancement of the Tree-LSTM and the external knowledge representation for biomedical event extraction.</abstract>
      <url hash="61883d21">N19-1145</url>
      <doi>10.18653/v1/N19-1145</doi>
      <bibkey>li-etal-2019-biomedical</bibkey>
    </paper>
    <paper id="150">
      <title>Predicting Annotation Difficulty to Improve Task Routing and Model Performance for Biomedical Information Extraction</title>
      <author><first>Yinfei</first><last>Yang</last></author>
      <author><first>Oshin</first><last>Agarwal</last></author>
      <author><first>Chris</first><last>Tar</last></author>
      <author><first>Byron C.</first><last>Wallace</last></author>
      <author><first>Ani</first><last>Nenkova</last></author>
      <pages>1471–1480</pages>
      <abstract>Modern NLP systems require high-quality annotated data. For specialized domains, expert annotations may be prohibitively expensive ; the alternative is to rely on <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourcing</a> to reduce costs at the risk of introducing noise. In this paper we demonstrate that directly modeling instance difficulty can be used to improve <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> performance and to route instances to appropriate annotators. Our difficulty prediction model combines two learned representations : a ‘universal’ encoder trained on out of domain data, and a task-specific encoder. Experiments on a complex biomedical information extraction task using expert and lay annotators show that : (i) simply excluding from the training data instances predicted to be difficult yields a small boost in performance ; (ii) using difficulty scores to weight instances during training provides further, consistent gains ; (iii) assigning instances predicted to be difficult to domain experts is an effective strategy for task routing. Further, our experiments confirm the expectation that for such domain-specific tasks expert annotations are of much higher quality and preferable to obtain if practical and that augmenting small amounts of expert data with a larger set of lay annotations leads to further improvements in model performance.</abstract>
      <url hash="7819465d">N19-1150</url>
      <doi>10.18653/v1/N19-1150</doi>
      <bibkey>yang-etal-2019-predicting</bibkey>
    </paper>
    <paper id="151">
      <title>Detecting Depression in <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a> using Fine-Grained Emotions</title>
      <author><first>Mario Ezra</first><last>Aragón</last></author>
      <author><first>Adrian Pastor</first><last>López-Monroy</last></author>
      <author><first>Luis Carlos</first><last>González-Gurrola</last></author>
      <author><first>Manuel</first><last>Montes-y-Gómez</last></author>
      <pages>1481–1486</pages>
      <abstract>Nowadays <a href="https://en.wikipedia.org/wiki/Social_media">social media platforms</a> are the most popular way for people to share information, from work issues to personal matters. For example, people with health disorders tend to share their concerns for advice, support or simply to relieve suffering. This provides a great opportunity to proactively detect these users and refer them as soon as possible to professional help. We propose a new representation called Bag of Sub-Emotions (BoSE), which represents social media documents by a set of fine-grained emotions automatically generated using a lexical resource of emotions and subword embeddings. The proposed <a href="https://en.wikipedia.org/wiki/Representation_(mathematics)">representation</a> is evaluated in the task of <a href="https://en.wikipedia.org/wiki/Depression_(mood)">depression detection</a>. The results are encouraging ; the usage of fine-grained emotions improved the results from a representation based on the <a href="https://en.wikipedia.org/wiki/Emotion">core emotions</a> and obtained competitive results in comparison to state of the art approaches.</abstract>
      <url hash="f426431a">N19-1151</url>
      <doi>10.18653/v1/N19-1151</doi>
      <bibkey>aragon-etal-2019-detecting</bibkey>
    </paper>
    <paper id="154">
      <title>One Size Does Not Fit All : Comparing NMT Representations of Different Granularities<fixed-case>NMT</fixed-case> Representations of Different Granularities</title>
      <author><first>Nadir</first><last>Durrani</last></author>
      <author><first>Fahim</first><last>Dalvi</last></author>
      <author><first>Hassan</first><last>Sajjad</last></author>
      <author><first>Yonatan</first><last>Belinkov</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <pages>1504–1516</pages>
      <abstract>Recent work has shown that contextualized word representations derived from <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> are a viable alternative to such from simple word predictions tasks. This is because the internal understanding that needs to be built in order to be able to translate from one language to another is much more comprehensive. Unfortunately, computational and memory limitations as of present prevent NMT models from using large word vocabularies, and thus alternatives such as subword units (BPE and morphological segmentations) and <a href="https://en.wikipedia.org/wiki/Character_(symbol)">characters</a> have been used. Here we study the impact of using different kinds of units on the quality of the resulting representations when used to model <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphology</a>, <a href="https://en.wikipedia.org/wiki/Syntax">syntax</a>, and <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a>. We found that while representations derived from subwords are slightly better for modeling <a href="https://en.wikipedia.org/wiki/Syntax">syntax</a>, character-based representations are superior for modeling <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphology</a> and are also more robust to noisy input.</abstract>
      <url hash="a141c3a4">N19-1154</url>
      <doi>10.18653/v1/N19-1154</doi>
      <video href="https://vimeo.com/360694967" />
      <bibkey>durrani-etal-2019-one</bibkey>
    </paper>
    <paper id="155">
      <title>A Simple Joint Model for Improved Contextual Neural Lemmatization</title>
      <author><first>Chaitanya</first><last>Malaviya</last></author>
      <author><first>Shijie</first><last>Wu</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <pages>1517–1528</pages>
      <abstract>English verbs have multiple forms. For instance, talk may also appear as talks, talked or talking, depending on the context. The NLP task of <a href="https://en.wikipedia.org/wiki/Lemmatization">lemmatization</a> seeks to map these diverse forms back to a canonical one, known as the lemma. We present a simple joint neural model for <a href="https://en.wikipedia.org/wiki/Lemmatization">lemmatization</a> and morphological tagging that achieves state-of-the-art results on 20 languages from the Universal Dependencies corpora. Our paper describes the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> in addition to training and decoding procedures. Error analysis indicates that joint morphological tagging and <a href="https://en.wikipedia.org/wiki/Lemmatization">lemmatization</a> is especially helpful in low-resource lemmatization and languages that display a larger degree of morphological complexity.</abstract>
      <url hash="2d5a381f">N19-1155</url>
      <doi>10.18653/v1/N19-1155</doi>
      <video href="https://vimeo.com/360705702" />
      <bibkey>malaviya-etal-2019-simple</bibkey>
    </paper>
    <paper id="159">
      <title>Recursive Subtree Composition in LSTM-Based Dependency Parsing<fixed-case>LSTM</fixed-case>-Based Dependency Parsing</title>
      <author><first>Miryam</first><last>de Lhoneux</last></author>
      <author><first>Miguel</first><last>Ballesteros</last></author>
      <author><first>Joakim</first><last>Nivre</last></author>
      <pages>1566–1576</pages>
      <abstract>The need for tree structure modelling on top of sequence modelling is an open issue in neural dependency parsing. We investigate the impact of adding a <a href="https://en.wikipedia.org/wiki/Tree_layer">tree layer</a> on top of a <a href="https://en.wikipedia.org/wiki/Sequential_model">sequential model</a> by recursively composing subtree representations (composition) in a transition-based parser that uses features extracted by a BiLSTM. Composition seems superfluous with such a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>, suggesting that BiLSTMs capture information about <a href="https://en.wikipedia.org/wiki/Tree_(graph_theory)">subtrees</a>. We perform model ablations to tease out the conditions under which <a href="https://en.wikipedia.org/wiki/Composition_(music)">composition</a> helps. When ablating the backward LSTM, performance drops and <a href="https://en.wikipedia.org/wiki/Musical_composition">composition</a> does not recover much of the gap. When ablating the forward LSTM, performance drops less dramatically and <a href="https://en.wikipedia.org/wiki/Composition_(music)">composition</a> recovers a substantial part of the gap, indicating that a forward LSTM and <a href="https://en.wikipedia.org/wiki/Composition_(music)">composition</a> capture similar information. We take the backward LSTM to be related to lookahead features and the forward LSTM to the rich history-based features both crucial for transition-based parsers. To capture history-based information, composition is better than a forward LSTM on its own, but it is even better to have a forward LSTM as part of a BiLSTM. We correlate results with language properties, showing that the improved <a href="https://en.wikipedia.org/wiki/Ahead-of-time_compilation">lookahead</a> of a backward LSTM is especially important for head-final languages.</abstract>
      <url hash="f9dc1d90">N19-1159</url>
      <attachment type="presentation" hash="a13d5e1a">N19-1159.Presentation.pdf</attachment>
      <doi>10.18653/v1/N19-1159</doi>
      <video href="https://vimeo.com/364704101" />
      <bibkey>de-lhoneux-etal-2019-recursive</bibkey>
      <revision id="1" href="N19-1159v1" hash="439cc71b" />
      <revision id="2" href="N19-1159v2" hash="f9dc1d90" date="2022-02-11">Added missing acknowledgment.</revision>
      <pwccode url="https://github.com/mdelhoneux/uuparser-composition" additional="false">mdelhoneux/uuparser-composition</pwccode>
    </paper>
    <paper id="161">
      <title>Density Matching for Bilingual Word Embedding</title>
      <author><first>Chunting</first><last>Zhou</last></author>
      <author><first>Xuezhe</first><last>Ma</last></author>
      <author><first>Di</first><last>Wang</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>1588–1598</pages>
      <abstract>Recent approaches to cross-lingual word embedding have generally been based on <a href="https://en.wikipedia.org/wiki/Linear_map">linear transformations</a> between the sets of embedding vectors in the two languages. In this paper, we propose an approach that instead expresses the two monolingual embedding spaces as <a href="https://en.wikipedia.org/wiki/Probability_density_function">probability densities</a> defined by a Gaussian mixture model, and matches the two densities using a method called normalizing flow. The method requires no explicit supervision, and can be learned with only a seed dictionary of words that have identical strings. We argue that this formulation has several intuitively attractive properties, particularly with the respect to improving <a href="https://en.wikipedia.org/wiki/Robustness_(computer_science)">robustness</a> and <a href="https://en.wikipedia.org/wiki/Generalization">generalization</a> to mappings between difficult language pairs or word pairs. On a benchmark data set of bilingual lexicon induction and cross-lingual word similarity, our approach can achieve competitive or superior performance compared to state-of-the-art published results, with particularly strong results being found on etymologically distant and/or morphologically rich languages.</abstract>
      <url hash="054d4e38">N19-1161</url>
      <doi>10.18653/v1/N19-1161</doi>
      <video href="https://vimeo.com/364706803" />
      <bibkey>zhou-etal-2019-density</bibkey>
      <pwccode url="https://github.com/violet-zct/DeMa-BWE" additional="false">violet-zct/DeMa-BWE</pwccode>
    </paper>
    <paper id="162">
      <title>Cross-Lingual Alignment of Contextual Word Embeddings, with Applications to Zero-shot Dependency Parsing</title>
      <author><first>Tal</first><last>Schuster</last></author>
      <author><first>Ori</first><last>Ram</last></author>
      <author><first>Regina</first><last>Barzilay</last></author>
      <author><first>Amir</first><last>Globerson</last></author>
      <pages>1599–1613</pages>
      <abstract>We introduce a novel method for multilingual transfer that utilizes deep contextual embeddings, pretrained in an unsupervised fashion. While contextual embeddings have been shown to yield richer representations of meaning compared to their static counterparts, aligning them poses a challenge due to their dynamic nature. To this end, we construct context-independent variants of the original monolingual spaces and utilize their <a href="https://en.wikipedia.org/wiki/Map_(mathematics)">mapping</a> to derive an <a href="https://en.wikipedia.org/wiki/Sequence_alignment">alignment</a> for the context-dependent spaces. This <a href="https://en.wikipedia.org/wiki/Map_(mathematics)">mapping</a> readily supports processing of a target language, improving <a href="https://en.wikipedia.org/wiki/Language_transfer">transfer</a> by context-aware embeddings. Our experimental results demonstrate the effectiveness of this approach for zero-shot and few-shot learning of dependency parsing. Specifically, our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> consistently outperforms the previous <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a> on 6 tested languages, yielding an improvement of 6.8 LAS points on average.</abstract>
      <url hash="1933d98d">N19-1162</url>
      <video href="https://vimeo.com/364708233" />
      <doi>10.18653/v1/N19-1162</doi>
      <bibkey>schuster-etal-2019-cross</bibkey>
      <pwccode url="https://github.com/TalSchuster/CrossLingualELMo" additional="true">TalSchuster/CrossLingualELMo</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="164">
      <title>Microblog Hashtag Generation via Encoding Conversation Contexts</title>
      <author><first>Yue</first><last>Wang</last></author>
      <author><first>Jing</first><last>Li</last></author>
      <author><first>Irwin</first><last>King</last></author>
      <author><first>Michael R.</first><last>Lyu</last></author>
      <author><first>Shuming</first><last>Shi</last></author>
      <pages>1624–1633</pages>
      <abstract>Automatic hashtag annotation plays an important role in content understanding for <a href="https://en.wikipedia.org/wiki/Microblogging">microblog posts</a>. To date, progress made in this field has been restricted to phrase selection from limited candidates, or word-level hashtag discovery using <a href="https://en.wikipedia.org/wiki/Topic_model">topic models</a>. Different from previous work considering <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a> to be inseparable, our work is the first effort to annotate <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a> with a novel sequence generation framework via viewing the <a href="https://en.wikipedia.org/wiki/Hashtag">hashtag</a> as a short sequence of words. Moreover, to address the data sparsity issue in processing short microblog posts, we propose to jointly model the target posts and the conversation contexts initiated by them with bidirectional attention. Extensive experimental results on two large-scale datasets, newly collected from <a href="https://en.wikipedia.org/wiki/Twitter">English Twitter</a> and <a href="https://en.wikipedia.org/wiki/Sina_Weibo">Chinese Weibo</a>, show that our model significantly outperforms state-of-the-art models based on <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a>. Further studies demonstrate our ability to effectively generate rare and even unseen hashtags, which is however not possible for most existing methods.</abstract>
      <url hash="e328b76e">N19-1164</url>
      <doi>10.18653/v1/N19-1164</doi>
      <video href="https://vimeo.com/364687803" />
      <bibkey>wang-etal-2019-microblog</bibkey>
      <pwccode url="https://github.com/yuewang-cuhk/HashtagGeneration" additional="false">yuewang-cuhk/HashtagGeneration</pwccode>
    </paper>
    <paper id="166">
      <title>Something’s Brewing ! Early Prediction of Controversy-causing Posts from Discussion Features</title>
      <author><first>Jack</first><last>Hessel</last></author>
      <author><first>Lillian</first><last>Lee</last></author>
      <pages>1648–1659</pages>
      <abstract>Controversial posts are those that split the preferences of a community, receiving both significant positive and significant negative feedback. Our inclusion of the word community here is deliberate : what is controversial to some audiences may not be so to others. Using data from several different communities on <a href="https://en.wikipedia.org/wiki/Reddit">reddit.com</a>, we predict the ultimate controversiality of posts, leveraging features drawn from both the textual content and the <a href="https://en.wikipedia.org/wiki/Tree_structure">tree structure</a> of the early comments that initiate the discussion. We find that even when only a handful of comments are available, e.g., the first 5 comments made within 15 minutes of the original post, discussion features often add predictive capacity to strong content-and- rate only baselines. Additional experiments on <a href="https://en.wikipedia.org/wiki/Domain_transfer">domain transfer</a> suggest that conversation- structure features often generalize to other communities better than conversation-content features do.</abstract>
      <url hash="6bd462c5">N19-1166</url>
      <attachment type="presentation" hash="6d9e743d">N19-1166.Presentation.pdf</attachment>
      <doi>10.18653/v1/N19-1166</doi>
      <video href="https://vimeo.com/364697819" />
      <bibkey>hessel-lee-2019-somethings</bibkey>
    </paper>
    <paper id="167">
      <title>No Permanent Friends or Enemies : Tracking Relationships between Nations from News<fixed-case>F</fixed-case>riends or Enemies: Tracking Relationships between Nations from News</title>
      <author><first>Xiaochuang</first><last>Han</last></author>
      <author><first>Eunsol</first><last>Choi</last></author>
      <author><first>Chenhao</first><last>Tan</last></author>
      <pages>1660–1676</pages>
      <abstract>Understanding the dynamics of international politics is important yet challenging for civilians. In this work, we explore <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised neural models</a> to infer <a href="https://en.wikipedia.org/wiki/International_relations">relations between nations</a> from <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a>. We extend existing models by incorporating shallow linguistics information and propose a new automatic evaluation metric that aligns relationship dynamics with manually annotated key events. As understanding <a href="https://en.wikipedia.org/wiki/International_relations">international relations</a> requires carefully analyzing <a href="https://en.wikipedia.org/wiki/Interpersonal_relationship">complex relationships</a>, we conduct in-person human evaluations with three groups of participants. Overall, humans prefer the outputs of our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> and give insightful feedback that suggests future directions for human-centered models. Furthermore, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> reveals interesting regional differences in <a href="https://en.wikipedia.org/wiki/News_media">news coverage</a>. For instance, with respect to <a href="https://en.wikipedia.org/wiki/China–United_States_relations">US-China relations</a>, <a href="https://en.wikipedia.org/wiki/Media_of_Singapore">Singaporean media</a> focus more on strengthening and purchasing, while <a href="https://en.wikipedia.org/wiki/Media_of_the_United_States">US media</a> focus more on criticizing and denouncing.</abstract>
      <url hash="7d2b5735">N19-1167</url>
      <doi>10.18653/v1/N19-1167</doi>
      <video href="https://vimeo.com/364700832" />
      <bibkey>han-etal-2019-permanent</bibkey>
      <pwccode url="https://github.com/BoulderDS/LARN" additional="false">BoulderDS/LARN</pwccode>
    </paper>
    <paper id="168">
      <title>Improving Human Text Comprehension through Semi-Markov CRF-based Neural Section Title Generation<fixed-case>M</fixed-case>arkov <fixed-case>CRF</fixed-case>-based Neural Section Title Generation</title>
      <author><first>Sebastian</first><last>Gehrmann</last></author>
      <author><first>Steven</first><last>Layne</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <pages>1677–1688</pages>
      <abstract>Titles of short sections within long documents support readers by guiding their focus towards relevant passages and by providing anchor-points that help to understand the progression of the document. The positive effects of section titles are even more pronounced when measured on readers with less developed reading abilities, for example in communities with limited labeled text resources. We, therefore, aim to develop <a href="https://en.wikipedia.org/wiki/Scientific_technique">techniques</a> to generate section titles in <a href="https://en.wikipedia.org/wiki/Developing_country">low-resource environments</a>. In particular, we present an extractive pipeline for section title generation by first selecting the most salient sentence and then applying deletion-based compression. Our compression approach is based on a Semi-Markov Conditional Random Field that leverages unsupervised word-representations such as ELMo or BERT, eliminating the need for a complex encoder-decoder architecture. The results show that this approach leads to competitive performance with sequence-to-sequence models with <a href="https://en.wikipedia.org/wiki/High-throughput_screening">high resources</a>, while strongly outperforming it with low resources. In a human-subject study across subjects with varying reading abilities, we find that our section titles improve the speed of completing comprehension tasks while retaining similar <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>.</abstract>
      <url hash="421a8cf8">N19-1168</url>
      <doi>10.18653/v1/N19-1168</doi>
      <video href="https://vimeo.com/361580764" />
      <bibkey>gehrmann-etal-2019-improving</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/sentence-compression">Sentence Compression</pwcdataset>
    </paper>
    <paper id="172">
      <title>Pun Generation with Surprise</title>
      <author><first>He</first><last>He</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <author><first>Percy</first><last>Liang</last></author>
      <pages>1734–1744</pages>
      <abstract>We tackle the problem of generating a pun sentence given a pair of homophones (e.g., died and dyed). Puns are by their very nature statistically anomalous and not amenable to most text generation methods that are supervised by a <a href="https://en.wikipedia.org/wiki/Text_corpus">large corpus</a>. In this paper, we propose an <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised approach</a> to <a href="https://en.wikipedia.org/wiki/Pun">pun generation</a> based on lots of raw (unhumorous) text and a surprisal principle. Specifically, we posit that in a pun sentence, there is a strong association between the pun word (e.g., dyed) and the <a href="https://en.wikipedia.org/wiki/Context_(language_use)">distant context</a>, but a strong association between the alternative word (e.g., died) and the <a href="https://en.wikipedia.org/wiki/Context_(language_use)">immediate context</a>. We instantiate the surprisal principle in two ways : (i) as a measure based on the ratio of probabilities given by a <a href="https://en.wikipedia.org/wiki/Language_model">language model</a>, and (ii) a retrieve-and-edit approach based on words suggested by a skip-gram model. Based on human evaluation, our retrieve-and-edit approach generates puns successfully 30 % of the time, doubling the success rate of a neural generation baseline.</abstract>
      <url hash="cd199482">N19-1172</url>
      <doi>10.18653/v1/N19-1172</doi>
      <video href="https://vimeo.com/359670150" />
      <bibkey>he-etal-2019-pun</bibkey>
      <pwccode url="https://github.com/hhexiy/pungen" additional="true">hhexiy/pungen</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/bookcorpus">BookCorpus</pwcdataset>
    </paper>
    <paper id="173">
      <title>Single Document Summarization as Tree Induction</title>
      <author id="yang-liu-edinburgh"><first>Yang</first><last>Liu</last></author>
      <author><first>Ivan</first><last>Titov</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <pages>1745–1755</pages>
      <abstract>In this paper, we conceptualize single-document extractive summarization as a tree induction problem. In contrast to previous approaches which have relied on linguistically motivated document representations to generate summaries, our model induces a multi-root dependency tree while predicting the output summary. Each root node in the <a href="https://en.wikipedia.org/wiki/Tree_(data_structure)">tree</a> is a summary sentence, and the subtrees attached to it are sentences whose content relates to or explains the summary sentence. We design a new iterative refinement algorithm : it induces the <a href="https://en.wikipedia.org/wiki/Tree_(graph_theory)">trees</a> through repeatedly refining the structures predicted by previous iterations. We demonstrate experimentally on two benchmark datasets that our <a href="https://en.wikipedia.org/wiki/Automatic_summarization">summarizer</a> performs competitively against state-of-the-art methods.</abstract>
      <url hash="9f3aaeaa">N19-1173</url>
      <doi>10.18653/v1/N19-1173</doi>
      <bibkey>liu-etal-2019-single</bibkey>
      <pwccode url="https://github.com/nlpyang/SUMO" additional="false">nlpyang/SUMO</pwccode>
    </paper>
    <paper id="174">
      <title>Fixed That for You : Generating Contrastive Claims with Semantic Edits</title>
      <author><first>Christopher</first><last>Hidey</last></author>
      <author><first>Kathy</first><last>McKeown</last></author>
      <pages>1756–1767</pages>
      <abstract>Understanding contrastive opinions is a key component of argument generation. Central to an argument is the claim, a statement that is in dispute. Generating a counter-argument then requires generating a response in contrast to the main claim of the original argument. To generate contrastive claims, we create a corpus of Reddit comment pairs self-labeled by posters using the acronym FTFY (fixed that for you). We then train neural models on these pairs to edit the original claim and produce a new claim with a different view. We demonstrate significant improvement over a sequence-to-sequence baseline in BLEU score and a human evaluation for <a href="https://en.wikipedia.org/wiki/Fluency">fluency</a>, <a href="https://en.wikipedia.org/wiki/Coherence_(linguistics)">coherence</a>, and <a href="https://en.wikipedia.org/wiki/Contrast_(vision)">contrast</a>.</abstract>
      <url hash="6b6a39d1">N19-1174</url>
      <doi>10.18653/v1/N19-1174</doi>
      <bibkey>hidey-mckeown-2019-fixed</bibkey>
      <pwccode url="https://github.com/chridey/fixedthat" additional="false">chridey/fixedthat</pwccode>
    </paper>
    <paper id="178">
      <title>Unsupervised Dialog Structure Learning</title>
      <author><first>Weiyan</first><last>Shi</last></author>
      <author><first>Tiancheng</first><last>Zhao</last></author>
      <author><first>Zhou</first><last>Yu</last></author>
      <pages>1797–1807</pages>
      <abstract>Learning a shared dialog structure from a set of task-oriented dialogs is an important challenge in <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational linguistics</a>. The learned dialog structure can shed light on how to analyze human dialogs, and more importantly contribute to the design and evaluation of dialog systems. We propose to extract dialog structures using a modified VRNN model with discrete latent vectors. Different from existing HMM-based models, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is based on variational-autoencoder (VAE). Such <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is able to capture more dynamics in <a href="https://en.wikipedia.org/wiki/Dialogue">dialogs</a> beyond the surface forms of the language. We find that qualitatively, our method extracts meaningful dialog structure, and quantitatively, outperforms previous models on the ability to predict unseen data. We further evaluate the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a>’s effectiveness in a downstream task, the dialog system building task. Experiments show that, by integrating the learned dialog structure into the reward function design, the model converges faster and to a better outcome in a reinforcement learning setting.</abstract>
      <url hash="fc6a8f87">N19-1178</url>
      <doi>10.18653/v1/N19-1178</doi>
      <bibkey>shi-etal-2019-unsupervised</bibkey>
      <pwccode url="https://github.com/wyshi/Unsupervised-Structure-Learning" additional="false">wyshi/Unsupervised-Structure-Learning</pwccode>
    </paper>
    <paper id="181">
      <title>Text Similarity Estimation Based on Word Embeddings and Matrix Norms for Targeted Marketing</title>
      <author><first>Tim</first><last>vor der Brück</last></author>
      <author><first>Marc</first><last>Pouly</last></author>
      <pages>1827–1836</pages>
      <abstract>The prevalent way to estimate the <a href="https://en.wikipedia.org/wiki/Similarity_measure">similarity</a> of two documents based on word embeddings is to apply the cosine similarity measure to the two <a href="https://en.wikipedia.org/wiki/Centroid">centroids</a> obtained from the embedding vectors associated with the words in each document. Motivated by an industrial application from the domain of <a href="https://en.wikipedia.org/wiki/Youth_marketing">youth marketing</a>, where this approach produced only mediocre results, we propose an alternative way of combining the <a href="https://en.wikipedia.org/wiki/Word_vectors">word vectors</a> using <a href="https://en.wikipedia.org/wiki/Matrix_norms">matrix norms</a>. The evaluation shows superior results for most of the investigated matrix norms in comparison to both the classical cosine measure and several other document similarity estimates.</abstract>
      <url hash="4ccf5357">N19-1181</url>
      <doi>10.18653/v1/N19-1181</doi>
      <bibkey>vor-der-bruck-pouly-2019-text</bibkey>
    </paper>
    <paper id="182">
      <title>Glocal : Incorporating Global Information in Local Convolution for Keyphrase Extraction<fixed-case>G</fixed-case>local: Incorporating Global Information in Local Convolution for Keyphrase Extraction</title>
      <author><first>Animesh</first><last>Prasad</last></author>
      <author><first>Min-Yen</first><last>Kan</last></author>
      <pages>1837–1846</pages>
      <abstract>Graph Convolutional Networks (GCNs) are a class of spectral clustering techniques that leverage localized convolution filters to perform <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised classification</a> directly on <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graphical structures</a>. While such methods model nodes’ local pairwise importance, they lack the capability to model global importance relative to other nodes of the <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph</a>. This causes such <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> to miss critical information in tasks where global ranking is a key component for the task, such as in <a href="https://en.wikipedia.org/wiki/Keyphrase_extraction">keyphrase extraction</a>. We address this shortcoming by allowing the proper incorporation of global information into the GCN family of models through the use of scaled node weights. In the context of <a href="https://en.wikipedia.org/wiki/Keyphrase_extraction">keyphrase extraction</a>, incorporating global random walk scores obtained from TextRank boosts performance significantly. With our proposed <a href="https://en.wikipedia.org/wiki/Methodology">method</a>, we achieve state-of-the-art results, bettering a strong <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a> by an absolute 2 % increase in F1 score.</abstract>
      <url hash="a630c3ff">N19-1182</url>
      <doi>10.18653/v1/N19-1182</doi>
      <bibkey>prasad-kan-2019-glocal</bibkey>
    </paper>
    <paper id="183">
      <title>A Study of Latent Structured Prediction Approaches to Passage Reranking</title>
      <author><first>Iryna</first><last>Haponchyk</last></author>
      <author><first>Alessandro</first><last>Moschitti</last></author>
      <pages>1847–1857</pages>
      <abstract>The structured output framework provides a helpful tool for learning to rank problems. In this paper, we propose a structured output approach which regards <a href="https://en.wikipedia.org/wiki/Ranking">rankings</a> as <a href="https://en.wikipedia.org/wiki/Latent_variable">latent variables</a>. Our approach addresses the complex optimization of Mean Average Precision (MAP) ranking metric. We provide an <a href="https://en.wikipedia.org/wiki/Statistical_inference">inference procedure</a> to find the max-violating ranking based on the decomposition of the corresponding loss. The results of our experiments on WikiQA and TREC13 datasets show that our reranking based on <a href="https://en.wikipedia.org/wiki/Structured_prediction">structured prediction</a> is a promising research direction.</abstract>
      <url hash="cce39004">N19-1183</url>
      <doi>10.18653/v1/N19-1183</doi>
      <bibkey>haponchyk-moschitti-2019-study</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wikiqa">WikiQA</pwcdataset>
    </paper>
    <paper id="185">
      <title>Tweet Stance Detection Using an Attention based Neural Ensemble Model<fixed-case>T</fixed-case>weet Stance Detection Using an Attention based Neural Ensemble Model</title>
      <author><first>Umme Aymun</first><last>Siddiqua</last></author>
      <author><first>Abu Nowshed</first><last>Chy</last></author>
      <author><first>Masaki</first><last>Aono</last></author>
      <pages>1868–1873</pages>
      <abstract>Stance detection in twitter aims at mining user stances expressed in a tweet towards a single or multiple target entities. To tackle this problem, most of the prior studies have been explored the traditional <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning models</a>, e.g., <a href="https://en.wikipedia.org/wiki/Linear_time-invariant_system">LSTM</a> and GRU. However, in compared to these traditional approaches, recently proposed densely connected Bi-LSTM and nested LSTMs architectures effectively address the vanishing-gradient and overfitting problems as well as dealing with long-term dependencies. In this paper, we propose a neural ensemble model that adopts the strengths of these two LSTM variants to learn better long-term dependencies, where each module coupled with an attention mechanism that amplifies the contribution of important elements in the final representation. We also employ a multi-kernel convolution on top of them to extract the higher-level tweet representations. Results of extensive experiments on single and multi-target stance detection datasets show that our proposed method achieves substantial improvement over the current state-of-the-art deep learning based methods.</abstract>
      <url hash="b4f84ee9">N19-1185</url>
      <doi>10.18653/v1/N19-1185</doi>
      <bibkey>siddiqua-etal-2019-tweet</bibkey>
    </paper>
    <paper id="188">
      <title>Learning Unsupervised Multilingual Word Embeddings with Incremental Multilingual Hubs</title>
      <author><first>Geert</first><last>Heyman</last></author>
      <author><first>Bregt</first><last>Verreet</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Marie-Francine</first><last>Moens</last></author>
      <pages>1890–1902</pages>
      <abstract>Recent research has discovered that a shared bilingual word embedding space can be induced by projecting monolingual word embedding spaces from two languages using a self-learning paradigm without any bilingual supervision. However, it has also been shown that for distant language pairs such fully unsupervised self-learning methods are unstable and often get stuck in poor local optima due to reduced isomorphism between starting monolingual spaces. In this work, we propose a new <a href="https://en.wikipedia.org/wiki/Robustness_(computer_science)">robust framework</a> for learning unsupervised multilingual word embeddings that mitigates the instability issues. We learn a shared multilingual embedding space for a variable number of languages by incrementally adding new languages one by one to the current multilingual space. Through the gradual language addition the <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">method</a> can leverage the <a href="https://en.wikipedia.org/wiki/Interconnection">interdependencies</a> between the new language and all other languages in the current multilingual space. We find that it is beneficial to project more distant languages later in the iterative process. Our fully unsupervised multilingual embedding spaces yield results that are on par with the state-of-the-art methods in the bilingual lexicon induction (BLI) task, and simultaneously obtain state-of-the-art scores on two downstream tasks : multilingual document classification and multilingual dependency parsing, outperforming even supervised baselines. This finding also accentuates the need to establish evaluation protocols for cross-lingual word embeddings beyond the omnipresent intrinsic BLI task in future work.</abstract>
      <url hash="e71e7891">N19-1188</url>
      <doi>10.18653/v1/N19-1188</doi>
      <bibkey>heyman-etal-2019-learning</bibkey>
    </paper>
    <paper id="189">
      <title>Curriculum Learning for Domain Adaptation in Neural Machine Translation</title>
      <author><first>Xuan</first><last>Zhang</last></author>
      <author><first>Pamela</first><last>Shapiro</last></author>
      <author><first>Gaurav</first><last>Kumar</last></author>
      <author><first>Paul</first><last>McNamee</last></author>
      <author><first>Marine</first><last>Carpuat</last></author>
      <author><first>Kevin</first><last>Duh</last></author>
      <pages>1903–1915</pages>
      <abstract>We introduce a curriculum learning approach to adapt generic neural machine translation models to a specific domain. Samples are grouped by their similarities to the domain of interest and each group is fed to the <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training algorithm</a> with a particular schedule. This approach is simple to implement on top of any neural framework or architecture, and consistently outperforms both unadapted and adapted baselines in experiments with two distinct domains and two language pairs.</abstract>
      <url hash="d23e0ddf">N19-1189</url>
      <doi>10.18653/v1/N19-1189</doi>
      <bibkey>zhang-etal-2019-curriculum</bibkey>
    </paper>
    <paper id="192">
      <title>Online Distilling from Checkpoints for Neural Machine Translation</title>
      <author><first>Hao-Ran</first><last>Wei</last></author>
      <author><first>Shujian</first><last>Huang</last></author>
      <author><first>Ran</first><last>Wang</last></author>
      <author><first>Xin-yu</first><last>Dai</last></author>
      <author><first>Jiajun</first><last>Chen</last></author>
      <pages>1932–1941</pages>
      <abstract>Current predominant neural machine translation (NMT) models often have a deep structure with large amounts of parameters, making these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> hard to train and easily suffering from <a href="https://en.wikipedia.org/wiki/Overfitting">over-fitting</a>. A common practice is to utilize a validation set to evaluate the training process and select the best checkpoint. Average and ensemble techniques on checkpoints can lead to further performance improvement. However, as these methods do not affect the <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training process</a>, the <a href="https://en.wikipedia.org/wiki/System">system</a> performance is restricted to the checkpoints generated in original <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training procedure</a>. In contrast, we propose an online knowledge distillation method. Our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> on-the-fly generates a teacher model from <a href="https://en.wikipedia.org/wiki/Checkpoint">checkpoints</a>, guiding the <a href="https://en.wikipedia.org/wiki/Training">training process</a> to obtain better performance. Experiments on several datasets and language pairs show steady improvement over a strong self-attention-based baseline system. We also provide analysis on data-limited setting against <a href="https://en.wikipedia.org/wiki/Overfitting">over-fitting</a>. Furthermore, our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> leads to an improvement in a machine reading experiment as well.</abstract>
      <url hash="20d76f06">N19-1192</url>
      <doi>10.18653/v1/N19-1192</doi>
      <bibkey>wei-etal-2019-online</bibkey>
    </paper>
    <paper id="193">
      <title>Value-based Search in Execution Space for Mapping Instructions to Programs</title>
      <author><first>Dor</first><last>Muhlgay</last></author>
      <author><first>Jonathan</first><last>Herzig</last></author>
      <author><first>Jonathan</first><last>Berant</last></author>
      <pages>1942–1954</pages>
      <abstract>Training models to map natural language instructions to <a href="https://en.wikipedia.org/wiki/Computer_program">programs</a>, given target world supervision only, requires searching for good programs at training time. Search is commonly done using <a href="https://en.wikipedia.org/wiki/Beam_search">beam search</a> in the space of partial programs or program trees, but as the length of the instructions grows finding a good program becomes difficult. In this work, we propose a <a href="https://en.wikipedia.org/wiki/Search_algorithm">search algorithm</a> that uses the target world state, known at training time, to train a critic network that predicts the expected reward of every search state. We then score search states on the beam by interpolating their expected reward with the likelihood of programs represented by the search state. Moreover, we search not in the space of programs but in a more compressed state of program executions, augmented with recent entities and actions. On the SCONE dataset, we show that our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> dramatically improves performance on all three domains compared to standard <a href="https://en.wikipedia.org/wiki/Beam_search">beam search</a> and other baselines.</abstract>
      <url hash="805a2fd3">N19-1193</url>
      <doi>10.18653/v1/N19-1193</doi>
      <bibkey>muhlgay-etal-2019-value</bibkey>
      <pwccode url="https://gitlab.com/tau-nlp/vbsix-lang2program" additional="false">tau-nlp/vbsix-lang2program</pwccode>
    </paper>
    <paper id="200">
      <title>Cross-lingual Visual Verb Sense Disambiguation</title>
      <author><first>Spandana</first><last>Gella</last></author>
      <author><first>Desmond</first><last>Elliott</last></author>
      <author><first>Frank</first><last>Keller</last></author>
      <pages>1998–2004</pages>
      <abstract>Recent work has shown that <a href="https://en.wikipedia.org/wiki/Context_(language_use)">visual context</a> improves cross-lingual sense disambiguation for <a href="https://en.wikipedia.org/wiki/Noun">nouns</a>. We extend this line of work to the more challenging task of cross-lingual verb sense disambiguation, introducing the MultiSense dataset of 9,504 images annotated with English, German, and Spanish verbs. Each image in MultiSense is annotated with an English verb and its translation in <a href="https://en.wikipedia.org/wiki/German_language">German</a> or Spanish. We show that cross-lingual verb sense disambiguation models benefit from <a href="https://en.wikipedia.org/wiki/Context_(language_use)">visual context</a>, compared to unimodal baselines. We also show that the verb sense predicted by our best disambiguation model can improve the results of a text-only machine translation system when used for a multimodal translation task.</abstract>
      <url hash="b0b68c88">N19-1200</url>
      <doi>10.18653/v1/N19-1200</doi>
      <video href="https://vimeo.com/354228781" />
      <bibkey>gella-etal-2019-cross</bibkey>
      <pwccode url="https://github.com/spandanagella/multisense" additional="false">spandanagella/multisense</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/multisense">MultiSense</pwcdataset>
    </paper>
    <paper id="201">
      <title>Subword-Level Language Identification for Intra-Word Code-Switching</title>
      <author><first>Manuel</first><last>Mager</last></author>
      <author><first>Özlem</first><last>Çetinoğlu</last></author>
      <author><first>Katharina</first><last>Kann</last></author>
      <pages>2005–2011</pages>
      <abstract>Language identification for code-switching (CS), the phenomenon of alternating between two or more languages in conversations, has traditionally been approached under the assumption of a single language per token. However, if at least one language is morphologically rich, a large number of words can be composed of morphemes from more than one language (intra-word CS). In this paper, we extend the language identification task to the subword-level, such that it includes splitting mixed words while tagging each part with a language ID. We further propose a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> for this task, which is based on a segmental recurrent neural network. In experiments on a new SpanishWixarika dataset and on an adapted GermanTurkish dataset, our proposed model performs slightly better than or roughly on par with our best baseline, respectively. Considering only mixed words, however, it strongly outperforms all baselines.</abstract>
      <url hash="0e3ece6f">N19-1201</url>
      <doi>10.18653/v1/N19-1201</doi>
      <video href="https://vimeo.com/354264673" />
      <bibkey>mager-etal-2019-subword</bibkey>
    </paper>
    <paper id="203">
      <title>Contextualization of Morphological Inflection</title>
      <author><first>Ekaterina</first><last>Vylomova</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <author><first>Jason</first><last>Eisner</last></author>
      <pages>2018–2024</pages>
      <abstract>Critical to <a href="https://en.wikipedia.org/wiki/Natural-language_generation">natural language generation</a> is the production of correctly inflected text. In this paper, we isolate the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> of predicting a fully inflected sentence from its partially lemmatized version. Unlike traditional <a href="https://en.wikipedia.org/wiki/Inflection">morphological inflection</a> or surface realization, our task input does not provide gold tags that specify what morphological features to realize on each lemmatized word ; rather, such features must be inferred from sentential context. We develop a neural hybrid graphical model that explicitly reconstructs <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological features</a> before predicting the <a href="https://en.wikipedia.org/wiki/Inflection">inflected forms</a>, and compare this to a system that directly predicts the <a href="https://en.wikipedia.org/wiki/Inflection">inflected forms</a> without relying on any morphological annotation. We experiment on several typologically diverse languages from the Universal Dependencies treebanks, showing the utility of incorporating linguistically-motivated latent variables into NLP models.</abstract>
      <url hash="0e455fa5">N19-1203</url>
      <doi>10.18653/v1/N19-1203</doi>
      <video href="https://vimeo.com/354264026" />
      <bibkey>vylomova-etal-2019-contextualization</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="206">
      <title>Measuring Immediate Adaptation Performance for Neural Machine Translation</title>
      <author><first>Patrick</first><last>Simianer</last></author>
      <author><first>Joern</first><last>Wuebker</last></author>
      <author><first>John</first><last>DeNero</last></author>
      <pages>2038–2046</pages>
      <abstract>Incremental domain adaptation, in which a system learns from the correct output for each input immediately after making its prediction for that input, can dramatically improve <a href="https://en.wikipedia.org/wiki/System">system</a> performance for <a href="https://en.wikipedia.org/wiki/Interactive_machine_translation">interactive machine translation</a>. Users of interactive systems are sensitive to the speed of adaptation and how often a system repeats mistakes, despite being corrected. Adaptation is most commonly assessed using corpus-level BLEU- or TER-derived metrics that do not explicitly take adaptation speed into account. We find that these <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> often do not capture immediate adaptation effects, such as zero-shot and one-shot learning of domain-specific lexical items. To this end, we propose new <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> that directly evaluate immediate adaptation performance for <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>. We use these <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> to choose the most suitable adaptation method from a range of different adaptation techniques for <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation systems</a>.</abstract>
      <url hash="421f7941">N19-1206</url>
      <doi>10.18653/v1/N19-1206</doi>
      <attachment type="presentation" hash="34f2b443">N19-1206.Presentation.pdf</attachment>
      <video href="https://vimeo.com/355794917" />
      <bibkey>simianer-etal-2019-measuring</bibkey>
    </paper>
    <paper id="208">
      <title>Reinforcement Learning based Curriculum Optimization for Neural Machine Translation</title>
      <author><first>Gaurav</first><last>Kumar</last></author>
      <author><first>George</first><last>Foster</last></author>
      <author><first>Colin</first><last>Cherry</last></author>
      <author><first>Maxim</first><last>Krikun</last></author>
      <pages>2054–2061</pages>
      <abstract>We consider the problem of making efficient use of heterogeneous training data in neural machine translation (NMT). Specifically, given a training dataset with a sentence-level feature such as <a href="https://en.wikipedia.org/wiki/Noise_(signal_processing)">noise</a>, we seek an optimal <a href="https://en.wikipedia.org/wiki/Curriculum">curriculum</a>, or order for presenting examples to the system during training. Our curriculum framework allows examples to appear an arbitrary number of times, and thus generalizes <a href="https://en.wikipedia.org/wiki/Weighting">data weighting</a>, <a href="https://en.wikipedia.org/wiki/Filter_(signal_processing)">filtering</a>, and fine-tuning schemes. Rather than relying on prior knowledge to design a <a href="https://en.wikipedia.org/wiki/Curriculum">curriculum</a>, we use <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> to learn one automatically, jointly with the NMT system, in the course of a single training run. We show that this approach can beat <a href="https://en.wikipedia.org/wiki/Baseline_(surveying)">uniform baselines</a> on Paracrawl and WMT English-to-French datasets by +3.4 and +1.3 BLEU respectively. Additionally, we match the performance of strong filtering baselines and hand-designed, state-of-the-art curricula.</abstract>
      <url hash="20789018">N19-1208</url>
      <doi>10.18653/v1/N19-1208</doi>
      <video href="https://vimeo.com/355798547" />
      <bibkey>kumar-etal-2019-reinforcement</bibkey>
    </paper>
    <paper id="209">
      <title>Overcoming <a href="https://en.wikipedia.org/wiki/Catastrophic_Forgetting">Catastrophic Forgetting</a> During <a href="https://en.wikipedia.org/wiki/Domain_adaptation">Domain Adaptation</a> of Neural Machine Translation</title>
      <author><first>Brian</first><last>Thompson</last></author>
      <author><first>Jeremy</first><last>Gwinnup</last></author>
      <author><first>Huda</first><last>Khayrallah</last></author>
      <author><first>Kevin</first><last>Duh</last></author>
      <author><first>Philipp</first><last>Koehn</last></author>
      <pages>2062–2068</pages>
      <abstract>Continued training is an effective method for <a href="https://en.wikipedia.org/wiki/Domain_adaptation">domain adaptation</a> in <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a>. However, in-domain gains from adaptation come at the expense of general-domain performance. In this work, we interpret the drop in general-domain performance as catastrophic forgetting of general-domain knowledge. To mitigate it, we adapt Elastic Weight Consolidation (EWC)a machine learning method for learning a new task without forgetting previous tasks. Our method retains the majority of general-domain performance lost in continued training without degrading in-domain performance, outperforming the previous <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a>. We also explore the full range of general-domain performance available when some in-domain degradation is acceptable.</abstract>
      <url hash="46e5819d">N19-1209</url>
      <doi>10.18653/v1/N19-1209</doi>
      <video href="https://vimeo.com/356056256" />
      <bibkey>thompson-etal-2019-overcoming</bibkey>
    </paper>
    <paper id="210">
      <title>Short-Term Meaning Shift : A Distributional Exploration</title>
      <author><first>Marco</first><last>Del Tredici</last></author>
      <author><first>Raquel</first><last>Fernández</last></author>
      <author><first>Gemma</first><last>Boleda</last></author>
      <pages>2069–2075</pages>
      <abstract>We present the first exploration of meaning shift over short periods of time in <a href="https://en.wikipedia.org/wiki/Online_community">online communities</a> using distributional representations. We create a small annotated dataset and use it to assess the performance of a standard <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> for meaning shift detection on short-term meaning shift. We find that the model has problems distinguishing meaning shift from referential phenomena, and propose a measure of contextual variability to remedy this.</abstract>
      <url hash="eb31c2a1">N19-1210</url>
      <doi>10.18653/v1/N19-1210</doi>
      <video href="https://vimeo.com/354246126" />
      <bibkey>del-tredici-etal-2019-short</bibkey>
      <pwccode url="https://github.com/marcodel13/Short-term-meaning-shift" additional="false">marcodel13/Short-term-meaning-shift</pwccode>
    </paper>
    <paper id="213">
      <title>An Embarrassingly Simple Approach for Transfer Learning from Pretrained Language Models</title>
      <author><first>Alexandra</first><last>Chronopoulou</last></author>
      <author><first>Christos</first><last>Baziotis</last></author>
      <author><first>Alexandros</first><last>Potamianos</last></author>
      <pages>2089–2095</pages>
      <abstract>A growing number of state-of-the-art transfer learning methods employ <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> pretrained on large generic corpora. In this paper we present a conceptually simple and effective transfer learning approach that addresses the problem of catastrophic forgetting. Specifically, we combine the task-specific optimization function with an auxiliary language model objective, which is adjusted during the training process. This preserves language regularities captured by <a href="https://en.wikipedia.org/wiki/Language_model">language models</a>, while enabling sufficient adaptation for solving the target task. Our method does not require pretraining or finetuning separate components of the network and we train our models end-to-end in a single step. We present results on a variety of challenging affective and text classification tasks, surpassing well established <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning methods</a> with greater level of <a href="https://en.wikipedia.org/wiki/Complexity">complexity</a>.</abstract>
      <url hash="82b40970">N19-1213</url>
      <doi>10.18653/v1/N19-1213</doi>
      <video href="https://vimeo.com/354239263" />
      <bibkey>chronopoulou-etal-2019-embarrassingly</bibkey>
      <pwccode url="https://github.com/alexandra-chron/siatl" additional="false">alexandra-chron/siatl</pwccode>
    </paper>
    <paper id="217">
      <title>Joint Detection and Location of English Puns<fixed-case>E</fixed-case>nglish Puns</title>
      <author><first>Yanyan</first><last>Zou</last></author>
      <author><first>Wei</first><last>Lu</last></author>
      <pages>2117–2123</pages>
      <abstract>A pun is a form of <a href="https://en.wikipedia.org/wiki/Word_play">wordplay</a> for an intended humorous or rhetorical effect, where a word suggests two or more meanings by exploiting <a href="https://en.wikipedia.org/wiki/Polysemy">polysemy</a> (homographic pun) or phonological similarity to another word (heterographic pun). This paper presents an approach that addresses pun detection and pun location jointly from a sequence labeling perspective. We employ a new tagging scheme such that the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is capable of performing such a joint task, where useful structural information can be properly captured. We show that our proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is effective in handling both homographic and heterographic puns. Empirical results on the benchmark datasets demonstrate that our approach can achieve new state-of-the-art results.</abstract>
      <url hash="e6affb2b">N19-1217</url>
      <doi>10.18653/v1/N19-1217</doi>
      <video href="https://vimeo.com/355805085" />
      <bibkey>zou-lu-2019-joint</bibkey>
      <pwccode url="https://github.com/zoezou2015/PunLocation" additional="false">zoezou2015/PunLocation</pwccode>
    </paper>
    <paper id="219">
      <title>Argument Mining for Understanding Peer Reviews</title>
      <author><first>Xinyu</first><last>Hua</last></author>
      <author><first>Mitko</first><last>Nikolov</last></author>
      <author><first>Nikhil</first><last>Badugu</last></author>
      <author><first>Lu</first><last>Wang</last></author>
      <pages>2131–2137</pages>
      <abstract>Peer-review plays a critical role in the scientific writing and publication ecosystem. To assess the efficiency and efficacy of the reviewing process, one essential element is to understand and evaluate the reviews themselves. In this work, we study the content and structure of <a href="https://en.wikipedia.org/wiki/Peer_review">peer reviews</a> under the argument mining framework, through automatically detecting (1) the <a href="https://en.wikipedia.org/wiki/Argument">argumentative propositions</a> put forward by reviewers, and (2) their types (e.g., evaluating the work or making suggestions for improvement). We first collect 14.2 K reviews from major machine learning and natural language processing venues. 400 reviews are annotated with 10,386 propositions and corresponding types of Evaluation, Request, Fact, Reference, or Quote. We then train state-of-the-art proposition segmentation and classification models on the data to evaluate their utilities and identify new challenges for this new domain, motivating future directions for <a href="https://en.wikipedia.org/wiki/Argument_mining">argument mining</a>. Further experiments show that proposition usage varies across venues in amount, type, and topic.</abstract>
      <url hash="afa70246">N19-1219</url>
      <attachment type="supplementary" hash="0c7eabe2">N19-1219.Supplementary.pdf</attachment>
      <doi>10.18653/v1/N19-1219</doi>
      <video href="https://vimeo.com/355808962" />
      <bibkey>hua-etal-2019-argument</bibkey>
    </paper>
    <paper id="221">
      <title>Abusive Language Detection with Graph Convolutional Networks<fixed-case>A</fixed-case>busive <fixed-case>L</fixed-case>anguage <fixed-case>D</fixed-case>etection with <fixed-case>G</fixed-case>raph <fixed-case>C</fixed-case>onvolutional <fixed-case>N</fixed-case>etworks</title>
      <author><first>Pushkar</first><last>Mishra</last></author>
      <author><first>Marco</first><last>Del Tredici</last></author>
      <author><first>Helen</first><last>Yannakoudakis</last></author>
      <author><first>Ekaterina</first><last>Shutova</last></author>
      <pages>2145–2150</pages>
      <abstract>Abuse on the <a href="https://en.wikipedia.org/wiki/Internet">Internet</a> represents a significant societal problem of our time. Previous research on automated abusive language detection in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> has shown that community-based profiling of users is a promising technique for this task. However, existing approaches only capture shallow properties of online communities by modeling followerfollowing relationships. In contrast, working with graph convolutional networks (GCNs), we present the first approach that captures not only the structure of online communities but also the linguistic behavior of the users within them. We show that such a heterogeneous graph-structured modeling of communities significantly advances the current state of the art in abusive language detection.</abstract>
      <url hash="9e8aa515">N19-1221</url>
      <doi>10.18653/v1/N19-1221</doi>
      <video href="https://vimeo.com/355811189" />
      <bibkey>mishra-etal-2019-abusive</bibkey>
    </paper>
    <paper id="223">
      <title>Factorising AMR generation through syntax<fixed-case>AMR</fixed-case> generation through syntax</title>
      <author><first>Kris</first><last>Cao</last></author>
      <author><first>Stephen</first><last>Clark</last></author>
      <pages>2157–2163</pages>
      <abstract>Generating from Abstract Meaning Representation (AMR) is an underspecified problem, as many syntactic decisions are not specified by the semantic graph. To explicitly account for this variation, we break down generating from AMR into two steps : first generate a <a href="https://en.wikipedia.org/wiki/Syntax">syntactic structure</a>, and then generate the surface form. We show that decomposing the generation process this way leads to state-of-the-art single model performance generating from AMR without additional unlabelled data. We also demonstrate that we can generate meaning-preserving syntactic paraphrases of the same AMR graph, as judged by humans.</abstract>
      <url hash="a5b96257">N19-1223</url>
      <doi>10.18653/v1/N19-1223</doi>
      <video href="https://vimeo.com/364735719" />
      <bibkey>cao-clark-2019-factorising</bibkey>
    </paper>
    <paper id="224">
      <title>A Crowdsourced Frame Disambiguation Corpus with Ambiguity</title>
      <author><first>Anca</first><last>Dumitrache</last></author>
      <author><first>Lora</first><last>Aroyo</last></author>
      <author><first>Chris</first><last>Welty</last></author>
      <pages>2164–2170</pages>
      <abstract>We present a resource for the task of FrameNet semantic frame disambiguation of over 5,000 word-sentence pairs from the Wikipedia corpus. The <a href="https://en.wikipedia.org/wiki/Annotation">annotations</a> were collected using a novel crowdsourcing approach with multiple workers per sentence to capture inter-annotator disagreement. In contrast to the typical approach of attributing the best single frame to each word, we provide a list of frames with disagreement-based scores that express the confidence with which each frame applies to the word. This is based on the idea that inter-annotator disagreement is at least partly caused by <a href="https://en.wikipedia.org/wiki/Ambiguity">ambiguity</a> that is inherent to the text and frames. We have found many examples where the <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> of individual frames overlap sufficiently to make them acceptable alternatives for interpreting a sentence. We have argued that ignoring this <a href="https://en.wikipedia.org/wiki/Ambiguity">ambiguity</a> creates an overly arbitrary target for training and evaluating natural language processing systems-if humans can not agree, why would we expect the correct answer from a machine to be any different? To process this data we also utilized an expanded lemma-set provided by the Framester system, which merges FN with <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a> to enhance coverage. Our <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> includes annotations of 1,000 sentence-word pairs whose lemmas are not part of FN. Finally we present <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> for evaluating frame disambiguation systems that account for <a href="https://en.wikipedia.org/wiki/Ambiguity">ambiguity</a>.</abstract>
      <url hash="bdae8c83">N19-1224</url>
      <attachment type="supplementary" hash="49860cc2">N19-1224.Supplementary.pdf</attachment>
      <attachment type="presentation" hash="344cf34d">N19-1224.Presentation.pdf</attachment>
      <doi>10.18653/v1/N19-1224</doi>
      <video href="https://vimeo.com/364709844" />
      <bibkey>dumitrache-etal-2019-crowdsourced</bibkey>
      <pwccode url="https://github.com/CrowdTruth/FrameDisambiguation" additional="false">CrowdTruth/FrameDisambiguation</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
    </paper>
    <paper id="227">
      <title>Partial Or Complete, That’s The Question</title>
      <author><first>Qiang</first><last>Ning</last></author>
      <author><first>Hangfeng</first><last>He</last></author>
      <author><first>Chuchu</first><last>Fan</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>2190–2200</pages>
      <abstract>For many structured learning tasks, the data annotation process is complex and costly. Existing annotation schemes usually aim at acquiring completely annotated structures, under the common perception that partial structures are of low quality and could hurt the learning process. This paper questions this common perception, motivated by the fact that <a href="https://en.wikipedia.org/wiki/Structure_(mathematical_logic)">structures</a> consist of interdependent sets of variables. Thus, given a fixed budget, partly annotating each structure may provide the same level of <a href="https://en.wikipedia.org/wiki/Supervisor">supervision</a>, while allowing for more <a href="https://en.wikipedia.org/wiki/Structure_(mathematical_logic)">structures</a> to be annotated. We provide an information theoretic formulation for this perspective and use it, in the context of three diverse structured learning tasks, to show that learning from partial structures can sometimes outperform learning from complete ones. Our findings may provide important insights into structured data annotation schemes and could support progress in learning protocols for structured tasks.</abstract>
      <url hash="f305d91c">N19-1227</url>
      <attachment type="supplementary" hash="ee74d2ca">N19-1227.Supplementary.pdf</attachment>
      <doi>10.18653/v1/N19-1227</doi>
      <bibkey>ning-etal-2019-partial</bibkey>
    </paper>
    <paper id="228">
      <title>Sequential Attention with Keyword Mask Model for Community-based Question Answering<fixed-case>S</fixed-case>equential <fixed-case>A</fixed-case>ttention with <fixed-case>K</fixed-case>eyword <fixed-case>M</fixed-case>ask <fixed-case>M</fixed-case>odel for <fixed-case>C</fixed-case>ommunity-based <fixed-case>Q</fixed-case>uestion <fixed-case>A</fixed-case>nswering</title>
      <author><first>Jianxin</first><last>Yang</last></author>
      <author><first>Wenge</first><last>Rong</last></author>
      <author><first>Libin</first><last>Shi</last></author>
      <author><first>Zhang</first><last>Xiong</last></author>
      <pages>2201–2211</pages>
      <abstract>In Community-based Question Answering system(CQA), Answer Selection(AS) is a critical task, which focuses on finding a suitable answer within a list of candidate answers. For neural network models, the key issue is how to model the representations of QA text pairs and calculate the interactions between them. We propose a Sequential Attention with Keyword Mask model(SAKM) for CQA to imitate human reading behavior. Question and answer text regard each other as context within keyword-mask attention when encoding the representations, and repeat multiple times(hops) in a sequential style. So the QA pairs capture features and information from both question text and answer text, interacting and improving vector representations iteratively through hops. The flexibility of the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> allows to extract meaningful <a href="https://en.wikipedia.org/wiki/Index_term">keywords</a> from the sentences and enhance diverse mutual information. We perform on <a href="https://en.wikipedia.org/wiki/Question_answering">answer selection tasks</a> and <a href="https://en.wikipedia.org/wiki/Question_answering">multi-level answer ranking tasks</a>. Experiment results demonstrate the superiority of our proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> on community-based QA datasets.</abstract>
      <url hash="61ec5828">N19-1228</url>
      <doi>10.18653/v1/N19-1228</doi>
      <bibkey>yang-etal-2019-sequential</bibkey>
      <pwccode url="https://github.com/sheep-for/question_answer_matching" additional="false">sheep-for/question_answer_matching</pwccode>
    </paper>
    <paper id="229">
      <title>Simple Attention-Based Representation Learning for Ranking Short Social Media Posts</title>
      <author><first>Peng</first><last>Shi</last></author>
      <author><first>Jinfeng</first><last>Rao</last></author>
      <author><first>Jimmy</first><last>Lin</last></author>
      <pages>2212–2217</pages>
      <abstract>This paper explores the problem of ranking short social media posts with respect to user queries using <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a>. Instead of starting with a complex <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a>, we proceed from the bottom up and examine the effectiveness of a simple, word-level Siamese architecture augmented with attention-based mechanisms for capturing semantic soft matches between query and post tokens. Extensive experiments on datasets from the TREC Microblog Tracks show that our simple models not only achieve better effectiveness than existing approaches that are far more complex or exploit a more diverse set of relevance signals, but are also much faster.</abstract>
      <url hash="d6f24cd5">N19-1229</url>
      <doi>10.18653/v1/N19-1229</doi>
      <bibkey>shi-etal-2019-simple</bibkey>
    </paper>
    <paper id="230">
      <title>AttentiveChecker : A Bi-Directional Attention Flow Mechanism for Fact Verification<fixed-case>A</fixed-case>ttentive<fixed-case>C</fixed-case>hecker: A Bi-Directional Attention Flow Mechanism for Fact Verification</title>
      <author><first>Santosh</first><last>Tokala</last></author>
      <author><first>Vishal</first><last>G</last></author>
      <author><first>Avirup</first><last>Saha</last></author>
      <author><first>Niloy</first><last>Ganguly</last></author>
      <pages>2218–2222</pages>
      <abstract>The recently released FEVER dataset provided benchmark results on a fact-checking task in which given a factual claim, the system must extract textual evidence (sets of sentences from Wikipedia pages) that support or refute the claim. In this paper, we present a completely task-agnostic pipelined system, AttentiveChecker, consisting of three homogeneous Bi-Directional Attention Flow (BIDAF) networks, which are multi-layer hierarchical networks that represent the context at different levels of granularity. We are the first to apply to this task a bi-directional attention flow mechanism to obtain a query-aware context representation without early summarization. AttentiveChecker can be used to perform <a href="https://en.wikipedia.org/wiki/Document_retrieval">document retrieval</a>, sentence selection, and claim verification. Experiments on the FEVER dataset indicate that AttentiveChecker is able to achieve the state-of-the-art results on the FEVER test set.</abstract>
      <url hash="6f5a8881">N19-1230</url>
      <doi>10.18653/v1/N19-1230</doi>
      <bibkey>tokala-etal-2019-attentivechecker</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/fever">FEVER</pwcdataset>
    </paper>
    <paper id="231">
      <title>Practical, Efficient, and Customizable <a href="https://en.wikipedia.org/wiki/Active_learning">Active Learning</a> for Named Entity Recognition in the <a href="https://en.wikipedia.org/wiki/Digital_humanities">Digital Humanities</a></title>
      <author><first>Alexander</first><last>Erdmann</last></author>
      <author><first>David Joseph</first><last>Wrisley</last></author>
      <author><first>Benjamin</first><last>Allen</last></author>
      <author><first>Christopher</first><last>Brown</last></author>
      <author><first>Sophie</first><last>Cohen-Bodénès</last></author>
      <author><first>Micha</first><last>Elsner</last></author>
      <author><first>Yukun</first><last>Feng</last></author>
      <author><first>Brian</first><last>Joseph</last></author>
      <author><first>Béatrice</first><last>Joyeux-Prunel</last></author>
      <author><first>Marie-Catherine</first><last>de Marneffe</last></author>
      <pages>2223–2234</pages>
      <abstract>Scholars in inter-disciplinary fields like the <a href="https://en.wikipedia.org/wiki/Digital_humanities">Digital Humanities</a> are increasingly interested in semantic annotation of specialized corpora. Yet, under-resourced languages, imperfect or noisily structured data, and user-specific classification tasks make it difficult to meet their needs using off-the-shelf models. Manual annotation of large corpora from scratch, meanwhile, can be prohibitively expensive. Thus, we propose an active learning solution for <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>, attempting to maximize a custom model’s improvement per additional unit of manual annotation. Our system robustly handles any domain or user-defined label set and requires no external resources, enabling quality <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a> for Humanities corpora where such resources are not available. Evaluating on typologically disparate languages and datasets, we reduce required annotation by 20-60 % and greatly outperform a competitive active learning baseline.</abstract>
      <url hash="edd74903">N19-1231</url>
      <doi>10.18653/v1/N19-1231</doi>
      <bibkey>erdmann-etal-2019-practical</bibkey>
      <pwccode url="https://github.com/alexerdmann/HER" additional="true">alexerdmann/HER</pwccode>
    </paper>
    <paper id="232">
      <title>Doc2hash : Learning Discrete Latent variables for Documents Retrieval<fixed-case>D</fixed-case>oc2hash: Learning Discrete Latent variables for Documents Retrieval</title>
      <author><first>Yifei</first><last>Zhang</last></author>
      <author><first>Hao</first><last>Zhu</last></author>
      <pages>2235–2240</pages>
      <abstract>Learning to hash via <a href="https://en.wikipedia.org/wiki/Generative_model">generative model</a> has become a powerful paradigm for fast similarity search in documents retrieval. To get <a href="https://en.wikipedia.org/wiki/Binary_number">binary representation</a> (i.e., hash codes), the discrete distribution prior (i.e., <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli Distribution</a>) is applied to train the variational autoencoder (VAE). However, the discrete stochastic layer is usually incompatible with the <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a> in the training stage, and thus causes a gradient flow problem because of non-differentiable operators. The reparameterization trick of sampling from a <a href="https://en.wikipedia.org/wiki/Probability_distribution">discrete distribution</a> usually inc <a href="https://en.wikipedia.org/wiki/Differentiable_function">non-differentiable operators</a>. In this paper, we propose a method, Doc2hash, that solves the gradient flow problem of the discrete stochastic layer by using continuous relaxation on priors, and trains the generative model in an end-to-end manner to generate hash codes. In qualitative and quantitative experiments, we show the proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms other state-of-art methods.</abstract>
      <url hash="7856cc21">N19-1232</url>
      <doi>10.18653/v1/N19-1232</doi>
      <bibkey>zhang-zhu-2019-doc2hash</bibkey>
      <pwccode url="https://github.com/yifeiacc/doc2hash" additional="false">yifeiacc/doc2hash</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/rcv1">RCV1</pwcdataset>
    </paper>
    <paper id="235">
      <title>Neural Text Generation from Rich Semantic Representations</title>
      <author><first>Valerie</first><last>Hajdik</last></author>
      <author><first>Jan</first><last>Buys</last></author>
      <author><first>Michael Wayne</first><last>Goodman</last></author>
      <author><first>Emily M.</first><last>Bender</last></author>
      <pages>2259–2266</pages>
      <abstract>We propose neural models to generate high-quality text from structured representations based on Minimal Recursion Semantics (MRS). MRS is a rich semantic representation that encodes more precise semantic detail than other representations such as Abstract Meaning Representation (AMR). We show that a sequence-to-sequence model that maps a linearization of Dependency MRS, a graph-based representation of MRS, to <a href="https://en.wikipedia.org/wiki/Plain_text">text</a> can achieve a BLEU score of 66.11 when trained on gold data. The performance of the <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> can be improved further using a high-precision, broad coverage grammar-based parser to generate a large silver training corpus, achieving a final BLEU score of 77.17 on the full test set, and 83.37 on the subset of test data most closely matching the silver data domain. Our results suggest that MRS-based representations are a good choice for applications that need both structured semantics and the ability to produce natural language text as output.</abstract>
      <url hash="d8b217c5">N19-1235</url>
      <doi>10.18653/v1/N19-1235</doi>
      <bibkey>hajdik-etal-2019-neural</bibkey>
      <pwccode url="https://github.com/shlurbee/dmrs-text-generation-naacl2019" additional="false">shlurbee/dmrs-text-generation-naacl2019</pwccode>
    </paper>
    <paper id="239">
      <title>Open Information Extraction from Question-Answer Pairs</title>
      <author><first>Nikita</first><last>Bhutani</last></author>
      <author><first>Yoshihiko</first><last>Suhara</last></author>
      <author><first>Wang-Chiew</first><last>Tan</last></author>
      <author><first>Alon</first><last>Halevy</last></author>
      <author><first>H. V.</first><last>Jagadish</last></author>
      <pages>2294–2305</pages>
      <abstract>Open Information Extraction (OpenIE) extracts meaningful structured tuples from free-form text. Most previous work on OpenIE considers extracting data from one sentence at a time. We describe NeurON, a <a href="https://en.wikipedia.org/wiki/System">system</a> for extracting tuples from question-answer pairs. One of the main motivations for <a href="https://en.wikipedia.org/wiki/Neuron">NeurON</a> is to be able to extend <a href="https://en.wikipedia.org/wiki/Knowledge_base">knowledge bases</a> in a way that considers precisely the information that users care about. NeurON addresses several challenges. First, an answer text is often hard to understand without knowing the question, and second, relevant information can span multiple sentences. To address these, NeurON formulates extraction as a multi-source sequence-to-sequence learning task, wherein it combines distributed representations of a question and an answer to generate knowledge facts. We describe experiments on two real-world datasets that demonstrate that NeurON can find a significant number of new and interesting facts to extend a <a href="https://en.wikipedia.org/wiki/Knowledge_base">knowledge base</a> compared to state-of-the-art OpenIE methods.</abstract>
      <url hash="d77a3a94">N19-1239</url>
      <doi>10.18653/v1/N19-1239</doi>
      <bibkey>bhutani-etal-2019-open</bibkey>
    </paper>
    <paper id="240">
      <title>Question Answering by Reasoning Across Documents with Graph Convolutional Networks</title>
      <author><first>Nicola</first><last>De Cao</last></author>
      <author><first>Wilker</first><last>Aziz</last></author>
      <author><first>Ivan</first><last>Titov</last></author>
      <pages>2306–2317</pages>
      <abstract>Most research in <a href="https://en.wikipedia.org/wiki/Reading_comprehension">reading comprehension</a> has focused on answering questions based on individual documents or even single paragraphs. We introduce a neural model which integrates and reasons relying on information spread within documents and across multiple documents. We frame it as an inference problem on a <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph</a>. Mentions of entities are <a href="https://en.wikipedia.org/wiki/Vertex_(graph_theory)">nodes</a> of this <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph</a> while <a href="https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms">edges</a> encode relations between different <a href="https://en.wikipedia.org/wiki/Note_(typography)">mentions</a> (e.g., within- and cross-document co-reference). Graph convolutional networks (GCNs) are applied to these <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graphs</a> and trained to perform multi-step reasoning. Our Entity-GCN method is scalable and compact, and it achieves state-of-the-art results on a multi-document question answering dataset, WikiHop (Welbl et al., 2018).</abstract>
      <url hash="51b0272a">N19-1240</url>
      <doi>10.18653/v1/N19-1240</doi>
      <bibkey>de-cao-etal-2019-question</bibkey>
      <pwccode url="https://worksheets.codalab.org/worksheets/0xd2fb12d9f637460db16c110b5d3f2ca5" additional="false">worksheets/0xd2fb12d9</pwccode>
    </paper>
    <paper id="241">
      <title>A Qualitative Comparison of CoQA, SQuAD 2.0 and QuAC<fixed-case>C</fixed-case>o<fixed-case>QA</fixed-case>, <fixed-case>SQ</fixed-case>u<fixed-case>AD</fixed-case> 2.0 and <fixed-case>Q</fixed-case>u<fixed-case>AC</fixed-case></title>
      <author><first>Mark</first><last>Yatskar</last></author>
      <pages>2318–2323</pages>
      <abstract>We compare three new datasets for <a href="https://en.wikipedia.org/wiki/Question_answering">question answering</a> : <a href="https://en.wikipedia.org/wiki/Question_answering">SQuAD 2.0</a>, <a href="https://en.wikipedia.org/wiki/Question_answering">QuAC</a>, and <a href="https://en.wikipedia.org/wiki/Question_answering">CoQA</a>, along several of their new features : (1) unanswerable questions, (2) multi-turn interactions, and (3) abstractive answers. We show that the datasets provide complementary coverage of the first two aspects, but weak coverage of the third. Because of the datasets’ structural similarity, a single extractive model can be easily adapted to any of the datasets and we show improved baseline results on both <a href="https://en.wikipedia.org/wiki/Question_answering">SQuAD 2.0</a> and <a href="https://en.wikipedia.org/wiki/Question_answering">CoQA</a>. Despite the similarity, <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> trained on one <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> are ineffective on another <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>, but we find moderate performance improvement through pretraining. To encourage cross-evaluation, we release code for conversion between datasets.</abstract>
      <url hash="2b57aff4">N19-1241</url>
      <doi>10.18653/v1/N19-1241</doi>
      <bibkey>yatskar-2019-qualitative</bibkey>
      <pwccode url="https://github.com/my89/co-squac" additional="false">my89/co-squac</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/coqa">CoQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/quac">QuAC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="242">
      <title>BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis<fixed-case>BERT</fixed-case> Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis</title>
      <author><first>Hu</first><last>Xu</last></author>
      <author><first>Bing</first><last>Liu</last></author>
      <author><first>Lei</first><last>Shu</last></author>
      <author><first>Philip</first><last>Yu</last></author>
      <pages>2324–2335</pages>
      <abstract>Question-answering plays an important role in <a href="https://en.wikipedia.org/wiki/E-commerce">e-commerce</a> as it allows potential customers to actively seek crucial information about products or services to help their purchase decision making. Inspired by the recent success of machine reading comprehension (MRC) on formal documents, this paper explores the potential of turning customer reviews into a large source of knowledge that can be exploited to answer user questions. We call this problem Review Reading Comprehension (RRC). To the best of our knowledge, no existing work has been done on RRC. In this work, we first build an RRC dataset called ReviewRC based on a popular <a href="https://en.wikipedia.org/wiki/Benchmarking">benchmark</a> for aspect-based sentiment analysis. Since ReviewRC has limited training examples for RRC (and also for aspect-based sentiment analysis), we then explore a novel post-training approach on the popular language model BERT to enhance the performance of fine-tuning of BERT for RRC. To show the generality of the approach, the proposed post-training is also applied to some other review-based tasks such as <a href="https://en.wikipedia.org/wiki/Aspect_extraction">aspect extraction</a> and aspect sentiment classification in aspect-based sentiment analysis. Experimental results demonstrate that the proposed post-training is highly effective.</abstract>
      <url hash="cf993df7">N19-1242</url>
      <doi>10.18653/v1/N19-1242</doi>
      <bibkey>xu-etal-2019-bert</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/coqa">CoQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ms-marco">MS MARCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2014-task-4-sub-task-2">SemEval 2014 Task 4 Sub Task 2</pwcdataset>
    </paper>
    <paper id="243">
      <title>Old is Gold : Linguistic Driven Approach for Entity and Relation Linking of Short Text</title>
      <author><first>Ahmad</first><last>Sakor</last></author>
      <author><first>Isaiah</first><last>Onando Mulang’</last></author>
      <author><first>Kuldeep</first><last>Singh</last></author>
      <author><first>Saeedeh</first><last>Shekarpour</last></author>
      <author><first>Maria</first><last>Esther Vidal</last></author>
      <author><first>Jens</first><last>Lehmann</last></author>
      <author><first>Sören</first><last>Auer</last></author>
      <pages>2336–2346</pages>
      <abstract>Short texts challenge NLP tasks such as <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>, <a href="https://en.wikipedia.org/wiki/Word-sense_disambiguation">disambiguation</a>, linking and relation inference because they do not provide sufficient context or are partially malformed (e.g. wrt. capitalization, <a href="https://en.wikipedia.org/wiki/Long_tail">long tail entities</a>, implicit relations). In this work, we present the Falcon approach which effectively maps entities and relations within a short text to its mentions of a background knowledge graph. Falcon overcomes the challenges of short text using a light-weight linguistic approach relying on a background knowledge graph. Falcon performs joint entity and relation linking of a short text by leveraging several fundamental principles of <a href="https://en.wikipedia.org/wiki/English_language">English morphology</a> (e.g. compounding, headword identification) and utilizes an extended <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graph</a> created by merging entities and relations from various knowledge sources. It uses the context of entities for finding relations and does not require <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training data</a>. Our empirical study using several standard benchmarks and datasets show that Falcon significantly outperforms state-of-the-art entity and relation linking for short text query inventories.</abstract>
      <url hash="0074924e">N19-1243</url>
      <doi>10.18653/v1/N19-1243</doi>
      <bibkey>sakor-etal-2019-old</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/dbpedia">DBpedia</pwcdataset>
    </paper>
    <paper id="244">
      <title>Be Consistent ! Improving Procedural Text Comprehension using Label Consistency</title>
      <author><first>Xinya</first><last>Du</last></author>
      <author><first>Bhavana</first><last>Dalvi</last></author>
      <author><first>Niket</first><last>Tandon</last></author>
      <author><first>Antoine</first><last>Bosselut</last></author>
      <author><first>Wen-tau</first><last>Yih</last></author>
      <author><first>Peter</first><last>Clark</last></author>
      <author><first>Claire</first><last>Cardie</last></author>
      <pages>2347–2356</pages>
      <abstract>Our goal is procedural text comprehension, namely tracking how the properties of entities (e.g., their location) change with time given a procedural text (e.g., a paragraph about photosynthesis, a recipe). This <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> is challenging as the world is changing throughout the text, and despite recent advances, current <a href="https://en.wikipedia.org/wiki/System">systems</a> still struggle with this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. Our approach is to leverage the fact that, for many procedural texts, multiple independent descriptions are readily available, and that predictions from them should be consistent (label consistency). We present a new learning framework that leverages label consistency during training, allowing consistency bias to be built into the <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a>. Evaluation on a standard benchmark dataset for procedural text, ProPara (Dalvi et al., 2018), shows that our approach significantly improves prediction performance (F1) over prior state-of-the-art systems.</abstract>
      <url hash="eba535ac">N19-1244</url>
      <doi>10.18653/v1/N19-1244</doi>
      <bibkey>du-etal-2019-consistent</bibkey>
      <pwccode url="https://github.com/allenai/propara" additional="false">allenai/propara</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/propara">ProPara</pwcdataset>
    </paper>
    <paper id="246">
      <title>DROP : A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs<fixed-case>DROP</fixed-case>: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs</title>
      <author><first>Dheeru</first><last>Dua</last></author>
      <author><first>Yizhong</first><last>Wang</last></author>
      <author><first>Pradeep</first><last>Dasigi</last></author>
      <author><first>Gabriel</first><last>Stanovsky</last></author>
      <author><first>Sameer</first><last>Singh</last></author>
      <author><first>Matt</first><last>Gardner</last></author>
      <pages>2368–2378</pages>
      <abstract>Reading comprehension has recently seen rapid progress, with <a href="https://en.wikipedia.org/wiki/Computer">systems</a> matching humans on the most popular datasets for the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. However, a large body of work has highlighted the brittleness of these <a href="https://en.wikipedia.org/wiki/System">systems</a>, showing that there is much work left to be done. We introduce a new reading comprehension benchmark, DROP, which requires Discrete Reasoning Over the content of Paragraphs. In this crowdsourced, adversarially-created, 55k-question benchmark, a system must resolve references in a question, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or sorting). These operations require a much more comprehensive understanding of the content of paragraphs, as they remove the paraphrase-and-entity-typing shortcuts available in prior datasets. We apply state-of-the-art methods from both the reading comprehension and semantic parsing literatures on this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and show that the best <a href="https://en.wikipedia.org/wiki/System">systems</a> only achieve 38.4 % <a href="https://en.wikipedia.org/wiki/F-number">F1</a> on our generalized accuracy metric, while expert human performance is 96 %. We additionally present a new model that combines reading comprehension methods with simple <a href="https://en.wikipedia.org/wiki/Numerical_analysis">numerical reasoning</a> to achieve 51 % <a href="https://en.wikipedia.org/wiki/F-number">F1</a>.</abstract>
      <url hash="7eceec60">N19-1246</url>
      <attachment type="supplementary" hash="df69723c">N19-1246.Supplementary.pdf</attachment>
      <doi>10.18653/v1/N19-1246</doi>
      <bibkey>dua-etal-2019-drop</bibkey>
      <pwccode url="" additional="true" />
      <pwcdataset url="https://paperswithcode.com/dataset/drop">DROP</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikitablequestions">WikiTableQuestions</pwcdataset>
    </paper>
    <paper id="251">
      <title>A Simple and Robust Approach to Detecting Subject-Verb Agreement Errors</title>
      <author><first>Simon</first><last>Flachs</last></author>
      <author><first>Ophélie</first><last>Lacroix</last></author>
      <author><first>Marek</first><last>Rei</last></author>
      <author><first>Helen</first><last>Yannakoudakis</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>2418–2427</pages>
      <abstract>While rule-based detection of subject-verb agreement (SVA) errors is sensitive to syntactic parsing errors and irregularities and exceptions to the main rules, neural sequential labelers have a tendency to overfit their training data. We observe that rule-based error generation is less sensitive to syntactic parsing errors and irregularities than <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error detection</a> and explore a simple, yet efficient approach to getting the best of both worlds : We train neural sequential labelers on the combination of large volumes of silver standard data, obtained through rule-based error generation, and gold standard data. We show that our simple protocol leads to more robust detection of SVA errors on both in-domain and out-of-domain data, as well as in the context of other errors and long-distance dependencies ; and across four standard benchmarks, the induced model on average achieves a new state of the art.</abstract>
      <url hash="827b874e">N19-1251</url>
      <doi>10.18653/v1/N19-1251</doi>
      <bibkey>flachs-etal-2019-simple</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/fce">FCE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/jfleg">JFLEG</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="252">
      <title>A Grounded Unsupervised Universal Part-of-Speech Tagger for Low-Resource Languages</title>
      <author><first>Ronald</first><last>Cardenas</last></author>
      <author><first>Ying</first><last>Lin</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <author><first>Jonathan</first><last>May</last></author>
      <pages>2428–2439</pages>
      <abstract>Unsupervised part of speech (POS) tagging is often framed as a clustering problem, but practical taggers need to ground their clusters as well. Grounding generally requires reference labeled data, a luxury a low-resource language might not have. In this work, we describe an approach for low-resource unsupervised POS tagging that yields fully grounded output and requires no labeled training data. We find the classic <a href="https://en.wikipedia.org/wiki/Scientific_method">method</a> of Brown et al. (1992) clusters well in our use case and employ a decipherment-based approach to grounding. This approach presumes a sequence of cluster IDs is a ‘ciphertext’ and seeks a POS tag-to-cluster ID mapping that will reveal the POS sequence. We show intrinsically that, despite the difficulty of the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, we obtain reasonable performance across a variety of languages. We also show extrinsically that incorporating our <a href="https://en.wikipedia.org/wiki/POS_tagger">POS tagger</a> into a name tagger leads to state-of-the-art tagging performance in <a href="https://en.wikipedia.org/wiki/Sinhala_language">Sinhalese</a> and <a href="https://en.wikipedia.org/wiki/Kinyarwanda">Kinyarwanda</a>, two languages with nearly no labeled POS data available. We further demonstrate our tagger’s utility by incorporating it into a true ‘zero-resource’ variant of the MALOPA (Ammar et al., 2016) dependency parser model that removes the current reliance on multilingual resources and gold POS tags for new languages. Experiments show that including our <a href="https://en.wikipedia.org/wiki/Tagger">tagger</a> makes up much of the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> lost when gold POS tags are unavailable.</abstract>
      <url hash="6b23c531">N19-1252</url>
      <doi>10.18653/v1/N19-1252</doi>
      <bibkey>cardenas-etal-2019-grounded</bibkey>
      <pwccode url="https://github.com/isi-nlp/universal-cipher-pos-tagging" additional="false">isi-nlp/universal-cipher-pos-tagging</pwccode>
    </paper>
    <paper id="253">
      <title>On Difficulties of Cross-Lingual Transfer with Order Differences : A Case Study on Dependency Parsing</title>
      <author><first>Wasi</first><last>Ahmad</last></author>
      <author><first>Zhisong</first><last>Zhang</last></author>
      <author><first>Xuezhe</first><last>Ma</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <author><first>Kai-Wei</first><last>Chang</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <pages>2440–2452</pages>
      <abstract>Different languages might have different <a href="https://en.wikipedia.org/wiki/Part_of_speech">word orders</a>. In this paper, we investigate crosslingual transfer and posit that an orderagnostic model will perform better when transferring to distant foreign languages. To test our hypothesis, we train dependency parsers on an <a href="https://en.wikipedia.org/wiki/English_language">English corpus</a> and evaluate their transfer performance on 30 other languages. Specifically, we compare <a href="https://en.wikipedia.org/wiki/Encoder">encoders</a> and <a href="https://en.wikipedia.org/wiki/Code">decoders</a> based on <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">Recurrent Neural Networks (RNNs)</a> and modified self-attentive architectures. The former relies on sequential information while the latter is more flexible at modeling <a href="https://en.wikipedia.org/wiki/Word_order">word order</a>. Rigorous experiments and detailed analysis shows that RNN-based architectures transfer well to languages that are close to <a href="https://en.wikipedia.org/wiki/English_language">English</a>, while self-attentive models have better overall cross-lingual transferability and perform especially well on distant languages.</abstract>
      <url hash="d3cffba9">N19-1253</url>
      <attachment type="supplementary" hash="73234b1e">N19-1253.Supplementary.pdf</attachment>
      <doi>10.18653/v1/N19-1253</doi>
      <bibkey>ahmad-etal-2019-difficulties</bibkey>
      <pwccode url="https://github.com/uclanlp/CrossLingualDepParser" additional="true">uclanlp/CrossLingualDepParser</pwccode>
    </paper>
    <paper id="255">
      <title>Self-Discriminative Learning for Unsupervised Document Embedding</title>
      <author><first>Hong-You</first><last>Chen</last></author>
      <author><first>Chin-Hua</first><last>Hu</last></author>
      <author><first>Leila</first><last>Wehbe</last></author>
      <author><first>Shou-De</first><last>Lin</last></author>
      <pages>2465–2474</pages>
      <abstract>Unsupervised document representation learning is an important <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> providing pre-trained features for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP applications</a>. Unlike most previous work which learn the <a href="https://en.wikipedia.org/wiki/Embedding">embedding</a> based on self-prediction of the surface of text, we explicitly exploit the inter-document information and directly model the relations of documents in <a href="https://en.wikipedia.org/wiki/Embedding">embedding space</a> with a discriminative network and a novel objective. Extensive experiments on both small and large public datasets show the competitiveness of the proposed <a href="https://en.wikipedia.org/wiki/Methodology">method</a>. In evaluations on standard <a href="https://en.wikipedia.org/wiki/Document_classification">document classification</a>, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> has errors that are 5 to 13 % lower than state-of-the-art unsupervised embedding models. The reduction in error is even more pronounced in scarce label setting.</abstract>
      <url hash="2f2582a4">N19-1255</url>
      <doi>10.18653/v1/N19-1255</doi>
      <video href="https://vimeo.com/355814096" />
      <bibkey>chen-etal-2019-self</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
    </paper>
    <paper id="256">
      <title>Adaptive Convolution for Text Classification</title>
      <author><first>Byung-Ju</first><last>Choi</last></author>
      <author><first>Jun-Hyung</first><last>Park</last></author>
      <author><first>SangKeun</first><last>Lee</last></author>
      <pages>2475–2485</pages>
      <abstract>In this paper, we present an adaptive convolution for <a href="https://en.wikipedia.org/wiki/Text_classification">text classification</a> to give flexibility to convolutional neural networks (CNNs). Unlike traditional convolutions which utilize the same set of <a href="https://en.wikipedia.org/wiki/Filter_(signal_processing)">filters</a> regardless of different inputs, the adaptive convolution employs adaptively generated convolutional filters conditioned on inputs. We achieve this by attaching filter-generating networks, which are carefully designed to generate input-specific filters, to convolution blocks in existing CNNs. We show the efficacy of our approach in existing CNNs based on the <a href="https://en.wikipedia.org/wiki/Performance_evaluation">performance evaluation</a>. Our evaluation indicates that all of our baselines achieve performance improvements with adaptive convolutions as much as up to 2.6 percentage point in seven benchmark text classification datasets.</abstract>
      <url hash="891ce0ab">N19-1256</url>
      <attachment type="software" hash="4fbbbbbe">N19-1256.Software.zip</attachment>
      <doi>10.18653/v1/N19-1256</doi>
      <bibkey>choi-etal-2019-adaptive</bibkey>
    </paper>
    <paper id="257">
      <title>Zero-Shot Cross-Lingual Opinion Target Extraction<fixed-case>Z</fixed-case>ero-Shot Cross-Lingual Opinion Target Extraction</title>
      <author><first>Soufian</first><last>Jebbara</last></author>
      <author><first>Philipp</first><last>Cimiano</last></author>
      <pages>2486–2495</pages>
      <abstract>Aspect-based sentiment analysis involves the recognition of so called opinion target expressions (OTEs). To automatically extract OTEs, supervised learning algorithms are usually employed which are trained on manually annotated corpora. The creation of these <a href="https://en.wikipedia.org/wiki/Corpus_linguistics">corpora</a> is labor-intensive and sufficiently large datasets are therefore usually only available for a very narrow selection of languages and domains. In this work, we address the lack of available annotated data for specific languages by proposing a zero-shot cross-lingual approach for the extraction of opinion target expressions. We leverage multilingual word embeddings that share a common vector space across various languages and incorporate these into a convolutional neural network architecture for OTE extraction. Our experiments with 5 languages give promising results : We can successfully train a <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> on annotated data of a source language and perform accurate <a href="https://en.wikipedia.org/wiki/Prediction">prediction</a> on a target language without ever using any annotated samples in that target language. Depending on the source and target language pairs, we reach performances in a zero-shot regime of up to 77 % of a <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> trained on target language data. Furthermore, we can increase this performance up to 87 % of a baseline model trained on target language data by performing cross-lingual learning from multiple source languages.</abstract>
      <url hash="277f240f">N19-1257</url>
      <doi>10.18653/v1/N19-1257</doi>
      <video href="https://vimeo.com/359684150" />
      <bibkey>jebbara-cimiano-2019-zero</bibkey>
    </paper>
    <paper id="260">
      <title>Abstractive Summarization of Reddit Posts with Multi-level Memory Networks<fixed-case>R</fixed-case>eddit Posts with Multi-level Memory Networks</title>
      <author><first>Byeongchang</first><last>Kim</last></author>
      <author><first>Hyunwoo</first><last>Kim</last></author>
      <author><first>Gunhee</first><last>Kim</last></author>
      <pages>2519–2531</pages>
      <abstract>We address the problem of abstractive summarization in two directions : proposing a novel <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and a new <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a>. First, we collect Reddit TIFU dataset, consisting of 120 K posts from the online discussion forum Reddit. We use such informal crowd-generated posts as text source, in contrast with existing <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> that mostly use formal documents as source such as <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a>. Thus, our dataset could less suffer from some biases that key sentences usually located at the beginning of the text and favorable summary candidates are already inside the text in similar forms. Second, we propose a novel abstractive summarization model named multi-level memory networks (MMN), equipped with multi-level memory to store the information of text from different levels of abstraction. With quantitative evaluation and user studies via <a href="https://en.wikipedia.org/wiki/Amazon_Mechanical_Turk">Amazon Mechanical Turk</a>, we show the Reddit TIFU dataset is highly abstractive and the MMN outperforms the state-of-the-art summarization models.</abstract>
      <url hash="632e8109">N19-1260</url>
      <doi>10.18653/v1/N19-1260</doi>
      <bibkey>kim-etal-2019-abstractive</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/reddit-tifu">Reddit TIFU</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/newsroom">NEWSROOM</pwcdataset>
    </paper>
    <paper id="263">
      <title>Text Generation with Exemplar-based Adaptive Decoding</title>
      <author><first>Hao</first><last>Peng</last></author>
      <author><first>Ankur</first><last>Parikh</last></author>
      <author><first>Manaal</first><last>Faruqui</last></author>
      <author><first>Bhuwan</first><last>Dhingra</last></author>
      <author><first>Dipanjan</first><last>Das</last></author>
      <pages>2555–2565</pages>
      <abstract>We propose a novel conditioned text generation model. It draws inspiration from traditional template-based text generation techniques, where the source provides the content (i.e., what to say), and the template influences how to say it. Building on the successful encoder-decoder paradigm, it first encodes the content representation from the given input text ; to produce the output, it retrieves exemplar text from the training data as soft templates, which are then used to construct an exemplar-specific decoder. We evaluate the proposed <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> on abstractive text summarization and data-to-text generation. Empirical results show that this <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves strong performance and outperforms comparable baselines.</abstract>
      <url hash="0c9f3475">N19-1263</url>
      <attachment type="supplementary" hash="6d76a135">N19-1263.Supplementary.pdf</attachment>
      <doi>10.18653/v1/N19-1263</doi>
      <bibkey>peng-etal-2019-text</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wikibio">WikiBio</pwcdataset>
    </paper>
    <paper id="267">
      <title>Strong and Simple Baselines for Multimodal Utterance Embeddings</title>
      <author><first>Paul Pu</first><last>Liang</last></author>
      <author><first>Yao Chong</first><last>Lim</last></author>
      <author><first>Yao-Hung Hubert</first><last>Tsai</last></author>
      <author><first>Ruslan</first><last>Salakhutdinov</last></author>
      <author><first>Louis-Philippe</first><last>Morency</last></author>
      <pages>2599–2609</pages>
      <abstract>Human language is a rich multimodal signal consisting of <a href="https://en.wikipedia.org/wiki/Speech">spoken words</a>, <a href="https://en.wikipedia.org/wiki/Facial_expression">facial expressions</a>, <a href="https://en.wikipedia.org/wiki/Gesture">body gestures</a>, and <a href="https://en.wikipedia.org/wiki/Intonation_(linguistics)">vocal intonations</a>. Learning representations for these spoken utterances is a complex research problem due to the presence of multiple heterogeneous sources of information. Recent advances in <a href="https://en.wikipedia.org/wiki/Multimodal_learning">multimodal learning</a> have followed the general trend of building more complex models that utilize various attention, memory and recurrent components. In this paper, we propose two simple but strong baselines to learn embeddings of multimodal utterances. The first baseline assumes a conditional factorization of the utterance into unimodal factors. Each <a href="https://en.wikipedia.org/wiki/Unimodality">unimodal factor</a> is modeled using the simple form of a <a href="https://en.wikipedia.org/wiki/Likelihood_function">likelihood function</a> obtained via a linear transformation of the embedding. We show that the optimal embedding can be derived in closed form by taking a weighted average of the unimodal features. In order to capture richer representations, our second baseline extends the first by factorizing into unimodal, bimodal, and trimodal factors, while retaining simplicity and efficiency during <a href="https://en.wikipedia.org/wiki/Machine_learning">learning</a> and <a href="https://en.wikipedia.org/wiki/Statistical_inference">inference</a>. From a set of experiments across two tasks, we show strong performance on both supervised and semi-supervised multimodal prediction, as well as significant (10 times) speedups over neural models during <a href="https://en.wikipedia.org/wiki/Statistical_inference">inference</a>. Overall, we believe that our strong baseline models offer new benchmarking options for future research in <a href="https://en.wikipedia.org/wiki/Multimodal_learning">multimodal learning</a>.</abstract>
      <url hash="a339f819">N19-1267</url>
      <attachment type="supplementary" hash="90422f94">N19-1267.Supplementary.pdf</attachment>
      <doi>10.18653/v1/N19-1267</doi>
      <video href="https://vimeo.com/364226255" />
      <bibkey>liang-etal-2019-strong</bibkey>
      <pwccode url="https://github.com/yaochie/multimodal-baselines" additional="false">yaochie/multimodal-baselines</pwccode>
    </paper>
    <paper id="269">
      <title>Towards Content Transfer through Grounded Text Generation</title>
      <author><first>Shrimai</first><last>Prabhumoye</last></author>
      <author><first>Chris</first><last>Quirk</last></author>
      <author><first>Michel</first><last>Galley</last></author>
      <pages>2622–2632</pages>
      <abstract>Recent work in neural generation has attracted significant interest in controlling the form of text, such as <a href="https://en.wikipedia.org/wiki/Style_(manner_of_address)">style</a>, <a href="https://en.wikipedia.org/wiki/Persona">persona</a>, and <a href="https://en.wikipedia.org/wiki/Politeness">politeness</a>. However, there has been less work on controlling neural text generation for <a href="https://en.wikipedia.org/wiki/Content_(media)">content</a>. This paper introduces the notion of Content Transfer for long-form text generation, where the task is to generate a next sentence in a document that both fits its context and is grounded in a content-rich external textual source such as a news story. Our experiments on Wikipedia data show significant improvements against competitive <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baselines</a>. As another contribution of this paper, we release a benchmark dataset of 640k Wikipedia referenced sentences paired with the source articles to encourage exploration of this new task.</abstract>
      <url hash="6042552e">N19-1269</url>
      <doi>10.18653/v1/N19-1269</doi>
      <video href="https://vimeo.com/364740187" />
      <bibkey>prabhumoye-etal-2019-towards</bibkey>
    </paper>
    <paper id="270">
      <title>Improving Machine Reading Comprehension with General Reading Strategies</title>
      <author><first>Kai</first><last>Sun</last></author>
      <author><first>Dian</first><last>Yu</last></author>
      <author><first>Dong</first><last>Yu</last></author>
      <author><first>Claire</first><last>Cardie</last></author>
      <pages>2633–2643</pages>
      <abstract>Reading strategies have been shown to improve <a href="https://en.wikipedia.org/wiki/Sentence_processing">comprehension levels</a>, especially for readers lacking adequate prior knowledge. Just as the process of knowledge accumulation is time-consuming for human readers, it is resource-demanding to impart rich general domain knowledge into a <a href="https://en.wikipedia.org/wiki/Deep_learning">deep language model</a> via pre-training. Inspired by reading strategies identified in <a href="https://en.wikipedia.org/wiki/Cognitive_science">cognitive science</a>, and given limited computational resources-just a pre-trained model and a fixed number of training instances-we propose three general strategies aimed to improve non-extractive machine reading comprehension (MRC): (i) BACK AND FORTH READING that considers both the original and reverse order of an input sequence, (ii) HIGHLIGHTING, which adds a trainable embedding to the text embedding of tokens that are relevant to the question and candidate answers, and (iii) SELF-ASSESSMENT that generates practice questions and candidate answers directly from the text in an unsupervised manner. By fine-tuning a pre-trained language model (Radford et al., 2018) with our proposed strategies on the largest general domain multiple-choice MRC dataset RACE, we obtain a 5.8 % absolute increase in accuracy over the previous best result achieved by the same pre-trained model fine-tuned on RACE without the use of strategies.</abstract>
      <url hash="164121b2">N19-1270</url>
      <doi>10.18653/v1/N19-1270</doi>
      <video href="https://vimeo.com/364746823" />
      <bibkey>sun-etal-2019-improving</bibkey>
      <pwccode url="https://github.com/nlpdata/strategy" additional="false">nlpdata/strategy</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/arc">ARC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mctest">MCTest</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/multirc">MultiRC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/openbookqa">OpenBookQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/race">RACE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/rocstories">ROCStories</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="271">
      <title>Multi-task Learning with Sample Re-weighting for Machine Reading Comprehension</title>
      <author><first>Yichong</first><last>Xu</last></author>
      <author><first>Xiaodong</first><last>Liu</last></author>
      <author><first>Yelong</first><last>Shen</last></author>
      <author><first>Jingjing</first><last>Liu</last></author>
      <author><first>Jianfeng</first><last>Gao</last></author>
      <pages>2644–2655</pages>
      <abstract>We propose a multi-task learning framework to learn a joint Machine Reading Comprehension (MRC) model that can be applied to a wide range of MRC tasks in different domains. Inspired by recent ideas of data selection in <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>, we develop a novel sample re-weighting scheme to assign sample-specific weights to the loss. Empirical study shows that our approach can be applied to many existing MRC models. Combined with contextual representations from pre-trained language models (such as ELMo), we achieve new state-of-the-art results on a set of MRC benchmark datasets. We release our code at.<url>https://github.com/xycforgithub/MultiTask-MRC</url>.</abstract>
      <url hash="6e138f70">N19-1271</url>
      <doi>10.18653/v1/N19-1271</doi>
      <video href="https://vimeo.com/364750438" />
      <bibkey>xu-etal-2019-multi</bibkey>
      <pwccode url="https://github.com/xycforgithub/MultiTask-MRC" additional="true">xycforgithub/MultiTask-MRC</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/ms-marco">MS MARCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/newsqa">NewsQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="273">
      <title>Iterative Search for Weakly Supervised Semantic Parsing</title>
      <author><first>Pradeep</first><last>Dasigi</last></author>
      <author><first>Matt</first><last>Gardner</last></author>
      <author><first>Shikhar</first><last>Murty</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <pages>2669–2680</pages>
      <abstract>Training semantic parsers from question-answer pairs typically involves searching over an exponentially large space of <a href="https://en.wikipedia.org/wiki/Logical_form">logical forms</a>, and an unguided search can easily be misled by spurious logical forms that coincidentally evaluate to the correct answer. We propose a novel iterative training algorithm that alternates between searching for consistent logical forms and maximizing the marginal likelihood of the retrieved ones. This training scheme lets us iteratively train <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> that provide guidance to subsequent ones to search for logical forms of increasing <a href="https://en.wikipedia.org/wiki/Computational_complexity_theory">complexity</a>, thus dealing with the problem of spuriousness. We evaluate these techniques on two hard datasets : WikiTableQuestions (WTQ) and Cornell Natural Language Visual Reasoning (NLVR), and show that our training algorithm outperforms the previous best systems, on WTQ in a comparable setting, and on NLVR with significantly less supervision.</abstract>
      <url hash="25daa9ab">N19-1273</url>
      <attachment type="presentation" hash="7a22f55d">N19-1273.Presentation.pdf</attachment>
      <doi>10.18653/v1/N19-1273</doi>
      <video href="https://vimeo.com/361691015" />
      <bibkey>dasigi-etal-2019-iterative</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/nlvr">NLVR</pwcdataset>
    </paper>
    <paper id="275">
      <title>Bridging the Gap : Attending to Discontinuity in Identification of Multiword Expressions<fixed-case>B</fixed-case>ridging the Gap: <fixed-case>A</fixed-case>ttending to Discontinuity in Identification of Multiword Expressions</title>
      <author><first>Omid</first><last>Rohanian</last></author>
      <author><first>Shiva</first><last>Taslimipoor</last></author>
      <author><first>Samaneh</first><last>Kouchaki</last></author>
      <author><first>Le An</first><last>Ha</last></author>
      <author><first>Ruslan</first><last>Mitkov</last></author>
      <pages>2692–2698</pages>
      <abstract>We introduce a new method to tag Multiword Expressions (MWEs) using a linguistically interpretable language-independent deep learning architecture. We specifically target <a href="https://en.wikipedia.org/wiki/Classification_of_discontinuities">discontinuity</a>, an under-explored aspect that poses a significant challenge to computational treatment of MWEs. Two neural architectures are explored : Graph Convolutional Network (GCN) and multi-head self-attention. GCN leverages dependency parse information, and self-attention attends to long-range relations. We finally propose a combined <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> that integrates complementary information from both, through a gating mechanism. The experiments on a standard multilingual dataset for verbal MWEs show that our model outperforms the baselines not only in the case of discontinuous MWEs but also in overall F-score.</abstract>
      <url hash="668e8d28">N19-1275</url>
      <doi>10.18653/v1/N19-1275</doi>
      <bibkey>rohanian-etal-2019-bridging</bibkey>
      <pwccode url="https://github.com/omidrohanian/gappy-mwes" additional="true">omidrohanian/gappy-mwes</pwccode>
    </paper>
    <paper id="277">
      <title>VCWE : Visual Character-Enhanced Word Embeddings<fixed-case>VCWE</fixed-case>: Visual Character-Enhanced Word Embeddings</title>
      <author><first>Chi</first><last>Sun</last></author>
      <author><first>Xipeng</first><last>Qiu</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>2710–2719</pages>
      <abstract>Chinese is a <a href="https://en.wikipedia.org/wiki/Logogram">logographic writing system</a>, and the shape of Chinese characters contain rich syntactic and semantic information. In this paper, we propose a model to learn Chinese word embeddings via three-level composition : (1) a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a> to extract the intra-character compositionality from the visual shape of a character ; (2) a <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network</a> with self-attention to compose character representation into word embeddings ; (3) the Skip-Gram framework to capture non-compositionality directly from the contextual information. Evaluations demonstrate the superior performance of our model on four tasks : word similarity, <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a>, <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a> and <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech tagging</a>.</abstract>
      <url hash="363725b5">N19-1277</url>
      <doi>10.18653/v1/N19-1277</doi>
      <bibkey>sun-etal-2019-vcwe</bibkey>
      <pwccode url="https://github.com/HSLCY/VCWE" additional="false">HSLCY/VCWE</pwccode>
    </paper>
    <paper id="278">
      <title>Subword Encoding in Lattice LSTM for Chinese Word Segmentation<fixed-case>LSTM</fixed-case> for <fixed-case>C</fixed-case>hinese Word Segmentation</title>
      <author><first>Jie</first><last>Yang</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <author><first>Shuailong</first><last>Liang</last></author>
      <pages>2720–2725</pages>
      <abstract>We investigate subword information for Chinese word segmentation, by integrating sub word embeddings trained using byte-pair encoding into a Lattice LSTM (LaLSTM) network over a character sequence. Experiments on standard benchmark show that subword information brings significant gains over strong character-based segmentation models. To our knowledge, this is the first research on the effectiveness of <a href="https://en.wikipedia.org/wiki/Subword">subwords</a> on neural word segmentation.</abstract>
      <url hash="568bdb97">N19-1278</url>
      <attachment type="supplementary" hash="fc343716">N19-1278.Supplementary.pdf</attachment>
      <doi>10.18653/v1/N19-1278</doi>
      <bibkey>yang-etal-2019-subword</bibkey>
      <pwccode url="https://github.com/jiesutd/SubwordEncoding-CWS" additional="false">jiesutd/SubwordEncoding-CWS</pwccode>
    </paper>
    <paper id="281">
      <title>Shrinking Japanese Morphological Analyzers With <a href="https://en.wikipedia.org/wiki/Neural_network">Neural Networks</a> and <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning">Semi-supervised Learning</a><fixed-case>J</fixed-case>apanese Morphological Analyzers With Neural Networks and Semi-supervised Learning</title>
      <author><first>Arseny</first><last>Tolmachev</last></author>
      <author><first>Daisuke</first><last>Kawahara</last></author>
      <author><first>Sadao</first><last>Kurohashi</last></author>
      <pages>2744–2755</pages>
      <abstract>For languages without natural word boundaries, like <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese</a> and <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a>, <a href="https://en.wikipedia.org/wiki/Word_segmentation">word segmentation</a> is a prerequisite for downstream analysis. For <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese</a>, segmentation is often done jointly with <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part of speech tagging</a>, and this process is usually referred to as <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological analysis</a>. Morphological analyzers are trained on data hand-annotated with segmentation boundaries and <a href="https://en.wikipedia.org/wiki/Tag_(metadata)">part of speech tags</a>. A segmentation dictionary or character n-gram information is also provided as additional inputs to the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>. Incorporating this extra information makes <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> large. Modern neural morphological analyzers can consume gigabytes of <a href="https://en.wikipedia.org/wiki/Computer_memory">memory</a>. We propose a compact alternative to these cumbersome approaches which do not rely on any externally provided n-gram or word representations. The model uses only unigram character embeddings, encodes them using either stacked bi-LSTM or a self-attention network, and independently infers both segmentation and part of speech information. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is trained in an end-to-end and semi-supervised fashion, on labels produced by a state-of-the-art analyzer. We demonstrate that the proposed technique rivals performance of a previous dictionary-based state-of-the-art approach and can even surpass it when training with the combination of human-annotated and automatically-annotated data. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> itself is significantly smaller than the dictionary-based one : it uses less than 15 megabytes of space.</abstract>
      <url hash="8ce59293">N19-1281</url>
      <doi>10.18653/v1/N19-1281</doi>
      <bibkey>tolmachev-etal-2019-shrinking</bibkey>
    </paper>
    <paper id="282">
      <title>Neural Constituency Parsing of Speech Transcripts</title>
      <author><first>Paria</first><last>Jamshid Lou</last></author>
      <author><first>Yufei</first><last>Wang</last></author>
      <author><first>Mark</first><last>Johnson</last></author>
      <pages>2756–2765</pages>
      <abstract>This paper studies the performance of a neural self-attentive parser on <a href="https://en.wikipedia.org/wiki/Transcription_(linguistics)">transcribed speech</a>. Speech presents parsing challenges that do not appear in written text, such as the lack of <a href="https://en.wikipedia.org/wiki/Punctuation">punctuation</a> and the presence of <a href="https://en.wikipedia.org/wiki/Speech_disfluency">speech disfluencies</a> (including filled pauses, <a href="https://en.wikipedia.org/wiki/Repetition_(rhetorical_device)">repetitions</a>, corrections, etc.). Disfluencies are especially problematic for conventional syntactic parsers, which typically fail to find any EDITED disfluency nodes at all. This motivated the development of special disfluency detection systems, and special mechanisms added to <a href="https://en.wikipedia.org/wiki/Parsing">parsers</a> specifically to handle <a href="https://en.wikipedia.org/wiki/Disfluency">disfluencies</a>. However, we show here that <a href="https://en.wikipedia.org/wiki/Parsing">neural parsers</a> can find EDITED disfluency nodes, and the best <a href="https://en.wikipedia.org/wiki/Parsing">neural parsers</a> find them with an accuracy surpassing that of specialized disfluency detection systems, thus making these specialized mechanisms unnecessary. This paper also investigates a modified <a href="https://en.wikipedia.org/wiki/Loss_function">loss function</a> that puts more weight on EDITED nodes. It also describes tree-transformations that simplify the disfluency detection task by providing alternative encodings of disfluencies and syntactic information.</abstract>
      <url hash="4f130f9d">N19-1282</url>
      <doi>10.18653/v1/N19-1282</doi>
      <bibkey>jamshid-lou-etal-2019-neural</bibkey>
    </paper>
    <paper id="283">
      <title>Acoustic-to-Word Models with Conversational Context Information</title>
      <author><first>Suyoun</first><last>Kim</last></author>
      <author><first>Florian</first><last>Metze</last></author>
      <pages>2766–2771</pages>
      <abstract>Conversational context information, higher-level knowledge that spans across sentences, can help to recognize a long conversation. However, existing speech recognition models are typically built at a <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentence level</a>, and thus it may not capture important <a href="https://en.wikipedia.org/wiki/Context_(language_use)">conversational context information</a>. The recent progress in end-to-end speech recognition enables integrating context with other available information (e.g., acoustic, linguistic resources) and directly recognizing words from <a href="https://en.wikipedia.org/wiki/Speech">speech</a>. In this work, we present a direct acoustic-to-word, end-to-end speech recognition model capable of utilizing the conversational context to better process long conversations. We evaluate our proposed approach on the Switchboard conversational speech corpus and show that our system outperforms a standard end-to-end speech recognition system.</abstract>
      <url hash="e8c684ee">N19-1283</url>
      <doi>10.18653/v1/N19-1283</doi>
      <bibkey>kim-metze-2019-acoustic</bibkey>
    </paper>
    <paper id="286">
      <title>Relation Classification Using Segment-Level Attention-based CNN and Dependency-based RNN<fixed-case>CNN</fixed-case> and Dependency-based <fixed-case>RNN</fixed-case></title>
      <author><first>Van-Hien</first><last>Tran</last></author>
      <author><first>Van-Thuy</first><last>Phi</last></author>
      <author><first>Hiroyuki</first><last>Shindo</last></author>
      <author><first>Yuji</first><last>Matsumoto</last></author>
      <pages>2793–2798</pages>
      <abstract>Recently, relation classification has gained much success by exploiting <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural networks</a>. In this paper, we propose a new model effectively combining Segment-level Attention-based Convolutional Neural Networks (SACNNs) and Dependency-based Recurrent Neural Networks (DepRNNs). While SACNNs allow the model to selectively focus on the important information segment from the raw sequence, DepRNNs help to handle the long-distance relations from the shortest dependency path of relation entities. Experiments on the SemEval-2010 Task 8 dataset show that our model is comparable to the <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a> without using any external lexical features.</abstract>
      <url hash="4c852a3b">N19-1286</url>
      <doi>10.18653/v1/N19-1286</doi>
      <bibkey>tran-etal-2019-relation</bibkey>
    </paper>
    <paper id="288">
      <title>Distant Supervision Relation Extraction with Intra-Bag and Inter-Bag Attentions</title>
      <author><first>Zhi-Xiu</first><last>Ye</last></author>
      <author><first>Zhen-Hua</first><last>Ling</last></author>
      <pages>2810–2819</pages>
      <abstract>This paper presents a neural relation extraction method to deal with the noisy training data generated by distant supervision. Previous studies mainly focus on sentence-level de-noising by designing <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a> with intra-bag attentions. In this paper, both intra-bag and inter-bag attentions are considered in order to deal with the <a href="https://en.wikipedia.org/wiki/Noise">noise</a> at sentence-level and bag-level respectively. First, relation-aware bag representations are calculated by weighting <a href="https://en.wikipedia.org/wiki/Sentence_embedding">sentence embeddings</a> using intra-bag attentions. Here, each possible relation is utilized as the query for attention calculation instead of only using the target relation in conventional methods. Furthermore, the representation of a group of bags in the training set which share the same relation label is calculated by weighting bag representations using a similarity-based inter-bag attention module. Finally, a bag group is utilized as a training sample when building our relation extractor. Experimental results on the New York Times dataset demonstrate the effectiveness of our proposed intra-bag and inter-bag attention modules. Our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> also achieves better relation extraction accuracy than state-of-the-art methods on this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>.</abstract>
      <url hash="c7e05b3d">N19-1288</url>
      <doi>10.18653/v1/N19-1288</doi>
      <bibkey>ye-ling-2019-distant</bibkey>
      <pwccode url="https://github.com/ZhixiuYe/Intra-Bag-and-Inter-Bag-Attentions" additional="false">ZhixiuYe/Intra-Bag-and-Inter-Bag-Attentions</pwccode>
    </paper>
    <paper id="289">
      <title>Ranking-Based Autoencoder for Extreme Multi-label Classification</title>
      <author><first>Bingyu</first><last>Wang</last></author>
      <author><first>Li</first><last>Chen</last></author>
      <author><first>Wei</first><last>Sun</last></author>
      <author><first>Kechen</first><last>Qin</last></author>
      <author><first>Kefeng</first><last>Li</last></author>
      <author><first>Hui</first><last>Zhou</last></author>
      <pages>2820–2830</pages>
      <abstract>Extreme Multi-label classification (XML) is an important yet challenging machine learning task, that assigns to each instance its most relevant candidate labels from an extremely large label collection, where the numbers of labels, <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> and instances could be thousands or millions. XML is more and more on demand in the Internet industries, accompanied with the increasing business scale / scope and data accumulation. The extremely large label collections yield challenges such as <a href="https://en.wikipedia.org/wiki/Computational_complexity_theory">computational complexity</a>, inter-label dependency and noisy labeling. Many methods have been proposed to tackle these challenges, based on different mathematical formulations. In this paper, we propose a deep learning XML method, with a word-vector-based self-attention, followed by a ranking-based AutoEncoder architecture. The proposed method has three major advantages : 1) the autoencoder simultaneously considers the inter-label dependencies and the feature-label dependencies, by projecting labels and <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> onto a common embedding space ; 2) the ranking loss not only improves the training efficiency and accuracy but also can be extended to handle noisy labeled data ; 3) the efficient attention mechanism improves feature representation by highlighting feature importance. Experimental results on benchmark datasets show the proposed method is competitive to state-of-the-art methods.</abstract>
      <url hash="7d546d94">N19-1289</url>
      <doi>10.18653/v1/N19-1289</doi>
      <bibkey>wang-etal-2019-ranking</bibkey>
    </paper>
    <paper id="290">
      <title>Posterior-regularized REINFORCE for Instance Selection in Distant Supervision<fixed-case>REINFORCE</fixed-case> for Instance Selection in Distant Supervision</title>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Siliang</first><last>Tang</last></author>
      <author><first>Xiang</first><last>Ren</last></author>
      <author><first>Fei</first><last>Wu</last></author>
      <author><first>Shiliang</first><last>Pu</last></author>
      <author><first>Yueting</first><last>Zhuang</last></author>
      <pages>2831–2835</pages>
      <abstract>This paper provides a new way to improve the efficiency of the REINFORCE training process. We apply <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> to the task of <a href="https://en.wikipedia.org/wiki/Instance_selection">instance selection</a> in distant supervision. Modeling the instance selection in one bag as a sequential decision process, a reinforcement learning agent is trained to determine whether an instance is valuable or not and construct a new bag with less noisy instances. However <a href="https://en.wikipedia.org/wiki/Bias_(statistics)">unbiased methods</a>, such as REINFORCE, could usually take much time to train. This paper adopts posterior regularization (PR) to integrate some domain-specific rules in instance selection using REINFORCE. As the experiment results show, this method remarkably improves the performance of the relation classifier trained on cleaned distant supervision dataset as well as the efficiency of the REINFORCE training.</abstract>
      <url hash="3c054d8c">N19-1290</url>
      <doi>10.18653/v1/N19-1290</doi>
      <bibkey>zhang-etal-2019-posterior</bibkey>
    </paper>
    <paper id="291">
      <title>Scalable Collapsed Inference for High-Dimensional Topic Models</title>
      <author><first>Rashidul</first><last>Islam</last></author>
      <author><first>James</first><last>Foulds</last></author>
      <pages>2836–2845</pages>
      <abstract>The bigger the corpus, the more topics it can potentially support. To truly make full use of massive text corpora, a topic model inference algorithm must therefore scale efficiently in 1) documents and 2) topics, while 3) achieving accurate <a href="https://en.wikipedia.org/wiki/Statistical_inference">inference</a>. Previous methods have achieved two out of three of these criteria simultaneously, but never all three at once. In this paper, we develop an online inference algorithm for <a href="https://en.wikipedia.org/wiki/Topic_model">topic models</a> which leverages <a href="https://en.wikipedia.org/wiki/Stochastic">stochasticity</a> to scale well in the number of documents, sparsity to scale well in the number of topics, and which operates in the collapsed representation of the topic model for improved accuracy and run-time performance. We use a <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo inner loop</a> in the online setting to approximate the collapsed variational Bayes updates in a sparse and efficient way, which we accomplish via the MetropolisHastings Walker method. We showcase our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> on LDA and the recently proposed mixed membership skip-gram topic model. Our method requires only amortized O(k_d) computation per word token instead of O(K) operations, where the number of topics occurring for a particular document k_d the total number of topics in the corpus K, to converge to a high-quality solution.<tex-math>O(k_{d})</tex-math> computation per word token instead of <tex-math>O(K)</tex-math> operations, where the number of topics occurring for a particular document <tex-math>k_{d}\ll</tex-math> the total number of topics in the corpus <tex-math>K</tex-math>, to converge to a high-quality solution.</abstract>
      <url hash="51790b27">N19-1291</url>
      <doi>10.18653/v1/N19-1291</doi>
      <bibkey>islam-foulds-2019-scalable</bibkey>
      <pwccode url="https://github.com/dr97531/SparseSCVB0" additional="false">dr97531/SparseSCVB0</pwccode>
    </paper>
    <paper id="293">
      <title>Predicting Malware Attributes from Cybersecurity Texts</title>
      <author><first>Arpita</first><last>Roy</last></author>
      <author><first>Youngja</first><last>Park</last></author>
      <author><first>Shimei</first><last>Pan</last></author>
      <pages>2857–2861</pages>
      <abstract>Text analytics is a useful tool for studying <a href="https://en.wikipedia.org/wiki/Malware">malware behavior</a> and <a href="https://en.wikipedia.org/wiki/Threat_(computer)">tracking emerging threats</a>. The task of automated malware attribute identification based on cybersecurity texts is very challenging due to a large number of malware attribute labels and a small number of training instances. In this paper, we propose a novel feature learning method to leverage diverse knowledge sources such as small amount of human annotations, unlabeled text and specifications about malware attribute labels. Our evaluation has demonstrated the effectiveness of our method over the state-of-the-art malware attribute prediction systems.</abstract>
      <url hash="5132e912">N19-1293</url>
      <doi>10.18653/v1/N19-1293</doi>
      <bibkey>roy-etal-2019-predicting</bibkey>
    </paper>
    <paper id="298">
      <title>A Richer-but-Smarter Shortest Dependency Path with Attentive Augmentation for <a href="https://en.wikipedia.org/wiki/Relation_extraction">Relation Extraction</a></title>
      <author><first>Duy-Cat</first><last>Can</last></author>
      <author><first>Hoang-Quynh</first><last>Le</last></author>
      <author><first>Quang-Thuy</first><last>Ha</last></author>
      <author><first>Nigel</first><last>Collier</last></author>
      <pages>2902–2912</pages>
      <abstract>To extract the relationship between two entities in a sentence, two common approaches are (1) using their shortest dependency path (SDP) and (2) using an attention model to capture a context-based representation of the sentence. Each <a href="https://en.wikipedia.org/wiki/Software_development_process">approach</a> suffers from its own disadvantage of either <a href="https://en.wikipedia.org/wiki/Information_asymmetry">missing or redundant information</a>. In this work, we propose a novel <a href="https://en.wikipedia.org/wiki/Scientific_modelling">model</a> that combines the advantages of these two <a href="https://en.wikipedia.org/wiki/Scientific_modelling">approaches</a>. This is based on the basic information in the SDP enhanced with information selected by several attention mechanisms with kernel filters, namely RbSP (Richer-but-Smarter SDP). To exploit the representation behind the RbSP structure effectively, we develop a combined <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural model</a> with a LSTM network on word sequences and a CNN on RbSP. Experimental results on the SemEval-2010 dataset demonstrate improved performance over competitive <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baselines</a>. The data and source code are available at https://github.com/catcd/RbSP.</abstract>
      <url hash="af300d6d">N19-1298</url>
      <doi>10.18653/v1/N19-1298</doi>
      <bibkey>can-etal-2019-richer</bibkey>
      <pwccode url="https://github.com/catcd/RbSP" additional="false">catcd/RbSP</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2010-task-8">SemEval-2010 Task 8</pwcdataset>
    </paper>
    <paper id="299">
      <title>Bidirectional Attentive Memory Networks for Question Answering over Knowledge Bases</title>
      <author><first>Yu</first><last>Chen</last></author>
      <author><first>Lingfei</first><last>Wu</last></author>
      <author><first>Mohammed J.</first><last>Zaki</last></author>
      <pages>2913–2923</pages>
      <abstract>When answering <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language questions</a> over knowledge bases (KBs), different question components and KB aspects play different roles. However, most existing embedding-based methods for knowledge base question answering (KBQA) ignore the subtle inter-relationships between the question and the KB (e.g., <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity types</a>, <a href="https://en.wikipedia.org/wiki/Relation_(database)">relation paths</a> and <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context</a>). In this work, we propose to directly model the two-way flow of interactions between the questions and the KB via a novel Bidirectional Attentive Memory Network, called BAMnet. Requiring no external resources and only very few hand-crafted features, on the WebQuestions benchmark, our method significantly outperforms existing information-retrieval based methods, and remains competitive with (hand-crafted) semantic parsing based methods. Also, since we use <a href="https://en.wikipedia.org/wiki/Attentional_control">attention mechanisms</a>, our method offers better <a href="https://en.wikipedia.org/wiki/Interpretability">interpretability</a> compared to other baselines.</abstract>
      <url hash="d2dbbfd5">N19-1299</url>
      <doi>10.18653/v1/N19-1299</doi>
      <video href="https://vimeo.com/356071812" />
      <bibkey>chen-etal-2019-bidirectional</bibkey>
      <pwccode url="https://github.com/hugochan/BAMnet" additional="true">hugochan/BAMnet</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/webquestions">WebQuestions</pwcdataset>
    </paper>
    <paper id="301">
      <title>Enhancing Key-Value Memory Neural Networks for Knowledge Based Question Answering</title>
      <author><first>Kun</first><last>Xu</last></author>
      <author><first>Yuxuan</first><last>Lai</last></author>
      <author><first>Yansong</first><last>Feng</last></author>
      <author><first>Zhiguo</first><last>Wang</last></author>
      <pages>2937–2947</pages>
      <abstract>Traditional Key-value Memory Neural Networks (KV-MemNNs) are proved to be effective to support shallow reasoning over a collection of documents in domain specific Question Answering or Reading Comprehension tasks. However, extending KV-MemNNs to Knowledge Based Question Answering (KB-QA) is not trivia, which should properly decompose a complex question into a sequence of queries against the <a href="https://en.wikipedia.org/wiki/Random-access_memory">memory</a>, and update the query representations to support multi-hop reasoning over the <a href="https://en.wikipedia.org/wiki/Random-access_memory">memory</a>. In this paper, we propose a novel mechanism to enable conventional KV-MemNNs models to perform interpretable reasoning for complex questions. To achieve this, we design a new query updating strategy to mask previously-addressed memory information from the query representations, and introduce a novel STOP strategy to avoid invalid or repeated memory reading without strong annotation signals. This also enables KV-MemNNs to produce structured queries and work in a semantic parsing fashion. Experimental results on benchmark datasets show that our solution, trained with question-answer pairs only, can provide conventional KV-MemNNs models with better reasoning abilities on complex questions, and achieve state-of-art performances.</abstract>
      <url hash="689def29">N19-1301</url>
      <doi>10.18653/v1/N19-1301</doi>
      <video href="https://vimeo.com/356088995" />
      <bibkey>xu-etal-2019-enhancing</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/dbpedia">DBpedia</pwcdataset>
    </paper>
    <paper id="304">
      <title>Analyzing Polarization in <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a> : Method and Application to <a href="https://en.wikipedia.org/wiki/Twitter">Tweets</a> on 21 Mass Shootings</title>
      <author><first>Dorottya</first><last>Demszky</last></author>
      <author><first>Nikhil</first><last>Garg</last></author>
      <author><first>Rob</first><last>Voigt</last></author>
      <author><first>James</first><last>Zou</last></author>
      <author><first>Jesse</first><last>Shapiro</last></author>
      <author><first>Matthew</first><last>Gentzkow</last></author>
      <author><first>Dan</first><last>Jurafsky</last></author>
      <pages>2970–3005</pages>
      <abstract>We provide an NLP framework to uncover four linguistic dimensions of <a href="https://en.wikipedia.org/wiki/Political_polarization">political polarization</a> in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> : topic choice, <a href="https://en.wikipedia.org/wiki/Framing_(social_sciences)">framing</a>, <a href="https://en.wikipedia.org/wiki/Affect_(psychology)">affect</a> and <a href="https://en.wikipedia.org/wiki/Illocutionary_force">illocutionary force</a>. We quantify these aspects with existing lexical methods, and propose clustering of tweet embeddings as a means to identify salient topics for analysis across events ; human evaluations show that our approach generates more cohesive topics than traditional LDA-based models. We apply our <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> to study 4.4 M tweets on 21 <a href="https://en.wikipedia.org/wiki/Mass_shooting">mass shootings</a>. We provide evidence that the discussion of these events is highly polarized politically and that this polarization is primarily driven by partisan differences in <a href="https://en.wikipedia.org/wiki/Framing_(social_sciences)">framing</a> rather than topic choice. We identify <a href="https://en.wikipedia.org/wiki/Framing_(social_sciences)">framing devices</a>, such as grounding and the contrasting use of the terms terrorist and crazy, that contribute to <a href="https://en.wikipedia.org/wiki/Political_polarization">polarization</a>. Results pertaining to topic choice, <a href="https://en.wikipedia.org/wiki/Affect_(psychology)">affect</a> and illocutionary force suggest that Republicans focus more on the shooter and event-specific facts (news) while Democrats focus more on the victims and call for policy changes. Our work contributes to a deeper understanding of the way group divisions manifest in language and to <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational methods</a> for studying them.</abstract>
      <url hash="c32776f5">N19-1304</url>
      <doi>10.18653/v1/N19-1304</doi>
      <video href="https://vimeo.com/359689303" />
      <bibkey>demszky-etal-2019-analyzing</bibkey>
      <pwccode url="https://github.com/ddemszky/framing-twitter" additional="false">ddemszky/framing-twitter</pwccode>
    </paper>
    <paper id="306">
      <title>Long-tail Relation Extraction via Knowledge Graph Embeddings and Graph Convolution Networks</title>
      <author><first>Ningyu</first><last>Zhang</last></author>
      <author><first>Shumin</first><last>Deng</last></author>
      <author><first>Zhanlin</first><last>Sun</last></author>
      <author><first>Guanying</first><last>Wang</last></author>
      <author><first>Xi</first><last>Chen</last></author>
      <author><first>Wei</first><last>Zhang</last></author>
      <author><first>Huajun</first><last>Chen</last></author>
      <pages>3016–3025</pages>
      <abstract>We propose a distance supervised relation extraction approach for long-tailed, imbalanced data which is prevalent in real-world settings. Here, the challenge is to learn accurate few-shot models for classes existing at the tail of the class distribution, for which little data is available. Inspired by the rich semantic correlations between classes at the long tail and those at the head, we take advantage of the knowledge from data-rich classes at the head of the distribution to boost the performance of the data-poor classes at the tail. First, we propose to leverage implicit relational knowledge among class labels from knowledge graph embeddings and learn explicit relational knowledge using graph convolution networks. Second, we integrate that <a href="https://en.wikipedia.org/wiki/Relational_model">relational knowledge</a> into relation extraction model by coarse-to-fine knowledge-aware attention mechanism. We demonstrate our results for a large-scale benchmark dataset which show that our approach significantly outperforms other <a href="https://en.wikipedia.org/wiki/Baseline_(medicine)">baselines</a>, especially for long-tail relations.</abstract>
      <url hash="c2a040bc">N19-1306</url>
      <doi>10.18653/v1/N19-1306</doi>
      <video href="https://vimeo.com/355830579" />
      <bibkey>zhang-etal-2019-long</bibkey>
    </paper>
    <paper id="309">
      <title>OpenCeres : When <a href="https://en.wikipedia.org/wiki/Open_information_extraction">Open Information Extraction</a> Meets the Semi-Structured Web<fixed-case>O</fixed-case>pen<fixed-case>C</fixed-case>eres: <fixed-case>W</fixed-case>hen Open Information Extraction Meets the Semi-Structured Web</title>
      <author><first>Colin</first><last>Lockard</last></author>
      <author><first>Prashant</first><last>Shiralkar</last></author>
      <author><first>Xin Luna</first><last>Dong</last></author>
      <pages>3047–3056</pages>
      <abstract>Open Information Extraction (OpenIE), the problem of harvesting triples from natural language text whose predicate relations are not aligned to any pre-defined ontology, has been a popular subject of research for the last decade. However, this research has largely ignored the vast quantity of facts available in semi-structured webpages. In this paper, we define the problem of OpenIE from <a href="https://en.wikipedia.org/wiki/Semi-structured_model">semi-structured websites</a> to extract such facts, and present an approach for solving it. We also introduce a labeled evaluation dataset to motivate research in this area. Given a semi-structured website and a set of seed facts for some relations existing on its pages, we employ a semi-supervised label propagation technique to automatically create <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training data</a> for the relations present on the site. We then use this <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training data</a> to learn a <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> for relation extraction. Experimental results of this method on our new benchmark dataset obtained a <a href="https://en.wikipedia.org/wiki/Precision_(statistics)">precision</a> of over 70 %. A larger scale extraction experiment on 31 websites in the movie vertical resulted in the extraction of over 2 million triples.</abstract>
      <url hash="eb5c2c10">N19-1309</url>
      <doi>10.18653/v1/N19-1309</doi>
      <video href="https://vimeo.com/355837778" />
      <bibkey>lockard-etal-2019-openceres</bibkey>
    </paper>
    <paper id="313">
      <title>Selective Attention for Context-aware Neural Machine Translation</title>
      <author><first>Sameen</first><last>Maruf</last></author>
      <author><first>André F. T.</first><last>Martins</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <pages>3092–3102</pages>
      <abstract>Despite the progress made in sentence-level NMT, current systems still fall short at achieving fluent, good quality translation for a full document. Recent works in context-aware NMT consider only a few previous sentences as context and may not scale to entire documents. To this end, we propose a novel and scalable top-down approach to hierarchical attention for context-aware NMT which uses sparse attention to selectively focus on relevant sentences in the document context and then attends to key words in those sentences. We also propose single-level attention approaches based on sentence or word-level information in the context. The document-level context representation, produced from these attention modules, is integrated into the encoder or decoder of the Transformer model depending on whether we use monolingual or bilingual context. Our experiments and evaluation on English-German datasets in different document MT settings show that our selective attention approach not only significantly outperforms context-agnostic baselines but also surpasses context-aware baselines in most cases.</abstract>
      <url hash="8ed8f169">N19-1313</url>
      <attachment type="presentation" hash="748838a0">N19-1313.Presentation.pdf</attachment>
      <doi>10.18653/v1/N19-1313</doi>
      <video href="https://vimeo.com/361725345" />
      <bibkey>maruf-etal-2019-selective</bibkey>
      <pwccode url="https://github.com/sameenmaruf/selective-attn" additional="false">sameenmaruf/selective-attn</pwccode>
    </paper>
    <paper id="315">
      <title>Accelerated Reinforcement Learning for Sentence Generation by Vocabulary Prediction</title>
      <author><first>Kazuma</first><last>Hashimoto</last></author>
      <author><first>Yoshimasa</first><last>Tsuruoka</last></author>
      <pages>3115–3125</pages>
      <abstract>A major obstacle in reinforcement learning-based sentence generation is the large action space whose size is equal to the vocabulary size of the target-side language. To improve the efficiency of <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>, we present a novel approach for reducing the action space based on dynamic vocabulary prediction. Our method first predicts a fixed-size small vocabulary for each input to generate its target sentence. The input-specific vocabularies are then used at supervised and reinforcement learning steps, and also at test time. In our experiments on six <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> and two image captioning datasets, our method achieves faster <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> (~2.7x faster) with less <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit">GPU memory</a> (~2.3x less) than the full-vocabulary counterpart. We also show that our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> more effectively receives rewards with fewer iterations of supervised pre-training.</abstract>
      <url hash="52189658">N19-1315</url>
      <attachment type="supplementary" hash="424339e5">N19-1315.Supplementary.pdf</attachment>
      <doi>10.18653/v1/N19-1315</doi>
      <video href="https://vimeo.com/356125366" />
      <bibkey>hashimoto-tsuruoka-2019-accelerated</bibkey>
      <pwccode url="https://github.com/hassyGo/NLG-RL" additional="false">hassyGo/NLG-RL</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/aspec">ASPEC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
    </paper>
    <paper id="316">
      <title>Mitigating Uncertainty in Document Classification</title>
      <author><first>Xuchao</first><last>Zhang</last></author>
      <author><first>Fanglan</first><last>Chen</last></author>
      <author><first>Chang-Tien</first><last>Lu</last></author>
      <author><first>Naren</first><last>Ramakrishnan</last></author>
      <pages>3126–3136</pages>
      <abstract>The uncertainty measurement of classifiers’ predictions is especially important in applications such as <a href="https://en.wikipedia.org/wiki/Medical_diagnosis">medical diagnoses</a> that need to ensure limited human resources can focus on the most uncertain predictions returned by <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning models</a>. However, few existing uncertainty models attempt to improve overall prediction accuracy where <a href="https://en.wikipedia.org/wiki/Human_resources">human resources</a> are involved in the text classification task. In this paper, we propose a novel neural-network-based model that applies a new dropout-entropy method for uncertainty measurement. We also design a metric learning method on <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">feature representations</a>, which can boost the performance of dropout-based uncertainty methods with smaller prediction variance in accurate prediction trials. Extensive experiments on real-world data sets demonstrate that our method can achieve a considerable improvement in overall prediction accuracy compared to existing approaches. In particular, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> improved the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> from 0.78 to 0.92 when 30 % of the most uncertain predictions were handed over to <a href="https://en.wikipedia.org/wiki/Expert_witness">human experts</a> in 20NewsGroup data.</abstract>
      <url hash="6cff087e">N19-1316</url>
      <doi>10.18653/v1/N19-1316</doi>
      <video href="https://vimeo.com/347415373" />
      <bibkey>zhang-etal-2019-mitigating</bibkey>
      <pwccode url="https://github.com/xuczhang/UncertainDC" additional="false">xuczhang/UncertainDC</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
    </paper>
    <paper id="322">
      <title>Customizing Grapheme-to-Phoneme System for Non-Trivial Transcription Problems in <a href="https://en.wikipedia.org/wiki/Bengali_language">Bangla Language</a><fixed-case>B</fixed-case>angla Language</title>
      <author><first>Sudipta Saha</first><last>Shubha</last></author>
      <author><first>Nafis</first><last>Sadeq</last></author>
      <author><first>Shafayat</first><last>Ahmed</last></author>
      <author><first>Md. Nahidul</first><last>Islam</last></author>
      <author><first>Muhammad Abdullah</first><last>Adnan</last></author>
      <author><first>Md. Yasin Ali</first><last>Khan</last></author>
      <author><first>Mohammad Zuberul</first><last>Islam</last></author>
      <pages>3191–3200</pages>
      <abstract>Grapheme to phoneme (G2P) conversion is an integral part in various text and speech processing systems, such as : <a href="https://en.wikipedia.org/wiki/Speech_synthesis">Text to Speech system</a>, <a href="https://en.wikipedia.org/wiki/Speech_recognition">Speech Recognition system</a>, etc. The existing <a href="https://en.wikipedia.org/wiki/Methodology">methodologies</a> for G2P conversion in <a href="https://en.wikipedia.org/wiki/Bengali_language">Bangla language</a> are mostly rule-based. However, data-driven approaches have proved their superiority over rule-based approaches for large-scale G2P conversion in other languages, such as : <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/German_language">German</a>, etc. As the performance of data-driven approaches for G2P conversion depend largely on pronunciation lexicon on which the system is trained, in this paper, we investigate on developing an improved training lexicon by identifying and categorizing the critical cases in <a href="https://en.wikipedia.org/wiki/Bengali_language">Bangla language</a> and include those critical cases in training lexicon for developing a robust G2P conversion system in <a href="https://en.wikipedia.org/wiki/Bengali_language">Bangla language</a>. Additionally, we have incorporated <a href="https://en.wikipedia.org/wiki/Nasal_vowel">nasal vowels</a> in our proposed phoneme list. Our <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> outperforms other state-of-the-art approaches for G2P conversion in <a href="https://en.wikipedia.org/wiki/Bengali_language">Bangla language</a>.</abstract>
      <url hash="0db769da">N19-1322</url>
      <doi>10.18653/v1/N19-1322</doi>
      <bibkey>shubha-etal-2019-customizing</bibkey>
    </paper>
    <paper id="325">
      <title>Exploiting Noisy Data in Distant Supervision Relation Classification</title>
      <author><first>Kaijia</first><last>Yang</last></author>
      <author><first>Liang</first><last>He</last></author>
      <author><first>Xin-yu</first><last>Dai</last></author>
      <author><first>Shujian</first><last>Huang</last></author>
      <author><first>Jiajun</first><last>Chen</last></author>
      <pages>3216–3225</pages>
      <abstract>Distant supervision has obtained great progress on relation classification task. However, <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> still suffers from noisy labeling problem. Different from previous works that underutilize <a href="https://en.wikipedia.org/wiki/Noisy_data">noisy data</a> which inherently characterize the property of classification, in this paper, we propose RCEND, a novel framework to enhance Relation Classification by Exploiting <a href="https://en.wikipedia.org/wiki/Noisy_data">Noisy Data</a>. First, an instance discriminator with <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> is designed to split the noisy data into correctly labeled data and incorrectly labeled data. Second, we learn a robust relation classifier in semi-supervised learning way, whereby the correctly and incorrectly labeled data are treated as labeled and unlabeled data respectively. The experimental results show that our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> outperforms the state-of-the-art models.</abstract>
      <url hash="d9decd35">N19-1325</url>
      <doi>10.18653/v1/N19-1325</doi>
      <bibkey>yang-etal-2019-exploiting</bibkey>
    </paper>
    <paper id="327">
      <title>Learning Relational Representations by Analogy using Hierarchical Siamese Networks<fixed-case>S</fixed-case>iamese Networks</title>
      <author><first>Gaetano</first><last>Rossiello</last></author>
      <author><first>Alfio</first><last>Gliozzo</last></author>
      <author><first>Robert</first><last>Farrell</last></author>
      <author><first>Nicolas</first><last>Fauceglia</last></author>
      <author><first>Michael</first><last>Glass</last></author>
      <pages>3235–3245</pages>
      <abstract>We address <a href="https://en.wikipedia.org/wiki/Relation_extraction">relation extraction</a> as an analogy problem by proposing a novel approach to learn representations of relations expressed by their textual mentions. In our assumption, if two pairs of entities belong to the same relation, then those two pairs are analogous. Following this idea, we collect a large set of analogous pairs by matching triples in <a href="https://en.wikipedia.org/wiki/Knowledge_base">knowledge bases</a> with web-scale corpora through distant supervision. We leverage this dataset to train a hierarchical siamese network in order to learn entity-entity embeddings which encode relational information through the different linguistic paraphrasing expressing the same relation. We evaluate our model in a one-shot learning task by showing a promising generalization capability in order to classify unseen relation types, which makes this approach suitable to perform automatic knowledge base population with minimal supervision. Moreover, the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> can be used to generate pre-trained embeddings which provide a valuable signal when integrated into an existing neural-based model by outperforming the state-of-the-art methods on a downstream relation extraction task.</abstract>
      <url hash="0a3d0f8b">N19-1327</url>
      <doi>10.18653/v1/N19-1327</doi>
      <bibkey>rossiello-etal-2019-learning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/t-rex">T-REx</pwcdataset>
    </paper>
    <paper id="328">
      <title>An Effective Label Noise Model for DNN Text Classification<fixed-case>DNN</fixed-case> Text Classification</title>
      <author><first>Ishan</first><last>Jindal</last></author>
      <author><first>Daniel</first><last>Pressel</last></author>
      <author><first>Brian</first><last>Lester</last></author>
      <author><first>Matthew</first><last>Nokleby</last></author>
      <pages>3246–3256</pages>
      <abstract>Because large, human-annotated datasets suffer from labeling errors, it is crucial to be able to train <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural networks</a> in the presence of label noise. While training <a href="https://en.wikipedia.org/wiki/Image_classification">image classification models</a> with label noise have received much attention, training <a href="https://en.wikipedia.org/wiki/Text_classification">text classification models</a> have not. In this paper, we propose an approach to training <a href="https://en.wikipedia.org/wiki/Deep_learning">deep networks</a> that is robust to label noise. This approach introduces a non-linear processing layer (noise model) that models the statistics of the label noise into a convolutional neural network (CNN) architecture. The noise model and the CNN weights are learned jointly from noisy training data, which prevents the <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> from overfitting to erroneous labels. Through extensive experiments on several text classification datasets, we show that this approach enables the CNN to learn better sentence representations and is robust even to extreme label noise. We find that proper initialization and <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">regularization</a> of this noise model is critical. Further, by contrast to results focusing on large batch sizes for mitigating label noise for image classification, we find that altering the batch size does not have much effect on <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> performance.</abstract>
      <url hash="95cbaa2f">N19-1328</url>
      <doi>10.18653/v1/N19-1328</doi>
      <bibkey>jindal-etal-2019-effective</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/ag-news">AG News</pwcdataset>
    </paper>
    <paper id="330">
      <title>Using Large Corpus N-gram Statistics to Improve Recurrent Neural Language Models</title>
      <author><first>Yiben</first><last>Yang</last></author>
      <author><first>Ji-Ping</first><last>Wang</last></author>
      <author><first>Doug</first><last>Downey</last></author>
      <pages>3268–3273</pages>
      <abstract>Recurrent neural network language models (RNNLM) form a valuable foundation for many NLP systems, but training the models can be computationally expensive, and may take days to train on a large corpus. We explore a technique that uses large corpus n-gram statistics as a regularizer for training a neural network LM on a smaller corpus. In experiments with the Billion-Word and Wikitext corpora, we show that the technique is effective, and more time-efficient than simply training on a larger sequential corpus. We also introduce new <a href="https://en.wikipedia.org/wiki/Strategy">strategies</a> for selecting the most informative n-grams, and show that these boost efficiency.</abstract>
      <url hash="15b9c7b7">N19-1330</url>
      <doi>10.18653/v1/N19-1330</doi>
      <bibkey>yang-etal-2019-using</bibkey>
    </paper>
    <paper id="332">
      <title>Relation Discovery with Out-of-Relation Knowledge Base as Supervision</title>
      <author><first>Yan</first><last>Liang</last></author>
      <author><first>Xin</first><last>Liu</last></author>
      <author><first>Jianwen</first><last>Zhang</last></author>
      <author><first>Yangqiu</first><last>Song</last></author>
      <pages>3280–3290</pages>
      <abstract>Unsupervised relation discovery aims to discover new relations from a given <a href="https://en.wikipedia.org/wiki/Text_corpus">text corpus</a> without <a href="https://en.wikipedia.org/wiki/Annotation">annotated data</a>. However, <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> does not consider existing human annotated knowledge bases even when they are relevant to the relations to be discovered. In this paper, we study the problem of how to use out-of-relation knowledge bases to supervise the discovery of unseen relations, where out-of-relation means that relations to discover from the <a href="https://en.wikipedia.org/wiki/Text_corpus">text corpus</a> and those in <a href="https://en.wikipedia.org/wiki/Knowledge_base">knowledge bases</a> are not overlapped. We construct a set of <a href="https://en.wikipedia.org/wiki/Constraint_(mathematics)">constraints</a> between entity pairs based on the knowledge base embedding and then incorporate <a href="https://en.wikipedia.org/wiki/Constraint_(mathematics)">constraints</a> into the relation discovery by a variational auto-encoder based algorithm. Experiments show that our new approach can improve the state-of-the-art relation discovery performance by a large margin.</abstract>
      <url hash="a2c17ef9">N19-1332</url>
      <doi>10.18653/v1/N19-1332</doi>
      <bibkey>liang-etal-2019-relation</bibkey>
      <pwccode url="https://github.com/HKUST-KnowComp/RE-RegDVAE" additional="false">HKUST-KnowComp/RE-RegDVAE</pwccode>
    </paper>
    <paper id="336">
      <title>Evaluating and Enhancing the Robustness of Dialogue Systems : A Case Study on a Negotiation Agent</title>
      <author><first>Minhao</first><last>Cheng</last></author>
      <author><first>Wei</first><last>Wei</last></author>
      <author><first>Cho-Jui</first><last>Hsieh</last></author>
      <pages>3325–3335</pages>
      <abstract>Recent research has demonstrated that goal-oriented dialogue agents trained on large datasets can achieve striking performance when interacting with human users. In real world applications, however, it is important to ensure that the <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agent</a> performs smoothly interacting with not only regular users but also those malicious ones who would attack the <a href="https://en.wikipedia.org/wiki/System">system</a> through interactions in order to achieve goals for their own advantage. In this paper, we develop <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> to evaluate the <a href="https://en.wikipedia.org/wiki/Robustness_(computer_science)">robustness</a> of a dialogue agent by carefully designed attacks using <a href="https://en.wikipedia.org/wiki/Adversarial_system">adversarial agents</a>. Those <a href="https://en.wikipedia.org/wiki/Attack_(computing)">attacks</a> are performed in both black-box and white-box settings. Furthermore, we demonstrate that adversarial training using our attacks can significantly improve the <a href="https://en.wikipedia.org/wiki/Robustness_(computer_science)">robustness</a> of a goal-oriented dialogue system. On a case-study of the negotiation agent developed by (Lewis et al., 2017), our attacks reduced the average advantage of rewards between the attacker and the trained RL-based agent from 2.68 to -5.76 on a scale from -10 to 10 for randomized goals. Moreover, we show that with the adversarial training, we are able to improve the <a href="https://en.wikipedia.org/wiki/Robustness_(computer_science)">robustness</a> of negotiation agents by 1.5 points on average against all our attacks.</abstract>
      <url hash="d173cd17">N19-1336</url>
      <doi>10.18653/v1/N19-1336</doi>
      <bibkey>cheng-etal-2019-evaluating</bibkey>
    </paper>
    <paper id="340">
      <title>Semantic Role Labeling with Associated Memory Network</title>
      <author><first>Chaoyu</first><last>Guan</last></author>
      <author><first>Yuhao</first><last>Cheng</last></author>
      <author><first>Hai</first><last>Zhao</last></author>
      <pages>3361–3371</pages>
      <abstract>Semantic role labeling (SRL) is a task to recognize all the predicate-argument pairs of a sentence, which has been in a performance improvement bottleneck after a series of latest works were presented. This paper proposes a novel syntax-agnostic SRL model enhanced by the proposed associated memory network (AMN), which makes use of inter-sentence attention of label-known associated sentences as a kind of <a href="https://en.wikipedia.org/wiki/Memory">memory</a> to further enhance dependency-based SRL. In detail, we use sentences and their labels from train dataset as an <a href="https://en.wikipedia.org/wiki/Association_(psychology)">associated memory cue</a> to help label the target sentence. Furthermore, we compare several associated sentences selecting strategies and label merging methods in AMN to find and utilize the label of associated sentences while attending them. By leveraging the attentive memory from known training data, Our full model reaches state-of-the-art on CoNLL-2009 benchmark datasets for syntax-agnostic setting, showing a new effective research line of SRL enhancement other than exploiting external resources such as well pre-trained language models.</abstract>
      <url hash="4cfef0cf">N19-1340</url>
      <doi>10.18653/v1/N19-1340</doi>
      <bibkey>guan-etal-2019-semantic</bibkey>
      <pwccode url="https://github.com/Frozenmad/AMN_SRL" additional="false">Frozenmad/AMN_SRL</pwccode>
    </paper>
    <paper id="341">
      <title>Better, Faster, Stronger Sequence Tagging Constituent Parsers</title>
      <author><first>David</first><last>Vilares</last></author>
      <author><first>Mostafa</first><last>Abdou</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>3372–3383</pages>
      <abstract>Sequence tagging models for constituent parsing are faster, but less accurate than other types of <a href="https://en.wikipedia.org/wiki/Parsing">parsers</a>. In this work, we address the following weaknesses of such constituent parsers : (a) high error rates around closing brackets of long constituents, (b) large label sets, leading to sparsity, and (c) error propagation arising from greedy decoding. To effectively close brackets, we train a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> that learns to switch between tagging schemes. To reduce sparsity, we decompose the label set and use <a href="https://en.wikipedia.org/wiki/Multi-task_learning">multi-task learning</a> to jointly learn to predict sublabels. Finally, we mitigate issues from greedy decoding through auxiliary losses and sentence-level fine-tuning with policy gradient. Combining these techniques, we clearly surpass the performance of sequence tagging constituent parsers on the English and Chinese Penn Treebanks, and reduce their parsing time even further. On the SPMRL datasets, we observe even greater improvements across the board, including a new state of the art on <a href="https://en.wikipedia.org/wiki/Basque_language">Basque</a>, <a href="https://en.wikipedia.org/wiki/Hebrew_language">Hebrew</a>, <a href="https://en.wikipedia.org/wiki/Polish_language">Polish</a> and <a href="https://en.wikipedia.org/wiki/Swedish_language">Swedish</a>.</abstract>
      <url hash="b153eb64">N19-1341</url>
      <doi>10.18653/v1/N19-1341</doi>
      <bibkey>vilares-etal-2019-better</bibkey>
      <pwccode url="https://github.com/aghie/tree2labels" additional="false">aghie/tree2labels</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="347">
      <title>Learning Hierarchical Discourse-level Structure for Fake News Detection</title>
      <author><first>Hamid</first><last>Karimi</last></author>
      <author><first>Jiliang</first><last>Tang</last></author>
      <pages>3432–3442</pages>
      <abstract>On the one hand, nowadays, <a href="https://en.wikipedia.org/wiki/Fake_news">fake news articles</a> are easily propagated through various online media platforms and have become a grand threat to the trustworthiness of information. On the other hand, our understanding of the language of fake news is still minimal. Incorporating hierarchical discourse-level structure of fake and real news articles is one crucial step toward a better understanding of how these <a href="https://en.wikipedia.org/wiki/Article_(publishing)">articles</a> are structured. Nevertheless, this has rarely been investigated in the fake news detection domain and faces tremendous challenges. First, existing methods for capturing discourse-level structure rely on annotated corpora which are not available for fake news datasets. Second, how to extract out useful information from such discovered <a href="https://en.wikipedia.org/wiki/Biomolecular_structure">structures</a> is another challenge. To address these challenges, we propose Hierarchical Discourse-level Structure for Fake news detection. HDSF learns and constructs a discourse-level structure for fake / real news articles in an automated and data-driven manner. Moreover, we identify insightful structure-related properties, which can explain the discovered structures and boost our understating of fake news. Conducted experiments show the effectiveness of the proposed approach. Further structural analysis suggests that real and fake news present substantial differences in the hierarchical discourse-level structures.</abstract>
      <url hash="0c5b45a3">N19-1347</url>
      <doi>10.18653/v1/N19-1347</doi>
      <bibkey>karimi-tang-2019-learning</bibkey>
      <pwccode url="https://github.com/hamidkarimi/HDSF" additional="true">hamidkarimi/HDSF</pwccode>
    </paper>
    <paper id="357">
      <title>Attention is not Explanation<fixed-case>A</fixed-case>ttention is not <fixed-case>E</fixed-case>xplanation</title>
      <author><first>Sarthak</first><last>Jain</last></author>
      <author><first>Byron C.</first><last>Wallace</last></author>
      <pages>3543–3556</pages>
      <abstract>Attention mechanisms have seen wide adoption in neural NLP models. In addition to improving predictive performance, these are often touted as affording transparency : models equipped with <a href="https://en.wikipedia.org/wiki/Attention">attention</a> provide a distribution over attended-to input units, and this is often presented (at least implicitly) as communicating the relative importance of inputs. However, it is unclear what relationship exists between attention weights and model outputs. In this work we perform extensive experiments across a variety of <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP tasks</a> that aim to assess the degree to which attention weights provide meaningful explanations for predictions. We find that they largely do not. For example, learned attention weights are frequently uncorrelated with gradient-based measures of feature importance, and one can identify very different attention distributions that nonetheless yield equivalent predictions. Our findings show that standard <a href="https://en.wikipedia.org/wiki/Attentional_control">attention modules</a> do not provide meaningful explanations and should not be treated as though they do.</abstract>
      <url hash="7dd3a9ed">N19-1357</url>
      <doi>10.18653/v1/N19-1357</doi>
      <video href="https://vimeo.com/359703968" />
      <bibkey>jain-wallace-2019-attention</bibkey>
      <pwccode url="https://github.com/successar/AttentionExplanation" additional="true">successar/AttentionExplanation</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/ag-news">AG News</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/babi-1">bAbI</pwcdataset>
    </paper>
    <paper id="358">
      <title>Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning</title>
      <author><first>Prithviraj</first><last>Ammanabrolu</last></author>
      <author><first>Mark</first><last>Riedl</last></author>
      <pages>3557–3565</pages>
      <abstract>Text-based adventure games provide a platform on which to explore <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> in the context of a combinatorial action space, such as <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language</a>. We present a deep reinforcement learning architecture that represents the game state as a <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graph</a> which is learned during exploration. This <a href="https://en.wikipedia.org/wiki/Graph_of_a_function">graph</a> is used to prune the action space, enabling more efficient <a href="https://en.wikipedia.org/wiki/Exploration">exploration</a>. The question of which action to take can be reduced to a question-answering task, a form of <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> that pre-trains certain parts of our <a href="https://en.wikipedia.org/wiki/Architecture">architecture</a>. In experiments using the TextWorld framework, we show that our proposed technique can learn a control policy faster than baseline alternatives. We have also open-sourced our code at https://github.com/rajammanabrolu/KG-DQN.</abstract>
      <url hash="18451cc6">N19-1358</url>
      <doi>10.18653/v1/N19-1358</doi>
      <video href="https://vimeo.com/359702665" />
      <bibkey>ammanabrolu-riedl-2019-playing</bibkey>
      <pwccode url="https://github.com/rajammanabrolu/KG-DQN" additional="true">rajammanabrolu/KG-DQN</pwccode>
    </paper>
    <paper id="360">
      <title>Context Dependent Semantic Parsing over Temporally Structured Data</title>
      <author><first>Charles</first><last>Chen</last></author>
      <author><first>Razvan</first><last>Bunescu</last></author>
      <pages>3576–3585</pages>
      <abstract>We describe a new semantic parsing setting that allows users to query the system using both natural language questions and actions within a <a href="https://en.wikipedia.org/wiki/Graphical_user_interface">graphical user interface</a>. Multiple <a href="https://en.wikipedia.org/wiki/Time_series">time series</a> belonging to an entity of interest are stored in a database and the user interacts with the system to obtain a better understanding of the entity’s state and behavior, entailing sequences of actions and questions whose answers may depend on previous factual or navigational interactions. We design an LSTM-based encoder-decoder architecture that models context dependency through copying mechanisms and multiple levels of attention over inputs and previous outputs. When trained to predict tokens using <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>, the proposed <a href="https://en.wikipedia.org/wiki/Computer_architecture">architecture</a> substantially outperforms standard sequence generation baselines. Training the <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> using policy gradient leads to further improvements in performance, reaching a <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">sequence-level accuracy</a> of 88.7 % on artificial data and 74.8 % on real data.</abstract>
      <url hash="e624e949">N19-1360</url>
      <attachment type="supplementary" hash="eceb76bb">N19-1360.Supplementary.pdf</attachment>
      <doi>10.18653/v1/N19-1360</doi>
      <video href="https://vimeo.com/359699975" />
      <bibkey>chen-bunescu-2019-context</bibkey>
    </paper>
    <paper id="362">
      <title>pair2vec : Compositional Word-Pair Embeddings for Cross-Sentence Inference</title>
      <author><first>Mandar</first><last>Joshi</last></author>
      <author><first>Eunsol</first><last>Choi</last></author>
      <author><first>Omer</first><last>Levy</last></author>
      <author><first>Daniel</first><last>Weld</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <pages>3597–3608</pages>
      <abstract>Reasoning about implied relationships (e.g. paraphrastic, <a href="https://en.wikipedia.org/wiki/Common_sense">common sense</a>, encyclopedic) between pairs of words is crucial for many cross-sentence inference problems. This paper proposes new methods for learning and using embeddings of word pairs that implicitly represent background knowledge about such relationships. Our pairwise embeddings are computed as a compositional function of each word’s representation, which is learned by maximizing the pointwise mutual information (PMI) with the contexts in which the the two words co-occur. We add these <a href="https://en.wikipedia.org/wiki/Representation_(mathematics)">representations</a> to the cross-sentence attention layer of existing <a href="https://en.wikipedia.org/wiki/Statistical_inference">inference models</a> (e.g. BiDAF for <a href="https://en.wikipedia.org/wiki/Quality_assurance">QA</a>, ESIM for NLI), instead of extending or replacing existing <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>. Experiments show a gain of 2.7 % on the recently released SQuAD 2.0 and 1.3 % on MultiNLI. Our representations also aid in better generalization with gains of around 6-7 % on adversarial SQuAD datasets, and 8.8 % on the adversarial entailment test set by Glockner et al.</abstract>
      <url hash="a34e3b80">N19-1362</url>
      <doi>10.18653/v1/N19-1362</doi>
      <video href="https://vimeo.com/356133444" />
      <bibkey>joshi-etal-2019-pair2vec</bibkey>
      <pwccode url="https://github.com/mandarjoshi90/pair2vec" additional="true">mandarjoshi90/pair2vec</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="364">
      <title>Let’s Make Your Request More Persuasive : Modeling Persuasive Strategies via Semi-Supervised Neural Nets on Crowdfunding Platforms</title>
      <author><first>Diyi</first><last>Yang</last></author>
      <author><first>Jiaao</first><last>Chen</last></author>
      <author><first>Zichao</first><last>Yang</last></author>
      <author><first>Dan</first><last>Jurafsky</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <pages>3620–3630</pages>
      <abstract>Modeling what makes a request persuasive-eliciting the desired response from a reader-is critical to the study of <a href="https://en.wikipedia.org/wiki/Propaganda">propaganda</a>, <a href="https://en.wikipedia.org/wiki/Behavioral_economics">behavioral economics</a>, and <a href="https://en.wikipedia.org/wiki/Advertising">advertising</a>. Yet current <a href="https://en.wikipedia.org/wiki/Scientific_modelling">models</a> ca n’t quantify the persuasiveness of requests or extract successful persuasive strategies. Building on theories of <a href="https://en.wikipedia.org/wiki/Persuasion">persuasion</a>, we propose a <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> to quantify persuasiveness and identify the persuasive strategies in advocacy requests. Our semi-supervised hierarchical neural network model is supervised by the number of people persuaded to take actions and partially supervised at the sentence level with human-labeled rhetorical strategies. Our method outperforms several baselines, uncovers persuasive strategies-offering increased interpretability of persuasive speech-and has applications for other situations with document-level supervision but only partial sentence supervision.</abstract>
      <url hash="bbd0c86f">N19-1364</url>
      <doi>10.18653/v1/N19-1364</doi>
      <video href="https://vimeo.com/356153695" />
      <bibkey>yang-etal-2019-lets</bibkey>
    </paper>
    <paper id="365">
      <title>Recursive Routing Networks : Learning to Compose Modules for Language Understanding</title>
      <author><first>Ignacio</first><last>Cases</last></author>
      <author><first>Clemens</first><last>Rosenbaum</last></author>
      <author><first>Matthew</first><last>Riemer</last></author>
      <author><first>Atticus</first><last>Geiger</last></author>
      <author><first>Tim</first><last>Klinger</last></author>
      <author><first>Alex</first><last>Tamkin</last></author>
      <author><first>Olivia</first><last>Li</last></author>
      <author><first>Sandhini</first><last>Agarwal</last></author>
      <author><first>Joshua D.</first><last>Greene</last></author>
      <author><first>Dan</first><last>Jurafsky</last></author>
      <author><first>Christopher</first><last>Potts</last></author>
      <author><first>Lauri</first><last>Karttunen</last></author>
      <pages>3631–3648</pages>
      <abstract>We introduce Recursive Routing Networks (RRNs), which are modular, adaptable models that learn effectively in diverse environments. RRNs consist of a set of <a href="https://en.wikipedia.org/wiki/Subroutine">functions</a>, typically organized into a <a href="https://en.wikipedia.org/wiki/Grid_(spatial_index)">grid</a>, and a meta-learner decision-making component called the <a href="https://en.wikipedia.org/wiki/Router_(computing)">router</a>. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> jointly optimizes the parameters of the <a href="https://en.wikipedia.org/wiki/Function_(mathematics)">functions</a> and the meta-learner’s policy for routing inputs through those <a href="https://en.wikipedia.org/wiki/Function_(mathematics)">functions</a>. RRNs can be incorporated into existing architectures in a number of ways ; we explore adding them to word representation layers, recurrent network hidden layers, and classifier layers. Our evaluation task is natural language inference (NLI). Using the MultiNLI corpus, we show that an RRN’s routing decisions reflect the high-level genre structure of that <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>. To show that RRNs can learn to specialize to more fine-grained semantic distinctions, we introduce a new corpus of NLI examples involving implicative predicates, and show that the model components become fine-tuned to the inferential signatures that are characteristic of these <a href="https://en.wikipedia.org/wiki/Predicate_(grammar)">predicates</a>.</abstract>
      <url hash="389a34ed">N19-1365</url>
      <doi>10.18653/v1/N19-1365</doi>
      <video href="https://vimeo.com/356167288" />
      <bibkey>cases-etal-2019-recursive</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
    </paper>
    <paper id="366">
      <title>Structural Neural Encoders for AMR-to-text Generation<fixed-case>AMR</fixed-case>-to-text Generation</title>
      <author><first>Marco</first><last>Damonte</last></author>
      <author><first>Shay B.</first><last>Cohen</last></author>
      <pages>3649–3658</pages>
      <abstract>AMR-to-text generation is a problem recently introduced to the NLP community, in which the goal is to generate sentences from Abstract Meaning Representation (AMR) graphs. Sequence-to-sequence models can be used to this end by converting the AMR graphs to strings. Approaching the problem while working directly with <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graphs</a> requires the use of graph-to-sequence models that encode the AMR graph into a <a href="https://en.wikipedia.org/wiki/Vector_graphics">vector representation</a>. Such <a href="https://en.wikipedia.org/wiki/Code">encoding</a> has been shown to be beneficial in the past, and unlike sequential encoding, it allows us to explicitly capture reentrant structures in the AMR graphs. We investigate the extent to which <a href="https://en.wikipedia.org/wiki/Reentrancy_(computing)">reentrancies</a> (nodes with multiple parents) have an impact on AMR-to-text generation by comparing graph encoders to tree encoders, where <a href="https://en.wikipedia.org/wiki/Reentrancy_(computing)">reentrancies</a> are not preserved. We show that improvements in the treatment of reentrancies and <a href="https://en.wikipedia.org/wiki/Long-range_dependence">long-range dependencies</a> contribute to higher overall scores for graph encoders. Our best <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves 24.40 BLEU on LDC2015E86, outperforming the state of the art by 1.1 points and 24.54 BLEU on LDC2017T10, outperforming the <a href="https://en.wikipedia.org/wiki/State_(computer_science)">state</a> of the art by 1.24 points.</abstract>
      <url hash="818d9d96">N19-1366</url>
      <attachment type="presentation" hash="d4183ec4">N19-1366.Presentation.pdf</attachment>
      <doi>10.18653/v1/N19-1366</doi>
      <video href="https://vimeo.com/356184145" />
      <bibkey>damonte-cohen-2019-structural</bibkey>
      <pwccode url="https://github.com/mdtux89/OpenNMT-py-AMR-to-text" additional="true">mdtux89/OpenNMT-py-AMR-to-text</pwccode>
    </paper>
    <paper id="378">
      <title>What do Entity-Centric Models Learn? Insights from Entity Linking in Multi-Party Dialogue</title>
      <author><first>Laura</first><last>Aina</last></author>
      <author><first>Carina</first><last>Silberer</last></author>
      <author><first>Ionut-Teodor</first><last>Sorodoc</last></author>
      <author><first>Matthijs</first><last>Westera</last></author>
      <author><first>Gemma</first><last>Boleda</last></author>
      <pages>3772–3783</pages>
      <abstract>Humans use <a href="https://en.wikipedia.org/wiki/Language">language</a> to refer to entities in the external world. Motivated by this, in recent years several <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> that incorporate a bias towards learning entity representations have been proposed. Such entity-centric models have shown empirical success, but we still know little about why. In this paper we analyze the behavior of two recently proposed entity-centric models in a referential task, Entity Linking in Multi-party Dialogue (SemEval 2018 Task 4). We show that these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> outperform the state of the art on this task, and that they do better on lower frequency entities than a counterpart model that is not entity-centric, with the same model size. We argue that making models entity-centric naturally fosters good architectural decisions. However, we also show that these <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> do not really build entity representations and that they make poor use of <a href="https://en.wikipedia.org/wiki/Context_(language_use)">linguistic context</a>. These negative results underscore the need for model analysis, to test whether the motivations for particular <a href="https://en.wikipedia.org/wiki/Software_architecture">architectures</a> are borne out in how <a href="https://en.wikipedia.org/wiki/Computer_simulation">models</a> behave when deployed.</abstract>
      <url hash="6e993e6d">N19-1378</url>
      <doi>10.18653/v1/N19-1378</doi>
      <bibkey>aina-etal-2019-entity</bibkey>
      <pwccode url="https://github.com/amore-upf/analysis-entity-centric-nns" additional="false">amore-upf/analysis-entity-centric-nns</pwccode>
    </paper>
    <paper id="380">
      <title>Cross-lingual Transfer Learning for Multilingual Task Oriented Dialog</title>
      <author><first>Sebastian</first><last>Schuster</last></author>
      <author><first>Sonal</first><last>Gupta</last></author>
      <author><first>Rushin</first><last>Shah</last></author>
      <author><first>Mike</first><last>Lewis</last></author>
      <pages>3795–3805</pages>
      <abstract>One of the first steps in the utterance interpretation pipeline of many task-oriented conversational AI systems is to identify user intents and the corresponding slots. Since data collection for <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning models</a> for this task is time-consuming, it is desirable to make use of existing <a href="https://en.wikipedia.org/wiki/Data">data</a> in a high-resource language to train models in low-resource languages. However, development of such <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> has largely been hindered by the lack of multilingual training data. In this paper, we present a new <a href="https://en.wikipedia.org/wiki/Data_set">data set</a> of 57k annotated utterances in <a href="https://en.wikipedia.org/wiki/English_language">English</a> (43k), <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a> (8.6k) and <a href="https://en.wikipedia.org/wiki/Thai_language">Thai</a> (5k) across the domains weather, alarm, and reminder. We use this data set to evaluate three different cross-lingual transfer methods : (1) translating the training data, (2) using cross-lingual pre-trained embeddings, and (3) a novel method of using a multilingual machine translation encoder as contextual word representations. We find that given several hundred training examples in the the target language, the latter two methods outperform translating the training data. Further, in very low-resource settings, multilingual contextual word representations give better results than using cross-lingual static embeddings. We also compare the cross-lingual methods to using monolingual resources in the form of contextual ELMo representations and find that given just small amounts of target language data, this method outperforms all cross-lingual methods, which highlights the need for more sophisticated cross-lingual methods.</abstract>
      <url hash="9b54b462">N19-1380</url>
      <doi>10.18653/v1/N19-1380</doi>
      <bibkey>schuster-etal-2019-cross-lingual</bibkey>
    </paper>
    <paper id="381">
      <title>Evaluating Coherence in <a href="https://en.wikipedia.org/wiki/Dialogue_system">Dialogue Systems</a> using Entailment</title>
      <author><first>Nouha</first><last>Dziri</last></author>
      <author><first>Ehsan</first><last>Kamalloo</last></author>
      <author><first>Kory</first><last>Mathewson</last></author>
      <author><first>Osmar</first><last>Zaiane</last></author>
      <pages>3806–3812</pages>
      <abstract>Evaluating open-domain dialogue systems is difficult due to the diversity of possible correct answers. Automatic metrics such as <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a> correlate weakly with human annotations, resulting in a significant bias across different models and datasets. Some researchers resort to human judgment experimentation for assessing response quality, which is expensive, time consuming, and not scalable. Moreover, judges tend to evaluate a small number of dialogues, meaning that minor differences in evaluation configuration may lead to dissimilar results. In this paper, we present interpretable metrics for evaluating topic coherence by making use of distributed sentence representations. Furthermore, we introduce calculable approximations of <a href="https://en.wikipedia.org/wiki/Judgement">human judgment</a> based on conversational coherence by adopting state-of-the-art entailment techniques. Results show that our <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> can be used as a surrogate for human judgment, making it easy to evaluate dialogue systems on large-scale datasets and allowing an unbiased estimate for the quality of the responses.</abstract>
      <url hash="4c1e491b">N19-1381</url>
      <doi>10.18653/v1/N19-1381</doi>
      <bibkey>dziri-etal-2019-evaluating</bibkey>
      <pwccode url="https://github.com/nouhadziri/DialogEntailment" additional="false">nouhadziri/DialogEntailment</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/persona-chat-1">PERSONA-CHAT</pwcdataset>
    </paper>
    <paper id="382">
      <title>On Knowledge distillation from <a href="https://en.wikipedia.org/wiki/Complex_network">complex networks</a> for response prediction</title>
      <author><first>Siddhartha</first><last>Arora</last></author>
      <author><first>Mitesh M.</first><last>Khapra</last></author>
      <author><first>Harish G.</first><last>Ramaswamy</last></author>
      <pages>3813–3822</pages>
      <abstract>Recent advances in <a href="https://en.wikipedia.org/wiki/Question_answering">Question Answering</a> have lead to the development of very complex models which compute rich representations for query and documents by capturing all pairwise interactions between query and document words. This makes these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> expensive in space and time, and in practice one has to restrict the length of the documents that can be fed to these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>. Such <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> have also been recently employed for the task of predicting dialog responses from available background documents (e.g., Holl-E dataset). However, here the documents are longer, thereby rendering these complex models infeasible except in select restricted settings. In order to overcome this, we use standard simple models which do not capture all pairwise interactions, but learn to emulate certain characteristics of a complex teacher network. Specifically, we first investigate the conicity of representations learned by a complex model and observe that it is significantly lower than that of simpler models. Based on this insight, we modify the simple architecture to mimic this <a href="https://en.wikipedia.org/wiki/Property_(philosophy)">characteristic</a>. We go further by using knowledge distillation approaches, where the simple model acts as a student and learns to match the output from the complex teacher network. We experiment with the Holl-E dialog data set and show that by mimicking characteristics and matching outputs from a teacher, even a simple network can give improved performance.</abstract>
      <url hash="c9f6f761">N19-1382</url>
      <doi>10.18653/v1/N19-1382</doi>
      <bibkey>arora-etal-2019-knowledge</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/holl-e">Holl-E</pwcdataset>
    </paper>
    <paper id="384">
      <title>Unsupervised Extraction of Partial Translations for <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a></title>
      <author><first>Benjamin</first><last>Marie</last></author>
      <author><first>Atsushi</first><last>Fujita</last></author>
      <pages>3834–3844</pages>
      <abstract>In neural machine translation (NMT), monolingual data are usually exploited through a so-called <a href="https://en.wikipedia.org/wiki/Back-translation">back-translation</a> : sentences in the target language are translated into the source language to synthesize new parallel data. While this method provides more training data to better model the target language, on the source side, it only exploits translations that the NMT system is already able to generate using a <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> trained on existing parallel data. In this work, we assume that new translation knowledge can be extracted from <a href="https://en.wikipedia.org/wiki/Monolingualism">monolingual data</a>, without relying at all on existing parallel data. We propose a new <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> for extracting from monolingual data what we call partial translations : pairs of source and target sentences that contain sequences of tokens that are translations of each other. Our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> is fully unsupervised and takes only source and target monolingual data as input. Our empirical evaluation points out that our partial translations can be used in combination with <a href="https://en.wikipedia.org/wiki/Back-translation">back-translation</a> to further improve NMT models. Furthermore, while partial translations are particularly useful for low-resource language pairs, they can also be successfully exploited in resource-rich scenarios to improve translation quality.</abstract>
      <url hash="aff0964b">N19-1384</url>
      <doi>10.18653/v1/N19-1384</doi>
      <bibkey>marie-fujita-2019-unsupervised</bibkey>
    </paper>
    <paper id="385">
      <title>Low-Resource Syntactic Transfer with Unsupervised Source Reordering</title>
      <author><first>Mohammad Sadegh</first><last>Rasooli</last></author>
      <author><first>Michael</first><last>Collins</last></author>
      <pages>3845–3856</pages>
      <abstract>We describe a cross-lingual transfer method for dependency parsing that takes into account the problem of word order differences between source and target languages. Our model only relies on the <a href="https://en.wikipedia.org/wiki/Bible">Bible</a>, a considerably smaller parallel data than the commonly used parallel data in transfer methods. We use the concatenation of projected trees from the <a href="https://en.wikipedia.org/wiki/Text_corpus">Bible corpus</a>, and the gold-standard treebanks in multiple source languages along with cross-lingual word representations. We demonstrate that reordering the source treebanks before training on them for a target language improves the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of languages outside the <a href="https://en.wikipedia.org/wiki/Languages_of_Europe">European language family</a>. Our experiments on 68 treebanks (38 languages) in the Universal Dependencies corpus achieve a high <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> for all languages. Among them, our experiments on 16 <a href="https://en.wikipedia.org/wiki/Treebank">treebanks</a> of 12 <a href="https://en.wikipedia.org/wiki/Languages_of_Europe">non-European languages</a> achieve an average UAS absolute improvement of 3.3 % over a <a href="https://en.wikipedia.org/wiki/State-of-the-art">state-of-the-art method</a>.</abstract>
      <url hash="d422a050">N19-1385</url>
      <doi>10.18653/v1/N19-1385</doi>
      <bibkey>rasooli-collins-2019-low</bibkey>
    </paper>
    <paper id="388">
      <title>Massively Multilingual Neural Machine Translation</title>
      <author><first>Roee</first><last>Aharoni</last></author>
      <author><first>Melvin</first><last>Johnson</last></author>
      <author><first>Orhan</first><last>Firat</last></author>
      <pages>3874–3884</pages>
      <abstract>Multilingual Neural Machine Translation enables training a single model that supports <a href="https://en.wikipedia.org/wiki/Translation">translation</a> from multiple source languages into multiple target languages. We perform extensive experiments in training massively multilingual NMT models, involving up to 103 distinct languages and 204 translation directions simultaneously. We explore different setups for training such <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> and analyze the trade-offs between translation quality and various modeling decisions. We report results on the publicly available TED talks multilingual corpus where we show that massively multilingual many-to-many models are effective in low resource settings, outperforming the previous state-of-the-art while supporting up to 59 languages in 116 translation directions in a single model. Our experiments on a large-scale dataset with 103 languages, 204 trained directions and up to one million examples per direction also show promising results, surpassing strong bilingual baselines and encouraging future work on massively multilingual NMT.</abstract>
      <url hash="7a9386fa">N19-1388</url>
      <doi>10.18653/v1/N19-1388</doi>
      <bibkey>aharoni-etal-2019-massively</bibkey>
    </paper>
    <paper id="390">
      <title>Combining Discourse Markers and Cross-lingual Embeddings for SynonymAntonym Classification</title>
      <author><first>Michael</first><last>Roth</last></author>
      <author><first>Shyam</first><last>Upadhyay</last></author>
      <pages>3899–3905</pages>
      <abstract>It is well-known that distributional semantic approaches have difficulty in distinguishing between <a href="https://en.wikipedia.org/wiki/Synonym">synonyms</a> and <a href="https://en.wikipedia.org/wiki/Opposite_(semantics)">antonyms</a> (Grefenstette, 1992 ; Pad and Lapata, 2003). Recent work has shown that supervision available in <a href="https://en.wikipedia.org/wiki/English_language">English</a> for this <a href="https://en.wikipedia.org/wiki/Task_force">task</a> (e.g., lexical resources) can be transferred to other languages via cross-lingual word embeddings. However, this kind of transfer misses monolingual distributional information available in a target language, such as <a href="https://en.wikipedia.org/wiki/Contrast_(linguistics)">contrast relations</a> that are indicative of <a href="https://en.wikipedia.org/wiki/Opposite_(semantics)">antonymy</a> (e.g. hot... while... cold). In this work, we improve the transfer by exploiting <a href="https://en.wikipedia.org/wiki/Monolingualism">monolingual information</a>, expressed in the form of co-occurrences with <a href="https://en.wikipedia.org/wiki/Discourse_marker">discourse markers</a> that convey contrast. Our approach makes use of less than a dozen <a href="https://en.wikipedia.org/wiki/Marker_(linguistics)">markers</a>, which can easily be obtained for many languages. Compared to a baseline using only cross-lingual embeddings, we show absolute improvements of 410 % F1-score in <a href="https://en.wikipedia.org/wiki/Vietnamese_language">Vietnamese</a> and <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a>.</abstract>
      <url hash="6223e2a0">N19-1390</url>
      <doi>10.18653/v1/N19-1390</doi>
      <bibkey>roth-upadhyay-2019-combining</bibkey>
    </paper>
    <paper id="391">
      <title>Context-Aware Cross-Lingual Mapping</title>
      <author><first>Hanan</first><last>Aldarmaki</last></author>
      <author><first>Mona</first><last>Diab</last></author>
      <pages>3906–3911</pages>
      <abstract>Cross-lingual word vectors are typically obtained by fitting an <a href="https://en.wikipedia.org/wiki/Orthogonal_matrix">orthogonal matrix</a> that maps the entries of a <a href="https://en.wikipedia.org/wiki/Bilingual_dictionary">bilingual dictionary</a> from a source to a target vector space. Word vectors, however, are most commonly used for sentence or document-level representations that are calculated as the weighted average of word embeddings. In this paper, we propose an alternative to word-level mapping that better reflects sentence-level cross-lingual similarity. We incorporate <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context</a> in the <a href="https://en.wikipedia.org/wiki/Transformation_matrix">transformation matrix</a> by directly mapping the averaged embeddings of aligned sentences in a <a href="https://en.wikipedia.org/wiki/Parallel_text">parallel corpus</a>. We also implement cross-lingual mapping of deep contextualized word embeddings using parallel sentences with word alignments. In our experiments, both approaches resulted in cross-lingual sentence embeddings that outperformed context-independent word mapping in sentence translation retrieval. Furthermore, the sentence-level transformation could be used for word-level mapping without loss in word translation quality.</abstract>
      <url hash="b5ff30ec">N19-1391</url>
      <doi>10.18653/v1/N19-1391</doi>
      <bibkey>aldarmaki-diab-2019-context</bibkey>
      <pwccode url="https://github.com/h-aldarmaki/sent_translation_retrieval" additional="false">h-aldarmaki/sent_translation_retrieval</pwccode>
    </paper>
    <paper id="394">
      <title>Recommendations for Datasets for Source Code Summarization</title>
      <author><first>Alexander</first><last>LeClair</last></author>
      <author><first>Collin</first><last>McMillan</last></author>
      <pages>3931–3937</pages>
      <abstract>Source Code Summarization is the task of writing short, natural language descriptions of source code. The main use for these descriptions is in <a href="https://en.wikipedia.org/wiki/Software_documentation">software documentation</a> e.g. the one-sentence Java method descriptions in JavaDocs. Code summarization is rapidly becoming a popular research problem, but progress is restrained due to a lack of suitable datasets. In addition, a lack of community standards for creating datasets leads to confusing and unreproducible research results   we observe swings in performance of more than 33 % due only to changes in dataset design. In this paper, we make recommendations for these standards from experimental results. We release a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> based on prior work of over 2.1 m pairs of Java methods and one sentence method descriptions from over 28k Java projects. We describe the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and point out key differences from <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language data</a>, to guide and support future researchers.</abstract>
      <url hash="55cc59e6">N19-1394</url>
      <doi>10.18653/v1/N19-1394</doi>
      <bibkey>leclair-mcmillan-2019-recommendations</bibkey>
      <pwccode url="" additional="true" />
      <pwcdataset url="https://paperswithcode.com/dataset/funcom">Funcom</pwcdataset>
    </paper>
    <paper id="396">
      <title>Understanding the Behaviour of Neural Abstractive Summarizers using Contrastive Examples<fixed-case>U</fixed-case>nderstanding the <fixed-case>B</fixed-case>ehaviour of <fixed-case>N</fixed-case>eural <fixed-case>A</fixed-case>bstractive <fixed-case>S</fixed-case>ummarizers using <fixed-case>C</fixed-case>ontrastive <fixed-case>E</fixed-case>xamples</title>
      <author><first>Krtin</first><last>Kumar</last></author>
      <author><first>Jackie Chi Kit</first><last>Cheung</last></author>
      <pages>3949–3954</pages>
      <abstract>Neural abstractive summarizers generate summary texts using a <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> conditioned on the input source text, and have recently achieved high ROUGE scores on benchmark summarization datasets. We investigate how they achieve this performance with respect to human-written gold-standard abstracts, and whether the systems are able to understand deeper syntactic and semantic structures. We generate a set of contrastive summaries which are perturbed, deficient versions of human-written summaries, and test whether existing neural summarizers score them more highly than the human-written summaries. We analyze their performance on different datasets and find that these <a href="https://en.wikipedia.org/wiki/System">systems</a> fail to understand the source text, in a majority of the cases.</abstract>
      <url hash="8b2a5350">N19-1396</url>
      <doi>10.18653/v1/N19-1396</doi>
      <bibkey>kumar-cheung-2019-understanding</bibkey>
    </paper>
    <paper id="401">
      <title>Positional Encoding to Control Output Sequence Length</title>
      <author><first>Sho</first><last>Takase</last></author>
      <author><first>Naoaki</first><last>Okazaki</last></author>
      <pages>3999–4004</pages>
      <abstract>Neural encoder-decoder models have been successful in <a href="https://en.wikipedia.org/wiki/Natural-language_generation">natural language generation tasks</a>. However, real applications of abstractive summarization must consider an additional constraint that a generated summary should not exceed a desired length. In this paper, we propose a simple but effective extension of a sinusoidal positional encoding (Vaswani et al., 2017) so that a neural encoder-decoder model preserves the length constraint. Unlike previous studies that learn length embeddings, the proposed method can generate a text of any length even if the target length is unseen in training data. The experimental results show that the proposed <a href="https://en.wikipedia.org/wiki/Methodology">method</a> is able not only to control generation length but also improve ROUGE scores.</abstract>
      <url hash="6ed95c97">N19-1401</url>
      <doi>10.18653/v1/N19-1401</doi>
      <bibkey>takase-okazaki-2019-positional</bibkey>
      <pwccode url="https://github.com/takase/control-length" additional="false">takase/control-length</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/duc-2004">DUC 2004</pwcdataset>
    </paper>
    <paper id="404">
      <title>Saliency Learning : Teaching the Model Where to Pay Attention<fixed-case>S</fixed-case>aliency <fixed-case>L</fixed-case>earning: <fixed-case>T</fixed-case>eaching the <fixed-case>M</fixed-case>odel <fixed-case>W</fixed-case>here to <fixed-case>P</fixed-case>ay <fixed-case>A</fixed-case>ttention</title>
      <author><first>Reza</first><last>Ghaeini</last></author>
      <author><first>Xiaoli</first><last>Fern</last></author>
      <author><first>Hamed</first><last>Shahbazi</last></author>
      <author><first>Prasad</first><last>Tadepalli</last></author>
      <pages>4016–4025</pages>
      <abstract>Deep learning has emerged as a compelling solution to many NLP tasks with remarkable performances. However, due to their opacity, such <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> are hard to interpret and trust. Recent work on explaining deep models has introduced approaches to provide insights toward the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>’s behaviour and predictions, which are helpful for assessing the reliability of the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>’s predictions. However, such methods do not improve the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model’s reliability</a>. In this paper, we aim to teach the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> to make the right prediction for the right reason by providing explanation training and ensuring the alignment of the model’s explanation with the ground truth explanation. Our experimental results on multiple tasks and datasets demonstrate the effectiveness of the proposed method, which produces more reliable predictions while delivering better results compared to traditionally trained models.</abstract>
      <url hash="1d376ee3">N19-1404</url>
      <doi>10.18653/v1/N19-1404</doi>
      <video href="https://vimeo.com/361773751" />
      <bibkey>ghaeini-etal-2019-saliency</bibkey>
    </paper>
    <paper id="407">
      <title>Convolutional Self-Attention Networks</title>
      <author><first>Baosong</first><last>Yang</last></author>
      <author><first>Longyue</first><last>Wang</last></author>
      <author><first>Derek F.</first><last>Wong</last></author>
      <author><first>Lidia S.</first><last>Chao</last></author>
      <author><first>Zhaopeng</first><last>Tu</last></author>
      <pages>4040–4045</pages>
      <abstract>Self-attention networks (SANs) have drawn increasing interest due to their high <a href="https://en.wikipedia.org/wiki/Parallel_computing">parallelization in computation</a> and flexibility in modeling <a href="https://en.wikipedia.org/wiki/Coupling_(computer_programming)">dependencies</a>. SANs can be further enhanced with multi-head attention by allowing the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> to attend to information from different representation subspaces. In this work, we propose novel convolutional self-attention networks, which offer SANs the abilities to 1) strengthen dependencies among neighboring elements, and 2) model the interaction between features extracted by multiple attention heads. Experimental results of <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> on different language pairs and model settings show that our approach outperforms both the strong Transformer baseline and other existing models on enhancing the locality of SANs. Comparing with prior studies, the proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is parameter free in terms of introducing no more parameters.</abstract>
      <url hash="3520ba5f">N19-1407</url>
      <doi>10.18653/v1/N19-1407</doi>
      <video href="https://vimeo.com/359716954" />
      <bibkey>yang-etal-2019-convolutional</bibkey>
    </paper>
    <paper id="415">
      <title>On the Idiosyncrasies of the Mandarin Chinese Classifier System<fixed-case>M</fixed-case>andarin <fixed-case>C</fixed-case>hinese Classifier System</title>
      <author><first>Shijia</first><last>Liu</last></author>
      <author><first>Hongyuan</first><last>Mei</last></author>
      <author><first>Adina</first><last>Williams</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <pages>4100–4106</pages>
      <abstract>While idiosyncrasies of the Chinese classifier system have been a richly studied topic among linguists (Adams and Conklin, 1973 ; Erbaugh, 1986 ; Lakoff, 1986), not much work has been done to quantify them with statistical methods. In this paper, we introduce an information-theoretic approach to measuring idiosyncrasy ; we examine how much the uncertainty in Mandarin Chinese classifiers can be reduced by knowing semantic information about the nouns that the <a href="https://en.wikipedia.org/wiki/Classifier_(linguistics)">classifiers</a> modify. Using the empirical distribution of <a href="https://en.wikipedia.org/wiki/Classifier_(linguistics)">classifiers</a> from the parsed Chinese Gigaword corpus (Graff et al., 2005), we compute the <a href="https://en.wikipedia.org/wiki/Mutual_information">mutual information</a> (in bits) between the distribution over <a href="https://en.wikipedia.org/wiki/Classifier_(linguistics)">classifiers</a> and distributions over other linguistic quantities. We investigate whether semantic classes of nouns and adjectives differ in how much they reduce uncertainty in classifier choice, and find that it is not fully idiosyncratic ; while there are no obvious trends for the majority of semantic classes, shape nouns reduce uncertainty in classifier choice the most.</abstract>
      <url hash="b65f38aa">N19-1415</url>
      <doi>10.18653/v1/N19-1415</doi>
      <video href="https://vimeo.com/359721173" />
      <bibkey>liu-etal-2019-idiosyncrasies</bibkey>
    </paper>
    <paper id="416">
      <title>Joint Learning of Pre-Trained and Random Units for Domain Adaptation in Part-of-Speech Tagging</title>
      <author><first>Sara</first><last>Meftah</last></author>
      <author><first>Youssef</first><last>Tamaazousti</last></author>
      <author><first>Nasredine</first><last>Semmar</last></author>
      <author><first>Hassane</first><last>Essafi</last></author>
      <author><first>Fatiha</first><last>Sadat</last></author>
      <pages>4107–4112</pages>
      <abstract>Fine-tuning neural networks is widely used to transfer valuable knowledge from high-resource to low-resource domains. In a standard fine-tuning scheme, source and target problems are trained using the same <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a>. Although capable of adapting to new domains, pre-trained units struggle with learning uncommon target-specific patterns. In this paper, we propose to augment the target-network with normalised, weighted and randomly initialised units that beget a better <a href="https://en.wikipedia.org/wiki/Adaptation">adaptation</a> while maintaining the valuable source knowledge. Our experiments on POS tagging of social media texts (Tweets domain) demonstrate that our method achieves state-of-the-art performances on 3 commonly used datasets.</abstract>
      <url hash="72be7b30">N19-1416</url>
      <doi>10.18653/v1/N19-1416</doi>
      <video href="https://vimeo.com/361815756" />
      <bibkey>meftah-etal-2019-joint</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/tweebank">Tweebank</pwcdataset>
    </paper>
    <paper id="418">
      <title>Data Augmentation for Context-Sensitive Neural Lemmatization Using Inflection Tables and Raw Text</title>
      <author><first>Toms</first><last>Bergmanis</last></author>
      <author><first>Sharon</first><last>Goldwater</last></author>
      <pages>4119–4128</pages>
      <abstract>Lemmatization aims to reduce the sparse data problem by relating the <a href="https://en.wikipedia.org/wiki/Inflection">inflected forms</a> of a word to its <a href="https://en.wikipedia.org/wiki/Dictionary">dictionary form</a>. Using <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context</a> can help, both for unseen and ambiguous words. Yet most context-sensitive approaches require full lemma-annotated sentences for training, which may be scarce or unavailable in low-resource languages. In addition (as shown here), in a low-resource setting, a <a href="https://en.wikipedia.org/wiki/Lemmatizer">lemmatizer</a> can learn more from n labeled examples of distinct words (types) than from n (contiguous) labeled tokens, since the latter contain far fewer distinct types. To combine the efficiency of type-based learning with the benefits of context, we propose a way to train a context-sensitive lemmatizer with little or no labeled corpus data, using inflection tables from the UniMorph project and raw text examples from <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a> that provide sentence contexts for the unambiguous UniMorph examples. Despite these being unambiguous examples, the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> successfully generalizes from them, leading to improved results (both overall, and especially on unseen words) in comparison to a baseline that does not use <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context</a>.</abstract>
      <url hash="5b5287c8">N19-1418</url>
      <attachment type="presentation" hash="a0f5d5d9">N19-1418.Presentation.pdf</attachment>
      <doi>10.18653/v1/N19-1418</doi>
      <video href="https://vimeo.com/361822826" />
      <bibkey>bergmanis-goldwater-2019-data</bibkey>
      <pwccode url="https://bitbucket.org/tomsbergmanis/data_augumentation_um_wiki" additional="false">tomsbergmanis/data_augumentation_um_wiki</pwccode>
    </paper>
    <paper id="419">
      <title>A Structural Probe for Finding Syntax in Word Representations<fixed-case>A</fixed-case> Structural Probe for Finding Syntax in Word Representations</title>
      <author><first>John</first><last>Hewitt</last></author>
      <author><first>Christopher D.</first><last>Manning</last></author>
      <pages>4129–4138</pages>
      <abstract>Recent work has improved our ability to detect linguistic knowledge in <a href="https://en.wikipedia.org/wiki/Representation_(mathematics)">word representations</a>. However, current methods for detecting syntactic knowledge do not test whether <a href="https://en.wikipedia.org/wiki/Syntax_tree">syntax trees</a> are represented in their entirety. In this work, we propose a structural probe, which evaluates whether syntax trees are embedded in a <a href="https://en.wikipedia.org/wiki/Linear_map">linear transformation</a> of a neural network’s word representation space. The probe identifies a <a href="https://en.wikipedia.org/wiki/Linear_map">linear transformation</a> under which squared L2 distance encodes the distance between words in the <a href="https://en.wikipedia.org/wiki/Parse_tree">parse tree</a>, and one in which squared L2 norm encodes depth in the <a href="https://en.wikipedia.org/wiki/Parse_tree">parse tree</a>. Using our probe, we show that such transformations exist for both ELMo and BERT but not in baselines, providing evidence that entire syntax trees are embedded implicitly in deep models’ vector geometry.</abstract>
      <url hash="33672bf1">N19-1419</url>
      <doi>10.18653/v1/N19-1419</doi>
      <video href="https://vimeo.com/361827125" />
      <bibkey>hewitt-manning-2019-structural</bibkey>
      <pwccode url="https://github.com/john-hewitt/structural-probes" additional="false">john-hewitt/structural-probes</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="422">
      <title>Probing the Need for Visual Context in Multimodal Machine Translation</title>
      <author><first>Ozan</first><last>Caglayan</last></author>
      <author><first>Pranava</first><last>Madhyastha</last></author>
      <author><first>Lucia</first><last>Specia</last></author>
      <author><first>Loïc</first><last>Barrault</last></author>
      <pages>4159–4170</pages>
      <abstract>Current work on multimodal machine translation (MMT) has suggested that the visual modality is either unnecessary or only marginally beneficial. We posit that this is a consequence of the very simple, short and repetitive sentences used in the only available dataset for the task (Multi30 K), rendering the source text sufficient as context. In the general case, however, we believe that it is possible to combine visual and textual information in order to ground translations. In this paper we probe the contribution of the visual modality to state-of-the-art MMT models by conducting a systematic analysis where we partially deprive the models from source-side textual context. Our results show that under limited textual context, <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> are capable of leveraging the <a href="https://en.wikipedia.org/wiki/Visual_system">visual input</a> to generate better translations. This contradicts the current belief that MMT models disregard the visual modality because of either the quality of the image features or the way they are integrated into the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>.</abstract>
      <url hash="8d9dcc51">N19-1422</url>
      <attachment type="presentation" hash="35b79de0">N19-1422.Presentation.pdf</attachment>
      <doi>10.18653/v1/N19-1422</doi>
      <award>Best Short Paper</award>
      <video href="https://vimeo.com/365146894" />
      <bibkey>caglayan-etal-2019-probing</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/flickr30k">Flickr30k</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/imagenet">ImageNet</pwcdataset>
    </paper>
    <paper id="424">
      <title>What’s in a Name? Reducing Bias in Bios without Access to Protected Attributes<fixed-case>R</fixed-case>educing Bias in Bios without Access to Protected Attributes</title>
      <author><first>Alexey</first><last>Romanov</last></author>
      <author><first>Maria</first><last>De-Arteaga</last></author>
      <author><first>Hanna</first><last>Wallach</last></author>
      <author><first>Jennifer</first><last>Chayes</last></author>
      <author><first>Christian</first><last>Borgs</last></author>
      <author><first>Alexandra</first><last>Chouldechova</last></author>
      <author><first>Sahin</first><last>Geyik</last></author>
      <author><first>Krishnaram</first><last>Kenthapadi</last></author>
      <author><first>Anna</first><last>Rumshisky</last></author>
      <author><first>Adam</first><last>Kalai</last></author>
      <pages>4187–4195</pages>
      <abstract>There is a growing body of work that proposes methods for mitigating bias in <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning systems</a>. These methods typically rely on access to protected attributes such as <a href="https://en.wikipedia.org/wiki/Race_(human_categorization)">race</a>, <a href="https://en.wikipedia.org/wiki/Gender">gender</a>, or age. However, this raises two significant challenges : (1) protected attributes may not be available or it may not be legal to use them, and (2) it is often desirable to simultaneously consider multiple protected attributes, as well as their intersections. In the context of mitigating bias in occupation classification, we propose a method for discouraging correlation between the predicted probability of an individual’s true occupation and a <a href="https://en.wikipedia.org/wiki/Word_embedding">word embedding</a> of their name. This method leverages the societal biases that are encoded in <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>, eliminating the need for access to <a href="https://en.wikipedia.org/wiki/Attribute_(computing)">protected attributes</a>. Crucially, <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> only requires access to individuals’ names at training time and not at deployment time. We evaluate two variations of our proposed <a href="https://en.wikipedia.org/wiki/Methodology">method</a> using a large-scale dataset of online biographies. We find that both variations simultaneously reduce race and gender biases, with almost no reduction in the classifier’s overall true positive rate.</abstract>
      <url hash="9052e980">N19-1424</url>
      <doi>10.18653/v1/N19-1424</doi>
      <award>Best Thematic Paper</award>
      <video href="https://vimeo.com/365132300" />
      <bibkey>romanov-etal-2019-whats</bibkey>
    </paper>
  </volume>
  <volume id="2">
    <meta>
      <booktitle>Proceedings of the 2019 Conference of the North <fixed-case>A</fixed-case>merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)</booktitle>
      <url hash="cf1aa4c0">N19-2</url>
      <editor><first>Anastassia</first><last>Loukina</last></editor>
      <editor><first>Michelle</first><last>Morales</last></editor>
      <editor><first>Rohit</first><last>Kumar</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url hash="4b4af3a9">N19-2000</url>
      <bibkey>naacl-2019-2019-north</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Enabling Real-time Neural IME with Incremental Vocabulary Selection<fixed-case>IME</fixed-case> with Incremental Vocabulary Selection</title>
      <author><first>Jiali</first><last>Yao</last></author>
      <author><first>Raphael</first><last>Shu</last></author>
      <author><first>Xinjian</first><last>Li</last></author>
      <author><first>Katsutoshi</first><last>Ohtsuki</last></author>
      <author><first>Hideki</first><last>Nakayama</last></author>
      <pages>1–8</pages>
      <abstract>Input method editor (IME) converts sequential alphabet key inputs to words in a target language. It is an indispensable service for billions of Asian users. Although the neural-based language model is extensively studied and shows promising results in sequence-to-sequence tasks, applying a neural-based language model to IME was not considered feasible due to high <a href="https://en.wikipedia.org/wiki/Latency_(engineering)">latency</a> when converting words on user devices. In this work, we articulate the bottleneck of neural IME decoding to be the heavy softmax computation over a large vocabulary. We propose an approach that incrementally builds a subset vocabulary from the word lattice. Our approach always computes the probability with a selected subset vocabulary. When the selected vocabulary is updated, the stale probabilities in previous steps are fixed by recomputing the missing logits. The experiments on Japanese IME benchmark shows an over 50x speedup for the softmax computations comparing to the baseline, reaching real-time speed even on commodity CPU without losing conversion accuracy. The approach is potentially applicable to other incremental sequence-to-sequence decoding tasks such as real-time continuous speech recognition.</abstract>
      <url hash="4d19c11f">N19-2001</url>
      <doi>10.18653/v1/N19-2001</doi>
      <bibkey>yao-etal-2019-enabling</bibkey>
      <pwccode url="https://github.com/jiali-ms/JLM" additional="false">jiali-ms/JLM</pwccode>
    </paper>
    <paper id="11">
      <title>Neural Lexicons for Slot Tagging in Spoken Language Understanding</title>
      <author><first>Kyle</first><last>Williams</last></author>
      <pages>83–89</pages>
      <abstract>We explore the use of <a href="https://en.wikipedia.org/wiki/Lexicon">lexicons</a> or <a href="https://en.wikipedia.org/wiki/Gazette">gazettes</a> in neural models for slot tagging in spoken language understanding. We develop models that encode lexicon information as <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">neural features</a> for use in a Long-short term memory neural network. Experiments are performed on <a href="https://en.wikipedia.org/wiki/Data">data</a> from 4 domains from an intelligent assistant under conditions that often occur in an industry setting, where there may be : 1) large amounts of training data, 2) limited amounts of training data for new domains, and 3) cross domain training. Results show that the use of neural lexicon information leads to a significant improvement in slot tagging, with improvements in the <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> of up to 12 %. Our findings have implications for how <a href="https://en.wikipedia.org/wiki/Lexicon">lexicons</a> can be used to improve the performance of neural slot tagging models.</abstract>
      <url hash="f25c33c0">N19-2011</url>
      <doi>10.18653/v1/N19-2011</doi>
      <bibkey>williams-2019-neural</bibkey>
    </paper>
    <paper id="12">
      <title>Active Learning for New Domains in Natural Language Understanding</title>
      <author><first>Stanislav</first><last>Peshterliev</last></author>
      <author><first>John</first><last>Kearney</last></author>
      <author><first>Abhyuday</first><last>Jagannatha</last></author>
      <author><first>Imre</first><last>Kiss</last></author>
      <author><first>Spyros</first><last>Matsoukas</last></author>
      <pages>90–96</pages>
      <abstract>We explore active learning (AL) for improving the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of new domains in a <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language understanding (NLU) system</a>. We propose an <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> called Majority-CRF that uses an ensemble of classification models to guide the selection of relevant utterances, as well as a sequence labeling model to help prioritize informative examples. Experiments with three domains show that Majority-CRF achieves 6.6%-9 % relative error rate reduction compared to <a href="https://en.wikipedia.org/wiki/Simple_random_sample">random sampling</a> with the same annotation budget, and statistically significant improvements compared to other AL approaches. Additionally, case studies with human-in-the-loop AL on six <a href="https://en.wikipedia.org/wiki/Domain_(software_engineering)">new domains</a> show 4.6%-9 % improvement on an existing NLU system.</abstract>
      <url hash="e23d88e8">N19-2012</url>
      <doi>10.18653/v1/N19-2012</doi>
      <bibkey>peshterliev-etal-2019-active</bibkey>
    </paper>
    <paper id="14">
      <title>Are the Tools up to the Task? an Evaluation of Commercial Dialog Tools in Developing Conversational Enterprise-grade Dialog Systems</title>
      <author><first>Marie</first><last>Meteer</last></author>
      <author><first>Meghan</first><last>Hickey</last></author>
      <author><first>Carmi</first><last>Rothberg</last></author>
      <author><first>David</first><last>Nahamoo</last></author>
      <author><first>Ellen</first><last>Eide Kislal</last></author>
      <pages>106–113</pages>
      <abstract>There has been a significant investment in dialog systems (tools and runtime) for building conversational systems by major companies including <a href="https://en.wikipedia.org/wiki/Google">Google</a>, <a href="https://en.wikipedia.org/wiki/IBM">IBM</a>, <a href="https://en.wikipedia.org/wiki/Microsoft">Microsoft</a>, and <a href="https://en.wikipedia.org/wiki/Amazon_(company)">Amazon</a>. The question remains whether these tools are up to the task of building conversational, task-oriented dialog applications at the enterprise level. In our company, we are exploring and comparing several toolsets in an effort to determine their strengths and weaknesses in meeting our goals for dialog system development : <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>, time to market, ease of replicating and extending applications, and efficiency and ease of use by developers. In this paper, we provide both quantitative and qualitative results in three main areas : <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language understanding</a>, <a href="https://en.wikipedia.org/wiki/Dialogue">dialog</a>, and text generation. While existing toolsets were all incomplete, we hope this paper will provide a roadmap of where they need to go to meet the goal of building effective dialog systems.</abstract>
      <url hash="83f2fe10">N19-2014</url>
      <doi>10.18653/v1/N19-2014</doi>
      <bibkey>meteer-etal-2019-tools</bibkey>
    </paper>
    <paper id="15">
      <title>Development and Deployment of a Large-Scale Dialog-based Intelligent Tutoring System</title>
      <author><first>Shazia</first><last>Afzal</last></author>
      <author><first>Tejas</first><last>Dhamecha</last></author>
      <author><first>Nirmal</first><last>Mukhi</last></author>
      <author><first>Renuka</first><last>Sindhgatta</last></author>
      <author><first>Smit</first><last>Marvaniya</last></author>
      <author><first>Matthew</first><last>Ventura</last></author>
      <author><first>Jessica</first><last>Yarbro</last></author>
      <pages>114–121</pages>
      <abstract>There are significant challenges involved in the design and implementation of a dialog-based tutoring system (DBT) ranging from <a href="https://en.wikipedia.org/wiki/Domain_engineering">domain engineering</a> to <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language classification</a> and eventually instantiating an adaptive, personalized dialog strategy. These issues are magnified when implementing such a <a href="https://en.wikipedia.org/wiki/System">system</a> at scale and across domains. In this paper, we describe and reflect on the design, methods, decisions and assessments that led to the successful deployment of our AI driven DBT currently being used by several hundreds of college level students for practice and self-regulated study in diverse subjects like <a href="https://en.wikipedia.org/wiki/Sociology">Sociology</a>, <a href="https://en.wikipedia.org/wiki/Communication">Communications</a>, and <a href="https://en.wikipedia.org/wiki/Federal_government_of_the_United_States">American Government</a>.</abstract>
      <url hash="812b087f">N19-2015</url>
      <doi>10.18653/v1/N19-2015</doi>
      <bibkey>afzal-etal-2019-development</bibkey>
    </paper>
    <paper id="16">
      <title>Learning When Not to Answer : a Ternary Reward Structure for Reinforcement Learning Based Question Answering</title>
      <author><first>Fréderic</first><last>Godin</last></author>
      <author><first>Anjishnu</first><last>Kumar</last></author>
      <author><first>Arpit</first><last>Mittal</last></author>
      <pages>122–129</pages>
      <abstract>In this paper, we investigate the challenges of using <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning agents</a> for question-answering over knowledge graphs for real-world applications. We examine the <a href="https://en.wikipedia.org/wiki/Performance_metric">performance metrics</a> used by state-of-the-art <a href="https://en.wikipedia.org/wiki/System">systems</a> and determine that they are inadequate for such settings. More specifically, they do not evaluate the <a href="https://en.wikipedia.org/wiki/System">systems</a> correctly for situations when there is no answer available and thus <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agents</a> optimized for these <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> are poor at modeling confidence. We introduce a simple new <a href="https://en.wikipedia.org/wiki/Performance_metric">performance metric</a> for evaluating question-answering agents that is more representative of practical usage conditions, and optimize for this metric by extending the binary reward structure used in prior work to a ternary reward structure which also rewards an agent for not answering a question rather than giving an incorrect answer. We show that this can drastically improve the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a> of answered questions while only not answering a limited number of previously correctly answered questions. Employing a supervised learning strategy using depth-first-search paths to bootstrap the reinforcement learning algorithm further improves performance.</abstract>
      <url hash="2ffea43d">N19-2016</url>
      <doi>10.18653/v1/N19-2016</doi>
      <bibkey>godin-etal-2019-learning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/fb15k-237">FB15k-237</pwcdataset>
    </paper>
    <paper id="17">
      <title>Extraction of Message Sequence Charts from Software Use-Case Descriptions</title>
      <author><first>Girish</first><last>Palshikar</last></author>
      <author><first>Nitin</first><last>Ramrakhiyani</last></author>
      <author><first>Sangameshwar</first><last>Patil</last></author>
      <author><first>Sachin</first><last>Pawar</last></author>
      <author><first>Swapnil</first><last>Hingmire</last></author>
      <author><first>Vasudeva</first><last>Varma</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>130–137</pages>
      <abstract>Software Requirement Specification documents provide natural language descriptions of the core functional requirements as a set of <a href="https://en.wikipedia.org/wiki/Use_case">use-cases</a>. Essentially, each use-case contains a set of <a href="https://en.wikipedia.org/wiki/Actor_(disambiguation)">actors</a> and sequences of steps describing the interactions among them. Goals of use-case reviews and analyses include their correctness, completeness, detection of ambiguities, <a href="https://en.wikipedia.org/wiki/Software_prototyping">prototyping</a>, <a href="https://en.wikipedia.org/wiki/Software_verification">verification</a>, <a href="https://en.wikipedia.org/wiki/Test_case">test case generation</a> and <a href="https://en.wikipedia.org/wiki/Traceability">traceability</a>. Message Sequence Chart (MSC) have been proposed as a expressive, rigorous yet intuitive visual representation of use-cases. In this paper, we describe a linguistic knowledge-based approach to extract MSCs from <a href="https://en.wikipedia.org/wiki/Use_case">use-cases</a>. Compared to existing techniques, we extract richer constructs of the MSC notation such as <a href="https://en.wikipedia.org/wiki/Timer">timers</a>, <a href="https://en.wikipedia.org/wiki/Conditional_(computer_programming)">conditions</a> and alt-boxes. We apply this <a href="https://en.wikipedia.org/wiki/Tool">tool</a> to extract MSCs from several real-life software use-case descriptions and show that it performs better than the existing techniques. We also discuss the benefits and limitations of the extracted MSCs to meet the above goals.</abstract>
      <url hash="cd1f3f05">N19-2017</url>
      <doi>10.18653/v1/N19-2017</doi>
      <bibkey>palshikar-etal-2019-extraction</bibkey>
    </paper>
    <paper id="18">
      <title>Improving Knowledge Base Construction from Robust Infobox Extraction</title>
      <author><first>Boya</first><last>Peng</last></author>
      <author><first>Yejin</first><last>Huh</last></author>
      <author><first>Xiao</first><last>Ling</last></author>
      <author><first>Michele</first><last>Banko</last></author>
      <pages>138–148</pages>
      <abstract>A capable, automatic Question Answering (QA) system can provide more complete and accurate answers using a comprehensive knowledge base (KB). One important approach to constructing a comprehensive knowledge base is to extract information from Wikipedia infobox tables to populate an existing KB. Despite previous successes in the Infobox Extraction (IBE) problem (e.g., DBpedia), three major challenges remain : 1) Deterministic extraction patterns used in DBpedia are vulnerable to template changes ; 2) Over-trusting Wikipedia anchor links can lead to entity disambiguation errors ; 3) Heuristic-based extraction of unlinkable entities yields low precision, hurting both accuracy and completeness of the final KB. This paper presents a <a href="https://en.wikipedia.org/wiki/Robustness_(computer_science)">robust approach</a> that tackles all three challenges. We build probabilistic models to predict relations between entity mentions directly from the infobox tables in <a href="https://en.wikipedia.org/wiki/HTML">HTML</a>. The entity mentions are linked to <a href="https://en.wikipedia.org/wiki/Identifier">identifiers</a> in an existing <a href="https://en.wikipedia.org/wiki/Kibibyte">KB</a> if possible. The unlinkable ones are also parsed and preserved in the final output. Training data for both the <a href="https://en.wikipedia.org/wiki/Relation_extraction">relation extraction</a> and the entity linking models are automatically generated using distant supervision. We demonstrate the empirical effectiveness of the proposed method in both <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a> and <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall</a> compared to a strong IBE baseline, <a href="https://en.wikipedia.org/wiki/DBpedia">DBpedia</a>, with an absolute improvement of 41.3 % in average F1. We also show that our <a href="https://en.wikipedia.org/wiki/Information_extraction">extraction</a> makes the final KB significantly more complete, improving the <a href="https://en.wikipedia.org/wiki/Completeness_(logic)">completeness score</a> of list-value relation types by 61.4 %.</abstract>
      <url hash="280c2110">N19-2018</url>
      <doi>10.18653/v1/N19-2018</doi>
      <bibkey>peng-etal-2019-improving</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/dbpedia">DBpedia</pwcdataset>
    </paper>
    <paper id="19">
      <title>A k-Nearest Neighbor Approach towards Multi-level Sequence Labeling</title>
      <author><first>Yue</first><last>Chen</last></author>
      <author><first>John</first><last>Chen</last></author>
      <pages>149–156</pages>
      <abstract>In this paper we present a new method for intent recognition for complex dialog management in low resource situations. Complex dialog management is required because our target domain is real world mixed initiative food ordering between agents and their customers, where individual customer utterances may contain multiple intents and refer to food items with complex structure. For example, a customer might say Can I get a deluxe burger with large fries and oh put extra mayo on the burger would you? We approach this task as a multi-level sequence labeling problem, with the constraint of limited real training data. Both traditional methods like HMM, <a href="https://en.wikipedia.org/wiki/Microelectromechanical_systems">MEMM</a>, or CRF and newer methods like <a href="https://en.wikipedia.org/wiki/Deep_learning">DNN</a> or BiLSTM use only homogeneous feature sets. Newer <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">methods</a> perform better but also require considerably more data. Previous research has done pseudo-data synthesis to obtain the required amounts of training data. We propose to use a k-NN learner with heterogeneous feature set. We used windowed word n-grams, POS tag n-grams and pre-trained word embeddings as features. For the experiments we perform a comparison between using pseudo-data and real world data. We also perform <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning">semi-supervised self-training</a> to obtain additional labeled data, in order to better model real world scenarios. Instead of using massive pseudo-data, we show that with only less than 1 % of the data size, we can achieve better result than any of the methods above by annotating real world data.</abstract>
      <url hash="8d89ad86">N19-2019</url>
      <attachment type="poster" hash="6c4efb70">N19-2019.Poster.pdf</attachment>
      <doi>10.18653/v1/N19-2019</doi>
      <bibkey>chen-chen-2019-k</bibkey>
    </paper>
    <paper id="24">
      <title>Neural Text Normalization with Subword Units</title>
      <author><first>Courtney</first><last>Mansfield</last></author>
      <author><first>Ming</first><last>Sun</last></author>
      <author><first>Yuzong</first><last>Liu</last></author>
      <author><first>Ankur</first><last>Gandhe</last></author>
      <author><first>Björn</first><last>Hoffmeister</last></author>
      <pages>190–196</pages>
      <abstract>Text normalization (TN) is an important step in conversational systems. It converts written text to its spoken form to facilitate <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech recognition</a>, <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language understanding</a> and <a href="https://en.wikipedia.org/wiki/Speech_synthesis">text-to-speech synthesis</a>. Finite state transducers (FSTs) are commonly used to build <a href="https://en.wikipedia.org/wiki/Formal_grammar">grammars</a> that handle <a href="https://en.wikipedia.org/wiki/Text_normalization">text normalization</a>. However, translating <a href="https://en.wikipedia.org/wiki/Linguistics">linguistic knowledge</a> into <a href="https://en.wikipedia.org/wiki/Grammar">grammars</a> requires extensive effort. In this paper, we frame TN as a machine translation task and tackle it with sequence-to-sequence (seq2seq) models. Previous research focuses on normalizing a word (or phrase) with the help of limited word-level context, while our approach directly normalizes full sentences. We find subword models with additional linguistic features yield the best performance (with a word error rate of 0.17 %).</abstract>
      <url hash="4d183620">N19-2024</url>
      <doi>10.18653/v1/N19-2024</doi>
      <bibkey>mansfield-etal-2019-neural</bibkey>
    </paper>
    <paper id="26">
      <title>In Other News : a Bi-style Text-to-speech Model for Synthesizing Newscaster Voice with Limited Data</title>
      <author><first>Nishant</first><last>Prateek</last></author>
      <author><first>Mateusz</first><last>Łajszczak</last></author>
      <author><first>Roberto</first><last>Barra-Chicote</last></author>
      <author><first>Thomas</first><last>Drugman</last></author>
      <author><first>Jaime</first><last>Lorenzo-Trueba</last></author>
      <author><first>Thomas</first><last>Merritt</last></author>
      <author><first>Srikanth</first><last>Ronanki</last></author>
      <author><first>Trevor</first><last>Wood</last></author>
      <pages>205–213</pages>
      <abstract>Neural text-to-speech synthesis (NTTS) models have shown significant progress in generating high-quality speech, however they require a large quantity of training data. This makes creating <a href="https://en.wikipedia.org/wiki/Model_(person)">models</a> for multiple styles expensive and time-consuming. In this paper different styles of speech are analysed based on <a href="https://en.wikipedia.org/wiki/Prosody_(linguistics)">prosodic variations</a>, from this a model is proposed to synthesise <a href="https://en.wikipedia.org/wiki/Speech">speech</a> in the style of a <a href="https://en.wikipedia.org/wiki/News_presenter">newscaster</a>, with just a few hours of supplementary data. We pose the problem of synthesising in a target style using limited data as that of creating a bi-style model that can synthesise both neutral-style and newscaster-style speech via a one-hot vector which factorises the two styles. We also propose conditioning the model on contextual word embeddings, and extensively evaluate it against neutral NTTS, and neutral concatenative-based synthesis. This model closes the gap in perceived style-appropriateness between <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural recordings</a> for <a href="https://en.wikipedia.org/wiki/News_style">newscaster-style of speech</a>, and neutral speech synthesis by approximately two-thirds.</abstract>
      <url hash="06680939">N19-2026</url>
      <doi>10.18653/v1/N19-2026</doi>
      <bibkey>prateek-etal-2019-news</bibkey>
    </paper>
    <paper id="28">
      <title>Content-based Dwell Time Engagement Prediction Model for News Articles</title>
      <author><first>Heidar</first><last>Davoudi</last></author>
      <author><first>Aijun</first><last>An</last></author>
      <author><first>Gordon</first><last>Edall</last></author>
      <pages>226–233</pages>
      <abstract>The article dwell time (i.e., expected time that users spend on an article) is among the most important factors showing the article engagement. It is of great interest to predict the dwell time of an article before its release. This allows <a href="https://en.wikipedia.org/wiki/Digital_newspaper">digital newspapers</a> to make informed decisions and publish more engaging articles. In this paper, we propose a novel content-based approach based on a deep neural network architecture for predicting article dwell times. The proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> extracts <a href="https://en.wikipedia.org/wiki/Emotion">emotion</a>, event and entity features from an article, learns interactions among them, and combines the interactions with the word-based features of the article to learn a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> for predicting the dwell time. The experimental results on a real dataset from a major newspaper show that the proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms other state-of-the-art baselines.</abstract>
      <url hash="7582faec">N19-2028</url>
      <doi>10.18653/v1/N19-2028</doi>
      <bibkey>davoudi-etal-2019-content</bibkey>
    </paper>
  </volume>
  <volume id="3">
    <meta>
      <booktitle>Proceedings of the 2019 Conference of the North <fixed-case>A</fixed-case>merican Chapter of the Association for Computational Linguistics: Student Research Workshop</booktitle>
      <url hash="18980fd1">N19-3</url>
      <editor><first>Sudipta</first><last>Kar</last></editor>
      <editor><first>Farah</first><last>Nadeem</last></editor>
      <editor><first>Laura</first><last>Burdick</last></editor>
      <editor><first>Greg</first><last>Durrett</last></editor>
      <editor><first>Na-Rae</first><last>Han</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url hash="251c7665">N19-3000</url>
      <bibkey>naacl-2019-2019-north-american</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Is It Dish Washer Safe? Automatically Answering Yes / No Questions Using Customer Reviews</title>
      <author><first>Daria</first><last>Dzendzik</last></author>
      <author><first>Carl</first><last>Vogel</last></author>
      <author><first>Jennifer</first><last>Foster</last></author>
      <pages>1–6</pages>
      <abstract>It has become commonplace for people to share their opinions about all kinds of products by posting reviews online. It has also become commonplace for potential customers to do research about the quality and limitations of these <a href="https://en.wikipedia.org/wiki/Product_(business)">products</a> by posting questions online. We test the extent to which reviews are useful in <a href="https://en.wikipedia.org/wiki/Question_answering">question-answering</a> by combining two <a href="https://en.wikipedia.org/wiki/Amazon_Web_Services">Amazon datasets</a> and focusing our attention on <a href="https://en.wikipedia.org/wiki/Yes–no_question">yes / no questions</a>. A manual analysis of 400 cases reveals that the reviews directly contain the answer to the question just over a third of the time. Preliminary reading comprehension experiments with this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> prove inconclusive, with <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> in the range 50-66 %.</abstract>
      <url hash="0fd24f28">N19-3001</url>
      <doi>10.18653/v1/N19-3001</doi>
      <bibkey>dzendzik-etal-2019-dish</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/movieqa">MovieQA</pwcdataset>
    </paper>
    <paper id="2">
      <title>Identifying and Reducing Gender Bias in Word-Level Language Models</title>
      <author><first>Shikha</first><last>Bordia</last></author>
      <author><first>Samuel R.</first><last>Bowman</last></author>
      <pages>7–15</pages>
      <abstract>Many <a href="https://en.wikipedia.org/wiki/Text_corpus">text corpora</a> exhibit socially problematic biases, which can be propagated or amplified in the <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> trained on such <a href="https://en.wikipedia.org/wiki/Data">data</a>. For example, doctor cooccurs more frequently with <a href="https://en.wikipedia.org/wiki/Sex_and_gender_distinction">male pronouns</a> than <a href="https://en.wikipedia.org/wiki/Sex_and_gender_distinction">female pronouns</a>. In this study we (i) propose a metric to measure <a href="https://en.wikipedia.org/wiki/Gender">gender bias</a> ; (ii) measure bias in a <a href="https://en.wikipedia.org/wiki/Text_corpus">text corpus</a> and the text generated from a recurrent neural network language model trained on the <a href="https://en.wikipedia.org/wiki/Text_corpus">text corpus</a> ; (iii) propose a regularization loss term for the language model that minimizes the projection of encoder-trained embeddings onto an embedding subspace that encodes <a href="https://en.wikipedia.org/wiki/Gender">gender</a> ; (iv) finally, evaluate efficacy of our proposed method on reducing <a href="https://en.wikipedia.org/wiki/Gender">gender bias</a>. We find this regularization method to be effective in reducing gender bias up to an optimal weight assigned to the loss term, beyond which the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> becomes unstable as the perplexity increases. We replicate this study on three training corporaPenn Treebank, WikiText-2, and CNN / Daily Mailresulting in similar conclusions.</abstract>
      <url hash="6853b895">N19-3002</url>
      <attachment type="presentation" hash="cd1efd9d">N19-3002.Presentation.pdf</attachment>
      <attachment type="note" hash="9746a3b7">N19-3002.Note.pdf</attachment>
      <video href="https://vimeo.com/347400639" />
      <doi>10.18653/v1/N19-3002</doi>
      <bibkey>bordia-bowman-2019-identifying</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikitext-2">WikiText-2</pwcdataset>
    </paper>
    <paper id="10">
      <title>Computational Investigations of Pragmatic Effects in <a href="https://en.wikipedia.org/wiki/Natural_language">Natural Language</a></title>
      <author><first>Jad</first><last>Kabbara</last></author>
      <pages>71–76</pages>
      <abstract>Semantics and <a href="https://en.wikipedia.org/wiki/Pragmatics">pragmatics</a> are two complimentary and intertwined aspects of meaning in language. The <a href="https://en.wikipedia.org/wiki/Literal_and_figurative_language">former</a> is concerned with the literal (context-free) meaning of words and sentences, the <a href="https://en.wikipedia.org/wiki/Literal_and_figurative_language">latter</a> focuses on the intended meaning, one that is context-dependent. While NLP research has focused in the past mostly on <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a>, the goal of this thesis is to develop computational models that leverage this pragmatic knowledge in language that is crucial to performing many NLP tasks correctly. In this proposal, we begin by reviewing the current progress in this thesis, namely, on the tasks of definiteness prediction and adverbial presupposition triggering. Then we discuss the proposed research for the remainder of the thesis which builds on this progress towards the goal of building better and more pragmatically-aware natural language generation and understanding systems.</abstract>
      <url hash="3961279f">N19-3010</url>
      <doi>10.18653/v1/N19-3010</doi>
      <bibkey>kabbara-2019-computational</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="11">
      <title>SEDTWik : Segmentation-based Event Detection from <a href="https://en.wikipedia.org/wiki/Twitter">Tweets</a> Using Wikipedia<fixed-case>SEDTW</fixed-case>ik: Segmentation-based Event Detection from Tweets Using <fixed-case>W</fixed-case>ikipedia</title>
      <author><first>Keval</first><last>Morabia</last></author>
      <author><first>Neti Lalita</first><last>Bhanu Murthy</last></author>
      <author><first>Aruna</first><last>Malapati</last></author>
      <author><first>Surender</first><last>Samant</last></author>
      <pages>77–85</pages>
      <abstract>Event Detection has been one of the research areas in <a href="https://en.wikipedia.org/wiki/Text_mining">Text Mining</a> that has attracted attention during this decade due to the widespread availability of social media data specifically twitter data. Twitter has become a major source for information about real-world events because of the use of <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a> and the small word limit of <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> that ensures concise presentation of events. Previous works on event detection from <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> are either applicable to detect localized events or breaking news only or miss out on many important events. This paper presents the problems associated with event detection from <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> and a tweet-segmentation based system for event detection called SEDTWik, an extension to a previous work, that is able to detect newsworthy events occurring at different locations of the world from a wide range of categories. The main idea is to split each tweet and <a href="https://en.wikipedia.org/wiki/Hashtag">hash-tag</a> into segments, extract bursty segments, cluster them, and summarize them. We evaluated our results on the well-known Events2012 corpus and achieved state-of-the-art results. Keywords : Event detection, <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>, <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a>, <a href="https://en.wikipedia.org/wiki/Microblogging">Microblogging</a>, Tweet segmentation, <a href="https://en.wikipedia.org/wiki/Text_mining">Text Mining</a>, <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a>, <a href="https://en.wikipedia.org/wiki/Hashtag">Hashtag</a>.</abstract>
      <url hash="5065be7f">N19-3011</url>
      <doi>10.18653/v1/N19-3011</doi>
      <bibkey>morabia-etal-2019-sedtwik</bibkey>
      <pwccode url="https://github.com/kevalmorabia97/SEDTWik-Event-Detection-from-Tweets" additional="false">kevalmorabia97/SEDTWik-Event-Detection-from-Tweets</pwccode>
    </paper>
    <paper id="12">
      <title>Multimodal Machine Translation with Embedding Prediction</title>
      <author><first>Tosho</first><last>Hirasawa</last></author>
      <author><first>Hayahide</first><last>Yamagishi</last></author>
      <author><first>Yukio</first><last>Matsumura</last></author>
      <author><first>Mamoru</first><last>Komachi</last></author>
      <pages>86–91</pages>
      <abstract>Multimodal machine translation is an attractive application of neural machine translation (NMT). It helps computers to deeply understand <a href="https://en.wikipedia.org/wiki/Visual_system">visual objects</a> and their relations with <a href="https://en.wikipedia.org/wiki/Natural_language">natural languages</a>. However, multimodal NMT systems suffer from a shortage of available training data, resulting in poor performance for translating rare words. In NMT, pretrained word embeddings have been shown to improve NMT of low-resource domains, and a search-based approach is proposed to address the rare word problem. In this study, we effectively combine these two approaches in the context of multimodal NMT and explore how we can take full advantage of pretrained word embeddings to better translate rare words. We report overall performance improvements of 1.24 METEOR and 2.49 BLEU and achieve an improvement of 7.67 <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> for rare word translation.</abstract>
      <url hash="668c7991">N19-3012</url>
      <attachment type="presentation" hash="88006697">N19-3012.Presentation.pdf</attachment>
      <doi>10.18653/v1/N19-3012</doi>
      <video href="https://vimeo.com/355800547" />
      <bibkey>hirasawa-etal-2019-multimodal</bibkey>
      <pwccode url="https://github.com/toshohirasawa/nmtpytorch-emb-pred" additional="false">toshohirasawa/nmtpytorch-emb-pred</pwccode>
    </paper>
    <paper id="13">
      <title>Deep Learning and Sociophonetics : Automatic Coding of Rhoticity Using <a href="https://en.wikipedia.org/wiki/Neural_network">Neural Networks</a></title>
      <author><first>Sarah</first><last>Gupta</last></author>
      <author><first>Anthony</first><last>DiPadova</last></author>
      <pages>92–96</pages>
      <abstract>Automated extraction methods are widely available for vowels, but automated methods for coding rhoticity have lagged far behind. R-fulness versus <a href="https://en.wikipedia.org/wiki/R-lessness">r-lessness</a> (in words like park, store, etc.) is a classic and frequently cited variable, but it is still commonly coded by human analysts rather than automated methods. Human-coding requires extensive resources and lacks replicability, making it difficult to compare large datasets across research groups. Can reliable automated methods be developed to aid in coding rhoticity? In this study, we use <a href="https://en.wikipedia.org/wiki/Neural_network">Neural Networks</a> / Deep Learning, training our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> on 208 Boston-area speakers.</abstract>
      <url hash="23552661">N19-3013</url>
      <doi>10.18653/v1/N19-3013</doi>
      <bibkey>gupta-dipadova-2019-deep</bibkey>
    </paper>
    <paper id="14">
      <title>Data Augmentation by Data Noising for Open-vocabulary Slots in Spoken Language Understanding</title>
      <author><first>Hwa-Yeon</first><last>Kim</last></author>
      <author><first>Yoon-Hyung</first><last>Roh</last></author>
      <author><first>Young-Kil</first><last>Kim</last></author>
      <pages>97–102</pages>
      <abstract>One of the main challenges in Spoken Language Understanding (SLU) is dealing with ‘open-vocabulary’ slots. Recently, SLU models based on <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> were proposed, but it is still difficult to recognize the slots of unknown words or ‘open-vocabulary’ slots because of the high cost of creating a manually tagged SLU dataset. This paper proposes data noising, which reflects the characteristics of the ‘open-vocabulary’ slots, for <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a>. We applied it to an attention based bi-directional recurrent neural network (Liu and Lane, 2016) and experimented with three datasets : Airline Travel Information System (ATIS), Snips, and MIT-Restaurant. We achieved performance improvements of up to 0.57 % and 3.25 in intent prediction (accuracy) and slot filling (f1-score), respectively. Our method is advantageous because <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> does not require additional memory and <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> can be applied simultaneously with the training process of the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>.</abstract>
      <url hash="f39b3ad1">N19-3014</url>
      <doi>10.18653/v1/N19-3014</doi>
      <bibkey>kim-etal-2019-data</bibkey>
    </paper>
    <paper id="15">
      <title>Expectation and Locality Effects in the Prediction of Disfluent Fillers and Repairs in <a href="https://en.wikipedia.org/wiki/English_language">English Speech</a><fixed-case>E</fixed-case>nglish Speech</title>
      <author><first>Samvit</first><last>Dammalapati</last></author>
      <author><first>Rajakrishnan</first><last>Rajkumar</last></author>
      <author><first>Sumeet</first><last>Agarwal</last></author>
      <pages>103–109</pages>
      <abstract>This study examines the role of three influential theories of <a href="https://en.wikipedia.org/wiki/Language_processing_in_the_brain">language processing</a>, viz., Surprisal Theory, Uniform Information Density (UID) hypothesis and Dependency Locality Theory (DLT), in predicting disfluencies in speech production. To this end, we incorporate features based on lexical surprisal, word duration and DLT integration and storage costs into logistic regression classifiers aimed to predict disfluencies in the Switchboard corpus of English conversational speech. We find that <a href="https://en.wikipedia.org/wiki/Speech_disfluency">disfluencies</a> occur in the face of upcoming difficulties and speakers tend to handle this by lessening <a href="https://en.wikipedia.org/wiki/Cognitive_load">cognitive load</a> before <a href="https://en.wikipedia.org/wiki/Speech_disfluency">disfluencies</a> occur. Further, we see that reparandums behave differently from disfluent fillers possibly due to the lessening of the <a href="https://en.wikipedia.org/wiki/Cognitive_load">cognitive load</a> also happening in the word choice of the reparandum, i.e., in the <a href="https://en.wikipedia.org/wiki/Disfluency">disfluency</a> itself. While the UID hypothesis does not seem to play a significant role in disfluency prediction, lexical surprisal and DLT costs do give promising results in explaining <a href="https://en.wikipedia.org/wiki/Language_production">language production</a>. Further, we also find that as a means to lessen <a href="https://en.wikipedia.org/wiki/Cognitive_load">cognitive load</a> for upcoming difficulties speakers take more time on words preceding disfluencies, making duration a key element in understanding <a href="https://en.wikipedia.org/wiki/Speech_disfluency">disfluencies</a>.<i>viz.</i>, Surprisal Theory, Uniform Information Density (UID) hypothesis and Dependency Locality Theory (DLT), in predicting disfluencies in speech production. To this end, we incorporate features based on lexical surprisal, word duration and DLT integration and storage costs into logistic regression classifiers aimed to predict disfluencies in the Switchboard corpus of English conversational speech. We find that disfluencies occur in the face of upcoming difficulties and speakers tend to handle this by lessening cognitive load before disfluencies occur. Further, we see that reparandums behave differently from disfluent fillers possibly due to the lessening of the cognitive load also happening in the word choice of the reparandum, i.e., in the disfluency itself. While the UID hypothesis does not seem to play a significant role in disfluency prediction, lexical surprisal and DLT costs do give promising results in explaining language production. Further, we also find that as a means to lessen cognitive load for upcoming difficulties speakers take more time on words preceding disfluencies, making duration a key element in understanding disfluencies.</abstract>
      <url hash="81e0ec66">N19-3015</url>
      <doi>10.18653/v1/N19-3015</doi>
      <bibkey>dammalapati-etal-2019-expectation</bibkey>
    </paper>
    </volume>
  <volume id="4">
    <meta>
      <booktitle>Proceedings of the 2019 Conference of the North <fixed-case>A</fixed-case>merican Chapter of the Association for Computational Linguistics (Demonstrations)</booktitle>
      <url hash="b6f11400">N19-4</url>
      <editor><first>Waleed</first><last>Ammar</last></editor>
      <editor><first>Annie</first><last>Louis</last></editor>
      <editor><first>Nasrin</first><last>Mostafazadeh</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url hash="dce2e295">N19-4000</url>
      <bibkey>naacl-2019-2019-north-american-chapter</bibkey>
    </frontmatter>
    <paper id="2">
      <title>ADIDA : Automatic Dialect Identification for <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a><fixed-case>ADIDA</fixed-case>: Automatic Dialect Identification for <fixed-case>A</fixed-case>rabic</title>
      <author><first>Ossama</first><last>Obeid</last></author>
      <author><first>Mohammad</first><last>Salameh</last></author>
      <author><first>Houda</first><last>Bouamor</last></author>
      <author><first>Nizar</first><last>Habash</last></author>
      <pages>6–11</pages>
      <abstract>This demo paper describes ADIDA, a web-based system for automatic dialect identification for <a href="https://en.wikipedia.org/wiki/Arabic_alphabet">Arabic text</a>. The system distinguishes among the dialects of 25 Arab cities (from Rabat to Muscat) in addition to Modern Standard <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a>. The results are presented with either a point map or a <a href="https://en.wikipedia.org/wiki/Heat_map">heat map</a> visualizing the automatic identification probabilities over a geographical map of the Arab World.</abstract>
      <url hash="816150f8">N19-4002</url>
      <doi>10.18653/v1/N19-4002</doi>
      <bibkey>obeid-etal-2019-adida</bibkey>
    </paper>
    <paper id="4">
      <title>INS : An Interactive Chinese News Synthesis System<fixed-case>INS</fixed-case>: An Interactive <fixed-case>C</fixed-case>hinese News Synthesis System</title>
      <author><first>Hui</first><last>Liu</last></author>
      <author><first>Wentao</first><last>Qin</last></author>
      <author><first>Xiaojun</first><last>Wan</last></author>
      <pages>18–23</pages>
      <abstract>Nowadays, we are surrounded by more and more <a href="https://en.wikipedia.org/wiki/Online_newspaper">online news articles</a>. Tens or hundreds of <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a> need to be read if we wish to explore a hot news event or topic. So it is of vital importance to automatically synthesize a batch of <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a> related to the event or topic into a new synthesis article (or overview article) for reader’s convenience. It is so challenging to make news synthesis fully automatic that there is no successful solution by now. In this paper, we put forward a novel Interactive News Synthesis system (i.e. INS), which can help generate news overview articles automatically or by interacting with users. More importantly, <a href="https://en.wikipedia.org/wiki/Immigration_and_Naturalization_Service">INS</a> can serve as a tool for editors to help them finish their jobs. In our experiments, INS performs well on both <a href="https://en.wikipedia.org/wiki/Topic_and_comment">topic representation</a> and synthesis article generation. A <a href="https://en.wikipedia.org/wiki/User_study">user study</a> also demonstrates the usefulness and users’ satisfaction with the INS tool. A demo video is available at.<url>https://youtu.be/7ItteKW3GEk</url>.</abstract>
      <url hash="faf39700">N19-4004</url>
      <doi>10.18653/v1/N19-4004</doi>
      <bibkey>liu-etal-2019-ins</bibkey>
    </paper>
    <paper id="6">
      <title>Train, Sort, Explain : Learning to Diagnose Translation Models</title>
      <author><first>Robert</first><last>Schwarzenberg</last></author>
      <author><first>David</first><last>Harbecke</last></author>
      <author><first>Vivien</first><last>Macketanz</last></author>
      <author><first>Eleftherios</first><last>Avramidis</last></author>
      <author><first>Sebastian</first><last>Möller</last></author>
      <pages>29–34</pages>
      <abstract>Evaluating translation models is a trade-off between effort and detail. On the one end of the spectrum there are automatic count-based methods such as <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a>, on the other end linguistic evaluations by humans, which arguably are more informative but also require a disproportionately high effort. To narrow the spectrum, we propose a general approach on how to automatically expose systematic differences between human and machine translations to human experts. Inspired by <a href="https://en.wikipedia.org/wiki/Adversarial_system">adversarial settings</a>, we train a neural text classifier to distinguish human from machine translations. A <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> that performs and generalizes well after training should recognize systematic differences between the two classes, which we uncover with neural explainability methods. Our proof-of-concept implementation, DiaMaT, is open source. Applied to a dataset translated by a state-of-the-art neural Transformer model, DiaMaT achieves a classification accuracy of 75 % and exposes meaningful differences between humans and the Transformer, amidst the current discussion about human parity.</abstract>
      <url hash="72fffab5">N19-4006</url>
      <doi>10.18653/v1/N19-4006</doi>
      <bibkey>schwarzenberg-etal-2019-train</bibkey>
      <pwccode url="https://github.com/dfki-nlp/diamat" additional="false">dfki-nlp/diamat</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2014">WMT 2014</pwcdataset>
    </paper>
    <paper id="12">
      <title>LeafNATS : An Open-Source Toolkit and Live Demo System for Neural Abstractive Text Summarization<fixed-case>L</fixed-case>eaf<fixed-case>NATS</fixed-case>: An Open-Source Toolkit and Live Demo System for Neural Abstractive Text Summarization</title>
      <author><first>Tian</first><last>Shi</last></author>
      <author><first>Ping</first><last>Wang</last></author>
      <author><first>Chandan K.</first><last>Reddy</last></author>
      <pages>66–71</pages>
      <abstract>Neural abstractive text summarization (NATS) has received a lot of attention in the past few years from both industry and academia. In this paper, we introduce an open-source toolkit, namely LeafNATS, for training and evaluation of different sequence-to-sequence based models for the NATS task, and for deploying the pre-trained models to real-world applications. The <a href="https://en.wikipedia.org/wiki/List_of_toolkits">toolkit</a> is modularized and extensible in addition to maintaining competitive performance in the NATS task. A live news blogging system has also been implemented to demonstrate how these models can aid blog / news editors by providing them suggestions of headlines and summaries of their articles.</abstract>
      <url hash="33a322d7">N19-4012</url>
      <doi>10.18653/v1/N19-4012</doi>
      <bibkey>shi-etal-2019-leafnats</bibkey>
      <pwccode url="https://github.com/tshi04/LeafNATS" additional="false">tshi04/LeafNATS</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/newsroom">NEWSROOM</pwcdataset>
    </paper>
    <paper id="14">
      <title>FAKTA : An Automatic End-to-End Fact Checking System<fixed-case>FAKTA</fixed-case>: An Automatic End-to-End Fact Checking System</title>
      <author><first>Moin</first><last>Nadeem</last></author>
      <author><first>Wei</first><last>Fang</last></author>
      <author><first>Brian</first><last>Xu</last></author>
      <author><first>Mitra</first><last>Mohtarami</last></author>
      <author><first>James</first><last>Glass</last></author>
      <pages>78–83</pages>
      <abstract>We present FAKTA which is a unified framework that integrates various components of a fact-checking process : document retrieval from media sources with various types of reliability, stance detection of documents with respect to given claims, evidence extraction, and linguistic analysis. FAKTA predicts the factuality of given claims and provides evidence at the document and sentence level to explain its predictions.</abstract>
      <url hash="b9a3d462">N19-4014</url>
      <doi>10.18653/v1/N19-4014</doi>
      <bibkey>nadeem-etal-2019-fakta</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/fever">FEVER</pwcdataset>
    </paper>
    <paper id="16">
      <title>Plan, Write, and Revise : an Interactive System for Open-Domain Story Generation</title>
      <author><first>Seraphina</first><last>Goldfarb-Tarrant</last></author>
      <author><first>Haining</first><last>Feng</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <pages>89–97</pages>
      <abstract>Story composition is a challenging problem for machines and even for humans. We present a neural narrative generation system that interacts with humans to generate stories. Our system has different levels of human interaction, which enables us to understand at what stage of story-writing human collaboration is most productive, both to improving story quality and human engagement in the writing process. We compare different varieties of interaction in story-writing, story-planning, and diversity controls under time constraints, and show that increased types of human collaboration at both planning and writing stages results in a 10-50 % improvement in story quality as compared to less interactive baselines. We also show an accompanying increase in user engagement and satisfaction with stories as compared to our own less interactive systems and to previous turn-taking approaches to <a href="https://en.wikipedia.org/wiki/Interaction">interaction</a>. Finally, we find that humans tasked with collaboratively improving a particular characteristic of a story are in fact able to do so, which has implications for future uses of human-in-the-loop systems.</abstract>
      <url hash="3cd824d3">N19-4016</url>
      <doi>10.18653/v1/N19-4016</doi>
      <bibkey>goldfarb-tarrant-etal-2019-plan</bibkey>
      <pwccode url="https://github.com/seraphinatarrant/plan-write-revise" additional="false">seraphinatarrant/plan-write-revise</pwccode>
    </paper>
    <paper id="17">
      <title>LT Expertfinder : An Evaluation Framework for Expert Finding Methods<fixed-case>LT</fixed-case> Expertfinder: An Evaluation Framework for Expert Finding Methods</title>
      <author><first>Tim</first><last>Fischer</last></author>
      <author><first>Steffen</first><last>Remus</last></author>
      <author><first>Chris</first><last>Biemann</last></author>
      <pages>98–104</pages>
      <abstract>Expert finding is the task of ranking persons for a predefined topic or search query. Finding experts for a specified area is an important task and has attracted much attention in the <a href="https://en.wikipedia.org/wiki/Information_retrieval">information retrieval community</a>. Most approaches for this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> are evaluated in a supervised fashion, which depend on predefined topics of interest as well as gold standard expert rankings. Famous representatives of such datasets are enriched versions of <a href="https://en.wikipedia.org/wiki/DBLP">DBLP</a> provided by the ArnetMiner projet or the W3C Corpus of TREC. However, manually ranking experts can be considered highly subjective and detailed rankings are hardly distinguishable. Evaluating these <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> does not necessarily guarantee a good or bad performance of the <a href="https://en.wikipedia.org/wiki/System">system</a>. Particularly for <a href="https://en.wikipedia.org/wiki/Dynamical_system">dynamic systems</a>, where topics are not predefined but formulated as a <a href="https://en.wikipedia.org/wiki/Web_search_query">search query</a>, we believe a more informative approach is to perform <a href="https://en.wikipedia.org/wiki/User_study">user studies</a> for directly comparing different methods in the same view. In order to accomplish this in a user-friendly way, we present the LT Expert Finder web-application, which is equipped with various query-based expert finding methods that can be easily extended, a detailed expert profile view, detailed evidence in form of relevant documents and statistics, and an evaluation component that allows the qualitative comparison between different rankings.</abstract>
      <url hash="90cc02dd">N19-4017</url>
      <doi>10.18653/v1/N19-4017</doi>
      <bibkey>fischer-etal-2019-lt</bibkey>
      <pwccode url="https://github.com/uhh-lt/lt-expertfinder" additional="false">uhh-lt/lt-expertfinder</pwccode>
    </paper>
    <paper id="20">
      <title>Litigation Analytics : Extracting and querying motions and orders from US federal courts<fixed-case>US</fixed-case> federal courts</title>
      <author><first>Thomas</first><last>Vacek</last></author>
      <author><first>Dezhao</first><last>Song</last></author>
      <author><first>Hugo</first><last>Molina-Salgado</last></author>
      <author><first>Ronald</first><last>Teo</last></author>
      <author><first>Conner</first><last>Cowling</last></author>
      <author><first>Frank</first><last>Schilder</last></author>
      <pages>116–121</pages>
      <abstract>Legal litigation planning can benefit from statistics collected from past decisions made by judges. Information on the typical duration for a submitted motion, for example, can give valuable clues for developing a successful <a href="https://en.wikipedia.org/wiki/Strategy">strategy</a>. Such information is encoded in semi-structured documents called dockets. In order to extract and aggregate this information, we deployed various <a href="https://en.wikipedia.org/wiki/Information_extraction">information extraction</a> and machine learning techniques. The aggregated data can be queried in real time within the Westlaw Edge search engine. In addition to a <a href="https://en.wikipedia.org/wiki/Keyword_search">keyword search</a> for <a href="https://en.wikipedia.org/wiki/Judge">judges</a>, <a href="https://en.wikipedia.org/wiki/Lawyer">lawyers</a>, <a href="https://en.wikipedia.org/wiki/Law_firm">law firms</a>, parties and courts, we also implemented a question answering interface that offers targeted questions in order to get to the respective answers quicker.</abstract>
      <url hash="4f3c775f">N19-4020</url>
      <doi>10.18653/v1/N19-4020</doi>
      <bibkey>vacek-etal-2019-litigation</bibkey>
    </paper>
    <paper id="23">
      <title>A Research Platform for Multi-Robot Dialogue with Humans<fixed-case>R</fixed-case>esearch <fixed-case>P</fixed-case>latform for <fixed-case>M</fixed-case>ulti-<fixed-case>R</fixed-case>obot <fixed-case>D</fixed-case>ialogue with <fixed-case>H</fixed-case>umans</title>
      <author><first>Matthew</first><last>Marge</last></author>
      <author><first>Stephen</first><last>Nogar</last></author>
      <author><first>Cory J.</first><last>Hayes</last></author>
      <author><first>Stephanie M.</first><last>Lukin</last></author>
      <author><first>Jesse</first><last>Bloecker</last></author>
      <author><first>Eric</first><last>Holder</last></author>
      <author><first>Clare</first><last>Voss</last></author>
      <pages>132–137</pages>
      <abstract>This paper presents a <a href="https://en.wikipedia.org/wiki/Computing_platform">research platform</a> that supports spoken dialogue interaction with multiple robots. The demonstration showcases our crafted MultiBot testing scenario in which users can verbally issue search, navigate, and follow instructions to two robotic teammates : a simulated ground robot and an <a href="https://en.wikipedia.org/wiki/Autonomous_robot">aerial robot</a>. This flexible language and robotic platform takes advantage of existing tools for <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech recognition</a> and dialogue management that are compatible with new domains, and implements an inter-agent communication protocol (tactical behavior specification), where verbal instructions are encoded for tasks assigned to the appropriate robot.</abstract>
      <url hash="7d39e661">N19-4023</url>
      <doi>10.18653/v1/N19-4023</doi>
      <bibkey>marge-etal-2019-research</bibkey>
    </paper>
    <paper id="24">
      <title>Chat-crowd : A Dialog-based Platform for Visual Layout Composition</title>
      <author><first>Paola</first><last>Cascante-Bonilla</last></author>
      <author><first>Xuwang</first><last>Yin</last></author>
      <author><first>Vicente</first><last>Ordonez</last></author>
      <author><first>Song</first><last>Feng</last></author>
      <pages>138–142</pages>
      <abstract>In this paper we introduce Chat-crowd, an interactive environment for visual layout composition via conversational interactions. Chat-crowd supports multiple agents with two conversational roles : agents who play the role of a designer are in charge of placing objects in an editable canvas according to instructions or commands issued by agents with a director role. The system can be integrated with <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourcing platforms</a> for both synchronous and asynchronous data collection and is equipped with comprehensive <a href="https://en.wikipedia.org/wiki/Quality_control">quality controls</a> on the performance of both types of <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agents</a>. We expect that this system will be useful to build multimodal goal-oriented dialog tasks that require spatial and geometric reasoning.</abstract>
      <url hash="3545aa22">N19-4024</url>
      <doi>10.18653/v1/N19-4024</doi>
      <bibkey>cascante-bonilla-etal-2019-chat</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/shapes-1">SHAPES</pwcdataset>
    </paper>
  </volume>
  <volume id="5">
    <meta>
      <booktitle>Proceedings of the 2019 Conference of the North <fixed-case>A</fixed-case>merican Chapter of the Association for Computational Linguistics: Tutorials</booktitle>
      <url hash="cf258c60">N19-5</url>
      <editor><first>Anoop</first><last>Sarkar</last></editor>
      <editor><first>Michael</first><last>Strube</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url hash="2247bda9">N19-5000</url>
      <bibkey>naacl-2019-2019-north-american-chapter-association</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Deep Adversarial Learning for <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP</a><fixed-case>NLP</fixed-case></title>
      <author><first>William Yang</first><last>Wang</last></author>
      <author><first>Sameer</first><last>Singh</last></author>
      <author><first>Jiwei</first><last>Li</last></author>
      <pages>1–5</pages>
      <abstract>Adversarial learning is a game-theoretic learning paradigm, which has achieved huge successes in the field of <a href="https://en.wikipedia.org/wiki/Computer_vision">Computer Vision</a> recently. Adversarial learning is also a general framework that enables a variety of learning models, including the popular Generative Adversarial Networks (GANs). Due to the discrete nature of language, designing adversarial learning models is still challenging for NLP problems. In this tutorial, we provide a gentle introduction to the foundation of deep adversarial learning, as well as some practical problem formulations and solutions in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>. We describe recent advances in deep adversarial learning for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>, with a special focus on generation, adversarial examples &amp; rules, and <a href="https://en.wikipedia.org/wiki/Dialogue">dialogue</a>. We provide an overview of the research area, categorize different types of <a href="https://en.wikipedia.org/wiki/Adversarial_learning">adversarial learning models</a>, and discuss pros and cons, aiming at providing some practical perspectives on the future of <a href="https://en.wikipedia.org/wiki/Adversarial_learning">adversarial learning</a> for solving real-world NLP problems.</abstract>
      <url hash="ca3736db">N19-5001</url>
      <attachment type="presentation" hash="e2938f40">N19-5001.Presentation.pdf</attachment>
      <doi>10.18653/v1/N19-5001</doi>
      <video href="https://vimeo.com/359555654" />
      <bibkey>wang-etal-2019-deep</bibkey>
    </paper>
    <paper id="3">
      <title>Measuring and Modeling Language Change</title>
      <author><first>Jacob</first><last>Eisenstein</last></author>
      <pages>9–14</pages>
      <abstract>This tutorial is designed to help researchers answer the following sorts of questions :-Are people happier on the weekend?-What was 1861’s word of the year?-Are Democrats and Republicans more different than ever?-When did gay stop meaning happy?-Are <a href="https://en.wikipedia.org/wiki/Gender_role">gender stereotypes</a> getting weaker, stronger, or just different?-Who is a linguistic leader?-How can we get internet users to be more polite and objective? Such questions are fundamental to the <a href="https://en.wikipedia.org/wiki/Social_science">social sciences</a> and humanities, and scholars in these disciplines are increasingly turning to <a href="https://en.wikipedia.org/wiki/Computational_science">computational techniques</a> for answers. Meanwhile, the ACL community is increasingly engaged with data that varies across time, and with the social insights that can be offered by analyzing temporal patterns and trends. The purpose of this tutorial is to facilitate this convergence in two main ways : 1. By synthesizing recent <a href="https://en.wikipedia.org/wiki/Computational_science">computational techniques</a> for handling and modeling <a href="https://en.wikipedia.org/wiki/Temporal_database">temporal data</a>, such as dynamic word embeddings, the tutorial will provide a starting point for future <a href="https://en.wikipedia.org/wiki/Computational_science">computational research</a>. It will also identify useful tools for <a href="https://en.wikipedia.org/wiki/Social_science">social scientists</a> and <a href="https://en.wikipedia.org/wiki/Digital_humanities">digital humanities scholars</a>. The tutorial will provide an overview of techniques and <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> from the quantitative social sciences and the <a href="https://en.wikipedia.org/wiki/Digital_humanities">digital humanities</a>, which are not well-known in the <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational linguistics community</a>. These techniques include <a href="https://en.wikipedia.org/wiki/Vector_autoregressive_model">vector autoregressive models</a>, multiple comparisons corrections for <a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing">hypothesis testing</a>, and <a href="https://en.wikipedia.org/wiki/Causal_inference">causal inference</a>. Datasets include historical newspaper archives and corpora of contemporary political speech.</abstract>
      <url hash="10d3e969">N19-5003</url>
      <attachment type="presentation" hash="4c1bbe48">N19-5003.Presentation.pdf</attachment>
      <doi>10.18653/v1/N19-5003</doi>
      <video href="https://vimeo.com/347475879" />
      <bibkey>eisenstein-2019-measuring</bibkey>
    </paper>
    </volume>
</collection>