<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.smm4h">
  <volume id="1" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the Fifth Social Media Mining for Health Applications Workshop &amp; Shared Task</booktitle>
      <editor><first>Graciela</first><last>Gonzalez-Hernandez</last></editor>
      <editor><first>Ari Z.</first><last>Klein</last></editor>
      <editor><first>Ivan</first><last>Flores</last></editor>
      <editor><first>Davy</first><last>Weissenbacher</last></editor>
      <editor><first>Arjun</first><last>Magge</last></editor>
      <editor><first>Karen</first><last>O'Connor</last></editor>
      <editor><first>Abeed</first><last>Sarker</last></editor>
      <editor><first>Anne-Lyse</first><last>Minard</last></editor>
      <editor><first>Elena</first><last>Tutubalina</last></editor>
      <editor><first>Zulfat</first><last>Miftahutdinov</last></editor>
      <editor><first>Ilseyar</first><last>Alimova</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Barcelona, Spain (Online)</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="d0fb857f">2020.smm4h-1.0</url>
      <bibkey>smm4h-2020-social</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Conversation-Aware Filtering of Online Patient Forum Messages</title>
      <author><first>Anne</first><last>Dirkson</last></author>
      <author><first>Suzan</first><last>Verberne</last></author>
      <author><first>Wessel</first><last>Kraaij</last></author>
      <pages>11–18</pages>
      <abstract>Previous approaches to NLP tasks on online patient forums have been limited to single posts as units, thereby neglecting the overarching conversational structure. In this paper we explore the benefit of exploiting <a href="https://en.wikipedia.org/wiki/Context_(language_use)">conversational context</a> for filtering posts relevant to a specific <a href="https://en.wikipedia.org/wiki/Medicine">medical topic</a>. We experiment with two approaches to add conversational context to a BERT model : a sequential CRF layer and manually engineered features. Although neither approach can outperform the F1 score of the BERT baseline, we find that adding a sequential layer improves <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">precision</a> for all target classes whereas adding a non-sequential layer with manually engineered features leads to a higher <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">recall</a> for two out of three target classes. Thus, depending on the end goal, conversation-aware modelling may be beneficial for identifying relevant messages. We hope our findings encourage other researchers in this domain to move beyond studying messages in isolation towards more discourse-based data collection and classification. We release our code for the purpose of follow-up research.</abstract>
      <url hash="dfb0c9ed">2020.smm4h-1.2</url>
      <bibkey>dirkson-etal-2020-conversation</bibkey>
    </paper>
    <paper id="4">
      <title>Overview of the Fifth <a href="https://en.wikipedia.org/wiki/Social_media_mining">Social Media Mining</a> for Health Applications (# SMM4H) Shared Tasks at COLING 2020<fixed-case>SMM</fixed-case>4<fixed-case>H</fixed-case>) Shared Tasks at <fixed-case>COLING</fixed-case> 2020</title>
      <author><first>Ari</first><last>Klein</last></author>
      <author><first>Ilseyar</first><last>Alimova</last></author>
      <author><first>Ivan</first><last>Flores</last></author>
      <author><first>Arjun</first><last>Magge</last></author>
      <author><first>Zulfat</first><last>Miftahutdinov</last></author>
      <author><first>Anne-Lyse</first><last>Minard</last></author>
      <author><first>Karen</first><last>O’Connor</last></author>
      <author><first>Abeed</first><last>Sarker</last></author>
      <author><first>Elena</first><last>Tutubalina</last></author>
      <author><first>Davy</first><last>Weissenbacher</last></author>
      <author><first>Graciela</first><last>Gonzalez-Hernandez</last></author>
      <pages>27–36</pages>
      <abstract>The vast amount of data on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> presents significant opportunities and challenges for utilizing <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> as a resource for <a href="https://en.wikipedia.org/wiki/Health_informatics">health informatics</a>. The fifth iteration of the Social Media Mining for Health Applications (# SMM4H) shared tasks sought to advance the use of Twitter data (tweets) for <a href="https://en.wikipedia.org/wiki/Pharmacovigilance">pharmacovigilance</a>, <a href="https://en.wikipedia.org/wiki/Toxicovigilance">toxicovigilance</a>, and epidemiology of birth defects. In addition to re-runs of three tasks, # SMM4H 2020 included new tasks for detecting adverse effects of medications in French and Russian tweets, characterizing chatter related to prescription medication abuse, and detecting self reports of birth defect pregnancy outcomes. The five tasks required methods for <a href="https://en.wikipedia.org/wiki/Binary_classification">binary classification</a>, multi-class classification, and named entity recognition (NER). With 29 teams and a total of 130 system submissions, participation in the # SMM4H shared tasks continues to grow.</abstract>
      <url hash="d466597e">2020.smm4h-1.4</url>
      <bibkey>klein-etal-2020-overview</bibkey>
    </paper>
    <paper id="5">
      <title>Ensemble BERT for Classifying Medication-mentioning Tweets<fixed-case>BERT</fixed-case> for Classifying Medication-mentioning Tweets</title>
      <author><first>Huong</first><last>Dang</last></author>
      <author><first>Kahyun</first><last>Lee</last></author>
      <author><first>Sam</first><last>Henry</last></author>
      <author><first>Özlem</first><last>Uzuner</last></author>
      <pages>37–41</pages>
      <abstract>Twitter is a valuable source of patient-generated data that has been used in various <a href="https://en.wikipedia.org/wiki/Population_study">population health studies</a>. The first step in many of these studies is to identify and capture Twitter messages (tweets) containing medication mentions. In this article, we describe our submission to Task 1 of the Social Media Mining for Health Applications (SMM4H) Shared Task 2020. This task challenged participants to detect tweets that mention <a href="https://en.wikipedia.org/wiki/Medication">medications</a> or <a href="https://en.wikipedia.org/wiki/Dietary_supplement">dietary supplements</a> in a natural, highly imbalance dataset. Our system combined a handcrafted preprocessing step with an ensemble of 20 BERT-based classifiers generated by dividing the training dataset into subsets using 10-fold cross validation and exploiting two BERT embedding models. Our system ranked first in this task, and improved the average F1 score across all participating teams by 19.07 % with a precision, <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall</a>, and <a href="https://en.wikipedia.org/wiki/F-number">F1</a> on the test set of 83.75 %, 87.01 %, and 85.35 % respectively.</abstract>
      <url hash="9ec7fef8">2020.smm4h-1.5</url>
      <bibkey>dang-etal-2020-ensemble</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/smm4h">SMM4H</pwcdataset>
    </paper>
    <paper id="9">
      <title>SMM4H Shared Task 2020-A Hybrid Pipeline for Identifying Prescription Drug Abuse from Twitter : <a href="https://en.wikipedia.org/wiki/Machine_learning">Machine Learning</a>, <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a>, and Post-Processing<fixed-case>SMM</fixed-case>4<fixed-case>H</fixed-case> Shared Task 2020 - A Hybrid Pipeline for Identifying Prescription Drug Abuse from <fixed-case>T</fixed-case>witter: Machine Learning, Deep Learning, and Post-Processing</title>
      <author><first>Isabel</first><last>Metzger</last></author>
      <author><first>Emir Y.</first><last>Haskovic</last></author>
      <author><first>Allison</first><last>Black</last></author>
      <author><first>Whitley M.</first><last>Yi</last></author>
      <author><first>Rajat S.</first><last>Chandra</last></author>
      <author><first>Mark T.</first><last>Rutledge</last></author>
      <author><first>William</first><last>McMahon</last></author>
      <author><first>Yindalon</first><last>Aphinyanaphongs</last></author>
      <pages>57–62</pages>
      <abstract>This paper presents our approach to multi-class text categorization of <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> mentioning prescription medications as being indicative of potential abuse / misuse (A), consumption / non-abuse (C), mention-only (M), or an unrelated reference (U) using natural language processing techniques. Data augmentation increased our <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training and validation corpora</a> from 13,172 tweets to 28,094 tweets. We also created word-embeddings on domain-specific social media and medical corpora. Our hybrid pipeline of an attention-based CNN with <a href="https://en.wikipedia.org/wiki/Post-processing">post-processing</a> was the best performing system in task 4 of SMM4H 2020, with an <a href="https://en.wikipedia.org/wiki/F-number">F1 score</a> of 0.51 for class A.</abstract>
      <url hash="4146f152">2020.smm4h-1.9</url>
      <bibkey>metzger-etal-2020-smm4h</bibkey>
    </paper>
    <paper id="14">
      <title>How Far Can We Go with Just Out-of-the-box BERT Models?<fixed-case>BERT</fixed-case> Models?</title>
      <author><first>Lucie</first><last>Gattepaille</last></author>
      <pages>95–100</pages>
      <abstract>Social media have been seen as a promising data source for <a href="https://en.wikipedia.org/wiki/Pharmacovigilance">pharmacovigilance</a>. Howev-er, methods for automatic extraction of Adverse Drug Reactions from social media plat-forms such as <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> still need further development before they can be included reliably in routine pharmacovigilance practices. As the Bidirectional Encoder Representations from Transformer (BERT) models have shown great performance in many major NLP tasks recently, we decided to test its performance on the SMM4H Shared Tasks 1 to 3, by submitting results of pretrained and fine-tuned BERT models without more added knowledge than the one carried in the training datasets and additional datasets. Our three submissions all ended up above average over all teams’ submissions : 0.766 F1 for task 1 (15 % above the average of 0.665), 0.47 F1 for task 2 (2 % above the average of 0.46) and 0.380 F1 score for task 3 (30 % above the average of 0.292). Used in many of the high-ranking submission in the 2019 edition of the SMM4H Shared Task, BERT contin-ues to be state-of-the-art in ADR extraction for Twitter data.</abstract>
      <url hash="40170bbc">2020.smm4h-1.14</url>
      <bibkey>gattepaille-2020-far</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/smm4h">SMM4H</pwcdataset>
    </paper>
    <paper id="15">
      <title>FBK@SMM4H2020 : RoBERTa for Detecting Medications on Twitter<fixed-case>FBK</fixed-case>@<fixed-case>SMM</fixed-case>4<fixed-case>H</fixed-case>2020: <fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a for Detecting Medications on <fixed-case>T</fixed-case>witter</title>
      <author><first>Silvia</first><last>Casola</last></author>
      <author><first>Alberto</first><last>Lavelli</last></author>
      <pages>101–103</pages>
      <abstract>This paper describes a classifier for tweets that mention medications or supplements, based on a pretrained transformer. We developed such a system for our participation in Subtask 1 of the Social Media Mining for Health Application workshop, which featured an extremely unbalanced dataset. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> showed promising results, with an F1 of 0.8 (task mean : 0.66).</abstract>
      <url hash="72711b9e">2020.smm4h-1.15</url>
      <bibkey>casola-lavelli-2020-fbk</bibkey>
    </paper>
    <paper id="16">
      <title>Autobots Ensemble : Identifying and Extracting Adverse Drug Reaction from Tweets Using Transformer Based Pipelines</title>
      <author><first>Sougata</first><last>Saha</last></author>
      <author><first>Souvik</first><last>Das</last></author>
      <author><first>Prashi</first><last>Khurana</last></author>
      <author><first>Rohini</first><last>Srihari</last></author>
      <pages>104–109</pages>
      <abstract>This paper details a <a href="https://en.wikipedia.org/wiki/System">system</a> designed for Social Media Mining for Health Applications (SMM4H) Shared Task 2020. We specifically describe the systems designed to solve task 2 : Automatic classification of multilingual tweets that report adverse effects, and task 3 : Automatic extraction and normalization of adverse effects in English tweets. Fine tuning RoBERTa large for classifying English tweets enables us to achieve a F1 score of 56 %, which is an increase of +10 % compared to the average F1 score for all the submissions. Using BERT based NER and question answering, we are able to achieve a F1 score of 57.6 % for extracting adverse reaction mentions from tweets, which is an increase of +1.2 % compared to the average F1 score for all the submissions.</abstract>
      <url hash="381beedf">2020.smm4h-1.16</url>
      <bibkey>saha-etal-2020-autobots</bibkey>
    </paper>
    <paper id="19">
      <title>SpeechTrans@SMM4H’20 : Impact of Preprocessing and N-grams on Automatic Classification of Tweets That Mention Medications<fixed-case>S</fixed-case>peech<fixed-case>T</fixed-case>rans@<fixed-case>SMM</fixed-case>4<fixed-case>H</fixed-case>’20: Impact of Preprocessing and N-grams on Automatic Classification of Tweets That Mention Medications</title>
      <author><first>Mohamed</first><last>Lichouri</last></author>
      <author><first>Mourad</first><last>Abbas</last></author>
      <pages>118–120</pages>
      <abstract>This paper describes our <a href="https://en.wikipedia.org/wiki/System">system</a> developed for automatically classifying tweets that mention medications. We used the <a href="https://en.wikipedia.org/wiki/Decision_tree_learning">Decision Tree classifier</a> for this <a href="https://en.wikipedia.org/wiki/Task_(computing)">task</a>. We have shown that using some elementary preprocessing steps and TF-IDF n-grams led to acceptable <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> performance. Indeed, the F1-score recorded was 74.58 % in the development phase and 63.70 % in the test phase.</abstract>
      <url hash="de11e720">2020.smm4h-1.19</url>
      <bibkey>lichouri-abbas-2020-speechtrans</bibkey>
    </paper>
    <paper id="20">
      <title>Want to Identify, Extract and Normalize Adverse Drug Reactions in Tweets? Use RoBERTa<fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a</title>
      <author><first>Katikapalli Subramanyam</first><last>Kalyan</last></author>
      <author><first>Sivanesan</first><last>Sangeetha</last></author>
      <pages>121–124</pages>
      <abstract>This paper presents our approach for task 2 and task 3 of Social Media Mining for Health (SMM4H) 2020 shared tasks. In task 2, we have to differentiate adverse drug reaction (ADR) tweets from nonADR tweets and is treated as <a href="https://en.wikipedia.org/wiki/Binary_classification">binary classification</a>. Task 3 involves extracting ADR mentions and then mapping them to MedDRA codes. Extracting ADR mentions is treated as sequence labeling and normalizing ADR mentions is treated as multi-class classification. Our system is based on pre-trained language model RoBERTa and it achieves a) F1-score of 58 % in task 2 which is 12 % more than the average score b) relaxed F1-score of 70.1 % in ADR extraction of task 3 which is 13.7 % more than the average score and relaxed F1-score of 35 % in ADR extraction + normalization of task 3 which is 5.8 % more than the average score. Overall, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> achieve promising results in both the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> with significant improvements over average scores.</abstract>
      <url hash="d62e8cc7">2020.smm4h-1.20</url>
      <bibkey>kalyan-sangeetha-2020-want</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/smm4h">SMM4H</pwcdataset>
    </paper>
    <paper id="21">
      <title>Detecting Tweets Reporting Birth Defect Pregnancy Outcome Using Two-View CNN RNN Based Architecture<fixed-case>CNN</fixed-case> <fixed-case>RNN</fixed-case> Based Architecture</title>
      <author><first>Saichethan</first><last>Reddy</last></author>
      <pages>125–127</pages>
      <abstract>This research work addresses a new multi-class classification task (fifth task) provided at the fifth Social Media Mining for Health Applications (SMM4H) workshop. This automatic tweet classification task involves distinguishing three classes of tweets that mention <a href="https://en.wikipedia.org/wiki/Birth_defect">birth defects</a>. We propose a novel two view based CNN-BiGRU based architectures for this <a href="https://en.wikipedia.org/wiki/Task_(computing)">task</a>. Experimental evaluation of our proposed <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> over the validation set gives encouraging results as it improves by approximately 7 % over our single view model for the fifth task. Code of our proposed <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> is made available on Github</abstract>
      <url hash="69d81814">2020.smm4h-1.21</url>
      <bibkey>reddy-2020-detecting</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/smm4h">SMM4H</pwcdataset>
    </paper>
    <paper id="24">
      <title>LITL at SMM4H : An Old-school Feature-based Classifier for Identifying Adverse Effects in Tweets<fixed-case>LITL</fixed-case> at <fixed-case>SMM</fixed-case>4<fixed-case>H</fixed-case>: An Old-school Feature-based Classifier for Identifying Adverse Effects in Tweets</title>
      <author><first>Ludovic</first><last>Tanguy</last></author>
      <author><first>Lydia-Mai</first><last>Ho-Dac</last></author>
      <author><first>Cécile</first><last>Fabre</last></author>
      <author><first>Roxane</first><last>Bois</last></author>
      <author><first>Touati Mohamed Yacine</first><last>Haddad</last></author>
      <author><first>Claire</first><last>Ibarboure</last></author>
      <author><first>Marie</first><last>Joyau</last></author>
      <author><first>François</first><last>Le moal</last></author>
      <author><first>Jade</first><last>Moiilic</last></author>
      <author><first>Laura</first><last>Roudaut</last></author>
      <author><first>Mathilde</first><last>Simounet</last></author>
      <author><first>Irena</first><last>Stankovic</last></author>
      <author><first>Mickaela</first><last>Vandewaetere</last></author>
      <pages>134–137</pages>
      <abstract>This paper describes our participation to the SMM4H shared task 2. We designed a rule-based classifier that estimates whether a tweet mentions an adverse effect associated to a medication. Our system addresses <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/French_language">French</a>, and is based on a number of specific word lists and features. These cues were mostly obtained through an extensive corpus analysis of the provided training data. Different <a href="https://en.wikipedia.org/wiki/Weighting">weighting schemes</a> were tested (manually tuned or based on a logistic regression), the best one achieving a <a href="https://en.wikipedia.org/wiki/F-number">F1 score</a> of 0.31 for <a href="https://en.wikipedia.org/wiki/English_language">English</a> and 0.15 for <a href="https://en.wikipedia.org/wiki/French_language">French</a>.</abstract>
      <url hash="8776f27d">2020.smm4h-1.24</url>
      <bibkey>tanguy-etal-2020-litl</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/smm4h">SMM4H</pwcdataset>
    </paper>
    <paper id="25">
      <title>Sentence Classification with Imbalanced Data for Health Applications</title>
      <author><first>Farhana Ferdousi</first><last>Liza</last></author>
      <pages>138–145</pages>
      <abstract>Identifying and extracting reports of medications, their abuse or adverse effects from <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> is a challenging task. In <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>, relevant reports are very infrequent, causes imbalanced class distribution for <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning algorithms</a>. Learning algorithms typically designed to optimize the overall accuracy without considering the relative distribution of each class. Thus, imbalanced class distribution is problematic as <a href="https://en.wikipedia.org/wiki/Machine_learning">learning algorithms</a> have low predictive accuracy for the infrequent class. Moreover, <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> represents natural linguistic variation in creative language expressions. In this paper, we have used a combination of data balancing and neural language representation techniques to address the challenges. Specifically, we participated the shared tasks 1, 2 (all languages), 4, and 3 (only the span detection, no normalization was attempted) in Social Media Mining for Health applications (SMM4H) 2020 (Klein et al., 2020). The results show that with the proposed methodology <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall scores</a> are better than the precision scores for the shared tasks. The <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall score</a> is also better compared to the mean score of the total submissions. However, the F1-score is worse than the mean score except for task 2 (French).</abstract>
      <url hash="5f506409">2020.smm4h-1.25</url>
      <bibkey>liza-2020-sentence</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/smm4h">SMM4H</pwcdataset>
    </paper>
    <paper id="31">
      <title>Sentence Contextual Encoder with BERT and BiLSTM for Automatic Classification with Imbalanced Medication Tweets<fixed-case>BERT</fixed-case> and <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case> for Automatic Classification with Imbalanced Medication Tweets</title>
      <author><first>Olanrewaju Tahir</first><last>Aduragba</last></author>
      <author><first>Jialin</first><last>Yu</last></author>
      <author><first>Gautham</first><last>Senthilnathan</last></author>
      <author><first>Alexandra</first><last>Crsitea</last></author>
      <pages>165–167</pages>
      <abstract>This paper details the system description and approach used by our team for the SMM4H 2020 competition, Task 1. Task 1 targets the automatic classification of tweets that mention medication. We adapted the standard BERT pretrain-then-fine-tune approach to include an intermediate training stage with a biLSTM architecture neural network acting as a further fine-tuning stage. We were inspired by the effectiveness of within-task further pre-training and sentence encoders. We show that this approach works well for a highly imbalanced dataset. In this case, the positive class is only 0.2 % of the entire dataset. Our model performed better in both F1 and precision scores compared to the mean score for all participants in the competition and had a competitive recall score.</abstract>
      <url hash="fd8de0a9">2020.smm4h-1.31</url>
      <bibkey>aduragba-etal-2020-sentence</bibkey>
    </paper>
    </volume>
</collection>