<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.internlp">
  <volume id="1" ingest-date="2021-07-25">
    <meta>
      <booktitle>Proceedings of the First Workshop on Interactive Learning for Natural Language Processing</booktitle>
      <editor><first>Kianté</first><last>Brantley</last></editor>
      <editor><first>Soham</first><last>Dan</last></editor>
      <editor><first>Iryna</first><last>Gurevych</last></editor>
      <editor><first>Ji-Ung</first><last>Lee</last></editor>
      <editor><first>Filip</first><last>Radlinski</last></editor>
      <editor><first>Hinrich</first><last>Schütze</last></editor>
      <editor><first>Edwin</first><last>Simpson</last></editor>
      <editor><first>Lili</first><last>Yu</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>August</month>
      <year>2021</year>
      <url hash="245ab163">2021.internlp-1</url>
    </meta>
    <frontmatter>
      <url hash="15b91d30">2021.internlp-1.0</url>
      <bibkey>internlp-2021-interactive</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Apple Core-dination : Linguistic Feedback and Learning in a Speech-to-Action Shared World Game</title>
      <author><first>Susann</first><last>Boy</last></author>
      <author><first>AriaRay</first><last>Brown</last></author>
      <author><first>Morgan</first><last>Wixted</last></author>
      <pages>7–15</pages>
      <abstract>We investigate the question of how adaptive feedback from a <a href="https://en.wikipedia.org/wiki/Virtual_agent">virtual agent</a> impacts the linguistic input of the user in a shared world game environment. To do so, we carry out an exploratory pilot study to observe how individualized linguistic feedback affects the user’s speech input. We introduce a speech-controlled game, Apple Core-dination, in which an agent learns complex tasks using a base knowledge of simple actions. The <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agent</a> is equipped with a <a href="https://en.wikipedia.org/wiki/Machine_learning">learning mechanism</a> for mapping new commands to sequences of simple actions, as well as the ability to incorporate <a href="https://en.wikipedia.org/wiki/User_(computing)">user input</a> into written responses. The <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agent</a> repeatedly shares its internal knowledge state by responding to what it knows and does not know about <a href="https://en.wikipedia.org/wiki/Meaning_(linguistics)">language meaning</a> and the shared environment. Our paper focuses on the linguistic feedback loop in order to analyze the nature of <a href="https://en.wikipedia.org/wiki/Input_(computer_science)">user input</a>. Feedback from the <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agent</a> is provided in the form of <a href="https://en.wikipedia.org/wiki/Motion">visual movement</a> and <a href="https://en.wikipedia.org/wiki/Writing">written linguistic responses</a>. Particular attention is given to incorporating user input into agent responses and updating the speech-to-action mappings based on commands provided by the user. Through our pilot study, we analyze task success and compare the <a href="https://en.wikipedia.org/wiki/Lexicon">lexical features</a> of user input. Results show variation in input length and <a href="https://en.wikipedia.org/wiki/Variety_(linguistics)">lexical variety</a> across users, suggesting a correlation between the two that can be studied further.</abstract>
      <url hash="6eeb0843">2021.internlp-1.2</url>
      <doi>10.18653/v1/2021.internlp-1.2</doi>
      <bibkey>boy-etal-2021-apple</bibkey>
    </paper>
    <paper id="4">
      <title>A Proposal : Interactively Learning to Summarise Timelines by <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement Learning</a></title>
      <author><first>Yuxuan</first><last>Ye</last></author>
      <author><first>Edwin</first><last>Simpson</last></author>
      <pages>25–31</pages>
      <abstract>Timeline Summarisation (TLS) aims to generate a concise, time-ordered list of events described in sources such as <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a>. However, current <a href="https://en.wikipedia.org/wiki/System">systems</a> do not provide an adequate way to adapt to new domains nor to focus on the aspects of interest to a particular user. Therefore, we propose a method for interactively learning abstractive TLS using Reinforcement Learning (RL). We define a compound reward function and use RL to fine-tune an abstractive Multi-document Summarisation (MDS) model, which avoids the need to train using reference summaries. One of the sub-reward functions will be learned interactively from user feedback to ensure the consistency between users’ demands and the generated <a href="https://en.wikipedia.org/wiki/Timeline">timeline</a>. The other sub-reward functions contribute to topical coherence and linguistic fluency. We plan experiments to evaluate whether our approach could generate accurate and precise <a href="https://en.wikipedia.org/wiki/Timeline">timelines</a> tailored for each user.</abstract>
      <url hash="21f50786">2021.internlp-1.4</url>
      <doi>10.18653/v1/2021.internlp-1.4</doi>
      <bibkey>ye-simpson-2021-proposal</bibkey>
    </paper>
    <paper id="5">
      <title>Dynamic Facet Selection by Maximizing Graded Relevance</title>
      <author><first>Michael</first><last>Glass</last></author>
      <author><first>Md Faisal Mahbub</first><last>Chowdhury</last></author>
      <author><first>Yu</first><last>Deng</last></author>
      <author><first>Ruchi</first><last>Mahindru</last></author>
      <author><first>Nicolas Rodolfo</first><last>Fauceglia</last></author>
      <author><first>Alfio</first><last>Gliozzo</last></author>
      <author><first>Nandana</first><last>Mihindukulasooriya</last></author>
      <pages>32–39</pages>
      <abstract>Dynamic faceted search (DFS), an interactive query refinement technique, is a form of Humancomputer information retrieval (HCIR) approach. It allows users to narrow down search results through facets, where the facets-documents mapping is determined at runtime based on the context of user query instead of pre-indexing the facets statically. In this paper, we propose a new unsupervised approach for dynamic facet generation, namely optimistic facets, which attempts to generate the best possible subset of facets, hence maximizing expected Discounted Cumulative Gain (DCG), a measure of ranking quality that uses a graded relevance scale. We also release code to generate a new evaluation dataset. Through empirical results on two datasets, we show that the proposed DFS approach considerably improves the document ranking in the search results.</abstract>
      <url hash="8c786b65">2021.internlp-1.5</url>
      <doi>10.18653/v1/2021.internlp-1.5</doi>
      <bibkey>glass-etal-2021-dynamic</bibkey>
      <pwccode url="https://github.com/ibm/stackoverflow-technotes-dataset" additional="false">ibm/stackoverflow-technotes-dataset</pwccode>
    </paper>
    <paper id="6">
      <title>Active Curriculum Learning</title>
      <author><first>Borna</first><last>Jafarpour</last></author>
      <author><first>Dawn</first><last>Sepehr</last></author>
      <author><first>Nick</first><last>Pogrebnyakov</last></author>
      <pages>40–45</pages>
      <abstract>This paper investigates and reveals the relationship between two closely related machine learning disciplines, namely Active Learning (AL) and Curriculum Learning (CL), from the lens of several novel <a href="https://en.wikipedia.org/wiki/Curriculum">curricula</a>. This paper also introduces Active Curriculum Learning (ACL) which improves AL by combining AL with CL to benefit from the dynamic nature of the AL informativeness concept as well as the human insights used in the design of the curriculum heuristics. Comparison of the performance of ACL and AL on two public datasets for the Named Entity Recognition (NER) task shows the effectiveness of combining AL and CL using our proposed framework.</abstract>
      <url hash="f1741a5b">2021.internlp-1.6</url>
      <doi>10.18653/v1/2021.internlp-1.6</doi>
      <bibkey>jafarpour-etal-2021-active</bibkey>
    </paper>
    <paper id="7">
      <title>Tackling Fake News Detection by Interactively Learning Representations using Graph Neural Networks</title>
      <author><first>Nikhil</first><last>Mehta</last></author>
      <author><first>Dan</first><last>Goldwasser</last></author>
      <pages>46–53</pages>
      <abstract>Easy access, variety of content, and fast widespread interactions are some of the reasons that have made <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> increasingly popular in today’s society. However, this has also enabled the widespread propagation of fake news, text that is published with an intent to spread <a href="https://en.wikipedia.org/wiki/Misinformation">misinformation</a> and sway beliefs. Detecting fake news is important to prevent <a href="https://en.wikipedia.org/wiki/Misinformation">misinformation</a> and maintain a healthy society. While prior works have tackled this problem by building <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning systems</a>, automatedly modeling the social media landscape that enables the spread of <a href="https://en.wikipedia.org/wiki/Fake_news">fake news</a> is challenging. On the contrary, having humans fact check all news is not scalable. Thus, in this paper, we propose to approach this problem interactively, where human insight can be continually combined with an automated system, enabling better social media representation quality. Our experiments show performance improvements in this setting.<i>interactively</i>, where human insight can be continually combined with an automated system, enabling better social media representation quality. Our experiments show performance improvements in this setting.</abstract>
      <url hash="d1fc0b98">2021.internlp-1.7</url>
      <doi>10.18653/v1/2021.internlp-1.7</doi>
      <bibkey>mehta-goldwasser-2021-tackling</bibkey>
    </paper>
  </volume>
</collection>