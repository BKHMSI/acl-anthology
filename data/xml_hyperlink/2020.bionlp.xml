<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.bionlp">
  <volume id="1" ingest-date="2020-06-21">
    <meta>
      <booktitle>Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing</booktitle>
      <editor><first>Dina</first><last>Demner-Fushman</last></editor>
      <editor><first>Kevin Bretonnel</first><last>Cohen</last></editor>
      <editor><first>Sophia</first><last>Ananiadou</last></editor>
      <editor><first>Junichi</first><last>Tsujii</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>July</month>
      <year>2020</year>
      <url hash="bea3611e">2020.bionlp-1</url>
    </meta>
    <frontmatter>
      <url hash="be6d2b3b">2020.bionlp-1.0</url>
      <bibkey>bionlp-2020-sigbiomed</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Interactive Extractive Search over Biomedical Corpora</title>
      <author><first>Hillel</first><last>Taub Tabib</last></author>
      <author><first>Micah</first><last>Shlain</last></author>
      <author><first>Shoval</first><last>Sadde</last></author>
      <author><first>Dan</first><last>Lahav</last></author>
      <author><first>Matan</first><last>Eyal</last></author>
      <author><first>Yaara</first><last>Cohen</last></author>
      <author><first>Yoav</first><last>Goldberg</last></author>
      <pages>28–37</pages>
      <abstract>We present a system that allows life-science researchers to search a linguistically annotated corpus of scientific texts using patterns over dependency graphs, as well as using patterns over token sequences and a powerful variant of boolean keyword queries. In contrast to previous attempts to dependency-based search, we introduce a light-weight query language that does not require the user to know the details of the underlying linguistic representations, and instead to query the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> by providing an example sentence coupled with simple markup. Search is performed at an interactive speed due to efficient linguistic graph-indexing and retrieval engine. This allows for rapid exploration, development and refinement of <a href="https://en.wikipedia.org/wiki/User_(computing)">user queries</a>. We demonstrate the system using example workflows over two <a href="https://en.wikipedia.org/wiki/Corpus_linguistics">corpora</a> : the PubMed corpus including 14,446,243 PubMed abstracts and the CORD-19 dataset, a collection of over 45,000 research papers focused on COVID-19 research. The <a href="https://en.wikipedia.org/wiki/System">system</a> is publicly available at https://allenai.github.io/spike</abstract>
      <url hash="f34737e0">2020.bionlp-1.3</url>
      <doi>10.18653/v1/2020.bionlp-1.3</doi>
      <video href="http://slideslive.com/38929643" />
      <bibkey>taub-tabib-etal-2020-interactive</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cord-19">CORD-19</pwcdataset>
    </paper>
    <paper id="4">
      <title>Improving Biomedical Analogical Retrieval with Embedding of Structural Dependencies</title>
      <author><first>Amandalynne</first><last>Paullada</last></author>
      <author><first>Bethany</first><last>Percha</last></author>
      <author><first>Trevor</first><last>Cohen</last></author>
      <pages>38–48</pages>
      <abstract>Inferring the nature of the relationships between biomedical entities from <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">text</a> is an important problem due to the difficulty of maintaining human-curated knowledge bases in rapidly evolving fields. Neural word embeddings have earned attention for an apparent ability to encode relational information. However, word embedding models that disregard <a href="https://en.wikipedia.org/wiki/Syntax">syntax</a> during training are limited in their ability to encode the structural relationships fundamental to <a href="https://en.wikipedia.org/wiki/Analogy">cognitive theories of analogy</a>. In this paper, we demonstrate the utility of encoding dependency structure in word embeddings in a model we call Embedding of Structural Dependencies (ESD) as a way to represent biomedical relationships in two analogical retrieval tasks : a relationship retrieval (RR) task, and a literature-based discovery (LBD) task meant to hypothesize plausible relationships between pairs of entities unseen in training. We compare our model to skip-gram with negative sampling (SGNS), using 19 databases of biomedical relationships as our evaluation data, with improvements in performance on 17 (LBD) and 18 (RR) of these sets. These results suggest embeddings encoding dependency path information are of value for biomedical analogy retrieval.</abstract>
      <url hash="fa2e9527">2020.bionlp-1.4</url>
      <doi>10.18653/v1/2020.bionlp-1.4</doi>
      <bibkey>paullada-etal-2020-improving</bibkey>
    </paper>
    <paper id="7">
      <title>A BERT-based One-Pass Multi-Task Model for Clinical Temporal Relation Extraction<fixed-case>BERT</fixed-case>-based One-Pass Multi-Task Model for Clinical Temporal Relation Extraction</title>
      <author><first>Chen</first><last>Lin</last></author>
      <author><first>Timothy</first><last>Miller</last></author>
      <author><first>Dmitriy</first><last>Dligach</last></author>
      <author><first>Farig</first><last>Sadeque</last></author>
      <author><first>Steven</first><last>Bethard</last></author>
      <author><first>Guergana</first><last>Savova</last></author>
      <pages>70–75</pages>
      <abstract>Recently BERT has achieved a state-of-the-art performance in temporal relation extraction from clinical Electronic Medical Records text. However, the current approach is inefficient as <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> requires multiple passes through each input sequence. We extend a recently-proposed one-pass model for relation classification to a one-pass model for relation extraction. We augment this framework by introducing global embeddings to help with long-distance relation inference, and by <a href="https://en.wikipedia.org/wiki/Multi-task_learning">multi-task learning</a> to increase model performance and generalizability. Our proposed model produces results on par with the state-of-the-art in temporal relation extraction on the THYME corpus and is much greener in <a href="https://en.wikipedia.org/wiki/Computational_cost">computational cost</a>.</abstract>
      <url hash="6120b644">2020.bionlp-1.7</url>
      <doi>10.18653/v1/2020.bionlp-1.7</doi>
      <bibkey>lin-etal-2020-bert</bibkey>
    </paper>
    <paper id="16">
      <title>Neural Transduction of Letter Position Dyslexia using an Anagram Matrix Representation</title>
      <author><first>Avi</first><last>Bleiweiss</last></author>
      <pages>150–155</pages>
      <abstract>Research on analyzing reading patterns of dyslectic children has mainly been driven by classifying dyslexia types offline. We contend that a framework to remedy reading errors inline is more far-reaching and will help to further advance our understanding of this impairment. In this paper, we propose a simple and intuitive neural model to reinstate migrating words that transpire in letter position dyslexia, a visual analysis deficit to the encoding of character order within a word. Introduced by the anagram matrix representation of an input verse, the novelty of our work lies in the expansion from one to a two dimensional context window for training. This warrants words that only differ in the disposition of letters to remain interpreted semantically similar in the <a href="https://en.wikipedia.org/wiki/Embedding">embedding space</a>. Subject to the apparent constraints of the self-attention transformer architecture, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieved a unigram BLEU score of 40.6 on our reconstructed dataset of the <a href="https://en.wikipedia.org/wiki/Shakespeare’s_sonnets">Shakespeare sonnets</a>.</abstract>
      <url hash="ab96024b">2020.bionlp-1.16</url>
      <doi>10.18653/v1/2020.bionlp-1.16</doi>
      <bibkey>bleiweiss-2020-neural</bibkey>
    </paper>
    <paper id="19">
      <title>Extensive Error Analysis and a Learning-Based Evaluation of Medical Entity Recognition Systems to Approximate User Experience</title>
      <author><first>Isar</first><last>Nejadgholi</last></author>
      <author><first>Kathleen C.</first><last>Fraser</last></author>
      <author><first>Berry</first><last>de Bruijn</last></author>
      <pages>177–186</pages>
      <abstract>When comparing entities extracted by a medical entity recognition system with gold standard annotations over a test set, two types of mismatches might occur, label mismatch or span mismatch. Here we focus on span mismatch and show that its severity can vary from a serious error to a fully acceptable entity extraction due to the subjectivity of span annotations. For a domain-specific BERT-based NER system, we showed that 25 % of the errors have the same labels and overlapping span with gold standard entities. We collected expert judgement which shows more than 90 % of these mismatches are accepted or partially accepted by the user. Using the training set of the NER system, we built a fast and lightweight <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity classifier</a> to approximate the <a href="https://en.wikipedia.org/wiki/User_experience">user experience</a> of such mismatches through accepting or rejecting them. The decisions made by this <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> are used to calculate a learning-based F-score which is shown to be a better approximation of a forgiving user’s experience than the relaxed F-score. We demonstrated the results of applying the proposed evaluation metric for a variety of deep learning medical entity recognition models trained with two datasets.</abstract>
      <url hash="89a62594">2020.bionlp-1.19</url>
      <doi>10.18653/v1/2020.bionlp-1.19</doi>
      <bibkey>nejadgholi-etal-2020-extensive</bibkey>
      <pwccode url="https://github.com/nrc-cnrc/NRC-MedNER-Eval" additional="false">nrc-cnrc/NRC-MedNER-Eval</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/medmentions">MedMentions</pwcdataset>
    </paper>
    <paper id="21">
      <title>Global Locality in Biomedical Relation and Event Extraction</title>
      <author><first>Elaheh</first><last>ShafieiBavani</last></author>
      <author><first>Antonio</first><last>Jimeno Yepes</last></author>
      <author><first>Xu</first><last>Zhong</last></author>
      <author><first>David</first><last>Martinez Iraola</last></author>
      <pages>195–204</pages>
      <abstract>Due to the exponential growth of <a href="https://en.wikipedia.org/wiki/Medical_literature">biomedical literature</a>, event and relation extraction are important tasks in <a href="https://en.wikipedia.org/wiki/Biomedical_text_mining">biomedical text mining</a>. Most work only focus on relation extraction, and detect a single entity pair mention on a short span of text, which is not ideal due to long sentences that appear in biomedical contexts. We propose an approach to both relation and event extraction, for simultaneously predicting relationships between all mention pairs in a text. We also perform an empirical study to discuss different network setups for this purpose. The best performing model includes a set of multi-head attentions and convolutions, an adaptation of the transformer architecture, which offers self-attention the ability to strengthen dependencies among related elements, and models the interaction between features extracted by multiple attention heads. Experiment results demonstrate that our approach outperforms the state of the art on a set of benchmark biomedical corpora including BioNLP 2009, 2011, 2013 and BioCreative 2017 shared tasks.</abstract>
      <url hash="3cb56dbd">2020.bionlp-1.21</url>
      <doi>10.18653/v1/2020.bionlp-1.21</doi>
      <bibkey>shafieibavani-etal-2020-global</bibkey>
    </paper>
    </volume>
</collection>