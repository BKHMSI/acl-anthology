<?xml version='1.0' encoding='utf-8'?>
<collection id="J17">
  <volume id="1">
    <meta>
      <booktitle>Computational Linguistics, Volume 43, Issue 1 - <fixed-case>A</fixed-case>pril 2017</booktitle>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <bibkey>cl-2017-linguistics</bibkey>
    </frontmatter>
    <paper id="1">
      <title>A Statistical, Grammar-Based Approach to Microplanning</title>
      <author><first>Claire</first><last>Gardent</last></author>
      <author><first>Laura</first><last>Perez-Beltrachini</last></author>
      <abstract>Although there has been much work in recent years on data-driven natural language generation, little attention has been paid to the fine-grained interactions that arise during microplanning between aggregation, surface realization, and <a href="https://en.wikipedia.org/wiki/Sentence_segmentation">sentence segmentation</a>. In this article, we propose a hybrid symbolic / statistical approach to jointly model the constraints regulating these <a href="https://en.wikipedia.org/wiki/Interaction_(statistics)">interactions</a>. Our approach integrates a small handwritten grammar, a statistical hypertagger, and a surface realization algorithm. It is applied to the verbalization of knowledge base queries and tested on 13 <a href="https://en.wikipedia.org/wiki/Knowledge_base">knowledge bases</a> to demonstrate domain independence. We evaluate our <a href="https://en.wikipedia.org/wiki/Tactic_(method)">approach</a> in several ways. A quantitative analysis shows that the hybrid approach outperforms a purely symbolic approach in terms of both <a href="https://en.wikipedia.org/wiki/Speed">speed</a> and <a href="https://en.wikipedia.org/wiki/Coverage_(telecommunication)">coverage</a>. Results from a human study indicate that users find the output of this hybrid statistic / symbolic system more fluent than both a template-based and a purely symbolic grammar-based approach. Finally, we illustrate by means of examples that our approach can account for various factors impacting <a href="https://en.wikipedia.org/wiki/Aggregate_data">aggregation</a>, <a href="https://en.wikipedia.org/wiki/Sentence_segmentation">sentence segmentation</a>, and surface realization.</abstract>
      <pages>1-30</pages>
      <doi>10.1162/COLI_a_00273</doi>
      <url hash="ac887648">J17-1001</url>
      <bibkey>gardent-perez-beltrachini-2017-statistical</bibkey>
    </paper>
    <paper id="2">
      <title>A Game-Theoretic Approach to Word Sense Disambiguation</title>
      <author><first>Rocco</first><last>Tripodi</last></author>
      <author><first>Marcello</first><last>Pelillo</last></author>
      <abstract>This article presents a new model for <a href="https://en.wikipedia.org/wiki/Word_sense_disambiguation">word sense disambiguation</a> formulated in terms of <a href="https://en.wikipedia.org/wiki/Evolutionary_game_theory">evolutionary game theory</a>, where each word to be disambiguated is represented as a node on a <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph</a> whose edges represent word relations and senses are represented as classes. The words simultaneously update their class membership preferences according to the senses that neighboring words are likely to choose. We use distributional information to weigh the influence that each word has on the decisions of the others and semantic similarity information to measure the strength of compatibility among the choices. With this information we can formulate the word sense disambiguation problem as a <a href="https://en.wikipedia.org/wiki/Constraint_satisfaction_problem">constraint satisfaction problem</a> and solve it using tools derived from <a href="https://en.wikipedia.org/wiki/Game_theory">game theory</a>, maintaining the textual coherence. The model is based on two ideas : Similar words should be assigned to similar classes and the meaning of a word does not depend on all the words in a text but just on some of them. The article provides an in-depth motivation of the idea of modeling the <a href="https://en.wikipedia.org/wiki/Word-sense_disambiguation">word sense disambiguation problem</a> in terms of <a href="https://en.wikipedia.org/wiki/Game_theory">game theory</a>, which is illustrated by an example. The conclusion presents an extensive analysis on the combination of <a href="https://en.wikipedia.org/wiki/Similarity_measure">similarity measures</a> to use in the <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> and a comparison with state-of-the-art systems. The results show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms state-of-the-art algorithms and can be applied to different <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> and in different scenarios.</abstract>
      <pages>31-70</pages>
      <doi>10.1162/COLI_a_00274</doi>
      <url hash="b79d9681">J17-1002</url>
      <bibkey>tripodi-pelillo-2017-game</bibkey>
    </paper>
    <paper id="3">
      <title>Multilingual Metaphor Processing : Experiments with Semi-Supervised and Unsupervised Learning</title>
      <author><first>Ekaterina</first><last>Shutova</last></author>
      <author><first>Lin</first><last>Sun</last></author>
      <author><first>Elkin</first><last>Darío Gutiérrez</last></author>
      <author><first>Patricia</first><last>Lichtenstein</last></author>
      <author><first>Srini</first><last>Narayanan</last></author>
      <abstract>Highly frequent in language and communication, <a href="https://en.wikipedia.org/wiki/Metaphor">metaphor</a> represents a significant challenge for Natural Language Processing (NLP) applications. Computational work on <a href="https://en.wikipedia.org/wiki/Metaphor">metaphor</a> has traditionally evolved around the use of hand-coded knowledge, making the <a href="https://en.wikipedia.org/wiki/System">systems</a> hard to scale. Recent years have witnessed a rise in <a href="https://en.wikipedia.org/wiki/Statistics">statistical approaches</a> to metaphor processing. However, these approaches often require extensive human annotation effort and are predominantly evaluated within a <a href="https://en.wikipedia.org/wiki/Domain_(biology)">limited domain</a>. In contrast, we experiment with weakly supervised and unsupervised techniqueswith little or no annotationto generalize higher-level mechanisms of metaphor from distributional properties of concepts. We investigate different levels and types of <a href="https://en.wikipedia.org/wiki/Supervisor">supervision</a> (learning from linguistic examples vs. learning from a given set of metaphorical mappings vs. learning without annotation) in flat and hierarchical, unconstrained and constrained clustering settings. Our aim is to identify the optimal type of <a href="https://en.wikipedia.org/wiki/Supervisor">supervision</a> for a <a href="https://en.wikipedia.org/wiki/Machine_learning">learning algorithm</a> that discovers patterns of metaphorical association from <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">text</a>. In order to investigate the scalability and adaptability of our models, we applied them to data in three languages from different language groupsEnglish, Spanish, and Russianachieving state-of-the-art results with little supervision. Finally, we demonstrate that <a href="https://en.wikipedia.org/wiki/Statistics">statistical methods</a> can facilitate and scale up cross-linguistic research on <a href="https://en.wikipedia.org/wiki/Metaphor">metaphor</a>.</abstract>
      <pages>71-123</pages>
      <doi>10.1162/COLI_a_00275</doi>
      <url hash="224e6445">J17-1003</url>
      <bibkey>shutova-etal-2017-multilingual</bibkey>
    </paper>
    <paper id="4">
      <title>Argumentation Mining in User-Generated Web Discourse</title>
      <author><first>Ivan</first><last>Habernal</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <abstract>The goal of argumentation mining, an evolving research field in <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational linguistics</a>, is to design methods capable of analyzing people’s argumentation. In this article, we go beyond the state of the art in several ways. (i) We deal with actual Web data and take up the challenges given by the variety of registers, multiple domains, and unrestricted noisy user-generated Web discourse. (ii) We bridge the gap between normative argumentation theories and argumentation phenomena encountered in actual data by adapting an argumentation model tested in an extensive annotation study. (iii) We create a new gold standard corpus (90k tokens in 340 documents) and experiment with several machine learning methods to identify argument components. We offer the <a href="https://en.wikipedia.org/wiki/Data">data</a>, source codes, and annotation guidelines to the community under free licenses. Our findings show that argumentation mining in user-generated Web discourse is a feasible but challenging task.</abstract>
      <pages>125-179</pages>
      <doi>10.1162/COLI_a_00276</doi>
      <url hash="9f356eaa">J17-1004</url>
      <bibkey>habernal-gurevych-2017-argumentation</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/ukp">UKP</pwcdataset>
    </paper>
    <paper id="5">
      <title>Hashtag Sense Clustering Based on Temporal Similarity</title>
      <author><first>Giovanni</first><last>Stilo</last></author>
      <author><first>Paola</first><last>Velardi</last></author>
      <abstract>Hashtags are creative labels used in <a href="https://en.wikipedia.org/wiki/Microblogging">micro-blogs</a> to characterize the topic of a message / discussion. Regardless of the use for which they were originally intended, <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a> can not be used as a means to cluster messages with similar content. First, because <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a> are created in a spontaneous and highly dynamic way by users in multiple languages, the same topic can be associated with different <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a>, and conversely, the same <a href="https://en.wikipedia.org/wiki/Hashtag">hashtag</a> may refer to different topics in different time periods. Second, contrary to common words, hashtag disambiguation is complicated by the fact that no <a href="https://en.wikipedia.org/wiki/Word-sense_disambiguation">sense catalogs</a> (e.g., <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a> or WordNet) are available ; and, furthermore, hashtag labels are difficult to analyze, as they often consist of <a href="https://en.wikipedia.org/wiki/Acronym">acronyms</a>, concatenated words, and so forth. A common way to determine the meaning of <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a> has been to analyze their context, but, as we have just pointed out, <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a> can have multiple and variable meanings. In this article, we propose a temporal sense clustering algorithm based on the idea that semantically related hashtags have similar and synchronous usage patterns.</abstract>
      <pages>181-200</pages>
      <doi>10.1162/COLI_a_00277</doi>
      <url hash="ea9e95f2">J17-1005</url>
      <bibkey>stilo-velardi-2017-hashtag</bibkey>
    </paper>
    </volume>
  <volume id="2">
    <meta>
      <booktitle>Computational Linguistics, Volume 43, Issue 2 - June 2017</booktitle>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
      <month>June</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <bibkey>cl-2017-linguistics-43</bibkey>
    </frontmatter>
    <paper id="1">
      <title>A Comprehensive Analysis of Bilingual Lexicon Induction</title>
      <author><first>Ann</first><last>Irvine</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <abstract>Bilingual lexicon induction is the task of inducing word translations from monolingual corpora in two languages. In this article we present the most comprehensive analysis of bilingual lexicon induction to date. We present experiments on a wide range of languages and data sizes. We examine translation into English from 25 foreign languages : <a href="https://en.wikipedia.org/wiki/Albanian_language">Albanian</a>, <a href="https://en.wikipedia.org/wiki/Azerbaijani_language">Azeri</a>, <a href="https://en.wikipedia.org/wiki/Bengali_language">Bengali</a>, <a href="https://en.wikipedia.org/wiki/Bosnian_language">Bosnian</a>, <a href="https://en.wikipedia.org/wiki/Bulgarian_language">Bulgarian</a>, <a href="https://en.wikipedia.org/wiki/Cebuano_language">Cebuano</a>, <a href="https://en.wikipedia.org/wiki/Gujarati_language">Gujarati</a>, <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a>, <a href="https://en.wikipedia.org/wiki/Hungarian_language">Hungarian</a>, <a href="https://en.wikipedia.org/wiki/Indonesian_language">Indonesian</a>, <a href="https://en.wikipedia.org/wiki/Latvian_language">Latvian</a>, <a href="https://en.wikipedia.org/wiki/Nepali_language">Nepali</a>, <a href="https://en.wikipedia.org/wiki/Romanian_language">Romanian</a>, <a href="https://en.wikipedia.org/wiki/Serbian_language">Serbian</a>, <a href="https://en.wikipedia.org/wiki/Slovak_language">Slovak</a>, <a href="https://en.wikipedia.org/wiki/Somali_language">Somali</a>, <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, <a href="https://en.wikipedia.org/wiki/Swedish_language">Swedish</a>, <a href="https://en.wikipedia.org/wiki/Tamil_language">Tamil</a>, <a href="https://en.wikipedia.org/wiki/Telugu_language">Telugu</a>, <a href="https://en.wikipedia.org/wiki/Turkish_language">Turkish</a>, Ukrainian, <a href="https://en.wikipedia.org/wiki/Uzbek_language">Uzbek</a>, <a href="https://en.wikipedia.org/wiki/Vietnamese_language">Vietnamese</a>, and <a href="https://en.wikipedia.org/wiki/Welsh_language">Welsh</a>. We analyze the behavior of bilingual lexicon induction on low-frequency words, rather than testing solely on high-frequency words, as previous research has done. Low-frequency words are more relevant to <a href="https://en.wikipedia.org/wiki/Statistical_machine_translation">statistical machine translation</a>, where systems typically lack translations of rare words that fall outside of their training data. We systematically explore a wide range of <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">features</a> and phenomena that affect the quality of the translations discovered by bilingual lexicon induction. We provide illustrative examples of the highest ranking translations for orthogonal signals of translation equivalence like contextual similarity and temporal similarity. We analyze the effects of frequency and burstiness, and the sizes of the seed bilingual dictionaries and the monolingual training corpora. Additionally, we introduce a novel discriminative approach to bilingual lexicon induction. Our <a href="https://en.wikipedia.org/wiki/Discriminative_model">discriminative model</a> is capable of combining a wide variety of <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> that individually provide only weak indications of translation equivalence.</abstract>
      <pages>273–310</pages>
      <doi>10.1162/COLI_a_00284</doi>
      <url hash="ac50ccab">J17-2001</url>
      <bibkey>irvine-callison-burch-2017-comprehensive</bibkey>
    </paper>
    <paper id="2">
      <title>Greedy Transition-Based Dependency Parsing with Stack LSTMs<fixed-case>LSTM</fixed-case>s</title>
      <author><first>Miguel</first><last>Ballesteros</last></author>
      <author><first>Chris</first><last>Dyer</last></author>
      <author><first>Yoav</first><last>Goldberg</last></author>
      <author><first>Noah A.</first><last>Smith</last></author>
      <abstract>We introduce a greedy transition-based parser that learns to represent <a href="https://en.wikipedia.org/wiki/State_(computer_science)">parser states</a> using <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural networks</a>. Our primary innovation that enables us to do this efficiently is a new control structure for sequential neural networksthe stack long short-term memory unit (LSTM). Like the conventional <a href="https://en.wikipedia.org/wiki/Stack_(abstract_data_type)">stack data structures</a> used in transition-based parsers, elements can be pushed to or popped from the top of the stack in constant time, but, in addition, an LSTM maintains a continuous space embedding of the stack contents. Our model captures three facets of the <a href="https://en.wikipedia.org/wiki/Parsing">parser</a>’s state : (i) unbounded look-ahead into the buffer of incoming words, (ii) the complete history of transition actions taken by the <a href="https://en.wikipedia.org/wiki/Parsing">parser</a>, and (iii) the complete contents of the stack of partially built tree fragments, including their internal structures. In addition, we compare two different word representations : (i) standard word vectors based on look-up tables and (ii) character-based models of words. Although standard word embedding models work well in all languages, the character-based models improve the handling of out-of-vocabulary words, particularly in <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphologically rich languages</a>. Finally, we discuss the use of <a href="https://en.wikipedia.org/wiki/Oracle_machine">dynamic oracles</a> in training the <a href="https://en.wikipedia.org/wiki/Parsing">parser</a>. During <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training</a>, dynamic oracles alternate between sampling parser states from the training data and from the model as it is being learned, making the model more robust to the kinds of errors that will be made at test time. Training our model with <a href="https://en.wikipedia.org/wiki/Oracle_machine">dynamic oracles</a> yields a linear-time greedy parser with very competitive performance.</abstract>
      <pages>311–347</pages>
      <doi>10.1162/COLI_a_00285</doi>
      <url hash="857e3f6c">J17-2002</url>
      <bibkey>ballesteros-etal-2017-greedy</bibkey>
    </paper>
    <paper id="3">
      <title>Statistical Models for Unsupervised, Semi-Supervised Supervised Transliteration Mining</title>
      <author><first>Hassan</first><last>Sajjad</last></author>
      <author><first>Helmut</first><last>Schmid</last></author>
      <author><first>Alexander</first><last>Fraser</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <abstract>We present a <a href="https://en.wikipedia.org/wiki/Generative_model">generative model</a> that efficiently mines <a href="https://en.wikipedia.org/wiki/Transliteration">transliteration pairs</a> in a consistent fashion in three different settings : unsupervised, semi-supervised, and supervised transliteration mining. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> interpolates two sub-models, one for the generation of transliteration pairs and one for the generation of non-transliteration pairs (i.e., noise). The <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> is trained on <a href="https://en.wikipedia.org/wiki/Noisy_data">noisy unlabeled data</a> using the <a href="https://en.wikipedia.org/wiki/EM_algorithm">EM algorithm</a>. During training the transliteration sub-model learns to generate transliteration pairs and the fixed non-transliteration model generates the noise pairs. After training, the unlabeled data is disambiguated based on the <a href="https://en.wikipedia.org/wiki/Posterior_probability">posterior probabilities</a> of the two <a href="https://en.wikipedia.org/wiki/Statistical_model">sub-models</a>. We evaluate our transliteration mining system on data from a transliteration mining shared task and on parallel corpora. For three out of four language pairs, our <a href="https://en.wikipedia.org/wiki/System">system</a> outperforms all semi-supervised and supervised systems that participated in the NEWS 2010 shared task. On word pairs extracted from <a href="https://en.wikipedia.org/wiki/Parallel_text">parallel corpora</a> with fewer than 2 % <a href="https://en.wikipedia.org/wiki/Transliteration">transliteration pairs</a>, our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves up to 86.7 % F-measure with 77.9 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a> and 97.8 % <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall</a>.</abstract>
      <pages>349–375</pages>
      <doi>10.1162/COLI_a_00286</doi>
      <url hash="0102b781">J17-2003</url>
      <bibkey>sajjad-etal-2017-statistical</bibkey>
    </paper>
    <paper id="4">
      <title>Identifying and Avoiding Confusion in Dialogue with People with Alzheimer’s Disease<fixed-case>A</fixed-case>lzheimer’s Disease</title>
      <author><first>Hamidreza</first><last>Chinaei</last></author>
      <author><first>Leila Chan</first><last>Currie</last></author>
      <author><first>Andrew</first><last>Danks</last></author>
      <author><first>Hubert</first><last>Lin</last></author>
      <author><first>Tejas</first><last>Mehta</last></author>
      <author><first>Frank</first><last>Rudzicz</last></author>
      <abstract>Alzheimer’s disease (AD) is an increasingly prevalent <a href="https://en.wikipedia.org/wiki/Cognitive_disorder">cognitive disorder</a> in which <a href="https://en.wikipedia.org/wiki/Memory">memory</a>, <a href="https://en.wikipedia.org/wiki/Language">language</a>, and <a href="https://en.wikipedia.org/wiki/Executive_functions">executive function</a> deteriorate, usually in that order. There is a growing need to support individuals with AD and other forms of <a href="https://en.wikipedia.org/wiki/Dementia">dementia</a> in their daily lives, and our goal is to do so through speech-based interaction. Given that 33 % of conversations with people with middle-stage AD involve a breakdown in communication, it is vital that automated dialogue systems be able to identify those breakdowns and, if possible, avoid them. In this article, we discuss several linguistic features that are verbal indicators of <a href="https://en.wikipedia.org/wiki/Confusion">confusion</a> in AD (including vocabulary richness, parse tree structures, and acoustic cues) and apply several <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning algorithms</a> to identify dialogue-relevant confusion from <a href="https://en.wikipedia.org/wiki/Speech">speech</a> with up to 82 % accuracy. We also learn dialogue strategies to avoid <a href="https://en.wikipedia.org/wiki/Confusion">confusion</a> in the first place, which is accomplished using a <a href="https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process">partially observable Markov decision process</a> and which obtains accuracies (up to 96.1 %) that are significantly higher than several baselines. This work represents a major step towards automated dialogue systems for individuals with dementia.</abstract>
      <pages>377–406</pages>
      <doi>10.1162/COLI_a_00290</doi>
      <url hash="991b7296">J17-2004</url>
      <bibkey>chinaei-etal-2017-identifying</bibkey>
    </paper>
    <paper id="5">
      <title>Framing QA as Building and Ranking Intersentence Answer Justifications<fixed-case>QA</fixed-case> as Building and Ranking Intersentence Answer Justifications</title>
      <author><first>Peter</first><last>Jansen</last></author>
      <author><first>Rebecca</first><last>Sharp</last></author>
      <author><first>Mihai</first><last>Surdeanu</last></author>
      <author><first>Peter</first><last>Clark</last></author>
      <abstract>We propose a question answering (QA) approach for standardized science exams that both identifies correct answers and produces compelling human-readable justifications for why those answers are correct. Our method first identifies the actual information needed in a question using psycholinguistic concreteness norms, then uses this information need to construct answer justifications by aggregating multiple sentences from different knowledge bases using syntactic and lexical information. We then jointly rank answers and their justifications using a reranking perceptron that treats <a href="https://en.wikipedia.org/wiki/Theory_of_justification">justification quality</a> as a <a href="https://en.wikipedia.org/wiki/Latent_variable">latent variable</a>. We evaluate our method on 1,000 multiple-choice questions from elementary school science exams, and empirically demonstrate that it performs better than several strong baselines, including neural network approaches. Our best configuration answers 44 % of the questions correctly, where the top justifications for 57 % of these correct answers contain a compelling human-readable justification that explains the inference required to arrive at the correct answer. We include a detailed characterization of the justification quality for both our method and a strong <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a>, and show that <a href="https://en.wikipedia.org/wiki/Information_aggregation">information aggregation</a> is key to addressing the information need in complex questions.</abstract>
      <pages>407–449</pages>
      <doi>10.1162/COLI_a_00287</doi>
      <url hash="52beb243">J17-2005</url>
      <bibkey>jansen-etal-2017-framing</bibkey>
    </paper>
    <paper id="6">
      <title>Squib : Effects of Cognitive Effort on the Resolution of Overspecified Descriptions<fixed-case>S</fixed-case>quib: Effects of Cognitive Effort on the Resolution of Overspecified Descriptions</title>
      <author><first>Ivandré</first><last>Paraboni</last></author>
      <author><first>Alex Gwo Jen</first><last>Lan</last></author>
      <author><first>Matheus Mendes</first><last>de Sant’Ana</last></author>
      <author><first>Flávio Luiz</first><last>Coutinho</last></author>
      <abstract>Studies in referring expression generation (REG) have shown different effects of referential overspecification on the resolution of certain descriptions. To further investigate effects of this kind, this article reports two <a href="https://en.wikipedia.org/wiki/Eye-tracking">eye-tracking</a> experiments that measure the time required to recognize target objects based on different kinds of information. Results suggest that referential overspecification may be either helpful or detrimental to identification depending on the kind of information that is actually overspecified, an insight that may be useful for the design of more informed hearer-oriented REG algorithms.</abstract>
      <pages>451–459</pages>
      <doi>10.1162/COLI_a_00288</doi>
      <url hash="59ddaba8">J17-2006</url>
      <bibkey>paraboni-etal-2017-squib</bibkey>
    </paper>
    </volume>
  <volume id="3">
    <meta>
      <booktitle>Computational Linguistics, Volume 43, Issue 3 - September 2017</booktitle>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
      <month>September</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <bibkey>cl-2017-linguistics-43-issue</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Hybrid Grammars for Parsing of Discontinuous Phrase Structures and Non-Projective Dependency Structures</title>
      <author><first>Kilian</first><last>Gebhardt</last></author>
      <author><first>Mark-Jan</first><last>Nederhof</last></author>
      <author><first>Heiko</first><last>Vogler</last></author>
      <abstract>We explore the concept of hybrid grammars, which formalize and generalize a range of existing frameworks for dealing with discontinuous syntactic structures. Covered are both <a href="https://en.wikipedia.org/wiki/Discontinuity_(linguistics)">discontinuous phrase structures</a> and non-projective dependency structures. Technically, hybrid grammars are related to synchronous grammars, where one grammar component generates linear structures and another generates hierarchical structures. By coupling <a href="https://en.wikipedia.org/wiki/Lexical_item">lexical elements</a> of both components together, <a href="https://en.wikipedia.org/wiki/Discontinuity_(linguistics)">discontinuous structures</a> result. Several types of hybrid grammars are characterized. We also discuss <a href="https://en.wikipedia.org/wiki/Grammar_induction">grammar induction</a> from <a href="https://en.wikipedia.org/wiki/Treebank">treebanks</a>. The main advantage over existing frameworks is the ability of hybrid grammars to separate discontinuity of the desired structures from <a href="https://en.wikipedia.org/wiki/Time_complexity">time complexity</a> of <a href="https://en.wikipedia.org/wiki/Parsing">parsing</a>. This permits exploration of a large variety of <a href="https://en.wikipedia.org/wiki/Parsing">parsing algorithms</a> for discontinuous structures, with different properties. This is confirmed by the reported experimental results, which show a wide variety of <a href="https://en.wikipedia.org/wiki/Time_complexity">running time</a>, <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>, and frequency of parse failures.</abstract>
      <pages>465–520</pages>
      <doi>10.1162/COLI_a_00291</doi>
      <url hash="b0a3e8db">J17-3001</url>
      <bibkey>gebhardt-etal-2017-hybrid</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="2">
      <title>Translation Divergences in ChineseEnglish Machine Translation : An Empirical Investigation<fixed-case>C</fixed-case>hinese–<fixed-case>E</fixed-case>nglish Machine Translation: An Empirical Investigation</title>
      <author><first>Dun</first><last>Deng</last></author>
      <author><first>Nianwen</first><last>Xue</last></author>
      <abstract>In this article, we conduct an empirical investigation of translation divergences between <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a> and <a href="https://en.wikipedia.org/wiki/English_language">English</a> relying on a parallel treebank. To do this, we first devise a hierarchical alignment scheme where Chinese and English parse trees are aligned in a way that eliminates conflicts and redundancies between word alignments and syntactic parses to prevent the generation of spurious translation divergences. Using this Hierarchically Aligned ChineseEnglish Parallel Treebank (HACEPT), we are able to semi-automatically identify and categorize the translation divergences between the two languages and quantify each type of translation divergence. Our results show that the translation divergences are much broader than described in previous studies that are largely based on anecdotal evidence and <a href="https://en.wikipedia.org/wiki/Linguistics">linguistic knowledge</a>. The distribution of the translation divergences also shows that some high-profile translation divergences that motivate previous research are actually very rare in our data, whereas other translation divergences that have previously received little attention actually exist in large quantities. We also show that HACEPT allows the extraction of syntax-based translation rules, most of which are expressive enough to capture the translation divergences, and point out that the syntactic annotation in existing treebanks is not optimal for extracting such translation rules. We also discuss the implications of our study for attempts to bridge translation divergences by devising shared semantic representations across languages. Our quantitative results lend further support to the observation that although it is possible to bridge some translation divergences with semantic representations, other translation divergences are open-ended, thus building a semantic representation that captures all possible translation divergences may be impractical.</abstract>
      <pages>521–565</pages>
      <doi>10.1162/COLI_a_00292</doi>
      <url hash="405354c6">J17-3002</url>
      <bibkey>deng-xue-2017-translation</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/amr-bank">AMR Bank</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="3">
      <title>A Kernel Independence Test for Geographical Language Variation</title>
      <author><first>Dong</first><last>Nguyen</last></author>
      <author><first>Jacob</first><last>Eisenstein</last></author>
      <abstract>Quantifying the degree of <a href="https://en.wikipedia.org/wiki/Spatial_dependence">spatial dependence</a> for <a href="https://en.wikipedia.org/wiki/Dependent_and_independent_variables">linguistic variables</a> is a key task for analyzing dialectal variation. However, existing <a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets">approaches</a> have important drawbacks. First, they are based on parametric models of dependence, which limits their power in cases where the underlying parametric assumptions are violated. Second, they are not applicable to all types of linguistic data : Some approaches apply only to <a href="https://en.wikipedia.org/wiki/Frequency">frequencies</a>, others to boolean indicators of whether a linguistic variable is present. We present a new <a href="https://en.wikipedia.org/wiki/Methodology">method</a> for measuring geographical language variation, which solves both of these problems. Our approach builds on Reproducing Kernel Hilbert Space (RKHS) representations for <a href="https://en.wikipedia.org/wiki/Nonparametric_statistics">nonparametric statistics</a>, and takes the form of a <a href="https://en.wikipedia.org/wiki/Test_statistic">test statistic</a> that is computed from pairs of individual geotagged observations without aggregation into predefined geographical bins. We compare this test with prior work using synthetic data as well as a diverse set of real data sets : a corpus of Dutch tweets, a Dutch syntactic atlas, and a data set of letters to the editor in North American newspapers. Our proposed <a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing">test</a> is shown to support robust inferences across a broad range of scenarios and types of data.</abstract>
      <pages>567–592</pages>
      <doi>10.1162/COLI_a_00293</doi>
      <url hash="a5da865a">J17-3003</url>
      <bibkey>nguyen-eisenstein-2017-kernel</bibkey>
      <pwccode url="https://github.com/dongpng/geo-independence-testing" additional="false">dongpng/geo-independence-testing</pwccode>
    </paper>
    <paper id="4">
      <title>AutoExtend : Combining Word Embeddings with Semantic Resources<fixed-case>A</fixed-case>uto<fixed-case>E</fixed-case>xtend: Combining Word Embeddings with Semantic Resources</title>
      <author><first>Sascha</first><last>Rothe</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <abstract>We present AutoExtend, a system that combines word embeddings with semantic resources by learning embeddings for non-word objects like synsets and entities and learning word embeddings that incorporate the semantic information from the resource. The method is based on encoding and decoding the <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> and is flexible in that it can take any <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> as input and does not need an additional <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training corpus</a>. The obtained <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> live in the same <a href="https://en.wikipedia.org/wiki/Vector_space">vector space</a> as the input word embeddings. A sparse tensor formalization guarantees efficiency and <a href="https://en.wikipedia.org/wiki/Parallelizability">parallelizability</a>. We use <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a>, <a href="https://en.wikipedia.org/wiki/GermaNet">GermaNet</a>, and <a href="https://en.wikipedia.org/wiki/Freebase">Freebase</a> as semantic resources. AutoExtend achieves state-of-the-art performance on Word-in-Context Similarity and Word Sense Disambiguation tasks.</abstract>
      <pages>593–617</pages>
      <doi>10.1162/COLI_a_00294</doi>
      <url hash="bb9fa638">J17-3004</url>
      <bibkey>rothe-schutze-2017-autoextend</bibkey>
    </paper>
    <paper id="5">
      <title>Parsing Argumentation Structures in Persuasive Essays</title>
      <author><first>Christian</first><last>Stab</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <abstract>In this article, we present a novel approach for parsing argumentation structures. We identify argument components using <a href="https://en.wikipedia.org/wiki/Sequence_labeling">sequence labeling</a> at the token level and apply a new joint model for detecting argumentation structures. The proposed model globally optimizes argument component types and argumentative relations using <a href="https://en.wikipedia.org/wiki/Integer_linear_programming">Integer Linear Programming</a>. We show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> significantly outperforms challenging heuristic baselines on two different types of <a href="https://en.wikipedia.org/wiki/Discourse">discourse</a>. Moreover, we introduce a novel corpus of persuasive essays annotated with <a href="https://en.wikipedia.org/wiki/Argumentation_theory">argumentation structures</a>. We show that our annotation scheme and annotation guidelines successfully guide human annotators to substantial agreement.</abstract>
      <pages>619–659</pages>
      <doi>10.1162/COLI_a_00295</doi>
      <url hash="2006196c">J17-3005</url>
      <bibkey>stab-gurevych-2017-parsing</bibkey>
    </paper>
    <paper id="6">
      <title>The Agreement Measure cat a Complement to   Focused on Categorization of a Continuum</title>
      <author><first>Yann</first><last>Mathet</last></author>
      <abstract>Agreement on unitizing, where several annotators freely put units of various sizes and categories on a continuum, is difficult to assess because of the simultaneaous discrepancies in positioning and categorizing. The recent agreement measure   offers an overall solution that simultaneously takes into account positions and categories. In this article, I propose the additional coefficient cat, which complements   by assessing the agreement on categorization of a continuum, putting aside positional discrepancies. When applied to pure categorization (with predefined units), <a href="https://en.wikipedia.org/wiki/Cat">cat</a> behaves the same way as the famous dedicated Krippendorff’s, even with missing values, which proves its consistency. A variation of <a href="https://en.wikipedia.org/wiki/Cat">cat</a> is also proposed that provides an in-depth assessment of <a href="https://en.wikipedia.org/wiki/Categorization">categorizing</a> for each individual category. The entire family of   coefficients is implemented in <a href="https://en.wikipedia.org/wiki/Free_software">free software</a>.</abstract>
      <pages>661–681</pages>
      <doi>10.1162/COLI_a_00296</doi>
      <url hash="f7241c3a">J17-3006</url>
      <bibkey>mathet-2017-agreement</bibkey>
    </paper>
  </volume>
  <volume id="4">
    <meta>
      <booktitle>Computational Linguistics, Volume 43, Issue 4 - <fixed-case>D</fixed-case>ecember 2017</booktitle>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
      <month>December</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <bibkey>cl-2017-linguistics-43-issue-4</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Discourse Structure in Machine Translation Evaluation</title>
      <author><first>Shafiq</first><last>Joty</last></author>
      <author><first>Francisco</first><last>Guzmán</last></author>
      <author><first>Lluís</first><last>Màrquez</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <abstract>In this article, we explore the potential of using sentence-level discourse structure for machine translation evaluation. We first design discourse-aware similarity measures, which use all-subtree kernels to compare discourse parse trees in accordance with the Rhetorical Structure Theory (RST). Then, we show that a simple <a href="https://en.wikipedia.org/wiki/Linear_combination">linear combination</a> with these measures can help improve various existing machine translation evaluation metrics regarding correlation with human judgments both at the segment level and at the system level. This suggests that discourse information is complementary to the information used by many of the existing evaluation metrics, and thus it could be taken into account when developing richer evaluation metrics, such as the WMT-14 winning combined metric DiscoTKparty. We also provide a detailed analysis of the relevance of various discourse elements and relations from the RST parse trees for machine translation evaluation. In particular, we show that (i) all aspects of the RST tree are relevant, (ii) <a href="https://en.wikipedia.org/wiki/Nuclearity">nuclearity</a> is more useful than relation type, and (iii) the similarity of the translation RST tree to the reference RST tree is positively correlated with translation quality.</abstract>
      <pages>683–722</pages>
      <doi>10.1162/COLI_a_00298</doi>
      <url hash="18904d86">J17-4001</url>
      <bibkey>joty-etal-2017-discourse</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2014">WMT 2014</pwcdataset>
    </paper>
    <paper id="2">
      <title>Adapting to Learner Errors with Minimal Supervision</title>
      <author><first>Alla</first><last>Rozovskaya</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <author><first>Mark</first><last>Sammons</last></author>
      <abstract>This article considers the problem of correcting errors made by English as a Second Language writers from a machine learning perspective, and addresses an important issue of developing an appropriate <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training paradigm</a> for the task, one that accounts for error patterns of non-native writers using minimal supervision. Existing training approaches present a trade-off between large amounts of cheap data offered by the native-trained models and additional knowledge of learner error patterns provided by the more expensive method of training on annotated learner data. We propose a novel training approach that draws on the strengths offered by the two standard training paradigmsof training either on native or on annotated learner dataand that outperforms both of these standard methods. Using the key observation that parameters relating to <a href="https://en.wikipedia.org/wiki/Errors_and_residuals">error regularities</a> exhibited by non-native writers are relatively simple, we develop models that can incorporate knowledge about <a href="https://en.wikipedia.org/wiki/Errors_and_residuals">error regularities</a> based on a small annotated sample but that are otherwise trained on native English data. The key contribution of this article is the introduction and analysis of two methods for adapting the learned models to error patterns of non-native writers ; one method that applies to generative classifiers and a second that applies to discriminative classifiers. Both <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> demonstrated state-of-the-art performance in several text correction competitions. In particular, the Illinois system that implements these <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> ranked at the top in two recent CoNLL shared tasks on error correction.1 We conduct further evaluation of the proposed approaches studying the effect of using <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error data</a> from speakers of the same native language, languages that are closely related linguistically, and unrelated languages.</abstract>
      <pages>723–760</pages>
      <doi>10.1162/COLI_a_00299</doi>
      <url hash="4373f1eb">J17-4002</url>
      <bibkey>rozovskaya-etal-2017-adapting</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/fce">FCE</pwcdataset>
    </paper>
    <paper id="4">
      <title>HyperLex : A Large-Scale Evaluation of Graded Lexical Entailment<fixed-case>H</fixed-case>yper<fixed-case>L</fixed-case>ex: A Large-Scale Evaluation of Graded Lexical Entailment</title>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Daniela</first><last>Gerz</last></author>
      <author><first>Douwe</first><last>Kiela</last></author>
      <author><first>Felix</first><last>Hill</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <abstract>We introduce HyperLexa data set and evaluation resource that quantifies the extent of the semantic category membership, that is, type-of relation, also known as <a href="https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy">hyponymyhypernymy</a> or lexical entailment (LE) relation between 2,616 concept pairs. Cognitive psychology research has established that typicality and category / class membership are computed in <a href="https://en.wikipedia.org/wiki/Semantic_memory">human semantic memory</a> as a gradual rather than <a href="https://en.wikipedia.org/wiki/Binary_relation">binary relation</a>. Nevertheless, most <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP research</a> and existing large-scale inventories of concept category membership (WordNet, <a href="https://en.wikipedia.org/wiki/DBPedia">DBPedia</a>, etc.) treat category membership and LE as binary. To address this, we asked hundreds of <a href="https://en.wikipedia.org/wiki/First_language">native English speakers</a> to indicate typicality and strength of <a href="https://en.wikipedia.org/wiki/Categorization">category membership</a> between a diverse range of concept pairs on a <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourcing platform</a>. Our results confirm that category membership and LE are indeed more gradual than <a href="https://en.wikipedia.org/wiki/Binary_relation">binary</a>. We then compare these human judgments with the predictions of automatic systems, which reveals a huge gap between human performance and state-of-the-art LE, distributional and representation learning models, and substantial differences between the models themselves. We discuss a pathway for improving semantic models to overcome this discrepancy, and indicate future application areas for improved graded LE systems.</abstract>
      <pages>781–835</pages>
      <doi>10.1162/COLI_a_00301</doi>
      <url hash="099e7e5d">J17-4004</url>
      <bibkey>vulic-etal-2017-hyperlex</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hyperlex">HyperLex</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/dbpedia">DBpedia</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/imagenet">ImageNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/yago">YAGO</pwcdataset>
    </paper>
    </volume>
</collection>