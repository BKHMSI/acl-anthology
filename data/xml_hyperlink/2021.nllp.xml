<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.nllp">
  <volume id="1" ingest-date="2021-10-28">
    <meta>
      <booktitle>Proceedings of the Natural Legal Language Processing Workshop 2021</booktitle>
      <editor><first>Nikolaos</first><last>Aletras</last></editor>
      <editor><first>Ion</first><last>Androutsopoulos</last></editor>
      <editor><first>Leslie</first><last>Barrett</last></editor>
      <editor><first>Catalina</first><last>Goanta</last></editor>
      <editor><first>Daniel</first><last>Preotiuc-Pietro</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Punta Cana, Dominican Republic</address>
      <month>November</month>
      <year>2021</year>
    </meta>
    <frontmatter>
      <url hash="db09a562">2021.nllp-1.0</url>
      <bibkey>nllp-2021-natural</bibkey>
    </frontmatter>
    <paper id="5">
      <title>A Multilingual Approach to Identify and Classify Exceptional Measures against COVID-19<fixed-case>COVID</fixed-case>-19</title>
      <author><first>Georgios</first><last>Tziafas</last></author>
      <author><first>Eugenie</first><last>de Saint-Phalle</last></author>
      <author><first>Wietse</first><last>de Vries</last></author>
      <author><first>Clara</first><last>Egger</last></author>
      <author><first>Tommaso</first><last>Caselli</last></author>
      <pages>46–62</pages>
      <abstract>The COVID-19 pandemic has witnessed the implementations of exceptional measures by governments across the world to counteract its impact. This work presents the initial results of an on-going project, EXCEPTIUS, aiming to automatically identify, classify and com- pare exceptional measures against COVID-19 across 32 countries in Europe. To this goal, we created a corpus of legal documents with sentence-level annotations of eight different classes of exceptional measures that are im- plemented across these countries. We evalu- ated multiple multi-label classifiers on a manu- ally annotated corpus at sentence level. The XLM-RoBERTa model achieves highest per- formance on this multilingual multi-label clas- sification task, with a <a href="https://en.wikipedia.org/wiki/Proportionality_(mathematics)">macro-average F1 score</a> of 59.8 %.</abstract>
      <url hash="ad6b41f8">2021.nllp-1.5</url>
      <bibkey>tziafas-etal-2021-multilingual</bibkey>
      <doi>10.18653/v1/2021.nllp-1.5</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="9">
      <title>JuriBERT : A Masked-Language Model Adaptation for French Legal Text<fixed-case>J</fixed-case>uri<fixed-case>BERT</fixed-case>: A Masked-Language Model Adaptation for <fixed-case>F</fixed-case>rench Legal Text</title>
      <author><first>Stella</first><last>Douka</last></author>
      <author><first>Hadi</first><last>Abdine</last></author>
      <author><first>Michalis</first><last>Vazirgiannis</last></author>
      <author><first>Rajaa</first><last>El Hamdani</last></author>
      <author><first>David</first><last>Restrepo Amariles</last></author>
      <pages>95–101</pages>
      <abstract>Language models have proven to be very useful when adapted to specific domains. Nonetheless, little research has been done on the adaptation of domain-specific BERT models in the <a href="https://en.wikipedia.org/wiki/French_language">French language</a>. In this paper, we focus on creating a <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> adapted to <a href="https://en.wikipedia.org/wiki/Law_of_France">French legal text</a> with the goal of helping law professionals. We conclude that some specific tasks do not benefit from generic language models pre-trained on large amounts of data. We explore the use of smaller <a href="https://en.wikipedia.org/wiki/Software_architecture">architectures</a> in domain-specific sub-languages and their benefits for <a href="https://en.wikipedia.org/wiki/Law_of_France">French legal text</a>. We prove that domain-specific pre-trained models can perform better than their equivalent generalised ones in the legal domain. Finally, we release JuriBERT, a new set of BERT models adapted to the <a href="https://en.wikipedia.org/wiki/Law_of_France">French legal domain</a>.</abstract>
      <url hash="9b9303ae">2021.nllp-1.9</url>
      <bibkey>douka-etal-2021-juribert</bibkey>
      <doi>10.18653/v1/2021.nllp-1.9</doi>
    </paper>
    <paper id="11">
      <title>A Free Format Legal Question Answering System</title>
      <author><first>Soha</first><last>Khazaeli</last></author>
      <author><first>Janardhana</first><last>Punuru</last></author>
      <author><first>Chad</first><last>Morris</last></author>
      <author><first>Sanjay</first><last>Sharma</last></author>
      <author><first>Bert</first><last>Staub</last></author>
      <author><first>Michael</first><last>Cole</last></author>
      <author><first>Sunny</first><last>Chiu-Webster</last></author>
      <author><first>Dhruv</first><last>Sakalley</last></author>
      <pages>107–113</pages>
      <abstract>We present an information retrieval-based question answer system to answer legal questions. The system is not limited to a predefined set of questions or patterns and uses both sparse vector search and <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> for input to a BERT-based answer re-ranking system. A combination of general domain and legal domain data is used for training. This natural question answering system is in production and is used commercially.</abstract>
      <url hash="3a813ff5">2021.nllp-1.11</url>
      <bibkey>khazaeli-etal-2021-free</bibkey>
      <doi>10.18653/v1/2021.nllp-1.11</doi>
    </paper>
    <paper id="16">
      <title>Legal Terminology Extraction with the Termolator</title>
      <author><first>Nhi</first><last>Pham</last></author>
      <author><first>Lachlan</first><last>Pham</last></author>
      <author><first>Adam L.</first><last>Meyers</last></author>
      <pages>155–162</pages>
      <abstract>Domain-specific terminology is ubiquitous in <a href="https://en.wikipedia.org/wiki/Legal_instrument">legal documents</a>. Despite potential utility in populating <a href="https://en.wikipedia.org/wiki/Glossary">glossaries</a> and <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontologies</a> or as arguments in <a href="https://en.wikipedia.org/wiki/Information_extraction">information extraction</a> and document classification tasks, there has been limited work done for legal terminology extraction. This paper describes some work to remedy this omission. In the described research, we make some modifications to the Termolator, a high-performing, open-source terminology extractor which has been tuned to scientific articles. Our changes are designed to improve the Termolator’s results when applied to United States Supreme Court decisions. Unaltered and using the recommended settings, the original Termolator provides a list of terminology with a precision of 23 % and 25 % for the categories of economic activity (development set) and criminal procedures (test set) respectively. These were the most frequently occurring broad issues in Washington University in St. Louis Database corpus, a database of Supreme Court decisions that have been manually classified by topic. Our contribution includes the introduction of several legal domain-specific filtration steps and changes to the web search relevance score ; each incrementally improved precision culminating in a combined <a href="https://en.wikipedia.org/wiki/Significant_figures">precision</a> of 63 % and 65 %. We also evaluated the baseline version of the Termolator on more specific subcategories and on broad issues with fewer cases. Our results show that a narrowed scope as well as smaller document numbers significantly lower the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a>. In both cases, the modifications to the Termolator improve <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a>.</abstract>
      <url hash="34970b99">2021.nllp-1.16</url>
      <bibkey>pham-etal-2021-legal</bibkey>
      <doi>10.18653/v1/2021.nllp-1.16</doi>
    </paper>
    <paper id="18">
      <title>Named Entity Recognition in Historic Legal Text : A Transformer and State Machine Ensemble Method</title>
      <author><first>Fernando</first><last>Trias</last></author>
      <author><first>Hongming</first><last>Wang</last></author>
      <author><first>Sylvain</first><last>Jaume</last></author>
      <author><first>Stratos</first><last>Idreos</last></author>
      <pages>172–179</pages>
      <abstract>Older legal texts are often scanned and digitized via Optical Character Recognition (OCR), which results in numerous errors. Although <a href="https://en.wikipedia.org/wiki/Spell_checker">spelling</a> and <a href="https://en.wikipedia.org/wiki/Spell_checker">grammar checkers</a> can correct much of the scanned text automatically, Named Entity Recognition (NER) is challenging, making correction of names difficult. To solve this, we developed an ensemble language model using a transformer neural network architecture combined with a <a href="https://en.wikipedia.org/wiki/Finite-state_machine">finite state machine</a> to extract names from English-language legal text. We use the US-based English language Harvard Caselaw Access Project for training and testing. Then, the extracted <a href="https://en.wikipedia.org/wiki/Name">names</a> are subjected to heuristic textual analysis to identify errors, make corrections, and quantify the extent of problems. With this <a href="https://en.wikipedia.org/wiki/System">system</a>, we are able to extract most <a href="https://en.wikipedia.org/wiki/Name">names</a>, automatically correct numerous errors and identify potential mistakes that can later be reviewed for manual correction.</abstract>
      <url hash="24d1967c">2021.nllp-1.18</url>
      <bibkey>trias-etal-2021-named</bibkey>
      <doi>10.18653/v1/2021.nllp-1.18</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
    </paper>
    <paper id="23">
      <title>Semi-automatic Triage of Requests for Free Legal Assistance</title>
      <author><first>Meladel</first><last>Mistica</last></author>
      <author><first>Jey Han</first><last>Lau</last></author>
      <author><first>Brayden</first><last>Merrifield</last></author>
      <author><first>Kate</first><last>Fazio</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <pages>217–227</pages>
      <abstract>Free legal assistance is critically under-resourced, and many of those who seek legal help have their needs unmet. A major bottleneck in the provision of free legal assistance to those most in need is the determination of the precise nature of the legal problem. This paper describes a collaboration with a major provider of free legal assistance, and the deployment of natural language processing models to assign area-of-law categories to real-world requests for <a href="https://en.wikipedia.org/wiki/Legal_aid">legal assistance</a>. In particular, we focus on an investigation of <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> to generate efficiencies in the triage process, but also the risks associated with naive use of model predictions, including fairness across different user demographics.</abstract>
      <url hash="80f93c57">2021.nllp-1.23</url>
      <bibkey>mistica-etal-2021-semi</bibkey>
      <doi>10.18653/v1/2021.nllp-1.23</doi>
    </paper>
    </volume>
</collection>