<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.nuse">
  <volume id="1" ingest-date="2021-05-24">
    <meta>
      <booktitle>Proceedings of the Third Workshop on Narrative Understanding</booktitle>
      <editor><first>Nader</first><last>Akoury</last></editor>
      <editor><first>Faeze</first><last>Brahman</last></editor>
      <editor><first>Snigdha</first><last>Chaturvedi</last></editor>
      <editor><first>Elizabeth</first><last>Clark</last></editor>
      <editor><first>Mohit</first><last>Iyyer</last></editor>
      <editor><first>Lara J.</first><last>Martin</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Virtual</address>
      <month>June</month>
      <year>2021</year>
      <url hash="85c83d62">2021.nuse-1</url>
    </meta>
    <frontmatter>
      <url hash="d9b091ca">2021.nuse-1.0</url>
      <bibkey>nuse-2021-narrative</bibkey>
    </frontmatter>
    <paper id="4">
      <title>Document-level Event Extraction with Efficient End-to-end Learning of Cross-event Dependencies</title>
      <author><first>Kung-Hsiang</first><last>Huang</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <pages>36–47</pages>
      <abstract>Fully understanding narratives often requires identifying events in the context of whole documents and modeling the event relations. However, document-level event extraction is a challenging task as it requires the extraction of event and entity coreference, and capturing arguments that span across different sentences. Existing works on <a href="https://en.wikipedia.org/wiki/Event_extraction">event extraction</a> usually confine on extracting events from single sentences, which fail to capture the relationships between the event mentions at the scale of a document, as well as the event arguments that appear in a different sentence than the event trigger. In this paper, we propose an end-to-end model leveraging Deep Value Networks (DVN), a structured prediction algorithm, to efficiently capture cross-event dependencies for document-level event extraction. Experimental results show that our approach achieves comparable performance to CRF-based models on ACE05, while enjoys significantly higher computational efficiency.</abstract>
      <url hash="ea52ccfa">2021.nuse-1.4</url>
      <doi>10.18653/v1/2021.nuse-1.4</doi>
      <bibkey>huang-peng-2021-document</bibkey>
    </paper>
    <paper id="5">
      <title>Gender and Representation Bias in GPT-3 Generated Stories<fixed-case>GPT</fixed-case>-3 Generated Stories</title>
      <author><first>Li</first><last>Lucy</last></author>
      <author><first>David</first><last>Bamman</last></author>
      <pages>48–55</pages>
      <abstract>Using <a href="https://en.wikipedia.org/wiki/Topic_modeling">topic modeling</a> and lexicon-based word similarity, we find that stories generated by GPT-3 exhibit many known <a href="https://en.wikipedia.org/wiki/Gender_role">gender stereotypes</a>. Generated stories depict different topics and descriptions depending on GPT-3’s perceived gender of the character in a prompt, with feminine characters more likely to be associated with family and appearance, and described as less powerful than masculine characters, even when associated with high power verbs in a prompt. Our study raises questions on how one can avoid unintended social biases when using large language models for <a href="https://en.wikipedia.org/wiki/Storytelling">storytelling</a>.</abstract>
      <url hash="06782ba9">2021.nuse-1.5</url>
      <doi>10.18653/v1/2021.nuse-1.5</doi>
      <bibkey>lucy-bamman-2021-gender</bibkey>
      <pwccode url="https://github.com/lucy3/gpt3_gender" additional="false">lucy3/gpt3_gender</pwccode>
    </paper>
    <paper id="6">
      <title>Transformer-based Screenplay Summarization Using Augmented Learning Representation with Dialogue Information</title>
      <author><first>Myungji</first><last>Lee</last></author>
      <author><first>Hongseok</first><last>Kwon</last></author>
      <author><first>Jaehun</first><last>Shin</last></author>
      <author><first>WonKee</first><last>Lee</last></author>
      <author><first>Baikjin</first><last>Jung</last></author>
      <author><first>Jong-Hyeok</first><last>Lee</last></author>
      <pages>56–61</pages>
      <abstract>Screenplay summarization is the task of extracting informative scenes from a <a href="https://en.wikipedia.org/wiki/Screenplay">screenplay</a>. The <a href="https://en.wikipedia.org/wiki/Screenplay">screenplay</a> contains turning point (TP) events that change the story direction and thus define the <a href="https://en.wikipedia.org/wiki/Story_structure">story structure</a> decisively. Accordingly, this <a href="https://en.wikipedia.org/wiki/Task_(computing)">task</a> can be defined as the TP identification task. We suggest using dialogue information, one attribute of <a href="https://en.wikipedia.org/wiki/Screenplay">screenplays</a>, motivated by previous work that discovered that TPs have a relation with <a href="https://en.wikipedia.org/wiki/Dialogue">dialogues</a> appearing in <a href="https://en.wikipedia.org/wiki/Screenplay">screenplays</a>. To teach a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> this characteristic, we add a dialogue feature to the input embedding. Moreover, in an attempt to improve the model architecture of previous studies, we replace LSTM with Transformer. We observed that the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> can better identify TPs in a <a href="https://en.wikipedia.org/wiki/Screenplay">screenplay</a> by using dialogue information and that a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> adopting Transformer outperforms LSTM-based models.</abstract>
      <url hash="75f5ca3f">2021.nuse-1.6</url>
      <doi>10.18653/v1/2021.nuse-1.6</doi>
      <bibkey>lee-etal-2021-transformer</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/tripod">TRIPOD</pwcdataset>
    </paper>
    <paper id="7">
      <title>Plug-and-Blend : A Framework for Controllable Story Generation with Blended Control Codes</title>
      <author><first>Zhiyu</first><last>Lin</last></author>
      <author><first>Mark</first><last>Riedl</last></author>
      <pages>62–71</pages>
      <abstract>We describe a Plug-and-Play controllable language generation framework, Plug-and-Blend, that allows a human user to input multiple control codes (topics). In the context of automated story generation, this allows a human user lose or fine grained control of the topics that will appear in the generated story, and can even allow for overlapping, blended topics. We show that our framework, working with different generation models, controls the generation towards given continuous-weighted control codes while keeping the generated sentences fluent, demonstrating strong blending capability.</abstract>
      <url hash="89fbed11">2021.nuse-1.7</url>
      <doi>10.18653/v1/2021.nuse-1.7</doi>
      <bibkey>lin-riedl-2021-plug</bibkey>
      <pwccode url="https://github.com/xxbidiao/plug-and-blend" additional="false">xxbidiao/plug-and-blend</pwccode>
    </paper>
    </volume>
</collection>