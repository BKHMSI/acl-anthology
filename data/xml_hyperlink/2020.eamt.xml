<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.eamt">
  <volume id="1" ingest-date="2020-08-11">
    <meta>
      <booktitle>Proceedings of the 22nd Annual Conference of the European Association for Machine Translation</booktitle>
      <editor><first>André</first><last>Martins</last></editor>
      <editor><first>Helena</first><last>Moniz</last></editor>
      <editor><first>Sara</first><last>Fumega</last></editor>
      <editor><first>Bruno</first><last>Martins</last></editor>
      <editor><first>Fernando</first><last>Batista</last></editor>
      <editor><first>Luisa</first><last>Coheur</last></editor>
      <editor><first>Carla</first><last>Parra</last></editor>
      <editor><first>Isabel</first><last>Trancoso</last></editor>
      <editor><first>Marco</first><last>Turchi</last></editor>
      <editor><first>Arianna</first><last>Bisazza</last></editor>
      <editor><first>Joss</first><last>Moorkens</last></editor>
      <editor><first>Ana</first><last>Guerberof</last></editor>
      <editor><first>Mary</first><last>Nurminen</last></editor>
      <editor><first>Lena</first><last>Marg</last></editor>
      <editor><first>Mikel L.</first><last>Forcada</last></editor>
      <publisher>European Association for Machine Translation</publisher>
      <address>Lisboa, Portugal</address>
      <month>November</month>
      <year>2020</year>
      <url hash="7d46b928">2020.eamt-1</url>
    </meta>
    <frontmatter>
      <url hash="ab0a7709">2020.eamt-1.0</url>
      <bibkey>eamt-2020-european</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Efficiently Reusing Old Models Across Languages via Transfer Learning</title>
      <author><first>Tom</first><last>Kocmi</last></author>
      <author><first>Ondřej</first><last>Bojar</last></author>
      <pages>19–28</pages>
      <abstract>Recent progress in neural machine translation (NMT) is directed towards larger <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a> trained on an increasing amount of hardware resources. As a result, NMT models are costly to train, both financially, due to the electricity and hardware cost, and environmentally, due to the <a href="https://en.wikipedia.org/wiki/Carbon_footprint">carbon footprint</a>. It is especially true in <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> for its additional cost of training the parent model before transferring knowledge and training the desired <a href="https://en.wikipedia.org/wiki/Child_model">child model</a>. In this paper, we propose a simple method of re-using an already trained <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> for different language pairs where there is no need for modifications in <a href="https://en.wikipedia.org/wiki/Statistical_model">model architecture</a>. Our approach does not need a separate parent model for each investigated language pair, as it is typical in NMT transfer learning. To show the applicability of our method, we recycle a Transformer model trained by different researchers and use it to seed models for different language pairs. We achieve better translation quality and shorter <a href="https://en.wikipedia.org/wiki/Convergence_of_random_variables">convergence times</a> than when training from random initialization.</abstract>
      <url hash="dc6b5b55">2020.eamt-1.3</url>
      <bibkey>kocmi-bojar-2020-efficiently</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2018">WMT 2018</pwcdataset>
    </paper>
    <paper id="4">
      <title>Efficient <a href="https://en.wikipedia.org/wiki/Transfer_learning">Transfer Learning</a> for Quality Estimation with Bottleneck Adapter Layer</title>
      <author><first>Hao</first><last>Yang</last></author>
      <author><first>Minghan</first><last>Wang</last></author>
      <author><first>Ning</first><last>Xie</last></author>
      <author><first>Ying</first><last>Qin</last></author>
      <author><first>Yao</first><last>Deng</last></author>
      <pages>29–34</pages>
      <abstract>The Predictor-Estimator framework for quality estimation (QE) is commonly used for its strong performance. Where the predictor and <a href="https://en.wikipedia.org/wiki/Estimator">estimator</a> works on <a href="https://en.wikipedia.org/wiki/Feature_extraction">feature extraction</a> and <a href="https://en.wikipedia.org/wiki/Quality_assurance">quality evaluation</a>, respectively. However, training the <a href="https://en.wikipedia.org/wiki/Prediction">predictor</a> from scratch is computationally expensive. In this paper, we propose an efficient transfer learning framework to transfer knowledge from NMT dataset into <a href="https://en.wikipedia.org/wiki/Quantum_electrodynamics">QE models</a>. A Predictor-Estimator alike model named BAL-QE is also proposed, aiming to extract high quality features with pre-trained NMT model, and make classification with a fine-tuned Bottleneck Adapter Layer (BAL). The experiment shows that BAL-QE achieves 97 % of the SOTA performance in WMT19 En-De and En-Ru QE tasks by only training 3 % of parameters within 4 hours on 4 Titan XP GPUs. Compared with the commonly used NuQE baseline, BAL-QE achieves 47 % (En-Ru) and 75 % (En-De) of performance promotions.</abstract>
      <url hash="44ec6031">2020.eamt-1.4</url>
      <bibkey>yang-etal-2020-efficient</bibkey>
    </paper>
    <paper id="6">
      <title>Incorporating External Annotation to improve Named Entity Translation in NMT<fixed-case>NMT</fixed-case></title>
      <author><first>Maciej</first><last>Modrzejewski</last></author>
      <author><first>Miriam</first><last>Exel</last></author>
      <author><first>Bianka</first><last>Buschbeck</last></author>
      <author><first>Thanh-Le</first><last>Ha</last></author>
      <author><first>Alexander</first><last>Waibel</last></author>
      <pages>45–51</pages>
      <abstract>The correct translation of named entities (NEs) still poses a challenge for conventional neural machine translation (NMT) systems. This study explores methods incorporating <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition (NER)</a> into <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">NMT</a> with the aim to improve <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity translation</a>. It proposes an annotation method that integrates <a href="https://en.wikipedia.org/wiki/Named_entity">named entities</a> and insideoutsidebeginning (IOB) tagging into the neural network input with the use of source factors. Our experiments on EnglishGerman and English Chinese show that just by including different NE classes and IOB tagging, we can increase the BLEU score by around 1 point using the standard test set from WMT2019 and achieve up to 12 % increase in NE translation rates over a strong baseline.</abstract>
      <url hash="a639a645">2020.eamt-1.6</url>
      <bibkey>modrzejewski-etal-2020-incorporating</bibkey>
    </paper>
    <paper id="8">
      <title>A multi-source approach for BretonFrench hybrid machine translation<fixed-case>B</fixed-case>reton–<fixed-case>F</fixed-case>rench hybrid machine translation</title>
      <author><first>Víctor M.</first><last>Sánchez-Cartagena</last></author>
      <author><first>Mikel L.</first><last>Forcada</last></author>
      <author><first>Felipe</first><last>Sánchez-Martínez</last></author>
      <pages>61–70</pages>
      <abstract>Corpus-based approaches to machine translation (MT) have difficulties when the amount of parallel corpora to use for training is scarce, especially if the languages involved in the <a href="https://en.wikipedia.org/wiki/Translation">translation</a> are highly inflected. This problem can be addressed from different perspectives, including <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a>, <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a>, and the use of additional resources, such as those used in rule-based MT. This paper focuses on the hybridisation of rule-based MT and neural MT for the BretonFrench under-resourced language pair in an attempt to study to what extent the rule-based MT resources help improve the translation quality of the neural MT system for this particular under-resourced language pair. We combine both translation approaches in a multi-source neural MT architecture and find out that, even though the rule-based system has a low performance according to automatic evaluation metrics, using it leads to improved translation quality.</abstract>
      <url hash="428bc35d">2020.eamt-1.8</url>
      <bibkey>sanchez-cartagena-etal-2020-multi</bibkey>
    </paper>
    <paper id="9">
      <title>Leveraging Multilingual Resources for Language Invariant Sentiment Analysis</title>
      <author><first>Allen</first><last>Antony</last></author>
      <author><first>Arghya</first><last>Bhattacharya</last></author>
      <author><first>Jaipal</first><last>Goud</last></author>
      <author><first>Radhika</first><last>Mamidi</last></author>
      <pages>71–79</pages>
      <abstract>Sentiment analysis is a widely researched NLP problem with state-of-the-art solutions capable of attaining human-like accuracies for various languages. However, these methods rely heavily on large amounts of labeled data or sentiment weighted language-specific lexical resources that are unavailable for low-resource languages. Our work attempts to tackle this data scarcity issue by introducing a neural architecture for language invariant sentiment analysis capable of leveraging various monolingual datasets for training without any kind of cross-lingual supervision. The proposed architecture attempts to learn language agnostic sentiment features via adversarial training on multiple resource-rich languages which can then be leveraged for inferring sentiment information at a sentence level on a low resource language. Our model outperforms the current state-of-the-art methods on the Multilingual Amazon Review Text Classification dataset [ REF ] and achieves significant performance gains over prior work on the low resource Sentiraama corpus [ REF ]. A detailed analysis of our research highlights the ability of our <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> to perform significantly well in the presence of minimal amounts of training data for low resource languages.</abstract>
      <url hash="fb4c0580">2020.eamt-1.9</url>
      <bibkey>antony-etal-2020-leveraging</bibkey>
    </paper>
    <paper id="12">
      <title>Double Attention-based Multimodal Neural Machine Translation with Semantic Image Regions</title>
      <author><first>Yuting</first><last>Zhao</last></author>
      <author><first>Mamoru</first><last>Komachi</last></author>
      <author><first>Tomoyuki</first><last>Kajiwara</last></author>
      <author><first>Chenhui</first><last>Chu</last></author>
      <pages>105–114</pages>
      <abstract>Existing studies on multimodal neural machine translation (MNMT) have mainly focused on the effect of combining visual and textual modalities to improve translations. However, it has been suggested that the <a href="https://en.wikipedia.org/wiki/Visual_system">visual modality</a> is only marginally beneficial. Conventional visual attention mechanisms have been used to select the visual features from equally-sized grids generated by convolutional neural networks (CNNs), and may have had modest effects on aligning the visual concepts associated with textual objects, because the grid visual features do not capture semantic information. In contrast, we propose the application of semantic image regions for MNMT by integrating visual and textual features using two individual attention mechanisms (double attention). We conducted experiments on the Multi30k dataset and achieved an improvement of 0.5 and 0.9 BLEU points for English-German and English-French translation tasks, compared with the MNMT with grid visual features. We also demonstrated concrete improvements on <a href="https://en.wikipedia.org/wiki/Translation">translation</a> performance benefited from semantic image regions.</abstract>
      <url hash="fb521973">2020.eamt-1.12</url>
      <bibkey>zhao-etal-2020-double</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-genome">Visual Genome</pwcdataset>
    </paper>
    <paper id="14">
      <title>Fine-grained Human Evaluation of Transformer and Recurrent Approaches to <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a> for English-to-Chinese<fixed-case>E</fixed-case>nglish-to-<fixed-case>C</fixed-case>hinese</title>
      <author><first>Yuying</first><last>Ye</last></author>
      <author><first>Antonio</first><last>Toral</last></author>
      <pages>125–134</pages>
      <abstract>This research presents a fine-grained human evaluation to compare the Transformer and recurrent approaches to neural machine translation (MT), on the translation direction English-to-Chinese. To this end, we develop an error taxonomy compliant with the Multidimensional Quality Metrics (MQM) framework that is customised to the relevant phenomena of this translation direction. We then conduct an <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error annotation</a> using this customised error taxonomy on the output of state-of-the-art recurrent- and Transformer-based MT systems on a subset of WMT2019’s news test set. The resulting annotation shows that, compared to the best recurrent system, the best Transformer system results in a 31 % reduction of the total number of errors and it produced significantly less errors in 10 out of 22 error categories. We also note that two of the <a href="https://en.wikipedia.org/wiki/System">systems</a> evaluated do not produce any error for a category that was relevant for this translation direction prior to the advent of NMT systems : Chinese classifiers.</abstract>
      <url hash="42195dd4">2020.eamt-1.14</url>
      <bibkey>ye-toral-2020-fine</bibkey>
      <pwccode url="https://github.com/yy-ye/mqm-analysis" additional="false">yy-ye/mqm-analysis</pwccode>
    </paper>
    <paper id="15">
      <title>Correct Me If You Can : Learning from Error Corrections and Markings</title>
      <author><first>Julia</first><last>Kreutzer</last></author>
      <author><first>Nathaniel</first><last>Berger</last></author>
      <author><first>Stefan</first><last>Riezler</last></author>
      <pages>135–144</pages>
      <abstract>Sequence-to-sequence learning involves a trade-off between <a href="https://en.wikipedia.org/wiki/Signal_strength_in_telecommunications">signal strength</a> and annotation cost of training data. For example, machine translation data range from costly expert-generated translations that enable <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>, to weak quality-judgment feedback that facilitate <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>. We present the first user study on annotation cost and <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learnability</a> for the less popular annotation mode of error markings. We show that error markings for translations of TED talks from <a href="https://en.wikipedia.org/wiki/English_language">English</a> to <a href="https://en.wikipedia.org/wiki/German_language">German</a> allow precise credit assignment while requiring significantly less human effort than correcting / post-editing, and that error-marked data can be used successfully to fine-tune neural machine translation models.</abstract>
      <url hash="e7af16b9">2020.eamt-1.15</url>
      <bibkey>kreutzer-etal-2020-correct</bibkey>
      <pwccode url="https://github.com/StatNLP/mt-correct-mark-interface" additional="false">StatNLP/mt-correct-mark-interface</pwccode>
    </paper>
    <paper id="17">
      <title>Fine-Grained Error Analysis on English-to-Japanese Machine Translation in the Medical Domain<fixed-case>E</fixed-case>nglish-to-<fixed-case>J</fixed-case>apanese Machine Translation in the Medical Domain</title>
      <author><first>Takeshi</first><last>Hayakawa</last></author>
      <author><first>Yuki</first><last>Arase</last></author>
      <pages>155–164</pages>
      <abstract>We performed a detailed <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error analysis</a> in domain-specific neural machine translation (NMT) for the English and Japanese language pair with fine-grained manual annotation. Despite its importance for advancing NMT technologies, research on the performance of domain-specific NMT and non-European languages has been limited. In this study, we designed an error typology based on the error types that were typically generated by NMT systems and might cause significant impact in technical translations : <a href="https://en.wikipedia.org/wiki/Addition">Addition</a>, Omission, <a href="https://en.wikipedia.org/wiki/Mistranslation">Mistranslation</a>, <a href="https://en.wikipedia.org/wiki/Grammar">Grammar</a>, and <a href="https://en.wikipedia.org/wiki/Terminology">Terminology</a>. The <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error annotation</a> was targeted to the <a href="https://en.wikipedia.org/wiki/Medicine">medical domain</a> and was performed by experienced professional translators specialized in <a href="https://en.wikipedia.org/wiki/Medicine">medicine</a> under careful quality control. The <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a> detected 4,912 errors on 2,480 sentences, and the frequency and distribution of errors were analyzed. We found that the major errors in NMT were <a href="https://en.wikipedia.org/wiki/Mistranslation">Mistranslation</a> and Terminology rather than <a href="https://en.wikipedia.org/wiki/Addition">Addition</a> and Omission, which have been reported as typical problems of NMT. Interestingly, more errors occurred in documents for professionals compared with those for the general public. The results of our annotation work will be published as a parallel corpus with error labels, which are expected to contribute to developing better NMT models, automatic evaluation metrics, and quality estimation models.</abstract>
      <url hash="9555cccb">2020.eamt-1.17</url>
      <bibkey>hayakawa-arase-2020-fine</bibkey>
    </paper>
    <paper id="21">
      <title>Modelling Source- and Target- Language Syntactic Information as Conditional Context in Interactive Neural Machine Translation</title>
      <author><first>Kamal Kumar</first><last>Gupta</last></author>
      <author><first>Rejwanul</first><last>Haque</last></author>
      <author><first>Asif</first><last>Ekbal</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <pages>195–204</pages>
      <abstract>In interactive machine translation (MT), human translators correct errors in automatic translations in collaboration with the MT systems, which is seen as an effective way to improve the productivity gain in <a href="https://en.wikipedia.org/wiki/Translation">translation</a>. In this study, we model source-language syntactic constituency parse and target-language syntactic descriptions in the form of supertags as conditional context for interactive prediction in neural MT (NMT). We found that the supertags significantly improve productivity gain in <a href="https://en.wikipedia.org/wiki/Translation">translation</a> in interactive-predictive NMT (INMT), while syntactic parsing somewhat found to be effective in reducing human effort in <a href="https://en.wikipedia.org/wiki/Translation">translation</a>. Furthermore, when we model this source- and target-language syntactic information together as the conditional context, both types complement each other and our fully syntax-informed INMT model statistically significantly reduces human efforts in a FrenchtoEnglish translation task, achieving 4.30 points absolute (corresponding to 9.18 % relative) improvement in terms of word prediction accuracy (WPA) and 4.84 points absolute (corresponding to 9.01 % relative) reduction in terms of word stroke ratio (WSR) over the baseline.</abstract>
      <url hash="4554ca33">2020.eamt-1.21</url>
      <bibkey>gupta-etal-2020-modelling</bibkey>
    </paper>
    <paper id="28">
      <title>Evaluating the usefulness of <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> for the Polish translators in the European Commission<fixed-case>P</fixed-case>olish translators in the <fixed-case>E</fixed-case>uropean Commission</title>
      <author><first>Karolina</first><last>Stefaniak</last></author>
      <pages>263–269</pages>
      <abstract>The mission of the Directorate General for Translation (DGT) is to provide high-quality translation to help the European Commission communicate with EU citizens. To this end <a href="https://en.wikipedia.org/wiki/Deutsche_Gesellschaft_für_Internationale_Zusammenarbeit">DGT</a> employs almost 2000 translators from all EU official languages. But while the demand for <a href="https://en.wikipedia.org/wiki/Translation">translation</a> has been continuously growing, following a global trend, the number of translators has decreased. To cope with the demand, DGT extensively uses a CAT environment encompassing <a href="https://en.wikipedia.org/wiki/Translation_memory">translation memories</a>, terminology databases and recently also <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>. This paper examines the benefits and risks of using <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> to augment the productivity of inhouse DGT translators for the EnglishPolish language pair. Based on the analysis of a sample of NMTtranslated texts and on the observations of the working practices of Polish translators it is concluded that the possible productivity gain is still modest, while the risks to <a href="https://en.wikipedia.org/wiki/Quality_(business)">quality</a> are quite substantial.</abstract>
      <url hash="79c3e33d">2020.eamt-1.28</url>
      <bibkey>stefaniak-2020-evaluating</bibkey>
    </paper>
    <paper id="29">
      <title>Terminology-Constrained Neural Machine Translation at SAP<fixed-case>SAP</fixed-case></title>
      <author><first>Miriam</first><last>Exel</last></author>
      <author><first>Bianka</first><last>Buschbeck</last></author>
      <author><first>Lauritz</first><last>Brandt</last></author>
      <author><first>Simona</first><last>Doneva</last></author>
      <pages>271–280</pages>
      <abstract>This paper examines approaches to bias a neural machine translation model to adhere to terminology constraints in an industrial setup. In particular, we investigate variations of the <a href="https://en.wikipedia.org/wiki/Scientific_method">approach</a> by Dinu et al. (2019), which uses inline annotation of the target terms in the source segment plus source factor embeddings during <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training</a> and <a href="https://en.wikipedia.org/wiki/Statistical_inference">inference</a>, and compare them to constrained decoding. We describe the challenges with respect to terminology in our usage scenario at SAP and show how far the investigated methods can help to overcome them. We extend the original study to a new language pair and provide an in-depth evaluation including an <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error classification</a> and a <a href="https://en.wikipedia.org/wiki/Evaluation">human evaluation</a>.</abstract>
      <url hash="199ff6ff">2020.eamt-1.29</url>
      <bibkey>exel-etal-2020-terminology</bibkey>
    </paper>
    <paper id="31">
      <title>Bifixer and Bicleaner : two open-source tools to clean your parallel data</title>
      <author><first>Gema</first><last>Ramírez-Sánchez</last></author>
      <author><first>Jaume</first><last>Zaragoza-Bernabeu</last></author>
      <author><first>Marta</first><last>Bañón</last></author>
      <author><first>Sergio Ortiz</first><last>Rojas</last></author>
      <pages>291–298</pages>
      <abstract>This paper shows the utility of two open-source tools designed for parallel data cleaning : Bifixer and Bicleaner. Already used to clean highly noisy parallel content from crawled multilingual websites, we evaluate their performance in a different scenario : cleaning publicly available corpora commonly used to train machine translation systems. We choose four EnglishPortuguese corpora which we plan to use internally to compute <a href="https://en.wikipedia.org/wiki/Paraphrase">paraphrases</a> at a later stage. We clean the four <a href="https://en.wikipedia.org/wiki/Text_corpus">corpora</a> using both <a href="https://en.wikipedia.org/wiki/Tool">tools</a>, which are described in detail, and analyse the effect of some of the cleaning steps on them. We then compare machine translation training times and <a href="https://en.wikipedia.org/wiki/Quality_(business)">quality</a> before and after cleaning these <a href="https://en.wikipedia.org/wiki/Text_corpus">corpora</a>, showing a positive impact particularly for the noisiest ones.</abstract>
      <url hash="c45fb6c6">2020.eamt-1.31</url>
      <bibkey>ramirez-sanchez-etal-2020-bifixer</bibkey>
      <pwccode url="https://github.com/bitextor/bicleaner" additional="false">bitextor/bicleaner</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/opensubtitles">OpenSubtitles</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikimatrix">WikiMatrix</pwcdataset>
    </paper>
    <paper id="32">
      <title>An English-Swahili parallel corpus and its use for <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> in the <a href="https://en.wikipedia.org/wiki/News_media">news domain</a><fixed-case>E</fixed-case>nglish-<fixed-case>S</fixed-case>wahili parallel corpus and its use for neural machine translation in the news domain</title>
      <author><first>Felipe</first><last>Sánchez-Martínez</last></author>
      <author><first>Víctor M.</first><last>Sánchez-Cartagena</last></author>
      <author><first>Juan Antonio</first><last>Pérez-Ortiz</last></author>
      <author><first>Mikel L.</first><last>Forcada</last></author>
      <author><first>Miquel</first><last>Esplà-Gomis</last></author>
      <author><first>Andrew</first><last>Secker</last></author>
      <author><first>Susie</first><last>Coleman</last></author>
      <author><first>Julie</first><last>Wall</last></author>
      <pages>299–308</pages>
      <abstract>This paper describes our approach to create a neural machine translation system to translate between <a href="https://en.wikipedia.org/wiki/English_language">English</a> and Swahili (both directions) in the news domain, as well as the process we followed to crawl the necessary parallel corpora from the Internet. We report the results of a pilot human evaluation performed by the news media organisations participating in the H2020 EU-funded project GoURMET.</abstract>
      <url hash="a78dd32d">2020.eamt-1.32</url>
      <bibkey>sanchez-martinez-etal-2020-english</bibkey>
    </paper>
    <paper id="34">
      <title>A User Study of the <a href="https://en.wikipedia.org/wiki/Incremental_learning">Incremental Learning</a> in NMT<fixed-case>NMT</fixed-case></title>
      <author><first>Miguel</first><last>Domingo</last></author>
      <author><first>Mercedes</first><last>García-Martínez</last></author>
      <author><first>Álvaro</first><last>Peris</last></author>
      <author><first>Alexandre</first><last>Helle</last></author>
      <author><first>Amando</first><last>Estela</last></author>
      <author><first>Laurent</first><last>Bié</last></author>
      <author><first>Francisco</first><last>Casacuberta</last></author>
      <author><first>Manuel</first><last>Herranz</last></author>
      <pages>319–328</pages>
      <abstract>In the translation industry, human experts usually supervise and post-edit machine translation hypotheses. Adaptive neural machine translation systems, able to incrementally update the underlying models under an online learning regime, have been proven to be useful to improve the efficiency of this <a href="https://en.wikipedia.org/wiki/Workflow">workflow</a>. However, this incremental adaptation is somewhat unstable, and <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> may lead to undesirable side effects. One of them is the sporadic appearance of made-up words, as a byproduct of an erroneous application of subword segmentation techniques. In this work, we extend previous studies on on-the-fly adaptation of neural machine translation systems. We perform a <a href="https://en.wikipedia.org/wiki/User_study">user study</a> involving professional, experienced post-editors, delving deeper on the aforementioned problems. Results show that adaptive systems were able to learn how to generate the correct translation for task-specific terms, resulting in an improvement of the user’s productivity. We also observed a close similitude, in terms of <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphology</a>, between made-up words and the words that were expected.</abstract>
      <url hash="bb6d3db2">2020.eamt-1.34</url>
      <bibkey>domingo-etal-2020-user</bibkey>
    </paper>
    <paper id="42">
      <title>How do LSPs compute MT discounts? Presenting a company’s pipeline and its use<fixed-case>LSP</fixed-case>s compute <fixed-case>MT</fixed-case> discounts? Presenting a company’s pipeline and its use</title>
      <author><first>Randy</first><last>Scansani</last></author>
      <author><first>Lamis</first><last>Mhedhbi</last></author>
      <pages>393–401</pages>
      <abstract>In this paper we present a <a href="https://en.wikipedia.org/wiki/Pipeline_(software)">pipeline</a> developed at Acolad to test a Machine Translation (MT) engine and compute the <a href="https://en.wikipedia.org/wiki/Discounting">discount</a> to be applied when its output is used in production. Our <a href="https://en.wikipedia.org/wiki/Pipeline_(software)">pipeline</a> includes three main steps where <a href="https://en.wikipedia.org/wiki/Quality_(business)">quality</a> and <a href="https://en.wikipedia.org/wiki/Productivity">productivity</a> are measured through automatic metrics, manual evaluation, and by keeping track of editing and temporal effort during a post-editing task. Thanks to this approach, it is possible to evaluate the output quality and compute an engine-specific discount. Our test pipeline tackles the complexity of transforming productivity measurements into discounts by comparing the outcome of each of the above-mentioned steps to an estimate of the average productivity of translation from scratch. The <a href="https://en.wikipedia.org/wiki/Discounting">discount</a> is obtained by subtracting the resulting coefficient from the per-word rate. After a description of the <a href="https://en.wikipedia.org/wiki/Pipeline_(computing)">pipeline</a>, the paper presents its application on four engines, discussing its results and showing that our method to estimate post-editing effort through manual evaluation seems to capture the actual productivity. The <a href="https://en.wikipedia.org/wiki/Pipeline_(software)">pipeline</a> relies heavily on the work of professional post-editors, with the aim of creating a mutually beneficial cooperation between users and developers.</abstract>
      <url hash="bfc11647">2020.eamt-1.42</url>
      <bibkey>scansani-mhedhbi-2020-lsps</bibkey>
    </paper>
    <paper id="45">
      <title>Comparing <a href="https://en.wikipedia.org/wiki/Post-editing">Post-editing</a> based on Four Editing Actions against Translating with an Auto-Complete Feature</title>
      <author><first>Félix Do</first><last>Carmo</last></author>
      <pages>421–430</pages>
      <abstract>This article describes the results of a workshop in which 50 translators tested two experimental translation interfaces, as part of a project which aimed at studying the details of editing work. In this work, <a href="https://en.wikipedia.org/wiki/Editing">editing</a> is defined as a selection of four actions : deleting, inserting, moving and replacing words. Four texts, machine-translated from English into <a href="https://en.wikipedia.org/wiki/European_Portuguese">European Portuguese</a>, were post-edited in four different sessions in which each translator swapped between texts and two work modes. One of the <a href="https://en.wikipedia.org/wiki/Mode_(user_interface)">work modes</a> involved a typical auto-complete feature, and the other was based on the four actions. The participants answered surveys before, during and after the workshop. A descriptive analysis of the answers to the surveys and of the logs recorded during the experiments was performed. The four editing actions mode is shown to be more intrusive, but to allow for more planned decisions : although they take more time in this mode, translators hesitate less and make fewer edits. The article shows the usefulness of the <a href="https://en.wikipedia.org/wiki/Methodology">approach</a> for research on the <a href="https://en.wikipedia.org/wiki/Editing">editing task</a>.</abstract>
      <url hash="1b512029">2020.eamt-1.45</url>
      <bibkey>carmo-2020-comparing</bibkey>
    </paper>
    <paper id="49">
      <title>Document-Level Machine Translation Evaluation Project : Methodology, Effort and Inter-Annotator Agreement</title>
      <author><first>Sheila</first><last>Castilho</last></author>
      <pages>455–456</pages>
      <abstract>Document-level (doc-level) human eval-uation of machine translation (MT) has raised interest in the community after a fewattempts have disproved claims of human parity (Toral et al., 2018 ; Laubli et al.,2018). However, little is known about bestpractices regarding doc-level human evalu-ation. The goal of this project is to identifywhich methodologies better cope with i)the current state-of-the-art (SOTA) humanmetrics, ii) a possible complexity when as-signing a single score to a text consisted of‘good’ and ‘bad’ sentences, iii) a possibletiredness bias in doc-level set-ups, and iv)the difference in inter-annotator agreement(IAA) between sentence and doc-level set-ups.</abstract>
      <url hash="8bd5f97e">2020.eamt-1.49</url>
      <bibkey>castilho-2020-document</bibkey>
    </paper>
    <paper id="51">
      <title>CEF Data Marketplace : Powering a Long-term Supply of Language Data<fixed-case>CEF</fixed-case> Data Marketplace: Powering a Long-term Supply of Language Data</title>
      <author><first>Amir</first><last>Kamran</last></author>
      <author><first>Dace</first><last>Dzeguze</last></author>
      <author><first>Jaap</first><last>van der Meer</last></author>
      <author><first>Milica</first><last>Panic</last></author>
      <author><first>Alessandro</first><last>Cattelan</last></author>
      <author><first>Daniele</first><last>Patrioli</last></author>
      <author><first>Luisa</first><last>Bentivogli</last></author>
      <author><first>Marco</first><last>Turchi</last></author>
      <pages>459–460</pages>
      <abstract>We describe the CEF Data Marketplace project, which focuses on the development of a trading platform of translation data for language professionals : translators, machine translation (MT) developers, language service providers (LSPs), translation buyers and government bodies. The CEF Data Marketplace platform will be designed and built to manage and trade data for all languages and domains. This project will open a continuous and longterm supply of <a href="https://en.wikipedia.org/wiki/Language_structure">language data</a> for MT and other machine learning applications.</abstract>
      <url hash="5d7cdf1a">2020.eamt-1.51</url>
      <bibkey>kamran-etal-2020-cef</bibkey>
    </paper>
    <paper id="59">
      <title>MICE : a middleware layer for MT<fixed-case>MICE</fixed-case>: a middleware layer for <fixed-case>MT</fixed-case></title>
      <author><first>Joachim</first><last>Van den Bogaert</last></author>
      <author><first>Tom</first><last>Vanallemeersch</last></author>
      <author><first>Heidi</first><last>Depraetere</last></author>
      <pages>475–476</pages>
      <abstract>The MICE project (2018-2020) will deliver a middleware layer for improving the output quality of the eTranslation system of EC’s Connecting Europe Facility through additional services, such as domain adaptation and <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>. It will also deliver a <a href="https://en.wikipedia.org/wiki/Web_portal">user portal</a>, allowing for <a href="https://en.wikipedia.org/wiki/Post-editing">human post-editing</a>.</abstract>
      <url hash="e078908c">2020.eamt-1.59</url>
      <bibkey>van-den-bogaert-etal-2020-mice</bibkey>
    </paper>
    <paper id="60">
      <title>Neural Translation for the European Union (NTEU) Project<fixed-case>E</fixed-case>uropean <fixed-case>U</fixed-case>nion (<fixed-case>NTEU</fixed-case>) Project</title>
      <author><first>Laurent</first><last>Bié</last></author>
      <author><first>Aleix</first><last>Cerdà-i-Cucó</last></author>
      <author><first>Hans</first><last>Degroote</last></author>
      <author><first>Amando</first><last>Estela</last></author>
      <author><first>Mercedes</first><last>García-Martínez</last></author>
      <author><first>Manuel</first><last>Herranz</last></author>
      <author><first>Alejandro</first><last>Kohan</last></author>
      <author><first>Maite</first><last>Melero</last></author>
      <author><first>Tony</first><last>O’Dowd</last></author>
      <author><first>Sinéad</first><last>O’Gorman</last></author>
      <author><first>Mārcis</first><last>Pinnis</last></author>
      <author><first>Roberts</first><last>Rozis</last></author>
      <author><first>Riccardo</first><last>Superbo</last></author>
      <author><first>Artūrs</first><last>Vasiļevskis</last></author>
      <pages>477–478</pages>
      <abstract>The Neural Translation for the European Union (NTEU) project aims to build a neural engine farm with all European official language combinations for eTranslation, without the necessity to use a high-resourced language as a pivot. NTEU started in September 2019 and will run until August 2021.</abstract>
      <url hash="cb823ed0">2020.eamt-1.60</url>
      <bibkey>bie-etal-2020-neural</bibkey>
    </paper>
    <paper id="62">
      <title>OCR, Classification &amp; Machine Translation (OCCAM)<fixed-case>OCR</fixed-case>, Classification

&amp; Machine Translation (<fixed-case>OCCAM</fixed-case>)</title>
      <author><first>Joachim</first><last>Van den Bogaert</last></author>
      <author><first>Arne</first><last>Defauw</last></author>
      <author><first>Frederic</first><last>Everaert</last></author>
      <author><first>Koen</first><last>Van Winckel</last></author>
      <author><first>Alina</first><last>Kramchaninova</last></author>
      <author><first>Anna</first><last>Bardadym</last></author>
      <author><first>Tom</first><last>Vanallemeersch</last></author>
      <author><first>Pavel</first><last>Smrž</last></author>
      <author><first>Michal</first><last>Hradiš</last></author>
      <pages>481–482</pages>
      <abstract>The OCCAM project (Optical Character recognition, ClassificAtion &amp; Machine Translation) aims at integrating the CEF (Connecting Europe Facility) Automated Translation service with image classification, Translation Memories (TMs), Optical Character Recognition (OCR), and Machine Translation (MT). It will support the automated translation of scanned business documents (a document format that, currently, can not be processed by the CEF eTranslation service) and will also lead to a tool useful for the Digital Humanities domain.</abstract>
      <url hash="f3a2980e">2020.eamt-1.62</url>
      <bibkey>van-den-bogaert-etal-2020-ocr</bibkey>
    </paper>
    <paper id="64">
      <title>Assessing the Comprehensibility of Automatic Translations (ArisToCAT)<fixed-case>A</fixed-case>ris<fixed-case>T</fixed-case>o<fixed-case>CAT</fixed-case>)</title>
      <author><first>Lieve</first><last>Macken</last></author>
      <author><first>Margot</first><last>Fonteyne</last></author>
      <author><first>Arda</first><last>Tezcan</last></author>
      <author><first>Joke</first><last>Daems</last></author>
      <pages>485–486</pages>
      <abstract>The ArisToCAT project aims to assess the comprehensibility of ‘raw’ (unedited) MT output for readers who can only rely on the MT output. In this project description, we summarize the main results of the project and present future work.</abstract>
      <url hash="f231fd46">2020.eamt-1.64</url>
      <bibkey>macken-etal-2020-assessing</bibkey>
    </paper>
    <paper id="69">
      <title>MTrill project : <a href="https://en.wikipedia.org/wiki/Machine_translation">Machine Translation</a> impact on language learning<fixed-case>MT</fixed-case>rill project: Machine Translation impact on language learning</title>
      <author><first>Natália</first><last>Resende</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <pages>497–498</pages>
      <abstract>Over the last decades, massive research investments have been made in the development of machine translation (MT) systems (Gupta and Dhawan, 2019). This has brought about a paradigm shift in the performance of these language tools, leading to widespread use of popular MT systems (Gaspari and Hutchins, 2007). Although the first MT engines were used for gisting purposes, in recent years, there has been an increasing interest in using MT tools, especially the freely available online MT tools, for language teaching and learning (Clifford et al., 2013). The literature on MT and Computer Assisted Language Learning (CALL) shows that, over the years, MT systems have been facilitating <a href="https://en.wikipedia.org/wiki/Language_education">language teaching</a> and also <a href="https://en.wikipedia.org/wiki/Language_acquisition">language learning</a> (Nin o, 2006). It has been shown that MT tools can increase awareness of <a href="https://en.wikipedia.org/wiki/Grammaticality">grammatical linguistic features</a> of a foreign language. Research also shows the positive role of MT systems in the development of writing skills in <a href="https://en.wikipedia.org/wiki/English_language">English</a> as well as in improving communication skills in English(Garcia and Pena, 2011). However, to date, the cognitive impact of MT on <a href="https://en.wikipedia.org/wiki/Language_acquisition">language acquisition</a> and on the syntactic aspects of language processing has not yet been investigated and deserves further scrutiny. The MTril project aims at filling this gap in the literature by examining whether MT is contributing to a central aspect of <a href="https://en.wikipedia.org/wiki/Language_acquisition">language acquisition</a> : the so-called <a href="https://en.wikipedia.org/wiki/Language_binding">language binding</a>, i.e., the ability to combine single words properly in a grammatical sentence (Heyselaar et al., 2017 ; Ferreira and Bock, 2006).</abstract>
      <url hash="3cc666fd">2020.eamt-1.69</url>
      <bibkey>resende-way-2020-mtrill</bibkey>
    </paper>
  </volume>
</collection>