<?xml version='1.0' encoding='utf-8'?>
<collection id="E17">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the 15th Conference of the <fixed-case>E</fixed-case>uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</booktitle>
      <url hash="5a53410a">E17-1</url>
      <editor><first>Mirella</first><last>Lapata</last></editor>
      <editor><first>Phil</first><last>Blunsom</last></editor>
      <editor><first>Alexander</first><last>Koller</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="d66936a7">E17-1000</url>
      <bibkey>eacl-2017-european</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Gated End-to-End Memory Networks</title>
      <author id="fei-liu-unimelb"><first>Fei</first><last>Liu</last></author>
      <author><first>Julien</first><last>Perez</last></author>
      <pages>1–10</pages>
      <url hash="ab4ecb33">E17-1001</url>
      <abstract>Machine reading using differentiable reasoning models has recently shown remarkable progress. In this context, End-to-End trainable Memory Networks (MemN2N) have demonstrated promising performance on simple natural language based reasoning tasks such as factual reasoning and basic deduction. However, other tasks, namely multi-fact question-answering, positional reasoning or dialog related tasks, remain challenging particularly due to the necessity of more complex interactions between the memory and controller modules composing this family of models. In this paper, we introduce a novel end-to-end memory access regulation mechanism inspired by the current progress on the connection short-cutting principle in the field of <a href="https://en.wikipedia.org/wiki/Computer_vision">computer vision</a>. Concretely, we develop a Gated End-to-End trainable Memory Network architecture (GMemN2N). From the machine learning perspective, this new capability is learned in an end-to-end fashion without the use of any additional supervision signal which is, as far as our knowledge goes, the first of its kind. Our experiments show significant improvements on the most challenging tasks in the 20 bAbI dataset, without the use of any <a href="https://en.wikipedia.org/wiki/Domain_knowledge">domain knowledge</a>. Then, we show improvements on the Dialog bAbI tasks including the real human-bot conversion-based Dialog State Tracking Challenge (DSTC-2) dataset. On these two <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a>, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> sets the new state of the art.</abstract>
      <bibkey>liu-perez-2017-gated</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/babi-1">bAbI</pwcdataset>
    </paper>
    <paper id="2">
      <title>Neural Tree Indexers for Text Understanding</title>
      <author><first>Tsendsuren</first><last>Munkhdalai</last></author>
      <author><first>Hong</first><last>Yu</last></author>
      <pages>11–21</pages>
      <url hash="c518d088">E17-1002</url>
      <abstract>Recurrent neural networks (RNNs) process input text sequentially and model the conditional transition between word tokens. In contrast, the advantages of recursive networks include that they explicitly model the <a href="https://en.wikipedia.org/wiki/Composition_(language)">compositionality</a> and the recursive structure of natural language. However, the current <a href="https://en.wikipedia.org/wiki/Recursion_(computer_science)">recursive architecture</a> is limited by its dependence on <a href="https://en.wikipedia.org/wiki/Tree_(data_structure)">syntactic tree</a>. In this paper, we introduce a robust syntactic parsing-independent tree structured model, Neural Tree Indexers (NTI) that provides a middle ground between the sequential RNNs and the syntactic treebased recursive models. NTI constructs a full n-ary tree by processing the input text with its node function in a bottom-up fashion. Attention mechanism can then be applied to both <a href="https://en.wikipedia.org/wiki/Mathematical_structure">structure</a> and node function. We implemented and evaluated a binary tree model of NTI, showing the model achieved the state-of-the-art performance on three different NLP tasks : natural language inference, answer sentence selection, and sentence classification, outperforming state-of-the-art recurrent and recursive neural networks.</abstract>
      <bibkey>munkhdalai-yu-2017-neural</bibkey>
      <pwccode url="https://bitbucket.org/tsendeemts/nti" additional="false">tsendeemts/nti</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="3">
      <title>Exploring Different Dimensions of Attention for Uncertainty Detection</title>
      <author><first>Heike</first><last>Adel</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>22–34</pages>
      <url hash="d8c66eaa">E17-1003</url>
      <abstract>Neural networks with <a href="https://en.wikipedia.org/wiki/Attention">attention</a> have proven effective for many natural language processing tasks. In this paper, we develop <a href="https://en.wikipedia.org/wiki/Attentional_control">attention mechanisms</a> for uncertainty detection. In particular, we generalize standardly used <a href="https://en.wikipedia.org/wiki/Attentional_control">attention mechanisms</a> by introducing external attention and sequence-preserving attention. These novel architectures differ from standard approaches in that they use external resources to compute attention weights and preserve <a href="https://en.wikipedia.org/wiki/Sequence">sequence information</a>. We compare them to other <a href="https://en.wikipedia.org/wiki/Configuration_(geometry)">configurations</a> along different dimensions of attention. Our novel architectures set the new state of the art on a Wikipedia benchmark dataset and perform similar to the state-of-the-art model on a biomedical benchmark which uses a large set of linguistic features.</abstract>
      <bibkey>adel-schutze-2017-exploring</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="4">
      <title>Classifying Illegal Activities on <a href="https://en.wikipedia.org/wiki/Tor_(anonymity_network)">Tor Network</a> Based on Web Textual Contents</title>
      <author><first>Mhd Wesam</first><last>Al Nabki</last></author>
      <author><first>Eduardo</first><last>Fidalgo</last></author>
      <author><first>Enrique</first><last>Alegre</last></author>
      <author><first>Ivan</first><last>de Paz</last></author>
      <pages>35–43</pages>
      <url hash="f5d465e6">E17-1004</url>
      <abstract>The freedom of the Deep Web offers a safe place where people can express themselves anonymously but they also can conduct <a href="https://en.wikipedia.org/wiki/Crime">illegal activities</a>. In this paper, we present and make publicly available a new <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> for Darknet active domains, which we call Darknet Usage Text Addresses (DUTA). We built DUTA by sampling the <a href="https://en.wikipedia.org/wiki/Tor_(anonymity_network)">Tor network</a> during two months and manually labeled each address into 26 classes. Using DUTA, we conducted a comparison between two well-known text representation techniques crossed by three different <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised classifiers</a> to categorize the <a href="https://en.wikipedia.org/wiki/Tor_(anonymity_network)">Tor hidden services</a>. We also fixed the pipeline elements and identified the aspects that have a critical influence on the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> results. We found that the combination of TFIDF words representation with <a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic Regression classifier</a> achieves 96.6 % of 10 folds cross-validation accuracy and a macro F1 score of 93.7 % when classifying a subset of illegal activities from DUTA. The good performance of the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> might support potential tools to help the authorities in the detection of these activities.</abstract>
      <bibkey>al-nabki-etal-2017-classifying</bibkey>
    </paper>
    <paper id="5">
      <title>When is <a href="https://en.wikipedia.org/wiki/Multitask_learning">multitask learning</a> effective? Semantic sequence prediction under varying data conditions</title>
      <author><first>Héctor</first><last>Martínez Alonso</last></author>
      <author><first>Barbara</first><last>Plank</last></author>
      <pages>44–53</pages>
      <url hash="d6595583">E17-1005</url>
      <abstract>Multitask learning has been applied successfully to a range of <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a>, mostly <a href="https://en.wikipedia.org/wiki/Morphology_(biology)">morphosyntactic</a>. However, little is known on when <a href="https://en.wikipedia.org/wiki/Machine_to_machine">MTL</a> works and whether there are data characteristics that help to determine the success of <a href="https://en.wikipedia.org/wiki/Machine_to_machine">MTL</a>. In this paper we evaluate a range of semantic sequence labeling tasks in a MTL setup. We examine different auxiliary task configurations, amongst which a novel setup, and correlate their impact to data-dependent conditions. Our results show that MTL is not always effective, because significant improvements are obtained only for 1 out of 5 <a href="https://en.wikipedia.org/wiki/Task_(computing)">tasks</a>. When successful, <a href="https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations">auxiliary tasks</a> with compact and more uniform label distributions are preferable.<i>when</i> MTL works and whether there are data characteristics that help to determine the success of MTL. In this paper we evaluate a range of semantic sequence labeling tasks in a MTL setup. We examine different auxiliary task configurations, amongst which a novel setup, and correlate their impact to data-dependent conditions. Our results show that MTL is not always effective, because significant improvements are obtained only for 1 out of 5 tasks. When successful, auxiliary tasks with compact and more uniform label distributions are preferable.</abstract>
      <bibkey>martinez-alonso-plank-2017-multitask</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="6">
      <title>Learning Compositionality Functions on Word Embeddings for Modelling Attribute Meaning in Adjective-Noun Phrases</title>
      <author><first>Matthias</first><last>Hartung</last></author>
      <author><first>Fabian</first><last>Kaupmann</last></author>
      <author><first>Soufian</first><last>Jebbara</last></author>
      <author><first>Philipp</first><last>Cimiano</last></author>
      <pages>54–64</pages>
      <url hash="4797bd38">E17-1006</url>
      <abstract>Word embeddings have been shown to be highly effective in a variety of lexical semantic tasks. They tend to capture meaningful relational similarities between individual words, at the expense of lacking the capabilty of making the underlying <a href="https://en.wikipedia.org/wiki/Semantic_relation">semantic relation</a> explicit. In this paper, we investigate the <a href="https://en.wikipedia.org/wiki/Affirmation_and_negation">attribute relation</a> that often holds between the constituents of <a href="https://en.wikipedia.org/wiki/Affirmation_and_negation">adjective-noun phrases</a>. We use CBOW word embeddings to represent word meaning and learn a compositionality function that combines the individual constituents into a phrase representation, thus capturing the compositional attribute meaning. The resulting embedding model, while being fully interpretable, outperforms count-based distributional vector space models that are tailored to attribute meaning in the two tasks of attribute selection and phrase similarity prediction. Moreover, as the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> captures a generalized layer of attribute meaning, it bears the potential to be used for predictions over various attribute inventories without <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">re-training</a>.</abstract>
      <bibkey>hartung-etal-2017-learning</bibkey>
    </paper>
    <paper id="7">
      <title>Hypernyms under Siege : Linguistically-motivated Artillery for Hypernymy Detection</title>
      <author><first>Vered</first><last>Shwartz</last></author>
      <author><first>Enrico</first><last>Santus</last></author>
      <author><first>Dominik</first><last>Schlechtweg</last></author>
      <pages>65–75</pages>
      <url hash="0fccde2e">E17-1007</url>
      <abstract>The fundamental role of <a href="https://en.wikipedia.org/wiki/Hypernymy">hypernymy</a> in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> has motivated the development of many methods for the automatic identification of this relation, most of which rely on word distribution. We investigate an extensive number of such <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised measures</a>, using several distributional semantic models that differ by <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context type</a> and feature weighting. We analyze the performance of the different <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> based on their linguistic motivation. Comparison to the state-of-the-art supervised methods shows that while supervised methods generally outperform the unsupervised ones, the former are sensitive to the distribution of training instances, hurting their reliability. Being based on general linguistic hypotheses and independent from training data, unsupervised measures are more robust, and therefore are still useful artillery for hypernymy detection.</abstract>
      <bibkey>shwartz-etal-2017-hypernyms</bibkey>
      <pwccode url="https://github.com/vered1986/UnsupervisedHypernymy" additional="false">vered1986/UnsupervisedHypernymy</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2018-task-9-hypernym-discovery">SemEval-2018 Task 9: Hypernym Discovery</pwcdataset>
    </paper>
    <paper id="8">
      <title>Distinguishing Antonyms and Synonyms in a Pattern-based Neural Network</title>
      <author><first>Kim Anh</first><last>Nguyen</last></author>
      <author><first>Sabine</first><last>Schulte im Walde</last></author>
      <author><first>Ngoc Thang</first><last>Vu</last></author>
      <pages>76–85</pages>
      <url hash="6d017ffe">E17-1008</url>
      <abstract>Distinguishing between <a href="https://en.wikipedia.org/wiki/Opposite_(semantics)">antonyms</a> and <a href="https://en.wikipedia.org/wiki/Synonym">synonyms</a> is a key task to achieve high performance in NLP systems. While they are notoriously difficult to distinguish by distributional co-occurrence models, pattern-based methods have proven effective to differentiate between the relations. In this paper, we present a novel neural network model AntSynNET that exploits lexico-syntactic patterns from syntactic parse trees. In addition to the lexical and syntactic information, we successfully integrate the distance between the related words along the syntactic path as a new pattern feature. The results from <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> experiments show that AntSynNET improves the performance over prior <a href="https://en.wikipedia.org/wiki/Pattern_recognition">pattern-based methods</a>.</abstract>
      <bibkey>nguyen-etal-2017-distinguishing</bibkey>
      <pwccode url="https://github.com/nguyenkh/AntSynNET" additional="false">nguyenkh/AntSynNET</pwccode>
    </paper>
    <paper id="9">
      <title>Unsupervised Does Not Mean Uninterpretable : The Case for Word Sense Induction and Disambiguation</title>
      <author><first>Alexander</first><last>Panchenko</last></author>
      <author><first>Eugen</first><last>Ruppert</last></author>
      <author><first>Stefano</first><last>Faralli</last></author>
      <author><first>Simone Paolo</first><last>Ponzetto</last></author>
      <author><first>Chris</first><last>Biemann</last></author>
      <pages>86–98</pages>
      <url hash="d2414a23">E17-1009</url>
      <abstract>The current trend in <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP</a> is the use of highly opaque models, e.g. neural networks and <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>. While these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> yield state-of-the-art results on a range of <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a>, their drawback is poor interpretability. On the example of word sense induction and disambiguation (WSID), we show that it is possible to develop an interpretable <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> that matches the state-of-the-art models in <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>. Namely, we present an unsupervised, knowledge-free WSID approach, which is interpretable at three levels : word sense inventory, sense feature representations, and disambiguation procedure. Experiments show that our model performs on par with state-of-the-art word sense embeddings and other <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised systems</a> while offering the possibility to justify its decisions in <a href="https://en.wikipedia.org/wiki/Human-readable_medium">human-readable form</a>.</abstract>
      <bibkey>panchenko-etal-2017-unsupervised-mean</bibkey>
    </paper>
    <paper id="10">
      <title>Word Sense Disambiguation : A Unified Evaluation Framework and Empirical Comparison</title>
      <author><first>Alessandro</first><last>Raganato</last></author>
      <author><first>Jose</first><last>Camacho-Collados</last></author>
      <author><first>Roberto</first><last>Navigli</last></author>
      <pages>99–110</pages>
      <url hash="51adaa36">E17-1010</url>
      <abstract>Word Sense Disambiguation is a long-standing task in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a>, lying at the core of <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">human language understanding</a>. However, the evaluation of <a href="https://en.wikipedia.org/wiki/Automation">automatic systems</a> has been problematic, mainly due to the lack of a reliable evaluation framework. In this paper we develop a unified evaluation framework and analyze the performance of various Word Sense Disambiguation systems in a fair setup. The results show that <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised systems</a> clearly outperform knowledge-based models. Among the <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised systems</a>, a <a href="https://en.wikipedia.org/wiki/Linear_classifier">linear classifier</a> trained on conventional local features still proves to be a hard baseline to beat. Nonetheless, recent approaches exploiting <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a> on unlabeled corpora achieve promising results, surpassing this hard baseline in most test sets.</abstract>
      <bibkey>raganato-etal-2017-word</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/word-sense-disambiguation-a-unified">Word Sense Disambiguation: a Unified Evaluation Framework and Empirical Comparison</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/senseval-2-1">Senseval-2</pwcdataset>
    </paper>
    <paper id="11">
      <title>Which is the Effective Way for Gaokao : <a href="https://en.wikipedia.org/wiki/Information_retrieval">Information Retrieval</a> or <a href="https://en.wikipedia.org/wiki/Neural_network">Neural Networks</a>?<fixed-case>G</fixed-case>aokao: Information Retrieval or Neural Networks?</title>
      <author><first>Shangmin</first><last>Guo</last></author>
      <author><first>Xiangrong</first><last>Zeng</last></author>
      <author><first>Shizhu</first><last>He</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <pages>111–120</pages>
      <url hash="66236688">E17-1011</url>
      <abstract>As one of the most important test of China, <a href="https://en.wikipedia.org/wiki/Gaokao">Gaokao</a> is designed to be difficult enough to distinguish the excellent high school students. In this work, we detailed the Gaokao History Multiple Choice Questions(GKHMC) and proposed two different approaches to address them using various resources. One approach is based on entity search technique (IR approach), the other is based on text entailment approach where we specifically employ deep neural networks(NN approach). The result of experiment on our collected real Gaokao questions showed that they are good at different categories of questions, that is IR approach performs much better at entity questions(EQs) while NN approach shows its advantage on sentence questions(SQs). We achieve state-of-the-art performance and show that it’s indispensable to apply hybrid method when participating in the real-world tests.</abstract>
      <bibkey>guo-etal-2017-effective</bibkey>
      <pwccode url="https://github.com/IACASNLPIR/GKHMC" additional="false">IACASNLPIR/GKHMC</pwccode>
    </paper>
    <paper id="12">
      <title>If You Ca n’t Beat Them Join Them : Handcrafted Features Complement Neural Nets for Non-Factoid Answer Reranking</title>
      <author><first>Dasha</first><last>Bogdanova</last></author>
      <author><first>Jennifer</first><last>Foster</last></author>
      <author><first>Daria</first><last>Dzendzik</last></author>
      <author><first>Qun</first><last>Liu</last></author>
      <pages>121–131</pages>
      <url hash="8986409c">E17-1012</url>
      <abstract>We show that a neural approach to the task of non-factoid answer reranking can benefit from the inclusion of tried-and-tested handcrafted features. We present a neural network architecture based on a combination of <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural networks</a> that are used to encode questions and answers, and a <a href="https://en.wikipedia.org/wiki/Multilayer_perceptron">multilayer perceptron</a>. We show how this approach can be combined with additional <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>, in particular, the discourse features used by previous research. Our neural approach achieves state-of-the-art performance on a public dataset from Yahoo ! Answers and its performance is further improved by incorporating the discourse features. Additionally, we present a new dataset of Ask Ubuntu questions where the hybrid approach also achieves good results.</abstract>
      <bibkey>bogdanova-etal-2017-cant</bibkey>
    </paper>
    <paper id="13">
      <title>Chains of Reasoning over Entities, Relations, and Text using <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">Recurrent Neural Networks</a></title>
      <author><first>Rajarshi</first><last>Das</last></author>
      <author><first>Arvind</first><last>Neelakantan</last></author>
      <author><first>David</first><last>Belanger</last></author>
      <author><first>Andrew</first><last>McCallum</last></author>
      <pages>132–141</pages>
      <url hash="da573e9a">E17-1013</url>
      <abstract>Our goal is to combine the rich multi-step inference of symbolic logical reasoning with the generalization capabilities of <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a>. We are particularly interested in complex reasoning about entities and relations in <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">text</a> and large-scale knowledge bases (KBs). Neelakantan et al. (2015) use RNNs to compose the distributed semantics of multi-hop paths in KBs ; however for multiple reasons, the approach lacks accuracy and practicality. This paper proposes three significant modeling advances : (1) we learn to jointly reason about <a href="https://en.wikipedia.org/wiki/Binary_relation">relations</a>, entities, and entity-types ; (2) we use neural attention modeling to incorporate multiple paths ; (3) we learn to share strength in a single RNN that represents logical composition across all relations. On a large-scale Freebase+ClueWeb prediction task, we achieve 25 % <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error reduction</a>, and a 53 % <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error reduction</a> on sparse relations due to shared strength. On chains of reasoning in <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a> we reduce error in mean quantile by 84 % versus previous <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a>.<i>entities, and entity-types</i>; (2) we use neural attention modeling to incorporate <i>multiple paths</i>; (3) we learn to <i>share strength in a single RNN</i> that represents logical composition across all relations. On a large-scale Freebase+ClueWeb prediction task, we achieve 25% error reduction, and a 53% error reduction on sparse relations due to shared strength. On chains of reasoning in WordNet we reduce error in mean quantile by 84% versus previous state-of-the-art.</abstract>
      <bibkey>das-etal-2017-chains</bibkey>
      <pwccode url="" additional="true" />
    </paper>
    <paper id="15">
      <title>Multitask Learning for Mental Health Conditions with Limited Social Media Data</title>
      <author><first>Adrian</first><last>Benton</last></author>
      <author><first>Margaret</first><last>Mitchell</last></author>
      <author><first>Dirk</first><last>Hovy</last></author>
      <pages>152–162</pages>
      <url hash="a2eb94d9">E17-1015</url>
      <revision id="1" href="E17-1015v1" hash="2b4866f2" />
      <revision id="2" href="E17-1015v2" hash="a2eb94d9">No description of the changes were recorded.</revision>
      <abstract>Language contains information about the author’s demographic attributes as well as their <a href="https://en.wikipedia.org/wiki/Mental_state">mental state</a>, and has been successfully leveraged in <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP</a> to predict either one alone. However, demographic attributes and mental states also interact with each other, and we are the first to demonstrate how to use them jointly to improve the prediction of mental health conditions across the board. We model the different conditions as tasks in a multitask learning (MTL) framework, and establish for the first time the potential of <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> in the prediction of mental health from online user-generated text. The framework we propose significantly improves over all baselines and single-task models for predicting mental health conditions, with particularly significant gains for conditions with limited data. In addition, our best MTL model can predict the presence of conditions (neuroatypicality) more generally, further reducing the error of the strong feed-forward baseline.</abstract>
      <bibkey>benton-etal-2017-multitask</bibkey>
    </paper>
    <paper id="17">
      <title>Computational Argumentation Quality Assessment in <a href="https://en.wikipedia.org/wiki/Natural_language">Natural Language</a></title>
      <author><first>Henning</first><last>Wachsmuth</last></author>
      <author><first>Nona</first><last>Naderi</last></author>
      <author><first>Yufang</first><last>Hou</last></author>
      <author><first>Yonatan</first><last>Bilu</last></author>
      <author><first>Vinodkumar</first><last>Prabhakaran</last></author>
      <author><first>Tim Alberdingk</first><last>Thijm</last></author>
      <author><first>Graeme</first><last>Hirst</last></author>
      <author><first>Benno</first><last>Stein</last></author>
      <pages>176–187</pages>
      <url hash="d1570681">E17-1017</url>
      <abstract>Research on computational argumentation faces the problem of how to automatically assess the quality of an argument or argumentation. While different quality dimensions have been approached in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>, a common understanding of argumentation quality is still missing. This paper presents the first holistic work on computational argumentation quality in <a href="https://en.wikipedia.org/wiki/Natural_language">natural language</a>. We comprehensively survey the diverse existing theories and approaches to assess logical, rhetorical, and dialectical quality dimensions, and we derive a systematic taxonomy from these. In addition, we provide a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> with 320 arguments, annotated for all 15 dimensions in the <a href="https://en.wikipedia.org/wiki/Taxonomy_(biology)">taxonomy</a>. Our results establish a common ground for research on computational argumentation quality assessment.</abstract>
      <bibkey>wachsmuth-etal-2017-computational</bibkey>
    </paper>
    <paper id="18">
      <title>A method for in-depth comparative evaluation : How (dis)similar are outputs of pos taggers, dependency parsers and coreference resolvers really?</title>
      <author><first>Don</first><last>Tuggener</last></author>
      <pages>188–198</pages>
      <url hash="01563cee">E17-1018</url>
      <abstract>This paper proposes a generic <a href="https://en.wikipedia.org/wiki/Methodology">method</a> for the comparative evaluation of system outputs. The approach is able to quantify the pairwise differences between two outputs and to unravel in detail what the differences consist of. We apply our approach to three <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> in <a href="https://en.wikipedia.org/wiki/Computational_linguistics">Computational Linguistics</a>, i.e. POS tagging, <a href="https://en.wikipedia.org/wiki/Dependency_grammar">dependency parsing</a>, and <a href="https://en.wikipedia.org/wiki/Coreference_resolution">coreference resolution</a>. We find that system outputs are more distinct than the (often) small differences in evaluation scores seem to suggest.</abstract>
      <bibkey>tuggener-2017-method</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="20">
      <title>Integrating <a href="https://en.wikipedia.org/wiki/Meaning_(philosophy_of_language)">Meaning</a> into Quality Evaluation of <a href="https://en.wikipedia.org/wiki/Machine_translation">Machine Translation</a></title>
      <author><first>Osman</first><last>Başkaya</last></author>
      <author><first>Eray</first><last>Yildiz</last></author>
      <author><first>Doruk</first><last>Tunaoğlu</last></author>
      <author><first>Mustafa Tolga</first><last>Eren</last></author>
      <author><first>A. Seza</first><last>Doğruöz</last></author>
      <pages>210–219</pages>
      <url hash="7d939d80">E17-1020</url>
      <abstract>Machine translation (MT) quality is evaluated through comparisons between MT outputs and the human translations (HT). Traditionally, this <a href="https://en.wikipedia.org/wiki/Validity_(logic)">evaluation</a> relies on form related features (e.g. lexicon and syntax) and ignores the transfer of meaning reflected in HT outputs. Instead, we evaluate the <a href="https://en.wikipedia.org/wiki/Quality_(business)">quality</a> of MT outputs through meaning related features (e.g. polarity, subjectivity) with two experiments. In the first experiment, the meaning related features are compared to human rankings individually. In the second experiment, combinations of meaning related features and other quality metrics are utilized to predict the same human rankings. The results of our experiments confirm the benefit of these features in predicting human evaluation of translation quality in addition to traditional <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> which focus mainly on form.</abstract>
      <bibkey>baskaya-etal-2017-integrating</bibkey>
    </paper>
    <paper id="21">
      <title>Cross-Lingual Dependency Parsing with Late Decoding for Truly Low-Resource Languages</title>
      <author><first>Michael</first><last>Schlichtkrull</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>220–229</pages>
      <url hash="46dc313f">E17-1021</url>
      <abstract>In cross-lingual dependency annotation projection, information is often lost during <a href="https://en.wikipedia.org/wiki/Language_transfer">transfer</a> because of early decoding. We present an end-to-end graph-based neural network dependency parser that can be trained to reproduce matrices of edge scores, which can be directly projected across word alignments. We show that our approach to cross-lingual dependency parsing is not only simpler, but also achieves an absolute improvement of 2.25 % averaged across 10 languages compared to the previous <a href="https://en.wikipedia.org/wiki/State_of_the_art">state of the art</a>.</abstract>
      <bibkey>schlichtkrull-sogaard-2017-cross</bibkey>
      <pwccode url="https://github.com/MichSchli/Tensor-LSTM" additional="false">MichSchli/Tensor-LSTM</pwccode>
    </paper>
    <paper id="22">
      <title>Parsing Universal Dependencies without training<fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies without training</title>
      <author><first>Héctor</first><last>Martínez Alonso</last></author>
      <author><first>Željko</first><last>Agić</last></author>
      <author><first>Barbara</first><last>Plank</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>230–240</pages>
      <url hash="90db81de">E17-1022</url>
      <abstract>We present UDP, the first training-free parser for Universal Dependencies (UD). Our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> is based on <a href="https://en.wikipedia.org/wiki/PageRank">PageRank</a> and a small set of specific dependency head rules. UDP features two-step decoding to guarantee that <a href="https://en.wikipedia.org/wiki/Function_word">function words</a> are attached as <a href="https://en.wikipedia.org/wiki/Tree_(data_structure)">leaf nodes</a>. The <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> requires no training, and <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> is competitive with a delexicalized transfer system. UDP offers a linguistically sound unsupervised alternative to cross-lingual parsing for UD. The <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> has very few parameters and distinctly robust to domain change across languages.</abstract>
      <bibkey>martinez-alonso-etal-2017-parsing</bibkey>
      <pwccode url="https://github.com/hectormartinez/ud_unsup_parser" additional="false">hectormartinez/ud_unsup_parser</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="24">
      <title>Stance Classification of Context-Dependent Claims</title>
      <author><first>Roy</first><last>Bar-Haim</last></author>
      <author><first>Indrajit</first><last>Bhattacharya</last></author>
      <author><first>Francesco</first><last>Dinuzzo</last></author>
      <author><first>Amrita</first><last>Saha</last></author>
      <author><first>Noam</first><last>Slonim</last></author>
      <pages>251–261</pages>
      <url hash="5a59a8ee">E17-1024</url>
      <abstract>Recent work has addressed the problem of detecting relevant claims for a given controversial topic. We introduce the complementary task of Claim Stance Classification, along with the first <a href="https://en.wikipedia.org/wiki/Benchmark_(computing)">benchmark dataset</a> for this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. We decompose this problem into : (a) open-domain target identification for topic and claim (b) sentiment classification for each target, and (c) open-domain contrast detection between the topic and the claim targets. Manual annotation of the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> confirms the applicability and validity of our <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a>. We describe an implementation of our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>, focusing on a novel <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> for contrast detection. Our approach achieves promising results, and is shown to outperform several baselines, which represent the common practice of applying a single, monolithic classifier for stance classification.</abstract>
      <bibkey>bar-haim-etal-2017-stance</bibkey>
    </paper>
    <paper id="25">
      <title>Exploring the Impact of Pragmatic Phenomena on Irony Detection in Tweets : A Multilingual Corpus Study</title>
      <author><first>Jihen</first><last>Karoui</last></author>
      <author><first>Farah</first><last>Benamara</last></author>
      <author><first>Véronique</first><last>Moriceau</last></author>
      <author><first>Viviana</first><last>Patti</last></author>
      <author><first>Cristina</first><last>Bosco</last></author>
      <author><first>Nathalie</first><last>Aussenac-Gilles</last></author>
      <pages>262–272</pages>
      <url hash="53f5c9d5">E17-1025</url>
      <abstract>This paper provides a linguistic and pragmatic analysis of the phenomenon of <a href="https://en.wikipedia.org/wiki/Irony">irony</a> in order to represent how Twitter’s users exploit <a href="https://en.wikipedia.org/wiki/Irony">irony devices</a> within their communication strategies for generating textual contents. We aim to measure the impact of a wide-range of pragmatic phenomena in the interpretation of irony, and to investigate how these <a href="https://en.wikipedia.org/wiki/Phenomenon">phenomena</a> interact with contexts local to the tweet. Informed by linguistic theories, we propose for the first time a multi-layered annotation schema for <a href="https://en.wikipedia.org/wiki/Irony">irony</a> and its application to a corpus of French, English and Italian tweets. We detail each layer, explore their interactions, and discuss our results according to a qualitative and quantitative perspective.</abstract>
      <bibkey>karoui-etal-2017-exploring</bibkey>
    </paper>
    <paper id="26">
      <title>A Multi-View Sentiment Corpus</title>
      <author><first>Debora</first><last>Nozza</last></author>
      <author><first>Elisabetta</first><last>Fersini</last></author>
      <author><first>Enza</first><last>Messina</last></author>
      <pages>273–280</pages>
      <url hash="d72938a1">E17-1026</url>
      <abstract>Sentiment Analysis is a broad task that involves the analysis of various aspect of the <a href="https://en.wikipedia.org/wiki/Natural_language">natural language text</a>. However, most of the <a href="https://en.wikipedia.org/wiki/List_of_art_media">approaches</a> in the state of the art usually investigate independently each aspect, i.e. Subjectivity Classification, Sentiment Polarity Classification, <a href="https://en.wikipedia.org/wiki/Emotion_recognition">Emotion Recognition</a>, Irony Detection. In this paper we present a Multi-View Sentiment Corpus (MVSC), which comprises 3000 English microblog posts related the movie domain. Three independent annotators manually labelled MVSC, following a broad annotation schema about different aspects that can be grasped from natural language text coming from <a href="https://en.wikipedia.org/wiki/List_of_social_networking_websites">social networks</a>. The contribution is therefore a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> that comprises five different views for each message, i.e. subjective / objective, sentiment polarity, implicit / explicit, <a href="https://en.wikipedia.org/wiki/Irony">irony</a>, <a href="https://en.wikipedia.org/wiki/Emotion">emotion</a>. In order to allow a more detailed investigation on the human labelling behaviour, we provide the annotations of each human annotator involved.</abstract>
      <bibkey>nozza-etal-2017-multi</bibkey>
    </paper>
    <paper id="27">
      <title>A Systematic Study of Neural Discourse Models for Implicit Discourse Relation</title>
      <author><first>Attapol</first><last>Rutherford</last></author>
      <author><first>Vera</first><last>Demberg</last></author>
      <author><first>Nianwen</first><last>Xue</last></author>
      <pages>281–291</pages>
      <url hash="971bbe06">E17-1027</url>
      <abstract>Inferring implicit discourse relations in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language text</a> is the most difficult subtask in discourse parsing. Many neural network models have been proposed to tackle this problem. However, the comparison for this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> is not unified, so we could hardly draw clear conclusions about the effectiveness of various <a href="https://en.wikipedia.org/wiki/Computer_architecture">architectures</a>. Here, we propose neural network models that are based on feedforward and long-short term memory architecture and systematically study the effects of varying structures. To our surprise, the best-configured feedforward architecture outperforms LSTM-based model in most cases despite thorough tuning. Further, we compare our best feedforward system with competitive convolutional and recurrent networks and find that feedforward can actually be more effective. For the first time for this task, we compile and publish outputs from previous neural and non-neural systems to establish the standard for further comparison.</abstract>
      <bibkey>rutherford-etal-2017-systematic</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="29">
      <title>Dialog state tracking, a machine reading approach using Memory Network</title>
      <author><first>Julien</first><last>Perez</last></author>
      <author id="fei-liu-unimelb"><first>Fei</first><last>Liu</last></author>
      <pages>305–314</pages>
      <url hash="637327fc">E17-1029</url>
      <abstract>In an end-to-end dialog system, the aim of dialog state tracking is to accurately estimate a compact representation of the current dialog status from a sequence of noisy observations produced by the <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech recognition</a> and the natural language understanding modules. This paper introduces a novel method of dialog state tracking based on the general paradigm of machine reading and proposes to solve it using an End-to-End Memory Network, MemN2N, a memory-enhanced neural network architecture. We evaluate the proposed approach on the second Dialog State Tracking Challenge (DSTC-2) dataset. The <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> has been converted for the occasion in order to frame the hidden state variable inference as a question-answering task based on a sequence of utterances extracted from a dialog. We show that the proposed <a href="https://en.wikipedia.org/wiki/Music_tracker">tracker</a> gives encouraging results. Then, we propose to extend the DSTC-2 dataset with specific reasoning capabilities requirement like <a href="https://en.wikipedia.org/wiki/Counting">counting</a>, list maintenance, yes-no question answering and indefinite knowledge management. Finally, we present encouraging results using our proposed MemN2N based tracking model.</abstract>
      <bibkey>perez-liu-2017-dialog</bibkey>
    </paper>
    <paper id="30">
      <title>Sentence Segmentation in Narrative Transcripts from Neuropsychological Tests using Recurrent Convolutional Neural Networks</title>
      <author><first>Marcos</first><last>Treviso</last></author>
      <author><first>Christopher</first><last>Shulby</last></author>
      <author><first>Sandra</first><last>Aluísio</last></author>
      <pages>315–325</pages>
      <url hash="b3ab9d33">E17-1030</url>
      <abstract>Automated discourse analysis tools based on Natural Language Processing (NLP) aiming at the diagnosis of language-impairing dementias generally extract several textual metrics of narrative transcripts. However, the absence of sentence boundary segmentation in the transcripts prevents the direct application of NLP methods which rely on these marks in order to function properly, such as taggers and <a href="https://en.wikipedia.org/wiki/Parsing">parsers</a>. We present the first steps taken towards automatic neuropsychological evaluation based on narrative discourse analysis, presenting a new automatic sentence segmentation method for impaired speech. Our model uses recurrent convolutional neural networks with prosodic, Part of Speech (PoS) features, and word embeddings. It was evaluated intrinsically on impaired, spontaneous speech as well as normal, prepared speech and presents better results for healthy elderly (CTL) (F1 = 0.74) and Mild Cognitive Impairment (MCI) patients (F1 = 0.70) than the Conditional Random Fields method (F1 = 0.55 and 0.53, respectively) used in the same context of our study. The results suggest that our model is robust for impaired speech and can be used in automated discourse analysis tools to differentiate narratives produced by MCI and CTL.</abstract>
      <bibkey>treviso-etal-2017-sentence</bibkey>
    </paper>
    <paper id="31">
      <title>Joint, Incremental Disfluency Detection and Utterance Segmentation from <a href="https://en.wikipedia.org/wiki/Speech">Speech</a></title>
      <author><first>Julian</first><last>Hough</last></author>
      <author><first>David</first><last>Schlangen</last></author>
      <pages>326–336</pages>
      <url hash="d4e517c5">E17-1031</url>
      <abstract>We present the joint task of incremental disfluency detection and utterance segmentation and a simple deep learning system which performs it on transcripts and ASR results. We show how the constraints of the two <a href="https://en.wikipedia.org/wiki/Task_(computing)">tasks</a> interact. Our joint-task system outperforms the equivalent individual task systems, provides competitive results and is suitable for future use in conversation agents in the psychiatric domain.</abstract>
      <bibkey>hough-schlangen-2017-joint</bibkey>
    </paper>
    <paper id="32">
      <title>From Segmentation to Analyses : a Probabilistic Model for Unsupervised Morphology Induction</title>
      <author><first>Toms</first><last>Bergmanis</last></author>
      <author><first>Sharon</first><last>Goldwater</last></author>
      <pages>337–346</pages>
      <url hash="cc8fa385">E17-1032</url>
      <abstract>A major motivation for unsupervised morphological analysis is to reduce the sparse data problem in under-resourced languages. Most previous work focus on segmenting surface forms into their constituent morphs (taking : tak + ing), but surface form segmentation does not solve the sparse data problem as the analyses of take and taking are not connected to each other. We present a system that adapts the MorphoChains system (Narasimhan et al., 2015) to provide morphological analyses that aim to abstract over spelling differences in functionally similar morphs. This results in analyses that are not compelled to use all the orthographic material of a word (stopping : stop + ing) or limited to only that material (acidified : acid + ify + ed). On average across six typologically varied languages our <a href="https://en.wikipedia.org/wiki/System">system</a> has a similar or better F-score on EMMA (a measure of underlying morpheme accuracy) than three strong baselines ; moreover, the total number of distinct morphemes identified by our <a href="https://en.wikipedia.org/wiki/System">system</a> is on average 12.8 % lower than for Morfessor (Virpioja et al., 2013), a state-of-the-art surface segmentation system.</abstract>
      <bibkey>bergmanis-goldwater-2017-segmentation</bibkey>
    </paper>
    <paper id="34">
      <title>Universal Dependencies and <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">Morphology</a> for Hungarian-and on the Price of Universality<fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies and Morphology for <fixed-case>H</fixed-case>ungarian - and on the Price of Universality</title>
      <author><first>Veronika</first><last>Vincze</last></author>
      <author><first>Katalin</first><last>Simkó</last></author>
      <author><first>Zsolt</first><last>Szántó</last></author>
      <author><first>Richárd</first><last>Farkas</last></author>
      <pages>356–365</pages>
      <url hash="c7bdab0a">E17-1034</url>
      <abstract>In this paper, we present how the principles of universal dependencies and <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphology</a> have been adapted to <a href="https://en.wikipedia.org/wiki/Hungarian_language">Hungarian</a>. We report the most challenging <a href="https://en.wikipedia.org/wiki/Grammaticality">grammatical phenomena</a> and our solutions to those. On the basis of the adapted guidelines, we have converted and manually corrected 1,800 sentences from the Szeged Treebank to universal dependency format. We also introduce experiments on this manually annotated corpus for evaluating automatic conversion and the added value of language-specific, i.e. non-universal, annotations. Our results reveal that converting to universal dependencies is not necessarily trivial, moreover, using language-specific morphological features may have an impact on overall performance.</abstract>
      <bibkey>vincze-etal-2017-universal</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="35">
      <title>Addressing the Data Sparsity Issue in Neural AMR Parsing<fixed-case>AMR</fixed-case> Parsing</title>
      <author><first>Xiaochang</first><last>Peng</last></author>
      <author><first>Chuan</first><last>Wang</last></author>
      <author><first>Daniel</first><last>Gildea</last></author>
      <author><first>Nianwen</first><last>Xue</last></author>
      <pages>366–375</pages>
      <url hash="0e1a5ce0">E17-1035</url>
      <abstract>Neural attention models have achieved great success in different <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP tasks</a>. However, they have not fulfilled their promise on the AMR parsing task due to the data sparsity issue. In this paper, we describe a sequence-to-sequence model for AMR parsing and present different ways to tackle the data sparsity problem. We show that our methods achieve significant improvement over a baseline neural attention model and our results are also competitive against state-of-the-art systems that do not use extra linguistic resources.</abstract>
      <bibkey>peng-etal-2017-addressing</bibkey>
    </paper>
    <paper id="37">
      <title>Enumeration of Extractive Oracle Summaries</title>
      <author><first>Tsutomu</first><last>Hirao</last></author>
      <author><first>Masaaki</first><last>Nishino</last></author>
      <author><first>Jun</first><last>Suzuki</last></author>
      <author><first>Masaaki</first><last>Nagata</last></author>
      <pages>386–396</pages>
      <url hash="2cf2147e">E17-1037</url>
      <abstract>To analyze the limitations and the future directions of the extractive summarization paradigm, this paper proposes an Integer Linear Programming (ILP) formulation to obtain extractive oracle summaries in terms of ROUGE-N. We also propose an algorithm that enumerates all of the <a href="https://en.wikipedia.org/wiki/Oracle_machine">oracle summaries</a> for a set of reference summaries to exploit F-measures that evaluate which system summaries contain how many sentences that are extracted as an oracle summary. Our experimental results obtained from Document Understanding Conference (DUC) corpora demonstrated the following : (1) room still exists to improve the performance of extractive summarization ; (2) the F-measures derived from the enumerated oracle summaries have significantly stronger correlations with human judgment than those derived from single oracle summaries.</abstract>
      <bibkey>hirao-etal-2017-enumeration</bibkey>
    </paper>
    <paper id="38">
      <title>Neural Semantic Encoders</title>
      <author><first>Tsendsuren</first><last>Munkhdalai</last></author>
      <author><first>Hong</first><last>Yu</last></author>
      <pages>397–407</pages>
      <url hash="3f81c0aa">E17-1038</url>
      <abstract>We present a memory augmented neural network for <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language understanding</a> : Neural Semantic Encoders. NSE is equipped with a novel memory update rule and has a variable sized encoding memory that evolves over time and maintains the understanding of input sequences through read, compose and write operations. NSE can also access 1 multiple and shared memories. In this paper, we demonstrated the effectiveness and the flexibility of NSE on five different natural language tasks : <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language inference</a>, <a href="https://en.wikipedia.org/wiki/Question_answering">question answering</a>, sentence classification, <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">document sentiment analysis</a> and <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> where NSE achieved state-of-the-art performance when evaluated on publically available benchmarks. For example, our shared-memory model showed an encouraging result on <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a>, improving an attention-based baseline by approximately 1.0 BLEU.</abstract>
      <bibkey>munkhdalai-yu-2017-neural-semantic</bibkey>
      <pwccode url="https://bitbucket.org/tsendeemts/nse" additional="true">tsendeemts/nse</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2014">WMT 2014</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikiqa">WikiQA</pwcdataset>
    </paper>
    <paper id="39">
      <title>Efficient Benchmarking of NLP APIs using Multi-armed Bandits<fixed-case>NLP</fixed-case> <fixed-case>API</fixed-case>s using Multi-armed Bandits</title>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <author><first>Tuan Dung</first><last>Tran</last></author>
      <author><first>Mark</first><last>Carman</last></author>
      <pages>408–416</pages>
      <url hash="6cf4d183">E17-1039</url>
      <abstract>Comparing NLP systems to select the best one for a task of interest, such as <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>, is critical for practitioners and researchers. A rigorous approach involves setting up a hypothesis testing scenario using the performance of the <a href="https://en.wikipedia.org/wiki/System">systems</a> on query documents. However, often the hypothesis testing approach needs to send a lot of document queries to the systems, which can be problematic. In this paper, we present an effective alternative based on the multi-armed bandit (MAB). We propose a hierarchical generative model to represent the uncertainty in the performance measures of the competing systems, to be used by <a href="https://en.wikipedia.org/wiki/Thompson_sampling">Thompson Sampling</a> to solve the resulting MAB. Experimental results on both synthetic and real data show that our approach requires significantly fewer queries compared to the standard benchmarking technique to identify the best <a href="https://en.wikipedia.org/wiki/System">system</a> according to <a href="https://en.wikipedia.org/wiki/F-measure">F-measure</a>.</abstract>
      <bibkey>haffari-etal-2017-efficient</bibkey>
    </paper>
    <paper id="40">
      <title>Character-Word LSTM Language Models<fixed-case>LSTM</fixed-case> Language Models</title>
      <author><first>Lyan</first><last>Verwimp</last></author>
      <author><first>Joris</first><last>Pelemans</last></author>
      <author><first>Hugo</first><last>Van hamme</last></author>
      <author><first>Patrick</first><last>Wambacq</last></author>
      <pages>417–427</pages>
      <url hash="9fcd655d">E17-1040</url>
      <abstract>We present a Character-Word Long Short-Term Memory Language Model which both reduces the perplexity with respect to a baseline word-level language model and reduces the number of parameters of the model. Character information can reveal structural (dis)similarities between words and can even be used when a word is out-of-vocabulary, thus improving the modeling of infrequent and unknown words. By concatenating <a href="https://en.wikipedia.org/wiki/Word_embedding">word and character embeddings</a>, we achieve up to 2.77 % relative improvement on <a href="https://en.wikipedia.org/wiki/English_language">English</a> compared to a baseline model with a similar amount of parameters and 4.57 % on <a href="https://en.wikipedia.org/wiki/Dutch_language">Dutch</a>. Moreover, we also outperform baseline word-level models with a larger number of parameters.</abstract>
      <bibkey>verwimp-etal-2017-character</bibkey>
    </paper>
    <paper id="41">
      <title>A Hierarchical Neural Model for Learning Sequences of Dialogue Acts</title>
      <author><first>Quan Hung</first><last>Tran</last></author>
      <author><first>Ingrid</first><last>Zukerman</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <pages>428–437</pages>
      <url hash="95b5f0a8">E17-1041</url>
      <abstract>We propose a novel hierarchical Recurrent Neural Network (RNN) for learning sequences of Dialogue Acts (DAs). The input in this task is a sequence of utterances (i.e., conversational contributions) comprising a sequence of tokens, and the output is a sequence of DA labels (one label per utterance). Our model leverages the hierarchical nature of dialogue data by using two nested RNNs that capture long-range dependencies at the dialogue level and the utterance level. This <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> is combined with an <a href="https://en.wikipedia.org/wiki/Attentional_control">attention mechanism</a> that focuses on salient tokens in utterances. Our experimental results show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms strong baselines on two popular datasets, Switchboard and MapTask ; and our detailed empirical analysis highlights the impact of each aspect of our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>.</abstract>
      <bibkey>tran-etal-2017-hierarchical</bibkey>
    </paper>
    <paper id="42">
      <title>A Network-based End-to-End Trainable Task-oriented Dialogue System</title>
      <author><first>Tsung-Hsien</first><last>Wen</last></author>
      <author><first>David</first><last>Vandyke</last></author>
      <author><first>Nikola</first><last>Mrkšić</last></author>
      <author><first>Milica</first><last>Gašić</last></author>
      <author><first>Lina M.</first><last>Rojas-Barahona</last></author>
      <author><first>Pei-Hao</first><last>Su</last></author>
      <author><first>Stefan</first><last>Ultes</last></author>
      <author><first>Steve</first><last>Young</last></author>
      <pages>438–449</pages>
      <url hash="9d3e4f48">E17-1042</url>
      <abstract>Teaching machines to accomplish tasks by conversing naturally with humans is challenging. Currently, developing task-oriented dialogue systems requires creating multiple components and typically this involves either a large amount of <a href="https://en.wikipedia.org/wiki/Handicraft">handcrafting</a>, or acquiring costly labelled datasets to solve a statistical learning problem for each component. In this work we introduce a neural network-based text-in, text-out end-to-end trainable goal-oriented dialogue system along with a new way of collecting dialogue data based on a novel pipe-lined Wizard-of-Oz framework. This approach allows us to develop <a href="https://en.wikipedia.org/wiki/Dialogue_system">dialogue systems</a> easily and without making too many assumptions about the task at hand. The results show that the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> can converse with human subjects naturally whilst helping them to accomplish tasks in a restaurant search domain.</abstract>
      <bibkey>wen-etal-2017-network</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wizard-of-oz">Wizard-of-Oz</pwcdataset>
    </paper>
    <paper id="43">
      <title>May I take your order? A Neural Model for Extracting Structured Information from Conversations<fixed-case>I</fixed-case> take your order? A Neural Model for Extracting Structured Information from Conversations</title>
      <author><first>Baolin</first><last>Peng</last></author>
      <author><first>Michael</first><last>Seltzer</last></author>
      <author><first>Y.C.</first><last>Ju</last></author>
      <author><first>Geoffrey</first><last>Zweig</last></author>
      <author><first>Kam-Fai</first><last>Wong</last></author>
      <pages>450–459</pages>
      <url hash="579f467c">E17-1043</url>
      <abstract>In this paper we tackle a unique and important problem of extracting a structured order from the conversation a customer has with an order taker at a restaurant. This is motivated by an actual <a href="https://en.wikipedia.org/wiki/System">system</a> under development to assist in the order taking process. We develop a sequence-to-sequence model that is able to map from unstructured conversational input to the structured form that is conveyed to the kitchen and appears on the customer receipt. This problem is critically different from other tasks like <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> where sequence-to-sequence models have been used : the input includes two sides of a conversation ; the output is highly structured ; and logical manipulations must be performed, for example when the customer changes his mind while ordering. We present a novel sequence-to-sequence model that incorporates a special attention-memory gating mechanism and conversational role markers. The proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> improves performance over both a phrase-based machine translation approach and a standard sequence-to-sequence model.</abstract>
      <bibkey>peng-etal-2017-may</bibkey>
    </paper>
    <paper id="44">
      <title>A Two-stage Sieve Approach for Quote Attribution</title>
      <author><first>Grace</first><last>Muzny</last></author>
      <author><first>Michael</first><last>Fang</last></author>
      <author><first>Angel</first><last>Chang</last></author>
      <author><first>Dan</first><last>Jurafsky</last></author>
      <pages>460–470</pages>
      <url hash="4515b09e">E17-1044</url>
      <abstract>We present a deterministic sieve-based system for attributing quotations in literary text and a new dataset : QuoteLi3. Quote attribution, determining who said what in a given text, is important for tasks like creating dialogue systems, and in newer areas like computational literary studies, where it creates opportunities to analyze novels at scale rather than only a few at a time. We release QuoteLi3, which contains more than 6,000 annotations linking quotes to speaker mentions and quotes to speaker entities, and introduce a new <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> for quote attribution. Our two-stage algorithm first links quotes to mentions, then mentions to entities. Using two stages encapsulates difficult sub-problems and improves system performance. The modular design allows us to tune for overall performance or higher <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a>, which is useful for many real-world use cases. Our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves an average <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> of 87.5 across three novels, outperforming previous systems, and can be tuned for <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">precision</a> of 90.4 at a <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">recall</a> of 65.1.</abstract>
      <bibkey>muzny-etal-2017-two</bibkey>
    </paper>
    <paper id="45">
      <title>Out-of-domain FrameNet Semantic Role Labeling<fixed-case>F</fixed-case>rame<fixed-case>N</fixed-case>et Semantic Role Labeling</title>
      <author><first>Silvana</first><last>Hartmann</last></author>
      <author><first>Ilia</first><last>Kuznetsov</last></author>
      <author><first>Teresa</first><last>Martin</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>471–482</pages>
      <url hash="fc190b2d">E17-1045</url>
      <abstract>Domain dependence of NLP systems is one of the major obstacles to their application in large-scale text analysis, also restricting the applicability of FrameNet semantic role labeling (SRL) systems. Yet, current FrameNet SRL systems are still only evaluated on a single in-domain test set. For the first time, we study the domain dependence of FrameNet SRL on a wide range of <a href="https://en.wikipedia.org/wiki/Benchmark_(computing)">benchmark sets</a>. We create a novel test set for FrameNet SRL based on user-generated web text and find that the major bottleneck for out-of-domain FrameNet SRL is the frame identification step. To address this problem, we develop a simple, yet efficient <a href="https://en.wikipedia.org/wiki/System">system</a> based on distributed word representations. Our <a href="https://en.wikipedia.org/wiki/System">system</a> closely approaches the state-of-the-art in-domain while outperforming the best available frame identification system out-of-domain. We publish our <a href="https://en.wikipedia.org/wiki/System">system</a> and test data for research purposes.</abstract>
      <bibkey>hartmann-etal-2017-domain</bibkey>
    </paper>
    <paper id="46">
      <title>TDParse : Multi-target-specific sentiment recognition on Twitter<fixed-case>TDP</fixed-case>arse: Multi-target-specific sentiment recognition on <fixed-case>T</fixed-case>witter</title>
      <author><first>Bo</first><last>Wang</last></author>
      <author><first>Maria</first><last>Liakata</last></author>
      <author><first>Arkaitz</first><last>Zubiaga</last></author>
      <author><first>Rob</first><last>Procter</last></author>
      <pages>483–493</pages>
      <url hash="fc6da506">E17-1046</url>
      <abstract>Existing target-specific sentiment recognition methods consider only a single target per tweet, and have been shown to miss nearly half of the actual targets mentioned. We present a <a href="https://en.wikipedia.org/wiki/Twitter">corpus of UK election tweets</a>, with an average of 3.09 entities per tweet and more than one type of <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment</a> in half of the tweets. This requires a method for multi-target specific sentiment recognition, which we develop by using the context around a target as well as syntactic dependencies involving the target. We present results of our method on both a benchmark corpus of single targets and the multi-target election corpus, showing state-of-the art performance in both corpora and outperforming previous approaches to multi-target sentiment task as well as deep learning models for single-target sentiment.</abstract>
      <bibkey>wang-etal-2017-tdparse</bibkey>
    </paper>
    <paper id="48">
      <title>An Extensive Empirical Evaluation of Character-Based Morphological Tagging for 14 Languages</title>
      <author><first>Georg</first><last>Heigold</last></author>
      <author><first>Guenter</first><last>Neumann</last></author>
      <author><first>Josef</first><last>van Genabith</last></author>
      <pages>505–513</pages>
      <url hash="34950c22">E17-1048</url>
      <abstract>This paper investigates neural character-based morphological tagging for languages with complex morphology and large tag sets. Character-based approaches are attractive as they can handle rarely- and unseen words gracefully. We evaluate on 14 languages and observe consistent gains over a state-of-the-art morphological tagger across all languages except for <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/French_language">French</a>, where we match the state-of-the-art. We compare two architectures for computing character-based word vectors using <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent (RNN)</a> and <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional (CNN) nets</a>. We show that the CNN based approach performs slightly worse and less consistently than the RNN based approach. Small but systematic gains are observed when combining the two <a href="https://en.wikipedia.org/wiki/Computer_architecture">architectures</a> by <a href="https://en.wikipedia.org/wiki/Assembly_language">ensembling</a>.</abstract>
      <bibkey>heigold-etal-2017-extensive</bibkey>
    </paper>
    <paper id="49">
      <title>Neural Multi-Source Morphological Reinflection</title>
      <author><first>Katharina</first><last>Kann</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>514–524</pages>
      <url hash="a7b17f05">E17-1049</url>
      <abstract>We explore the task of multi-source morphological reinflection, which generalizes the standard, single-source version. The input consists of (i) a target tag and (ii) multiple pairs of source form and source tag for a lemma. The motivation is that it is beneficial to have access to more than one <a href="https://en.wikipedia.org/wiki/Form_(document)">source form</a> since different <a href="https://en.wikipedia.org/wiki/Form_(document)">source forms</a> can provide complementary information, e.g., different <a href="https://en.wikipedia.org/wiki/Word_stem">stems</a>. We further present a novel extension to the encoder-decoder recurrent neural architecture, consisting of multiple encoders, to better solve the task. We show that our new architecture outperforms single-source reinflection models and publish our dataset for multi-source morphological reinflection to facilitate future research.</abstract>
      <bibkey>kann-etal-2017-neural</bibkey>
    </paper>
    <paper id="50">
      <title>Online Automatic Post-editing for MT in a Multi-Domain Translation Environment<fixed-case>MT</fixed-case> in a Multi-Domain Translation Environment</title>
      <author><first>Rajen</first><last>Chatterjee</last></author>
      <author><first>Gebremedhen</first><last>Gebremelak</last></author>
      <author><first>Matteo</first><last>Negri</last></author>
      <author><first>Marco</first><last>Turchi</last></author>
      <pages>525–535</pages>
      <url hash="bc02472a">E17-1050</url>
      <abstract>Automatic post-editing (APE) for <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation (MT)</a> aims to fix recurrent errors made by the <a href="https://en.wikipedia.org/wiki/Machine_translation">MT decoder</a> by learning from correction examples. In controlled evaluation scenarios, the representativeness of the training set with respect to the test data is a key factor to achieve good performance. Real-life scenarios, however, do not guarantee such favorable learning conditions. Ideally, to be integrated in a real professional translation workflow (e.g. to play a role in computer-assisted translation framework), APE tools should be flexible enough to cope with continuous streams of diverse data coming from different domains / genres. To cope with this problem, we propose an online APE framework that is : i) robust to data diversity (i.e. capable to learn and apply correction rules in the right contexts) and ii) able to evolve over time (by continuously extending and refining its knowledge). In a comparative evaluation, with English-German test data coming in random order from two different domains, we show the effectiveness of our approach, which outperforms a strong <a href="https://en.wikipedia.org/wiki/Batch_processing">batch system</a> and the <a href="https://en.wikipedia.org/wiki/State_of_the_art">state of the art</a> in online APE.</abstract>
      <bibkey>chatterjee-etal-2017-online</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2016">WMT 2016</pwcdataset>
    </paper>
    <paper id="51">
      <title>An Incremental Parser for Abstract Meaning Representation<fixed-case>A</fixed-case>bstract <fixed-case>M</fixed-case>eaning <fixed-case>R</fixed-case>epresentation</title>
      <author><first>Marco</first><last>Damonte</last></author>
      <author><first>Shay B.</first><last>Cohen</last></author>
      <author><first>Giorgio</first><last>Satta</last></author>
      <pages>536–546</pages>
      <url hash="244b81fb">E17-1051</url>
      <abstract>Abstract Meaning Representation (AMR) is a semantic representation for natural language that embeds annotations related to traditional tasks such as <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>, <a href="https://en.wikipedia.org/wiki/Semantic_role_labeling">semantic role labeling</a>, <a href="https://en.wikipedia.org/wiki/Word-sense_disambiguation">word sense disambiguation</a> and co-reference resolution. We describe a transition-based parser for AMR that parses sentences left-to-right, in <a href="https://en.wikipedia.org/wiki/Time_complexity">linear time</a>. We further propose a test-suite that assesses specific subtasks that are helpful in comparing AMR parsers, and show that our <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> is competitive with the state of the art on the LDC2015E86 dataset and that it outperforms state-of-the-art parsers for recovering named entities and handling polarity.</abstract>
      <bibkey>damonte-etal-2017-incremental</bibkey>
      <pwccode url="https://github.com/mdtux89/amr-evaluation" additional="true">mdtux89/amr-evaluation</pwccode>
    </paper>
    <paper id="52">
      <title>Integrated Learning of Dialog Strategies and Semantic Parsing</title>
      <author><first>Aishwarya</first><last>Padmakumar</last></author>
      <author><first>Jesse</first><last>Thomason</last></author>
      <author><first>Raymond J.</first><last>Mooney</last></author>
      <pages>547–557</pages>
      <url hash="7b235d12">E17-1052</url>
      <abstract>Natural language understanding and <a href="https://en.wikipedia.org/wiki/Dialog_management">dialog management</a> are two integral components of interactive dialog systems. Previous research has used machine learning techniques to individually optimize these <a href="https://en.wikipedia.org/wiki/Component_(graph_theory)">components</a>, with different forms of direct and indirect supervision. We present an approach to integrate the learning of both a dialog strategy using <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>, and a semantic parser for robust <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language understanding</a>, using only natural dialog interaction for supervision. Experimental results on a simulated task of robot instruction demonstrate that joint learning of both <a href="https://en.wikipedia.org/wiki/Component-based_software_engineering">components</a> improves dialog performance over learning either of these <a href="https://en.wikipedia.org/wiki/Component-based_software_engineering">components</a> alone.</abstract>
      <bibkey>padmakumar-etal-2017-integrated</bibkey>
    </paper>
    <paper id="53">
      <title>Unsupervised AMR-Dependency Parse Alignment<fixed-case>AMR</fixed-case>-Dependency Parse Alignment</title>
      <author><first>Wei-Te</first><last>Chen</last></author>
      <author><first>Martha</first><last>Palmer</last></author>
      <pages>558–567</pages>
      <url hash="8d5f2231">E17-1053</url>
      <abstract>In this paper, we introduce an Abstract Meaning Representation (AMR) to Dependency Parse aligner. Alignment is a preliminary step for AMR parsing, and our aligner improves current AMR parser performance. Our aligner involves several different features, including named entity tags and semantic role labels, and uses Expectation-Maximization training. Results show that our aligner reaches an 87.1 % F-Score score with the experimental data, and enhances AMR parsing.</abstract>
      <bibkey>chen-palmer-2017-unsupervised</bibkey>
    </paper>
    <paper id="54">
      <title>Improving Chinese Semantic Role Labeling using High-quality Surface and Deep Case Frames<fixed-case>C</fixed-case>hinese Semantic Role Labeling using High-quality Surface and Deep Case Frames</title>
      <author><first>Gongye</first><last>Jin</last></author>
      <author><first>Daisuke</first><last>Kawahara</last></author>
      <author><first>Sadao</first><last>Kurohashi</last></author>
      <pages>568–577</pages>
      <url hash="85d716b2">E17-1054</url>
      <abstract>This paper presents a method for applying automatically acquired knowledge to semantic role labeling (SRL). We use a large amount of automatically extracted knowledge to improve the performance of SRL. We present two varieties of <a href="https://en.wikipedia.org/wiki/Knowledge">knowledge</a>, which we call surface case frames and deep case frames. Although the surface case frames are compiled from syntactic parses and can be used as rich syntactic knowledge, they have limited capability for resolving semantic ambiguity. To compensate the deficiency of the <a href="https://en.wikipedia.org/wiki/Frame_(artificial_intelligence)">surface case frames</a>, we compile <a href="https://en.wikipedia.org/wiki/Frame_(artificial_intelligence)">deep case frames</a> from automatic semantic roles. We also consider <a href="https://en.wikipedia.org/wiki/Quality_management">quality management</a> for both types of <a href="https://en.wikipedia.org/wiki/Knowledge">knowledge</a> in order to get rid of the noise brought from the automatic analyses. The experimental results show that Chinese SRL can be improved using automatically acquired knowledge and the <a href="https://en.wikipedia.org/wiki/Quality_management">quality management</a> shows a positive effect on this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>.</abstract>
      <bibkey>jin-etal-2017-improving</bibkey>
    </paper>
    <paper id="55">
      <title>Multi-level Representations for Fine-Grained Typing of Knowledge Base Entities</title>
      <author><first>Yadollah</first><last>Yaghoobzadeh</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>578–589</pages>
      <url hash="b7e7b5b8">E17-1055</url>
      <abstract>Entities are essential elements of <a href="https://en.wikipedia.org/wiki/Natural_language">natural language</a>. In this paper, we present <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> for learning multi-level representations of entities on three complementary levels : character (character patterns in entity names extracted, e.g., by neural networks), word (embeddings of words in entity names) and entity (entity embeddings). We investigate state-of-the-art learning methods on each level and find large differences, e.g., for <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning models</a>, traditional ngram features and the subword model of fasttext (Bojanowski et al., 2016) on the character level ; for <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> (Mikolov et al., 2013) on the word level ; and for the order-aware model wang2vec (Ling et al., 2015a) on the entity level. We confirm experimentally that each level of <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">representation</a> contributes complementary information and a joint representation of all three levels improves the existing embedding based baseline for fine-grained entity typing by a large margin. Additionally, we show that adding information from entity descriptions further improves multi-level representations of entities.</abstract>
      <bibkey>yaghoobzadeh-schutze-2017-multi</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/figer">FIGER</pwcdataset>
    </paper>
    <paper id="56">
      <title>The ContrastMedium Algorithm : Taxonomy Induction From Noisy Knowledge Graphs With Just A Few Links<fixed-case>C</fixed-case>ontrast<fixed-case>M</fixed-case>edium Algorithm: Taxonomy Induction From Noisy Knowledge Graphs With Just A Few Links</title>
      <author><first>Stefano</first><last>Faralli</last></author>
      <author><first>Alexander</first><last>Panchenko</last></author>
      <author><first>Chris</first><last>Biemann</last></author>
      <author><first>Simone Paolo</first><last>Ponzetto</last></author>
      <pages>590–600</pages>
      <url hash="e2a5a0bb">E17-1056</url>
      <abstract>In this paper, we present ContrastMedium, an <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> that transforms noisy semantic networks into full-fledged, clean taxonomies. ContrastMedium is able to identify the embedded taxonomy structure from a noisy knowledge graph without explicit human supervision such as, for instance, a set of manually selected input root and leaf concepts. This is achieved by leveraging structural information from a companion reference taxonomy, to which the input <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graph</a> is linked (either automatically or manually). When used in conjunction with methods for hypernym acquisition and knowledge base linking, our methodology provides a complete solution for end-to-end taxonomy induction. We conduct experiments using automatically acquired knowledge graphs, as well as a SemEval benchmark, and show that our method is able to achieve high performance on the task of taxonomy induction.</abstract>
      <bibkey>faralli-etal-2017-contrastmedium</bibkey>
    </paper>
    <paper id="57">
      <title>Probabilistic Inference for Cold Start Knowledge Base Population with Prior World Knowledge</title>
      <author><first>Bonan</first><last>Min</last></author>
      <author><first>Marjorie</first><last>Freedman</last></author>
      <author><first>Talya</first><last>Meltzer</last></author>
      <pages>601–612</pages>
      <url hash="5388d126">E17-1057</url>
      <abstract>Building knowledge bases (KB) automatically from <a href="https://en.wikipedia.org/wiki/Text_corpus">text corpora</a> is crucial for many applications such as <a href="https://en.wikipedia.org/wiki/Question_answering">question answering</a> and <a href="https://en.wikipedia.org/wiki/Web_search_engine">web search</a>. The problem is very challenging and has been divided into sub-problems such as mention and named entity recognition, <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity linking</a> and <a href="https://en.wikipedia.org/wiki/Relation_extraction">relation extraction</a>. However, combining these components has shown to be under-constrained and often produces KBs with supersize entities and common-sense errors in relations (a person has multiple birthdates). The errors are difficult to resolve solely with IE tools but become obvious with <a href="https://en.wikipedia.org/wiki/World_knowledge">world knowledge</a> at the corpus level. By analyzing <a href="https://en.wikipedia.org/wiki/Freebase">Freebase</a> and a large text collection, we found that per-relation cardinality and the popularity of entities follow the <a href="https://en.wikipedia.org/wiki/Power_law">power-law distribution</a> favoring flat long tails with low-frequency instances. We present a probabilistic joint inference algorithm to incorporate this <a href="https://en.wikipedia.org/wiki/World_knowledge">world knowledge</a> during KB construction. Our approach yields state-of-the-art performance on the TAC Cold Start task, and 42 % and 19.4 % relative improvements in F1 over our baseline on Cold Start hop-1 and all-hop queries respectively.</abstract>
      <bibkey>min-etal-2017-probabilistic</bibkey>
    </paper>
    <paper id="58">
      <title>Generalizing to Unseen Entities and Entity Pairs with Row-less Universal Schema</title>
      <author><first>Patrick</first><last>Verga</last></author>
      <author><first>Arvind</first><last>Neelakantan</last></author>
      <author><first>Andrew</first><last>McCallum</last></author>
      <pages>613–622</pages>
      <url hash="a12a6697">E17-1058</url>
      <abstract>Universal schema predicts the types of entities and relations in a knowledge base (KB) by jointly embedding the union of all available schema typesnot only types from multiple structured databases (such as <a href="https://en.wikipedia.org/wiki/Freebase">Freebase</a> or Wikipedia infoboxes), but also types expressed as textual patterns from raw text. This prediction is typically modeled as a matrix completion problem, with one type per column, and either one or two entities per row (in the case of <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity types</a> or <a href="https://en.wikipedia.org/wiki/Binary_relation">binary relation types</a>, respectively). Factorizing this sparsely observed matrix yields a learned vector embedding for each row and each column. In this paper we explore the problem of making predictions for entities or entity-pairs unseen at training time (and hence without a pre-learned row embedding). We propose an approach having no per-row parameters at all ; rather we produce a row vector on the fly using a learned aggregation function of the vectors of the observed columns for that row. We experiment with various aggregation functions, including neural network attention models. Our approach can be understood as a natural language database, in that questions about KB entities are answered by attending to textual or database evidence. In experiments predicting both relations and entity types, we demonstrate that despite having an order of magnitude fewer parameters than traditional universal schema, we can match the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of the traditional model, and more importantly, we can now make predictions about unseen rows with nearly the same <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> as rows available at training time.</abstract>
      <bibkey>verga-etal-2017-generalizing</bibkey>
      <pwccode url="https://github.com/patverga/torch-relation-extraction" additional="false">patverga/torch-relation-extraction</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/fb15k">FB15k</pwcdataset>
    </paper>
    <paper id="59">
      <title>Learning to Generate Product Reviews from Attributes</title>
      <author><first>Li</first><last>Dong</last></author>
      <author><first>Shaohan</first><last>Huang</last></author>
      <author><first>Furu</first><last>Wei</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <author><first>Ke</first><last>Xu</last></author>
      <pages>623–632</pages>
      <url hash="c2aab7d3">E17-1059</url>
      <abstract>Automatically generating product reviews is a meaningful, yet not well-studied task in <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a>. Traditional natural language generation methods rely extensively on hand-crafted rules and predefined templates. This paper presents an attention-enhanced attribute-to-sequence model to generate product reviews for given attribute information, such as <a href="https://en.wikipedia.org/wiki/User_(computing)">user</a>, product, and rating. The attribute encoder learns to represent input attributes as vectors. Then, the sequence decoder generates reviews by conditioning its output on these vectors. We also introduce an <a href="https://en.wikipedia.org/wiki/Attentional_control">attention mechanism</a> to jointly generate <a href="https://en.wikipedia.org/wiki/Review_article">reviews</a> and align words with input attributes. The proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is trained end-to-end to maximize the likelihood of target product reviews given the <a href="https://en.wikipedia.org/wiki/Variable_and_attribute_(research)">attributes</a>. We build a publicly available dataset for the review generation task by leveraging the Amazon book reviews and their metadata. Experiments on the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> show that our approach outperforms baseline methods and the <a href="https://en.wikipedia.org/wiki/Attentional_control">attention mechanism</a> significantly improves the performance of our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>.</abstract>
      <bibkey>dong-etal-2017-learning-generate</bibkey>
    </paper>
    <paper id="60">
      <title>Learning to generate one-sentence biographies from <a href="https://en.wikipedia.org/wiki/Wikidata">Wikidata</a><fixed-case>W</fixed-case>ikidata</title>
      <author><first>Andrew</first><last>Chisholm</last></author>
      <author><first>Will</first><last>Radford</last></author>
      <author><first>Ben</first><last>Hachey</last></author>
      <pages>633–642</pages>
      <url hash="0b54ba37">E17-1060</url>
      <abstract>We investigate the generation of one-sentence Wikipedia biographies from facts derived from Wikidata slot-value pairs. We train a recurrent neural network sequence-to-sequence model with attention to select facts and generate textual summaries. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> incorporates a novel secondary objective that helps ensure <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> generates sentences that contain the input facts. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves a BLEU score of 41, improving significantly upon the vanilla sequence-to-sequence model and scoring roughly twice that of a simple template baseline. Human preference evaluation suggests the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is nearly as good as the Wikipedia reference. Manual analysis explores content selection, suggesting the model can trade the ability to infer knowledge against the risk of hallucinating incorrect information.</abstract>
      <bibkey>chisholm-etal-2017-learning</bibkey>
      <pwccode url="https://github.com/andychisholm/mimo" additional="false">andychisholm/mimo</pwccode>
    </paper>
    <paper id="61">
      <title>Transition-Based Deep Input Linearization</title>
      <author><first>Ratish</first><last>Puduppully</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <author><first>Manish</first><last>Shrivastava</last></author>
      <pages>643–654</pages>
      <url hash="c182746b">E17-1061</url>
      <abstract>Traditional methods for deep NLG adopt pipeline approaches comprising stages such as constructing syntactic input, predicting function words, linearizing the syntactic input and generating the surface forms. Though easier to visualize, pipeline approaches suffer from error propagation. In addition, information available across modules can not be leveraged by all modules. We construct a transition-based model to jointly perform <a href="https://en.wikipedia.org/wiki/Linearization">linearization</a>, function word prediction and morphological generation, which considerably improves upon the accuracy compared to a pipelined baseline system. On a standard deep input linearization shared task, our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves the best results reported so far.</abstract>
      <bibkey>puduppully-etal-2017-transition</bibkey>
      <pwccode url="https://github.com/SUTDNLP/ZGen" additional="false">SUTDNLP/ZGen</pwccode>
    </paper>
    <paper id="64">
      <title>Tackling Error Propagation through <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement Learning</a> : A Case of Greedy Dependency Parsing</title>
      <author><first>Minh</first><last>Lê</last></author>
      <author><first>Antske</first><last>Fokkens</last></author>
      <pages>677–687</pages>
      <url hash="60b8b802">E17-1064</url>
      <abstract>Error propagation is a common problem in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>. Reinforcement learning explores erroneous states during training and can therefore be more robust when mistakes are made early in a process. In this paper, we apply <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> to greedy dependency parsing which is known to suffer from <a href="https://en.wikipedia.org/wiki/Error_propagation">error propagation</a>. Reinforcement learning improves accuracy of both labeled and unlabeled dependencies of the Stanford Neural Dependency Parser, a high performance greedy parser, while maintaining its efficiency. We investigate the portion of errors which are the result of <a href="https://en.wikipedia.org/wiki/Error_propagation">error propagation</a> and confirm that <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> reduces the occurrence of <a href="https://en.wikipedia.org/wiki/Error_propagation">error propagation</a>.</abstract>
      <bibkey>le-fokkens-2017-tackling</bibkey>
      <pwccode url="https://bitbucket.org/cltl/redep-java" additional="false">cltl/redep-java</pwccode>
    </paper>
    <paper id="65">
      <title>Noisy-context surprisal as a human sentence processing cost model</title>
      <author><first>Richard</first><last>Futrell</last></author>
      <author><first>Roger</first><last>Levy</last></author>
      <pages>688–698</pages>
      <url hash="11906a5e">E17-1065</url>
      <abstract>We use the noisy-channel theory of human sentence comprehension to develop an incremental processing cost model that unifies and extends key features of expectation-based and memory-based models. In this model, which we call noisy-context surprisal, the processing cost of a word is the surprisal of the word given a noisy representation of the preceding context. We show that this model accounts for an outstanding puzzle in sentence comprehension, language-dependent structural forgetting effects (Gibson and Thomas, 1999 ; Vasishth et al., 2010 ; Frank et al., 2016), which are previously not well modeled by either expectation-based or memory-based approaches. Additionally, we show that this model derives and generalizes locality effects (Gibson, 1998 ; Demberg and Keller, 2008), a signature prediction of memory-based models. We give <a href="https://en.wikipedia.org/wiki/Corpus_linguistics">corpus-based evidence</a> for a key assumption in this derivation.</abstract>
      <bibkey>futrell-levy-2017-noisy</bibkey>
    </paper>
    <paper id="66">
      <title>Task-Specific Attentive Pooling of Phrase Alignments Contributes to Sentence Matching</title>
      <author><first>Wenpeng</first><last>Yin</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>699–709</pages>
      <url hash="4c9d276d">E17-1066</url>
      <abstract>This work studies comparatively two typical sentence matching tasks : textual entailment (TE) and answer selection (AS), observing that weaker phrase alignments are more critical in TE, while stronger phrase alignments deserve more attention in AS. The key to reach this observation lies in phrase detection, phrase representation, phrase alignment, and more importantly how to connect those aligned phrases of different matching degrees with the final <a href="https://en.wikipedia.org/wiki/Classifier_(linguistics)">classifier</a>. Prior work (i) has limitations in phrase generation and representation, or (ii) conducts <a href="https://en.wikipedia.org/wiki/Sequence_alignment">alignment</a> at word and phrase levels by handcrafted features or (iii) utilizes a single framework of <a href="https://en.wikipedia.org/wiki/Sequence_alignment">alignment</a> without considering the characteristics of specific tasks, which limits the <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a>’s effectiveness across tasks. We propose an architecture based on Gated Recurrent Unit that supports (i) representation learning of phrases of arbitrary granularity and (ii) task-specific attentive pooling of phrase alignments between two sentences. Experimental results on TE and AS match our observation and show the effectiveness of our approach.</abstract>
      <bibkey>yin-schutze-2017-task</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/sick">SICK</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikiqa">WikiQA</pwcdataset>
    </paper>
    <paper id="67">
      <title>On-demand Injection of Lexical Knowledge for Recognising Textual Entailment</title>
      <author><first>Pascual</first><last>Martínez-Gómez</last></author>
      <author><first>Koji</first><last>Mineshima</last></author>
      <author><first>Yusuke</first><last>Miyao</last></author>
      <author><first>Daisuke</first><last>Bekki</last></author>
      <pages>710–720</pages>
      <url hash="5adc44c3">E17-1067</url>
      <abstract>We approach the recognition of textual entailment using logical semantic representations and a <a href="https://en.wikipedia.org/wiki/Automated_theorem_proving">theorem prover</a>. In this setup, lexical divergences that preserve semantic entailment between the source and target texts need to be explicitly stated. However, recognising subsentential semantic relations is not trivial. We address this problem by monitoring the proof of the theorem and detecting unprovable sub-goals that share <a href="https://en.wikipedia.org/wiki/Predicate_(mathematical_logic)">predicate arguments</a> with <a href="https://en.wikipedia.org/wiki/Premise">logical premises</a>. If a <a href="https://en.wikipedia.org/wiki/Binary_relation">linguistic relation</a> exists, then an appropriate <a href="https://en.wikipedia.org/wiki/Axiom">axiom</a> is constructed on-demand and the theorem proving continues. Experiments show that this approach is effective and precise, producing a <a href="https://en.wikipedia.org/wiki/System">system</a> that outperforms other <a href="https://en.wikipedia.org/wiki/Logic_programming">logic-based systems</a> and is competitive with state-of-the-art <a href="https://en.wikipedia.org/wiki/Statistics">statistical methods</a>.</abstract>
      <bibkey>martinez-gomez-etal-2017-demand</bibkey>
      <pwccode url="https://github.com/mynlp/ccg2lambda" additional="false">mynlp/ccg2lambda</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/sick">SICK</pwcdataset>
    </paper>
    <paper id="68">
      <title>Learning to Predict Denotational Probabilities For Modeling Entailment</title>
      <author><first>Alice</first><last>Lai</last></author>
      <author><first>Julia</first><last>Hockenmaier</last></author>
      <pages>721–730</pages>
      <url hash="f535c671">E17-1068</url>
      <abstract>We propose a framework that captures the denotational probabilities of words and phrases by embedding them in a <a href="https://en.wikipedia.org/wiki/Vector_space">vector space</a>, and present a method to induce such an <a href="https://en.wikipedia.org/wiki/Embedding">embedding</a> from a dataset of denotational probabilities. We show that our model successfully predicts denotational probabilities for unseen phrases, and that its predictions are useful for textual entailment datasets such as SICK and SNLI.</abstract>
      <bibkey>lai-hockenmaier-2017-learning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/sick">SICK</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="70">
      <title>Argument Strength is in the Eye of the Beholder : Audience Effects in <a href="https://en.wikipedia.org/wiki/Persuasion">Persuasion</a></title>
      <author><first>Stephanie</first><last>Lukin</last></author>
      <author><first>Pranav</first><last>Anand</last></author>
      <author><first>Marilyn</first><last>Walker</last></author>
      <author><first>Steve</first><last>Whittaker</last></author>
      <pages>742–753</pages>
      <url hash="9dcb34e6">E17-1070</url>
      <abstract>Americans spend about a third of their time online, with many participating in online conversations on social and political issues. We hypothesize that social media arguments on such issues may be more engaging and persuasive than traditional media summaries, and that particular types of people may be more or less convinced by particular styles of argument, e.g. emotional arguments may resonate with some personalities while factual arguments resonate with others. We report a set of experiments testing at large scale how audience variables interact with argument style to affect the persuasiveness of an argument, an under-researched topic within <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. We show that belief change is affected by <a href="https://en.wikipedia.org/wiki/Personality_psychology">personality factors</a>, with conscientious, open and agreeable people being more convinced by emotional arguments.</abstract>
      <bibkey>lukin-etal-2017-argument</bibkey>
    </paper>
    <paper id="71">
      <title>A Language-independent and Compositional Model for Personality Trait Recognition from Short Texts</title>
      <author id="fei-liu-unimelb"><first>Fei</first><last>Liu</last></author>
      <author><first>Julien</first><last>Perez</last></author>
      <author><first>Scott</first><last>Nowson</last></author>
      <pages>754–764</pages>
      <url hash="de04c706">E17-1071</url>
      <abstract>There have been many attempts at automatically recognising author personality traits from text, typically incorporating <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">linguistic features</a> with conventional <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning models</a>, e.g. linear regression or <a href="https://en.wikipedia.org/wiki/Support_vector_machine">Support Vector Machines</a>. In this work, we propose to use deep-learning-based models with atomic features of text   the characters   to build hierarchical, vectorial word and sentence representations for the task of trait inference. On a corpus of tweets, this method shows state-of-the-art performance across five traits and three languages (English, Spanish and Italian) compared with prior work in <a href="https://en.wikipedia.org/wiki/Author_profiling">author profiling</a>. The results, supported by preliminary visualisation work, are encouraging for the ability to detect <a href="https://en.wikipedia.org/wiki/Complex_traits">complex human traits</a>.</abstract>
      <bibkey>liu-etal-2017-language</bibkey>
    </paper>
    <paper id="72">
      <title>A Strong Baseline for Learning Cross-Lingual Word Embeddings from Sentence Alignments</title>
      <author><first>Omer</first><last>Levy</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <author><first>Yoav</first><last>Goldberg</last></author>
      <pages>765–774</pages>
      <url hash="cc355432">E17-1072</url>
      <abstract>While cross-lingual word embeddings have been studied extensively in recent years, the qualitative differences between the different <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> remain vague. We observe that whether or not an <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> uses a particular feature set (sentence IDs) accounts for a significant performance gap among these <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a>. This feature set is also used by traditional alignment algorithms, such as IBM Model-1, which demonstrate similar performance to state-of-the-art embedding algorithms on a variety of <a href="https://en.wikipedia.org/wiki/Benchmark_(computing)">benchmarks</a>. Overall, we observe that different algorithmic approaches for utilizing the sentence ID feature space result in similar performance. This paper draws both empirical and theoretical parallels between the embedding and alignment literature, and suggests that adding additional sources of information, which go beyond the traditional signal of bilingual sentence-aligned corpora, may substantially improve cross-lingual word embeddings, and that future baselines should at least take such features into account.</abstract>
      <bibkey>levy-etal-2017-strong</bibkey>
    </paper>
    <paper id="73">
      <title>Online Learning of Task-specific Word Representations with a Joint Biconvex Passive-Aggressive Algorithm</title>
      <author><first>Pascal</first><last>Denis</last></author>
      <author><first>Liva</first><last>Ralaivola</last></author>
      <pages>775–784</pages>
      <url hash="05466654">E17-1073</url>
      <abstract>This paper presents a new, efficient method for learning task-specific word vectors using a variant of the Passive-Aggressive algorithm. Specifically, this <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> learns a word embedding matrix in tandem with the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier parameters</a> in an online fashion, solving a <a href="https://en.wikipedia.org/wiki/Convex_optimization">bi-convex constrained optimization</a> at each iteration. We provide a theoretical analysis of this new <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> in terms of regret bounds, and evaluate it on both synthetic data and NLP classification problems, including text classification and <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a>. In the latter case, we compare various pre-trained word vectors to initialize our word embedding matrix, and show that the <a href="https://en.wikipedia.org/wiki/Matrix_(mathematics)">matrix</a> learned by our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> vastly outperforms the initial <a href="https://en.wikipedia.org/wiki/Matrix_(mathematics)">matrix</a>, with performance results comparable or above the state-of-the-art on these tasks.</abstract>
      <bibkey>denis-ralaivola-2017-online</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
    </paper>
    <paper id="74">
      <title>Nonsymbolic Text Representation</title>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>785–796</pages>
      <url hash="c9e16ee2">E17-1074</url>
      <abstract>We introduce the first generic text representation model that is completely nonsymbolic, i.e., it does not require the availability of a segmentation or tokenization method that attempts to identify words or other symbolic units in text. This applies to training the parameters of the <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> on a training corpus as well as to applying it when computing the representation of a new text. We show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> performs better than prior work on an <a href="https://en.wikipedia.org/wiki/Information_extraction">information extraction</a> and a text denoising task.</abstract>
      <bibkey>schutze-2017-nonsymbolic</bibkey>
    </paper>
    <paper id="76">
      <title>Event extraction from <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> using Non-Parametric Bayesian Mixture Model with Word Embeddings<fixed-case>T</fixed-case>witter using Non-Parametric <fixed-case>B</fixed-case>ayesian Mixture Model with Word Embeddings</title>
      <author><first>Deyu</first><last>Zhou</last></author>
      <author><first>Xuan</first><last>Zhang</last></author>
      <author><first>Yulan</first><last>He</last></author>
      <pages>808–817</pages>
      <url hash="c78baba2">E17-1076</url>
      <abstract>To extract structured representations of newsworthy events from <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>, <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised models</a> typically assume that tweets involving the same named entities and expressed using similar words are likely to belong to the same event. Hence, they group tweets into clusters based on the <a href="https://en.wikipedia.org/wiki/Co-occurrence">co-occurrence patterns</a> of <a href="https://en.wikipedia.org/wiki/Named_entity">named entities</a> and <a href="https://en.wikipedia.org/wiki/Index_term">topical keywords</a>. However, there are two main limitations. First, they require the number of events to be known beforehand, which is not realistic in practical applications. Second, they do n’t recognise that the same named entity might be referred to by multiple mentions and tweets using different mentions would be wrongly assigned to different events. To overcome these limitations, we propose a non-parametric Bayesian mixture model with <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> for <a href="https://en.wikipedia.org/wiki/Event_(probability_theory)">event extraction</a>, in which the number of events can be inferred automatically and the issue of lexical variations for the same named entity can be dealt with properly. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> has been evaluated on three <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> with sizes ranging between 2,499 and over 60 million tweets. Experimental results show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms the baseline approach on all <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> by 5-8 % in <a href="https://en.wikipedia.org/wiki/F-measure">F-measure</a>.</abstract>
      <bibkey>zhou-etal-2017-event</bibkey>
    </paper>
    <paper id="77">
      <title>End-to-end Relation Extraction using <a href="https://en.wikipedia.org/wiki/Neural_network">Neural Networks</a> and <a href="https://en.wikipedia.org/wiki/Markov_logic_network">Markov Logic Networks</a><fixed-case>M</fixed-case>arkov <fixed-case>L</fixed-case>ogic <fixed-case>N</fixed-case>etworks</title>
      <author><first>Sachin</first><last>Pawar</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <author><first>Girish</first><last>Palshikar</last></author>
      <pages>818–827</pages>
      <url hash="7f2043a3">E17-1077</url>
      <abstract>End-to-end relation extraction refers to identifying boundaries of entity mentions, entity types of these mentions and appropriate <a href="https://en.wikipedia.org/wiki/Semantic_relation">semantic relation</a> for each pair of mentions. Traditionally, separate <a href="https://en.wikipedia.org/wiki/Predictive_modelling">predictive models</a> were trained for each of these tasks and were used in a pipeline fashion where output of one <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is fed as input to another. But it was observed that addressing some of these <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> jointly results in better performance. We propose a single, joint neural network based model to carry out all the three tasks of boundary identification, <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity type classification</a> and relation type classification. This <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> is referred to as All Word Pairs model (AWP-NN) as it assigns an appropriate label to each word pair in a given sentence for performing end-to-end relation extraction. We also propose to refine output of the AWP-NN model by using inference in Markov Logic Networks (MLN) so that additional <a href="https://en.wikipedia.org/wiki/Domain_knowledge">domain knowledge</a> can be effectively incorporated. We demonstrate effectiveness of our approach by achieving better end-to-end relation extraction performance than all 4 previous joint modelling approaches, on the standard dataset of ACE 2004.</abstract>
      <bibkey>pawar-etal-2017-end</bibkey>
    </paper>
    <paper id="78">
      <title>Trust, but Verify ! Better Entity Linking through Automatic Verification</title>
      <author><first>Benjamin</first><last>Heinzerling</last></author>
      <author><first>Michael</first><last>Strube</last></author>
      <author><first>Chin-Yew</first><last>Lin</last></author>
      <pages>828–838</pages>
      <url hash="d5f5781e">E17-1078</url>
      <abstract>We introduce automatic verification as a post-processing step for entity linking (EL). The proposed method trusts EL system results collectively, by assuming entity mentions are mostly linked correctly, in order to create a semantic profile of the given text using geospatial and temporal information, as well as fine-grained entity types. This profile is then used to automatically verify each linked mention individually, i.e., to predict whether it has been linked correctly or not. Verification allows leveraging a rich set of global and pairwise features that would be prohibitively expensive for EL systems employing global inference. Evaluation shows consistent improvements across datasets and systems. In particular, when applied to state-of-the-art systems, our method yields an absolute improvement in <a href="https://en.wikipedia.org/wiki/Linker_(computing)">linking</a> performance of up to 1.7 F1 on AIDA / CoNLL’03 and up to 2.4 F1 on the English TAC KBP 2015 TEDL dataset.</abstract>
      <bibkey>heinzerling-etal-2017-trust</bibkey>
    </paper>
    <paper id="79">
      <title>Named Entity Recognition in the Medical Domain with Constrained CRF Models<fixed-case>CRF</fixed-case> Models</title>
      <author><first>Charles</first><last>Jochim</last></author>
      <author><first>Léa</first><last>Deleris</last></author>
      <pages>839–849</pages>
      <url hash="cdde40fa">E17-1079</url>
      <abstract>This paper investigates how to improve performance on information extraction tasks by constraining and sequencing CRF-based approaches. We consider two different relation extraction tasks, both from the <a href="https://en.wikipedia.org/wiki/Medical_literature">medical literature</a> : <a href="https://en.wikipedia.org/wiki/Independence_(probability_theory)">dependence relations</a> and <a href="https://en.wikipedia.org/wiki/Probability">probability statements</a>. We explore whether adding <a href="https://en.wikipedia.org/wiki/Constraint_(mathematics)">constraints</a> can lead to an improvement over standard CRF decoding. Results on our relation extraction tasks are promising, showing significant increases in performance from both (i) adding <a href="https://en.wikipedia.org/wiki/Constraint_(mathematics)">constraints</a> to post-process the output of a baseline CRF, which captures <a href="https://en.wikipedia.org/wiki/Domain_knowledge">domain knowledge</a>, and (ii) further allowing flexibility in the application of those <a href="https://en.wikipedia.org/wiki/Constraint_(mathematics)">constraints</a> by leveraging a binary classifier as a pre-processing step.</abstract>
      <bibkey>jochim-deleris-2017-named</bibkey>
    </paper>
    <paper id="80">
      <title>Learning and Knowledge Transfer with Memory Networks for Machine Comprehension</title>
      <author><first>Mohit</first><last>Yadav</last></author>
      <author><first>Lovekesh</first><last>Vig</last></author>
      <author><first>Gautam</first><last>Shroff</last></author>
      <pages>850–859</pages>
      <url hash="fa3a87f2">E17-1080</url>
      <abstract>Enabling machines to read and comprehend <a href="https://en.wikipedia.org/wiki/Unstructured_data">unstructured text</a> remains an unfulfilled goal for <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP research</a>. Recent research efforts on the machine comprehension task have managed to achieve close to ideal performance on <a href="https://en.wikipedia.org/wiki/Simulation">simulated data</a>. However, achieving similar levels of performance on small real world datasets has proved difficult ; major challenges stem from the large vocabulary size, complex grammar, and, the frequent ambiguities in linguistic structure. On the other hand, the requirement of human generated annotations for training, in order to ensure a sufficiently diverse set of questions is prohibitively expensive. Motivated by these practical issues, we propose a novel curriculum inspired training procedure for Memory Networks to improve the performance for machine comprehension with relatively small volumes of training data. Additionally, we explore various <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training regimes</a> for Memory Networks to allow <a href="https://en.wikipedia.org/wiki/Knowledge_transfer">knowledge transfer</a> from a closely related domain having larger volumes of <a href="https://en.wikipedia.org/wiki/Data">labelled data</a>. We also suggest the use of a <a href="https://en.wikipedia.org/wiki/Loss_function">loss function</a> to incorporate the asymmetric nature of <a href="https://en.wikipedia.org/wiki/Knowledge_transfer">knowledge transfer</a>. Our experiments demonstrate improvements on <a href="https://en.wikipedia.org/wiki/Dailymail">Dailymail</a>, <a href="https://en.wikipedia.org/wiki/CNN">CNN</a>, and MCTest datasets.</abstract>
      <bibkey>yadav-etal-2017-learning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/mctest">MCTest</pwcdataset>
    </paper>
    <paper id="81">
      <title>If No Media Were Allowed inside the Venue, Was Anybody Allowed?</title>
      <author><first>Zahra</first><last>Sarabi</last></author>
      <author><first>Eduardo</first><last>Blanco</last></author>
      <pages>860–869</pages>
      <url hash="0cef6d01">E17-1081</url>
      <abstract>This paper presents a <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> to understand <a href="https://en.wikipedia.org/wiki/Negation">negation</a> in positive terms. Specifically, we extract <a href="https://en.wikipedia.org/wiki/Meaning_(linguistics)">positive meaning</a> from <a href="https://en.wikipedia.org/wiki/Affirmation_and_negation">negation</a> when the <a href="https://en.wikipedia.org/wiki/Affirmation_and_negation">negation cue</a> syntactically modifies a noun or adjective. Our approach is grounded on generating potential positive interpretations automatically, and then scoring them. Experimental results show that interpretations scored high can be reliably identified.</abstract>
      <bibkey>sarabi-blanco-2017-media</bibkey>
    </paper>
    <paper id="82">
      <title>Metaheuristic Approaches to Lexical Substitution and Simplification</title>
      <author><first>Sallam</first><last>Abualhaija</last></author>
      <author><first>Tristan</first><last>Miller</last></author>
      <author><first>Judith</first><last>Eckle-Kohler</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <author><first>Karl-Heinz</first><last>Zimmermann</last></author>
      <pages>870–880</pages>
      <url hash="a55bdc11">E17-1082</url>
      <abstract>In this paper, we propose using metaheuristicsin particular, simulated annealing and the new D-Bees algorithmto solve <a href="https://en.wikipedia.org/wiki/Word-sense_disambiguation">word sense disambiguation</a> as an optimization problem within a knowledge-based lexical substitution system. We are the first to perform such an extrinsic evaluation of metaheuristics, for which we use two standard lexical substitution datasets, one <a href="https://en.wikipedia.org/wiki/English_language">English</a> and one <a href="https://en.wikipedia.org/wiki/German_language">German</a>. We find that D-Bees has robust performance for both languages, and performs better than <a href="https://en.wikipedia.org/wiki/Simulated_annealing">simulated annealing</a>, though both achieve good results. Moreover, the D-Beesbased lexical substitution system outperforms state-of-the-art systems on several evaluation metrics. We also show that D-Bees achieves competitive performance in <a href="https://en.wikipedia.org/wiki/Lexical_simplification">lexical simplification</a>, a variant of <a href="https://en.wikipedia.org/wiki/Lexical_substitution">lexical substitution</a>.</abstract>
      <bibkey>abualhaija-etal-2017-metaheuristic</bibkey>
    </paper>
    <paper id="83">
      <title>Paraphrasing Revisited with <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a></title>
      <author><first>Jonathan</first><last>Mallinson</last></author>
      <author><first>Rico</first><last>Sennrich</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <pages>881–893</pages>
      <url hash="7e819361">E17-1083</url>
      <abstract>Recognizing and generating paraphrases is an important component in many <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing applications</a>. A well-established technique for automatically extracting paraphrases leverages bilingual corpora to find meaning-equivalent phrases in a single language by pivoting over a shared translation in another language. In this paper we revisit bilingual pivoting in the context of <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> and present a paraphrasing model based purely on <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a>. Our model represents <a href="https://en.wikipedia.org/wiki/Paraphrase">paraphrases</a> in a continuous space, estimates the degree of semantic relatedness between text segments of arbitrary length, and generates candidate <a href="https://en.wikipedia.org/wiki/Paraphrase">paraphrases</a> for any source input. Experimental results across tasks and datasets show that neural paraphrases outperform those obtained with conventional phrase-based pivoting approaches.</abstract>
      <bibkey>mallinson-etal-2017-paraphrasing</bibkey>
    </paper>
    <paper id="84">
      <title>Multilingual Training of Crosslingual Word Embeddings</title>
      <author><first>Long</first><last>Duong</last></author>
      <author><first>Hiroshi</first><last>Kanayama</last></author>
      <author><first>Tengfei</first><last>Ma</last></author>
      <author><first>Steven</first><last>Bird</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <pages>894–904</pages>
      <url hash="749c13f3">E17-1084</url>
      <abstract>Crosslingual word embeddings represent lexical items from different languages using the same <a href="https://en.wikipedia.org/wiki/Vector_space">vector space</a>, enabling crosslingual transfer. Most prior work constructs <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> for a pair of languages, with English on one side. We investigate methods for building high quality crosslingual word embeddings for many languages in a unified vector space. In this way, we can exploit and combine strength of many languages. We obtained high performance on bilingual lexicon induction, monolingual similarity and crosslingual document classification tasks.</abstract>
      <bibkey>duong-etal-2017-multilingual</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/panlex">Panlex</pwcdataset>
    </paper>
    <paper id="85">
      <title>Building Lexical Vector Representations from Concept Definitions</title>
      <author><first>Danilo</first><last>Silva de Carvalho</last></author>
      <author><first>Minh Le</first><last>Nguyen</last></author>
      <pages>905–915</pages>
      <url hash="c54fcb75">E17-1085</url>
      <abstract>The use of distributional language representations have opened new paths in solving a variety of NLP problems. However, alternative approaches can take advantage of information unavailable through pure <a href="https://en.wikipedia.org/wiki/Statistics">statistical means</a>. This paper presents a method for building vector representations from meaning unit blocks called concept definitions, which are obtained by extracting information from a curated linguistic resource (Wiktionary). The <a href="https://en.wikipedia.org/wiki/Representation_(mathematics)">representations</a> obtained in this way can be compared through conventional cosine similarity and are also interpretable by humans. Evaluation was conducted in semantic similarity and relatedness test sets, with results indicating a performance comparable to other methods based on single linguistic resource extraction. The results also indicate noticeable performance gains when combining distributional similarity scores with the ones obtained using this approach. Additionally, a discussion on the proposed <a href="https://en.wikipedia.org/wiki/Methodology">method</a>’s shortcomings is provided in the analysis of error cases.</abstract>
      <bibkey>silva-de-carvalho-nguyen-2017-building</bibkey>
    </paper>
    <paper id="86">
      <title>ShotgunWSD : An unsupervised algorithm for global word sense disambiguation inspired by <a href="https://en.wikipedia.org/wiki/DNA_sequencing">DNA sequencing</a><fixed-case>S</fixed-case>hotgun<fixed-case>WSD</fixed-case>: An unsupervised algorithm for global word sense disambiguation inspired by <fixed-case>DNA</fixed-case> sequencing</title>
      <author><first>Andrei</first><last>Butnaru</last></author>
      <author><first>Radu Tudor</first><last>Ionescu</last></author>
      <author><first>Florentina</first><last>Hristea</last></author>
      <pages>916–926</pages>
      <url hash="8ad8d8df">E17-1086</url>
      <abstract>In this paper, we present a novel <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised algorithm</a> for word sense disambiguation (WSD) at the document level. Our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> is inspired by a widely-used approach in the field of <a href="https://en.wikipedia.org/wiki/Genetics">genetics</a> for <a href="https://en.wikipedia.org/wiki/Whole_genome_sequencing">whole genome sequencing</a>, known as the Shotgun sequencing technique. The proposed WSD algorithm is based on three main steps. First, a brute-force WSD algorithm is applied to short context windows (up to 10 words) selected from the document in order to generate a short list of likely sense configurations for each window. In the second step, these local sense configurations are assembled into longer composite configurations based on suffix and prefix matching. The resulted configurations are ranked by their length, and the sense of each word is chosen based on a <a href="https://en.wikipedia.org/wiki/Electoral_system">voting scheme</a> that considers only the top k configurations in which the word appears. We compare our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> with other state-of-the-art unsupervised WSD algorithms and demonstrate better performance, sometimes by a very large margin. We also show that our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> can yield better performance than the Most Common Sense (MCS) baseline on one data set. Moreover, our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> has a very small number of parameters, is robust to parameter tuning, and, unlike other bio-inspired methods, it gives a deterministic solution (it does not involve random choices).</abstract>
      <bibkey>butnaru-etal-2017-shotgunwsd</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2013">SemEval 2013</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/senseval-2-1">Senseval-2</pwcdataset>
    </paper>
    <paper id="87">
      <title>LanideNN : Multilingual Language Identification on Character Window<fixed-case>L</fixed-case>anide<fixed-case>NN</fixed-case>: Multilingual Language Identification on Character Window</title>
      <author><first>Tom</first><last>Kocmi</last></author>
      <author><first>Ondřej</first><last>Bojar</last></author>
      <pages>927–936</pages>
      <url hash="a1feec36">E17-1087</url>
      <abstract>In <a href="https://en.wikipedia.org/wiki/Language_identification">language identification</a>, a common first step in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>, we want to automatically determine the language of some input text. Monolingual language identification assumes that the given document is written in one language. In multilingual language identification, the document is usually in two or three languages and we just want their names. We aim one step further and propose a method for textual language identification where languages can change arbitrarily and the goal is to identify the spans of each of the languages. Our method is based on Bidirectional Recurrent Neural Networks and it performs well in monolingual and multilingual language identification tasks on six datasets covering 131 languages. The method keeps the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> also for short documents and across domains, so it is ideal for off-the-shelf use without preparation of training data.</abstract>
      <bibkey>kocmi-bojar-2017-lanidenn</bibkey>
      <pwccode url="https://github.com/tomkocmi/LanideNN" additional="false">tomkocmi/LanideNN</pwccode>
    </paper>
    <paper id="88">
      <title>Cross-Lingual Word Embeddings for Low-Resource Language Modeling</title>
      <author><first>Oliver</first><last>Adams</last></author>
      <author><first>Adam</first><last>Makarucha</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <author><first>Steven</first><last>Bird</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <pages>937–947</pages>
      <url hash="c4c89420">E17-1088</url>
      <abstract>Most languages have no established <a href="https://en.wikipedia.org/wiki/Writing_system">writing system</a> and minimal written records. However, <a href="https://en.wikipedia.org/wiki/Textual_data">textual data</a> is essential for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>, and particularly important for training <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> to support <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech recognition</a>. Even in cases where text data is missing, there are some languages for which bilingual lexicons are available, since creating lexicons is a fundamental task of documentary linguistics. We investigate the use of such <a href="https://en.wikipedia.org/wiki/Lexicon">lexicons</a> to improve <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> when textual training data is limited to as few as a thousand sentences. The method involves learning cross-lingual word embeddings as a preliminary step in training monolingual language models. Results across a number of languages show that <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> are improved by this pre-training. Application to <a href="https://en.wikipedia.org/wiki/Yongning_Na">Yongning Na</a>, a threatened language, highlights challenges in deploying the approach in real low-resource environments.</abstract>
      <bibkey>adams-etal-2017-cross</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/panlex">Panlex</pwcdataset>
    </paper>
    <paper id="90">
      <title>Psycholinguistic Models of Sentence Processing Improve Sentence Readability Ranking</title>
      <author><first>David M.</first><last>Howcroft</last></author>
      <author><first>Vera</first><last>Demberg</last></author>
      <pages>958–968</pages>
      <url hash="854173db">E17-1090</url>
      <abstract>While previous research on <a href="https://en.wikipedia.org/wiki/Readability">readability</a> has typically focused on document-level measures, recent work in areas such as <a href="https://en.wikipedia.org/wiki/Natural-language_generation">natural language generation</a> has pointed out the need of sentence-level readability measures. Much of <a href="https://en.wikipedia.org/wiki/Psycholinguistics">psycholinguistics</a> has focused for many years on processing measures that provide difficulty estimates on a word-by-word basis. However, these psycholinguistic measures have not yet been tested on sentence readability ranking tasks. In this paper, we use four psycholinguistic measures : idea density, surprisal, integration cost, and embedding depth to test whether these features are predictive of readability levels. We find that psycholinguistic features significantly improve performance by up to 3 percentage points over a standard document-level readability metric baseline.</abstract>
      <bibkey>howcroft-demberg-2017-psycholinguistic</bibkey>
    </paper>
    <paper id="91">
      <title>Web-Scale Language-Independent Cataloging of Noisy Product Listings for E-Commerce<fixed-case>E</fixed-case>-Commerce</title>
      <author><first>Pradipto</first><last>Das</last></author>
      <author><first>Yandi</first><last>Xia</last></author>
      <author><first>Aaron</first><last>Levine</last></author>
      <author><first>Giuseppe</first><last>Di Fabbrizio</last></author>
      <author><first>Ankur</first><last>Datta</last></author>
      <pages>969–979</pages>
      <url hash="f2a2e944">E17-1091</url>
      <abstract>The cataloging of product listings through <a href="https://en.wikipedia.org/wiki/Taxonomy_(general)">taxonomy categorization</a> is a fundamental problem for any <a href="https://en.wikipedia.org/wiki/E-commerce">e-commerce marketplace</a>, with applications ranging from personalized search recommendations to <a href="https://en.wikipedia.org/wiki/Query_understanding">query understanding</a>. However, manual and rule based approaches to <a href="https://en.wikipedia.org/wiki/Categorization">categorization</a> are not scalable. In this paper, we compare several <a href="https://en.wikipedia.org/wiki/Classifier_(linguistics)">classifiers</a> for categorizing listings in both English and Japanese product catalogs. We show empirically that a combination of words from product titles, navigational breadcrumbs, and <a href="https://en.wikipedia.org/wiki/List_price">list prices</a>, when available, improves results significantly. We outline a novel method using correspondence topic models and a lightweight manual process to reduce <a href="https://en.wikipedia.org/wiki/Noise_(signal_processing)">noise</a> from mis-labeled data in the training set. We contrast linear models, gradient boosted trees (GBTs) and convolutional neural networks (CNNs), and show that GBTs and CNNs yield the highest gains in error reduction. Finally, we show GBTs applied in a language-agnostic way on a large-scale Japanese e-commerce dataset have improved <a href="https://en.wikipedia.org/wiki/Taxonomy_(general)">taxonomy categorization</a> performance over current <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a> based on deep belief network models.</abstract>
      <bibkey>das-etal-2017-web</bibkey>
    </paper>
    <paper id="92">
      <title>Recognizing Insufficiently Supported Arguments in Argumentative Essays</title>
      <author><first>Christian</first><last>Stab</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>980–990</pages>
      <url hash="8da794c8">E17-1092</url>
      <abstract>In this paper, we propose a new <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> for assessing the quality of <a href="https://en.wikipedia.org/wiki/Argument_(linguistics)">natural language arguments</a>. The premises of a well-reasoned argument should provide enough evidence for accepting or rejecting its claim. Although this criterion, known as <a href="https://en.wikipedia.org/wiki/Necessity_and_sufficiency">sufficiency</a>, is widely adopted in <a href="https://en.wikipedia.org/wiki/Argumentation_theory">argumentation theory</a>, there are no empirical studies on its applicability to real arguments. In this work, we show that human annotators substantially agree on the sufficiency criterion and introduce a novel annotated corpus. Furthermore, we experiment with feature-rich SVMs and <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Networks</a> and achieve 84 % accuracy for automatically identifying insufficiently supported arguments. The final <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> as well as the annotation guideline are freely available for encouraging future research on argument quality.</abstract>
      <bibkey>stab-gurevych-2017-recognizing</bibkey>
    </paper>
    <paper id="93">
      <title>Distributed Document and Phrase Co-embeddings for Descriptive Clustering</title>
      <author><first>Motoki</first><last>Sato</last></author>
      <author><first>Austin J.</first><last>Brockmeier</last></author>
      <author><first>Georgios</first><last>Kontonatsios</last></author>
      <author><first>Tingting</first><last>Mu</last></author>
      <author><first>John Y.</first><last>Goulermas</last></author>
      <author><first>Jun’ichi</first><last>Tsujii</last></author>
      <author><first>Sophia</first><last>Ananiadou</last></author>
      <pages>991–1001</pages>
      <url hash="662b298b">E17-1093</url>
      <abstract>Descriptive document clustering aims to automatically discover groups of semantically related documents and to assign a meaningful label to characterise the content of each cluster. In this paper, we present a descriptive clustering approach that employs a distributed representation model, namely the paragraph vector model, to capture semantic similarities between documents and phrases. The proposed method uses a joint representation of phrases and documents (i.e., a co-embedding) to automatically select a <a href="https://en.wikipedia.org/wiki/Linguistic_description">descriptive phrase</a> that best represents each document cluster. We evaluate our method by comparing its performance to an existing state-of-the-art descriptive clustering method that also uses co-embedding but relies on a bag-of-words representation. Results obtained on benchmark datasets demonstrate that the paragraph vector-based method obtains superior performance over the existing approach in both identifying clusters and assigning appropriate descriptive labels to them.</abstract>
      <bibkey>sato-etal-2017-distributed</bibkey>
    </paper>
    <paper id="94">
      <title>SMARTies : Sentiment Models for Arabic Target entities<fixed-case>SMART</fixed-case>ies: Sentiment Models for <fixed-case>A</fixed-case>rabic Target entities</title>
      <author><first>Noura</first><last>Farra</last></author>
      <author><first>Kathy</first><last>McKeown</last></author>
      <pages>1002–1013</pages>
      <url hash="5d10f530">E17-1094</url>
      <abstract>We consider entity-level sentiment analysis in <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a>, a morphologically rich language with increasing resources. We present a <a href="https://en.wikipedia.org/wiki/System">system</a> that is applied to complex posts written in response to Arabic newspaper articles. Our goal is to identify important entity targets within the post along with the polarity expressed about each target. We achieve significant improvements over multiple baselines, demonstrating that the use of specific morphological representations improves the performance of identifying both important targets and their sentiment, and that the use of distributional semantic clusters further boosts performances for these representations, especially when richer linguistic resources are not available.</abstract>
      <bibkey>farra-mckeown-2017-smarties</bibkey>
    </paper>
    <paper id="95">
      <title>Exploring <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Networks</a> for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> of Spanish tweets<fixed-case>S</fixed-case>panish tweets</title>
      <author><first>Isabel</first><last>Segura-Bedmar</last></author>
      <author><first>Antonio</first><last>Quirós</last></author>
      <author><first>Paloma</first><last>Martínez</last></author>
      <pages>1014–1022</pages>
      <url hash="8a138394">E17-1095</url>
      <abstract>Spanish is the third-most used language on the internet, after <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a>, with a total of 7.7 % (more than 277 million of users) and a huge internet growth of more than 1,400 %. However, most work on <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> has been focused on <a href="https://en.wikipedia.org/wiki/English_language">English</a>. This paper describes a deep learning system for Spanish sentiment analysis. To the best of our knowledge, this is the first work that explores the use of a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a> to polarity classification of Spanish tweets.</abstract>
      <bibkey>segura-bedmar-etal-2017-exploring</bibkey>
    </paper>
    <paper id="96">
      <title>Contextual Bidirectional Long Short-Term Memory Recurrent Neural Network Language Models : A Generative Approach to Sentiment Analysis</title>
      <author><first>Amr</first><last>Mousa</last></author>
      <author><first>Björn</first><last>Schuller</last></author>
      <pages>1023–1032</pages>
      <url hash="2b8e170b">E17-1096</url>
      <abstract>Traditional learning-based approaches to <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> of written text use the concept of bag-of-words or bag-of-n-grams, where a document is viewed as a set of terms or short combinations of terms disregarding grammar rules or <a href="https://en.wikipedia.org/wiki/Word_order">word order</a>. Novel approaches de-emphasize this concept and view the <a href="https://en.wikipedia.org/wiki/Problem_solving">problem</a> as a sequence classification problem. In this context, <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural networks (RNNs)</a> have achieved significant success. The idea is to use RNNs as discriminative binary classifiers to predict a positive or negative sentiment label at every word position then perform a type of pooling to get a sentence-level polarity. Here, we investigate a novel generative approach in which a separate <a href="https://en.wikipedia.org/wiki/Probability_distribution">probability distribution</a> is estimated for every sentiment using language models (LMs) based on long short-term memory (LSTM) RNNs. We introduce a novel type of LM using a modified version of bidirectional LSTM (BLSTM) called contextual BLSTM (cBLSTM), where the probability of a word is estimated based on its full left and right contexts. Our approach is compared with a BLSTM binary classifier. Significant improvements are observed in classifying the IMDB movie review dataset. Further improvements are achieved via model combination.</abstract>
      <bibkey>mousa-schuller-2017-contextual</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="97">
      <title>Large-scale Opinion Relation Extraction with Distantly Supervised Neural Network</title>
      <author><first>Changzhi</first><last>Sun</last></author>
      <author><first>Yuanbin</first><last>Wu</last></author>
      <author><first>Man</first><last>Lan</last></author>
      <author><first>Shiliang</first><last>Sun</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <pages>1033–1043</pages>
      <url hash="8781c3ba">E17-1097</url>
      <abstract>We investigate the task of open domain opinion relation extraction. Different from works on manually labeled corpus, we propose an efficient distantly supervised framework based on <a href="https://en.wikipedia.org/wiki/Pattern_matching">pattern matching</a> and neural network classifiers. The <a href="https://en.wikipedia.org/wiki/Pattern_recognition">patterns</a> are designed to automatically generate training data, and the <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning model</a> is design to capture various lexical and syntactic features. The result <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> is fast and scalable on large-scale corpus. We test the <a href="https://en.wikipedia.org/wiki/System">system</a> on the <a href="https://en.wikipedia.org/wiki/Amazon_(company)">Amazon online review dataset</a>. The result shows that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is able to achieve promising performances without any human annotations.</abstract>
      <bibkey>sun-etal-2017-large</bibkey>
    </paper>
    <paper id="98">
      <title>Decoding with <a href="https://en.wikipedia.org/wiki/Finite-state_transducer">Finite-State Transducers</a> on GPUs<fixed-case>GPU</fixed-case>s</title>
      <author><first>Arturo</first><last>Argueta</last></author>
      <author><first>David</first><last>Chiang</last></author>
      <pages>1044–1052</pages>
      <url hash="345e451f">E17-1098</url>
      <abstract>Weighted finite automata and transducers (including hidden Markov models and conditional random fields) are widely used in natural language processing (NLP) to perform tasks such as morphological analysis, <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech tagging</a>, chunking, <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>, <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech recognition</a>, and others. Parallelizing finite state algorithms on graphics processing units (GPUs) would benefit many areas of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>. Although researchers have implemented GPU versions of basic graph algorithms, no work, to our knowledge, has been done on GPU algorithms for weighted finite automata. We introduce a GPU implementation of the Viterbi and forward-backward algorithm, achieving speedups of up to 4x over our serial implementations running on different computer architectures and 3335x over widely used tools such as OpenFST.</abstract>
      <bibkey>argueta-chiang-2017-decoding</bibkey>
    </paper>
    <paper id="100">
      <title>A Multifaceted Evaluation of Neural versus Phrase-Based Machine Translation for 9 Language Directions</title>
      <author><first>Antonio</first><last>Toral</last></author>
      <author><first>Víctor M.</first><last>Sánchez-Cartagena</last></author>
      <pages>1063–1073</pages>
      <url hash="de089a13">E17-1100</url>
      <abstract>We aim to shed light on the strengths and weaknesses of the newly introduced neural machine translation paradigm. To that end, we conduct a multifaceted evaluation in which we compare outputs produced by state-of-the-art <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> and phrase-based machine translation systems for 9 language directions across a number of dimensions. Specifically, we measure the similarity of the outputs, their fluency and amount of reordering, the effect of <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentence length</a> and performance across different error categories. We find out that translations produced by neural machine translation systems are considerably different, more fluent and more accurate in terms of <a href="https://en.wikipedia.org/wiki/Word_order">word order</a> compared to those produced by phrase-based systems. Neural machine translation systems are also more accurate at producing inflected forms, but they perform poorly when translating very long sentences.</abstract>
      <bibkey>toral-sanchez-cartagena-2017-multifaceted</bibkey>
      <pwccode url="https://github.com/antot/neural_vs_-phrasebased_smt_eacl17" additional="false">antot/neural_vs_-phrasebased_smt_eacl17</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2016">WMT 2016</pwcdataset>
    </paper>
    <paper id="101">
      <title>Personalized Machine Translation : Preserving Original Author Traits</title>
      <author><first>Ella</first><last>Rabinovich</last></author>
      <author><first>Raj Nath</first><last>Patel</last></author>
      <author><first>Shachar</first><last>Mirkin</last></author>
      <author><first>Lucia</first><last>Specia</last></author>
      <author><first>Shuly</first><last>Wintner</last></author>
      <pages>1074–1084</pages>
      <url hash="1930aabc">E17-1101</url>
      <abstract>The language that we produce reflects our personality, and various personal and demographic characteristics can be detected in natural language texts. We focus on one particular <a href="https://en.wikipedia.org/wiki/Trait_theory">personal trait</a> of the author, <a href="https://en.wikipedia.org/wiki/Gender">gender</a>, and study how it is manifested in original texts and in <a href="https://en.wikipedia.org/wiki/Translation">translations</a>. We show that author’s gender has a powerful, clear signal in originals texts, but this <a href="https://en.wikipedia.org/wiki/Signal_(IPC)">signal</a> is obfuscated in <a href="https://en.wikipedia.org/wiki/Translation">human and machine translation</a>. We then propose simple domain-adaptation techniques that help retain the original gender traits in the <a href="https://en.wikipedia.org/wiki/Translation_(biology)">translation</a>, without harming the quality of the <a href="https://en.wikipedia.org/wiki/Translation_(biology)">translation</a>, thereby creating more personalized machine translation systems.</abstract>
      <attachment type="presentation" hash="2aae1ad2">E17-1101.Presentation.pdf</attachment>
      <bibkey>rabinovich-etal-2017-personalized</bibkey>
    </paper>
    <paper id="103">
      <title>Grouping business news stories based on salience of named entities</title>
      <author><first>Llorenç</first><last>Escoter</last></author>
      <author><first>Lidia</first><last>Pivovarova</last></author>
      <author><first>Mian</first><last>Du</last></author>
      <author><first>Anisia</first><last>Katinskaia</last></author>
      <author><first>Roman</first><last>Yangarber</last></author>
      <pages>1096–1106</pages>
      <url hash="fc293ee7">E17-1103</url>
      <abstract>In <a href="https://en.wikipedia.org/wiki/News_aggregator">news aggregation systems</a> focused on broad news domains, certain stories may appear in multiple articles. Depending on the relative importance of the story, the number of versions can reach dozens or hundreds within a day. The text in these versions may be nearly identical or quite different. Linking multiple versions of a story into a single group brings several important benefits to the end-userreducing the cognitive load on the reader, as well as signaling the relative importance of the story. We present a grouping algorithm, and explore several vector-based representations of input documents : from a baseline using keywords, to a method using saliencea measure of importance of named entities in the text. We demonstrate that <a href="https://en.wikipedia.org/wiki/Software_feature">features</a> beyond <a href="https://en.wikipedia.org/wiki/Index_term">keywords</a> yield substantial improvements, verified on a manually-annotated corpus of business news stories.</abstract>
      <bibkey>escoter-etal-2017-grouping</bibkey>
    </paper>
    <paper id="104">
      <title>Very Deep Convolutional Networks for Text Classification</title>
      <author><first>Alexis</first><last>Conneau</last></author>
      <author><first>Holger</first><last>Schwenk</last></author>
      <author><first>Loïc</first><last>Barrault</last></author>
      <author><first>Yann</first><last>Lecun</last></author>
      <pages>1107–1116</pages>
      <url hash="12484645">E17-1104</url>
      <abstract>The dominant approach for many NLP tasks are <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural networks</a>, in particular LSTMs, and <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural networks</a>. However, these <a href="https://en.wikipedia.org/wiki/Computer_architecture">architectures</a> are rather shallow in comparison to the deep convolutional networks which have pushed the state-of-the-art in <a href="https://en.wikipedia.org/wiki/Computer_vision">computer vision</a>. We present a new architecture (VDCNN) for text processing which operates directly at the character level and uses only small convolutions and pooling operations. We are able to show that the performance of this model increases with the depth : using up to 29 convolutional layers, we report improvements over the <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a> on several public text classification tasks. To the best of our knowledge, this is the first time that very deep convolutional nets have been applied to <a href="https://en.wikipedia.org/wiki/Text_processing">text processing</a>.</abstract>
      <bibkey>conneau-etal-2017-deep</bibkey>
      <pwccode url="" additional="true" />
      <pwcdataset url="https://paperswithcode.com/dataset/ag-news">AG News</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/dbpedia">DBpedia</pwcdataset>
    </paper>
    <paper id="105">
      <title>PageRank for Argument Relevance<fixed-case>P</fixed-case>age<fixed-case>R</fixed-case>ank” for Argument Relevance</title>
      <author><first>Henning</first><last>Wachsmuth</last></author>
      <author><first>Benno</first><last>Stein</last></author>
      <author><first>Yamen</first><last>Ajjour</last></author>
      <pages>1117–1127</pages>
      <url hash="69dd1d67">E17-1105</url>
      <abstract>Future <a href="https://en.wikipedia.org/wiki/Web_search_engine">search engines</a> are expected to deliver pro and con arguments in response to queries on controversial topics. While <a href="https://en.wikipedia.org/wiki/Argument_mining">argument mining</a> is now in the focus of research, the question of how to retrieve the relevant arguments remains open. This paper proposes a radical model to assess <a href="https://en.wikipedia.org/wiki/Relevance">relevance</a> objectively at web scale : the <a href="https://en.wikipedia.org/wiki/Relevance">relevance</a> of an argument’s conclusion is decided by what other arguments reuse it as a premise. We build an argument graph for this <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> that we analyze with a recursive weighting scheme, adapting key ideas of <a href="https://en.wikipedia.org/wiki/PageRank">PageRank</a>. In experiments on a large ground-truth argument graph, the resulting relevance scores correlate with human average judgments. We outline what natural language challenges must be faced at <a href="https://en.wikipedia.org/wiki/Scalability">web scale</a> in order to stepwise bring argument relevance to <a href="https://en.wikipedia.org/wiki/Web_search_engine">web search engines</a>.</abstract>
      <bibkey>wachsmuth-etal-2017-pagerank</bibkey>
    </paper>
    <paper id="106">
      <title>Predicting Counselor Behaviors in Motivational Interviewing Encounters</title>
      <author><first>Verónica</first><last>Pérez-Rosas</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <author><first>Kenneth</first><last>Resnicow</last></author>
      <author><first>Satinder</first><last>Singh</last></author>
      <author><first>Lawrence</first><last>An</last></author>
      <author><first>Kathy J.</first><last>Goggin</last></author>
      <author><first>Delwyn</first><last>Catley</last></author>
      <pages>1128–1137</pages>
      <url hash="f78d3125">E17-1106</url>
      <abstract>As the number of people receiving psycho-therapeutic treatment increases, the automatic evaluation of counseling practice arises as an important challenge in the clinical domain. In this paper, we address the automatic evaluation of counseling performance by analyzing counselors’ language during their interaction with clients. In particular, we present a model towards the automation of Motivational Interviewing (MI) coding, which is the current gold standard to evaluate MI counseling. First, we build a dataset of hand labeled MI encounters ; second, we use text-based methods to extract and analyze linguistic patterns associated with counselor behaviors ; and third, we develop an automatic system to predict these behaviors. We introduce a new set of <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> based on <a href="https://en.wikipedia.org/wiki/Semantics">semantic information</a> and <a href="https://en.wikipedia.org/wiki/Syntax">syntactic patterns</a>, and show that they lead to accuracy figures of up to 90 %, which represent a significant improvement with respect to <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> used in the past.</abstract>
      <bibkey>perez-rosas-etal-2017-predicting</bibkey>
    </paper>
    <paper id="107">
      <title>Authorship Attribution Using Text Distortion</title>
      <author><first>Efstathios</first><last>Stamatatos</last></author>
      <pages>1138–1149</pages>
      <url hash="6cedf6ed">E17-1107</url>
      <abstract>Authorship attribution is associated with important applications in <a href="https://en.wikipedia.org/wiki/Forensic_science">forensics</a> and humanities research. A crucial point in this field is to quantify the personal style of writing, ideally in a way that is not affected by changes in topic or genre. In this paper, we present a novel method that enhances <a href="https://en.wikipedia.org/wiki/Attribution_(psychology)">authorship attribution</a> effectiveness by introducing a text distortion step before extracting <a href="https://en.wikipedia.org/wiki/Stylometry">stylometric measures</a>. The proposed method attempts to mask topic-specific information that is not related to the personal style of authors. Based on experiments on two main tasks in <a href="https://en.wikipedia.org/wiki/Attribution_(psychology)">authorship attribution</a>, <a href="https://en.wikipedia.org/wiki/Attribution_(psychology)">closed-set attribution</a> and <a href="https://en.wikipedia.org/wiki/Attribution_(psychology)">authorship verification</a>, we demonstrate that the proposed approach can enhance existing methods especially under cross-topic conditions, where the training and test corpora do not match in topic.</abstract>
      <bibkey>stamatatos-2017-authorship</bibkey>
    </paper>
    <paper id="108">
      <title>Structured Learning for Temporal Relation Extraction from Clinical Records</title>
      <author><first>Artuur</first><last>Leeuwenberg</last></author>
      <author><first>Marie-Francine</first><last>Moens</last></author>
      <pages>1150–1158</pages>
      <url hash="b5d807cf">E17-1108</url>
      <abstract>We propose a scalable structured learning model that jointly predicts temporal relations between events and temporal expressions (TLINKS), and the relation between these <a href="https://en.wikipedia.org/wiki/Event_(philosophy)">events</a> and the document creation time (DCTR). We employ a structured perceptron, together with integer linear programming constraints for document-level inference during training and prediction to exploit relational properties of temporality, together with global learning of the relations at the document level. Moreover, this study gives insights in the results of integrating constraints for temporal relation extraction when using structured learning and prediction. Our best system outperforms the <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the art</a> on both the CONTAINS TLINK task, and the DCTR task.</abstract>
      <bibkey>leeuwenberg-moens-2017-structured</bibkey>
      <pwccode url="https://github.com/tuur/SPTempRels" additional="false">tuur/SPTempRels</pwccode>
    </paper>
    <paper id="109">
      <title>Entity Extraction in Biomedical Corpora : An Approach to Evaluate Word Embedding Features with PSO based Feature Selection<fixed-case>PSO</fixed-case> based Feature Selection</title>
      <author><first>Shweta</first><last>Yadav</last></author>
      <author><first>Asif</first><last>Ekbal</last></author>
      <author><first>Sriparna</first><last>Saha</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>1159–1170</pages>
      <url hash="180339e4">E17-1109</url>
      <abstract>Text mining has drawn significant attention in recent past due to the rapid growth in biomedical and clinical records. Entity extraction is one of the fundamental components for <a href="https://en.wikipedia.org/wiki/Biomedical_text_mining">biomedical text mining</a>. In this paper, we propose a novel approach of <a href="https://en.wikipedia.org/wiki/Feature_selection">feature selection</a> for <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity extraction</a> that exploits the concept of <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> and Particle Swarm Optimization (PSO). The system utilizes word embedding features along with several other <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> extracted by studying the properties of the <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a>. We obtain an interesting observation that compact word embedding features as determined by PSO are more effective compared to the entire word embedding feature set for entity extraction. The proposed system is evaluated on three benchmark biomedical datasets such as GENIA, GENETAG, and AiMed. The effectiveness of the proposed approach is evident with significant performance gains over the baseline models as well as the other existing systems. We observe improvements of 7.86 %, 5.27 % and 7.25 % <a href="https://en.wikipedia.org/wiki/F-measure">F-measure</a> points over the baseline models for GENIA, GENETAG, and AiMed dataset respectively.</abstract>
      <bibkey>yadav-etal-2017-entity</bibkey>
    </paper>
    <paper id="110">
      <title>Distant Supervision for Relation Extraction beyond the Sentence Boundary</title>
      <author><first>Chris</first><last>Quirk</last></author>
      <author><first>Hoifung</first><last>Poon</last></author>
      <pages>1171–1182</pages>
      <url hash="f9024ad9">E17-1110</url>
      <abstract>The growing demand for structured knowledge has led to great interest in <a href="https://en.wikipedia.org/wiki/Relation_extraction">relation extraction</a>, especially in cases with limited supervision. However, existing distance supervision approaches only extract <a href="https://en.wikipedia.org/wiki/Binary_relation">relations</a> expressed in single sentences. In general, cross-sentence relation extraction is under-explored, even in the supervised-learning setting. In this paper, we propose the first approach for applying distant supervision to cross-sentence relation extraction. At the core of our approach is a <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph representation</a> that can incorporate both standard dependencies and <a href="https://en.wikipedia.org/wiki/Discourse_analysis">discourse relations</a>, thus providing a unifying way to model <a href="https://en.wikipedia.org/wiki/Binary_relation">relations</a> within and across sentences. We extract features from multiple paths in this <a href="https://en.wikipedia.org/wiki/Graph_of_a_function">graph</a>, increasing <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and robustness when confronted with <a href="https://en.wikipedia.org/wiki/Variation_(linguistics)">linguistic variation</a> and analysis error. Experiments on an important extraction task for <a href="https://en.wikipedia.org/wiki/Precision_medicine">precision medicine</a> show that our approach can learn an accurate cross-sentence extractor, using only a small existing <a href="https://en.wikipedia.org/wiki/Knowledge_base">knowledge base</a> and unlabeled text from biomedical research articles. Compared to the existing distant supervision paradigm, our approach extracted twice as many relations at similar precision, thus demonstrating the prevalence of cross-sentence relations and the promise of our approach.</abstract>
      <bibkey>quirk-poon-2017-distant</bibkey>
    </paper>
    <paper id="111">
      <title>Noise Mitigation for Neural Entity Typing and <a href="https://en.wikipedia.org/wiki/Relation_extraction">Relation Extraction</a></title>
      <author><first>Yadollah</first><last>Yaghoobzadeh</last></author>
      <author><first>Heike</first><last>Adel</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>1183–1194</pages>
      <url hash="d91e363c">E17-1111</url>
      <abstract>In this paper, we address two different types of <a href="https://en.wikipedia.org/wiki/Noise_(signal_processing)">noise</a> in information extraction models : noise from distant supervision and noise from pipeline input features. Our target tasks are <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity typing</a> and <a href="https://en.wikipedia.org/wiki/Relation_(database)">relation extraction</a>. For the first noise type, we introduce multi-instance multi-label learning algorithms using neural network models, and apply them to fine-grained entity typing for the first time. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms the state-of-the-art supervised approach which uses global embeddings of entities. For the second noise type, we propose ways to improve the integration of noisy entity type predictions into <a href="https://en.wikipedia.org/wiki/Relation_extraction">relation extraction</a>. Our experiments show that probabilistic predictions are more robust than discrete predictions and that joint training of the two tasks performs best.</abstract>
      <bibkey>yaghoobzadeh-etal-2017-noise</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/figer">FIGER</pwcdataset>
    </paper>
    <paper id="113">
      <title>Using support vector machines and state-of-the-art <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> for <a href="https://en.wikipedia.org/wiki/Phonetic_transcription">phonetic alignment</a> to identify cognates in multi-lingual wordlists</title>
      <author><first>Gerhard</first><last>Jäger</last></author>
      <author><first>Johann-Mattis</first><last>List</last></author>
      <author><first>Pavel</first><last>Sofroniev</last></author>
      <pages>1205–1216</pages>
      <url hash="1797d28d">E17-1113</url>
      <abstract>Most current approaches in phylogenetic linguistics require as input multilingual word lists partitioned into sets of etymologically related words (cognates). Cognate identification is so far done manually by experts, which is time consuming and as of yet only available for a small number of well-studied language families. Automatizing this step will greatly expand the empirical scope of phylogenetic methods in <a href="https://en.wikipedia.org/wiki/Linguistics">linguistics</a>, as raw wordlists (in phonetic transcription) are much easier to obtain than wordlists in which cognate words have been fully identified and annotated, even for under-studied languages. A couple of different <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> have been proposed in the past, but they are either disappointing regarding their performance or not applicable to larger datasets. Here we present a new approach that uses support vector machines to unify different state-of-the-art methods for <a href="https://en.wikipedia.org/wiki/Phonetic_transcription">phonetic alignment</a> and cognate detection within a single framework. Training and evaluating these method on a typologically broad collection of gold-standard data shows it to be superior to the existing state of the art.</abstract>
      <bibkey>jager-etal-2017-using</bibkey>
    </paper>
    <paper id="114">
      <title>A Multi-task Approach to Predict Likability of Books</title>
      <author><first>Suraj</first><last>Maharjan</last></author>
      <author><first>John</first><last>Arevalo</last></author>
      <author><first>Manuel</first><last>Montes</last></author>
      <author><first>Fabio A.</first><last>González</last></author>
      <author><first>Thamar</first><last>Solorio</last></author>
      <pages>1217–1227</pages>
      <url hash="ffe9394f">E17-1114</url>
      <abstract>We investigate the value of <a href="https://en.wikipedia.org/wiki/Feature_engineering">feature engineering</a> and <a href="https://en.wikipedia.org/wiki/Neural_network">neural network models</a> for predicting successful writing. Similar to previous work, we treat this as a binary classification task and explore new strategies to automatically learn representations from book contents. We evaluate our <a href="https://en.wikipedia.org/wiki/Software_feature">feature set</a> on two different <a href="https://en.wikipedia.org/wiki/Text_corpus">corpora</a> created from Project Gutenberg books. The first presents a novel approach for generating the gold standard labels for the task and the <a href="https://en.wikipedia.org/wiki/Other_(philosophy)">other</a> is based on prior research. Using a combination of hand-crafted and recurrent neural network learned representations in a dual learning setting, we obtain the best performance of 73.50 % weighted F1-score.</abstract>
      <bibkey>maharjan-etal-2017-multi</bibkey>
    </paper>
    <paper id="115">
      <title>A Data-Oriented Model of Literary Language</title>
      <author><first>Andreas</first><last>van Cranenburgh</last></author>
      <author><first>Rens</first><last>Bod</last></author>
      <pages>1228–1238</pages>
      <url hash="682e7f1f">E17-1115</url>
      <abstract>We consider the task of predicting how literary a text is, with a gold standard from human ratings. Aside from a standard bigram baseline, we apply rich syntactic tree fragments, mined from the training set, and a series of hand-picked features. Our model is the first to distinguish degrees of highly and less literary novels using a variety of <a href="https://en.wikipedia.org/wiki/Lexicon">lexical and syntactic features</a>, and explains 76.0 % of the variation in literary ratings.</abstract>
      <bibkey>van-cranenburgh-bod-2017-data</bibkey>
    </paper>
    <paper id="116">
      <title>Aye or naw, whit dae ye hink? <a href="https://en.wikipedia.org/wiki/Scottish_independence">Scottish independence</a> and linguistic identity on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a><fixed-case>S</fixed-case>cottish independence and linguistic identity on social media</title>
      <author><first>Philippa</first><last>Shoemark</last></author>
      <author><first>Debnil</first><last>Sur</last></author>
      <author><first>Luke</first><last>Shrimpton</last></author>
      <author><first>Iain</first><last>Murray</last></author>
      <author><first>Sharon</first><last>Goldwater</last></author>
      <pages>1239–1248</pages>
      <url hash="30f63e7f">E17-1116</url>
      <abstract>Political surveys have indicated a relationship between a sense of Scottish identity and voting decisions in the 2014 <a href="https://en.wikipedia.org/wiki/2014_Scottish_independence_referendum">Scottish Independence Referendum</a>. Identity is often reflected in language use, suggesting the intuitive hypothesis that individuals who support <a href="https://en.wikipedia.org/wiki/Scottish_independence">Scottish independence</a> are more likely to use distinctively Scottish words than those who oppose it. In the first large-scale study of sociolinguistic variation on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> in the UK, we identify distinctively Scottish terms in a data-driven way, and find that these <a href="https://en.wikipedia.org/wiki/Terminology">terms</a> are indeed used at a higher rate by users of pro-independence hashtags than by users of anti-independence hashtags. However, we also find that in general people are less likely to use distinctively Scottish words in tweets with referendum-related hashtags than in their general Twitter activity. We attribute this difference to style shifting relative to audience, aligning with previous work showing that Twitter users tend to use fewer local variants when addressing a broader audience.</abstract>
      <bibkey>shoemark-etal-2017-aye</bibkey>
    </paper>
    <paper id="118">
      <title>Incremental Discontinuous Phrase Structure Parsing with the GAP Transition<fixed-case>GAP</fixed-case> Transition</title>
      <author><first>Maximin</first><last>Coavoux</last></author>
      <author><first>Benoît</first><last>Crabbé</last></author>
      <pages>1259–1270</pages>
      <url hash="e5679dd8">E17-1118</url>
      <abstract>This article introduces a novel transition system for discontinuous lexicalized constituent parsing called SR-GAP. It is an extension of the shift-reduce algorithm with an additional gap transition. Evaluation on two German treebanks shows that SR-GAP outperforms the previous best transition-based discontinuous parser (Maier, 2015) by a large margin (it is notably twice as accurate on the prediction of discontinuous constituents), and is competitive with the state of the art (Fernndez-Gonzlez and Martins, 2015). As a side contribution, we adapt span features (Hall et al., 2014) to discontinuous parsing.</abstract>
      <bibkey>coavoux-crabbe-2017-incremental</bibkey>
      <pwccode url="https://github.com/mcoavoux/mtg" additional="false">mcoavoux/mtg</pwccode>
    </paper>
    <paper id="119">
      <title>Neural Architectures for Fine-grained Entity Type Classification</title>
      <author><first>Sonse</first><last>Shimaoka</last></author>
      <author><first>Pontus</first><last>Stenetorp</last></author>
      <author><first>Kentaro</first><last>Inui</last></author>
      <author><first>Sebastian</first><last>Riedel</last></author>
      <pages>1271–1280</pages>
      <url hash="a446c065">E17-1119</url>
      <abstract>In this work, we investigate several neural network architectures for fine-grained entity type classification and make three key contributions. Despite being a natural comparison and addition, previous work on attentive neural architectures have not considered hand-crafted features and we combine these with learnt features and establish that they complement each other. Additionally, through quantitative analysis we establish that the <a href="https://en.wikipedia.org/wiki/Attentional_control">attention mechanism</a> learns to attend over syntactic heads and the phrase containing the mention, both of which are known to be strong hand-crafted features for our task. We introduce parameter sharing between labels through a hierarchical encoding method, that in low-dimensional projections show clear clusters for each type hierarchy. Lastly, despite using the same evaluation dataset, the literature frequently compare <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> trained using different data. We demonstrate that the choice of training data has a drastic impact on performance, which decreases by as much as 9.85 % loose micro F1 score for a previously proposed method. Despite this discrepancy, our best model achieves state-of-the-art results with 75.36 % loose micro F1 score on the well-established Figer (GOLD) dataset and we report the best results for models trained using publicly available data for the OntoNotes dataset with 64.93 % loose micro F1 score.</abstract>
      <bibkey>shimaoka-etal-2017-neural</bibkey>
      <pwccode url="https://github.com/shimaokasonse/NFGEC" additional="false">shimaokasonse/NFGEC</pwccode>
    </paper>
  </volume>
  <volume id="2">
    <meta>
      <booktitle>Proceedings of the 15th Conference of the <fixed-case>E</fixed-case>uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</booktitle>
      <url hash="aa8810b7">E17-2</url>
      <editor><first>Mirella</first><last>Lapata</last></editor>
      <editor><first>Phil</first><last>Blunsom</last></editor>
      <editor><first>Alexander</first><last>Koller</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="9e41232c">E17-2000</url>
      <bibkey>eacl-2017-european-chapter</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Multilingual Back-and-Forth Conversion between Content and Function Head for Easy Dependency Parsing</title>
      <author><first>Ryosuke</first><last>Kohita</last></author>
      <author><first>Hiroshi</first><last>Noji</last></author>
      <author><first>Yuji</first><last>Matsumoto</last></author>
      <pages>1–7</pages>
      <url hash="6d54bba4">E17-2001</url>
      <abstract>Universal Dependencies (UD) is becoming a standard annotation scheme cross-linguistically, but it is argued that this scheme centering on content words is harder to parse than the conventional one centering on function words. To improve the <a href="https://en.wikipedia.org/wiki/Parsing">parsability</a> of UD, we propose a back-and-forth conversion algorithm, in which we preprocess the training treebank to increase <a href="https://en.wikipedia.org/wiki/Parsing">parsability</a>, and reconvert the parser outputs to follow the UD scheme as a postprocess. We show that this technique consistently improves <a href="https://en.wikipedia.org/wiki/Lisp_(programming_language)">LAS</a> across languages even with a state-of-the-art <a href="https://en.wikipedia.org/wiki/Parsing">parser</a>, in particular on core dependency arcs such as nominal modifier. We also provide an in-depth analysis to understand why our <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">method</a> increases <a href="https://en.wikipedia.org/wiki/Parsing">parsability</a>.</abstract>
      <bibkey>kohita-etal-2017-multilingual</bibkey>
      <pwccode url="https://github.com/kohilin/MultiBFConv" additional="false">kohilin/MultiBFConv</pwccode>
    </paper>
    <paper id="5">
      <title>Using Twitter Language to Predict the Real Estate Market<fixed-case>T</fixed-case>witter Language to Predict the Real Estate Market</title>
      <author><first>Mohammadzaman</first><last>Zamani</last></author>
      <author><first>H. Andrew</first><last>Schwartz</last></author>
      <pages>28–33</pages>
      <url hash="5730cc74">E17-2005</url>
      <abstract>We explore whether <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> can provide a window into community real estate -foreclosure rates and price changes- beyond that of traditional economic and demographic variables. We find language use in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> not only predicts real estate outcomes as well as traditional variables across counties, but that including <a href="https://en.wikipedia.org/wiki/Twitter">Twitter language</a> in traditional models leads to a significant improvement (e.g. from Pearson r = : 50 to r = : 59 for price changes). We overcome the challenge of the relative sparsity and noise in Twitter language variables by showing that training on the <a href="https://en.wikipedia.org/wiki/Errors_and_residuals">residual error</a> of the traditional <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> leads to more accurate overall assessments. Finally, we discover that it is <a href="https://en.wikipedia.org/wiki/List_of_Latin-script_digraphs">Twitter language</a> related to business (e.g. ‘company’, ‘marketing’) and <a href="https://en.wikipedia.org/wiki/Technology">technology</a> (e.g. ‘technology’, ‘internet’), among others, that yield predictive power over <a href="https://en.wikipedia.org/wiki/Economics">economics</a>.</abstract>
      <bibkey>zamani-schwartz-2017-using</bibkey>
    </paper>
    <paper id="6">
      <title>Lexical Simplification with Neural Ranking</title>
      <author><first>Gustavo</first><last>Paetzold</last></author>
      <author><first>Lucia</first><last>Specia</last></author>
      <pages>34–40</pages>
      <url hash="8c2e55aa">E17-2006</url>
      <abstract>We present a new Lexical Simplification approach that exploits Neural Networks to learn substitutions from the Newsela corpus-a large set of professionally produced simplifications. We extract candidate substitutions by combining the Newsela corpus with a retrofitted context-aware word embeddings model and rank them using a new neural regression model that learns rankings from annotated data. This strategy leads to the highest <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">Accuracy</a>, <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">Precision</a> and F1 scores to date in standard datasets for the task.</abstract>
      <bibkey>paetzold-specia-2017-lexical</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/newsela">Newsela</pwcdataset>
    </paper>
    <paper id="8">
      <title>Crowd-Sourced Iterative Annotation for Narrative Summarization Corpora</title>
      <author><first>Jessica</first><last>Ouyang</last></author>
      <author><first>Serina</first><last>Chang</last></author>
      <author><first>Kathy</first><last>McKeown</last></author>
      <pages>46–51</pages>
      <url hash="8ae8c040">E17-2008</url>
      <abstract>We present an iterative annotation process for producing aligned, parallel corpora of abstractive and extractive summaries for <a href="https://en.wikipedia.org/wiki/Narrative">narrative</a>. Our approach uses a combination of trained annotators and <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowd-sourcing</a>, allowing us to elicit human-generated summaries and alignments quickly and at low cost. We use <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowd-sourcing</a> to annotate aligned phrases with the text-to-text generation techniques needed to transform each phrase into the other. We apply this process to a corpus of 476 personal narratives, which we make available on the Web.</abstract>
      <bibkey>ouyang-etal-2017-crowd</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/sentence-compression">Sentence Compression</pwcdataset>
    </paper>
    <paper id="9">
      <title>Broad Context Language Modeling as Reading Comprehension</title>
      <author><first>Zewei</first><last>Chu</last></author>
      <author><first>Hai</first><last>Wang</last></author>
      <author><first>Kevin</first><last>Gimpel</last></author>
      <author><first>David</first><last>McAllester</last></author>
      <pages>52–57</pages>
      <url hash="ed1b2312">E17-2009</url>
      <abstract>Progress in <a href="https://en.wikipedia.org/wiki/Reading_comprehension">text understanding</a> has been driven by large datasets that test particular capabilities, like recent <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> for <a href="https://en.wikipedia.org/wiki/Reading_comprehension">reading comprehension</a> (Hermann et al., 2015). We focus here on the LAMBADA dataset (Paperno et al., 2016), a word prediction task requiring broader context than the immediate sentence. We view LAMBADA as a <a href="https://en.wikipedia.org/wiki/Reading_comprehension">reading comprehension problem</a> and apply comprehension models based on <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a>. Though these <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> are constrained to choose a word from the context, they improve the state of the art on LAMBADA from 7.3 % to 49 %. We analyze 100 instances, finding that neural network readers perform well in cases that involve selecting a name from the context based on dialogue or discourse cues but struggle when <a href="https://en.wikipedia.org/wiki/Coreference_resolution">coreference resolution</a> or external knowledge is needed.</abstract>
      <bibkey>chu-etal-2017-broad</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/bookcorpus">BookCorpus</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/lambada">LAMBADA</pwcdataset>
    </paper>
    <paper id="10">
      <title>Detecting negation scope is easy, except when it is n’t</title>
      <author><first>Federico</first><last>Fancellu</last></author>
      <author><first>Adam</first><last>Lopez</last></author>
      <author><first>Bonnie</first><last>Webber</last></author>
      <author><first>Hangfeng</first><last>He</last></author>
      <pages>58–63</pages>
      <url hash="54797b3f">E17-2010</url>
      <abstract>Several <a href="https://en.wikipedia.org/wiki/Text_corpus">corpora</a> have been annotated with negation scopethe set of words whose meaning is negated by a cue like the word notleading to the development of <a href="https://en.wikipedia.org/wiki/Classifier_(linguistics)">classifiers</a> that detect negation scope with high accuracy. We show that for nearly all of these corpora, this high accuracy can be attributed to a single fact : they frequently annotate negation scope as a single span of text delimited by <a href="https://en.wikipedia.org/wiki/Punctuation">punctuation</a>. For negation scopes not of this form, detection accuracy is low and under-sampling the easy training examples does not substantially improve <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>. We demonstrate that this is partly an artifact of annotation guidelines, and we argue that future negation scope annotation efforts should focus on these more difficult cases.</abstract>
      <bibkey>fancellu-etal-2017-detecting</bibkey>
    </paper>
    <paper id="11">
      <title>MT / IE : Cross-lingual Open Information Extraction with Neural Sequence-to-Sequence Models<fixed-case>MT</fixed-case>/<fixed-case>IE</fixed-case>: Cross-lingual Open Information Extraction with Neural Sequence-to-Sequence Models</title>
      <author><first>Sheng</first><last>Zhang</last></author>
      <author><first>Kevin</first><last>Duh</last></author>
      <author><first>Benjamin</first><last>Van Durme</last></author>
      <pages>64–70</pages>
      <url hash="6aeef027">E17-2011</url>
      <abstract>Cross-lingual information extraction is the task of distilling facts from foreign language (e.g. Chinese text) into representations in another language that is preferred by the user (e.g. English tuples). Conventional pipeline solutions decompose the task as <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> followed by <a href="https://en.wikipedia.org/wiki/Information_extraction">information extraction</a> (or vice versa). We propose a joint solution with a neural sequence model, and show that it outperforms the pipeline in a cross-lingual open information extraction setting by 1-4 BLEU and 0.5-0.8 <a href="https://en.wikipedia.org/wiki/F-number">F1</a>.</abstract>
      <bibkey>zhang-etal-2017-mt</bibkey>
    </paper>
    <paper id="12">
      <title>Learning to Negate Adjectives with Bilinear Models</title>
      <author><first>Laura</first><last>Rimell</last></author>
      <author><first>Amandla</first><last>Mabona</last></author>
      <author><first>Luana</first><last>Bulat</last></author>
      <author><first>Douwe</first><last>Kiela</last></author>
      <pages>71–78</pages>
      <url hash="d0453511">E17-2012</url>
      <abstract>We learn a <a href="https://en.wikipedia.org/wiki/Map_(mathematics)">mapping</a> that negates <a href="https://en.wikipedia.org/wiki/Adjective">adjectives</a> by predicting an adjective’s antonym in an arbitrary word embedding model. We show that both <a href="https://en.wikipedia.org/wiki/Linear_model">linear models</a> and <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a> improve on this task when they have access to a vector representing the <a href="https://en.wikipedia.org/wiki/Semantic_domain">semantic domain</a> of the input word, e.g. a centroid of temperature words when predicting the antonym of ‘cold’. We introduce a continuous class-conditional bilinear neural network which is able to negate <a href="https://en.wikipedia.org/wiki/Adjective">adjectives</a> with high <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a>.</abstract>
      <bibkey>rimell-etal-2017-learning</bibkey>
    </paper>
    <paper id="13">
      <title>Instances and concepts in distributional space</title>
      <author><first>Gemma</first><last>Boleda</last></author>
      <author><first>Abhijeet</first><last>Gupta</last></author>
      <author><first>Sebastian</first><last>Padó</last></author>
      <pages>79–85</pages>
      <url hash="622aa9da">E17-2013</url>
      <abstract>Instances (Mozart) are ontologically distinct from concepts or classes (composer). Natural language encompasses both, but instances have received comparatively little attention in <a href="https://en.wikipedia.org/wiki/Distributional_semantics">distributional semantics</a>. Our results show that instances and concepts differ in their <a href="https://en.wikipedia.org/wiki/Distribution_(mathematics)">distributional properties</a>. We also establish that <a href="https://en.wikipedia.org/wiki/Instance_(computer_science)">instantiation detection (Mozart   composer)</a> is generally easier than hypernymy detection (chemist   scientist), and that results on the influence of input representation do not transfer from <a href="https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy">hyponymy</a> to <a href="https://en.wikipedia.org/wiki/Instance_(computer_science)">instantiation</a>.</abstract>
      <bibkey>boleda-etal-2017-instances</bibkey>
    </paper>
    <paper id="14">
      <title>Is this a Child, a Girl or a Car? Exploring the Contribution of Distributional Similarity to Learning Referential Word Meanings</title>
      <author><first>Sina</first><last>Zarrieß</last></author>
      <author><first>David</first><last>Schlangen</last></author>
      <pages>86–91</pages>
      <url hash="ce10e0e2">E17-2014</url>
      <abstract>There has recently been a lot of work trying to use images of referents of words for improving vector space meaning representations derived from <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">text</a>. We investigate the opposite direction, as it were, trying to improve visual word predictors that identify objects in images, by exploiting distributional similarity information during <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training</a>. We show that for certain <a href="https://en.wikipedia.org/wiki/Word">words</a> (such as entry-level nouns or hypernyms), we can indeed learn better referential word meanings by taking into account their semantic similarity to other words. For other words, there is no or even a detrimental effect, compared to a learning setup that presents even semantically related objects as negative instances.</abstract>
      <bibkey>zarriess-schlangen-2017-child</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/refcoco">RefCOCO</pwcdataset>
    </paper>
    <paper id="15">
      <title>The Semantic Proto-Role Linking Model</title>
      <author><first>Aaron Steven</first><last>White</last></author>
      <author><first>Kyle</first><last>Rawlins</last></author>
      <author><first>Benjamin</first><last>Van Durme</last></author>
      <pages>92–98</pages>
      <url hash="e4df1638">E17-2015</url>
      <abstract>We propose the semantic proto-role linking model, which jointly induces both predicate-specific semantic roles and predicate-general semantic proto-roles based on semantic proto-role property likelihood judgments. We use this <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> to empirically evaluate Dowty’s thematic proto-role linking theory.</abstract>
      <bibkey>white-etal-2017-semantic</bibkey>
    </paper>
    <paper id="16">
      <title>The Language of Place : Semantic Value from <a href="https://en.wikipedia.org/wiki/Geographic_data_and_information">Geospatial Context</a></title>
      <author><first>Anne</first><last>Cocos</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <pages>99–104</pages>
      <url hash="fed22c6d">E17-2016</url>
      <abstract>There is a relationship between what we say and where we say it. Word embeddings are usually trained assuming that semantically-similar words occur within the same textual contexts. We investigate the extent to which <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantically-similar words</a> occur within the same <a href="https://en.wikipedia.org/wiki/Geographic_data_and_information">geospatial contexts</a>. We enrich a corpus of geolocated Twitter posts with physical data derived from <a href="https://en.wikipedia.org/wiki/Google_Places">Google Places</a> and <a href="https://en.wikipedia.org/wiki/OpenStreetMap">OpenStreetMap</a>, and train word embeddings using the resulting geospatial contexts. Intrinsic evaluation of the resulting vectors shows that <a href="https://en.wikipedia.org/wiki/Context_(language_use)">geographic context</a> alone does provide useful information about <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic relatedness</a>.</abstract>
      <bibkey>cocos-callison-burch-2017-language</bibkey>
    </paper>
    <paper id="18">
      <title>A Rich Morphological Tagger for <a href="https://en.wikipedia.org/wiki/English_language">English</a> : Exploring the Cross-Linguistic Tradeoff Between <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">Morphology</a> and <a href="https://en.wikipedia.org/wiki/Syntax">Syntax</a><fixed-case>E</fixed-case>nglish: Exploring the Cross-Linguistic Tradeoff Between Morphology and Syntax</title>
      <author><first>Christo</first><last>Kirov</last></author>
      <author><first>John</first><last>Sylak-Glassman</last></author>
      <author><first>Rebecca</first><last>Knowles</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <author><first>Matt</first><last>Post</last></author>
      <pages>112–117</pages>
      <url hash="f9bee6ea">E17-2018</url>
      <abstract>A traditional claim in <a href="https://en.wikipedia.org/wiki/Linguistics">linguistics</a> is that all human languages are equally expressiveable to convey the same wide range of meanings. Morphologically rich languages, such as <a href="https://en.wikipedia.org/wiki/Czech_language">Czech</a>, rely on overt inflectional and derivational morphology to convey many semantic distinctions. Languages with comparatively limited morphology, such as <a href="https://en.wikipedia.org/wiki/English_language">English</a>, should be able to accomplish the same using a combination of syntactic and contextual cues. We capitalize on this idea by training a tagger for <a href="https://en.wikipedia.org/wiki/English_language">English</a> that uses syntactic features obtained by automatic parsing to recover complex morphological tags projected from <a href="https://en.wikipedia.org/wiki/Czech_language">Czech</a>. The high <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of the resulting model provides quantitative confirmation of the underlying linguistic hypothesis of equal expressivity, and bodes well for future improvements in downstream HLT tasks including <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>.</abstract>
      <bibkey>kirov-etal-2017-rich</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="19">
      <title>Context-Aware Prediction of Derivational Word-forms</title>
      <author><first>Ekaterina</first><last>Vylomova</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <pages>118–124</pages>
      <url hash="e41bf20d">E17-2019</url>
      <abstract>Derivational morphology is a fundamental and complex characteristic of language. In this paper we propose a new task of predicting the <a href="https://en.wikipedia.org/wiki/Derivation_(differential_algebra)">derivational form</a> of a given base-form lemma that is appropriate for a given context. We present an encoder-decoder style neural network to produce a derived form character-by-character, based on its corresponding character-level representation of the base form and the context. We demonstrate that our model is able to generate valid context-sensitive derivations from known base forms, but is less accurate under lexicon agnostic setting.</abstract>
      <bibkey>vylomova-etal-2017-context</bibkey>
      <pwccode url="https://github.com/ivri/dmorph" additional="false">ivri/dmorph</pwccode>
    </paper>
    <paper id="20">
      <title>Comparing Character-level Neural Language Models Using a Lexical Decision Task</title>
      <author><first>Gaël</first><last>Le Godais</last></author>
      <author><first>Tal</first><last>Linzen</last></author>
      <author><first>Emmanuel</first><last>Dupoux</last></author>
      <pages>125–130</pages>
      <url hash="aac2d7b5">E17-2020</url>
      <abstract>What is the information captured by neural network models of language? We address this question in the case of character-level recurrent neural language models. These <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> do not have explicit word representations ; do they acquire implicit ones? We assess the lexical capacity of a network using the <a href="https://en.wikipedia.org/wiki/Lexical_decision_task">lexical decision task</a> common in <a href="https://en.wikipedia.org/wiki/Psycholinguistics">psycholinguistics</a> : the <a href="https://en.wikipedia.org/wiki/System">system</a> is required to decide whether or not a string of characters forms a word. We explore how accuracy on this task is affected by the architecture of the <a href="https://en.wikipedia.org/wiki/Telecommunications_network">network</a>, focusing on cell type (LSTM vs. SRN), depth and width. We also compare these architectural properties to a simple count of the parameters of the <a href="https://en.wikipedia.org/wiki/Network_analysis_(electrical_circuits)">network</a>. The overall number of parameters in the <a href="https://en.wikipedia.org/wiki/Flow_network">network</a> turns out to be the most important predictor of <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> ; in particular, there is little evidence that deeper networks are beneficial for this task.</abstract>
      <bibkey>le-godais-etal-2017-comparing</bibkey>
    </paper>
    <paper id="21">
      <title>Optimal encoding !-Information Theory constrains article omission in newspaper headlines</title>
      <author><first>Robin</first><last>Lemke</last></author>
      <author><first>Eva</first><last>Horch</last></author>
      <author><first>Ingo</first><last>Reich</last></author>
      <pages>131–135</pages>
      <url hash="fb6aefe2">E17-2021</url>
      <abstract>In this paper we pursue the hypothesis that the distribution of article omission specifically is constrained by principles of <a href="https://en.wikipedia.org/wiki/Information_theory">Information Theory</a> (Shannon 1948). In particular, <a href="https://en.wikipedia.org/wiki/Information_theory">Information Theory</a> predicts a stronger preference for article omission before nouns which are relatively unpredictable in context of the preceding words. We investigated article omission in <a href="https://en.wikipedia.org/wiki/List_of_newspapers_in_Germany">German newspaper headlines</a> with a corpus and acceptability rating study. Both support our hypothesis : Articles are inserted more often before unpredictable nouns and subjects perceive article omission before predictable nouns as more well-formed than before unpredictable ones. This suggests that <a href="https://en.wikipedia.org/wiki/Information_theory">information theoretic principles</a> constrain the distribution of article omission in <a href="https://en.wikipedia.org/wiki/Headline">headlines</a>.</abstract>
      <bibkey>lemke-etal-2017-optimal</bibkey>
    </paper>
    <paper id="22">
      <title>A Computational Analysis of the Language of Drug Addiction</title>
      <author><first>Carlo</first><last>Strapparava</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <pages>136–142</pages>
      <url hash="0310e0a5">E17-2022</url>
      <abstract>We present a <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational analysis</a> of the language of drug users when talking about their drug experiences. We introduce a new dataset of over 4,000 descriptions of experiences reported by users of four main drug types, and show that we can predict with an F1-score of up to 88 % the drug behind a certain experience. We also perform an analysis of the dominant psycholinguistic processes and dominant emotions associated with each drug type, which sheds light on the characteristics of drug users.</abstract>
      <bibkey>strapparava-mihalcea-2017-computational</bibkey>
    </paper>
    <paper id="23">
      <title>A Practical Perspective on Latent Structured Prediction for <a href="https://en.wikipedia.org/wiki/Coreference_resolution">Coreference Resolution</a></title>
      <author><first>Iryna</first><last>Haponchyk</last></author>
      <author><first>Alessandro</first><last>Moschitti</last></author>
      <pages>143–149</pages>
      <url hash="9817fe86">E17-2023</url>
      <abstract>Latent structured prediction theory proposes powerful methods such as Latent Structural SVM (LSSVM), which can potentially be very appealing for coreference resolution (CR). In contrast, only small work is available, mainly targeting the latent structured perceptron (LSP). In this paper, we carried out a practical study comparing for the first time <a href="https://en.wikipedia.org/wiki/Educational_technology">online learning</a> with LSSVM. We analyze the intricacies that may have made initial attempts to use LSSVM fail, i.e., a huge <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training time</a> and much lower accuracy produced by Kruskal’s spanning tree algorithm. In this respect, we also propose a new effective feature selection approach for improving system efficiency. The results show that LSP, if correctly parameterized, produces the same performance as LSSVM, being much more efficient.</abstract>
      <bibkey>haponchyk-moschitti-2017-practical</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2012-1">CoNLL-2012</pwcdataset>
    </paper>
    <paper id="24">
      <title>On the Need of <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">Cross Validation</a> for Discourse Relation Classification</title>
      <author><first>Wei</first><last>Shi</last></author>
      <author><first>Vera</first><last>Demberg</last></author>
      <pages>150–156</pages>
      <url hash="e09cb49f">E17-2024</url>
      <abstract>The task of implicit discourse relation classification has received increased attention in recent years, including two CoNNL shared tasks on the topic. Existing machine learning models for the task train on sections 2-21 of the PDTB and test on section 23, which includes a total of 761 implicit discourse relations. In this paper, we’d like to make a methodological point, arguing that the standard test set is too small to draw conclusions about whether the inclusion of certain features constitute a genuine improvement, or whether one got lucky with some properties of the <a href="https://en.wikipedia.org/wiki/Test_set">test set</a>, and argue for the adoption of <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">cross validation</a> for the discourse relation classification task by the community.</abstract>
      <bibkey>shi-demberg-2017-need</bibkey>
    </paper>
    <paper id="25">
      <title>Using the Output Embedding to Improve <a href="https://en.wikipedia.org/wiki/Language_model">Language Models</a></title>
      <author><first>Ofir</first><last>Press</last></author>
      <author><first>Lior</first><last>Wolf</last></author>
      <pages>157–163</pages>
      <url hash="091485ef">E17-2025</url>
      <abstract>We study the topmost weight matrix of neural network language models. We show that this <a href="https://en.wikipedia.org/wiki/Matrix_(mathematics)">matrix</a> constitutes a valid <a href="https://en.wikipedia.org/wiki/Word_embedding">word embedding</a>. When training <a href="https://en.wikipedia.org/wiki/Language_model">language models</a>, we recommend tying the input embedding and this output embedding. We analyze the resulting update rules and show that the tied embedding evolves in a more similar way to the output embedding than to the input embedding in the untied model. We also offer a new method of regularizing the output embedding. Our methods lead to a significant reduction in <a href="https://en.wikipedia.org/wiki/Perplexity">perplexity</a>, as we are able to show on a variety of neural network language models. Finally, we show that weight tying can reduce the size of neural translation models to less than half of their original size without harming their performance.</abstract>
      <bibkey>press-wolf-2017-using</bibkey>
      <pwccode url="https://github.com/ofirpress/UsingTheOutputEmbedding" additional="true">ofirpress/UsingTheOutputEmbedding</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="26">
      <title>Identifying beneficial task relations for <a href="https://en.wikipedia.org/wiki/Multi-task_learning">multi-task learning</a> in deep neural networks</title>
      <author><first>Joachim</first><last>Bingel</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>164–169</pages>
      <url hash="0da6d2d4">E17-2026</url>
      <abstract>Multi-task learning (MTL) in <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural networks</a> for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> has recently received increasing interest due to some compelling benefits, including its potential to efficiently regularize models and to reduce the need for <a href="https://en.wikipedia.org/wiki/Labeled_data">labeled data</a>. While it has brought significant improvements in a number of <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP tasks</a>, mixed results have been reported, and little is known about the conditions under which MTL leads to gains in <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP</a>. This paper sheds light on the specific task relations that can lead to gains from MTL models over single-task setups.</abstract>
      <bibkey>bingel-sogaard-2017-identifying</bibkey>
      <pwccode url="https://github.com/jbingel/eacl2017_mtl" additional="false">jbingel/eacl2017_mtl</pwccode>
    </paper>
    <paper id="27">
      <title>Effective search space reduction for spell correction using character neural embeddings</title>
      <author><first>Harshit</first><last>Pande</last></author>
      <pages>170–174</pages>
      <url hash="6f6d4f9c">E17-2027</url>
      <abstract>We present a novel, unsupervised, and distance measure agnostic method for search space reduction in spell correction using neural character embeddings. The embeddings are learned by skip-gram word2vec training on sequences generated from dictionary words in a phonetic information-retentive manner. We report a very high performance in terms of both success rates and reduction of search space on the Birkbeck spelling error corpus. To the best of our knowledge, this is the first application of <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> to spell correction.</abstract>
      <bibkey>pande-2017-effective</bibkey>
    </paper>
    <paper id="28">
      <title>Explaining and Generalizing Skip-Gram through Exponential Family Principal Component Analysis</title>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <author><first>Adam</first><last>Poliak</last></author>
      <author><first>Benjamin</first><last>Van Durme</last></author>
      <author><first>Jason</first><last>Eisner</last></author>
      <pages>175–181</pages>
      <url hash="f8e2bbcd">E17-2028</url>
      <abstract>The popular skip-gram model induces <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> by exploiting the signal from word-context coocurrence. We offer a new interpretation of <a href="https://en.wikipedia.org/wiki/Skip-gram">skip-gram</a> based on exponential family PCA-a form of matrix factorization to generalize the <a href="https://en.wikipedia.org/wiki/Skip-gram">skip-gram model</a> to tensor factorization. In turn, this lets us train <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> through richer higher-order coocurrences, e.g., triples that include positional information (to incorporate syntax) or <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological information</a> (to share parameters across related words). We experiment on 40 languages and show our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> improves upon <a href="https://en.wikipedia.org/wiki/Skip-gram">skip-gram</a>.</abstract>
      <bibkey>cotterell-etal-2017-explaining</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="29">
      <title>Latent Variable Dialogue Models and their Diversity</title>
      <author><first>Kris</first><last>Cao</last></author>
      <author><first>Stephen</first><last>Clark</last></author>
      <pages>182–187</pages>
      <url hash="be1ffa47">E17-2029</url>
      <abstract>We present a dialogue generation model that directly captures the variability in possible responses to a given input, which reduces the ‘boring output’ issue of deterministic dialogue models. Experiments show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> generates more diverse outputs than baseline models, and also generates more consistently acceptable output than sampling from a deterministic encoder-decoder model.</abstract>
      <bibkey>cao-clark-2017-latent</bibkey>
    </paper>
    <paper id="30">
      <title>Age Group Classification with Speech and Metadata Multimodality Fusion</title>
      <author><first>Denys</first><last>Katerenchuk</last></author>
      <pages>188–193</pages>
      <url hash="4913ddc6">E17-2030</url>
      <abstract>Children comprise a significant proportion of TV viewers and it is worthwhile to customize the experience for them. However, identifying who is a child in the audience can be a challenging task. We present initial studies of a novel <a href="https://en.wikipedia.org/wiki/Methodology">method</a> which combines utterances with user metadata. In particular, we develop an ensemble of different machine learning techniques on different subsets of data to improve child detection. Our initial results show an 9.2 % absolute improvement over the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a>, leading to a state-of-the-art performance.</abstract>
      <bibkey>katerenchuk-2017-age</bibkey>
    </paper>
    <paper id="31">
      <title>Automatically augmenting an emotion dataset improves <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> using audio</title>
      <author><first>Egor</first><last>Lakomkin</last></author>
      <author><first>Cornelius</first><last>Weber</last></author>
      <author><first>Stefan</first><last>Wermter</last></author>
      <pages>194–197</pages>
      <url hash="e2450fd4">E17-2031</url>
      <abstract>In this work, we tackle a problem of <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech emotion classification</a>. One of the issues in the area of affective computation is that the amount of annotated data is very limited. On the other hand, the number of ways that the same emotion can be expressed verbally is enormous due to variability between speakers. This is one of the factors that limits performance and <a href="https://en.wikipedia.org/wiki/Generalization">generalization</a>. We propose a simple method that extracts <a href="https://en.wikipedia.org/wiki/Sampling_(music)">audio samples</a> from <a href="https://en.wikipedia.org/wiki/Film">movies</a> using textual sentiment analysis. As a result, it is possible to automatically construct a larger dataset of <a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">audio samples</a> with positive, negative emotional and neutral speech. We show that pretraining <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network</a> on such a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> yields better results on the challenging EmotiW corpus. This experiment shows a potential benefit of combining textual sentiment analysis with <a href="https://en.wikipedia.org/wiki/Voice_(phonetics)">vocal information</a>.</abstract>
      <bibkey>lakomkin-etal-2017-automatically</bibkey>
    </paper>
    <paper id="33">
      <title>Hybrid Dialog State Tracker with ASR Features<fixed-case>ASR</fixed-case> Features</title>
      <author><first>Miroslav</first><last>Vodolán</last></author>
      <author><first>Rudolf</first><last>Kadlec</last></author>
      <author><first>Jan</first><last>Kleindienst</last></author>
      <pages>205–210</pages>
      <url hash="209a394a">E17-2033</url>
      <abstract>This paper presents a hybrid dialog state tracker enhanced by trainable Spoken Language Understanding (SLU) for slot-filling dialog systems. Our <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> is inspired by previously proposed neural-network-based belief-tracking systems. In addition, we extended some parts of our <a href="https://en.wikipedia.org/wiki/Modular_programming">modular architecture</a> with <a href="https://en.wikipedia.org/wiki/Differentiable_function">differentiable rules</a> to allow <a href="https://en.wikipedia.org/wiki/End-to-end_principle">end-to-end training</a>. We hypothesize that these rules allow our <a href="https://en.wikipedia.org/wiki/Music_tracker">tracker</a> to generalize better than pure machine-learning based systems. For evaluation, we used the Dialog State Tracking Challenge (DSTC) 2 dataset-a popular belief tracking testbed with dialogs from restaurant information system. To our knowledge, our hybrid tracker sets a new state-of-the-art result in three out of four categories within the DSTC2.</abstract>
      <bibkey>vodolan-etal-2017-hybrid</bibkey>
    </paper>
    <paper id="34">
      <title>Morphological Analysis without Expert Annotation</title>
      <author><first>Garrett</first><last>Nicolai</last></author>
      <author><first>Grzegorz</first><last>Kondrak</last></author>
      <pages>211–216</pages>
      <url hash="36ce50e5">E17-2034</url>
      <abstract>The task of <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological analysis</a> is to produce a complete list of lemma+tag analyses for a given <a href="https://en.wikipedia.org/wiki/Logical_form">word-form</a>. We propose a discriminative string transduction approach which exploits plain inflection tables and raw text corpora, thus obviating the need for expert annotation. Experiments on four languages demonstrate that our system has much higher coverage than a hand-engineered FST analyzer, and is more accurate than a state-of-the-art morphological tagger.</abstract>
      <bibkey>nicolai-kondrak-2017-morphological</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/celex">CELEX</pwcdataset>
    </paper>
    <paper id="35">
      <title>Morphological Analysis of the Dravidian Language Family<fixed-case>D</fixed-case>ravidian Language Family</title>
      <author><first>Arun</first><last>Kumar</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <author><first>Lluís</first><last>Padró</last></author>
      <author><first>Antoni</first><last>Oliver</last></author>
      <pages>217–222</pages>
      <url hash="390f4b39">E17-2035</url>
      <abstract>The <a href="https://en.wikipedia.org/wiki/Dravidian_languages">Dravidian languages</a> are one of the most widely spoken language families in the world, yet there are very few annotated resources available to NLP researchers. To remedy this, we create DravMorph, a <a href="https://en.wikipedia.org/wiki/Speech_corpus">corpus</a> annotated for morphological segmentation and <a href="https://en.wikipedia.org/wiki/Part_of_speech">part-of-speech</a>. Additionally, we exploit novel features and higher-order models to set state-of-the-art results on these corpora on both tasks, beating techniques proposed in the literature by as much as 4 points in segmentation F1.</abstract>
      <bibkey>kumar-etal-2017-morphological</bibkey>
    </paper>
    <paper id="36">
      <title>BabelDomains : Large-Scale Domain Labeling of Lexical Resources<fixed-case>B</fixed-case>abel<fixed-case>D</fixed-case>omains: Large-Scale Domain Labeling of Lexical Resources</title>
      <author><first>Jose</first><last>Camacho-Collados</last></author>
      <author><first>Roberto</first><last>Navigli</last></author>
      <pages>223–228</pages>
      <url hash="73376b61">E17-2036</url>
      <abstract>In this paper we present BabelDomains, a unified resource which provides lexical items with information about domains of knowledge. We propose an automatic method that uses knowledge from various lexical resources, exploiting both distributional and graph-based clues, to accurately propagate domain information. We evaluate our <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> intrinsically on two lexical resources (WordNet and BabelNet), achieving a <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a> over 80 % in both cases. Finally, we show the potential of BabelDomains in a supervised learning setting, clustering training data by domain for hypernym discovery.</abstract>
      <bibkey>camacho-collados-navigli-2017-babeldomains</bibkey>
    </paper>
    <paper id="37">
      <title>JFLEG : A Fluency Corpus and Benchmark for Grammatical Error Correction<fixed-case>JFLEG</fixed-case>: A Fluency Corpus and Benchmark for Grammatical Error Correction</title>
      <author><first>Courtney</first><last>Napoles</last></author>
      <author><first>Keisuke</first><last>Sakaguchi</last></author>
      <author><first>Joel</first><last>Tetreault</last></author>
      <pages>229–234</pages>
      <url hash="7a69e260">E17-2037</url>
      <abstract>We present a new parallel corpus, JHU FLuency-Extended GUG corpus (JFLEG) for developing and evaluating grammatical error correction (GEC). Unlike other <a href="https://en.wikipedia.org/wiki/Text_corpus">corpora</a>, it represents a broad range of language proficiency levels and uses holistic fluency edits to not only correct <a href="https://en.wikipedia.org/wiki/Error_(linguistics)">grammatical errors</a> but also make the original text more native sounding. We describe the types of corrections made and benchmark four leading GEC systems on this <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>, identifying specific areas in which they do well and how they can improve. JFLEG fulfills the need for a new gold standard to properly assess the current state of <a href="https://en.wikipedia.org/wiki/General_Electric_Company">GEC</a>.</abstract>
      <bibkey>napoles-etal-2017-jfleg</bibkey>
      <pwccode url="https://github.com/keisks/jfleg" additional="false">keisks/jfleg</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/jfleg">JFLEG</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2014-shared-task-grammatical-error">CoNLL-2014 Shared Task: Grammatical Error Correction</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/fce">FCE</pwcdataset>
    </paper>
    <paper id="39">
      <title>The Parallel Meaning Bank : Towards a Multilingual Corpus of Translations Annotated with Compositional Meaning Representations<fixed-case>P</fixed-case>arallel <fixed-case>M</fixed-case>eaning <fixed-case>B</fixed-case>ank: Towards a Multilingual Corpus of Translations Annotated with Compositional Meaning Representations</title>
      <author><first>Lasha</first><last>Abzianidze</last></author>
      <author><first>Johannes</first><last>Bjerva</last></author>
      <author><first>Kilian</first><last>Evang</last></author>
      <author><first>Hessel</first><last>Haagsma</last></author>
      <author><first>Rik</first><last>van Noord</last></author>
      <author><first>Pierre</first><last>Ludmann</last></author>
      <author><first>Duc-Duy</first><last>Nguyen</last></author>
      <author><first>Johan</first><last>Bos</last></author>
      <pages>242–247</pages>
      <url hash="7d68a950">E17-2039</url>
      <abstract>The Parallel Meaning Bank is a corpus of translations annotated with shared, formal meaning representations comprising over 11 million words divided over four languages (English, German, Italian, and Dutch). Our approach is based on cross-lingual projection : automatically produced (and manually corrected) semantic annotations for English sentences are mapped onto their word-aligned translations, assuming that the translations are meaning-preserving. The <a href="https://en.wikipedia.org/wiki/Semantic_annotation">semantic annotation</a> consists of five main steps : (i) segmentation of the text in sentences and lexical items ; (ii) syntactic parsing with Combinatory Categorial Grammar ; (iii) universal semantic tagging ; (iv) symbolization ; and (v) compositional semantic analysis based on <a href="https://en.wikipedia.org/wiki/Discourse_representation_theory">Discourse Representation Theory</a>. These steps are performed using <a href="https://en.wikipedia.org/wiki/Statistical_model">statistical models</a> trained in a <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning">semi-supervised manner</a>. The employed annotation models are all language-neutral. Our first results are promising.</abstract>
      <bibkey>abzianidze-etal-2017-parallel</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/groningen-meaning-bank">Groningen Meaning Bank</pwcdataset>
    </paper>
    <paper id="40">
      <title>Cross-lingual tagger evaluation without test data</title>
      <author><first>Željko</first><last>Agić</last></author>
      <author><first>Barbara</first><last>Plank</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>248–253</pages>
      <url hash="ffeb845f">E17-2040</url>
      <abstract>We address the challenge of cross-lingual POS tagger evaluation in absence of manually annotated test data. We put forth and evaluate two dictionary-based metrics. On the tasks of accuracy prediction and system ranking, we reveal that these metrics are reliable enough to approximate test set-based evaluation, and at the same time lean enough to support assessment for truly low-resource languages.</abstract>
      <bibkey>agic-etal-2017-cross</bibkey>
    </paper>
    <paper id="42">
      <title>The Content Types Dataset : a New Resource to Explore Semantic and Functional Characteristics of Texts</title>
      <author><first>Rachele</first><last>Sprugnoli</last></author>
      <author><first>Tommaso</first><last>Caselli</last></author>
      <author><first>Sara</first><last>Tonelli</last></author>
      <author><first>Giovanni</first><last>Moretti</last></author>
      <pages>260–266</pages>
      <url hash="a4bf8583">E17-2042</url>
      <abstract>This paper presents a new resource, called Content Types Dataset, to promote the analysis of texts as a composition of units with specific semantic and functional roles. By developing this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>, we also introduce a new NLP task for the automatic classification of Content Types. The annotation scheme and the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> are described together with two sets of <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> experiments.</abstract>
      <bibkey>sprugnoli-etal-2017-content</bibkey>
    </paper>
    <paper id="43">
      <title>Continuous N-gram Representations for Authorship Attribution</title>
      <author><first>Yunita</first><last>Sari</last></author>
      <author><first>Andreas</first><last>Vlachos</last></author>
      <author><first>Mark</first><last>Stevenson</last></author>
      <pages>267–273</pages>
      <url hash="f89a455a">E17-2043</url>
      <abstract>This paper presents work on using continuous representations for <a href="https://en.wikipedia.org/wiki/Attribution_(copyright)">authorship attribution</a>. In contrast to previous work, which uses discrete feature representations, our model learns continuous representations for <a href="https://en.wikipedia.org/wiki/N-gram">n-gram features</a> via a <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> jointly with the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification layer</a>. Experimental results demonstrate that the proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms the <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a> on two datasets, while producing comparable results on the remaining two.</abstract>
      <bibkey>sari-etal-2017-continuous</bibkey>
    </paper>
    <paper id="44">
      <title>Reconstructing the house from the ad : <a href="https://en.wikipedia.org/wiki/Structured_prediction">Structured prediction</a> on real estate classifieds</title>
      <author><first>Giannis</first><last>Bekoulis</last></author>
      <author><first>Johannes</first><last>Deleu</last></author>
      <author><first>Thomas</first><last>Demeester</last></author>
      <author><first>Chris</first><last>Develder</last></author>
      <pages>274–279</pages>
      <url hash="e19d0b37">E17-2044</url>
      <abstract>In this paper, we address the (to the best of our knowledge) new problem of extracting a structured description of real estate properties from their natural language descriptions in <a href="https://en.wikipedia.org/wiki/Classified_advertising">classifieds</a>. We survey and present several models to (a) identify important <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entities</a> of a property (e.g.,rooms) from classifieds and (b) structure them into a tree format, with the <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entities</a> as <a href="https://en.wikipedia.org/wiki/Vertex_(graph_theory)">nodes</a> and <a href="https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms">edges</a> representing a <a href="https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms">part-of relation</a>. Experiments show that a graph-based system deriving the <a href="https://en.wikipedia.org/wiki/Tree_(graph_theory)">tree</a> from an initially fully connected entity graph, outperforms a transition-based system starting from only the entity nodes, since it better reconstructs the <a href="https://en.wikipedia.org/wiki/Tree_(graph_theory)">tree</a>.</abstract>
      <bibkey>bekoulis-etal-2017-reconstructing</bibkey>
      <pwccode url="https://github.com/bekou/ad_data" additional="false">bekou/ad_data</pwccode>
    </paper>
    <paper id="46">
      <title>Improving ROUGE for Timeline Summarization<fixed-case>ROUGE</fixed-case> for Timeline Summarization</title>
      <author><first>Sebastian</first><last>Martschat</last></author>
      <author><first>Katja</first><last>Markert</last></author>
      <pages>285–290</pages>
      <url hash="ccb0906d">E17-2046</url>
      <abstract>Current evaluation metrics for timeline summarization either ignore the temporal aspect of the task or require strict date matching. We introduce variants of ROUGE that allow alignment of daily summaries via temporal distance or <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a>. We argue for the suitability of these variants in a theoretical analysis and demonstrate it in a battery of task-specific tests.</abstract>
      <bibkey>martschat-markert-2017-improving</bibkey>
    </paper>
    <paper id="47">
      <title>Cutting-off Redundant Repeating Generations for Neural Abstractive Summarization</title>
      <author><first>Jun</first><last>Suzuki</last></author>
      <author><first>Masaaki</first><last>Nagata</last></author>
      <pages>291–297</pages>
      <url hash="b68f5013">E17-2047</url>
      <abstract>This paper tackles the reduction of redundant repeating generation that is often observed in RNN-based encoder-decoder models. Our basic idea is to jointly estimate the upper-bound frequency of each target vocabulary in the <a href="https://en.wikipedia.org/wiki/Encoder">encoder</a> and control the output words based on the estimation in the <a href="https://en.wikipedia.org/wiki/Codec">decoder</a>. Our method shows significant improvement over a strong RNN-based encoder-decoder baseline and achieved its best results on an abstractive summarization benchmark.</abstract>
      <bibkey>suzuki-nagata-2017-cutting</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/duc-2004">DUC 2004</pwcdataset>
    </paper>
    <paper id="48">
      <title>To Sing like a Mockingbird</title>
      <author><first>Lorenzo</first><last>Gatti</last></author>
      <author><first>Gözde</first><last>Özbal</last></author>
      <author><first>Oliviero</first><last>Stock</last></author>
      <author><first>Carlo</first><last>Strapparava</last></author>
      <pages>298–304</pages>
      <url hash="8b05bd6e">E17-2048</url>
      <abstract>Musical parody, i.e. the act of changing the lyrics of an existing and very well-known song, is a commonly used technique for creating catchy advertising tunes and for mocking people or events. Here we describe a <a href="https://en.wikipedia.org/wiki/System">system</a> for automatically producing a <a href="https://en.wikipedia.org/wiki/Parody_music">musical parody</a>, starting from a <a href="https://en.wikipedia.org/wiki/Corpus_linguistics">corpus of songs</a>. The <a href="https://en.wikipedia.org/wiki/System">system</a> can automatically identify characterizing words and concepts related to a novel text, which are taken from the <a href="https://en.wikipedia.org/wiki/News">daily news</a>. These concepts are then used as seeds to appropriately replace part of the original <a href="https://en.wikipedia.org/wiki/Lyrics">lyrics</a> of a song, using <a href="https://en.wikipedia.org/wiki/Metre_(poetry)">metrical</a>, <a href="https://en.wikipedia.org/wiki/Rhyme">rhyming</a> and lexical constraints. Finally, the <a href="https://en.wikipedia.org/wiki/Parody">parody</a> can be sung with a singing speech synthesizer, with no intervention from the user.</abstract>
      <bibkey>gatti-etal-2017-sing</bibkey>
    </paper>
    <paper id="49">
      <title>K-best Iterative Viterbi Parsing<fixed-case>V</fixed-case>iterbi Parsing</title>
      <author><first>Katsuhiko</first><last>Hayashi</last></author>
      <author><first>Masaaki</first><last>Nagata</last></author>
      <pages>305–310</pages>
      <url hash="74340737">E17-2049</url>
      <abstract>This paper presents an efficient and optimal parsing algorithm for probabilistic context-free grammars (PCFGs). To achieve faster <a href="https://en.wikipedia.org/wiki/Parsing">parsing</a>, our proposal employs a pruning technique to reduce unnecessary edges in the <a href="https://en.wikipedia.org/wiki/Feasible_region">search space</a>. The key is to conduct repetitively Viterbi inside and outside parsing, while gradually expanding the <a href="https://en.wikipedia.org/wiki/Feasible_region">search space</a> to efficiently compute <a href="https://en.wikipedia.org/wiki/Heuristic_(computer_science)">heuristic bounds</a> used for <a href="https://en.wikipedia.org/wiki/Parsing">pruning</a>. Our experimental results using the English Penn Treebank corpus show that the proposed <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> is faster than the standard CKY parsing algorithm. In addition, we also show how to extend this <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> to extract k-best Viterbi parse trees.</abstract>
      <bibkey>hayashi-nagata-2017-k</bibkey>
    </paper>
    <paper id="50">
      <title>PP Attachment : Where do We Stand?<fixed-case>PP</fixed-case> Attachment: Where do We Stand?</title>
      <author><first>Daniël</first><last>de Kok</last></author>
      <author><first>Jianqiang</first><last>Ma</last></author>
      <author><first>Corina</first><last>Dima</last></author>
      <author><first>Erhard</first><last>Hinrichs</last></author>
      <pages>311–317</pages>
      <url hash="3e96f603">E17-2050</url>
      <abstract>Prepostitional phrase (PP) attachment is a well known challenge to <a href="https://en.wikipedia.org/wiki/Parsing">parsing</a>. In this paper, we combine the insights of different works, namely : (1) treating PP attachment as a classification task with an arbitrary number of attachment candidates ; (2) using auxiliary distributions to augment the data beyond the hand-annotated training set ; (3) using topological fields to get information about the distribution of PP attachment throughout clauses and (4) using state-of-the-art techniques such as word embeddings and neural networks. We show that jointly using these <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">techniques</a> leads to substantial improvements. We also conduct a qualitative analysis to gauge where the ceiling of the task is in a realistic setup.</abstract>
      <bibkey>de-kok-etal-2017-pp</bibkey>
    </paper>
    <paper id="51">
      <title>Do n’t Stop Me Now ! Using Global Dynamic Oracles to Correct Training Biases of Transition-Based Dependency Parsers</title>
      <author><first>Lauriane</first><last>Aufrant</last></author>
      <author><first>Guillaume</first><last>Wisniewski</last></author>
      <author><first>François</first><last>Yvon</last></author>
      <pages>318–323</pages>
      <url hash="10363d62">E17-2051</url>
      <abstract>This paper formalizes a sound extension of dynamic oracles to global training, in the frame of transition-based dependency parsers. By dispensing with the pre-computation of references, this extension widens the training strategies that can be entertained for such parsers ; we show this by revisiting two standard training procedures, early-update and max-violation, to correct some of their search space sampling biases. Experimentally, on the SPMRL treebanks, this improvement increases the similarity between the train and test distributions and yields performance improvements up to 0.7 UAS, without any <a href="https://en.wikipedia.org/wiki/Overhead_(computing)">computation overhead</a>.</abstract>
      <bibkey>aufrant-etal-2017-dont</bibkey>
    </paper>
    <paper id="52">
      <title>Joining Hands : Exploiting Monolingual Treebanks for Parsing of Code-mixing Data</title>
      <author><first>Irshad</first><last>Bhat</last></author>
      <author><first>Riyaz A.</first><last>Bhat</last></author>
      <author><first>Manish</first><last>Shrivastava</last></author>
      <author><first>Dipti</first><last>Sharma</last></author>
      <pages>324–330</pages>
      <url hash="e2770613">E17-2052</url>
      <abstract>In this paper, we propose efficient and less resource-intensive strategies for parsing of code-mixed data. These strategies are not constrained by in-domain annotations, rather they leverage pre-existing monolingual annotated resources for training. We show that these <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> can produce significantly better results as compared to an <a href="https://en.wikipedia.org/wiki/Baseline_(medicine)">informed baseline</a>. Due to lack of an evaluation set for code-mixed structures, we also present a data set of 450 Hindi and English code-mixed tweets of Hindi multilingual speakers for evaluation.</abstract>
      <bibkey>bhat-etal-2017-joining</bibkey>
    </paper>
    <paper id="53">
      <title>Multilingual Lexicalized Constituency Parsing with Word-Level Auxiliary Tasks</title>
      <author><first>Maximin</first><last>Coavoux</last></author>
      <author><first>Benoît</first><last>Crabbé</last></author>
      <pages>331–336</pages>
      <url hash="a436d2b1">E17-2053</url>
      <abstract>We introduce a constituency parser based on a bi-LSTM encoder adapted from recent work (Cross and Huang, 2016b ; Kiperwasser and Goldberg, 2016), which can incorporate a lower level character biLSTM (Ballesteros et al., 2015 ; Plank et al., 2016). We model two important interfaces of constituency parsing with auxiliary tasks supervised at the word level : (i) part-of-speech (POS) and morphological tagging, (ii) functional label prediction. On the SPMRL dataset, our <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> obtains above state-of-the-art results on constituency parsing without requiring either predicted POS or morphological tags, and outputs labelled dependency trees.</abstract>
      <bibkey>coavoux-crabbe-2017-multilingual</bibkey>
      <pwccode url="https://github.com/mcoavoux/mtg" additional="false">mcoavoux/mtg</pwccode>
    </paper>
    <paper id="54">
      <title>Be Precise or Fuzzy : Learning the Meaning of Cardinals and Quantifiers from Vision</title>
      <author><first>Sandro</first><last>Pezzelle</last></author>
      <author><first>Marco</first><last>Marelli</last></author>
      <author><first>Raffaella</first><last>Bernardi</last></author>
      <pages>337–342</pages>
      <url hash="8c596dd9">E17-2054</url>
      <abstract>People can refer to quantities in a visual scene by using either exact cardinals (e.g. one, two, three) or <a href="https://en.wikipedia.org/wiki/Quantifier_(linguistics)">natural language quantifiers</a> (e.g. few, most, all). In humans, these two <a href="https://en.wikipedia.org/wiki/Process_(anatomy)">processes</a> underlie fairly different <a href="https://en.wikipedia.org/wiki/Cognition">cognitive and neural mechanisms</a>. Inspired by this evidence, the present study proposes two <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> for learning the objective meaning of cardinals and <a href="https://en.wikipedia.org/wiki/Quantifier_(logic)">quantifiers</a> from visual scenes containing multiple objects. We show that a model capitalizing on a ‘fuzzy’ measure of similarity is effective for learning <a href="https://en.wikipedia.org/wiki/Quantifier_(logic)">quantifiers</a>, whereas the learning of exact cardinals is better accomplished when information about number is provided.</abstract>
      <bibkey>pezzelle-etal-2017-precise</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imagenet">ImageNet</pwcdataset>
    </paper>
    <paper id="55">
      <title>Improving a Strong Neural Parser with Conjunction-Specific Features</title>
      <author><first>Jessica</first><last>Ficler</last></author>
      <author><first>Yoav</first><last>Goldberg</last></author>
      <pages>343–348</pages>
      <url hash="eb9fdc07">E17-2055</url>
      <abstract>While dependency parsers reach very high overall accuracy, some dependency relations are much harder than others. In particular, dependency parsers perform poorly in coordination construction (i.e., correctly attaching the conj relation). We extend a state-of-the-art dependency parser with conjunction-specific features, focusing on the similarity between the conjuncts head words. Training the extended <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> yields an improvement in conj attachment as well as in overall dependency parsing accuracy on the Stanford dependency conversion of the Penn TreeBank.</abstract>
      <bibkey>ficler-goldberg-2017-improving</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="57">
      <title>Improving Evaluation of Document-level Machine Translation Quality Estimation</title>
      <author><first>Yvette</first><last>Graham</last></author>
      <author><first>Qingsong</first><last>Ma</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <author><first>Qun</first><last>Liu</last></author>
      <author><first>Carla</first><last>Parra</last></author>
      <author><first>Carolina</first><last>Scarton</last></author>
      <pages>356–361</pages>
      <url hash="d91571f4">E17-2057</url>
      <abstract>Meaningful conclusions about the relative performance of NLP systems are only possible if the <a href="https://en.wikipedia.org/wiki/Gold_standard_(test)">gold standard</a> employed in a given <a href="https://en.wikipedia.org/wiki/Evaluation">evaluation</a> is both valid and reliable. In this paper, we explore the validity of human annotations currently employed in the evaluation of document-level quality estimation for <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation (MT)</a>. We demonstrate the degree to which MT system rankings are dependent on weights employed in the construction of the <a href="https://en.wikipedia.org/wiki/Gold_standard">gold standard</a>, before proposing direct human assessment as a valid alternative. Experiments show direct assessment (DA) scores for documents to be highly reliable, achieving a correlation of above 0.9 in a self-replication experiment, in addition to a substantial estimated cost reduction through quality controlled crowd-sourcing. The original <a href="https://en.wikipedia.org/wiki/Gold_standard">gold standard</a> based on <a href="https://en.wikipedia.org/wiki/Post-editing">post-edits</a> incurs a 1020 times greater cost than DA.</abstract>
      <bibkey>graham-etal-2017-improving</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2016">WMT 2016</pwcdataset>
    </paper>
    <paper id="58">
      <title>Neural Machine Translation by Minimising the Bayes-risk with Respect to Syntactic Translation Lattices<fixed-case>B</fixed-case>ayes-risk with Respect to Syntactic Translation Lattices</title>
      <author><first>Felix</first><last>Stahlberg</last></author>
      <author><first>Adrià</first><last>de Gispert</last></author>
      <author><first>Eva</first><last>Hasler</last></author>
      <author><first>Bill</first><last>Byrne</last></author>
      <pages>362–368</pages>
      <url hash="12e0359b">E17-2058</url>
      <abstract>We present a novel scheme to combine <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation (NMT)</a> with traditional <a href="https://en.wikipedia.org/wiki/Statistical_machine_translation">statistical machine translation (SMT)</a>. Our approach borrows ideas from linearised lattice minimum Bayes-risk decoding for <a href="https://en.wikipedia.org/wiki/Signal-to-noise_ratio">SMT</a>. The NMT score is combined with the <a href="https://en.wikipedia.org/wiki/Bayes_risk">Bayes-risk</a> of the <a href="https://en.wikipedia.org/wiki/Translation_(geometry)">translation</a> according the SMT lattice. This makes our approach much more flexible than n-best list or lattice rescoring as the neural decoder is not restricted to the SMT search space. We show an efficient and simple way to integrate risk estimation into the NMT decoder which is suitable for word-level as well as subword-unit-level NMT. We test our method on <a href="https://en.wikipedia.org/wiki/German_language">English-German</a> and <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese-English</a> and report significant gains over lattice rescoring on several data sets for both single and ensembled NMT. The MBR decoder produces entirely new hypotheses far beyond simply rescoring the SMT search space or fixing UNKs in the NMT output.</abstract>
      <bibkey>stahlberg-etal-2017-neural</bibkey>
    </paper>
    <paper id="59">
      <title>Producing Unseen <a href="https://en.wikipedia.org/wiki/Morphology_(biology)">Morphological Variants</a> in Statistical Machine Translation</title>
      <author><first>Matthias</first><last>Huck</last></author>
      <author><first>Aleš</first><last>Tamchyna</last></author>
      <author><first>Ondřej</first><last>Bojar</last></author>
      <author><first>Alexander</first><last>Fraser</last></author>
      <pages>369–375</pages>
      <url hash="d18b23be">E17-2059</url>
      <abstract>Translating into <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphologically rich languages</a> is difficult. Although the coverage of lemmas may be reasonable, many morphological variants can not be learned from the training data. We present a statistical translation system that is able to produce these <a href="https://en.wikipedia.org/wiki/Inflection">inflected word forms</a>. Different from most previous work, we do not separate morphological prediction from <a href="https://en.wikipedia.org/wiki/Lexical_choice">lexical choice</a> into two consecutive steps. Our approach is novel in that it is integrated in decoding and takes advantage of <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context information</a> from both the source language and the target language sides.</abstract>
      <bibkey>huck-etal-2017-producing</bibkey>
    </paper>
    <paper id="60">
      <title>How Grammatical is Character-level Neural Machine Translation? Assessing MT Quality with Contrastive Translation Pairs<fixed-case>MT</fixed-case> Quality with Contrastive Translation Pairs</title>
      <author><first>Rico</first><last>Sennrich</last></author>
      <pages>376–382</pages>
      <url hash="1614bc0a">E17-2060</url>
      <abstract>Analysing translation quality in regards to specific linguistic phenomena has historically been difficult and time-consuming. Neural machine translation has the attractive property that it can produce scores for arbitrary translations, and we propose a novel method to assess how well NMT systems model specific linguistic phenomena such as <a href="https://en.wikipedia.org/wiki/Agreement_(linguistics)">agreement</a> over long distances, the production of novel words, and the faithful translation of polarity. The core idea is that we measure whether a reference translation is more probable under a NMT model than a contrastive translation which introduces a specific type of <a href="https://en.wikipedia.org/wiki/Error">error</a>. We present LingEval97, a large-scale data set of 97000 contrastive translation pairs based on the WMT English-German translation task, with errors automatically created with simple rules. We report results for a number of systems, and find that recently introduced character-level NMT systems perform better at <a href="https://en.wikipedia.org/wiki/Transliteration">transliteration</a> than models with byte-pair encoding (BPE) segmentation, but perform more poorly at morphosyntactic agreement, and translating discontiguous units of meaning.</abstract>
      <bibkey>sennrich-2017-grammatical</bibkey>
      <pwccode url="https://github.com/rsennrich/lingeval97" additional="false">rsennrich/lingeval97</pwccode>
    </paper>
    <paper id="61">
      <title>Neural Machine Translation with Recurrent Attention Modeling</title>
      <author><first>Zichao</first><last>Yang</last></author>
      <author><first>Zhiting</first><last>Hu</last></author>
      <author><first>Yuntian</first><last>Deng</last></author>
      <author><first>Chris</first><last>Dyer</last></author>
      <author><first>Alex</first><last>Smola</last></author>
      <pages>383–387</pages>
      <url hash="cf0130ae">E17-2061</url>
      <abstract>Knowing which words have been attended to in previous time steps while generating a <a href="https://en.wikipedia.org/wiki/Translation">translation</a> is a rich source of information for predicting what words will be attended to in the future. We improve upon the attention model of Bahdanau et al. (2014) by explicitly modeling the relationship between previous and subsequent attention levels for each word using one <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent network</a> per input word. This <a href="https://en.wikipedia.org/wiki/Architecture">architecture</a> easily captures informative features, such as <a href="https://en.wikipedia.org/wiki/Fertility">fertility</a> and regularities in relative distortion. In experiments, we show our parameterization of attention improves translation quality.</abstract>
      <bibkey>yang-etal-2017-neural</bibkey>
    </paper>
    <paper id="62">
      <title>Inducing Embeddings for Rare and Unseen Words by Leveraging Lexical Resources</title>
      <author><first>Mohammad Taher</first><last>Pilehvar</last></author>
      <author><first>Nigel</first><last>Collier</last></author>
      <pages>388–393</pages>
      <url hash="293cb21e">E17-2062</url>
      <abstract>We put forward an approach that exploits the knowledge encoded in lexical resources in order to induce representations for words that were not encountered frequently during training. Our approach provides an advantage over the past work in that it enables vocabulary expansion not only for <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological variations</a>, but also for infrequent domain specific terms. We performed evaluations in different settings, showing that the technique can provide consistent improvements on multiple benchmarks across domains.</abstract>
      <bibkey>pilehvar-collier-2017-inducing</bibkey>
    </paper>
    <paper id="63">
      <title>Large-scale evaluation of dependency-based DSMs : Are they worth the effort?<fixed-case>DSM</fixed-case>s: Are they worth the effort?</title>
      <author><first>Gabriella</first><last>Lapesa</last></author>
      <author><first>Stefan</first><last>Evert</last></author>
      <pages>394–400</pages>
      <url hash="163566e5">E17-2063</url>
      <abstract>This paper presents a large-scale evaluation study of dependency-based distributional semantic models. We evaluate dependency-filtered and dependency-structured DSMs in a number of standard semantic similarity tasks, systematically exploring their parameter space in order to give them a fair shot against window-based models. Our results show that properly tuned window-based DSMs still outperform the dependency-based models in most tasks. There appears to be little need for the language-dependent resources and <a href="https://en.wikipedia.org/wiki/Computational_cost">computational cost</a> associated with <a href="https://en.wikipedia.org/wiki/Syntactic_analysis">syntactic analysis</a>.</abstract>
      <bibkey>lapesa-evert-2017-large</bibkey>
    </paper>
    <paper id="64">
      <title>How Well Can We Predict Hypernyms from Word Embeddings? A Dataset-Centric Analysis</title>
      <author><first>Ivan</first><last>Sanchez</last></author>
      <author><first>Sebastian</first><last>Riedel</last></author>
      <pages>401–407</pages>
      <url hash="30261370">E17-2064</url>
      <abstract>One key property of <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> currently under study is their capacity to encode <a href="https://en.wikipedia.org/wiki/Hypernymy">hypernymy</a>. Previous works have used <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised models</a> to recover hypernymy structures from <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a>. However, the overall results do not clearly show how well we can recover such <a href="https://en.wikipedia.org/wiki/Mathematical_structure">structures</a>. We conduct the first dataset-centric analysis that shows how only the Baroni dataset provides consistent results. We empirically show that a possible reason for its good performance is its alignment to dimensions specific of <a href="https://en.wikipedia.org/wiki/Hypernymy">hypernymy</a> : generality and similarity</abstract>
      <bibkey>sanchez-riedel-2017-well</bibkey>
    </paper>
    <paper id="65">
      <title>Cross-Lingual Syntactically Informed Distributed Word Representations</title>
      <author><first>Ivan</first><last>Vulić</last></author>
      <pages>408–414</pages>
      <url hash="a1eff5a2">E17-2065</url>
      <abstract>We develop a novel cross-lingual word representation model which injects syntactic information through dependency-based contexts into a shared cross-lingual word vector space. The model, termed CL-DepEmb, is based on the following assumptions : (1) dependency relations are largely language-independent, at least for related languages and prominent dependency links such as direct objects, as evidenced by the Universal Dependencies project ; (2) word translation equivalents take similar grammatical roles in a sentence and are therefore substitutable within their syntactic contexts. Experiments with several language pairs on word similarity and bilingual lexicon induction, two fundamental semantic tasks emphasising <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a>, suggest the usefulness of the proposed syntactically informed cross-lingual word vector spaces. Improvements are observed in both tasks over standard cross-lingual offline mapping baselines trained using the same setup and an equal level of bilingual supervision.</abstract>
      <bibkey>vulic-2017-cross</bibkey>
    </paper>
    <paper id="66">
      <title>Using Word Embedding for Cross-Language Plagiarism Detection</title>
      <author><first>Jérémy</first><last>Ferrero</last></author>
      <author><first>Laurent</first><last>Besacier</last></author>
      <author><first>Didier</first><last>Schwab</last></author>
      <author><first>Frédéric</first><last>Agnès</last></author>
      <pages>415–421</pages>
      <url hash="3e0bf0c3">E17-2066</url>
      <abstract>This paper proposes to use distributed representation of words (word embeddings) in cross-language textual similarity detection. The main contributions of this paper are the following : (a) we introduce new cross-language similarity detection methods based on distributed representation of words ; (b) we combine the different methods proposed to verify their complementarity and finally obtain an overall F1 score of 89.15 % for English-French similarity detection at chunk level (88.5 % at sentence level) on a very challenging corpus.</abstract>
      <attachment type="presentation" hash="37c62a21">E17-2066.Presentation.pdf</attachment>
      <bibkey>ferrero-etal-2017-using</bibkey>
    </paper>
    <paper id="67">
      <title>The Interplay of <a href="https://en.wikipedia.org/wiki/Semantics">Semantics</a> and <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">Morphology</a> in Word Embeddings</title>
      <author><first>Oded</first><last>Avraham</last></author>
      <author><first>Yoav</first><last>Goldberg</last></author>
      <pages>422–426</pages>
      <url hash="3dc2dbb7">E17-2067</url>
      <abstract>We explore the ability of word embeddings to capture both semantic and morphological similarity, as affected by the different types of linguistic properties (surface form, <a href="https://en.wikipedia.org/wiki/Lemma_(morphology)">lemma</a>, morphological tag) used to compose the representation of each word. We train several <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>, where each uses a different subset of these properties to compose its <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">representations</a>. By evaluating the models on semantic and morphological measures, we reveal some useful insights on the relationship between <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> and <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphology</a>.</abstract>
      <bibkey>avraham-goldberg-2017-interplay</bibkey>
      <pwccode url="https://github.com/oavraham1/prop2vec" additional="false">oavraham1/prop2vec</pwccode>
    </paper>
    <paper id="68">
      <title>Bag of Tricks for Efficient Text Classification</title>
      <author><first>Armand</first><last>Joulin</last></author>
      <author><first>Edouard</first><last>Grave</last></author>
      <author><first>Piotr</first><last>Bojanowski</last></author>
      <author><first>Tomas</first><last>Mikolov</last></author>
      <pages>427–431</pages>
      <url hash="0e826023">E17-2068</url>
      <abstract>This paper explores a simple and efficient <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a> for <a href="https://en.wikipedia.org/wiki/Text_classification">text classification</a>. Our experiments show that our fast text classifier fastText is often on par with deep learning classifiers in terms of accuracy, and many orders of magnitude faster for training and evaluation. We can train <a href="https://en.wikipedia.org/wiki/FastText">fastText</a> on more than one billion words in less than ten minutes using a standard <a href="https://en.wikipedia.org/wiki/Multi-core_processor">multicore CPU</a>, and classify half a million sentences among 312 K classes in less than a minute.</abstract>
      <bibkey>joulin-etal-2017-bag</bibkey>
      <pwccode url="https://github.com/facebookresearch/fastText" additional="true">facebookresearch/fastText</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/ag-news">AG News</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/dbpedia">DBpedia</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/yfcc100m">YFCC100M</pwcdataset>
    </paper>
    <paper id="69">
      <title>Pulling Out the Stops : Rethinking Stopword Removal for Topic Models</title>
      <author><first>Alexandra</first><last>Schofield</last></author>
      <author><first>Måns</first><last>Magnusson</last></author>
      <author><first>David</first><last>Mimno</last></author>
      <pages>432–436</pages>
      <url hash="3ab2b20e">E17-2069</url>
      <abstract>It is often assumed that <a href="https://en.wikipedia.org/wiki/Topic_model">topic models</a> benefit from the use of a manually curated stopword list. Constructing this <a href="https://en.wikipedia.org/wiki/List_(abstract_data_type)">list</a> is time-consuming and often subject to user judgments about what kinds of words are important to the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> and the application. Although stopword removal clearly affects which word types appear as most probable terms in topics, we argue that this improvement is superficial, and that topic inference benefits little from the practice of removing <a href="https://en.wikipedia.org/wiki/Stopword">stopwords</a> beyond very frequent terms. Removing corpus-specific stopwords after model inference is more transparent and produces similar results to removing those words prior to <a href="https://en.wikipedia.org/wiki/Statistical_inference">inference</a>.</abstract>
      <bibkey>schofield-etal-2017-pulling</bibkey>
    </paper>
    <paper id="70">
      <title>Measuring Topic Coherence through Optimal Word Buckets</title>
      <author><first>Nitin</first><last>Ramrakhiyani</last></author>
      <author><first>Sachin</first><last>Pawar</last></author>
      <author><first>Swapnil</first><last>Hingmire</last></author>
      <author><first>Girish</first><last>Palshikar</last></author>
      <pages>437–442</pages>
      <url hash="71fe0ec8">E17-2070</url>
      <abstract>Measuring topic quality is essential for scoring the learned topics and their subsequent use in <a href="https://en.wikipedia.org/wiki/Information_retrieval">Information Retrieval</a> and <a href="https://en.wikipedia.org/wiki/Text_classification">Text classification</a>. To measure quality of Latent Dirichlet Allocation (LDA) based topics learned from text, we propose a novel approach based on grouping of topic words into buckets (TBuckets). A single large bucket signifies a single <a href="https://en.wikipedia.org/wiki/Coherence_(linguistics)">coherent theme</a>, in turn indicating high <a href="https://en.wikipedia.org/wiki/Coherence_(linguistics)">topic coherence</a>. TBuckets uses word embeddings of topic words and employs <a href="https://en.wikipedia.org/wiki/Singular_value_decomposition">singular value decomposition (SVD)</a> and Integer Linear Programming based optimization to create coherent word buckets. TBuckets outperforms the state-of-the-art techniques when evaluated using 3 publicly available datasets and on another one proposed in this paper.</abstract>
      <bibkey>ramrakhiyani-etal-2017-measuring</bibkey>
    </paper>
    <paper id="71">
      <title>A Hybrid CNN-RNN Alignment Model for Phrase-Aware Sentence Classification<fixed-case>CNN</fixed-case>-<fixed-case>RNN</fixed-case> Alignment Model for Phrase-Aware Sentence Classification</title>
      <author><first>Shiou Tian</first><last>Hsu</last></author>
      <author><first>Changsung</first><last>Moon</last></author>
      <author><first>Paul</first><last>Jones</last></author>
      <author><first>Nagiza</first><last>Samatova</last></author>
      <pages>443–449</pages>
      <url hash="1e235c3a">E17-2071</url>
      <abstract>The success of sentence classification often depends on understanding both the syntactic and semantic properties of <a href="https://en.wikipedia.org/wiki/Phrase">word-phrases</a>. Recent progress on this task has been based on exploiting the <a href="https://en.wikipedia.org/wiki/Grammar">grammatical structure</a> of sentences but often this structure is difficult to parse and noisy. In this paper, we propose a structure-independent ‘Gated Representation Alignment’ (GRA) model that blends a phrase-focused Convolutional Neural Network (CNN) approach with sequence-oriented Recurrent Neural Network (RNN). Our novel alignment mechanism allows the RNN to selectively include phrase information in a word-by-word sentence representation, and to do this without awareness of the <a href="https://en.wikipedia.org/wiki/Syntax">syntactic structure</a>. An empirical evaluation of GRA shows higher prediction accuracy (up to 4.6 %) of fine-grained sentiment ratings, when compared to other structure-independent baselines. We also show comparable results to several structure-dependent methods. Finally, we analyzed the effect of our alignment mechanism and found that this is critical to the effectiveness of the CNN-RNN hybrid.</abstract>
      <bibkey>hsu-etal-2017-hybrid</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="72">
      <title>Multivariate Gaussian Document Representation from Word Embeddings for Text Categorization<fixed-case>G</fixed-case>aussian Document Representation from Word Embeddings for Text Categorization</title>
      <author><first>Giannis</first><last>Nikolentzos</last></author>
      <author><first>Polykarpos</first><last>Meladianos</last></author>
      <author><first>François</first><last>Rousseau</last></author>
      <author><first>Yannis</first><last>Stavrakas</last></author>
      <author><first>Michalis</first><last>Vazirgiannis</last></author>
      <pages>450–455</pages>
      <url hash="4f7dd334">E17-2072</url>
      <abstract>Recently, there has been a lot of activity in learning distributed representations of words in <a href="https://en.wikipedia.org/wiki/Vector_space">vector spaces</a>. Although there are <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> capable of learning high-quality distributed representations of words, how to generate <a href="https://en.wikipedia.org/wiki/Vector_graphics">vector representations</a> of the same quality for phrases or documents still remains a challenge. In this paper, we propose to model each document as a multivariate Gaussian distribution based on the distributed representations of its words. We then measure the <a href="https://en.wikipedia.org/wiki/Similarity_measure">similarity</a> between two documents based on the similarity of their distributions. Experiments on eight standard text categorization datasets demonstrate the effectiveness of the proposed approach in comparison with state-of-the-art methods.</abstract>
      <bibkey>nikolentzos-etal-2017-multivariate</bibkey>
    </paper>
    <paper id="73">
      <title>Derivation of Document Vectors from Adaptation of LSTM Language Model<fixed-case>LSTM</fixed-case> Language Model</title>
      <author><first>Wei</first><last>Li</last></author>
      <author><first>Brian</first><last>Mak</last></author>
      <pages>456–461</pages>
      <url hash="1a14fffe">E17-2073</url>
      <abstract>In many natural language processing (NLP) tasks, a document is commonly modeled as a <a href="https://en.wikipedia.org/wiki/Bag_of_words">bag of words</a> using the term frequency-inverse document frequency (TF-IDF) vector. One major shortcoming of the frequency-based TF-IDF feature vector is that it ignores word orders that carry syntactic and semantic relationships among the words in a document. This paper proposes a novel distributed vector representation of a document, which will be labeled as DV-LSTM, and is derived from the result of adapting a long short-term memory recurrent neural network language model by the document. DV-LSTM is expected to capture some high-level sequential information in the document, which other current document representations fail to do. It was evaluated in document genre classification in the <a href="https://en.wikipedia.org/wiki/Brown_Corpus">Brown Corpus</a> and the BNC Baby Corpus. The results show that DV-LSTM significantly outperforms TF-IDF vector and paragraph vector (PV-DM) in most cases, and their combinations may further improve the classification performance.</abstract>
      <bibkey>li-mak-2017-derivation</bibkey>
    </paper>
    <paper id="74">
      <title>Real-Time Keyword Extraction from Conversations</title>
      <author><first>Polykarpos</first><last>Meladianos</last></author>
      <author><first>Antoine</first><last>Tixier</last></author>
      <author><first>Ioannis</first><last>Nikolentzos</last></author>
      <author><first>Michalis</first><last>Vazirgiannis</last></author>
      <pages>462–467</pages>
      <url hash="4a36f322">E17-2074</url>
      <abstract>We introduce a novel <a href="https://en.wikipedia.org/wiki/Scientific_method">method</a> to extract <a href="https://en.wikipedia.org/wiki/Index_term">keywords</a> from meeting speech in real-time. Our approach builds on the graph-of-words representation of text and leverages the k-core decomposition algorithm and properties of submodular functions. We outperform multiple baselines in a real-time scenario emulated from the AMI and ICSI meeting corpora. Evaluation is conducted against both extractive and abstractive gold standard using two standard <a href="https://en.wikipedia.org/wiki/Performance_metric">performance metrics</a> and a newer one based on <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>.</abstract>
      <bibkey>meladianos-etal-2017-real</bibkey>
    </paper>
    <paper id="77">
      <title>Evaluating Persuasion Strategies and Deep Reinforcement Learning methods for Negotiation Dialogue agents</title>
      <author><first>Simon</first><last>Keizer</last></author>
      <author><first>Markus</first><last>Guhe</last></author>
      <author><first>Heriberto</first><last>Cuayáhuitl</last></author>
      <author><first>Ioannis</first><last>Efstathiou</last></author>
      <author><first>Klaus-Peter</first><last>Engelbrecht</last></author>
      <author><first>Mihai</first><last>Dobre</last></author>
      <author><first>Alex</first><last>Lascarides</last></author>
      <author><first>Oliver</first><last>Lemon</last></author>
      <pages>480–484</pages>
      <url hash="03f5791f">E17-2077</url>
      <abstract>In this paper we present a comparative evaluation of various <a href="https://en.wikipedia.org/wiki/Negotiation">negotiation strategies</a> within an online version of the game Settlers of Catan. The comparison is based on human subjects playing games against artificial game-playing agents (‘bots’) which implement different negotiation dialogue strategies, using a chat dialogue interface to negotiate trades. Our results suggest that a negotiation strategy that uses <a href="https://en.wikipedia.org/wiki/Persuasion">persuasion</a>, as well as a strategy that is trained from data using Deep Reinforcement Learning, both lead to an improved win rate against humans, compared to previous rule-based and supervised learning baseline dialogue negotiators.</abstract>
      <bibkey>keizer-etal-2017-evaluating</bibkey>
    </paper>
    <paper id="78">
      <title>Unsupervised Dialogue Act Induction using Gaussian Mixtures<fixed-case>G</fixed-case>aussian Mixtures</title>
      <author><first>Tomáš</first><last>Brychcín</last></author>
      <author><first>Pavel</first><last>Král</last></author>
      <pages>485–490</pages>
      <url hash="bdccb948">E17-2078</url>
      <abstract>This paper introduces a new <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised approach</a> for dialogue act induction. Given the sequence of dialogue utterances, the task is to assign them the labels representing their function in the dialogue. Utterances are represented as real-valued vectors encoding their meaning. We model the <a href="https://en.wikipedia.org/wiki/Dialogue">dialogue</a> as <a href="https://en.wikipedia.org/wiki/Hidden_Markov_model">Hidden Markov model</a> with emission probabilities estimated by Gaussian mixtures. We use <a href="https://en.wikipedia.org/wiki/Gibbs_sampling">Gibbs sampling</a> for <a href="https://en.wikipedia.org/wiki/Posterior_probability">posterior inference</a>. We present the results on the standard Switchboard-DAMSL corpus. Our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> achieves promising results compared with strong supervised baselines and outperforms other unsupervised algorithms.</abstract>
      <bibkey>brychcin-kral-2017-unsupervised</bibkey>
    </paper>
    <paper id="79">
      <title>Grounding Language by Continuous Observation of Instruction Following</title>
      <author><first>Ting</first><last>Han</last></author>
      <author><first>David</first><last>Schlangen</last></author>
      <pages>491–496</pages>
      <url hash="d7ccfaa1">E17-2079</url>
      <abstract>Grounded semantics is typically learnt from utterance-level meaning representations (e.g., successful database retrievals, denoted objects in <a href="https://en.wikipedia.org/wiki/Digital_image">images</a>, moves in a game). We explore learning word and utterance meanings by continuous observation of the actions of an instruction follower (IF). While an instruction giver (IG) provided a verbal description of a configuration of objects, IF recreated it using a <a href="https://en.wikipedia.org/wiki/Graphical_user_interface">GUI</a>. Aligning these GUI actions to sub-utterance chunks allows a simple <a href="https://en.wikipedia.org/wiki/Maximum_entropy_model">maximum entropy model</a> to associate them as chunk meaning better than just providing it with the utterance-final configuration. This shows that <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> useful for incremental (word-by-word) application, as required in natural dialogue, might also be better acquired from incremental settings.</abstract>
      <bibkey>han-schlangen-2017-grounding</bibkey>
    </paper>
    <paper id="81">
      <title>Efficient, Compositional, Order-sensitive n-gram Embeddings</title>
      <author><first>Adam</first><last>Poliak</last></author>
      <author><first>Pushpendre</first><last>Rastogi</last></author>
      <author><first>M. Patrick</first><last>Martin</last></author>
      <author><first>Benjamin</first><last>Van Durme</last></author>
      <pages>503–508</pages>
      <url hash="6a3da8bf">E17-2081</url>
      <abstract>We propose ECO : a new way to generate embeddings for phrases that is Efficient, Compositional, and Order-sensitive. Our method creates decompositional embeddings for words offline and combines them to create new <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> for phrases in real time. Unlike other approaches, ECO can create <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> for phrases not seen during training. We evaluate ECO on supervised and unsupervised tasks and demonstrate that creating phrase embeddings that are sensitive to <a href="https://en.wikipedia.org/wiki/Word_order">word order</a> can help downstream tasks.</abstract>
      <bibkey>poliak-etal-2017-efficient</bibkey>
      <pwccode url="https://github.com/azpoliak/eco" additional="false">azpoliak/eco</pwccode>
    </paper>
    <paper id="82">
      <title>Integrating Semantic Knowledge into <a href="https://en.wikipedia.org/wiki/Lexical_analysis">Lexical Embeddings</a> Based on Information Content Measurement</title>
      <author><first>Hsin-Yang</first><last>Wang</last></author>
      <author><first>Wei-Yun</first><last>Ma</last></author>
      <pages>509–515</pages>
      <url hash="f143f7e4">E17-2082</url>
      <abstract>Distributional word representations are widely used in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP tasks</a>. These <a href="https://en.wikipedia.org/wiki/Representation_(arts)">representations</a> are based on an assumption that words with a similar context tend to have a similar meaning. To improve the quality of the context-based embeddings, many researches have explored how to make full use of existing lexical resources. In this paper, we argue that while we incorporate the prior knowledge with context-based embeddings, words with different occurrences should be treated differently. Therefore, we propose to rely on the measurement of information content to control the degree of applying prior knowledge into context-based embeddings-different words would have different learning rates when adjusting their embeddings. In the result, we demonstrate that our <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> get significant improvements on two different tasks : <a href="https://en.wikipedia.org/wiki/Similarity_measure">Word Similarity</a> and <a href="https://en.wikipedia.org/wiki/Analogical_reasoning">Analogical Reasoning</a>.</abstract>
      <bibkey>wang-ma-2017-integrating</bibkey>
      <pwccode url="https://github.com/hywangntut/KBE" additional="false">hywangntut/KBE</pwccode>
    </paper>
    <paper id="83">
      <title>Improving Neural Knowledge Base Completion with Cross-Lingual Projections</title>
      <author><first>Patrick</first><last>Klein</last></author>
      <author><first>Simone Paolo</first><last>Ponzetto</last></author>
      <author><first>Goran</first><last>Glavaš</last></author>
      <pages>516–522</pages>
      <url hash="3518bd5d">E17-2083</url>
      <abstract>In this paper we present a cross-lingual extension of a neural tensor network model for knowledge base completion. We exploit multilingual synsets from <a href="https://en.wikipedia.org/wiki/BabelNet">BabelNet</a> to translate English triples to other languages and then augment the reference knowledge base with cross-lingual triples. We project monolingual embeddings of different languages to a shared multilingual space and use them for <a href="https://en.wikipedia.org/wiki/Network_topology">network initialization</a> (i.e., as initial concept embeddings). We then train the <a href="https://en.wikipedia.org/wiki/Computer_network">network</a> with triples from the cross-lingually augmented knowledge base. Results on WordNet link prediction show that leveraging cross-lingual information yields significant gains over exploiting only monolingual triples.</abstract>
      <bibkey>klein-etal-2017-improving</bibkey>
    </paper>
    <paper id="84">
      <title>Modelling metaphor with attribute-based semantics</title>
      <author><first>Luana</first><last>Bulat</last></author>
      <author><first>Stephen</first><last>Clark</last></author>
      <author><first>Ekaterina</first><last>Shutova</last></author>
      <pages>523–528</pages>
      <url hash="cd989416">E17-2084</url>
      <abstract>One of the key problems in computational metaphor modelling is finding the optimal level of abstraction of semantic representations, such that these are able to capture and generalise metaphorical mechanisms. In this paper we present the first metaphor identification method that uses <a href="https://en.wikipedia.org/wiki/Representation_(mathematics)">representations</a> constructed from <a href="https://en.wikipedia.org/wiki/Norm_(philosophy)">property norms</a>. Such <a href="https://en.wikipedia.org/wiki/Social_norm">norms</a> have been previously shown to provide a cognitively plausible representation of concepts in terms of <a href="https://en.wikipedia.org/wiki/Semantics">semantic properties</a>. Our results demonstrate that such property-based semantic representations provide a suitable model of cross-domain knowledge projection in metaphors, outperforming standard distributional models on a metaphor identification task.</abstract>
      <bibkey>bulat-etal-2017-modelling</bibkey>
    </paper>
    <paper id="85">
      <title>When a Red Herring in Not a Red Herring : Using Compositional Methods to Detect Non-Compositional Phrases</title>
      <author><first>Julie</first><last>Weeds</last></author>
      <author><first>Thomas</first><last>Kober</last></author>
      <author><first>Jeremy</first><last>Reffin</last></author>
      <author><first>David</first><last>Weir</last></author>
      <pages>529–534</pages>
      <url hash="b6430d35">E17-2085</url>
      <abstract>Non-compositional phrases such as <a href="https://en.wikipedia.org/wiki/Red_herring">red herring</a> and weakly compositional phrases such as <a href="https://en.wikipedia.org/wiki/Spelling_bee">spelling bee</a> are an integral part of <a href="https://en.wikipedia.org/wiki/Natural_language">natural language</a> (Sag, 2002). They are also the phrases that are difficult, or even impossible, for good compositional distributional models of semantics. Compositionality detection therefore provides a good testbed for <a href="https://en.wikipedia.org/wiki/Compositing">compositional methods</a>. We compare an integrated compositional distributional approach, using sparse high dimensional representations, with the ad-hoc compositional approach of applying simple composition operations to state-of-the-art neural embeddings.<i>red herring</i> and weakly compositional phrases such as <i>spelling bee</i> are an integral part of natural language (Sag, 2002).  They are also the phrases that are difficult, or even impossible, for good compositional distributional models of semantics. Compositionality detection therefore provides a good testbed for compositional methods. We compare an integrated compositional distributional approach, using sparse high dimensional representations, with the ad-hoc compositional approach of applying simple composition operations to state-of-the-art neural embeddings.</abstract>
      <bibkey>weeds-etal-2017-red</bibkey>
    </paper>
    <paper id="86">
      <title>Applying Multi-Sense Embeddings for German Verbs to Determine Semantic Relatedness and to Detect Non-Literal Language<fixed-case>G</fixed-case>erman Verbs to Determine Semantic Relatedness and to Detect Non-Literal Language</title>
      <author><first>Maximilian</first><last>Köper</last></author>
      <author><first>Sabine</first><last>Schulte im Walde</last></author>
      <pages>535–542</pages>
      <url hash="1c6d8693">E17-2086</url>
      <abstract>Up to date, the majority of <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational models</a> still determines the <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic relatedness</a> between words (or larger linguistic units) on the type level. In this paper, we compare and extend multi-sense embeddings, in order to model and utilise <a href="https://en.wikipedia.org/wiki/Word_sense">word senses</a> on the token level. We focus on the challenging class of complex verbs, and evaluate the model variants on various semantic tasks : semantic classification ; predicting compositionality ; and detecting non-literal language usage. While there is no overall best model, all models significantly outperform a word2vec single-sense skip baseline, thus demonstrating the need to distinguish between <a href="https://en.wikipedia.org/wiki/Word_sense">word senses</a> in a distributional semantic model.</abstract>
      <bibkey>koper-schulte-im-walde-2017-applying</bibkey>
    </paper>
    <paper id="87">
      <title>Negative Sampling Improves Hypernymy Extraction Based on Projection Learning</title>
      <author><first>Dmitry</first><last>Ustalov</last></author>
      <author><first>Nikolay</first><last>Arefyev</last></author>
      <author><first>Chris</first><last>Biemann</last></author>
      <author><first>Alexander</first><last>Panchenko</last></author>
      <pages>543–550</pages>
      <url hash="56b46ff5">E17-2087</url>
      <abstract>We present a new approach to extraction of hypernyms based on projection learning and <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>. In contrast to <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification-based approaches</a>, <a href="https://en.wikipedia.org/wiki/Projection_(linear_algebra)">projection-based methods</a> require no candidate <a href="https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy">hyponym-hypernym pairs</a>. While it is natural to use both positive and negative training examples in supervised relation extraction, the impact of positive examples on hypernym prediction was not studied so far. In this paper, we show that explicit negative examples used for <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">regularization</a> of the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> significantly improve performance compared to the state-of-the-art approach of Fu et al. (2014) on three <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> from different languages.</abstract>
      <bibkey>ustalov-etal-2017-negative</bibkey>
      <pwccode url="https://github.com/nlpub/projlearn" additional="false">nlpub/projlearn</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/evalution">EVALution</pwcdataset>
    </paper>
    <paper id="88">
      <title>A Dataset for Multi-Target Stance Detection</title>
      <author><first>Parinaz</first><last>Sobhani</last></author>
      <author><first>Diana</first><last>Inkpen</last></author>
      <author><first>Xiaodan</first><last>Zhu</last></author>
      <pages>551–557</pages>
      <url hash="d2fae70b">E17-2088</url>
      <abstract>Current <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> for stance classification often treat each target independently, but in many <a href="https://en.wikipedia.org/wiki/Application_software">applications</a>, there exist natural dependencies among targets, e.g., stance towards two or more politicians in an election or towards several brands of the same product. In this paper, we focus on the problem of multi-target stance detection. We present a new <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> that we built for this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. Furthermore, We experiment with several neural models on the dataset and show that they are more effective in jointly modeling the overall position towards two related targets compared to <a href="https://en.wikipedia.org/wiki/Independence_(probability_theory)">independent predictions</a> and other models of joint learning, such as cascading classification. We make the new <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> publicly available, in order to facilitate further research in multi-target stance classification.</abstract>
      <bibkey>sobhani-etal-2017-dataset</bibkey>
    </paper>
    <paper id="90">
      <title>Predicting Emotional Word Ratings using Distributional Representations and Signed Clustering</title>
      <author><first>João</first><last>Sedoc</last></author>
      <author><first>Daniel</first><last>Preoţiuc-Pietro</last></author>
      <author><first>Lyle</first><last>Ungar</last></author>
      <pages>564–571</pages>
      <url hash="e5e3dda5">E17-2090</url>
      <abstract>Inferring the emotional content of words is important for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">text-based sentiment analysis</a>, dialogue systems and <a href="https://en.wikipedia.org/wiki/Psycholinguistics">psycholinguistics</a>, but word ratings are expensive to collect at scale and across languages or domains. We develop a method that automatically extends word-level ratings to unrated words using signed clustering of vector space word representations along with affect ratings. We use our method to determine a word’s valence and arousal, which determine its position on the circumplex model of affect, the most popular dimensional model of emotion. Our method achieves superior out-of-sample word rating prediction on both affective dimensions across three different languages when compared to state-of-the-art word similarity based methods. Our method can assist building word ratings for new languages and improve downstream tasks such as <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> and <a href="https://en.wikipedia.org/wiki/Emotion_detection">emotion detection</a>.</abstract>
      <bibkey>sedoc-etal-2017-predicting</bibkey>
    </paper>
    <paper id="91">
      <title>Attention Modeling for Targeted Sentiment</title>
      <author><first>Jiangming</first><last>Liu</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <pages>572–577</pages>
      <url hash="3d6d0242">E17-2091</url>
      <abstract>Neural network models have been used for target-dependent sentiment analysis. Previous work focus on learning a target specific representation for a given input sentence which is used for <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a>. However, they do not explicitly model the contribution of each word in a sentence with respect to targeted sentiment polarities. We investigate an attention model to this end. In particular, a vanilla LSTM model is used to induce an attention value of the whole sentence. The <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> is further extended to differentiate left and right contexts given a certain target following previous work. Results show that by using <a href="https://en.wikipedia.org/wiki/Attention">attention</a> to model the contribution of each word with respect to the target, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> gives significantly improved results over two standard <a href="https://en.wikipedia.org/wiki/Benchmarking">benchmarks</a>. We report the best <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> for this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>.</abstract>
      <bibkey>liu-zhang-2017-attention</bibkey>
    </paper>
    <paper id="92">
      <title>EmoBank : Studying the Impact of Annotation Perspective and Representation Format on Dimensional Emotion Analysis<fixed-case>E</fixed-case>mo<fixed-case>B</fixed-case>ank: Studying the Impact of Annotation Perspective and Representation Format on Dimensional Emotion Analysis</title>
      <author><first>Sven</first><last>Buechel</last></author>
      <author><first>Udo</first><last>Hahn</last></author>
      <pages>578–585</pages>
      <url hash="c5365d3a">E17-2092</url>
      <abstract>We describe EmoBank, a corpus of 10k English sentences balancing multiple genres, which we annotated with dimensional emotion metadata in the Valence-Arousal-Dominance (VAD) representation format. EmoBank excels with a bi-perspectival and bi-representational design. On the one hand, we distinguish between writer’s and reader’s emotions, on the other hand, a subset of the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> complements dimensional VAD annotations with categorical ones based on Basic Emotions. We find evidence for the supremacy of the reader’s perspective in terms of IAA and rating intensity, and achieve close-to-human performance when mapping between dimensional and categorical formats.</abstract>
      <bibkey>buechel-hahn-2017-emobank</bibkey>
      <pwccode url="https://github.com/JULIELab/EmoBank" additional="false">JULIELab/EmoBank</pwccode>
    </paper>
    <paper id="93">
      <title>Structural Attention Neural Networks for improved <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a></title>
      <author><first>Filippos</first><last>Kokkinos</last></author>
      <author><first>Alexandros</first><last>Potamianos</last></author>
      <pages>586–591</pages>
      <url hash="f67ed8a9">E17-2093</url>
      <abstract>We introduce a tree-structured attention neural network for <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentences</a> and small phrases and apply it to the problem of sentiment classification. Our model expands the current recursive models by incorporating structural information around a node of a syntactic tree using both bottom-up and top-down information propagation. Also, the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> utilizes structural attention to identify the most salient representations during the construction of the <a href="https://en.wikipedia.org/wiki/Syntactic_tree">syntactic tree</a>.</abstract>
      <bibkey>kokkinos-potamianos-2017-structural</bibkey>
    </paper>
    <paper id="94">
      <title>Ranking Convolutional Recurrent Neural Networks for Purchase Stage Identification on Imbalanced Twitter Data<fixed-case>T</fixed-case>witter Data</title>
      <author><first>Heike</first><last>Adel</last></author>
      <author><first>Francine</first><last>Chen</last></author>
      <author><first>Yan-Ying</first><last>Chen</last></author>
      <pages>592–598</pages>
      <url hash="28daf44d">E17-2094</url>
      <abstract>Users often use <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> to share their interest in products. We propose to identify purchase stages from Twitter data following the AIDA model (Awareness, Interest, Desire, Action). In particular, we define the task of classifying the purchase stage of each tweet in a user’s tweet sequence. We introduce RCRNN, a Ranking Convolutional Recurrent Neural Network which computes tweet representations using convolution over word embeddings and models a tweet sequence with gated recurrent units. Also, we consider various methods to cope with the imbalanced label distribution in our data and show that a ranking layer outperforms class weights.</abstract>
      <bibkey>adel-etal-2017-ranking</bibkey>
    </paper>
    <paper id="96">
      <title>Reranking Translation Candidates Produced by Several Bilingual Word Similarity Sources</title>
      <author><first>Laurent</first><last>Jakubina</last></author>
      <author><first>Phillippe</first><last>Langlais</last></author>
      <pages>605–611</pages>
      <url hash="7bd5e73c">E17-2096</url>
      <abstract>We investigate the <a href="https://en.wikipedia.org/wiki/Ranking">reranking</a> of the output of several distributional approaches on the Bilingual Lexicon Induction task. We show that reranking an n-best list produced by any of those approaches leads to very substantial improvements. We further demonstrate that combining several n-best lists by <a href="https://en.wikipedia.org/wiki/Ranking">reranking</a> is an effective way of further boosting performance.</abstract>
      <bibkey>jakubina-langlais-2017-reranking</bibkey>
    </paper>
    <paper id="97">
      <title>Lexicalized Reordering for Left-to-Right Hierarchical Phrase-based Translation</title>
      <author><first>Maryam</first><last>Siahbani</last></author>
      <author><first>Anoop</first><last>Sarkar</last></author>
      <pages>612–618</pages>
      <url hash="d924f526">E17-2097</url>
      <abstract>Phrase-based and hierarchical phrase-based (Hiero) translation models differ radically in the way reordering is modeled. Lexicalized reordering models play an important role in phrase-based MT and such <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> have been added to CKY-based decoders for Hiero. Watanabe et al. (2006) proposed a promising decoding algorithm for Hiero (LR-Hiero) that visits input spans in arbitrary order and produces the translation in left to right (LR) order which leads to far fewer language model calls and leads to a considerable speedup in decoding. We introduce a novel shift-reduce algorithm to LR-Hiero to decode with our lexicalized reordering model (LRM) and show that it improves translation quality for Czech-English, Chinese-English and German-English.</abstract>
      <bibkey>siahbani-sarkar-2017-lexicalized</bibkey>
    </paper>
    <paper id="99">
      <title>Addressing Problems across Linguistic Levels in SMT : Combining Approaches to Model <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">Morphology</a>, <a href="https://en.wikipedia.org/wiki/Syntax">Syntax</a> and Lexical Choice<fixed-case>SMT</fixed-case>: Combining Approaches to Model Morphology, Syntax and Lexical Choice</title>
      <author><first>Marion</first><last>Weller-Di Marco</last></author>
      <author><first>Alexander</first><last>Fraser</last></author>
      <author><first>Sabine</first><last>Schulte im Walde</last></author>
      <pages>625–630</pages>
      <url hash="c012935f">E17-2099</url>
      <abstract>Many errors in phrase-based SMT can be attributed to problems on three linguistic levels : <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological complexity</a> in the target language, structural differences and <a href="https://en.wikipedia.org/wiki/Lexical_choice">lexical choice</a>. We explore combinations of linguistically motivated approaches to address these problems in English-to-German SMT and show that they are complementary to one another, but also that the popular verbal pre-ordering can cause problems on the morphological and lexical level. A discriminative classifier can overcome these problems, in particular when enriching standard lexical features with <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">features</a> geared towards verbal inflection.</abstract>
      <bibkey>weller-di-marco-etal-2017-addressing</bibkey>
    </paper>
    <paper id="100">
      <title>Machine Translation of Spanish Personal and Possessive Pronouns Using Anaphora Probabilities<fixed-case>S</fixed-case>panish Personal and Possessive Pronouns Using Anaphora Probabilities</title>
      <author><first>Ngoc Quang</first><last>Luong</last></author>
      <author><first>Andrei</first><last>Popescu-Belis</last></author>
      <author><first>Annette</first><last>Rios Gonzales</last></author>
      <author><first>Don</first><last>Tuggener</last></author>
      <pages>631–636</pages>
      <url hash="0b7f627f">E17-2100</url>
      <abstract>We implement a fully probabilistic model to combine the hypotheses of a Spanish anaphora resolution system with those of a Spanish-English machine translation system. The probabilities over antecedents are converted into probabilities for the features of translated pronouns, and are integrated with phrase-based MT using an additional translation model for <a href="https://en.wikipedia.org/wiki/Pronoun">pronouns</a>. The system improves the translation of several Spanish personal and possessive pronouns into <a href="https://en.wikipedia.org/wiki/English_language">English</a>, by solving translation divergencies such as ‘ella’ vs. ‘she’/‘it’ or ‘su’ vs. ‘his’/‘her’/‘its’/‘their’. On a test set with 2,286 <a href="https://en.wikipedia.org/wiki/Pronoun">pronouns</a>, a baseline system correctly translates 1,055 of them, while ours improves this by 41. Moreover, with oracle antecedents, <a href="https://en.wikipedia.org/wiki/Possessive">possessives</a> are translated with an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 83 %.</abstract>
      <bibkey>luong-etal-2017-machine</bibkey>
      <pwccode url="https://github.com/a-rios/CorefMT" additional="false">a-rios/CorefMT</pwccode>
    </paper>
    <paper id="101">
      <title>Using Images to Improve Machine-Translating E-Commerce Product Listings.<fixed-case>E</fixed-case>-Commerce Product Listings.</title>
      <author><first>Iacer</first><last>Calixto</last></author>
      <author><first>Daniel</first><last>Stein</last></author>
      <author><first>Evgeny</first><last>Matusov</last></author>
      <author><first>Pintu</first><last>Lohar</last></author>
      <author><first>Sheila</first><last>Castilho</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <pages>637–643</pages>
      <url hash="aa16b521">E17-2101</url>
      <abstract>In this paper we study the impact of using <a href="https://en.wikipedia.org/wiki/Digital_image">images</a> to machine-translate user-generated e-commerce product listings. We study how a multi-modal Neural Machine Translation (NMT) model compares to two text-only approaches : a conventional state-of-the-art attentional NMT and a Statistical Machine Translation (SMT) model. User-generated product listings often do not constitute <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">grammatical or well-formed sentences</a>. More often than not, they consist of the juxtaposition of short phrases or <a href="https://en.wikipedia.org/wiki/Index_term">keywords</a>. We train our <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> end-to-end as well as use text-only and multi-modal NMT models for re-ranking n-best lists generated by an SMT model. We qualitatively evaluate our user-generated training data also analyse how adding synthetic data impacts the results. We evaluate our models quantitatively using BLEU and TER and find that (i) additional synthetic data has a general positive impact on text-only and multi-modal NMT models, and that (ii) using a multi-modal NMT model for re-ranking n-best lists improves TER significantly across different n-best list sizes.<tex-math>n</tex-math>-best lists generated by an SMT model. We qualitatively evaluate our user-generated training data also analyse how adding synthetic data impacts the results. We evaluate our models quantitatively using BLEU and TER and find that (i) additional synthetic data has a general positive impact on text-only and multi-modal NMT models, and that (ii) using a multi-modal NMT model for re-ranking n-best lists improves TER significantly across different n-best list sizes.</abstract>
      <bibkey>calixto-etal-2017-using</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/flickr30k">Flickr30k</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2015">WMT 2015</pwcdataset>
    </paper>
    <paper id="105">
      <title>Large-Scale Categorization of Japanese Product Titles Using Neural Attention Models<fixed-case>J</fixed-case>apanese Product Titles Using Neural Attention Models</title>
      <author><first>Yandi</first><last>Xia</last></author>
      <author><first>Aaron</first><last>Levine</last></author>
      <author><first>Pradipto</first><last>Das</last></author>
      <author><first>Giuseppe</first><last>Di Fabbrizio</last></author>
      <author><first>Keiji</first><last>Shinzato</last></author>
      <author><first>Ankur</first><last>Datta</last></author>
      <pages>663–668</pages>
      <url hash="de1c01ed">E17-2105</url>
      <abstract>We propose a variant of Convolutional Neural Network (CNN) models, the Attention CNN (ACNN) ; for large-scale categorization of millions of Japanese items into thirty-five product categories. Compared to a state-of-the-art Gradient Boosted Tree (GBT) classifier, the proposed model reduces training time from three weeks to three days while maintaining more than 96 % accuracy. Additionally, our proposed <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> characterizes products by imputing attentive focus on word tokens in a language agnostic way. The attention words have been observed to be semantically highly correlated with the predicted categories and give us a choice of automatic feature extraction for <a href="https://en.wikipedia.org/wiki/Downstream_processing">downstream processing</a>.</abstract>
      <bibkey>xia-etal-2017-large</bibkey>
    </paper>
    <paper id="106">
      <title>Convolutional Neural Networks for Authorship Attribution of Short Texts</title>
      <author><first>Prasha</first><last>Shrestha</last></author>
      <author><first>Sebastian</first><last>Sierra</last></author>
      <author><first>Fabio</first><last>González</last></author>
      <author><first>Manuel</first><last>Montes</last></author>
      <author><first>Paolo</first><last>Rosso</last></author>
      <author><first>Thamar</first><last>Solorio</last></author>
      <pages>669–674</pages>
      <url hash="abf8ebe2">E17-2106</url>
      <abstract>We present a model to perform <a href="https://en.wikipedia.org/wiki/Attribution_(psychology)">authorship attribution</a> of tweets using <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Networks (CNNs)</a> over <a href="https://en.wikipedia.org/wiki/N-gram">character n-grams</a>. We also present a strategy that improves model interpretability by estimating the importance of input text fragments in the predicted classification. The experimental evaluation shows that text CNNs perform competitively and are able to outperform previous methods.</abstract>
      <bibkey>shrestha-etal-2017-convolutional</bibkey>
    </paper>
    <paper id="108">
      <title>On the Relevance of Syntactic and Discourse Features for Author Profiling and Identification</title>
      <author><first>Juan</first><last>Soler-Company</last></author>
      <author><first>Leo</first><last>Wanner</last></author>
      <pages>681–687</pages>
      <url hash="59224b48">E17-2108</url>
      <abstract>The majority of approaches to <a href="https://en.wikipedia.org/wiki/Author_profiling">author profiling</a> and author identification focus mainly on <a href="https://en.wikipedia.org/wiki/Lexicon">lexical features</a>, i.e., on the content of a text. We argue that syntactic and discourse features play a significantly more prominent role than they were given in the past. We show that they achieve state-of-the-art performance in author and gender identification on a <a href="https://en.wikipedia.org/wiki/Text_corpus">literary corpus</a> while keeping the feature set small : the used feature set is composed of only 188 features and still outperforms the winner of the PAN 2014 shared task on author verification in the <a href="https://en.wikipedia.org/wiki/Literary_genre">literary genre</a>.</abstract>
      <bibkey>soler-company-wanner-2017-relevance</bibkey>
    </paper>
    <paper id="109">
      <title>Unsupervised Cross-Lingual Scaling of Political Texts</title>
      <author><first>Goran</first><last>Glavaš</last></author>
      <author><first>Federico</first><last>Nanni</last></author>
      <author><first>Simone Paolo</first><last>Ponzetto</last></author>
      <pages>688–693</pages>
      <url hash="73a998cc">E17-2109</url>
      <abstract>Political text scaling aims to linearly order parties and politicians across <a href="https://en.wikipedia.org/wiki/Political_dimension">political dimensions</a> (e.g., <a href="https://en.wikipedia.org/wiki/Left–right_political_spectrum">left-to-right ideology</a>) based on <a href="https://en.wikipedia.org/wiki/Content_(media)">textual content</a> (e.g., <a href="https://en.wikipedia.org/wiki/Public_speaking">politician speeches</a> or party manifestos). Existing <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> scale texts based on relative word usage and can not be used for cross-lingual analyses. Additionally, there is little quantitative evidence that the output of these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> correlates with common political dimensions like left-to-right orientation. Experimental results show that the semantically-informed scaling models better predict the party positions than the existing word-based models in two different political dimensions. Furthermore, the proposed <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> exhibit no drop in performance in the cross-lingual compared to monolingual setting.</abstract>
      <bibkey>glavas-etal-2017-unsupervised</bibkey>
      <pwccode url="https://bitbucket.org/gg42554/cl-scaling" additional="false">gg42554/cl-scaling</pwccode>
    </paper>
    <paper id="111">
      <title>Multimodal Topic Labelling</title>
      <author><first>Ionut</first><last>Sorodoc</last></author>
      <author><first>Jey Han</first><last>Lau</last></author>
      <author><first>Nikolaos</first><last>Aletras</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <pages>701–706</pages>
      <url hash="937a9d0f">E17-2111</url>
      <abstract>Topics generated by topic models are typically presented as a list of topic terms. Automatic topic labelling is the task of generating a succinct label that summarises the theme or subject of a topic, with the intention of reducing the cognitive load of end-users when interpreting these topics. Traditionally, topic label systems focus on a single label modality, e.g. textual labels. In this work we propose a multimodal approach to topic labelling using a simple <a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">feedforward neural network</a>. Given a topic and a candidate image or textual label, our method automatically generates a rating for the label, relative to the topic. Experiments show that this multimodal approach outperforms single-modality topic labelling systems.</abstract>
      <bibkey>sorodoc-etal-2017-multimodal</bibkey>
    </paper>
    <paper id="112">
      <title>Detecting (Un)Important Content for Single-Document News Summarization</title>
      <author><first>Yinfei</first><last>Yang</last></author>
      <author><first>Forrest</first><last>Bao</last></author>
      <author><first>Ani</first><last>Nenkova</last></author>
      <pages>707–712</pages>
      <url hash="28c45c10">E17-2112</url>
      <abstract>We present a robust approach for detecting intrinsic sentence importance in <a href="https://en.wikipedia.org/wiki/News">news</a>, by training on two corpora of document-summary pairs. When used for single-document summarization, our approach, combined with the beginning of document heuristic, outperforms a state-of-the-art summarizer and the beginning-of-article baseline in both automatic and manual evaluations. These results represent an important advance because in the absence of cross-document repetition, single document summarizers for <a href="https://en.wikipedia.org/wiki/News">news</a> have not been able to consistently outperform the strong beginning-of-article baseline.</abstract>
      <bibkey>yang-etal-2017-detecting</bibkey>
    </paper>
    <paper id="113">
      <title>F-Score Driven Max Margin Neural Network for Named Entity Recognition in Chinese Social Media<fixed-case>F</fixed-case>-Score Driven Max Margin Neural Network for Named Entity Recognition in <fixed-case>C</fixed-case>hinese Social Media</title>
      <author><first>Hangfeng</first><last>He</last></author>
      <author><first>Xu</first><last>Sun</last></author>
      <pages>713–718</pages>
      <url hash="bf5d73b2">E17-2113</url>
      <abstract>We focus on named entity recognition (NER) for Chinese social media. With massive unlabeled text and quite limited labelled corpus, we propose a <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning">semi-supervised learning model</a> based on B-LSTM neural network. To take advantage of traditional methods in NER such as CRF, we combine <a href="https://en.wikipedia.org/wiki/Transition_probability">transition probability</a> with <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> in our model. To bridge the gap between label accuracy and <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> of NER, we construct a <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> which can be directly trained on <a href="https://en.wikipedia.org/wiki/F-score">F-score</a>. When considering the instability of <a href="https://en.wikipedia.org/wiki/F-score">F-score driven method</a> and meaningful information provided by label accuracy, we propose an integrated method to train on both <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> and label accuracy. Our integrated model yields 7.44 % improvement over previous state-of-the-art result.</abstract>
      <bibkey>he-sun-2017-f</bibkey>
    </paper>
    <paper id="114">
      <title>Discriminative Information Retrieval for Question Answering Sentence Selection</title>
      <author><first>Tongfei</first><last>Chen</last></author>
      <author><first>Benjamin</first><last>Van Durme</last></author>
      <pages>719–725</pages>
      <url hash="3d5590d5">E17-2114</url>
      <abstract>We propose a framework for discriminative IR atop linguistic features, trained to improve the recall of answer candidate passage retrieval, the initial step in text-based question answering. We formalize this as an instance of linear feature-based IR, demonstrating a 34%-43 % improvement in <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall</a> for <a href="https://en.wikipedia.org/wiki/Triage">candidate triage</a> for <a href="https://en.wikipedia.org/wiki/Quality_assurance">QA</a>.</abstract>
      <bibkey>chen-van-durme-2017-discriminative</bibkey>
      <pwccode url="https://github.com/ctongfei/probe" additional="false">ctongfei/probe</pwccode>
    </paper>
    <paper id="115">
      <title>Effective shared representations with <a href="https://en.wikipedia.org/wiki/Multitask_learning">Multitask Learning</a> for Community Question Answering</title>
      <author><first>Daniele</first><last>Bonadiman</last></author>
      <author><first>Antonio</first><last>Uva</last></author>
      <author><first>Alessandro</first><last>Moschitti</last></author>
      <pages>726–732</pages>
      <url hash="f38f774f">E17-2115</url>
      <abstract>An important asset of using Deep Neural Networks (DNNs) for text applications is their ability to automatically engineering features. Unfortunately, DNNs usually require a lot of training data, especially for highly semantic tasks such as community Question Answering (cQA). In this paper, we tackle the problem of data scarcity by learning the target <a href="https://en.wikipedia.org/wiki/Deep_learning">DNN</a> together with two auxiliary tasks in a multitask learning setting. We exploit the strong semantic connection between selection of comments relevant to (i) new questions and (ii) forum questions. This enables a global representation for comments, new and previous questions. The experiments of our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> on a SemEval challenge dataset for cQA show a 20 % of relative improvement over standard DNNs.</abstract>
      <bibkey>bonadiman-etal-2017-effective</bibkey>
    </paper>
    <paper id="117">
      <title>Temporal information extraction from clinical text</title>
      <author><first>Julien</first><last>Tourille</last></author>
      <author><first>Olivier</first><last>Ferret</last></author>
      <author><first>Xavier</first><last>Tannier</last></author>
      <author><first>Aurélie</first><last>Névéol</last></author>
      <pages>739–745</pages>
      <url hash="bbda1185">E17-2117</url>
      <abstract>In this paper, we present a method for temporal relation extraction from clinical narratives in <a href="https://en.wikipedia.org/wiki/French_language">French</a> and in <a href="https://en.wikipedia.org/wiki/English_language">English</a>. We experiment on two comparable corpora, the MERLOT corpus and the THYME corpus, and show that a common approach can be used for both languages.</abstract>
      <bibkey>tourille-etal-2017-temporal</bibkey>
    </paper>
    <paper id="118">
      <title>Neural Temporal Relation Extraction</title>
      <author><first>Dmitriy</first><last>Dligach</last></author>
      <author><first>Timothy</first><last>Miller</last></author>
      <author><first>Chen</first><last>Lin</last></author>
      <author><first>Steven</first><last>Bethard</last></author>
      <author><first>Guergana</first><last>Savova</last></author>
      <pages>746–751</pages>
      <url hash="97737a29">E17-2118</url>
      <abstract>We experiment with neural architectures for temporal relation extraction and establish a new <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a> for several scenarios. We find that neural models with only tokens as input outperform state-of-the-art hand-engineered feature-based models, that convolutional neural networks outperform LSTM models, and that encoding relation arguments with XML tags outperforms a traditional position-based encoding.</abstract>
      <bibkey>dligach-etal-2017-neural</bibkey>
    </paper>
    <paper id="119">
      <title>End-to-End Trainable Attentive Decoder for Hierarchical Entity Classification</title>
      <author><first>Sanjeev</first><last>Karn</last></author>
      <author><first>Ulli</first><last>Waltinger</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>752–758</pages>
      <url hash="10d48bea">E17-2119</url>
      <abstract>We address fine-grained entity classification and propose a novel attention-based recurrent neural network (RNN) encoder-decoder that generates paths in the type hierarchy and can be trained end-to-end. We show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> performs better on fine-grained entity classification than prior work that relies on flat or local classifiers that do not directly model hierarchical structure.</abstract>
      <bibkey>karn-etal-2017-end</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/figer">FIGER</pwcdataset>
    </paper>
    </volume>
  <volume id="3">
    <meta>
      <booktitle>Proceedings of the Software Demonstrations of the 15th Conference of the <fixed-case>E</fixed-case>uropean Chapter of the Association for Computational Linguistics</booktitle>
      <url hash="e7754cd9">E17-3</url>
      <editor><first>André</first><last>Martins</last></editor>
      <editor><first>Anselmo</first><last>Peñas</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="90a3c31b">E17-3000</url>
      <bibkey>eacl-2017-software</bibkey>
    </frontmatter>
    <paper id="1">
      <title>COVER : Covering the Semantically Tractable Questions<fixed-case>COVER</fixed-case>: Covering the Semantically Tractable Questions</title>
      <author><first>Michael</first><last>Minock</last></author>
      <pages>1–4</pages>
      <url hash="15a9b77e">E17-3001</url>
      <abstract>In <a href="https://en.wikipedia.org/wiki/Semantic_parsing">semantic parsing</a>, natural language questions map to expressions in a meaning representation language (MRL) over some fixed vocabulary of predicates. To do this reliably, one must guarantee that for a wide class of natural language questions (the so called semantically tractable questions), correct interpretations are always in the mapped set of possibilities. In this demonstration, we introduce the system COVER which significantly clarifies, revises and extends the basic notion of semantic tractability. COVER achieves coverage of 89 % while the earlier PRECISE system achieved coverage of 77 % on the well known GeoQuery corpus. Like PRECISE, COVER requires only a simple domain lexicon and integrates off-the-shelf syntactic parsers. Beyond PRECISE, COVER also integrates off-the-shelf <a href="https://en.wikipedia.org/wiki/Automated_theorem_proving">theorem provers</a> to provide more accurate results. COVER is written in <a href="https://en.wikipedia.org/wiki/Python_(programming_language)">Python</a> and uses the <a href="https://en.wikipedia.org/wiki/NLTK">NLTK</a>.</abstract>
      <bibkey>minock-2017-cover</bibkey>
    </paper>
    <paper id="2">
      <title>Common Round : Application of Language Technologies to Large-Scale Web Debates</title>
      <author><first>Hans</first><last>Uszkoreit</last></author>
      <author><first>Aleksandra</first><last>Gabryszak</last></author>
      <author><first>Leonhard</first><last>Hennig</last></author>
      <author><first>Jörg</first><last>Steffen</last></author>
      <author><first>Renlong</first><last>Ai</last></author>
      <author><first>Stephan</first><last>Busemann</last></author>
      <author><first>Jon</first><last>Dehdari</last></author>
      <author><first>Josef</first><last>van Genabith</last></author>
      <author><first>Georg</first><last>Heigold</last></author>
      <author><first>Nils</first><last>Rethmeier</last></author>
      <author><first>Raphael</first><last>Rubino</last></author>
      <author><first>Sven</first><last>Schmeier</last></author>
      <author><first>Philippe</first><last>Thomas</last></author>
      <author><first>He</first><last>Wang</last></author>
      <author><first>Feiyu</first><last>Xu</last></author>
      <pages>5–8</pages>
      <url hash="ff3a619b">E17-3002</url>
      <abstract>Web debates play an important role in enabling broad participation of constituencies in social, political and economic decision-taking. However, it is challenging to organize, structure, and navigate a vast number of diverse argumentations and comments collected from many participants over a long time period. In this paper we demonstrate Common Round, a next generation platform for large-scale web debates, which provides functions for eliciting the semantic content and structures from the contributions of participants. In particular, Common Round applies <a href="https://en.wikipedia.org/wiki/Language_technology">language technologies</a> for the extraction of semantic essence from textual input, aggregation of the formulated opinions and arguments. The <a href="https://en.wikipedia.org/wiki/Computing_platform">platform</a> also provides a cross-lingual access to <a href="https://en.wikipedia.org/wiki/Debate">debates</a> using <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>.</abstract>
      <bibkey>uszkoreit-etal-2017-common</bibkey>
    </paper>
    <paper id="3">
      <title>A Web-Based Interactive Tool for Creating, Inspecting, Editing, and Publishing Etymological Datasets</title>
      <author><first>Johann-Mattis</first><last>List</last></author>
      <pages>9–12</pages>
      <url hash="21dbc813">E17-3003</url>
      <abstract>The paper presents the Etymological DICtionary ediTOR (EDICTOR), a free, interactive, web-based tool designed to aid historical linguists in creating, editing, analysing, and publishing etymological datasets. The EDICTOR offers interactive solutions for important tasks in <a href="https://en.wikipedia.org/wiki/Historical_linguistics">historical linguistics</a>, including facilitated input and segmentation of phonetic transcriptions, quantitative and qualitative analyses of phonetic and morphological data, enhanced interfaces for cognate class assignment and multiple word alignment, and automated evaluation of regular sound correspondences. As a <a href="https://en.wikipedia.org/wiki/Web_application">web-based tool</a> written in <a href="https://en.wikipedia.org/wiki/JavaScript">JavaScript</a>, the EDICTOR can be used in standard <a href="https://en.wikipedia.org/wiki/Web_browser">web browsers</a> across all major platforms.</abstract>
      <bibkey>list-2017-web</bibkey>
      <pwccode url="https://github.com/digling/edictor" additional="false">digling/edictor</pwccode>
    </paper>
    <paper id="5">
      <title>TextImager as a Generic Interface to R<fixed-case>T</fixed-case>ext<fixed-case>I</fixed-case>mager as a Generic Interface to <fixed-case>R</fixed-case></title>
      <author><first>Tolga</first><last>Uslu</last></author>
      <author><first>Wahed</first><last>Hemati</last></author>
      <author><first>Alexander</first><last>Mehler</last></author>
      <author><first>Daniel</first><last>Baumartz</last></author>
      <pages>17–20</pages>
      <url hash="02585ffb">E17-3005</url>
      <abstract>R is a very powerful framework for <a href="https://en.wikipedia.org/wiki/Statistical_model">statistical modeling</a>. Thus, it is of high importance to integrate <a href="https://en.wikipedia.org/wiki/R_(programming_language)">R</a> with state-of-the-art tools in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>. In this paper, we present the functionality and architecture of such an <a href="https://en.wikipedia.org/wiki/System_integration">integration</a> by means of TextImager. We use the OpenCPU API to integrate <a href="https://en.wikipedia.org/wiki/R_(programming_language)">R</a> based on our own R-Server. This allows for communicating with R-packages and combining them with TextImager’s NLP-components.</abstract>
      <bibkey>uslu-etal-2017-textimager</bibkey>
    </paper>
    <paper id="7">
      <title>TWINE : A real-time system for TWeet analysis via INformation Extraction<fixed-case>TWINE</fixed-case>: A real-time system for <fixed-case>TW</fixed-case>eet analysis via <fixed-case>IN</fixed-case>formation Extraction</title>
      <author><first>Debora</first><last>Nozza</last></author>
      <author><first>Fausto</first><last>Ristagno</last></author>
      <author><first>Matteo</first><last>Palmonari</last></author>
      <author><first>Elisabetta</first><last>Fersini</last></author>
      <author><first>Pikakshi</first><last>Manchanda</last></author>
      <author><first>Enza</first><last>Messina</last></author>
      <pages>25–28</pages>
      <url hash="fbd32e9e">E17-3007</url>
      <abstract>In the recent years, the amount of <a href="https://en.wikipedia.org/wiki/User-generated_content">user generated contents</a> shared on the Web has significantly increased, especially in <a href="https://en.wikipedia.org/wiki/Social_media">social media environment</a>, e.g. Twitter, <a href="https://en.wikipedia.org/wiki/Facebook">Facebook</a>, <a href="https://en.wikipedia.org/wiki/Google+">Google+</a>. This large quantity of data has generated the need of reactive and sophisticated systems for capturing and understanding the underlying information enclosed in them. In this paper we present TWINE, a real-time system for the big data analysis and exploration of information extracted from Twitter streams. The proposed system based on a Named Entity Recognition and Linking pipeline and a multi-dimensional spatial geo-localization is managed by a scalable and flexible architecture for an interactive visualization of micropost streams insights. The demo is available at.<url>http://twine-mind.cloudapp.net/streaming</url>.</abstract>
      <bibkey>nozza-etal-2017-twine</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/ipm-nel">IPM NEL</pwcdataset>
    </paper>
    <paper id="8">
      <title>Alto : Rapid Prototyping for Parsing and Translation<fixed-case>A</fixed-case>lto: Rapid Prototyping for Parsing and Translation</title>
      <author><first>Johannes</first><last>Gontrum</last></author>
      <author><first>Jonas</first><last>Groschwitz</last></author>
      <author><first>Alexander</first><last>Koller</last></author>
      <author><first>Christoph</first><last>Teichmann</last></author>
      <pages>29–32</pages>
      <url hash="f348ca97">E17-3008</url>
      <abstract>We present <a href="https://en.wikipedia.org/wiki/Alto">Alto</a>, a <a href="https://en.wikipedia.org/wiki/Rapid_prototyping">rapid prototyping tool</a> for new <a href="https://en.wikipedia.org/wiki/Formal_grammar">grammar formalisms</a>. Alto implements generic but efficient algorithms for <a href="https://en.wikipedia.org/wiki/Parsing">parsing</a>, <a href="https://en.wikipedia.org/wiki/Translation">translation</a>, and <a href="https://en.wikipedia.org/wiki/Formal_grammar">training</a> for a range of monolingual and synchronous grammar formalisms. It can easily be extended to new <a href="https://en.wikipedia.org/wiki/Formalism_(philosophy_of_mathematics)">formalisms</a>, which makes all of these <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> immediately available for the new <a href="https://en.wikipedia.org/wiki/Formalism_(philosophy_of_mathematics)">formalism</a>.</abstract>
      <bibkey>gontrum-etal-2017-alto</bibkey>
    </paper>
    <paper id="9">
      <title>CASSANDRA : A multipurpose configurable voice-enabled human-computer-interface<fixed-case>CASSANDRA</fixed-case>: A multipurpose configurable voice-enabled human-computer-interface</title>
      <author><first>Tiberiu</first><last>Boros</last></author>
      <author><first>Stefan Daniel</first><last>Dumitrescu</last></author>
      <author><first>Sonia</first><last>Pipa</last></author>
      <pages>33–36</pages>
      <url hash="f53bafdb">E17-3009</url>
      <abstract>Voice enabled human computer interfaces (HCI) that integrate <a href="https://en.wikipedia.org/wiki/Speech_recognition">automatic speech recognition</a>, <a href="https://en.wikipedia.org/wiki/Speech_synthesis">text-to-speech synthesis</a> and <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language understanding</a> have become a commodity, introduced by the immersion of <a href="https://en.wikipedia.org/wiki/Smartphone">smart phones</a> and other gadgets in our daily lives. Smart assistants are able to respond to simple queries (similar to text-based question-answering systems), perform simple tasks (call a number, reject a call etc.) and help organizing appointments. With this paper we introduce a newly created process automation platform that enables the user to control <a href="https://en.wikipedia.org/wiki/Application_software">applications</a> and <a href="https://en.wikipedia.org/wiki/Home_appliance">home appliances</a> and to query the system for information using a natural voice interface. We offer an overview of the technologies that enabled us to construct our <a href="https://en.wikipedia.org/wiki/System">system</a> and we present different usage scenarios in home and office environments.</abstract>
      <bibkey>boros-etal-2017-cassandra</bibkey>
    </paper>
    <paper id="10">
      <title>An Extensible Framework for Verification of Numerical Claims</title>
      <author><first>James</first><last>Thorne</last></author>
      <author><first>Andreas</first><last>Vlachos</last></author>
      <pages>37–40</pages>
      <url hash="89edd9cd">E17-3010</url>
      <abstract>In this paper we present our automated fact checking system demonstration which we developed in order to participate in the Fast and Furious Fact Check challenge. We focused on simple numerical claims such as population of Germany in 2015 was 80 million which comprised a quarter of the test instances in the challenge, achieving 68 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>. Our system extends previous work on semantic parsing and claim identification to handle temporal expressions and knowledge bases consisting of multiple tables, while relying solely on automatically generated training data. We demonstrate the extensible nature of our <a href="https://en.wikipedia.org/wiki/System">system</a> by evaluating <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> on relations used in previous work. We make our <a href="https://en.wikipedia.org/wiki/System">system</a> publicly available so that <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> can be used and extended by the community.</abstract>
      <bibkey>thorne-vlachos-2017-extensible</bibkey>
    </paper>
    <paper id="13">
      <title>Multilingual CALL Framework for Automatic Language Exercise Generation from Free Text<fixed-case>CALL</fixed-case> Framework for Automatic Language Exercise Generation from Free Text</title>
      <author><first>Naiara</first><last>Perez</last></author>
      <author><first>Montse</first><last>Cuadros</last></author>
      <pages>49–52</pages>
      <url hash="d82f7845">E17-3013</url>
      <abstract>This paper describes a <a href="https://en.wikipedia.org/wiki/Web_application">web-based application</a> to design and answer exercises for <a href="https://en.wikipedia.org/wiki/Language_acquisition">language learning</a>. It is available in <a href="https://en.wikipedia.org/wiki/Basque_language">Basque</a>, <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, <a href="https://en.wikipedia.org/wiki/English_language">English</a>, and <a href="https://en.wikipedia.org/wiki/French_language">French</a>. Based on open-source Natural Language Processing (NLP) technology such as word embedding models and <a href="https://en.wikipedia.org/wiki/Word-sense_disambiguation">word sense disambiguation</a>, the application enables users to automatic create easily and in real time three types of exercises, namely, Fill-in-the-Gaps, Multiple Choice, and Shuffled Sentences questionnaires. These are generated from texts of the users’ own choice, so they can train their language skills with content of their particular interest.</abstract>
      <bibkey>perez-cuadros-2017-multilingual</bibkey>
    </paper>
    <paper id="14">
      <title>Audience Segmentation in <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a></title>
      <author><first>Verena</first><last>Henrich</last></author>
      <author><first>Alexander</first><last>Lang</last></author>
      <pages>53–56</pages>
      <url hash="a04de36e">E17-3014</url>
      <abstract>Understanding the social media audience is becoming increasingly important for social media analysis. This paper presents an approach that detects various audience attributes, including author location, <a href="https://en.wikipedia.org/wiki/Demography">demographics</a>, <a href="https://en.wikipedia.org/wiki/Behavior">behavior</a> and <a href="https://en.wikipedia.org/wiki/Interest_(emotion)">interests</a>. It works both for a variety of <a href="https://en.wikipedia.org/wiki/Social_media">social media sources</a> and for multiple languages. The approach has been implemented within <a href="https://en.wikipedia.org/wiki/Watson_(computer)">IBM Watson Analytics</a> for <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a> and creates author profiles for more than 300 different analysis domains every day.</abstract>
      <bibkey>henrich-lang-2017-audience</bibkey>
    </paper>
    <paper id="15">
      <title>The arText prototype : An automatic system for writing specialized texts<fixed-case>T</fixed-case>ext prototype: An automatic system for writing specialized texts</title>
      <author><first>Iria</first><last>da Cunha</last></author>
      <author><first>M. Amor</first><last>Montané</last></author>
      <author><first>Luis</first><last>Hysa</last></author>
      <pages>57–60</pages>
      <url hash="df4743e6">E17-3015</url>
      <abstract>This article describes an automatic system for writing specialized texts in <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>. The arText prototype is a free online text editor that includes different types of <a href="https://en.wikipedia.org/wiki/Linguistic_description">linguistic information</a>. It is designed for a variety of end users and domains, including specialists and university students working in the fields of medicine and tourism, and laypersons writing to the public administration. ArText provides guidance on how to structure a text, prompts users to include all necessary contents in each section, and detects lexical and discourse problems in the text.</abstract>
      <bibkey>da-cunha-etal-2017-artext</bibkey>
    </paper>
    <paper id="16">
      <title>QCRI Live Speech Translation System<fixed-case>QCRI</fixed-case> Live Speech Translation System</title>
      <author><first>Fahim</first><last>Dalvi</last></author>
      <author><first>Yifan</first><last>Zhang</last></author>
      <author><first>Sameer</first><last>Khurana</last></author>
      <author><first>Nadir</first><last>Durrani</last></author>
      <author><first>Hassan</first><last>Sajjad</last></author>
      <author><first>Ahmed</first><last>Abdelali</last></author>
      <author><first>Hamdy</first><last>Mubarak</last></author>
      <author><first>Ahmed</first><last>Ali</last></author>
      <author><first>Stephan</first><last>Vogel</last></author>
      <pages>61–64</pages>
      <url hash="735856f5">E17-3016</url>
      <abstract>This paper presents QCRI’s Arabic-to-English live speech translation system. It features modern <a href="https://en.wikipedia.org/wiki/World_Wide_Web">web technologies</a> to capture <a href="https://en.wikipedia.org/wiki/Live_streaming">live audio</a>, and broadcasts <a href="https://en.wikipedia.org/wiki/Transcription_(linguistics)">Arabic transcriptions</a> and <a href="https://en.wikipedia.org/wiki/Transcription_(linguistics)">English translations</a> simultaneously. Our Kaldi-based ASR system uses the Time Delay Neural Network (TDNN) architecture, while our Machine Translation (MT) system uses both phrase-based and neural frameworks. Although our neural MT system is slower than the phrase-based system, it produces significantly better translations and is memory efficient. The demo is available at.<url>https://st.qcri.org/demos/livetranslation</url>.</abstract>
      <bibkey>dalvi-etal-2017-qcri</bibkey>
    </paper>
    <paper id="18">
      <title>A tool for extracting sense-disambiguated example sentences through user feedback</title>
      <author><first>Beto</first><last>Boullosa</last></author>
      <author><first>Richard</first><last>Eckart de Castilho</last></author>
      <author><first>Alexander</first><last>Geyken</last></author>
      <author><first>Lothar</first><last>Lemnitzer</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>69–72</pages>
      <url hash="dc98b9f1">E17-3018</url>
      <abstract>This paper describes an application system aimed to help <a href="https://en.wikipedia.org/wiki/Lexicography">lexicographers</a> in the extraction of example sentences for a given headword based on its different senses. The <a href="https://en.wikipedia.org/wiki/Tool">tool</a> uses classification and clustering methods and incorporates user feedback to refine its results.</abstract>
      <bibkey>boullosa-etal-2017-tool</bibkey>
    </paper>
    <paper id="19">
      <title>Lingmotif : Sentiment Analysis for the <a href="https://en.wikipedia.org/wiki/Digital_humanities">Digital Humanities</a><fixed-case>L</fixed-case>ingmotif: Sentiment Analysis for the Digital Humanities</title>
      <author><first>Antonio</first><last>Moreno-Ortiz</last></author>
      <pages>73–76</pages>
      <url hash="a49328f7">E17-3019</url>
      <abstract>Lingmotif is a lexicon-based, linguistically-motivated, user-friendly, GUI-enabled, multi-platform, Sentiment Analysis desktop application. Lingmotif can perform SA on any type of input texts, regardless of their length and topic. The analysis is based on the identification of sentiment-laden words and phrases contained in the application’s rich core lexicons, and employs context rules to account for sentiment shifters. It offers easy-to-interpret visual representations of quantitative data (text polarity, sentiment intensity, sentiment profile), as well as a detailed, qualitative analysis of the text in terms of its sentiment. Lingmotif can also take user-provided plugin lexicons in order to account for domain-specific sentiment expression. Lingmotif currently analyzes English and Spanish texts.</abstract>
      <bibkey>moreno-ortiz-2017-lingmotif</bibkey>
    </paper>
    <paper id="20">
      <title>RAMBLE ON : Tracing Movements of Popular Historical Figures<fixed-case>RAMBLE</fixed-case> <fixed-case>ON</fixed-case>: Tracing Movements of Popular Historical Figures</title>
      <author><first>Stefano</first><last>Menini</last></author>
      <author><first>Rachele</first><last>Sprugnoli</last></author>
      <author><first>Giovanni</first><last>Moretti</last></author>
      <author><first>Enrico</first><last>Bignotti</last></author>
      <author><first>Sara</first><last>Tonelli</last></author>
      <author><first>Bruno</first><last>Lepri</last></author>
      <pages>77–80</pages>
      <url hash="de6455ee">E17-3020</url>
      <abstract>We present RAMBLE ON, an <a href="https://en.wikipedia.org/wiki/Application_software">application</a> integrating a <a href="https://en.wikipedia.org/wiki/Pipeline_(computing)">pipeline</a> for frame-based information extraction and an <a href="https://en.wikipedia.org/wiki/User_interface">interface</a> to track and display movement trajectories. The code of the extraction pipeline and a navigator are freely available ; moreover we display in a demonstrator the outcome of a case study carried out on trajectories of notable persons of the XX Century.</abstract>
      <bibkey>menini-etal-2017-ramble</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
    </paper>
    <paper id="21">
      <title>Autobank : a semi-automatic annotation tool for developing deep Minimalist Grammar treebanks<fixed-case>A</fixed-case>utobank: a semi-automatic annotation tool for developing deep <fixed-case>M</fixed-case>inimalist <fixed-case>G</fixed-case>rammar treebanks</title>
      <author><first>John</first><last>Torr</last></author>
      <pages>81–86</pages>
      <url hash="1bb2d845">E17-3021</url>
      <abstract>This paper presents Autobank, a prototype tool for constructing a wide-coverage Minimalist Grammar (MG) (Stabler 1997), and semi-automatically converting the Penn Treebank (PTB) into a deep Minimalist treebank. The front end of the tool is a <a href="https://en.wikipedia.org/wiki/Graphical_user_interface">graphical user interface</a> which facilitates the rapid development of a seed set of MG trees via manual reannotation of PTB preterminals with MG lexical categories. The system then extracts various dependency mappings between the source and target trees, and uses these in concert with a non-statistical MG parser to automatically reannotate the rest of the corpus. Autobank thus enables deep treebank conversions (and subsequent modifications) without the need for complex transduction algorithms accompanied by cascades of ad hoc rules ; instead, the locus of human effort falls directly on the task of grammar construction itself.</abstract>
      <bibkey>torr-2017-autobank</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="22">
      <title>Chatbot with a Discourse Structure-Driven Dialogue Management</title>
      <author><first>Boris</first><last>Galitsky</last></author>
      <author><first>Dmitry</first><last>Ilvovsky</last></author>
      <pages>87–90</pages>
      <url hash="3ccb3c58">E17-3022</url>
      <abstract>We build a chat bot with iterative content exploration that leads a user through a personalized knowledge acquisition session. The <a href="https://en.wikipedia.org/wiki/Chat_bot">chat bot</a> is designed as an automated customer support or product recommendation agent assisting a user in learning product features, product usability, suitability, <a href="https://en.wikipedia.org/wiki/Troubleshooting">troubleshooting</a> and other related tasks. To control the user navigation through content, we extend the notion of a linguistic discourse tree (DT) towards a set of documents with multiple sections covering a topic. For a given paragraph, a DT is built by DT parsers. We then combine DTs for the paragraphs of documents to form what we call extended DT, which is a basis for interactive content exploration facilitated by the chat bot. To provide cohesive answers, we use a measure of rhetoric agreement between a question and an answer by tree kernel learning of their DTs.</abstract>
      <bibkey>galitsky-ilvovsky-2017-chatbot</bibkey>
    </paper>
    <paper id="25">
      <title>Building Web-Interfaces for Vector Semantic Models with the WebVectors Toolkit<fixed-case>W</fixed-case>eb<fixed-case>V</fixed-case>ectors Toolkit</title>
      <author><first>Andrey</first><last>Kutuzov</last></author>
      <author><first>Elizaveta</first><last>Kuzmenko</last></author>
      <pages>99–103</pages>
      <url hash="cf370d6b">E17-3025</url>
      <abstract>In this demo we present WebVectors, a free and open-source toolkit helping to deploy <a href="https://en.wikipedia.org/wiki/Web_service">web services</a> which demonstrate and visualize distributional semantic models (widely known as word embeddings). WebVectors can be useful in a very common situation when one has trained a distributional semantics model for one’s particular corpus or language (tools for this are now widespread and simple to use), but then there is a need to demonstrate the results to general public over the Web. We show its abilities on the example of the living web services featuring distributional models for <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Norwegian_language">Norwegian</a> and <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a>.</abstract>
      <bibkey>kutuzov-kuzmenko-2017-building</bibkey>
    </paper>
    <paper id="26">
      <title>InToEventS : An Interactive Toolkit for Discovering and Building Event Schemas<fixed-case>I</fixed-case>n<fixed-case>T</fixed-case>o<fixed-case>E</fixed-case>vent<fixed-case>S</fixed-case>: An Interactive Toolkit for Discovering and Building Event Schemas</title>
      <author><first>Germán</first><last>Ferrero</last></author>
      <author><first>Audi</first><last>Primadhanty</last></author>
      <author><first>Ariadna</first><last>Quattoni</last></author>
      <pages>104–107</pages>
      <url hash="88765cca">E17-3026</url>
      <abstract>Event Schema Induction is the task of learning a <a href="https://en.wikipedia.org/wiki/Representation_(arts)">representation of events</a> (e.g., bombing) and the roles involved in them (e.g, victim and perpetrator). This paper presents InToEventS, an interactive tool for learning these <a href="https://en.wikipedia.org/wiki/Schema_(psychology)">schemas</a>. InToEventS allows users to explore a corpus and discover which kind of events are present. We show how users can create useful event schemas using two interactive clustering steps.</abstract>
      <bibkey>ferrero-etal-2017-intoevents</bibkey>
    </paper>
    <paper id="27">
      <title>ICE : Idiom and Collocation Extractor for Research and Education<fixed-case>ICE</fixed-case>: Idiom and Collocation Extractor for Research and Education</title>
      <author><first>Vasanthi</first><last>Vuppuluri</last></author>
      <author><first>Shahryar</first><last>Baki</last></author>
      <author><first>An</first><last>Nguyen</last></author>
      <author><first>Rakesh</first><last>Verma</last></author>
      <pages>108–111</pages>
      <url hash="f32aa0e5">E17-3027</url>
      <abstract>Collocation and idiom extraction are well-known challenges with many potential applications in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing (NLP)</a>. Our experimental, open-source software system, called ICE, is a python package for flexibly extracting collocations and idioms, currently in English. It also has a competitive POS tagger that can be used alone or as part of collocation / idiom extraction. ICE is available free of cost for research and educational uses in two user-friendly formats. This paper gives an overview of ICE and its performance, and briefly describes the research underlying the extraction algorithms.</abstract>
      <bibkey>vuppuluri-etal-2017-ice</bibkey>
    </paper>
    </volume>
  <volume id="4">
    <meta>
      <booktitle>Proceedings of the Student Research Workshop at the 15th Conference of the <fixed-case>E</fixed-case>uropean Chapter of the Association for Computational Linguistics</booktitle>
      <url hash="9a8c60e3">E17-4</url>
      <editor><first>Florian</first><last>Kunneman</last></editor>
      <editor><first>Uxoa</first><last>Iñurrieta</last></editor>
      <editor><first>John J.</first><last>Camilleri</last></editor>
      <editor><first>Mariona Coll</first><last>Ardanuy</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="bce4b098">E17-4000</url>
      <bibkey>eacl-2017-student</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Pragmatic descriptions of perceptual stimuli</title>
      <author><first>Emiel</first><last>van Miltenburg</last></author>
      <pages>1–10</pages>
      <url hash="6745c0be">E17-4001</url>
      <abstract>This research proposal discusses pragmatic factors in image description, arguing that current automatic image description systems do not take these factors into account. I present a general model of the human image description process, and propose to study this process using <a href="https://en.wikipedia.org/wiki/Corpus_linguistics">corpus analysis</a>, experiments, and <a href="https://en.wikipedia.org/wiki/Computer_simulation">computational modeling</a>. This will lead to a better characterization of human image description behavior, providing a road map for future research in automatic image description, and the automatic description of perceptual stimuli in general.</abstract>
      <bibkey>van-miltenburg-2017-pragmatic</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/flickr30k">Flickr30k</pwcdataset>
    </paper>
    <paper id="2">
      <title>Detecting spelling variants in <a href="https://en.wikipedia.org/wiki/Standard_language">non-standard texts</a></title>
      <author><first>Fabian</first><last>Barteld</last></author>
      <pages>11–22</pages>
      <url hash="3fac01db">E17-4002</url>
      <abstract>Spelling variation in <a href="https://en.wikipedia.org/wiki/Standard_language">non-standard language</a>, e.g. computer-mediated communication and <a href="https://en.wikipedia.org/wiki/Text_corpus">historical texts</a>, is usually treated as a deviation from a standard spelling, e.g. 2mr as an non-standard spelling for tomorrow. Consequently, in normalization   the standard approach of dealing with spelling variation   so-called non-standard words are mapped to their corresponding standard words. However, there is not always a corresponding <a href="https://en.wikipedia.org/wiki/Standard_language">standard word</a>. This can be the case for single types (like <a href="https://en.wikipedia.org/wiki/Emoticon">emoticons</a> in computer-mediated communication) or a complete language, e.g. texts from <a href="https://en.wikipedia.org/wiki/Historical_language">historical languages</a> that did not develop to a standard variety. The approach presented in this thesis proposal deals with spelling variation in absence of reference to a standard. The task is to detect pairs of types that are variants of the same <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological word</a>. An approach for spelling-variant detection is presented, where pairs of potential spelling variants are generated with <a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein distance</a> and subsequently filtered by <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised machine learning</a>. The <a href="https://en.wikipedia.org/wiki/Composition_(language)">approach</a> is evaluated on historical Low German texts. Finally, further perspectives are discussed.</abstract>
      <bibkey>barteld-2017-detecting</bibkey>
    </paper>
    <paper id="3">
      <title>Replication issues in syntax-based aspect extraction for <a href="https://en.wikipedia.org/wiki/Opinion_mining">opinion mining</a></title>
      <author><first>Edison</first><last>Marrese-Taylor</last></author>
      <author><first>Yutaka</first><last>Matsuo</last></author>
      <pages>23–32</pages>
      <url hash="2959493d">E17-4003</url>
      <abstract>Reproducing experiments is an important instrument to validate previous work and build upon existing approaches. It has been tackled numerous times in different areas of science. In this paper, we introduce an empirical replicability study of three well-known <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> for syntactic centric aspect-based opinion mining. We show that reproducing results continues to be a difficult endeavor, mainly due to the lack of details regarding preprocessing and parameter setting, as well as due to the absence of available implementations that clarify these details. We consider these are important threats to validity of the research on the field, specifically when compared to other problems in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> where public datasets and <a href="https://en.wikipedia.org/wiki/Software_release_life_cycle">code availability</a> are critical validity components. We conclude by encouraging code-based research, which we think has a key role in helping researchers to understand the meaning of the state-of-the-art better and to generate continuous advances.</abstract>
      <bibkey>marrese-taylor-matsuo-2017-replication</bibkey>
      <pwccode url="https://github.com/epochx/opminreplicability" additional="false">epochx/opminreplicability</pwccode>
    </paper>
    <paper id="4">
      <title>Discourse Relations and <a href="https://en.wikipedia.org/wiki/Conjoined_twins">Conjoined VPs</a> : Automated Sense Recognition<fixed-case>VP</fixed-case>s: Automated Sense Recognition</title>
      <author><first>Valentina</first><last>Pyatkin</last></author>
      <author><first>Bonnie</first><last>Webber</last></author>
      <pages>33–42</pages>
      <url hash="7f3904e3">E17-4004</url>
      <abstract>Sense classification of discourse relations is a sub-task of shallow discourse parsing. Discourse relations can occur both across sentences (inter-sentential) and within sentences (intra-sentential), and more than one <a href="https://en.wikipedia.org/wiki/Discourse_relation">discourse relation</a> can hold between the same units. Using a newly available corpus of discourse-annotated intra-sentential conjoined verb phrases, we demonstrate a sequential classification pipeline for their multi-label sense classification. We assess the importance of each <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">feature</a> used in the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a>, the <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">feature scope</a>, and what is lost in moving from gold standard manual parses to the output of an off-the-shelf <a href="https://en.wikipedia.org/wiki/Parsing">parser</a>.<i>inter-sentential</i>) and within sentences (<i>intra-sentential</i>), and more than one discourse relation can hold between the same units. Using a newly available corpus of discourse-annotated intra-sentential conjoined verb phrases, we demonstrate a sequential classification pipeline for their multi-label sense classification. We assess the importance of each feature used in the classification, the feature scope, and what is lost in moving from gold standard manual parses to the output of an off-the-shelf parser.</abstract>
      <bibkey>pyatkin-webber-2017-discourse</bibkey>
    </paper>
    <paper id="5">
      <title>Deception detection in <a href="https://en.wikipedia.org/wiki/Russian_language">Russian texts</a><fixed-case>R</fixed-case>ussian texts</title>
      <author><first>Olga</first><last>Litvinova</last></author>
      <author><first>Pavel</first><last>Seredin</last></author>
      <author><first>Tatiana</first><last>Litvinova</last></author>
      <author><first>John</first><last>Lyell</last></author>
      <pages>43–52</pages>
      <url hash="0edda1b0">E17-4005</url>
      <abstract>Humans are known to detect <a href="https://en.wikipedia.org/wiki/Deception">deception</a> in <a href="https://en.wikipedia.org/wiki/Speech">speech</a> randomly and it is therefore important to develop tools to enable them to detect <a href="https://en.wikipedia.org/wiki/Deception">deception</a>. The problem of deception detection has been studied for a significant amount of time, however the last 10-15 years have seen methods of <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational linguistics</a> being employed. Texts are processed using different <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP tools</a> and then classified as deceptive / truthful using <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning methods</a>. While most research has been performed for <a href="https://en.wikipedia.org/wiki/English_language">English</a>, Slavic languages have never been a focus of detection deception studies. The paper deals with deception detection in <a href="https://en.wikipedia.org/wiki/Russian_language">Russian narratives</a>. It employs a specially designed corpus of truthful and deceptive texts on the same topic from each respondent, N = 113. The texts were processed using <a href="https://en.wikipedia.org/wiki/Linguistic_Inquiry">Linguistic Inquiry</a> and Word Count software that is used in most studies of text-based deception detection. The list of parameters computed using the <a href="https://en.wikipedia.org/wiki/Software">software</a> was expanded due to the designed users’ dictionaries. A variety of text classification methods was employed. The <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> was found to depend on the author’s gender and text type (deceptive / truthful).</abstract>
      <bibkey>litvinova-etal-2017-deception</bibkey>
    </paper>
    <paper id="6">
      <title>A Computational Model of Human Preferences for Pronoun Resolution</title>
      <author><first>Olga</first><last>Seminck</last></author>
      <author><first>Pascal</first><last>Amsili</last></author>
      <pages>53–63</pages>
      <url hash="d782b028">E17-4006</url>
      <abstract>We present a cognitive computational model of pronoun resolution that reproduces the human interpretation preferences of the Subject Assignment Strategy and the Parallel Function Strategy. Our <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> relies on a probabilistic pronoun resolution system trained on <a href="https://en.wikipedia.org/wiki/Corpus_linguistics">corpus data</a>. Factors influencing pronoun resolution are represented as <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> weighted by their relative importance. The importance the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> gives to the preferences is in line with <a href="https://en.wikipedia.org/wiki/Psycholinguistics">psycholinguistic studies</a>. We demonstrate the cognitive plausibility of the model by running it on experimental items and simulating antecedent choice and reading times of human participants. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> can be used as a new means to study pronoun resolution, because it captures the interaction of preferences.</abstract>
      <bibkey>seminck-amsili-2017-computational</bibkey>
    </paper>
    <paper id="7">
      <title>Automatic Extraction of News Values from Headline Text</title>
      <author><first>Alicja</first><last>Piotrkowicz</last></author>
      <author><first>Vania</first><last>Dimitrova</last></author>
      <author><first>Katja</first><last>Markert</last></author>
      <pages>64–74</pages>
      <url hash="b29fc8dd">E17-4007</url>
      <abstract>Headlines play a crucial role in attracting audiences’ attention to <a href="https://en.wikipedia.org/wiki/Digital_artifact">online artefacts</a> (e.g. news articles, videos, blogs). The ability to carry out an automatic, large-scale analysis of headlines is critical to facilitate the selection and prioritisation of a large volume of <a href="https://en.wikipedia.org/wiki/Digital_content">digital content</a>. In journalism studies news content has been extensively studied using manually annotated news values-factors used implicitly and explicitly when making decisions on the selection and prioritisation of news items. This paper presents the first attempt at a fully automatic extraction of <a href="https://en.wikipedia.org/wiki/News_value">news values</a> from <a href="https://en.wikipedia.org/wiki/Headline">headline text</a>. The news values extraction methods are applied on a large headlines corpus collected from The Guardian, and evaluated by comparing it with a manually annotated gold standard. A crowdsourcing survey indicates that <a href="https://en.wikipedia.org/wiki/News_values">news values</a> affect people’s decisions to click on a headline, supporting the need for an automatic news values detection.</abstract>
      <bibkey>piotrkowicz-etal-2017-automatic</bibkey>
    </paper>
    <paper id="8">
      <title>Assessing Convincingness of Arguments in Online Debates with Limited Number of Features</title>
      <author><first>Lisa Andreevna</first><last>Chalaguine</last></author>
      <author><first>Claudia</first><last>Schulz</last></author>
      <pages>75–83</pages>
      <url hash="3ef8cb0a">E17-4008</url>
      <abstract>We propose a new method in the field of argument analysis in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> to determining convincingness of arguments in online debates, following previous research by Habernal and Gurevych (2016). Rather than using argument specific feature values, we measure <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">feature values</a> relative to the average value in the debate, allowing us to determine argument convincingness with fewer <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> (between 5 and 35) than normally used for natural language processing tasks. We use a simple forward-feeding neural network for this task and achieve an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 0.77 which is comparable to the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> obtained using 64k features and a support vector machine by Habernal and Gurevych.</abstract>
      <bibkey>chalaguine-schulz-2017-assessing</bibkey>
      <pwccode url="https://github.com/lisanka93/individualProject" additional="false">lisanka93/individualProject</pwccode>
    </paper>
    <paper id="9">
      <title>Zipf’s and Benford’s laws in Twitter hashtags<fixed-case>Z</fixed-case>ipf’s and <fixed-case>B</fixed-case>enford’s laws in <fixed-case>T</fixed-case>witter hashtags</title>
      <author><first>José Alberto</first><last>Pérez Melián</last></author>
      <author><first>J. Alberto</first><last>Conejero</last></author>
      <author><first>Cèsar</first><last>Ferri Ramírez</last></author>
      <pages>84–93</pages>
      <url hash="6c0d2935">E17-4009</url>
      <abstract>Social networks have transformed communication dramatically in recent years through the rise of new <a href="https://en.wikipedia.org/wiki/Computing_platform">platforms</a> and the development of a new language of communication. This <a href="https://en.wikipedia.org/wiki/Landscape">landscape</a> requires new forms to describe and predict the behaviour of users in <a href="https://en.wikipedia.org/wiki/Computer_network">networks</a>. This paper presents an analysis of the <a href="https://en.wikipedia.org/wiki/Frequency_distribution">frequency distribution of hashtag popularity</a> in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter conversations</a>. Our objective is to determine if these <a href="https://en.wikipedia.org/wiki/Frequency_distribution">frequency distribution</a> follow some well-known <a href="https://en.wikipedia.org/wiki/Frequency_distribution">frequency distribution</a> that many real-life sets of numerical data satisfy. In particular, we study the similarity of <a href="https://en.wikipedia.org/wiki/Frequency_distribution">frequency distribution</a> of hashtag popularity with respect to <a href="https://en.wikipedia.org/wiki/Zipf’s_law">Zipf’s law</a>, an empirical law referring to the phenomenon that many types of data in <a href="https://en.wikipedia.org/wiki/Social_science">social sciences</a> can be approximated with a <a href="https://en.wikipedia.org/wiki/Zipf’s_law">Zipfian distribution</a>. Additionally, we also analyse <a href="https://en.wikipedia.org/wiki/Benford’s_law">Benford’s law</a>, is a special case of <a href="https://en.wikipedia.org/wiki/Zipf’s_law">Zipf’s law</a>, a common pattern about the <a href="https://en.wikipedia.org/wiki/Frequency_distribution">frequency distribution</a> of leading digits. In order to compute correctly the <a href="https://en.wikipedia.org/wiki/Frequency_distribution">frequency distribution of hashtag popularity</a>, we need to correct many spelling errors that Twitter’s users introduce. For this purpose we introduce a new <a href="https://en.wikipedia.org/wiki/Filter_(software)">filter</a> to correct hashtag mistake based on string distances. The experiments obtained employing datasets of <a href="https://en.wikipedia.org/wiki/Twitter">Twitter streams</a> generated under controlled conditions show that <a href="https://en.wikipedia.org/wiki/Benford’s_law">Benford’s law</a> and <a href="https://en.wikipedia.org/wiki/Zipf’s_law">Zipf’s law</a> can be used to model hashtag frequency distribution.</abstract>
      <bibkey>perez-melian-etal-2017-zipfs</bibkey>
    </paper>
    <paper id="10">
      <title>A Multi-aspect Analysis of Automatic Essay Scoring for <a href="https://en.wikipedia.org/wiki/Brazilian_Portuguese">Brazilian Portuguese</a><fixed-case>B</fixed-case>razilian <fixed-case>P</fixed-case>ortuguese</title>
      <author><first>Evelin</first><last>Amorim</last></author>
      <author><first>Adriano</first><last>Veloso</last></author>
      <pages>94–102</pages>
      <url hash="f7bae8b5">E17-4010</url>
      <abstract>Several methods for automatic essay scoring (AES) for <a href="https://en.wikipedia.org/wiki/English_language">English language</a> have been proposed. However, multi-aspect AES systems for other languages are unusual. Therefore, we propose a multi-aspect AES system to apply on a dataset of Brazilian Portuguese essays, which human experts evaluated according to five aspects defined by Brazilian Government to the National Exam to High School Student (ENEM). These aspects are skills that student must master and every skill is assessed apart from each other. Besides the prediction of each aspect, the feature analysis also was performed for each aspect. The <a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES system</a> proposed employs several <a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">features</a> already employed by <a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES systems</a> for <a href="https://en.wikipedia.org/wiki/English_language">English language</a>. Our results show that predictions for some aspects performed well with the <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> we employed, while predictions for other aspects performed poorly. Also, it is possible to note the difference between the five aspects in the detailed feature analysis we performed. Besides these contributions, the eight millions of enrollments every year for ENEM raise some challenge issues for future directions in our research.</abstract>
      <bibkey>amorim-veloso-2017-multi</bibkey>
    </paper>
    <paper id="12">
      <title>Evaluating the Reliability and Interaction of Recursively Used Feature Classes for Terminology Extraction</title>
      <author><first>Anna</first><last>Hätty</last></author>
      <author><first>Michael</first><last>Dorna</last></author>
      <author><first>Sabine</first><last>Schulte im Walde</last></author>
      <pages>113–121</pages>
      <url hash="d198457e">E17-4012</url>
      <abstract>Feature design and selection is a crucial aspect when treating <a href="https://en.wikipedia.org/wiki/Terminology_extraction">terminology extraction</a> as a machine learning classification problem. We designed feature classes which characterize different properties of terms based on <a href="https://en.wikipedia.org/wiki/Probability_distribution">distributions</a>, and propose a new feature class for components of term candidates. By using <a href="https://en.wikipedia.org/wiki/Random_forest">random forests</a>, we infer optimal features which are later used to build <a href="https://en.wikipedia.org/wiki/Decision_tree_learning">decision tree classifiers</a>. We evaluate our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> using the ACL RD-TEC dataset. We demonstrate the importance of the novel feature class for downgrading termhood which exploits properties of term components. Furthermore, our <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> suggests that the identification of reliable term candidates should be performed successively, rather than just once.</abstract>
      <bibkey>hatty-etal-2017-evaluating</bibkey>
    </paper>
  </volume>
  <volume id="5">
    <meta>
      <booktitle>Proceedings of the 15th Conference of the <fixed-case>E</fixed-case>uropean Chapter of the Association for Computational Linguistics: Tutorial Abstracts</booktitle>
      <editor><first>Alexandre</first><last>Klementiev</last></editor>
      <editor><first>Lucia</first><last>Specia</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Valencia, Spain</address>
      <month>April</month>
      <year>2017</year>
    </meta>
    <paper id="1">
      <title>Universal Dependencies<fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies</title>
      <author><first>Joakim</first><last>Nivre</last></author>
      <author><first>Daniel</first><last>Zeman</last></author>
      <author><first>Filip</first><last>Ginter</last></author>
      <author><first>Francis</first><last>Tyers</last></author>
      <url hash="4dacb20e">E17-5001</url>
      <abstract>Universal Dependencies (UD) is a project that seeks to develop cross-linguistically consistent treebank annotation for many languages. This tutorial gives an introduction to the UD framework and resources, from basic design principles to annotation guidelines and existing <a href="https://en.wikipedia.org/wiki/Treebank">treebanks</a>. We also discuss tools for developing and exploiting UD treebanks and survey applications of UD in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> and <a href="https://en.wikipedia.org/wiki/Linguistics">linguistics</a>.</abstract>
      <bibkey>nivre-etal-2017-universal</bibkey>
    </paper>
    <paper id="2">
      <title>Practical Neural Machine Translation</title>
      <author><first>Rico</first><last>Sennrich</last></author>
      <author><first>Barry</first><last>Haddow</last></author>
      <url hash="ea1ce4ac">E17-5002</url>
      <abstract>Neural Machine Translation (NMT) has achieved new breakthroughs in <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> in recent years. It has dominated recent shared translation tasks in machine translation research, and is also being quickly adopted in industry. The technical differences between NMT and the previously dominant phrase-based statistical approach require that practictioners learn new best practices for building MT systems, ranging from different hardware requirements, new techniques for handling rare words and monolingual data, to new opportunities in continued learning and domain adaptation. This tutorial is aimed at researchers and users of <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> interested in working with NMT. The tutorial will cover a basic theoretical introduction to <a href="https://en.wikipedia.org/wiki/Network_topology">NMT</a>, discuss the components of state-of-the-art systems, and provide practical advice for building <a href="https://en.wikipedia.org/wiki/Network_topology">NMT systems</a>.</abstract>
      <bibkey>sennrich-haddow-2017-practical</bibkey>
    </paper>
    <paper id="3">
      <title>Imitation learning for <a href="https://en.wikipedia.org/wiki/Structured_prediction">structured prediction</a> in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a></title>
      <author><first>Andreas</first><last>Vlachos</last></author>
      <author><first>Gerasimos</first><last>Lampouras</last></author>
      <author><first>Sebastian</first><last>Riedel</last></author>
      <url hash="fe5527fd">E17-5003</url>
      <abstract>Imitation learning is a learning paradigm originally developed to learn <a href="https://en.wikipedia.org/wiki/Robot_control">robotic controllers</a> from demonstrations by humans, e.g. autonomous flight from pilot demonstrations. Recently, algorithms for <a href="https://en.wikipedia.org/wiki/Structured_prediction">structured prediction</a> were proposed under this paradigm and have been applied successfully to a number of tasks including syntactic dependency parsing, <a href="https://en.wikipedia.org/wiki/Information_extraction">information extraction</a>, <a href="https://en.wikipedia.org/wiki/Coreference_resolution">coreference resolution</a>, dynamic feature selection, semantic parsing and <a href="https://en.wikipedia.org/wiki/Natural-language_generation">natural language generation</a>. Key advantages are the ability to handle large output search spaces and to learn with non-decomposable loss functions. Our aim in this tutorial is to have a unified presentation of the various imitation algorithms for structure prediction, and show how they can be applied to a variety of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP tasks</a>. All material associated with the tutorial will be made available through https://sheffieldnlp.github.io/ImitationLearningTutorialEACL2017/.</abstract>
      <bibkey>vlachos-etal-2017-imitation</bibkey>
    </paper>
    <paper id="5">
      <title>Integer Linear Programming formulations in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a></title>
      <author><first>Dan</first><last>Roth</last></author>
      <author><first>Vivek</first><last>Srikumar</last></author>
      <url hash="8404bafa">E17-5005</url>
      <abstract>Making decisions in natural language processing problems often involves assigning values to sets of <a href="https://en.wikipedia.org/wiki/Dependent_and_independent_variables">interdependent variables</a> where the expressive dependency structure can influence, or even dictate what assignments are possible. This setting includes a broad range of structured prediction problems such as <a href="https://en.wikipedia.org/wiki/Semantic_role_labeling">semantic role labeling</a>, <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity and relation recognition</a>, co-reference resolution, dependency parsing and <a href="https://en.wikipedia.org/wiki/Semantic_parsing">semantic parsing</a>. The setting is also appropriate for cases that may require making global decisions that involve multiple components, possibly pre-designed or pre-learned, as in event recognition and analysis, <a href="https://en.wikipedia.org/wiki/Automatic_summarization">summarization</a>, <a href="https://en.wikipedia.org/wiki/Paraphrase">paraphrasing</a>, textual entailment and <a href="https://en.wikipedia.org/wiki/Question_answering">question answering</a>. In all these cases, it is natural to formulate the <a href="https://en.wikipedia.org/wiki/Decision_problem">decision problem</a> as a constrained optimization problem, with an <a href="https://en.wikipedia.org/wiki/Loss_function">objective function</a> that is composed of learned models, subject to domain or problem specific constraints. Over the last few years, starting with a couple of papers written by (Roth &amp; Yih, 2004, 2005), dozens of papers have been using the Integer linear programming (ILP) formulation developed there, including several award-winning papers (e.g., (Martins, Smith, &amp; Xing, 2009 ; Koo, Rush, Collins, Jaakkola, &amp; Sontag., 2010 ; Berant, Dagan, &amp; Goldberger, 2011)).This tutorial will present the key ingredients of ILP formulations of natural language processing problems, aiming at guiding readers through the key modeling steps, explaining the learning and inference paradigms and exemplifying these by providing examples from the literature. We will cover a range of topics, from the theoretical foundations of learning and inference with ILP models, to practical modeling guides, to software packages and applications. The goal of this tutorial is to introduce the computational framework to broader ACL community, motivate it as a generic framework for learning and inference in global NLP decision problems, present some of the key theoretical and practical issues involved and survey some of the existing applications of it as a way to promote further development of the framework and additional applications. We will also make connections with some of the hot topics in current NLP research and show how they can be used within the general framework proposed here. The tutorial will thus be useful for many of the senior and junior researchers that have interest in global decision problems in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>, providing a concise overview of recent perspectives and research results.</abstract>
      <bibkey>roth-srikumar-2017-integer</bibkey>
    </paper>
    <paper id="6">
      <title>Building Multimodal Simulations for Natural Language</title>
      <author><first>James</first><last>Pustejovsky</last></author>
      <author><first>Nikhil</first><last>Krishnaswamy</last></author>
      <url hash="13ce8c26">E17-5006</url>
      <abstract>In this tutorial, we introduce a computational framework and modeling language (VoxML) for composing multimodal simulations of natural language expressions within a 3D simulation environment (VoxSim). We demonstrate how to construct voxemes, which are visual object representations of linguistic entities. We also show how to compose events and actions over these <a href="https://en.wikipedia.org/wiki/Object_(computer_science)">objects</a>, within a restricted domain of dynamics. This gives us the building blocks to simulate narratives of multiple events or participate in a multimodal dialogue with synthetic agents in the simulation environment. To our knowledge, this is the first time such material has been presented as a tutorial within the CL community. This will be of relevance to students and researchers interested in modeling actionable language, natural language communication with agents and robots, spatial and temporal constraint solving through language, referring expression generation, embodied cognition, as well as minimal model creation. Multimodal simulation of language, particularly motion expressions, brings together a number of existing lines of research from the computational linguistic, semantics, robotics, and formal logic communities, including action and event representation (Di Eugenio, 1991), modeling gestural correlates to NL expressions (Kipp et al., 2007 ; Neff et al., 2008), and action event modeling (Kipper and Palmer, 2000 ; Yang et al., 2015). We combine an approach to event modeling with a scene generation approach akin to those found in work by (Coyne and Sproat, 2001 ; Siskind, 2011 ; Chang et al., 2015). Mapping natural language expressions through a <a href="https://en.wikipedia.org/wiki/Formal_system">formal model</a> and a dynamic logic interpretation into a visualization of the event described provides an environment for grounding concepts and referring expressions that is interpretable by both a computer and a human user. This opens a variety of avenues for humans to communicate with computerized agents and robots, as in (Matuszek et al., 2013 ; Lauria et al., 2001), (Forbes et al., 2015), and (Deits et al., 2013 ; Walter et al., 2013 ; Tellex et al., 2014). Simulation and automatic visualization of events from natural language descriptions and supplementary modalities, such as gestures, allows humans to use their native capabilities as linguistic and visual interpreters to collaborate on tasks with an artificial agent or to put semantic intuitions to the test in an environment where user and agent share a common context. In previous work (Pustejovsky and Krishnaswamy, 2014 ; Pustejovsky, 2013a), we introduced a method for modeling natural language expressions within a 3D simulation environment built on top of the game development platform Unity (Goldstone, 2009). The goal of that work was to evaluate, through explicit visualizations of linguistic input, the semantic presuppositions inherent in the different lexical choices of an utterance. This work led to two additional lines of research : an explicit encoding for how an object is itself situated relative to its environment ; and an operational characterization of how an object changes its location or how an agent acts on an object over time, e.g., its affordance structure. The former has developed into a semantic notion of situational context, called a habitat (Pustejovsky, 2013a ; McDonald and Pustejovsky, 2014), while the latter is addressed by dynamic interpretations of event structure (Pustejovsky and Moszkowicz, 2011 ; Pustejovsky and Krishnaswamy, 2016b ; Pustejovsky, 2013b).The requirements on building a visual simulation from language include several components. We require a rich type system for lexical items and their composition, as well as a language for modeling the dynamics of events, based on Generative Lexicon (GL). Further, a minimal embedding space (MES) for the <a href="https://en.wikipedia.org/wiki/Simulation">simulation</a> must be determined. This is the <a href="https://en.wikipedia.org/wiki/Three-dimensional_space">3D region</a> within which the state is configured or the event unfolds. Object-based attributes for participants in a situation or event also need to be specified ; e.g., <a href="https://en.wikipedia.org/wiki/Orientation_(geometry)">orientation</a>, relative size, default position or pose, etc. The <a href="https://en.wikipedia.org/wiki/Simulation">simulation</a> establishes an epistemic condition on the object and event rendering, imposing an implicit point of view (POV). Finally, there must be some sort of agent-dependent embodiment ; this determines the relative scaling of an agent and its event participants and their surroundings, as it engages in the environment. In order to construct a robust simulation from linguistic input, an event and its participants must be embedded within an appropriate minimal embedding space. This must sufficiently enclose the <a href="https://en.wikipedia.org/wiki/Event_(computing)">event localization</a>, while optionally including space enough for a frame of reference for the event (the viewers perspective).We first describe the formal multimodal foundations for the <a href="https://en.wikipedia.org/wiki/Modeling_language">modeling language</a>, VoxML, which creates a minimal simulation from the linguistic input interpreted by the multimodal language, DITL. We then describe VoxSim, the compositional modeling and simulation environment, which maps the minimal VoxML model of the linguistic utterance to a simulation in <a href="https://en.wikipedia.org/wiki/Unity_(game_engine)">Unity</a>. This knowledge includes specification of object affordances, e.g., what actions are possible or enabled by use an object. VoxML (Pustejovsky and Krishnaswamy, 2016b ; Pustejovsky and Krishnaswamy, 2016a) encodes semantic knowledge of real-world objects represented as <a href="https://en.wikipedia.org/wiki/3D_modeling">3D models</a>, and of events and attributes related to and enacted over these <a href="https://en.wikipedia.org/wiki/Object_(computer_science)">objects</a>. VoxML goes beyond the limitations of existing 3D visual markup languages by allowing for the encoding of a broad range of semantic knowledge that can be exploited by a simulation platform such as VoxSim. VoxSim (Krishnaswamy and Pustejovsky, 2016a ; Krishnaswamy and Pustejovsky, 2016b) uses object and event semantic knowledge to generate animated scenes in real time without a complex animation interface. It uses the <a href="https://en.wikipedia.org/wiki/Unity_(game_engine)">Unity game engine</a> for graphics and I / O processing and takes as input a simple <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language utterance</a>. The parsed utterance is semantically interpreted and transformed into a hybrid dynamic logic representation (DITL), and used to generate a minimal simulation of the event when composed with VoxML knowledge.</abstract>
      <bibkey>pustejovsky-krishnaswamy-2017-building</bibkey>
    </paper>
  </volume>
</collection>