<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.fnp">
  <volume id="1" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the 1st Joint Workshop on Financial Narrative Processing and MultiLing Financial Summarisation</booktitle>
      <editor><first>Dr Mahmoud</first><last>El-Haj</last></editor>
      <editor><first>Dr Vasiliki</first><last>Athanasakou</last></editor>
      <editor><first>Dr Sira</first><last>Ferradans</last></editor>
      <editor><first>Dr Catherine</first><last>Salzedo</last></editor>
      <editor><first>Dr Ans</first><last>Elhag</last></editor>
      <editor><first>Dr Houda</first><last>Bouamor</last></editor>
      <editor><first>Dr Marina</first><last>Litvak</last></editor>
      <editor><first>Dr Paul</first><last>Rayson</last></editor>
      <editor><first>Dr George</first><last>Giannakopoulos</last></editor>
      <editor><first>Nikiforos</first><last>Pittaras</last></editor>
      <publisher>COLING</publisher>
      <address>Barcelona, Spain (Online)</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="e65cdc18">2020.fnp-1.0</url>
      <bibkey>fnp-2020-joint</bibkey>
    </frontmatter>
    <paper id="3">
      <title>The Financial Document Causality Detection Shared Task (FinCausal 2020)<fixed-case>F</fixed-case>in<fixed-case>C</fixed-case>ausal 2020)</title>
      <author><first>Dominique</first><last>Mariko</last></author>
      <author><first>Hanna</first><last>Abi-Akl</last></author>
      <author><first>Estelle</first><last>Labidurie</last></author>
      <author><first>Stephane</first><last>Durfort</last></author>
      <author><first>Hugues</first><last>De Mazancourt</last></author>
      <author><first>Mahmoud</first><last>El-Haj</last></author>
      <pages>23–32</pages>
      <abstract>We present the FinCausal 2020 Shared Task on Causality Detection in Financial Documents and the associated FinCausal dataset, and discuss the participating systems and results. Two sub-tasks are proposed : a binary classification task (Task 1) and a relation extraction task (Task 2). A total of 16 teams submitted runs across the two <a href="https://en.wikipedia.org/wiki/Task_(project_management)">Tasks</a> and 13 of them contributed with a system description paper. This workshop is associated to the Joint Workshop on Financial Narrative Processing and MultiLing Financial Summarisation (FNP-FNS 2020), held at The 28th International Conference on Computational Linguistics (COLING’2020), Barcelona, Spain on September 12, 2020.</abstract>
      <url hash="08403b89">2020.fnp-1.3</url>
      <bibkey>mariko-etal-2020-financial</bibkey>
    </paper>
    <paper id="7">
      <title>JDD @ FinCausal 2020, Task 2 : Financial Document Causality Detection<fixed-case>JDD</fixed-case> @ <fixed-case>F</fixed-case>in<fixed-case>C</fixed-case>ausal 2020, Task 2: Financial Document Causality Detection</title>
      <author><first>Toshiya</first><last>Imoto</last></author>
      <author><first>Tomoki</first><last>Ito</last></author>
      <pages>50–54</pages>
      <abstract>This paper describes the approach we built for the Financial Document Causality Detection Shared Task (FinCausal-2020) Task 2 : Cause and Effect Detection. Our approach is based on a multi-class classifier using BiLSTM with Graph Convolutional Neural Network (GCN) trained by minimizing the binary cross entropy loss. In our approach, we have not used any extra data source apart from combining the trial and practice dataset. We achieve <a href="https://en.wikipedia.org/wiki/Weighted_arithmetic_mean">weighted F1 score</a> to 75.61 percent and are ranked at 7-th place.</abstract>
      <url hash="fec1db74">2020.fnp-1.7</url>
      <bibkey>imoto-ito-2020-jdd</bibkey>
    </paper>
    <paper id="9">
      <title>NITK NLP at FinCausal-2020 Task 1 Using BERT and Linear models.<fixed-case>NITK</fixed-case> <fixed-case>NLP</fixed-case> at <fixed-case>F</fixed-case>in<fixed-case>C</fixed-case>ausal-2020 Task 1 Using <fixed-case>BERT</fixed-case> and Linear models.</title>
      <author><first>Hariharan</first><last>R L</last></author>
      <author><first>Anand Kumar</first><last>M</last></author>
      <pages>60–63</pages>
      <abstract>FinCausal-2020 is the shared task which focuses on the causality detection of factual data for <a href="https://en.wikipedia.org/wiki/Financial_analysis">financial analysis</a>. The financial data facts do n’t provide much explanation on the variability of these <a href="https://en.wikipedia.org/wiki/Data">data</a>. This paper aims to propose an efficient method to classify the data into one which is having any financial cause or not. Many models were used to classify the data, out of which <a href="https://en.wikipedia.org/wiki/Statistical_model">SVM model</a> gave an <a href="https://en.wikipedia.org/wiki/F-score">F-Score</a> of 0.9435, BERT with specific <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a> achieved best results with <a href="https://en.wikipedia.org/wiki/F-score">F-Score</a> of 0.9677.</abstract>
      <url hash="d621f784">2020.fnp-1.9</url>
      <bibkey>r-l-m-2020-nitk</bibkey>
    </paper>
    <paper id="10">
      <title>Fraunhofer IAIS at FinCausal 2020, Tasks 1 &amp; 2 : Using Ensemble Methods and Sequence Tagging to Detect Causality in Financial Documents<fixed-case>IAIS</fixed-case> at <fixed-case>F</fixed-case>in<fixed-case>C</fixed-case>ausal 2020, Tasks 1 &amp; 2: Using Ensemble Methods and Sequence Tagging to Detect Causality in Financial Documents</title>
      <author><first>Maren</first><last>Pielka</last></author>
      <author><first>Rajkumar</first><last>Ramamurthy</last></author>
      <author><first>Anna</first><last>Ladi</last></author>
      <author><first>Eduardo</first><last>Brito</last></author>
      <author><first>Clayton</first><last>Chapman</last></author>
      <author><first>Paul</first><last>Mayer</last></author>
      <author><first>Rafet</first><last>Sifa</last></author>
      <pages>64–68</pages>
      <abstract>The FinCausal 2020 shared task aims to detect <a href="https://en.wikipedia.org/wiki/Causality">causality</a> on financial news and identify those parts of the causal sentences related to the underlying cause and effect. We apply ensemble-based and sequence tagging methods for identifying <a href="https://en.wikipedia.org/wiki/Causality">causality</a>, and extracting causal subsequences. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> yield promising results on both sub-tasks, with the prospect of further improvement given more time and computing resources. With respect to task 1, we achieved an F1 score of 0.9429 on the evaluation data, and a corresponding ranking of 12/14. For task 2, we were ranked 6/10, with an F1 score of 0.76 and an ExactMatch score of 0.1912.</abstract>
      <url hash="b612206a">2020.fnp-1.10</url>
      <bibkey>pielka-etal-2020-fraunhofer</bibkey>
    </paper>
    <paper id="11">
      <title>NTUNLPL at FinCausal 2020, Task 2 : Improving Causality Detection Using Viterbi Decoder<fixed-case>NTUNLPL</fixed-case> at <fixed-case>F</fixed-case>in<fixed-case>C</fixed-case>ausal 2020, Task 2:Improving Causality Detection Using <fixed-case>V</fixed-case>iterbi Decoder</title>
      <author><first>Pei-Wei</first><last>Kao</last></author>
      <author><first>Chung-Chi</first><last>Chen</last></author>
      <author><first>Hen-Hsen</first><last>Huang</last></author>
      <author><first>Hsin-Hsi</first><last>Chen</last></author>
      <pages>69–73</pages>
      <abstract>In order to provide an explanation of <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning models</a>, causality detection attracts lots of attention in the artificial intelligence research community. In this paper, we explore the cause-effect detection in financial news and propose an approach, which combines the BIO scheme with the <a href="https://en.wikipedia.org/wiki/Viterbi_decoder">Viterbi decoder</a> for addressing this challenge. Our approach is ranked the first in the official run of cause-effect detection (Task 2) of the FinCausal-2020 shared task. We not only report the implementation details and ablation analysis in this paper, but also publish our <a href="https://en.wikipedia.org/wiki/Source_code">code</a> for academic usage.</abstract>
      <url hash="8e862016">2020.fnp-1.11</url>
      <bibkey>kao-etal-2020-ntunlpl</bibkey>
      <pwccode url="https://github.com/pxpxkao/fincausal-2020" additional="false">pxpxkao/fincausal-2020</pwccode>
    </paper>
    <paper id="12">
      <title>FiNLP at FinCausal 2020 Task 1 : Mixture of BERTs for Causal Sentence Identification in Financial Texts<fixed-case>F</fixed-case>i<fixed-case>NLP</fixed-case> at <fixed-case>F</fixed-case>in<fixed-case>C</fixed-case>ausal 2020 Task 1: Mixture of <fixed-case>BERT</fixed-case>s for Causal Sentence Identification in Financial Texts</title>
      <author><first>Sarthak</first><last>Gupta</last></author>
      <pages>74–79</pages>
      <abstract>This paper describes our system developed for the sub-task 1 of the FinCausal shared task in the FNP-FNS workshop held in conjunction with COLING-2020. The <a href="https://en.wikipedia.org/wiki/System">system</a> classifies whether a financial news text segment contains causality or not. To address this task, we fine-tune and ensemble the generic and domain-specific BERT language models pre-trained on financial text corpora. The task data is highly imbalanced with the majority non-causal class ; therefore, we train the models using strategies such as under-sampling, cost-sensitive learning, and <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a>. Our best <a href="https://en.wikipedia.org/wiki/System">system</a> achieves a weighted F1-score of 96.98 securing 4th position on the evaluation leaderboard. The code is available at https://github.com/sarthakTUM/fincausal</abstract>
      <url hash="60bbeee2">2020.fnp-1.12</url>
      <bibkey>gupta-2020-finlp</bibkey>
      <pwccode url="https://github.com/sarthaktum/fincausal" additional="false">sarthaktum/fincausal</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2010-task-8">SemEval-2010 Task 8</pwcdataset>
    </paper>
    <paper id="15">
      <title>Domino at FinCausal 2020, Task 1 and 2 : Causal Extraction System<fixed-case>F</fixed-case>in<fixed-case>C</fixed-case>ausal 2020, Task 1 and 2: Causal Extraction System</title>
      <author><first>Sharanya</first><last>Chakravarthy</last></author>
      <author><first>Tushar</first><last>Kanakagiri</last></author>
      <author><first>Karthik</first><last>Radhakrishnan</last></author>
      <author><first>Anjana</first><last>Umapathy</last></author>
      <pages>90–94</pages>
      <abstract>Automatic identification of cause-effect relationships from <a href="https://en.wikipedia.org/wiki/Data">data</a> is a challenging but important problem in <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">artificial intelligence</a>. Identifying semantic relationships has become increasingly important for multiple downstream applications like <a href="https://en.wikipedia.org/wiki/Question_answering">Question Answering</a>, <a href="https://en.wikipedia.org/wiki/Information_retrieval">Information Retrieval</a> and Event Prediction. In this work, we tackle the problem of <a href="https://en.wikipedia.org/wiki/Causal_inference">causal relationship extraction</a> from financial news using the FinCausal 2020 dataset. We tackle two tasks-1) Detecting the presence of <a href="https://en.wikipedia.org/wiki/Causality">causal relationships</a> and 2) Extracting segments corresponding to cause and effect from news snippets. We propose Transformer based sequence and token classification models with post-processing rules which achieve an <a href="https://en.wikipedia.org/wiki/F-number">F1 score</a> of 96.12 and 79.60 on Tasks 1 and 2 respectively.</abstract>
      <url hash="5960491b">2020.fnp-1.15</url>
      <bibkey>chakravarthy-etal-2020-domino</bibkey>
      <pwccode url="https://github.com/sharanyarc96/domino-fincausal2020" additional="false">sharanyarc96/domino-fincausal2020</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="16">
      <title>IITkgp at FinCausal 2020, Shared Task 1 : Causality Detection using Sentence Embeddings in Financial Reports<fixed-case>IIT</fixed-case>kgp at <fixed-case>F</fixed-case>in<fixed-case>C</fixed-case>ausal 2020, Shared Task 1: Causality Detection using Sentence Embeddings in Financial Reports</title>
      <author><first>Arka</first><last>Mitra</last></author>
      <author><first>Harshvardhan</first><last>Srivastava</last></author>
      <author><first>Yugam</first><last>Tiwari</last></author>
      <pages>95–99</pages>
      <abstract>The paper describes the work that the team submitted to FinCausal 2020 Shared Task. This work is associated with the first sub-task of identifying causality in sentences. The various <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> used in the experiments tried to obtain a latent space representation for each of the sentences. Linear regression was performed on these <a href="https://en.wikipedia.org/wiki/Representation_(mathematics)">representations</a> to classify whether the sentence is causal or not. The experiments have shown BERT (Large) performed the best, giving a F1 score of 0.958, in the task of detecting the causality of sentences in <a href="https://en.wikipedia.org/wiki/Financial_statement">financial texts</a> and <a href="https://en.wikipedia.org/wiki/Financial_statement">reports</a>. The class imbalance was dealt with a modified <a href="https://en.wikipedia.org/wiki/Loss_function">loss function</a> to give a better metric score for the evaluation.</abstract>
      <url hash="320606fe">2020.fnp-1.16</url>
      <bibkey>mitra-etal-2020-iitkgp</bibkey>
    </paper>
    <paper id="17">
      <title>Extractive Financial Narrative Summarisation based on DPPs<fixed-case>DPP</fixed-case>s</title>
      <author><first>Lei</first><last>Li</last></author>
      <author><first>Yafei</first><last>Jiang</last></author>
      <author><first>Yinan</first><last>Liu</last></author>
      <pages>100–104</pages>
      <abstract>We participate in the FNS-Summarisation 2020 shared task to be held at FNP 2020 workshop at COLING 2020. Based on Determinantal Point Processes (DPPs), we build an extractive automatic financial summarisation system for the specific task. In this <a href="https://en.wikipedia.org/wiki/System">system</a>, we first analyze the long report data to select the important narrative parts and generate an intermediate document. Next, we build the kernel Matrix L for the intermediate document, which represents the quality of its sentences. On the basis of <a href="https://en.wikipedia.org/wiki/L_(complexity)">L</a>, we then can use the DPPs sampling algorithm to choose those sentences with high quality and diversity as the final summary sentences.</abstract>
      <url hash="30d861d5">2020.fnp-1.17</url>
      <bibkey>li-etal-2020-extractive</bibkey>
    </paper>
    <paper id="20">
      <title>End-to-end Training For Financial Report Summarization</title>
      <author><first>Moreno</first><last>La Quatra</last></author>
      <author><first>Luca</first><last>Cagliero</last></author>
      <pages>118–123</pages>
      <abstract>Quoted companies are requested to periodically publish <a href="https://en.wikipedia.org/wiki/Financial_statement">financial reports</a> in textual form. The annual financial reports typically include detailed financial and business information, thus giving relevant insights into company outlooks. However, a manual exploration of these financial reports could be very time consuming since most of the available information can be deemed as non-informative or redundant by expert readers. Hence, an increasing research interest has been devoted to automatically extracting domain-specific summaries, which include only the most relevant information. This paper describes the SumTO system architecture, which addresses the Shared Task of the Financial Narrative Summarisation (FNS) 2020 contest. The main task objective is to automatically extract the most informative, domain-specific textual content from financial, English-written documents. The aim is to create a summary of each company report covering all the business-relevant key points. To address the above-mentioned goal, we propose an end-to-end training method relying on Deep NLP techniques. The idea behind the system is to exploit the syntactic overlap between input sentences and ground-truth summaries to fine-tune pre-trained BERT embedding models, thus making such <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> tailored to the specific context. The achieved results confirm the effectiveness of the proposed <a href="https://en.wikipedia.org/wiki/Methodology">method</a>, especially when the goal is to select relatively long text snippets.</abstract>
      <url hash="628f542b">2020.fnp-1.20</url>
      <bibkey>la-quatra-cagliero-2020-end</bibkey>
      <pwccode url="https://github.com/morenolaquatra/sumto_financial_summarization" additional="false">morenolaquatra/sumto_financial_summarization</pwccode>
    </paper>
    <paper id="23">
      <title>AMEX AI-Labs : An Investigative Study on Extractive Summarization of Financial Documents<fixed-case>AMEX</fixed-case> <fixed-case>AI</fixed-case>-Labs: An Investigative Study on Extractive Summarization of Financial Documents</title>
      <author><first>Piyush</first><last>Arora</last></author>
      <author><first>Priya</first><last>Radhakrishnan</last></author>
      <pages>137–142</pages>
      <abstract>We describe the work carried out by AMEX AI-LABS on an extractive summarization benchmark task focused on Financial Narratives Summarization (FNS). This task focuses on summarizing annual financial reports which poses two main challenges as compared to typical news document summarization tasks : i) <a href="https://en.wikipedia.org/wiki/Annual_report">annual reports</a> are more lengthier (average length about 80 pages) as compared to typical news documents, and ii) <a href="https://en.wikipedia.org/wiki/Annual_report">annual reports</a> are more loosely structured e.g. comprising of tables, charts, <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">textual data</a> and <a href="https://en.wikipedia.org/wiki/Digital_image">images</a>, which makes it challenging to effectively summarize. To address this summarization task we investigate a range of unsupervised, supervised and ensemble based techniques. We find that ensemble based techniques perform relatively better as compared to using only the unsupervised and supervised based techniques. Our ensemble based model achieved the highest rank of 9 out of 31 systems submitted for the benchmark task based on Rouge-L evaluation metric.</abstract>
      <url hash="75e35e28">2020.fnp-1.23</url>
      <bibkey>arora-radhakrishnan-2020-amex</bibkey>
    </paper>
    <paper id="28">
      <title>Taxy.io@FinTOC-2020 : Multilingual Document Structure Extraction using Transfer Learning<fixed-case>F</fixed-case>in<fixed-case>TOC</fixed-case>-2020: Multilingual Document Structure Extraction using Transfer Learning</title>
      <author><first>Frederic</first><last>Haase</last></author>
      <author><first>Steffen</first><last>Kirchhoff</last></author>
      <pages>163–168</pages>
      <abstract>In this paper we describe our <a href="https://en.wikipedia.org/wiki/System">system</a> submitted to the FinTOC-2020 shared task on financial doc- ument structure extraction. We propose a two-step approach to identify titles in financial docu- ments and to extract their table of contents (TOC). First, we identify text blocks as candidates for titles using <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised learning</a> based on character-level information of each document. Then, we apply <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a> on a self-constructed regression task to predict the depth of each text block in the document structure hierarchy using <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> combined with document features and layout features. It is noteworthy that our single multilingual model performs well on both tasks and on different languages, which indicates the usefulness of <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> for title detection and TOC generation. Moreover, our approach is independent of the presence of actual <a href="https://en.wikipedia.org/wiki/Table_of_contents">TOC pages</a> in the documents. It is also one of the few submissions to the FinTOC-2020 shared task addressing both subtasks in both languages, <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/French_language">French</a>, with one single <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a>.</abstract>
      <url hash="65681eb8">2020.fnp-1.28</url>
      <bibkey>haase-kirchhoff-2020-taxy</bibkey>
    </paper>
    <paper id="31">
      <title>A Computational Analysis of Financial and Environmental Narratives within <a href="https://en.wikipedia.org/wiki/Financial_statement">Financial Reports</a> and its Value for Investors</title>
      <author><first>Felix</first><last>Armbrust</last></author>
      <author><first>Henry</first><last>Schäfer</last></author>
      <author><first>Roman</first><last>Klinger</last></author>
      <pages>181–194</pages>
      <abstract>Public companies are obliged to include financial and non-financial information within their cor- porate filings under Regulation S-K, in the United States (SEC, 2010). However, the requirements still allow for manager’s discretion. This raises the question to which extent the information is actually included and if this information is at all relevant for investors. We answer this question by training and evaluating an end-to-end deep learning approach (based on BERT and GloVe embeddings) to predict the financial and environmental performance of the company from the Management’s Discussion and Analysis of Financial Conditions and Results of Operations (MD&amp;A) section of 10-K (yearly) and 10-Q (quarterly) filings. We further analyse the mediating effect of the environmental performance on the relationship between the company’s disclosures and financial performance. Hereby, we address the results of previous studies regarding environ- mental performance. We find that the textual information contained within the MD&amp;A section does not allow for conclusions about the future (corporate) financial performance. However, there is evidence that the environmental performance can be extracted by <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing methods</a>.</abstract>
      <url hash="93580757">2020.fnp-1.31</url>
      <bibkey>armbrust-etal-2020-computational</bibkey>
      <pwccode url="https://github.com/forgefin/fin-env-narrative" additional="false">forgefin/fin-env-narrative</pwccode>
    </paper>
    <paper id="33">
      <title>Mitigating Silence in Compliance Terminology during Parsing of Utterances</title>
      <author><first>Esme</first><last>Manandise</last></author>
      <author><first>Conrad</first><last>de Peuter</last></author>
      <pages>204–212</pages>
      <abstract>This paper reports on an approach to increase multi-token-term recall in a parsing task. We use a compliance-domain parser to extract, during the process of parsing raw text, terms that are unlisted in the terminology. The <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> uses a similarity measure (Generalized Dice Coefficient) between listed terms and unlisted term candidates to (i) determine term status, (ii) serve putative terms to the <a href="https://en.wikipedia.org/wiki/Parsing">parser</a>, (iii) decrease parsing complexity by glomming multi-tokens as lexical singletons, and (iv) automatically augment the terminology after parsing of an utterance completes. We illustrate a small experiment with examples from the tax-and-regulations domain. Bootstrapping the parsing process to detect out- of-vocabulary terms at runtime increases parsing accuracy in addition to producing other benefits to a natural-language-processing pipeline, which translates arithmetic calculations written in English into computer-executable operations.</abstract>
      <url hash="fb22bb11">2020.fnp-1.33</url>
      <bibkey>manandise-de-peuter-2020-mitigating</bibkey>
    </paper>
    </volume>
</collection>