<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.sigdial">
  <volume id="1" ingest-date="2020-07-09">
    <meta>
      <booktitle>Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</booktitle>
      <editor><first>Olivier</first><last>Pietquin</last></editor>
      <editor><first>Smaranda</first><last>Muresan</last></editor>
      <editor><first>Vivian</first><last>Chen</last></editor>
      <editor><first>Casey</first><last>Kennington</last></editor>
      <editor><first>David</first><last>Vandyke</last></editor>
      <editor><first>Nina</first><last>Dethlefs</last></editor>
      <editor><first>Koji</first><last>Inoue</last></editor>
      <editor><first>Erik</first><last>Ekstedt</last></editor>
      <editor><first>Stefan</first><last>Ultes</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>1st virtual meeting</address>
      <month>July</month>
      <year>2020</year>
      <url hash="0fec3bb3">2020.sigdial-1</url>
    </meta>
    <frontmatter>
      <url hash="37c3ed2c">2020.sigdial-1.0</url>
      <bibkey>sigdial-2020-special</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Semantic Guidance of Dialogue Generation with <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement Learning</a></title>
      <author><first>Cheng-Hsun</first><last>Hsueh</last></author>
      <author><first>Wei-Yun</first><last>Ma</last></author>
      <pages>1–9</pages>
      <abstract>Neural encoder-decoder models have shown promising performance for <a href="https://en.wikipedia.org/wiki/Human–computer_interaction">human-computer dialogue systems</a> over the past few years. However, due to the maximum-likelihood objective for the decoder, the generated responses are often universal and safe to the point that they lack meaningful information and are no longer relevant to the post. To address this, in this paper, we propose semantic guidance using <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> to ensure that the generated responses indeed include the given or predicted semantics and that these <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> do not appear repeatedly in the response. Synsets, which comprise sets of manually defined synonyms, are used as the form of assigned semantics. For a given / assigned / predicted synset, only one of its <a href="https://en.wikipedia.org/wiki/Synonym">synonyms</a> should appear in the generated response ; this constitutes a simple but effective semantic-control mechanism. We conduct both quantitative and qualitative evaluations, which show that the generated responses are not only higher-quality but also reflect the assigned semantic controls.</abstract>
      <url hash="b4dfdde2">2020.sigdial-1.1</url>
      <video href="https://youtube.com/watch?v=nNvH4co2qr0" />
      <bibkey>hsueh-ma-2020-semantic</bibkey>
    </paper>
    <paper id="4">
      <title>TripPy : A Triple Copy Strategy for Value Independent Neural Dialog State Tracking<fixed-case>T</fixed-case>rip<fixed-case>P</fixed-case>y: A Triple Copy Strategy for Value Independent Neural Dialog State Tracking</title>
      <author><first>Michael</first><last>Heck</last></author>
      <author><first>Carel</first><last>van Niekerk</last></author>
      <author><first>Nurul</first><last>Lubis</last></author>
      <author><first>Christian</first><last>Geishauser</last></author>
      <author><first>Hsien-Chin</first><last>Lin</last></author>
      <author><first>Marco</first><last>Moresi</last></author>
      <author><first>Milica</first><last>Gasic</last></author>
      <pages>35–44</pages>
      <abstract>Task-oriented dialog systems rely on dialog state tracking (DST) to monitor the user’s goal during the course of an interaction. Multi-domain and open-vocabulary settings complicate the task considerably and demand scalable solutions. In this paper we present a new approach to <a href="https://en.wikipedia.org/wiki/Discrete_cosine_transform">DST</a> which makes use of various copy mechanisms to fill slots with values. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> has no need to maintain a list of candidate values. Instead, all values are extracted from the <a href="https://en.wikipedia.org/wiki/Context_(computing)">dialog context</a> on-the-fly. A slot is filled by one of three copy mechanisms : (1) Span prediction may extract values directly from the user input ; (2) a value may be copied from a system inform memory that keeps track of the system’s inform operations (3) a value may be copied over from a different slot that is already contained in the dialog state to resolve coreferences within and across domains. Our approach combines the advantages of span-based slot filling methods with memory methods to avoid the use of value picklists altogether. We argue that our <a href="https://en.wikipedia.org/wiki/Strategy">strategy</a> simplifies the DST task while at the same time achieving state of the art performance on various popular evaluation sets including Multiwoz 2.1, where we achieve a joint goal accuracy beyond 55 %.</abstract>
      <url hash="39b9202b">2020.sigdial-1.4</url>
      <video href="https://youtube.com/watch?v=qWLnp4tPbPM" />
      <bibkey>heck-etal-2020-trippy</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/multiwoz">MultiWOZ</pwcdataset>
    </paper>
    <paper id="7">
      <title>MC-Saar-Instruct : a Platform for Minecraft Instruction Giving Agents<fixed-case>MC</fixed-case>-Saar-Instruct: a Platform for <fixed-case>M</fixed-case>inecraft Instruction Giving Agents</title>
      <author><first>Arne</first><last>Köhn</last></author>
      <author><first>Julia</first><last>Wichlacz</last></author>
      <author><first>Christine</first><last>Schäfer</last></author>
      <author><first>Álvaro</first><last>Torralba</last></author>
      <author><first>Joerg</first><last>Hoffmann</last></author>
      <author><first>Alexander</first><last>Koller</last></author>
      <pages>53–56</pages>
      <abstract>We present a comprehensive platform to run <a href="https://en.wikipedia.org/wiki/Human–computer_interaction">human-computer experiments</a> where an <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agent</a> instructs a human in Minecraft, a 3D blocksworld environment. This <a href="https://en.wikipedia.org/wiki/Computing_platform">platform</a> enables comparisons between different <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agents</a> by matching users to agents. It performs extensive logging and takes care of all boilerplate, allowing to easily incorporate new <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agents</a> to evaluate <a href="https://en.wikipedia.org/wiki/Intelligent_agent">them</a>. Our <a href="https://en.wikipedia.org/wiki/Environment_(systems)">environment</a> is prepared to evaluate any kind of instruction giving system, recording the <a href="https://en.wikipedia.org/wiki/Interaction">interaction</a> and all actions of the user. We provide example <a href="https://en.wikipedia.org/wiki/Architect">architects</a>, a Wizard-of-Oz architect and set-up scripts to automatically download, build and start the <a href="https://en.wikipedia.org/wiki/Computing_platform">platform</a>.</abstract>
      <url hash="649a092c">2020.sigdial-1.7</url>
      <video href="https://youtube.com/watch?v=ipGAj_qLXz4" />
      <bibkey>kohn-etal-2020-mc</bibkey>
    </paper>
    <paper id="10">
      <title>Identifying Collaborative Conversations using Latent Discourse Behaviors</title>
      <author><first>Ayush</first><last>Jain</last></author>
      <author><first>Maria Leonor</first><last>Pacheco</last></author>
      <author><first>Steven</first><last>Lancette</last></author>
      <author><first>Mahak</first><last>Goindani</last></author>
      <author><first>Dan</first><last>Goldwasser</last></author>
      <pages>74–78</pages>
      <abstract>In this work, we study collaborative online conversations. Such <a href="https://en.wikipedia.org/wiki/Conversation">conversations</a> are rich in content, constructive and motivated by a shared goal. Automatically identifying such conversations requires modeling complex discourse behaviors, which characterize the flow of information, <a href="https://en.wikipedia.org/wiki/Sentimentality">sentiment</a> and <a href="https://en.wikipedia.org/wiki/Community_structure">community structure</a> within discussions. To help capture these <a href="https://en.wikipedia.org/wiki/Behavior">behaviors</a>, we define a hybrid relational model in which relevant discourse behaviors are formulated as discrete latent variables and scored using <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a>. These <a href="https://en.wikipedia.org/wiki/Variable_(mathematics)">variables</a> provide the information needed for predicting the overall collaborative characterization of the entire conversational thread. We show that adding <a href="https://en.wikipedia.org/wiki/Inductive_bias">inductive bias</a> in the form of <a href="https://en.wikipedia.org/wiki/Latent_variable">latent variables</a> results in performance improvement, while providing a natural way to explain the decision.</abstract>
      <url hash="99f84b81">2020.sigdial-1.10</url>
      <bibkey>jain-etal-2020-identifying</bibkey>
    </paper>
    <paper id="14">
      <title>Learning and Reasoning for Robot Dialog and Navigation Tasks</title>
      <author><first>Keting</first><last>Lu</last></author>
      <author><first>Shiqi</first><last>Zhang</last></author>
      <author><first>Peter</first><last>Stone</last></author>
      <author><first>Xiaoping</first><last>Chen</last></author>
      <pages>107–117</pages>
      <abstract>Reinforcement learning and probabilistic reasoning algorithms aim at learning from interaction experiences and reasoning with probabilistic contextual knowledge respectively. In this research, we develop <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> for robot task completions, while looking into the complementary strengths of <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> and probabilistic reasoning techniques. The robots learn from trial-and-error experiences to augment their declarative knowledge base, and the augmented knowledge can be used for speeding up the learning process in potentially different tasks. We have implemented and evaluated the developed <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> using <a href="https://en.wikipedia.org/wiki/Mobile_robot">mobile robots</a> conducting dialog and navigation tasks. From the results, we see that our <a href="https://en.wikipedia.org/wiki/Robot">robot</a>’s performance can be improved by both reasoning with <a href="https://en.wikipedia.org/wiki/Knowledge">human knowledge</a> and learning from task-completion experience. More interestingly, the <a href="https://en.wikipedia.org/wiki/Robot">robot</a> was able to learn from navigation tasks to improve its dialog strategies.</abstract>
      <url hash="f3873d64">2020.sigdial-1.14</url>
      <video href="https://youtube.com/watch?v=KS4LPkdFyBU" />
      <revision id="1" href="2020.sigdial-1.14v1" hash="681a0ae1" />
      <revision id="2" href="2020.sigdial-1.14v2" hash="f3873d64" date="2020-09-08">A sponsor was removed from the Acknowledgments section.</revision>
      <bibkey>lu-etal-2020-learning</bibkey>
    </paper>
    <paper id="15">
      <title>An Attentive Listening System with Android ERICA : Comparison of Autonomous and WOZ Interactions<fixed-case>ERICA</fixed-case>: Comparison of Autonomous and <fixed-case>WOZ</fixed-case> Interactions</title>
      <author><first>Koji</first><last>Inoue</last></author>
      <author><first>Divesh</first><last>Lala</last></author>
      <author><first>Kenta</first><last>Yamamoto</last></author>
      <author><first>Shizuka</first><last>Nakamura</last></author>
      <author><first>Katsuya</first><last>Takanashi</last></author>
      <author><first>Tatsuya</first><last>Kawahara</last></author>
      <pages>118–127</pages>
      <abstract>We describe an attentive listening system for the autonomous android robot ERICA. The proposed system generates several types of listener responses : backchannels, repeats, elaborating questions, assessments, generic sentimental responses, and generic responses. In this paper, we report a subjective experiment with 20 elderly people. First, we evaluated each system utterance excluding backchannels and generic responses, in an offline manner. It was found that most of the system utterances were linguistically appropriate, and they elicited positive reactions from the subjects. Furthermore, 58.2 % of the responses were acknowledged as being appropriate listener responses. We also compared the proposed <a href="https://en.wikipedia.org/wiki/System">system</a> with a WOZ system where a human operator was operating the robot. From the subjective evaluation, the proposed system achieved comparable scores in basic skills of attentive listening such as encouragement to talk, focused on the talk, and actively listening. It was also found that there is still a gap between the <a href="https://en.wikipedia.org/wiki/System">system</a> and the WOZ for more sophisticated skills such as dialogue understanding, showing interest, and empathy towards the user.</abstract>
      <url hash="7bcad570">2020.sigdial-1.15</url>
      <video href="https://youtube.com/watch?v=Ds4LiqSh_EA" />
      <bibkey>inoue-etal-2020-attentive</bibkey>
    </paper>
    <paper id="18">
      <title>Discovering Knowledge Graph Schema from Short Natural Language Text via Dialog</title>
      <author><first>Subhasis</first><last>Ghosh</last></author>
      <author><first>Arpita</first><last>Kundu</last></author>
      <author><first>Aniket</first><last>Pramanick</last></author>
      <author><first>Indrajit</first><last>Bhattacharya</last></author>
      <pages>136–146</pages>
      <abstract>We study the problem of schema discovery for <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graphs</a>. We propose a <a href="https://en.wikipedia.org/wiki/Solution">solution</a> where an agent engages in multi-turn dialog with an expert for this purpose. Each mini-dialog focuses on a short natural language statement, and looks to elicit the expert’s desired schema-based interpretation of that statement, taking into account possible augmentations to the schema. The overall schema evolves by performing <a href="https://en.wikipedia.org/wiki/Dialogue">dialog</a> over a collection of such statements. We take into account the probability that the expert does not respond to a query, and model this probability as a function of the <a href="https://en.wikipedia.org/wiki/Computational_complexity_theory">complexity</a> of the query. For such mini-dialogs with response uncertainty, we propose a dialog strategy that looks to elicit the schema over as short a dialog as possible. By combining the notion of uncertainty sampling from active learning with generalized binary search, the strategy asks the query with the highest expected reduction of entropy. We show that this significantly reduces dialog complexity while engaging the expert in meaningful dialog.</abstract>
      <url hash="ab21813f">2020.sigdial-1.18</url>
      <video href="https://youtube.com/watch?v=OD_c-tim8JI" />
      <bibkey>ghosh-etal-2020-discovering</bibkey>
    </paper>
    <paper id="19">
      <title>User Impressions of Questions to Acquire Lexical Knowledge</title>
      <author><first>Kazunori</first><last>Komatani</last></author>
      <author><first>Mikio</first><last>Nakano</last></author>
      <pages>147–156</pages>
      <abstract>For the acquisition of knowledge through <a href="https://en.wikipedia.org/wiki/Dialogue">dialogues</a>, it is crucial for systems to ask questions that do not diminish the user’s willingness to talk, i.e., that do not degrade the user’s impression. This paper reports the results of our analysis on how user impression changes depending on the types of questions to acquire lexical knowledge, that is, explicit and implicit questions, and the correctness of the content of the questions. We also analyzed how sequences of the same type of questions affect <a href="https://en.wikipedia.org/wiki/User_experience">user impression</a>. User impression scores were collected from 104 participants recruited via <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourcing</a> and then <a href="https://en.wikipedia.org/wiki/Regression_analysis">regression analysis</a> was conducted. The results demonstrate that implicit questions give a good impression when their content is correct, but a bad impression otherwise. We also found that consecutive explicit questions are more annoying than implicit ones when the content of the questions is correct. Our findings reveal helpful insights for creating a <a href="https://en.wikipedia.org/wiki/Strategy">strategy</a> to avoid user impression deterioration during <a href="https://en.wikipedia.org/wiki/Knowledge_acquisition">knowledge acquisition</a>.</abstract>
      <url hash="b4a55b09">2020.sigdial-1.19</url>
      <video href="https://youtube.com/watch?v=-i9XnHcoIRc" />
      <bibkey>komatani-nakano-2020-user</bibkey>
    </paper>
    <paper id="20">
      <title>Simulating Turn-Taking in Conversations with Delayed Transmission</title>
      <author><first>Thilo</first><last>Michael</last></author>
      <author><first>Sebastian</first><last>Möller</last></author>
      <pages>157–161</pages>
      <abstract>Conversations over the telephone require timely turn-taking cues that signal the participants when to speak and when to listen. When a two-way transmission delay is introduced into such <a href="https://en.wikipedia.org/wiki/Conversation">conversations</a>, the immediate feedback is delayed, and the interactivity of the conversation is impaired. With <a href="https://en.wikipedia.org/wiki/Delayed_speech">delayed speech</a> on each side of the transmission, different conversation realities emerge on both ends, which alters the way the participants interact with each other. Simulating conversations can give insights on turn-taking and spoken interactions between humans but can also used for analyzing and even predicting human behavior in conversations. In this paper, we simulate two types of <a href="https://en.wikipedia.org/wiki/Conversation">conversations</a> with distinct levels of <a href="https://en.wikipedia.org/wiki/Interactivity">interactivity</a>. We then introduce three levels of two-way transmission delay between the agents and compare the resulting interaction-patterns with human-to-human dialog from an empirical study. We show how the turn-taking mechanisms modeled for conversations without delay perform in scenarios with delay and identify to which extend the <a href="https://en.wikipedia.org/wiki/Simulation">simulation</a> is able to model the delayed turn-taking observed in human conversation.</abstract>
      <url hash="816d6543">2020.sigdial-1.20</url>
      <video href="https://youtube.com/watch?v=9jerzgGw0pY" />
      <bibkey>michael-moller-2020-simulating</bibkey>
    </paper>
    <paper id="21">
      <title>Is this Dialogue Coherent? Learning from Dialogue Acts and Entities</title>
      <author><first>Alessandra</first><last>Cervone</last></author>
      <author><first>Giuseppe</first><last>Riccardi</last></author>
      <pages>162–174</pages>
      <abstract>In this work, we investigate the <a href="https://en.wikipedia.org/wiki/Coherence_(linguistics)">human perception of coherence</a> in open-domain dialogues. In particular, we address the problem of annotating and modeling the coherence of next-turn candidates while considering the entire history of the dialogue. First, we create the Switchboard Coherence (SWBD-Coh) corpus, a dataset of human-human spoken dialogues annotated with turn coherence ratings, where next-turn candidate utterances ratings are provided considering the full dialogue context. Our statistical analysis of the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> indicates how turn coherence perception is affected by patterns of distribution of entities previously introduced and the Dialogue Acts used. Second, we experiment with different architectures to model entities, Dialogue Acts and their combination and evaluate their performance in predicting human coherence ratings on SWBD-Coh. We find that models combining both DA and <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity information</a> yield the best performances both for response selection and turn coherence rating.</abstract>
      <url hash="d62102f6">2020.sigdial-1.21</url>
      <video href="https://youtube.com/watch?v=IIcHVI9Kc0Y" />
      <bibkey>cervone-riccardi-2020-dialogue</bibkey>
      <pwccode url="https://github.com/alecervi/switchboard-coherence-corpus" additional="true">alecervi/switchboard-coherence-corpus</pwccode>
    </paper>
    <paper id="23">
      <title>Contextualized Emotion Recognition in Conversation as Sequence Tagging</title>
      <author><first>Yan</first><last>Wang</last></author>
      <author><first>Jiayu</first><last>Zhang</last></author>
      <author><first>Jun</first><last>Ma</last></author>
      <author><first>Shaojun</first><last>Wang</last></author>
      <author><first>Jing</first><last>Xiao</last></author>
      <pages>186–195</pages>
      <abstract>Emotion recognition in conversation (ERC) is an important topic for developing empathetic machines in a variety of areas including social opinion mining, <a href="https://en.wikipedia.org/wiki/Health_care">health-care</a> and so on. In this paper, we propose a method to model ERC task as sequence tagging where a Conditional Random Field (CRF) layer is leveraged to learn the emotional consistency in the conversation. We employ LSTM-based encoders that capture self and inter-speaker dependency of interlocutors to generate contextualized utterance representations which are fed into the CRF layer. For capturing long-range global context, we use a multi-layer Transformer encoder to enhance the LSTM-based encoder. Experiments show that our method benefits from modeling the emotional consistency and outperforms the current state-of-the-art methods on multiple emotion classification datasets.</abstract>
      <url hash="6416ca30">2020.sigdial-1.23</url>
      <video href="https://youtube.com/watch?v=1PH6JXbc3EI" />
      <bibkey>wang-etal-2020-contextualized</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/dailydialog">DailyDialog</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/iemocap">IEMOCAP</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/meld">MELD</pwcdataset>
    </paper>
    <paper id="31">
      <title>Agent-Based Dynamic Collaboration Support in a Smart Office Space</title>
      <author><first>Yansen</first><last>Wang</last></author>
      <author><first>R. Charles</first><last>Murray</last></author>
      <author><first>Haogang</first><last>Bao</last></author>
      <author><first>Carolyn</first><last>Rose</last></author>
      <pages>257–260</pages>
      <abstract>For the past 15 years, in computer-supported collaborative learning applications, conversational agents have been used to structure group interactions in online chat-based environments. A series of experimental studies has provided an empirical foundation for the design of chat-based conversational agents that significantly improve learning over no-support control conditions and static-support control conditions. In this demo, we expand upon this foundation, bringing conversational agents to structure group interaction into physical spaces, with the specific goal of facilitating <a href="https://en.wikipedia.org/wiki/Collaboration">collaboration</a> and <a href="https://en.wikipedia.org/wiki/Learning">learning</a> in workplace scenarios.</abstract>
      <url hash="8d12f903">2020.sigdial-1.31</url>
      <video href="https://youtube.com/watch?v=3uC3ZJSL2Xc" />
      <bibkey>wang-etal-2020-agent</bibkey>
    </paper>
    <paper id="34">
      <title>A Sequence-to-sequence Approach for Numerical Slot-filling Dialog Systems</title>
      <author><first>Hongjie</first><last>Shi</last></author>
      <pages>272–277</pages>
      <abstract>Dialog systems capable of filling slots with numerical values have wide applicability to many task-oriented applications. In this paper, we perform a particular case study on the number_of_guests slot-filling in hotel reservation domain, and propose two methods to improve current dialog system model on 1. numerical reasoning performance by training the model to predict arithmetic expressions, and 2. multi-turn question generation by introducing additional context slots. Furthermore, because the proposed methods are all based on an end-to-end trainable sequence-to-sequence (seq2seq) neural model, it is possible to achieve further performance improvement on increasing dialog logs in the future.</abstract>
      <url hash="e62fb03c">2020.sigdial-1.34</url>
      <video href="https://youtube.com/watch?v=p8cvYEjct5g" />
      <bibkey>shi-2020-sequence</bibkey>
    </paper>
    <paper id="38">
      <title>Similarity Scoring for Dialogue Behaviour Comparison</title>
      <author><first>Stefan</first><last>Ultes</last></author>
      <author><first>Wolfgang</first><last>Maier</last></author>
      <pages>311–322</pages>
      <abstract>The differences in <a href="https://en.wikipedia.org/wiki/Decision-making">decision making</a> between behavioural models of voice interfaces are hard to capture using existing measures for the absolute performance of such <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>. For instance, two <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> may have a similar task success rate, but very different ways of getting there. In this paper, we propose a general <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> to compute the <a href="https://en.wikipedia.org/wiki/Similarity_measure">similarity</a> of two dialogue behaviour models and investigate different ways of computing scores on both the semantic and the textual level. Complementing absolute measures of performance, we test our scores on three different <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> and show the practical usability of the <a href="https://en.wikipedia.org/wiki/Measurement">measures</a>.</abstract>
      <url hash="84acdb32">2020.sigdial-1.38</url>
      <video href="https://youtube.com/watch?v=zs0yOpHWBf8" />
      <bibkey>ultes-maier-2020-similarity</bibkey>
    </paper>
    <paper id="39">
      <title>Collection and Analysis of Dialogues Provided by Two Speakers Acting as One</title>
      <author><first>Tsunehiro</first><last>Arimoto</last></author>
      <author><first>Ryuichiro</first><last>Higashinaka</last></author>
      <author><first>Kou</first><last>Tanaka</last></author>
      <author><first>Takahito</first><last>Kawanishi</last></author>
      <author><first>Hiroaki</first><last>Sugiyama</last></author>
      <author><first>Hiroshi</first><last>Sawada</last></author>
      <author><first>Hiroshi</first><last>Ishiguro</last></author>
      <pages>323–328</pages>
      <abstract>We are studying a cooperation style where multiple speakers can provide both advanced dialogue services and operator education. We focus on a style in which two operators interact with a user by pretending to be a single operator. For two operators to effectively act as one, each must adjust his / her conversational content and timing to the other. In the process, we expect each operator to experience the conversational content of his / her partner as if it were his / her own, creating efficient and effective learning of the other’s skill. We analyzed this educational effect and examined whether dialogue services can be successfully provided by collecting travel guidance dialogue data from operators who give travel information to users. In this paper, we report our preliminary results on dialogue content and user satisfaction of operators and users.</abstract>
      <url hash="18cb50ab">2020.sigdial-1.39</url>
      <video href="https://youtube.com/watch?v=hFIHx-PqzDE" />
      <bibkey>arimoto-etal-2020-collection</bibkey>
    </paper>
    </volume>
</collection>