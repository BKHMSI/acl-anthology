<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.clinicalnlp">
  <volume id="1" ingest-date="2020-11-06">
    <meta>
      <booktitle>Proceedings of the 3rd Clinical Natural Language Processing Workshop</booktitle>
      <editor><first>Anna</first><last>Rumshisky</last></editor>
      <editor><first>Kirk</first><last>Roberts</last></editor>
      <editor><first>Steven</first><last>Bethard</last></editor>
      <editor><first>Tristan</first><last>Naumann</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>November</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="794ae931">2020.clinicalnlp-1.0</url>
      <bibkey>clinicalnlp-2020-clinical</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Various Approaches for Predicting Stroke Prognosis using Magnetic Resonance Imaging Text Records</title>
      <author><first>Tak-Sung</first><last>Heo</last></author>
      <author><first>Chulho</first><last>Kim</last></author>
      <author><first>Jeong-Myeong</first><last>Choi</last></author>
      <author><first>Yeong-Seok</first><last>Jeong</last></author>
      <author><first>Yu-Seop</first><last>Kim</last></author>
      <pages>1–6</pages>
      <abstract>Stroke is one of the leading causes of death and disability worldwide. Stroke is treatable, but <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> is prone to disability after treatment and must be prevented. To grasp the degree of disability caused by <a href="https://en.wikipedia.org/wiki/Stroke">stroke</a>, we use magnetic resonance imaging text records to predict <a href="https://en.wikipedia.org/wiki/Stroke">stroke</a> and measure the performance according to the document-level and sentence-level representation. As a result of the experiment, the document-level representation shows better performance.</abstract>
      <url hash="3479fe47">2020.clinicalnlp-1.1</url>
      <doi>10.18653/v1/2020.clinicalnlp-1.1</doi>
      <video href="https://slideslive.com/38939817" />
      <bibkey>heo-etal-2020-various</bibkey>
    </paper>
    <paper id="3">
      <title>BERT-XML : Large Scale Automated ICD Coding Using BERT Pretraining<fixed-case>BERT</fixed-case>-<fixed-case>XML</fixed-case>: Large Scale Automated <fixed-case>ICD</fixed-case> Coding Using <fixed-case>BERT</fixed-case> Pretraining</title>
      <author><first>Zachariah</first><last>Zhang</last></author>
      <author><first>Jingshu</first><last>Liu</last></author>
      <author><first>Narges</first><last>Razavian</last></author>
      <pages>24–34</pages>
      <abstract>ICD coding is the task of classifying and cod-ing all diagnoses, symptoms and proceduresassociated with a patient’s visit. The process isoften manual, extremely time-consuming andexpensive for hospitals as clinical interactionsare usually recorded in free text medical notes. In this paper, we propose a machine learningmodel, BERT-XML, for large scale automatedICD coding of EHR notes, utilizing recentlydeveloped unsupervised pretraining that haveachieved state of the art performance on a va-riety of NLP tasks. We train a BERT modelfrom scratch on EHR notes, learning with vo-cabulary better suited for EHR tasks and thusoutperform off-the-shelf models. We furtheradapt the BERT architecture for ICD codingwith multi-label attention. We demonstratethe effectiveness of BERT-based models on thelarge scale ICD code classification task usingmillions of EHR notes to predict thousands ofunique codes.</abstract>
      <url hash="2fa42ef4">2020.clinicalnlp-1.3</url>
      <doi>10.18653/v1/2020.clinicalnlp-1.3</doi>
      <video href="https://slideslive.com/38939836" />
      <bibkey>zhang-etal-2020-bert</bibkey>
    </paper>
    <paper id="4">
      <title>Incorporating Risk Factor Embeddings in Pre-trained Transformers Improves Sentiment Prediction in Psychiatric Discharge Summaries</title>
      <author><first>Xiyu</first><last>Ding</last></author>
      <author><first>Mei-Hua</first><last>Hall</last></author>
      <author><first>Timothy</first><last>Miller</last></author>
      <pages>35–40</pages>
      <abstract>Reducing rates of early hospital readmission has been recognized and identified as a key to improve quality of care and reduce costs. There are a number of <a href="https://en.wikipedia.org/wiki/Risk_factor">risk factors</a> that have been hypothesized to be important for understanding re-admission risk, including such factors as problems with substance abuse, ability to maintain work, relations with family. In this work, we develop Roberta-based models to predict the sentiment of sentences describing readmission risk factors in discharge summaries of patients with psychosis. We improve substantially on previous results by a scheme that shares information across <a href="https://en.wikipedia.org/wiki/Risk_factor">risk factors</a> while also allowing the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> to learn risk factor-specific information.</abstract>
      <url hash="4a86ef4f">2020.clinicalnlp-1.4</url>
      <doi>10.18653/v1/2020.clinicalnlp-1.4</doi>
      <video href="https://slideslive.com/38939823" />
      <bibkey>ding-etal-2020-incorporating</bibkey>
    </paper>
    <paper id="7">
      <title>BioBERTpt-A Portuguese Neural Language Model for Clinical Named Entity Recognition<fixed-case>B</fixed-case>io<fixed-case>BERT</fixed-case>pt - A <fixed-case>P</fixed-case>ortuguese Neural Language Model for Clinical Named Entity Recognition</title>
      <author><first>Elisa Terumi Rubel</first><last>Schneider</last></author>
      <author><first>João Vitor Andrioli</first><last>de Souza</last></author>
      <author><first>Julien</first><last>Knafou</last></author>
      <author><first>Lucas Emanuel Silva e</first><last>Oliveira</last></author>
      <author><first>Jenny</first><last>Copara</last></author>
      <author><first>Yohan Bonescki</first><last>Gumiel</last></author>
      <author><first>Lucas Ferro Antunes de</first><last>Oliveira</last></author>
      <author><first>Emerson Cabrera</first><last>Paraiso</last></author>
      <author><first>Douglas</first><last>Teodoro</last></author>
      <author><first>Cláudia Maria Cabral Moro</first><last>Barra</last></author>
      <pages>65–72</pages>
      <abstract>With the growing number of <a href="https://en.wikipedia.org/wiki/Electronic_health_record">electronic health record data</a>, clinical NLP tasks have become increasingly relevant to unlock valuable information from unstructured clinical text. Although the performance of downstream NLP tasks, such as named-entity recognition (NER), in English corpus has recently improved by contextualised language models, less research is available for clinical texts in low resource languages. Our goal is to assess a deep contextual embedding model for <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a>, so called BioBERTpt, to support clinical and biomedical NER. We transfer learned information encoded in a multilingual-BERT model to a corpora of clinical narratives and biomedical-scientific papers in <a href="https://en.wikipedia.org/wiki/Brazilian_Portuguese">Brazilian Portuguese</a>. To evaluate the performance of BioBERTpt, we ran NER experiments on two annotated corpora containing clinical narratives and compared the results with existing BERT models. Our in-domain model outperformed the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline model</a> in <a href="https://en.wikipedia.org/wiki/F-number">F1-score</a> by 2.72 %, achieving higher performance in 11 out of 13 assessed entities. We demonstrate that enriching contextual embedding models with domain literature can play an important role in improving performance for specific NLP tasks. The transfer learning process enhanced the Portuguese biomedical NER model by reducing the necessity of labeled data and the demand for retraining a whole new <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>.</abstract>
      <url hash="bcfce65d">2020.clinicalnlp-1.7</url>
      <doi>10.18653/v1/2020.clinicalnlp-1.7</doi>
      <video href="https://slideslive.com/38939829" />
      <bibkey>schneider-etal-2020-biobertpt</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/semclinbr">SemClinBr</pwcdataset>
    </paper>
    <paper id="13">
      <title>How You Ask Matters : The Effect of Paraphrastic Questions to BERT Performance on a Clinical SQuAD Dataset<fixed-case>BERT</fixed-case> Performance on a Clinical <fixed-case>SQ</fixed-case>u<fixed-case>AD</fixed-case> Dataset</title>
      <author><first>Sungrim (Riea)</first><last>Moon</last></author>
      <author><first>Jungwei</first><last>Fan</last></author>
      <pages>111–116</pages>
      <abstract>Reading comprehension style question-answering (QA) based on patient-specific documents represents a growing area in clinical NLP with plentiful applications. Bidirectional Encoder Representations from Transformers (BERT) and its derivatives lead the state-of-the-art accuracy on the task, but most evaluation has treated the data as a pre-mixture without systematically looking into the potential effect of imperfect train / test questions. The current study seeks to address this gap by experimenting with full versus partial train / test data consisting of paraphrastic questions. Our key findings include 1) training with all pooled question variants yielded best <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>, 2) the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> varied widely, from 0.74 to 0.80, when trained with each single question variant, and 3) questions of similar lexical / syntactic structure tended to induce identical answers. The results suggest that how you ask questions matters in BERT-based QA, especially at the training stage.</abstract>
      <url hash="02b90c0a">2020.clinicalnlp-1.13</url>
      <doi>10.18653/v1/2020.clinicalnlp-1.13</doi>
      <video href="https://slideslive.com/38939814" />
      <bibkey>moon-fan-2020-ask</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/emrqa">emrQA</pwcdataset>
    </paper>
    <paper id="15">
      <title>MeDAL : Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining<fixed-case>M</fixed-case>e<fixed-case>DAL</fixed-case>: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining</title>
      <author><first>Zhi</first><last>Wen</last></author>
      <author><first>Xing Han</first><last>Lu</last></author>
      <author><first>Siva</first><last>Reddy</last></author>
      <pages>130–135</pages>
      <abstract>One of the biggest challenges that prohibit the use of many current <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP methods</a> in clinical settings is the availability of <a href="https://en.wikipedia.org/wiki/Data_set">public datasets</a>. In this work, we present MeDAL, a large medical text dataset curated for abbreviation disambiguation, designed for <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language understanding</a> pre-training in the medical domain. We pre-trained several models of common architectures on this dataset and empirically showed that such pre-training leads to improved performance and <a href="https://en.wikipedia.org/wiki/Convergence_of_random_variables">convergence speed</a> when <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a> on downstream medical tasks.</abstract>
      <url hash="5eaf318e">2020.clinicalnlp-1.15</url>
      <attachment type="OptionalSupplementaryMaterial" hash="a36a04dd">2020.clinicalnlp-1.15.OptionalSupplementaryMaterial.zip</attachment>
      <doi>10.18653/v1/2020.clinicalnlp-1.15</doi>
      <video href="https://slideslive.com/38939819" />
      <bibkey>wen-etal-2020-medal</bibkey>
      <pwccode url="https://github.com/BruceWen120/medal" additional="false">BruceWen120/medal</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/medal">MeDAL</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/adam">ADAM</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mimic-iii">MIMIC-III</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/pubmed">Pubmed</pwcdataset>
    </paper>
    <paper id="21">
      <title>Extracting Relations between Radiotherapy Treatment Details</title>
      <author><first>Danielle</first><last>Bitterman</last></author>
      <author><first>Timothy</first><last>Miller</last></author>
      <author><first>David</first><last>Harris</last></author>
      <author><first>Chen</first><last>Lin</last></author>
      <author><first>Sean</first><last>Finan</last></author>
      <author><first>Jeremy</first><last>Warner</last></author>
      <author><first>Raymond</first><last>Mak</last></author>
      <author><first>Guergana</first><last>Savova</last></author>
      <pages>194–200</pages>
      <abstract>We present work on extraction of radiotherapy treatment information from the clinical narrative in the <a href="https://en.wikipedia.org/wiki/Electronic_health_record">electronic medical records</a>. Radiotherapy is a central component of the treatment of most solid cancers. Its details are described in non-standardized fashions using jargon not found in other medical specialties, complicating the already difficult task of manual data extraction. We examine the performance of several state-of-the-art neural methods for relation extraction of radiotherapy treatment details, with a goal of automating detailed information extraction. The <a href="https://en.wikipedia.org/wiki/Nervous_system">neural systems</a> perform at 0.82-0.88 macro-average F1, which approximates or in some cases exceeds the <a href="https://en.wikipedia.org/wiki/Inter-annotator_agreement">inter-annotator agreement</a>. To the best of our knowledge, this is the first effort to develop models for radiotherapy relation extraction and one of the few efforts for <a href="https://en.wikipedia.org/wiki/Relation_extraction">relation extraction</a> to describe <a href="https://en.wikipedia.org/wiki/Treatment_of_cancer">cancer treatment</a> in general.</abstract>
      <url hash="09caa91e">2020.clinicalnlp-1.21</url>
      <doi>10.18653/v1/2020.clinicalnlp-1.21</doi>
      <video href="https://slideslive.com/38939827" />
      <bibkey>bitterman-etal-2020-extracting</bibkey>
    </paper>
    <paper id="22">
      <title>Cancer Registry Information Extraction via <a href="https://en.wikipedia.org/wiki/Transfer_learning">Transfer Learning</a></title>
      <author><first>Yan-Jie</first><last>Lin</last></author>
      <author><first>Hong-Jie</first><last>Dai</last></author>
      <author><first>You-Chen</first><last>Zhang</last></author>
      <author><first>Chung-Yang</first><last>Wu</last></author>
      <author><first>Yu-Cheng</first><last>Chang</last></author>
      <author><first>Pin-Jou</first><last>Lu</last></author>
      <author><first>Chih-Jen</first><last>Huang</last></author>
      <author><first>Yu-Tsang</first><last>Wang</last></author>
      <author><first>Hui-Min</first><last>Hsieh</last></author>
      <author><first>Kun-San</first><last>Chao</last></author>
      <author><first>Tsang-Wu</first><last>Liu</last></author>
      <author><first>I-Shou</first><last>Chang</last></author>
      <author><first>Yi-Hsin Connie</first><last>Yang</last></author>
      <author><first>Ti-Hao</first><last>Wang</last></author>
      <author><first>Ko-Jiunn</first><last>Liu</last></author>
      <author><first>Li-Tzong</first><last>Chen</last></author>
      <author><first>Sheau-Fang</first><last>Yang</last></author>
      <pages>201–208</pages>
      <abstract>A <a href="https://en.wikipedia.org/wiki/Cancer_registry">cancer registry</a> is a critical and massive database for which various types of <a href="https://en.wikipedia.org/wiki/Domain_knowledge">domain knowledge</a> are needed and whose maintenance requires labor-intensive <a href="https://en.wikipedia.org/wiki/Data_curation">data curation</a>. In order to facilitate the curation process for building a high-quality and integrated cancer registry database, we compiled a cross-hospital corpus and applied neural network methods to develop a natural language processing system for extracting cancer registry variables buried in unstructured pathology reports. The performance of the developed networks was compared with various baselines using standard <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">micro-precision</a>, recall and <a href="https://en.wikipedia.org/wiki/F-measure">F-measure</a>. Furthermore, we conducted experiments to study the feasibility of applying <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> to rapidly develop a well-performing <a href="https://en.wikipedia.org/wiki/System">system</a> for processing reports from different sources that might be presented in different writing styles and formats. The results demonstrate that the transfer learning method enables us to develop a satisfactory <a href="https://en.wikipedia.org/wiki/System">system</a> for a new hospital with only a few annotations and suggest more opportunities to reduce the burden of <a href="https://en.wikipedia.org/wiki/Cancer_registry">cancer registry curation</a>.</abstract>
      <url hash="837bfaa6">2020.clinicalnlp-1.22</url>
      <doi>10.18653/v1/2020.clinicalnlp-1.22</doi>
      <video href="https://slideslive.com/38939830" />
      <bibkey>lin-etal-2020-cancer</bibkey>
    </paper>
    <paper id="24">
      <title>Where’s the Question? A Multi-channel Deep Convolutional Neural Network for Question Identification in Textual Data</title>
      <author><first>George</first><last>Michalopoulos</last></author>
      <author><first>Helen</first><last>Chen</last></author>
      <author><first>Alexander</first><last>Wong</last></author>
      <pages>215–226</pages>
      <abstract>In most clinical practice settings, there is no rigorous reviewing of the clinical documentation, resulting in inaccurate information captured in the patient medical records. The gold standard in clinical data capturing is achieved via expert-review, where clinicians can have a dialogue with a domain expert (reviewers) and ask them questions about data entry rules. Automatically identifying real questions in these dialogues could uncover ambiguities or common problems in data capturing in a given clinical setting. In this study, we proposed a novel multi-channel deep convolutional neural network architecture, namely Quest-CNN, for the purpose of separating real questions that expect an answer (information or help) about an issue from sentences that are not questions, as well as from questions referring to an issue mentioned in a nearby sentence (e.g., can you clarify this?), which we will refer as c-questions. We conducted a comprehensive performance comparison analysis of the proposed multi-channel deep convolutional neural network against other <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural networks</a>. Furthermore, we evaluated the performance of traditional rule-based and learning-based methods for detecting question sentences. The proposed Quest-CNN achieved the best F1 score both on a dataset of data entry-review dialogue in a dialysis care setting, and on a general domain dataset.</abstract>
      <url hash="8cf7e093">2020.clinicalnlp-1.24</url>
      <doi>10.18653/v1/2020.clinicalnlp-1.24</doi>
      <video href="https://slideslive.com/38939833" />
      <bibkey>michalopoulos-etal-2020-wheres</bibkey>
    </paper>
    <paper id="28">
      <title>An Ensemble Approach for Automatic Structuring of Radiology Reports</title>
      <author><first>Morteza</first><last>Pourreza Shahri</last></author>
      <author><first>Amir</first><last>Tahmasebi</last></author>
      <author><first>Bingyang</first><last>Ye</last></author>
      <author><first>Henghui</first><last>Zhu</last></author>
      <author><first>Javed</first><last>Aslam</last></author>
      <author><first>Timothy</first><last>Ferris</last></author>
      <pages>249–258</pages>
      <abstract>Automatic structuring of electronic medical records is of high demand for clinical workflow solutions to facilitate extraction, storage, and querying of patient care information. However, developing a scalable solution is extremely challenging, specifically for radiology reports, as most healthcare institutes use either no template or department / institute specific templates. Moreover, radiologists’ reporting style varies from one to another as sentences are written in a telegraphic format and do not follow general English grammar rules. In this work, we present an <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble method</a> that consolidates the predictions of three models, capturing various attributes of textual information for automatic labeling of sentences with section labels. These three models are : 1) Focus Sentence model, capturing context of the target sentence ; 2) Surrounding Context model, capturing the neighboring context of the target sentence ; and finally, 3) Formatting / Layout model, aimed at learning report formatting cues. We utilize Bi-directional LSTMs, followed by sentence encoders, to acquire the context. Furthermore, we define several <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> that incorporate the structure of reports. We compare our proposed approach against multiple baselines and state-of-the-art approaches on a proprietary dataset as well as 100 manually annotated radiology notes from the MIMIC-III dataset, which we are making publicly available. Our proposed <a href="https://en.wikipedia.org/wiki/Scientific_method">approach</a> significantly outperforms other <a href="https://en.wikipedia.org/wiki/Scientific_method">approaches</a> by achieving 97.1 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>.</abstract>
      <url hash="912a4471">2020.clinicalnlp-1.28</url>
      <doi>10.18653/v1/2020.clinicalnlp-1.28</doi>
      <video href="https://slideslive.com/38939816" />
      <bibkey>pourreza-shahri-etal-2020-ensemble</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/mimic-iii">MIMIC-III</pwcdataset>
    </paper>
    <paper id="30">
      <title>Advancing Seq2seq with Joint Paraphrase Learning</title>
      <author><first>So Yeon</first><last>Min</last></author>
      <author><first>Preethi</first><last>Raghavan</last></author>
      <author><first>Peter</first><last>Szolovits</last></author>
      <pages>269–279</pages>
      <abstract>We address the problem of model generalization for sequence to sequence (seq2seq) architectures. We propose going beyond <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a> via paraphrase-optimized multi-task learning and observe that it is useful in correctly handling unseen sentential paraphrases as inputs. Our <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> greatly outperform SOTA seq2seq models for <a href="https://en.wikipedia.org/wiki/Semantic_analysis_(linguistics)">semantic parsing</a> on diverse domains (Overnight-up to 3.2 % and emrQA-7 %) and <a href="https://en.wikipedia.org/wiki/Nematus">Nematus</a>, the winning solution for WMT 2017, for <a href="https://en.wikipedia.org/wiki/Czech_language">Czech to English translation</a> (CzENG 1.6-1.5 BLEU).</abstract>
      <url hash="bdb0b4cb">2020.clinicalnlp-1.30</url>
      <doi>10.18653/v1/2020.clinicalnlp-1.30</doi>
      <video href="https://slideslive.com/38939834" />
      <bibkey>min-etal-2020-advancing</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/emrqa">emrQA</pwcdataset>
    </paper>
    <paper id="31">
      <title>On the diminishing return of labeling clinical reports</title>
      <author><first>Jean-Baptiste</first><last>Lamare</last></author>
      <author><first>Oloruntobiloba</first><last>Olatunji</last></author>
      <author><first>Li</first><last>Yao</last></author>
      <pages>280–290</pages>
      <abstract>Ample evidence suggests that better machine learning models may be steadily obtained by training on increasingly larger datasets on natural language processing (NLP) problems from non-medical domains. Whether the same holds true for medical NLP has by far not been thoroughly investigated. This work shows that this is indeed not always the case. We reveal the somehow counter-intuitive observation that performant medical NLP models may be obtained with small amount of labeled data, quite the opposite to the common belief, most likely due to the domain specificity of the problem. We show quantitatively the effect of training data size on a fixed test set composed of two of the largest public chest x-ray radiology report datasets on the task of abnormality classification. The trained <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> not only make use of the training data efficiently, but also outperform the current state-of-the-art <a href="https://en.wikipedia.org/wiki/Rule-based_system">rule-based systems</a> by a significant margin.</abstract>
      <url hash="9fdbf8b6">2020.clinicalnlp-1.31</url>
      <doi>10.18653/v1/2020.clinicalnlp-1.31</doi>
      <video href="https://slideslive.com/38939812" />
      <bibkey>lamare-etal-2020-diminishing</bibkey>
    </paper>
    <paper id="32">
      <title>The Chilean Waiting List Corpus : a new resource for clinical Named Entity Recognition in Spanish<fixed-case>C</fixed-case>hilean Waiting List Corpus: a new resource for clinical Named Entity Recognition in <fixed-case>S</fixed-case>panish</title>
      <author><first>Pablo</first><last>Báez</last></author>
      <author><first>Fabián</first><last>Villena</last></author>
      <author><first>Matías</first><last>Rojas</last></author>
      <author><first>Manuel</first><last>Durán</last></author>
      <author><first>Jocelyn</first><last>Dunstan</last></author>
      <pages>291–300</pages>
      <abstract>In this work we describe the Waiting List Corpus consisting of de-identified referrals for several specialty consultations from the waiting list in Chilean public hospitals. A subset of 900 referrals was manually annotated with 9,029 entities, 385 attributes, and 284 pairs of relations with clinical relevance. A trained medical doctor annotated these referrals, and then together with other three researchers, consolidated each of the annotations. The annotated corpus has nested entities, with 32.2 % of entities embedded in other entities. We use this annotated corpus to obtain preliminary results for Named Entity Recognition (NER). The best results were achieved by using a biLSTM-CRF architecture using word embeddings trained over <a href="https://en.wikipedia.org/wiki/Spanish_Wikipedia">Spanish Wikipedia</a> together with clinical embeddings computed by the group. NER models applied to this <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> can leverage statistics of diseases and pending procedures within this waiting list. This work constitutes the first <a href="https://en.wikipedia.org/wiki/Text_corpus">annotated corpus</a> using clinical narratives from <a href="https://en.wikipedia.org/wiki/Chile">Chile</a>, and one of the few for the <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish language</a>. The annotated corpus, the clinical word embeddings, and the annotation guidelines are freely released to the research community.</abstract>
      <url hash="c574ca00">2020.clinicalnlp-1.32</url>
      <doi>10.18653/v1/2020.clinicalnlp-1.32</doi>
      <video href="https://slideslive.com/38939828" />
      <bibkey>baez-etal-2020-chilean</bibkey>
    </paper>
    <paper id="33">
      <title>Exploring Text Specific and Blackbox Fairness Algorithms in Multimodal Clinical NLP<fixed-case>NLP</fixed-case></title>
      <author><first>John</first><last>Chen</last></author>
      <author><first>Ian</first><last>Berlot-Attwell</last></author>
      <author><first>Xindi</first><last>Wang</last></author>
      <author><first>Safwan</first><last>Hossain</last></author>
      <author><first>Frank</first><last>Rudzicz</last></author>
      <pages>301–312</pages>
      <abstract>Clinical machine learning is increasingly multimodal, collected in both structured tabular formats and <a href="https://en.wikipedia.org/wiki/Unstructured_data">unstructured forms</a> such as free text. We propose a novel task of exploring fairness on a multimodal clinical dataset, adopting equalized odds for the downstream medical prediction tasks. To this end, we investigate a modality-agnostic fairness algorithm-equalized odds post processing-and compare it to a text-specific fairness algorithm : debiased clinical word embeddings. Despite the fact that debiased word embeddings do not explicitly address equalized odds of protected groups, we show that a text-specific approach to <a href="https://en.wikipedia.org/wiki/Social_justice">fairness</a> may simultaneously achieve a good balance of performance classical notions of <a href="https://en.wikipedia.org/wiki/Social_justice">fairness</a>. Our work opens the door for future work at the critical intersection of clinical NLP and <a href="https://en.wikipedia.org/wiki/Social_justice">fairness</a>.<i>fairness</i> on a multimodal clinical dataset, adopting <i>equalized odds</i> for the downstream medical prediction tasks. To this end, we investigate a modality-agnostic fairness algorithm - equalized odds post processing - and compare it to a text-specific fairness algorithm: debiased clinical word embeddings. Despite the fact that debiased word embeddings do not explicitly address equalized odds of protected groups, we show that a text-specific approach to fairness may simultaneously achieve a good balance of performance classical notions of fairness. Our work opens the door for future work at the critical intersection of clinical NLP and fairness.</abstract>
      <url hash="67e02280">2020.clinicalnlp-1.33</url>
      <doi>10.18653/v1/2020.clinicalnlp-1.33</doi>
      <video href="https://slideslive.com/38939838" />
      <bibkey>chen-etal-2020-exploring</bibkey>
      <pwccode url="https://github.com/johntiger1/multimodal_fairness" additional="false">johntiger1/multimodal_fairness</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/mimic-iii">MIMIC-III</pwcdataset>
    </paper>
  </volume>
</collection>