<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.sdp">
  <volume id="1" ingest-date="2021-05-24">
    <meta>
      <booktitle>Proceedings of the Second Workshop on Scholarly Document Processing</booktitle>
      <editor><first>Iz</first><last>Beltagy</last></editor>
      <editor><first>Arman</first><last>Cohan</last></editor>
      <editor><first>Guy</first><last>Feigenblat</last></editor>
      <editor><first>Dayne</first><last>Freitag</last></editor>
      <editor><first>Tirthankar</first><last>Ghosal</last></editor>
      <editor><first>Keith</first><last>Hall</last></editor>
      <editor><first>Drahomira</first><last>Herrmannova</last></editor>
      <editor><first>Petr</first><last>Knoth</last></editor>
      <editor><first>Kyle</first><last>Lo</last></editor>
      <editor><first>Philipp</first><last>Mayr</last></editor>
      <editor><first>Robert M.</first><last>Patton</last></editor>
      <editor><first>Michal</first><last>Shmueli-Scheuer</last></editor>
      <editor><first>Anita</first><last>de Waard</last></editor>
      <editor><first>Kuansan</first><last>Wang</last></editor>
      <editor><first>Lucy Lu</first><last>Wang</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>June</month>
      <year>2021</year>
      <url hash="85c83d62">2021.sdp-1</url>
    </meta>
    <frontmatter>
      <url hash="f7ce0583">2021.sdp-1.0</url>
      <bibkey>sdp-2021-scholarly</bibkey>
    </frontmatter>
    <paper id="6">
      <title>Keyphrase Extraction from Scientific Articles via Extractive Summarization</title>
      <author><first>Chrysovalantis Giorgos</first><last>Kontoulis</last></author>
      <author><first>Eirini</first><last>Papagiannopoulou</last></author>
      <author><first>Grigorios</first><last>Tsoumakas</last></author>
      <pages>49–55</pages>
      <abstract>Automatically extracting keyphrases from scholarly documents leads to a valuable concise representation that humans can understand and machines can process for tasks, such as <a href="https://en.wikipedia.org/wiki/Information_retrieval">information retrieval</a>, article clustering and article classification. This paper is concerned with the parts of a scientific article that should be given as input to keyphrase extraction methods. Recent deep learning methods take titles and abstracts as input due to the increased <a href="https://en.wikipedia.org/wiki/Computational_complexity_theory">computational complexity</a> in processing long sequences, whereas traditional approaches can also work with <a href="https://en.wikipedia.org/wiki/Text_corpus">full-texts</a>. Titles and abstracts are dense in keyphrases, but often miss important aspects of the articles, while full-texts on the other hand are richer in keyphrases but much noisier. To address this trade-off, we propose the use of extractive summarization models on the full-texts of scholarly documents. Our empirical study on 3 article collections using 3 keyphrase extraction methods shows promising results.</abstract>
      <url hash="ab1057a1">2021.sdp-1.6</url>
      <doi>10.18653/v1/2021.sdp-1.6</doi>
      <bibkey>kontoulis-etal-2021-keyphrase</bibkey>
      <pwccode url="https://github.com/intelligence-csd-auth-gr/keyphrase-extraction-via-summarization" additional="false">intelligence-csd-auth-gr/keyphrase-extraction-via-summarization</pwccode>
    </paper>
    <paper id="9">
      <title>The Effect of Pretraining on Extractive Summarization for Scientific Documents</title>
      <author><first>Yash</first><last>Gupta</last></author>
      <author><first>Pawan Sasanka</first><last>Ammanamanchi</last></author>
      <author><first>Shikha</first><last>Bordia</last></author>
      <author><first>Arjun</first><last>Manoharan</last></author>
      <author><first>Deepak</first><last>Mittal</last></author>
      <author><first>Ramakanth</first><last>Pasunuru</last></author>
      <author><first>Manish</first><last>Shrivastava</last></author>
      <author><first>Maneesh</first><last>Singh</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <author><first>Preethi</first><last>Jyothi</last></author>
      <pages>73–82</pages>
      <abstract>Large pretrained models have seen enormous success in extractive summarization tasks. In this work, we investigate the influence of pretraining on a BERT-based extractive summarization system for <a href="https://en.wikipedia.org/wiki/Scientific_literature">scientific documents</a>. We derive significant performance improvements using an intermediate pretraining step that leverages existing summarization datasets and report state-of-the-art results on a recently released scientific summarization dataset, SciTLDR. We systematically analyze the intermediate pretraining step by varying the size and domain of the pretraining corpus, changing the length of the input sequence in the target task and varying target tasks. We also investigate how intermediate pretraining interacts with contextualized word embeddings trained on different domains.</abstract>
      <url hash="826fc418">2021.sdp-1.9</url>
      <doi>10.18653/v1/2021.sdp-1.9</doi>
      <bibkey>gupta-etal-2021-effect</bibkey>
    </paper>
    <paper id="10">
      <title>Finding Pragmatic Differences Between Disciplines</title>
      <author><first>Lee</first><last>Kezar</last></author>
      <author><first>Jay</first><last>Pujara</last></author>
      <pages>83–90</pages>
      <abstract>Scholarly documents have a great degree of variation, both in terms of content (semantics) and structure (pragmatics). Prior work in scholarly document understanding emphasizes <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> through <a href="https://en.wikipedia.org/wiki/Document_summarization">document summarization</a> and corpus topic modeling but tends to omit <a href="https://en.wikipedia.org/wiki/Pragmatics">pragmatics</a> such as document organization and flow. Using a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus of scholarly documents</a> across 19 disciplines and state-of-the-art language modeling techniques, we learn a fixed set of domain-agnostic descriptors for document sections and retrofit the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> to these descriptors (also referred to as normalization). Then, we analyze the position and ordering of these descriptors across documents to understand the relationship between <a href="https://en.wikipedia.org/wiki/Discipline">discipline</a> and <a href="https://en.wikipedia.org/wiki/Structure">structure</a>. We report within-discipline structural archetypes, variability, and between-discipline comparisons, supporting the hypothesis that scholarly communities, despite their size, diversity, and breadth, share similar avenues for expressing their work. Our findings lay the foundation for future work in assessing research quality, domain style transfer, and further pragmatic analysis.</abstract>
      <url hash="6724d9e5">2021.sdp-1.10</url>
      <doi>10.18653/v1/2021.sdp-1.10</doi>
      <bibkey>kezar-pujara-2021-finding</bibkey>
    </paper>
    <paper id="11">
      <title>Extractive Research Slide Generation Using Windowed Labeling Ranking</title>
      <author><first>Athar</first><last>Sefid</last></author>
      <author><first>Prasenjit</first><last>Mitra</last></author>
      <author><first>Jian</first><last>Wu</last></author>
      <author><first>C Lee</first><last>Giles</last></author>
      <pages>91–96</pages>
      <abstract>Presentation slides generated from original research papers provide an efficient form to present research innovations. Manually generating presentation slides is labor-intensive. We propose a method to automatically generates slides for scientific articles based on a corpus of 5000 paper-slide pairs compiled from conference proceedings websites. The sentence labeling module of our method is based on SummaRuNNer, a neural sequence model for extractive summarization. Instead of ranking sentences based on semantic similarities in the whole document, our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> measures the importance and novelty of sentences by combining semantic and lexical features within a sentence window. Our method outperforms several baseline methods including SummaRuNNer by a significant margin in terms of ROUGE score.</abstract>
      <url hash="3b9dcf40">2021.sdp-1.11</url>
      <doi>10.18653/v1/2021.sdp-1.11</doi>
      <bibkey>sefid-etal-2021-extractive</bibkey>
      <pwccode url="https://github.com/atharsefid/Extractive_Research_Slide_Generation_Using_Windowed_Labeling_Ranking" additional="false">atharsefid/Extractive_Research_Slide_Generation_Using_Windowed_Labeling_Ranking</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/5k-presetation-slides">5k_presetation_slides</pwcdataset>
    </paper>
    <paper id="14">
      <title>Unsupervised document summarization using pre-trained sentence embeddings and graph centrality</title>
      <author><first>Juan</first><last>Ramirez-Orta</last></author>
      <author><first>Evangelos</first><last>Milios</last></author>
      <pages>110–115</pages>
      <abstract>This paper describes our submission for the LongSumm task in SDP 2021. We propose a method for incorporating sentence embeddings produced by deep language models into extractive summarization techniques based on graph centrality in an unsupervised manner. The proposed method is simple, fast, can summarize any kind of document of any size and can satisfy any length constraints for the summaries produced. The method offers competitive performance to more sophisticated <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised methods</a> and can serve as a proxy for abstractive summarization techniques</abstract>
      <url hash="b96b587b">2021.sdp-1.14</url>
      <doi>10.18653/v1/2021.sdp-1.14</doi>
      <bibkey>ramirez-orta-milios-2021-unsupervised</bibkey>
    </paper>
    <paper id="15">
      <title>QMUL-SDS at SCIVER : Step-by-Step Binary Classification for Scientific Claim Verification<fixed-case>QMUL</fixed-case>-<fixed-case>SDS</fixed-case> at <fixed-case>SCIVER</fixed-case>: Step-by-Step Binary Classification for Scientific Claim Verification</title>
      <author><first>Xia</first><last>Zeng</last></author>
      <author><first>Arkaitz</first><last>Zubiaga</last></author>
      <pages>116–123</pages>
      <abstract>Scientific claim verification is a unique challenge that is attracting increasing interest. The SCIVER shared task offers a benchmark scenario to test and compare claim verification approaches by participating teams and consists in three steps : relevant abstract selection, rationale selection and label prediction. In this paper, we present team QMUL-SDS’s participation in the shared task. We propose an approach that performs scientific claim verification by doing binary classifications step-by-step. We trained a BioBERT-large classifier to select abstracts based on pairwise relevance assessments for each claim, title of the abstract and continued to train it to select rationales out of each retrieved abstract based on claim, sentence. We then propose a two-step setting for label prediction, i.e. first predicting NOT_ENOUGH_INFO or ENOUGH_INFO, then label those marked as ENOUGH_INFO as either SUPPORT or CONTRADICT. Compared to the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline system</a>, we achieve substantial improvements on the dev set. As a result, our team is the No. 4 team on the leaderboard.</abstract>
      <url hash="c8ee47ef">2021.sdp-1.15</url>
      <doi>10.18653/v1/2021.sdp-1.15</doi>
      <bibkey>zeng-zubiaga-2021-qmul</bibkey>
      <pwccode url="https://github.com/XiaZeng0223/sciverbinary" additional="false">XiaZeng0223/sciverbinary</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/fever">FEVER</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/scifact">SciFact</pwcdataset>
    </paper>
    </volume>
</collection>