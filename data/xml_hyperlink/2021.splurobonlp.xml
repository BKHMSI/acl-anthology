<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.splurobonlp">
  <volume id="1" ingest-date="2021-07-25">
    <meta>
      <booktitle>Proceedings of Second International Combined Workshop on Spatial Language Understanding and Grounded Communication for Robotics</booktitle>
      <editor><first>Malihe</first><last>Alikhani</last></editor>
      <editor><first>Valts</first><last>Blukis</last></editor>
      <editor><first>Parisa</first><last>Kordjamshidi</last></editor>
      <editor><first>Aishwarya</first><last>Padmakumar</last></editor>
      <editor><first>Hao</first><last>Tan</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>August</month>
      <year>2021</year>
      <url hash="14057496">2021.splurobonlp-1</url>
    </meta>
    <frontmatter>
      <url hash="bc4036e1">2021.splurobonlp-1.0</url>
      <bibkey>splurobonlp-2021-international</bibkey>
    </frontmatter>
    <paper id="4">
      <title>Modeling Semantics and Pragmatics of Spatial Prepositions via Hierarchical Common-Sense Primitives</title>
      <author><first>Georgiy</first><last>Platonov</last></author>
      <author><first>Yifei</first><last>Yang</last></author>
      <author><first>Haoyu</first><last>Wu</last></author>
      <author><first>Jonathan</first><last>Waxman</last></author>
      <author><first>Marcus</first><last>Hill</last></author>
      <author><first>Lenhart</first><last>Schubert</last></author>
      <pages>32–41</pages>
      <abstract>Understanding spatial expressions and using them appropriately is necessary for seamless and natural human-machine interaction. However, capturing the <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> and appropriate usage of spatial prepositions is notoriously difficult, because of their vagueness and <a href="https://en.wikipedia.org/wiki/Polysemy">polysemy</a>. Although modern data-driven approaches are good at capturing statistical regularities in the usage, they usually require substantial sample sizes, often do not generalize well to unseen instances and, most importantly, their structure is essentially opaque to analysis, which makes diagnosing problems and understanding their reasoning process difficult. In this work, we discuss our attempt at modeling spatial senses of prepositions in <a href="https://en.wikipedia.org/wiki/English_language">English</a> using a combination of rule-based and statistical learning approaches. Each preposition model is implemented as a <a href="https://en.wikipedia.org/wiki/Tree_(data_structure)">tree</a> where each node computes certain intuitive relations associated with the preposition, with the root computing the final value of the <a href="https://en.wikipedia.org/wiki/Preposition_and_postposition">prepositional relation</a> itself. The <a href="https://en.wikipedia.org/wiki/3D_modeling">models</a> operate on a set of artificial 3D room world environments, designed in <a href="https://en.wikipedia.org/wiki/Blender_(software)">Blender</a>, taking the scene itself as an input. We also discuss our annotation framework used to collect <a href="https://en.wikipedia.org/wiki/Judgement">human judgments</a> employed in the model training. Both our <a href="https://en.wikipedia.org/wiki/Factor_analysis">factored models</a> and black-box baseline models perform quite well, but the <a href="https://en.wikipedia.org/wiki/Factor_analysis">factored models</a> will enable reasoned explanations of spatial relation judgements.</abstract>
      <url hash="20abfb4e">2021.splurobonlp-1.4</url>
      <doi>10.18653/v1/2021.splurobonlp-1.4</doi>
      <bibkey>platonov-etal-2021-modeling</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/clevr">CLEVR</pwcdataset>
    </paper>
    <paper id="8">
      <title>Interactive Reinforcement Learning for Table Balancing Robot</title>
      <author><first>Haein</first><last>Jeon</last></author>
      <author><first>Yewon</first><last>Kim</last></author>
      <author><first>Bo-Yeong</first><last>Kang</last></author>
      <pages>71–78</pages>
      <abstract>With the development of <a href="https://en.wikipedia.org/wiki/Robotics">robotics</a>, the use of <a href="https://en.wikipedia.org/wiki/Robot">robots</a> in daily life is increasing, which has led to the need for anyone to easily train robots to improve robot use. Interactive reinforcement learning(IARL) is a method for robot training based on <a href="https://en.wikipedia.org/wiki/Human–robot_interaction">humanrobot interaction</a> ; prior studies on IARL provide only limited types of <a href="https://en.wikipedia.org/wiki/Feedback">feedback</a> or require appropriately designed shaping rewards, which is known to be difficult and time-consuming. Therefore, in this study, we propose interactive deep reinforcement learning models based on voice feedback. In the proposed system, a robot learns the task of cooperative table balancing through <a href="https://en.wikipedia.org/wiki/Deep_learning">deep Q-network</a> using voice feedback provided by humans in real-time, with automatic speech recognition(ASR) and <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> to understand human voice feedback. As a result, an optimal policy convergence rate of up to 96 % was realized, and performance was improved in all voice feedback-based models</abstract>
      <url hash="f5793e00">2021.splurobonlp-1.8</url>
      <doi>10.18653/v1/2021.splurobonlp-1.8</doi>
      <bibkey>jeon-etal-2021-interactive</bibkey>
    </paper>
    </volume>
</collection>