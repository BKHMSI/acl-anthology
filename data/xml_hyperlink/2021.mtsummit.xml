<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.mtsummit">
  <volume id="research" ingest-date="2021-08-14">
    <meta>
      <booktitle>Proceedings of Machine Translation Summit XVIII: Research Track</booktitle>
      <publisher>Association for Machine Translation in the Americas</publisher>
      <address>Virtual</address>
      <month>August</month>
      <year>2021</year>
      <editor><first>Kevin</first><last>Duh</last></editor>
      <editor><first>Francisco</first><last>Guzmán</last></editor>
      <url hash="7b81460c">2021.mtsummit-research</url>
    </meta>
    <frontmatter>
      <url hash="d25ee171">2021.mtsummit-research.0</url>
      <bibkey>mtsummit-2021-biennial</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Learning Curricula for Multilingual Neural Machine Translation Training</title>
      <author><first>Gaurav</first><last>Kumar</last></author>
      <author><first>Philipp</first><last>Koehn</last></author>
      <author><first>Sanjeev</first><last>Khudanpur</last></author>
      <pages>1-9</pages>
      <url hash="d1a0e709">2021.mtsummit-research.1</url>
      <abstract>Low-resource Multilingual Neural Machine Translation (MNMT) is typically tasked with improving the <a href="https://en.wikipedia.org/wiki/Translation">translation</a> performance on one or more language pairs with the aid of high-resource language pairs. In this paper and we propose two simple search based curricula   orderings of the multilingual training data   which help improve <a href="https://en.wikipedia.org/wiki/Translation">translation</a> performance in conjunction with existing techniques such as <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a>. Additionally and we attempt to learn a <a href="https://en.wikipedia.org/wiki/Curriculum">curriculum</a> for MNMT from scratch jointly with the training of the translation system using contextual multi-arm bandits. We show on the FLORES low-resource translation dataset that these learned curricula can provide better starting points for fine tuning and improve overall performance of the translation system.</abstract>
      <bibkey>kumar-etal-2021-learning-curricula</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/flores">FLoRes</pwcdataset>
    </paper>
    <paper id="5">
      <title>Transformers for Low-Resource Languages : Is Fidir Linn !</title>
      <author><first>Seamus</first><last>Lankford</last></author>
      <author><first>Haithem</first><last>Alfi</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <pages>48-60</pages>
      <url hash="c2adacfa">2021.mtsummit-research.5</url>
      <abstract>The Transformer model is the state-of-the-art in <a href="https://en.wikipedia.org/wiki/Machine_translation">Machine Translation</a>. However and in general and neural translation models often under perform on language pairs with insufficient training data. As a consequence and relatively few experiments have been carried out using this <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> on low-resource language pairs. In this study and hyperparameter optimization of Transformer models in translating the low-resource English-Irish language pair is evaluated. We demonstrate that choosing appropriate parameters leads to considerable performance improvements. Most importantly and the correct choice of subword model is shown to be the biggest driver of <a href="https://en.wikipedia.org/wiki/Translation">translation</a> performance. SentencePiece models using both unigram and BPE approaches were appraised. Variations on model architectures included modifying the number of layers and testing various <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">regularization techniques</a> and evaluating the optimal number of heads for <a href="https://en.wikipedia.org/wiki/Attention">attention</a>. A generic 55k DGT corpus and an in-domain 88k public admin corpus were used for evaluation. A Transformer optimized model demonstrated a BLEU score improvement of 7.8 points when compared with a baseline <a href="https://en.wikipedia.org/wiki/Real-time_locating_system">RNN model</a>. Improvements were observed across a range of metrics and including TER and indicating a substantially reduced post editing effort for Transformer optimized models with 16k BPE subword models. Bench-marked against <a href="https://en.wikipedia.org/wiki/Google_Translate">Google Translate</a> and our translation engines demonstrated significant improvements. The question of whether or not <a href="https://en.wikipedia.org/wiki/Transformers_(toy_line)">Transformers</a> can be used effectively in a low-resource setting of English-Irish translation has been addressed. Is fidir linn-yes we can.</abstract>
      <bibkey>lankford-etal-2021-transformers</bibkey>
    </paper>
    <paper id="6">
      <title>The Effect of Domain and Diacritics in YorubaEnglish Neural Machine Translation<fixed-case>Y</fixed-case>oruba–<fixed-case>E</fixed-case>nglish Neural Machine Translation</title>
      <author><first>David</first><last>Adelani</last></author>
      <author><first>Dana</first><last>Ruiter</last></author>
      <author><first>Jesujoba</first><last>Alabi</last></author>
      <author><first>Damilola</first><last>Adebonojo</last></author>
      <author><first>Adesina</first><last>Ayeni</last></author>
      <author><first>Mofe</first><last>Adeyemi</last></author>
      <author><first>Ayodele Esther</first><last>Awokoya</last></author>
      <author><first>Cristina</first><last>España-Bonet</last></author>
      <pages>61-75</pages>
      <url hash="2a7fbaa1">2021.mtsummit-research.6</url>
      <abstract>Massively multilingual machine translation (MT) has shown impressive capabilities and including zero and few-shot translation between low-resource language pairs. However and these <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> are often evaluated on high-resource languages with the assumption that they generalize to low-resource ones. The difficulty of evaluating MT models on low-resource pairs is often due to lack of standardized evaluation datasets. In this paper and we present MENYO-20k and the first multi-domain parallel corpus with a especially curated orthography for YorubaEnglish with standardized train-test splits for benchmarking. We provide several neural MT benchmarks and compare them to the performance of popular pre-trained (massively multilingual) MT models both for the heterogeneous test set and its subdomains. Since these pre-trained models use huge amounts of data with uncertain quality and we also analyze the effect of diacritics and a major characteristic of <a href="https://en.wikipedia.org/wiki/Yoruba_language">Yoruba</a> and in the training data. We investigate how and when this training condition affects the final quality of a translation and its understandability. Our <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> outperform massively multilingual models such as Google (+8.7 BLEU) and Facebook M2 M (+9.1) when translating to <a href="https://en.wikipedia.org/wiki/Yoruba_language">Yoruba</a> and setting a high quality benchmark for future research.<tex-math>+8.7</tex-math> BLEU) and Facebook M2M (<tex-math>+9.1</tex-math>) when translating to Yoruba and setting a high quality benchmark for future research.</abstract>
      <bibkey>adelani-etal-2021-effect</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/jw300">JW300</pwcdataset>
    </paper>
    <paper id="9">
      <title>Like Chalk and Cheese? On the Effects of Translationese in MT Training<fixed-case>MT</fixed-case> Training</title>
      <author><first>Samuel</first><last>Larkin</last></author>
      <author><first>Michel</first><last>Simard</last></author>
      <author><first>Rebecca</first><last>Knowles</last></author>
      <pages>103-113</pages>
      <url hash="2449aac9">2021.mtsummit-research.9</url>
      <abstract>We revisit the topic of translation direction in the data used for training neural machine translation systems and focusing on a real-world scenario with known translation direction and imbalances in translation direction : the Canadian Hansard. According to automatic metrics and we observe that using parallel data that was produced in the matching translation direction (Authentic source and translationese target) improves translation quality. In cases of data imbalance in terms of translation direction and we find that tagging of translation direction can close the performance gap. We perform a human evaluation that differs slightly from the automatic metrics and but nevertheless confirms that for this French-English dataset that is known to contain high-quality translations and authentic or tagged mixed source improves over translationese source for training.</abstract>
      <bibkey>larkin-etal-2021-like</bibkey>
    </paper>
    <paper id="10">
      <title>Investigating Softmax Tempering for Training Neural Machine Translation Models</title>
      <author><first>Raj</first><last>Dabre</last></author>
      <author><first>Atsushi</first><last>Fujita</last></author>
      <pages>114-126</pages>
      <url hash="c2c0d716">2021.mtsummit-research.10</url>
      <abstract>Neural machine translation (NMT) models are typically trained using a softmax cross-entropy loss where the softmax distribution is compared against the gold labels. In low-resource scenarios and NMT models tend to perform poorly because the model training quickly converges to a point where the softmax distribution computed using <a href="https://en.wikipedia.org/wiki/Logit">logits</a> approaches the gold label distribution. Although label smoothing is a well-known solution to address this issue and we further propose to divide the logits by a <a href="https://en.wikipedia.org/wiki/Temperature_coefficient">temperature coefficient</a> greater than one and forcing the softmax distribution to be smoother during training. This makes it harder for the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> to quickly over-fit. In our experiments on 11 language pairs in the low-resource Asian Language Treebank dataset and we observed significant improvements in translation quality. Our analysis focuses on finding the right balance of label smoothing and softmax tempering which indicates that they are orthogonal methods. Finally and a study of softmax entropies and gradients reveal the impact of our method on the internal behavior of our NMT models.</abstract>
      <bibkey>dabre-fujita-2021-investigating</bibkey>
    </paper>
    <paper id="11">
      <title>Scrambled Translation Problem : A Problem of Denoising UNMT<fixed-case>UNMT</fixed-case></title>
      <author><first>Tamali</first><last>Banerjee</last></author>
      <author><first>Rudra</first><last>V Murthy</last></author>
      <author><first>Pushpak</first><last>Bhattacharya</last></author>
      <pages>127-138</pages>
      <url hash="92ca6c7d">2021.mtsummit-research.11</url>
      <abstract>In this paper and we identify an interesting kind of error in the output of Unsupervised Neural Machine Translation (UNMT) systems like Undreamt1. We refer to this error type as Scrambled Translation problem. We observe that UNMT models which use word shuffle noise (as in case of Undreamt) can generate correct words and but fail to stitch them together to form phrases. As a result and words of the translated sentence look scrambled and resulting in decreased <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a>. We hypothesise that the reason behind scrambled translation problem is’ shuffling noise’ which is introduced in every input sentence as a <a href="https://en.wikipedia.org/wiki/Noise_reduction">denoising strategy</a>. To test our hypothesis and we experiment by retraining UNMT models with a simple retraining strategy. We stop the training of the Denoising UNMT model after a pre-decided number of iterations and resume the training for the remaining iterations- which number is also pre-decided- using original sentence as input without adding any noise. Our proposed <a href="https://en.wikipedia.org/wiki/Solution">solution</a> achieves significant performance improvement UNMT models that train conventionally. We demonstrate these performance gains on four language pairs and viz. and English-French and English-German and English-Spanish and Hindi-Punjabi. Our qualitative and quantitative analysis shows that the retraining strategy helps achieve better alignment as observed by attention heatmap and better phrasal translation and leading to statistically significant improvement in BLEU scores.</abstract>
      <bibkey>banerjee-etal-2021-scrambled</bibkey>
    </paper>
    <paper id="14">
      <title>On nature and causes of observed MT errors<fixed-case>MT</fixed-case> errors</title>
      <author><first>Maja</first><last>Popovic</last></author>
      <pages>163-175</pages>
      <url hash="e5ca11cd">2021.mtsummit-research.14</url>
      <abstract>This work describes analysis of nature and causes of MT errors observed by different evaluators under guidance of different quality criteria : <a href="https://en.wikipedia.org/wiki/Adequality">adequacy</a> and <a href="https://en.wikipedia.org/wiki/Comprehension_(logic)">comprehension</a> and and a not specified generic mixture of <a href="https://en.wikipedia.org/wiki/Adequality">adequacy</a> and <a href="https://en.wikipedia.org/wiki/Fluency">fluency</a>. We report results for three language pairs and two domains and eleven MT systems. Our findings indicate that and despite the fact that some of the identified phenomena depend on domain and/or language and the following set of phenomena can be considered as generally challenging for modern MT systems : rephrasing groups of words and translation of ambiguous source words and translating noun phrases and and mistranslations. Furthermore and we show that the quality criterion also has impact on error perception. Our findings indicate that <a href="https://en.wikipedia.org/wiki/Sentence_processing">comprehension</a> and adequacy can be assessed simultaneously by different evaluators and so that <a href="https://en.wikipedia.org/wiki/Sentence_processing">comprehension</a> and as an important quality criterion and can be included more often in human evaluations.</abstract>
      <bibkey>popovic-2021-nature</bibkey>
      <pwccode url="https://github.com/awslabs/sockeye" additional="false">awslabs/sockeye</pwccode>
    </paper>
    <paper id="17">
      <title>Studying The Impact Of Document-level Context On Simultaneous Neural Machine Translation</title>
      <author><first>Raj</first><last>Dabre</last></author>
      <author><first>Aizhan</first><last>Imankulova</last></author>
      <author><first>Masahiro</first><last>Kaneko</last></author>
      <pages>202-214</pages>
      <url hash="2c986a6a">2021.mtsummit-research.17</url>
      <abstract>In a real-time simultaneous translation setting and neural machine translation (NMT) models start generating target language tokens from incomplete source language sentences and making them harder to translate and leading to poor translation quality. Previous research has shown that document-level NMT and comprising of sentence and context encoders and a decoder and leverages context from neighboring sentences and helps improve translation quality. In simultaneous translation settings and the context from previous sentences should be even more critical. To this end and in this paper and we propose wait-k simultaneous document-level NMT where we keep the context encoder as it is and replace the source sentence encoder and target language decoder with their wait-k equivalents. We experiment with low and high resource settings using the ALT and OpenSubtitles2018 corpora and where we observe minor improvements in translation quality. We then perform an analysis of the translations obtained using our models by focusing on sentences that should benefit from the context where we found out that the model does and in fact and benefit from context but is unable to effectively leverage it and especially in a low-resource setting. This shows that there is a need for further innovation in the way useful context is identified and leveraged.</abstract>
      <bibkey>dabre-etal-2021-studying</bibkey>
    </paper>
    <paper id="18">
      <title>Attainable Text-to-Text Machine Translation vs. <a href="https://en.wikipedia.org/wiki/Translation">Translation</a> : Issues Beyond Linguistic Processing</title>
      <author><first>Atsushi</first><last>Fujita</last></author>
      <pages>215-230</pages>
      <url hash="a0a1548f">2021.mtsummit-research.18</url>
      <abstract>Existing approaches for machine translation (MT) mostly translate given text in the source language into the target language and without explicitly referring to information indispensable for producing proper <a href="https://en.wikipedia.org/wiki/Translation">translation</a>. This includes not only information in other textual elements and modalities than texts in the same document and but also extra-document and non-linguistic information and such as <a href="https://en.wikipedia.org/wiki/Social_norm">norms</a> and <a href="https://en.wikipedia.org/wiki/Skopos">skopos</a>. To design better translation production work-flows and we need to distinguish translation issues that could be resolved by the existing text-to-text approaches and those beyond them. To this end and we conducted an analytic assessment of MT outputs and taking an English-to-Japanese news translation task as a case study. First and examples of <a href="https://en.wikipedia.org/wiki/Translation">translation issues</a> and their revisions were collected by a two-stage post-editing (PE) method : performing minimal PE to obtain <a href="https://en.wikipedia.org/wiki/Translation">translation</a> attainable based on the given textual information and further performing full PE to obtain truly acceptable <a href="https://en.wikipedia.org/wiki/Translation">translation</a> referring to any information if necessary. Then and the collected revision examples were manually analyzed. We revealed dominant issues and information indispensable for resolving them and such as fine-grained style specifications and terminology and domain-specific knowledge and and reference documents and delineating a clear distinction between <a href="https://en.wikipedia.org/wiki/Translation">translation</a> and what text-to-text MT can ultimately attain.</abstract>
      <bibkey>fujita-2021-attainable</bibkey>
      <pwccode url="https://github.com/akfujita/staged-pe" additional="false">akfujita/staged-pe</pwccode>
    </paper>
    <paper id="19">
      <title>Modeling Target-side Inflection in Placeholder Translation</title>
      <author><first>Ryokan</first><last>Ri</last></author>
      <author><first>Toshiaki</first><last>Nakazawa</last></author>
      <author><first>Yoshimasa</first><last>Tsuruoka</last></author>
      <pages>231-242</pages>
      <url hash="6bd323a3">2021.mtsummit-research.19</url>
      <abstract>Placeholder translation systems enable the users to specify how a specific phrase is translated in the output sentence. The system is trained to output special placeholder tokens and the user-specified term is injected into the output through the context-free replacement of the placeholder token. However and this approach could result in ungrammatical sentences because it is often the case that the specified term needs to be inflected according to the context of the output and which is unknown before the translation. To address this problem and we propose a novel method of placeholder translation that can inflect specified terms according to the <a href="https://en.wikipedia.org/wiki/Grammar">grammatical construction</a> of the output sentence. We extend the seq2seq architecture with a character-level decoder that takes the lemma of a user-specified term and the words generated from the word-level decoder to output a correct inflected form of the lemma. We evaluate our approach with a Japanese-to-English translation task in the scientific writing domain and and show our model can incorporate specified terms in a correct form more successfully than other comparable models.</abstract>
      <bibkey>ri-etal-2021-modeling</bibkey>
      <pwccode url="https://github.com/Ryou0634/placeholder_translation" additional="false">Ryou0634/placeholder_translation</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/aspec">ASPEC</pwcdataset>
    </paper>
    <paper id="23">
      <title>Neural Machine Translation with Inflected Lexicon</title>
      <author><first>Artur</first><last>Nowakowski</last></author>
      <author><first>Krzysztof</first><last>Jassem</last></author>
      <pages>282-292</pages>
      <url hash="3e6e063b">2021.mtsummit-research.23</url>
      <abstract>The paper presents experiments in <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> with <a href="https://en.wikipedia.org/wiki/Lexical_analysis">lexical constraints</a> into a <a href="https://en.wikipedia.org/wiki/Morphological_analysis">morphologically rich language</a>. In particular and we introduce a method and based on constrained decoding and which handles the inflected forms of lexical entries and does not require any modification to the training data or model architecture. To evaluate its effectiveness and we carry out experiments in two different scenarios : general and domain-specific. We compare our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> with baseline translation and i.e. translation without <a href="https://en.wikipedia.org/wiki/Lexical_item">lexical constraints</a> and in terms of translation speed and <a href="https://en.wikipedia.org/wiki/Translation">translation quality</a>. To evaluate how well the method handles the constraints and we propose new evaluation metrics which take into account the presence and placement and duplication and inflectional correctness of lexical terms in the output sentence.</abstract>
      <bibkey>nowakowski-jassem-2021-neural</bibkey>
    </paper>
    </volume>
  <volume id="asltrw" ingest-date="2021-08-19">
    <meta>
      <booktitle>Proceedings of the 1st Workshop on Automatic Spoken Language Translation in Real-World Settings (ASLTRW)</booktitle>
      <publisher>Association for Machine Translation in the Americas</publisher>
      <address>Virtual</address>
      <month>August</month>
      <year>2021</year>
      <editor><first>Marco</first><last>Turchi</last></editor>
      <editor><first>Claudio</first><last>Fantinuoli</last></editor>
      <url hash="7eb0fa67">2021.mtsummit-asltrw</url>
    </meta>
    <frontmatter>
      <url hash="b1f110cd">2021.mtsummit-asltrw.0</url>
      <bibkey>mtsummit-2021-automatic</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Seed Words Based Data Selection for Language Model Adaptation</title>
      <author><first>Roberto</first><last>Gretter</last></author>
      <author><first>Marco</first><last>Matassoni</last></author>
      <author><first>Daniele</first><last>Falavigna</last></author>
      <pages>1-12</pages>
      <url hash="b0308a90">2021.mtsummit-asltrw.1</url>
      <abstract>We address the problem of language model customization in applications where the ASR component needs to manage domain-specific terminology ; although current state-of-the-art speech recognition technology provides excellent results for generic domains, the adaptation to specialized dictionaries or glossaries is still an open issue. In this work we present an approach for automatically selecting sentences, from a <a href="https://en.wikipedia.org/wiki/Text_corpus">text corpus</a>, that match, both semantically and morphologically, a glossary of terms (words or composite words) furnished by the user. The final goal is to rapidly adapt the <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> of an hybrid ASR system with a limited amount of in-domain text data in order to successfully cope with the linguistic domain at hand ; the <a href="https://en.wikipedia.org/wiki/Vocabulary">vocabulary</a> of the baseline model is expanded and tailored, reducing the resulting OOV rate. Data selection strategies based on shallow morphological seeds and semantic similarity via <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> are introduced and discussed ; the experimental setting consists in a simultaneous interpreting scenario, where ASRs in three languages are designed to recognize the domainspecific terms (i.e. dentistry). Results using different metrics (OOV rate, WER, precision and recall) show the effectiveness of the proposed techniques.</abstract>
      <bibkey>gretter-etal-2021-seed</bibkey>
    </paper>
    </volume>
  <volume id="at4ssl" ingest-date="2021-08-19">
    <meta>
      <booktitle>Proceedings of the 1st International Workshop on Automatic Translation for Signed and Spoken Languages (AT4SSL)</booktitle>
      <publisher>Association for Machine Translation in the Americas</publisher>
      <address>Virtual</address>
      <month>August</month>
      <year>2021</year>
      <editor><first>Dimitar</first><last>Shterionov</last></editor>
      <url hash="8f55092e">2021.mtsummit-at4ssl</url>
    </meta>
    <frontmatter>
      <url hash="1714f5bc">2021.mtsummit-at4ssl.0</url>
      <bibkey>mtsummit-2021-international</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Sign and Search : Sign Search Functionality for Sign Language Lexica</title>
      <author><first>Manolis</first><last>Fragkiadakis</last></author>
      <author><first>Peter</first><last>van der Putten</last></author>
      <pages>23-32</pages>
      <url hash="deda50c0">2021.mtsummit-at4ssl.3</url>
      <abstract>Sign language lexica are a useful resource for researchers and people learning <a href="https://en.wikipedia.org/wiki/Sign_language">sign languages</a>. Current implementations allow a user to search a sign either by its gloss or by selecting its primary features such as <a href="https://en.wikipedia.org/wiki/Handshape">handshape</a> and <a href="https://en.wikipedia.org/wiki/Location">location</a>. This study focuses on exploring a reverse search functionality where a user can sign a query sign in front of a webcam and retrieve a set of matching signs. By extracting different body joints combinations (upper body, dominant hand’s arm and wrist) using the pose estimation framework OpenPose, we compare four techniques (PCA, UMAP, DTW and Euclidean distance) as distance metrics between 20 query signs, each performed by eight participants on a 1200 sign lexicon. The results show that UMAP and DTW can predict a matching sign with an 80 % and 71 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> respectively at the top-20 retrieved signs using the movement of the dominant hand arm. Using DTW and adding more sign instances from other participants in the lexicon, the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> can be raised to 90 % at the top-10 ranking. Our results suggest that our <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> can be used with no training in any sign language lexicon regardless of its size.</abstract>
      <bibkey>fragkiadakis-van-der-putten-2021-sign</bibkey>
    </paper>
    <paper id="4">
      <title>The Myth of Signing Avatars</title>
      <author><first>John C.</first><last>McDonald</last></author>
      <author><first>Rosalee</first><last>Wolfe</last></author>
      <author><first>Eleni</first><last>Efthimiou</last></author>
      <author><first>Evita</first><last>Fontinea</last></author>
      <author><first>Frankie</first><last>Picron</last></author>
      <author><first>Davy</first><last>Van Landuyt</last></author>
      <author><first>Tina</first><last>Sioen</last></author>
      <author><first>Annelies</first><last>Braffort</last></author>
      <author><first>Michael</first><last>Filhol</last></author>
      <author><first>Sarah</first><last>Ebling</last></author>
      <author><first>Thomas</first><last>Hanke</last></author>
      <author><first>Verena</first><last>Krausneker</last></author>
      <pages>33-42</pages>
      <url hash="33f694fb">2021.mtsummit-at4ssl.4</url>
      <abstract>Development of <a href="https://en.wikipedia.org/wiki/Machine_translation">automatic translation</a> between signed and spoken languages has lagged behind the development of <a href="https://en.wikipedia.org/wiki/Machine_translation">automatic translation</a> between <a href="https://en.wikipedia.org/wiki/Spoken_language">spoken languages</a>, but it is a common misperception that extending machine translation techniques to include signed languages should be a straightforward process. A contributing factor is the lack of an acceptable method for displaying <a href="https://en.wikipedia.org/wiki/Sign_language">sign language</a> apart from <a href="https://en.wikipedia.org/wiki/Language_interpretation">interpreters</a> on video. This position paper examines the challenges of displaying a <a href="https://en.wikipedia.org/wiki/Sign_language">signed language</a> as a target in <a href="https://en.wikipedia.org/wiki/Automatic_translation">automatic translation</a>, analyses the underlying causes and suggests strategies to develop display technologies that are acceptable to sign language communities.</abstract>
      <bibkey>rosalee-wolfe-etal-2021-myth</bibkey>
    </paper>
    <paper id="5">
      <title>AVASAG : A German Sign Language Translation System for Public Services (short paper)<fixed-case>AVASAG</fixed-case>: A <fixed-case>G</fixed-case>erman <fixed-case>S</fixed-case>ign <fixed-case>L</fixed-case>anguage Translation System for Public Services (short paper)</title>
      <author><first>Fabrizio</first><last>Nunnari</last></author>
      <author><first>Judith</first><last>Bauerdiek</last></author>
      <author><first>Lucas</first><last>Bernhard</last></author>
      <author><first>Cristina</first><last>España-Bonet</last></author>
      <author><first>Corinna</first><last>Jäger</last></author>
      <author><first>Amelie</first><last>Unger</last></author>
      <author><first>Kristoffer</first><last>Waldow</last></author>
      <author><first>Sonja</first><last>Wecker</last></author>
      <author><first>Elisabeth</first><last>André</last></author>
      <author><first>Stephan</first><last>Busemann</last></author>
      <author><first>Christian</first><last>Dold</last></author>
      <author><first>Arnulph</first><last>Fuhrmann</last></author>
      <author><first>Patrick</first><last>Gebhard</last></author>
      <author><first>Yasser</first><last>Hamidullah</last></author>
      <author><first>Marcel</first><last>Hauck</last></author>
      <author><first>Yvonne</first><last>Kossel</last></author>
      <author><first>Martin</first><last>Misiak</last></author>
      <author><first>Dieter</first><last>Wallach</last></author>
      <author><first>Alexander</first><last>Stricker</last></author>
      <pages>43-48</pages>
      <url hash="aaf021a0">2021.mtsummit-at4ssl.5</url>
      <abstract>This paper presents an overview of AVASAG ; an ongoing applied-research project developing a text-to-sign-language translation system for public services. We describe the scientific innovation points (geometry-based SL-description, 3D animation and video corpus, simplified annotation scheme, motion capture strategy) and the overall translation pipeline.</abstract>
      <bibkey>nunnari-etal-2021-avasag</bibkey>
    </paper>
    <paper id="7">
      <title>Approaching Sign Language Gloss Translation as a Low-Resource Machine Translation Task</title>
      <author><first>Xuan</first><last>Zhang</last></author>
      <author><first>Kevin</first><last>Duh</last></author>
      <pages>60-70</pages>
      <url hash="9b4ced03">2021.mtsummit-at4ssl.7</url>
      <abstract>A cascaded Sign Language Translation system first maps sign videos to gloss annotations and then translates <a href="https://en.wikipedia.org/wiki/Gloss_(annotation)">glosses</a> into a <a href="https://en.wikipedia.org/wiki/Spoken_language">spoken languages</a>. This work focuses on the second-stage gloss translation component, which is challenging due to the scarcity of publicly available parallel data. We approach <a href="https://en.wikipedia.org/wiki/Gloss_(annotation)">gloss translation</a> as a low-resource machine translation task and investigate two popular methods for improving translation quality : hyperparameter search and backtranslation. We discuss the potentials and pitfalls of these methods based on experiments on the RWTH-PHOENIX-Weather 2014 T dataset.</abstract>
      <bibkey>zhang-duh-2021-approaching</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/phoenix14t">PHOENIX14T</pwcdataset>
    </paper>
    <paper id="8">
      <title>Automatic generation of a 3D sign language avatar on <a href="https://en.wikipedia.org/wiki/Augmented_reality">AR glasses</a> given 2D videos of human signers<fixed-case>D</fixed-case> sign language avatar on <fixed-case>AR</fixed-case> glasses given 2<fixed-case>D</fixed-case> videos of human signers</title>
      <author><first>Lan Thao</first><last>Nguyen</last></author>
      <author><first>Florian</first><last>Schicktanz</last></author>
      <author><first>Aeneas</first><last>Stankowski</last></author>
      <author><first>Eleftherios</first><last>Avramidis</last></author>
      <pages>71-81</pages>
      <url hash="4457bbf7">2021.mtsummit-at4ssl.8</url>
      <abstract>In this paper we present a prototypical implementation of a <a href="https://en.wikipedia.org/wiki/Pipeline_(computing)">pipeline</a> that allows the automatic generation of a German Sign Language avatar from <a href="https://en.wikipedia.org/wiki/2D_computer_graphics">2D video material</a>. The presentation is accompanied by the source code. We record <a href="https://en.wikipedia.org/wiki/List_of_human_positions">human pose movements</a> during signing with <a href="https://en.wikipedia.org/wiki/Computer_vision">computer vision models</a>. The joint coordinates of hands and arms are imported as <a href="https://en.wikipedia.org/wiki/Landmark">landmarks</a> to control the skeleton of our avatar. From the anatomically independent landmarks, we create another <a href="https://en.wikipedia.org/wiki/Skeleton">skeleton</a> based on the avatar’s skeletal bone architecture to calculate the bone rotation data. This <a href="https://en.wikipedia.org/wiki/Data">data</a> is then used to control our <a href="https://en.wikipedia.org/wiki/Avatar_(computing)">human 3D avatar</a>. The <a href="https://en.wikipedia.org/wiki/Avatar_(computing)">avatar</a> is displayed on <a href="https://en.wikipedia.org/wiki/Augmented_reality">AR glasses</a> and can be placed virtually in the room, in a way that it can be perceived simultaneously to the verbal speaker. In further work <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> is aimed to be enhanced with <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech recognition</a> and <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation methods</a> for serving as a <a href="https://en.wikipedia.org/wiki/Language_interpretation">sign language interpreter</a>. The <a href="https://en.wikipedia.org/wiki/Prototype">prototype</a> has been shown to people of the deaf and hard-of-hearing community for assessing its comprehensibility. Problems emerged with the transferred hand rotations, hand gestures were hard to recognize on the <a href="https://en.wikipedia.org/wiki/Avatar_(computing)">avatar</a> due to deformations like twisted finger meshes.</abstract>
      <bibkey>nguyen-etal-2021-automatic</bibkey>
    </paper>
    <paper id="11">
      <title>Defining meaningful units. Challenges in sign segmentation and segment-meaning mapping (short paper)</title>
      <author><first>Mirella</first><last>De Sisto</last></author>
      <author><first>Dimitar</first><last>Shterionov</last></author>
      <author><first>Irene</first><last>Murtagh</last></author>
      <author><first>Myriam</first><last>Vermeerbergen</last></author>
      <author><first>Lorraine</first><last>Leeson</last></author>
      <pages>98-103</pages>
      <url hash="9d07a557">2021.mtsummit-at4ssl.11</url>
      <abstract>This paper addresses the tasks of sign segmentation and segment-meaning mapping in the context of sign language (SL) recognition. It aims to give an overview of the linguistic properties of SL, such as <a href="https://en.wikipedia.org/wiki/Coarticulation">coarticulation</a> and <a href="https://en.wikipedia.org/wiki/Simultaneity">simultaneity</a>, which make these tasks complex. A better understanding of SL structure is the necessary ground for the design and development of SL recognition and segmentation methodologies, which are fundamental for <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> of these languages. Based on this preliminary exploration, a proposal for mapping segments to meaning in the form of an agglomerate of lexical and non-lexical information is introduced.</abstract>
      <bibkey>de-sisto-etal-2021-defining</bibkey>
    </paper>
  </volume>
  <volume id="up" ingest-date="2021-09-15">
    <meta>
      <booktitle>Proceedings of Machine Translation Summit XVIII: Users and Providers Track</booktitle>
      <publisher>Association for Machine Translation in the Americas</publisher>
      <address>Virtual</address>
      <month>August</month>
      <year>2021</year>
      <editor><first>Janice</first><last>Campbell</last></editor>
      <editor><first>Ben</first><last>Huyck</last></editor>
      <editor><first>Stephen</first><last>Larocca</last></editor>
      <editor><first>Jay</first><last>Marciano</last></editor>
      <editor><first>Konstantin</first><last>Savenkov</last></editor>
      <editor><first>Alex</first><last>Yanishevsky</last></editor>
      <url hash="14bd8b24">2021.mtsummit-up</url>
    </meta>
    <frontmatter>
      <url hash="fe8dce6a">2021.mtsummit-up.0</url>
      <bibkey>mtsummit-2021-machine</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Roundtable: Digital Marketing Globalization at <fixed-case>N</fixed-case>et<fixed-case>A</fixed-case>pp: A Case Study of Digital Transformation utilizing Neural Machine Translation</title>
      <author><first>Edith</first><last>Bendermacher</last></author>
      <pages>1-6</pages>
      <attachment type="presentation" hash="22162b71">2021.mtsummit-up.1.Presentation.pdf</attachment>
      <bibkey>bendermacher-2021-roundtable</bibkey>
    </paper>
    <paper id="2">
      <title>Roundtable: Neural Machine Translation at Ford Motor Company</title>
      <author><first>Nestor</first><last>Rychtyckyj</last></author>
      <pages>7-16</pages>
      <attachment type="presentation" hash="0350667e">2021.mtsummit-up.2.Presentation.pdf</attachment>
      <bibkey>rychtyckyj-2021-roundtable</bibkey>
    </paper>
    <paper id="3">
      <title>Roundtable: Salesforce <fixed-case>NMT</fixed-case> System: A Year Later</title>
      <author><first>Raffaella</first><last>Buschiazzo</last></author>
      <pages>17-28</pages>
      <attachment type="presentation" hash="95fab9ef">2021.mtsummit-up.3.Presentation.pdf</attachment>
      <bibkey>buschiazzo-2021-roundtable</bibkey>
    </paper>
    <paper id="4">
      <title>Roundtable: <fixed-case>A</fixed-case>utodesk: Neural Machine Translation – Localization and beyond</title>
      <author><first>Emanuele</first><last>Dias</last></author>
      <pages>29-37</pages>
      <attachment type="presentation" hash="2788c46f">2021.mtsummit-up.4.Presentation.pdf</attachment>
      <bibkey>dias-2021-roundtable</bibkey>
    </paper>
    <paper id="7">
      <title>From Research to Production: Fine-Grained Analysis of Terminology Integration</title>
      <author><first>Toms</first><last>Bergmanis</last></author>
      <author><first>Mārcis</first><last>Pinnis</last></author>
      <author><first>Paula</first><last>Reichenberg</last></author>
      <pages>54-77</pages>
      <abstract>Dynamic terminology integration in neural machine translation (NMT) is a sought-after feature of computer-aided translation tools among language service providers and small to medium businesses. Despite the recent surge in research on terminology integration in NMT, it still is seldom or inadequately supported in commercial machine translation solutions. In this presentation, we will share our experience of developing and deploying terminology integration capabilities for NMT systems in production. We will look at the three core tasks of terminology integration: terminology management, terminology identification, and translation with terminology. This talk will be insightful for NMT system developers, translators, terminologists, and anyone interested in translation projects.</abstract>
      <attachment type="presentation" hash="f62f6138">2021.mtsummit-up.7.Presentation.pdf</attachment>
      <bibkey>bergmanis-etal-2021-research</bibkey>
    </paper>
    <paper id="10">
      <title>A Review for Large Volumes of Post-edited Data</title>
      <author><first>Silvio</first><last>Picinini</last></author>
      <pages>98-130</pages>
      <abstract>Interested in being more confident about the quality of your post-edited data? This is a session to learn how to create a Longitudinal Review that looks at specific aspects of quality in a systematic way, for the entire content and not just for a sample. Are you a project manager for a multilingual project? The Longitudinal Review can give insights to help project management, even if you are not a speaker of the target language. And it can help you detect issues that a Sample Review may not detect. Please come learn more about this new way to look at review.</abstract>
      <attachment type="presentation" hash="07bc42b3">2021.mtsummit-up.10.Presentation.pdf</attachment>
      <bibkey>picinini-2021-review</bibkey>
    </paper>
    <paper id="11">
      <title>Accelerated Human <fixed-case>NMT</fixed-case> Evaluation Approaches for <fixed-case>NMT</fixed-case> Workflow Integration</title>
      <author><first>James</first><last>Phillips</last></author>
      <pages>131-148</pages>
      <abstract>Attendees to this session will get a clear view into how neural machine translation is leveraged in a large-scale real-life scenario to make substantial cost savings in comparison to conventional approaches without compromising quality. This will include an overview of how quality is measured, when and why quality estimation is applied, what preparations are required to do so, and what attempts are made to minimize the amount of human effort involved. It will also be outlined as to what worked well and what pitfalls are to be avoided to give pointers to others who may be considering similar strategies.</abstract>
      <attachment type="presentation" hash="82f99f54">2021.mtsummit-up.11.Presentation.pdf</attachment>
      <bibkey>phillips-2021-accelerated</bibkey>
    </paper>
    <paper id="12">
      <title><fixed-case>MT</fixed-case> Human Evaluation – Insights &amp; Approaches</title>
      <author><first>Paula</first><last>Manzur</last></author>
      <pages>149-165</pages>
      <abstract>This session is designed to help companies and people in the business of translation evaluate MT output and to show how human translator feedback can be tweaked to make the process more objective and accurate. You will hear recommendations, insights, and takeaways on how to improve the procedure for human evaluation. When this is achieved, we can understand if the human eval study and machine metric result coheres. And we can think about what the future of translators looks like – the final “human touch” and automated MT review.”</abstract>
      <attachment type="presentation" hash="c2ada632">2021.mtsummit-up.12.Presentation.pdf</attachment>
      <bibkey>manzur-2021-mt</bibkey>
    </paper>
    <paper id="13">
      <title>A Rising Tide Lifts All Boats? Quality Correlation between Human Translation and Machine Assisted Translation</title>
      <author><first>Evelyn</first><last>Yang Garland</last></author>
      <author><first>Rony</first><last>Gao</last></author>
      <pages>166-174</pages>
      <abstract>Does the human who produces the best translation without Machine Translation (MT) also produce the best translation with the assistance of MT? Our empirical study has found a strong correlation between the quality of pure human translation (HT) and that of machine-assisted translation (MAT) produced by the same translator (Pearson correlation coefficient 0.85, p=0.007). Data from the study also indicates a more concentrated distribution of the MAT quality scores than that of the HT scores. Additional insights will also be discussed during the presentation. This study has two prominent features: the participation of professional translators (mostly ATA members, English-into-Chinese) as subjects, and the rigorous quality evaluation by multiple professional translators (all ATA certified) using ATA’s time-tested certification exam grading metrics. Despite a major limitation in sample size, our findings provide a strong indication of correlation between HT and MAT quality, adding to the body of evidence in support of further studies on larger scales.</abstract>
      <attachment type="presentation" hash="e0463b77">2021.mtsummit-up.13.Presentation.pdf</attachment>
      <bibkey>yang-garland-gao-2021-rising</bibkey>
    </paper>
    <paper id="14">
      <title>Bad to the Bone: Predicting the Impact of Source on <fixed-case>MT</fixed-case></title>
      <author><first>Alex</first><last>Yanishevsky</last></author>
      <pages>175-199</pages>
      <abstract>It’s a well-known truism that poorly written source has a profound negative effect on the quality of machine translation, drastically reduces the productivity of post-editors and impacts turnaround times. But what is bad and how bad is bad? Conversely, what are the features emblematic of good content and how good is good? The impact of source on MT is crucial since a lot of content is written by non-native authors, created by technical specialists for a non-technical audience and may not adhere to brand tone and voice. AI can be employed to identify these errors and predict ‘at-risk’ content prior to localization in a multitude of languages. The presentation will show how source files and even individual sentences within those source files can be analyzed for markers of complexity and readability and thus are more likely to cause mistranslations and omissions for machine translation and subsequent post-editing. Potential solutions will be explored such as rewriting the source to be in line with acceptable threshold criteria for each product and/or domain, re-routing to other machine translation engines better suited for the task at hand and building AI-based predictive models.</abstract>
      <attachment type="presentation" hash="ea3c81dc">2021.mtsummit-up.14.Presentation.pdf</attachment>
      <bibkey>yanishevsky-2021-bad</bibkey>
    </paper>
    <paper id="16">
      <title>Using Raw <fixed-case>MT</fixed-case> to make essential information available for a diverse range of potential customers</title>
      <author><first>Sabine</first><last>Peng</last></author>
      <pages>211-226</pages>
      <abstract>This presentation will share how we use raw machine translation to reach more potential customers. The attendees will learn about the raw machine strategies and workflow, how to select languages and products through data analysis, how to evaluate the overall quality of documentation with raw machine translation. The attendees will also learn about the direction we are going, that is, collecting user feedback and optimizing raw machine translation, so to build a complete and sustainable closed loop.</abstract>
      <attachment type="presentation" hash="da4a2b82">2021.mtsummit-up.16.Presentation.pdf</attachment>
      <bibkey>peng-2021-using</bibkey>
    </paper>
    <paper id="18">
      <title>A Common Machine Translation Post-Editing Training Protocol by <fixed-case>GALA</fixed-case></title>
      <author><first>Viveta</first><last>Gene</last></author>
      <author><first>Lucía</first><last>Guerrero</last></author>
      <pages>233-245</pages>
      <attachment type="presentation" hash="af11c99d">2021.mtsummit-up.18.Presentation.pdf</attachment>
      <bibkey>gene-guerrero-2021-common</bibkey>
    </paper>
    <paper id="19">
      <title>Preserving high <fixed-case>MT</fixed-case> quality for content with inline tags</title>
      <author><first>Konstantin</first><last>Savenkov</last></author>
      <author><first>Grigory</first><last>Sapunov</last></author>
      <author><first>Pavel</first><last>Stepachev</last></author>
      <pages>246-276</pages>
      <abstract>Attendees will learn about how we use machine translation to provide targeted, high MT quality for content with inline tags. We offer a new and innovative approach to inserting tags into the translated text in a way that reliably preserves their quality. This process can achieve better MT quality and lower costs, as it is MT-independent, and can be used for all languages, MT engines, and use cases.</abstract>
      <attachment type="presentation" hash="6b879691">2021.mtsummit-up.19.Presentation.pdf</attachment>
      <bibkey>savenkov-2021-preserving</bibkey>
    </paper>
    <paper id="20">
      <title>Early-stage development of the <fixed-case>S</fixed-case>ign<fixed-case>ON</fixed-case> application and open framework – challenges and opportunities</title>
      <author><first>Dimitar</first><last>Shterionov</last></author>
      <author><first>John</first><last>J O’Flaherty</last></author>
      <author><first>Edward</first><last>Keane</last></author>
      <author><first>Connor</first><last>O’Reilly</last></author>
      <author><first>Marcello</first><last>Paolo Scipioni</last></author>
      <author><first>Marco</first><last>Giovanelli</last></author>
      <author><first>Matteo</first><last>Villa</last></author>
      <pages>277-290</pages>
      <abstract>SignON is an EU Horizon 2020 Research and Innovation project, that is developing a smartphone application and an open framework to facilitate translation between different European sign, spoken and text languages. The framework will incorporate state of the art sign language recognition and presentation, speech processing technologies and, in its core, multi-modal, cross-language machine translation. The framework, dedicated to the computationally heavy tasks and distributed on the cloud powers the application – a lightweight app running on a standard mobile device. The application and framework are being researched, designed and developed through a co-creation user-centric approach with the European deaf and hard of hearing communities. In this session, the speakers will detail their progress, challenges and lessons learned in the early-stage development of the application and framework. They will also present their Agile DevOps approach and the next steps in the evolution of the SignON project.</abstract>
      <attachment type="presentation" hash="0a80bb8f">2021.mtsummit-up.20.Presentation.pdf</attachment>
      <bibkey>shterionov-2021-early</bibkey>
    </paper>
    <paper id="21">
      <title>Deploying <fixed-case>MT</fixed-case> Quality Estimation on a large scale: Lessons learned and open questions</title>
      <author><first>Aleš</first><last>Tamchyna</last></author>
      <pages>291-305</pages>
      <abstract>This talk will focus on Memsource’s experience implementing MT Quality Estimation on a large scale within a translation management system. We will cover the whole development journey: from our early experimentation and the challenges we faced adapting academic models for a real world setting, all the way through to the practical implementation. Since the launch of this feature, we’ve accumulated a significant amount of experience and feedback, which has informed our subsequent development. Lastly we will discuss several open questions regarding the future role of quality estimation in translation.</abstract>
      <attachment type="presentation" hash="3c1bef2f">2021.mtsummit-up.21.Presentation.pdf</attachment>
      <bibkey>tamchyna-2021-deploying</bibkey>
    </paper>
    <paper id="23">
      <title>Neural Translation for <fixed-case>E</fixed-case>uropean <fixed-case>U</fixed-case>nion (<fixed-case>NTEU</fixed-case>)</title>
      <author><first>Mercedes</first><last>García-Martínez</last></author>
      <author><first>Laurent</first><last>Bié</last></author>
      <author><first>Aleix</first><last>Cerdà</last></author>
      <author><first>Amando</first><last>Estela</last></author>
      <author><first>Manuel</first><last>Herranz</last></author>
      <author><first>Rihards</first><last>Krišlauks</last></author>
      <author><first>Maite</first><last>Melero</last></author>
      <author><first>Tony</first><last>O’Dowd</last></author>
      <author><first>Sinead</first><last>O’Gorman</last></author>
      <author><first>Marcis</first><last>Pinnis</last></author>
      <author><first>Artūrs</first><last>Stafanovič</last></author>
      <author><first>Riccardo</first><last>Superbo</last></author>
      <author><first>Artūrs</first><last>Vasiļevskis</last></author>
      <pages>316-334</pages>
      <abstract>The Neural Translation for the European Union (NTEU) engine farm enables direct machine translation for all 24 official languages of the European Union without the necessity to use a high-resourced language as a pivot. This amounts to a total of 552 translation engines for all combinations of the 24 languages. We have collected parallel data for all the language combinations publickly shared in elrc-share.eu. The translation engines have been customized to domain,for the use of the European public administrations. The delivered engines will be published in the European Language Grid. In addition to the usual automatic metrics, all the engines have been evaluated by humans based on the direct assessment methodology. For this purpose, we built an open-source platform called MTET The evaluation shows that most of the engines reach high quality and get better scores compared to an external machine translation service in a blind evaluation setup.</abstract>
      <attachment type="presentation" hash="86c35b74">2021.mtsummit-up.23.Presentation.pdf</attachment>
      <bibkey>garcia-martinez-etal-2021-neural</bibkey>
    </paper>
    <paper id="24">
      <title>A Data-Centric Approach to Real-World Custom <fixed-case>NMT</fixed-case> for <fixed-case>A</fixed-case>rabic</title>
      <author><first>Rebecca</first><last>Jonsson</last></author>
      <author><first>Ruba</first><last>Jaikat</last></author>
      <author><first>Abdallah</first><last>Nasir</last></author>
      <author><first>Nour</first><last>Al-Khdour</last></author>
      <author><first>Sara</first><last>Alisis</last></author>
      <pages>335-352</pages>
      <abstract>In this presentation, we will present our approach to taking Custom NMT to the next level by building tailor-made NMT to fit the needs of businesses seeking to scale in the Arabic-speaking world. In close collaboration with customers in the MENA region and with a deep understanding of their data, we work on building a variety of NMT models that accommodate to the unique challenges of the Arabic language. This session will provide insights into the challenges of acquiring, analyzing, and processing customer data in various sectors, as well as insights into how to best make use of this data to build high-quality Custom NMT models in English-Arabic. Feedback from usage of these models in production will be provided. Furthermore, we will show how to use our translation management system to make the most of the custom NMT, by leveraging the models, fine-tuning and continuing to improve them over time.</abstract>
      <attachment type="presentation" hash="b3ff86db">2021.mtsummit-up.24.Presentation.pdf</attachment>
      <bibkey>jonsson-jaikat-2021-data</bibkey>
    </paper>
    <paper id="25">
      <title>Building <fixed-case>MT</fixed-case> systems in low resourced languages for Public Sector users in <fixed-case>C</fixed-case>roatia, <fixed-case>I</fixed-case>celand, <fixed-case>I</fixed-case>reland, and <fixed-case>N</fixed-case>orway</title>
      <author><first>Róisín</first><last>Moran</last></author>
      <author><first>Carla</first><last>Para Escartín</last></author>
      <author><first>Akshai</first><last>Ramesh</last></author>
      <author><first>Páraic</first><last>Sheridan</last></author>
      <author><first>Jane</first><last>Dunne</last></author>
      <author><first>Federico</first><last>Gaspari</last></author>
      <author><first>Sheila</first><last>Castilho</last></author>
      <author><first>Natalia</first><last>Resende</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <pages>353-381</pages>
      <abstract>When developing Machine Translation engines, low resourced language pairs tend to be in a disadvantaged position: less available data means that developing robust MT models can be more challenging.The EU-funded PRINCIPLE project aims at overcoming this challenge for four low resourced European languages: Norwegian, Croatian, Irish and Icelandic. This presentation will give an overview of the project, with a focus on the set of Public Sector users and their use cases for which we have developed MT solutions.We will discuss the range of language resources that have been gathered through contributions from public sector collaborators, and present the extensive evaluations that have been undertaken, including significant user evaluation of MT systems across all of the public sector participants in each of the four countries involved.</abstract>
      <attachment type="presentation" hash="961ec080">2021.mtsummit-up.25.Presentation.pdf</attachment>
      <bibkey>moran-etal-2021-building</bibkey>
    </paper>
    <paper id="26">
      <title>Using speech technology in the translation process workflow in international organizations: A quantitative and qualitative study</title>
      <author><first>Pierrette</first><last>Bouillon</last></author>
      <author><first>Jeevanthi</first><last>Liyanapathirana</last></author>
      <pages>382-395</pages>
      <abstract>In international organizations, the growing demand for translations has increased the need for post-editing. Different studies show that automatic speech recognition systems have the potential to increase the productivity of the translation process as well as the quality. In this talk, we will explore the possibilities of using speech in the translation process by conducting a post-editing experiment with three professional translators in an international organization. Our experiment consisted of comparing three translation methods: speaking the translation with MT as an inspiration (RESpeaking), post-editing the MT suggestions by typing (PE), and editing the MT suggestion using speech (SPE). BLEU and HTER scores were used to compare the three methods. Our study shows that translators did more edits under condition RES, whereas in SPE, the resulting translations were closer to the reference according to the BLEU score and required less edits. Time taken to translate was the least in SPE followed by PE, RES methods and the translators preferred using speech to typing.These results show the potential of speech when it is coupled with post-editing.To the best of our knowledge, this is the first quantitative study conducted on using post-editing and speech together in large scale international organizations.</abstract>
      <attachment type="presentation" hash="28b0a7a2">2021.mtsummit-up.26.Presentation.pdf</attachment>
      <bibkey>bouillon-liyanapathirana-2021-using</bibkey>
    </paper>
    <paper id="28">
      <title>cush<fixed-case>LEPOR</fixed-case> uses <fixed-case>LABSE</fixed-case> distilled knowledge to improve correlation with human translation evaluations</title>
      <author><first>Gleb</first><last>Erofeev</last></author>
      <author><first>Irina</first><last>Sorokina</last></author>
      <author><first>Lifeng</first><last>Han</last></author>
      <author><first>Serge</first><last>Gladkoff</last></author>
      <pages>421-439</pages>
      <abstract>Automatic MT evaluation metrics are indispensable for MT research. Augmented metrics such as hLEPOR include broader evaluation factors (recall and position difference penalty) in addition to the factors used in BLEU (sentence length, precision), and demonstrated higher accuracy. However, the obstacles preventing the wide use of hLEPOR were the lack of easy portable Python package and empirical weighting parameters that were tuned by manual work. This project addresses the above issues by offering a Python implementation of hLEPOR and automatic tuning of the parameters. We use existing translation memories (TM) as reference set and distillation modeling with LaBSE (Language-Agnostic BERT Sentence Embedding) to calibrate parameters for custom hLEPOR (cushLEPOR). cushLEPOR maximizes the correlation between hLEPOR and the distilling model similarity score towards reference. It can be used quickly and precisely to evaluate MT output from different engines, without need of manual weight tuning for optimization. In this session you will learn how to tune hLEPOR to obtain automatic custom-tuned cushLEPOR metric far more precise than BLEU. The method does not require costly human evaluations, existing TM is taken as a reference translation set, and cushLEPOR is created to select the best MT engine for the reference data-set.</abstract>
      <attachment type="presentation" hash="681d41a2">2021.mtsummit-up.28.Presentation.pdf</attachment>
      <bibkey>erofeev-etal-2021-cushlepor</bibkey>
    </paper>
    <paper id="29">
      <title>A Synthesis of Human and Machine: Correlating “New” Automatic Evaluation Metrics with Human Assessments</title>
      <author><first>Mara</first><last>Nunziatini</last></author>
      <author><first>Andrea</first><last>Alfieri</last></author>
      <pages>440-465</pages>
      <abstract>The session will provide an overview of some of the new Machine Translation metrics available on the market, analyze if and how these new metrics correlate at a segment level to the results of Adequacy and Fluency Human Assessments, and how they compare against TER scores and Levenshtein Distance – two of our currently preferred metrics – as well as against each of the other. The information in this session will help to get a better understanding of their strengths and weaknesses and make informed decisions when it comes to forecasting MT production.</abstract>
      <attachment type="presentation" hash="b571b885">2021.mtsummit-up.29.Presentation.pdf</attachment>
      <bibkey>nunziatini-alfieri-2021-synthesis</bibkey>
    </paper>
    <paper id="30">
      <title>Lab vs. Production: Two Approaches to Productivity Evaluation for <fixed-case>MTPE</fixed-case> for <fixed-case>LSP</fixed-case></title>
      <author><first>Elena</first><last>Murgolo</last></author>
      <pages>466-490</pages>
      <abstract>In the paper we propose both kind of tests as viable post-editing productivity evaluation solutions as they both deliver a clear overview of the difference in speed between HT and PE of the translators involved. The decision on whether to use the first approach or the second can be based on a number of factors, such as: availability of actual orders in the domain and language combination to be tested; time; availability of Post-editors in the domain and in the language combination to be tested. The aim of this paper will be to show that both methodologies can be useful in different settings for a preliminary evaluation of possible productivity gain with MTPE.</abstract>
      <attachment type="presentation" hash="fac5e41d">2021.mtsummit-up.30.Presentation.pdf</attachment>
      <bibkey>murgolo-2021-lab</bibkey>
    </paper>
  </volume>
  <volume id="loresmt" ingest-date="2021-09-26">
    <meta>
      <booktitle>Proceedings of the 4th Workshop on Technologies for MT of Low Resource Languages (LoResMT2021)</booktitle>
      <publisher>Association for Machine Translation in the Americas</publisher>
      <address>Virtual</address>
      <month>August</month>
      <year>2021</year>
      <editor><first>John</first><last>Ortega</last></editor>
      <editor><first>Atul Kr.</first><last>Ojha</last></editor>
      <editor><first>Katharina</first><last>Kann</last></editor>
      <editor><first>Chao-Hong</first><last>Liu</last></editor>
      <url hash="2510de92">2021.mtsummit-loresmt</url>
    </meta>
    <frontmatter>
      <url hash="abf10b8d">2021.mtsummit-loresmt.0</url>
      <bibkey>mtsummit-2021-technologies</bibkey>
    </frontmatter>
    </volume>
</collection>