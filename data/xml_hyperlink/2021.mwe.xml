<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.mwe">
  <volume id="1" ingest-date="2021-07-25">
    <meta>
      <booktitle>Proceedings of the 17th Workshop on Multiword Expressions (MWE 2021)</booktitle>
      <editor><first>Paul</first><last>Cook</last></editor>
      <editor><first>Jelena</first><last>Mitrović</last></editor>
      <editor><first>Carla Parra</first><last>Escartín</last></editor>
      <editor><first>Ashwini</first><last>Vaidya</last></editor>
      <editor><first>Petya</first><last>Osenova</last></editor>
      <editor><first>Shiva</first><last>Taslimipoor</last></editor>
      <editor><first>Carlos</first><last>Ramisch</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>August</month>
      <year>2021</year>
      <url hash="f2cb1188">2021.mwe-1</url>
    </meta>
    <frontmatter>
      <url hash="36cb2cc9">2021.mwe-1.0</url>
      <bibkey>mwe-2021-multiword</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Where Do Aspectual Variants of Light Verb Constructions Belong?</title>
      <author><first>Aggeliki</first><last>Fotopoulou</last></author>
      <author><first>Eric</first><last>Laporte</last></author>
      <author><first>Takuya</first><last>Nakamura</last></author>
      <pages>2–12</pages>
      <abstract>Expressions with an <a href="https://en.wikipedia.org/wiki/Grammatical_aspect">aspectual variant</a> of a <a href="https://en.wikipedia.org/wiki/Light_verb">light verb</a>, e.g. ‘take on debt’ vs. ‘have debt’, are frequent in texts but often difficult to classify between <a href="https://en.wikipedia.org/wiki/Idiom_(language_structure)">verbal idioms</a>, <a href="https://en.wikipedia.org/wiki/Light_verb_construction">light verb constructions</a> or compositional phrases. We investigate the properties of such <a href="https://en.wikipedia.org/wiki/Expression_(mathematics)">expressions</a> with a disputed membership and propose a selection of <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">features</a> that determine more satisfactory boundaries between the three categories in this zone, assigning the <a href="https://en.wikipedia.org/wiki/Expression_(mathematics)">expressions</a> to one of them.</abstract>
      <url hash="472c33f2">2021.mwe-1.2</url>
      <doi>10.18653/v1/2021.mwe-1.2</doi>
      <bibkey>fotopoulou-etal-2021-aspectual</bibkey>
    </paper>
    <paper id="3">
      <title>Data-driven Identification of Idioms in Song Lyrics</title>
      <author><first>Miriam</first><last>Amin</last></author>
      <author><first>Peter</first><last>Fankhauser</last></author>
      <author><first>Marc</first><last>Kupietz</last></author>
      <author><first>Roman</first><last>Schneider</last></author>
      <pages>13–22</pages>
      <abstract>The automatic recognition of idioms poses a challenging problem for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP applications</a>. Whereas <a href="https://en.wikipedia.org/wiki/First_language">native speakers</a> can intuitively handle multiword expressions whose compositional meanings are hard to trace back to individual <a href="https://en.wikipedia.org/wiki/Semantics">word semantics</a>, there is still ample scope for improvement regarding computational approaches. We assume that idiomatic constructions can be characterized by gradual intensities of semantic non-compositionality, formal fixedness, and unusual usage context, and introduce a number of measures for these characteristics, comprising count-based and predictive collocation measures together with measures of context (un)similarity. We evaluate our approach on a manually labelled gold standard, derived from a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus of German pop lyrics</a>. To this end, we apply a Random Forest classifier to analyze the individual contribution of <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> for automatically detecting idioms, and study the trade-off between <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall</a> and <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">precision</a>. Finally, we evaluate the classifier on an independent dataset of idioms extracted from a list of Wikipedia idioms, achieving state-of-the art accuracy.</abstract>
      <url hash="04e3aa89">2021.mwe-1.3</url>
      <doi>10.18653/v1/2021.mwe-1.3</doi>
      <bibkey>amin-etal-2021-data</bibkey>
    </paper>
    <paper id="5">
      <title>PIE : A Parallel Idiomatic Expression Corpus for Idiomatic Sentence Generation and Paraphrasing<fixed-case>PIE</fixed-case>: A Parallel Idiomatic Expression Corpus for Idiomatic Sentence Generation and Paraphrasing</title>
      <author><first>Jianing</first><last>Zhou</last></author>
      <author><first>Hongyu</first><last>Gong</last></author>
      <author><first>Suma</first><last>Bhat</last></author>
      <pages>33–48</pages>
      <abstract>Idiomatic expressions (IE) play an important role in <a href="https://en.wikipedia.org/wiki/Natural_language">natural language</a>, and have long been a pain in the neck for NLP systems. Despite this, text generation tasks related to IEs remain largely under-explored. In this paper, we propose two new tasks of idiomatic sentence generation and <a href="https://en.wikipedia.org/wiki/Paraphrase">paraphrasing</a> to fill this research gap. We introduce a curated dataset of 823 IEs, and a parallel corpus with sentences containing them and the same sentences where the IEs were replaced by their literal paraphrases as the primary resource for our tasks. We benchmark existing deep learning models, which have state-of-the-art performance on related tasks using automated and manual evaluation with our dataset to inspire further research on our proposed tasks. By establishing baseline models, we pave the way for more comprehensive and accurate <a href="https://en.wikipedia.org/wiki/Computer_simulation">modeling</a> of <a href="https://en.wikipedia.org/wiki/Integrated_circuit">IEs</a>, both for generation and <a href="https://en.wikipedia.org/wiki/Paraphrase">paraphrasing</a>.</abstract>
      <url hash="196aa6f7">2021.mwe-1.5</url>
      <doi>10.18653/v1/2021.mwe-1.5</doi>
      <bibkey>zhou-etal-2021-pie</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wikilarge">WikiLarge</pwcdataset>
    </paper>
    <paper id="6">
      <title>Lexical Semantic Recognition</title>
      <author><first>Nelson F.</first><last>Liu</last></author>
      <author><first>Daniel</first><last>Hershcovich</last></author>
      <author><first>Michael</first><last>Kranzlein</last></author>
      <author><first>Nathan</first><last>Schneider</last></author>
      <pages>49–56</pages>
      <abstract>In <a href="https://en.wikipedia.org/wiki/Lexical_semantics">lexical semantics</a>, full-sentence segmentation and segment labeling of various <a href="https://en.wikipedia.org/wiki/Phenomenon">phenomena</a> are generally treated separately, despite their interdependence. We hypothesize that a unified lexical semantic recognition task is an effective way to encapsulate previously disparate styles of <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a>, including multiword expression identification / classification and supersense tagging. Using the STREUSLE corpus, we train a neural CRF sequence tagger and evaluate its performance along various axes of annotation. As the label set generalizes that of previous tasks (PARSEME, DiMSUM), we additionally evaluate how well the model generalizes to those test sets, finding that it approaches or surpasses existing models despite training only on STREUSLE. Our work also establishes <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline models</a> and evaluation metrics for integrated and accurate modeling of <a href="https://en.wikipedia.org/wiki/Lexical_semantics">lexical semantics</a>, facilitating future work in this area.</abstract>
      <url hash="220c2f48">2021.mwe-1.6</url>
      <attachment type="OptionalSupplementaryMaterial" hash="132180d7">2021.mwe-1.6.OptionalSupplementaryMaterial.zip</attachment>
      <doi>10.18653/v1/2021.mwe-1.6</doi>
      <bibkey>liu-etal-2021-lexical</bibkey>
      <pwccode url="https://github.com/nert-nlp/streusle" additional="true">nert-nlp/streusle</pwccode>
    </paper>
    </volume>
</collection>