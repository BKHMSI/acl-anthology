<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.cmlc">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the 8th Workshop on Challenges in the Management of Large Corpora</booktitle>
      <editor><first>Piotr</first><last>Bański</last></editor>
      <editor><first>Adrien</first><last>Barbaresi</last></editor>
      <editor><first>Simon</first><last>Clematide</last></editor>
      <editor><first>Marc</first><last>Kupietz</last></editor>
      <editor><first>Harald</first><last>Lüngen</last></editor>
      <editor><first>Ines</first><last>Pisetta</last></editor>
      <publisher>European Language Ressources Association</publisher>
      <address>Marseille, France</address>
      <month>May</month>
      <year>2020</year>
      <isbn>979-10-95546-61-0</isbn>
    </meta>
    <frontmatter>
      <url hash="1a1df40e">2020.cmlc-1.0</url>
      <bibkey>cmlc-2020-challenges</bibkey>
    </frontmatter>
    <paper id="4">
      <title>Geoparsing the historical Gazetteers of Scotland : accurately computing location in mass digitised texts<fixed-case>S</fixed-case>cotland: accurately computing location in mass digitised texts</title>
      <author><first>Rosa</first><last>Filgueira</last></author>
      <author><first>Claire</first><last>Grover</last></author>
      <author><first>Melissa</first><last>Terras</last></author>
      <author><first>Beatrice</first><last>Alex</last></author>
      <pages>24–30</pages>
      <abstract>This paper describes work in progress on devising automatic and parallel methods for geoparsing large digital historical textual data by combining the strengths of three natural language processing (NLP) tools, the Edinburgh Geoparser, spaCy and defoe, and employing different tokenisation and named entity recognition (NER) techniques. We apply these tools to a large collection of nineteenth century Scottish geographical dictionaries, and describe preliminary results obtained when processing this <a href="https://en.wikipedia.org/wiki/Data">data</a>.</abstract>
      <url hash="a3c3df6b">2020.cmlc-1.4</url>
      <language>eng</language>
      <bibkey>filgueira-etal-2020-geoparsing</bibkey>
    </paper>
    <paper id="5">
      <title>The Corpus Query Middleware of Tomorrow   A Proposal for a Hybrid Corpus Query Architecture</title>
      <author><first>Markus</first><last>Gärtner</last></author>
      <pages>31–39</pages>
      <abstract>Development of dozens of specialized corpus query systems and languages over the past decades has let to a diverse but also fragmented landscape. Today we are faced with a plethora of query tools that each provide unique features, but which are also not interoperable and often rely on very specific database back-ends or formats for storage. This severely hampers usability both for end users that want to query different corpora and also for corpus designers that wish to provide users with an interface for querying and exploration. We propose a hybrid corpus query architecture as a first step to overcoming this issue. It takes the form of a <a href="https://en.wikipedia.org/wiki/Middleware">middleware system</a> between user front-ends and optional database or text indexing solutions as <a href="https://en.wikipedia.org/wiki/Front_and_back_ends">back-ends</a>. At its core is a custom query evaluation engine for index-less processing of corpus queries. With a flexible JSON-LD query protocol the approach allows communication with <a href="https://en.wikipedia.org/wiki/Front_and_back_ends">back-end systems</a> to partially solve queries and offset some of the performance penalties imposed by the custom evaluation engine. This paper outlines the details of our first draft of aforementioned <a href="https://en.wikipedia.org/wiki/Architecture">architecture</a>.</abstract>
      <url hash="8778b5da">2020.cmlc-1.5</url>
      <language>eng</language>
      <bibkey>gartner-2020-corpus</bibkey>
    </paper>
    <paper id="6">
      <title>Using <a href="https://en.wikipedia.org/wiki/Full-text_search">full text indices</a> for querying spoken language data</title>
      <author><first>Elena</first><last>Frick</last></author>
      <author><first>Thomas</first><last>Schmidt</last></author>
      <pages>40–46</pages>
      <abstract>As a part of the ZuMult-project, we are currently modelling a backend architecture that should provide query access to corpora from the Archive of Spoken German (AGD) at the Leibniz-Institute for the German Language (IDS). We are exploring how to reuse existing search engine frameworks providing full text indices and allowing to query corpora by one of the corpus query languages (QLs) established and actively used in the corpus research community. For this purpose, we tested MTAS-an open source Lucene-based search engine for querying on text with multilevel annotations. We applied MTAS on three oral corpora stored in the TEI-based ISO standard for transcriptions of spoken language (ISO 24624:2016). These corpora differ from the corpus data that MTAS was developed for, because they include interactions with two and more speakers and are enriched, inter alia, with timeline-based annotations. In this contribution, we report our test results and address issues that arise when search frameworks originally developed for querying <a href="https://en.wikipedia.org/wiki/Text_corpus">written corpora</a> are being transferred into the field of <a href="https://en.wikipedia.org/wiki/Spoken_language">spoken language</a>.</abstract>
      <url hash="1278b161">2020.cmlc-1.6</url>
      <language>eng</language>
      <bibkey>frick-schmidt-2020-using</bibkey>
    </paper>
    <paper id="8">
      <title>Czech National Corpus in 2020 : Recent Developments and Future Outlook<fixed-case>C</fixed-case>zech National Corpus in 2020: Recent Developments and Future Outlook</title>
      <author><first>Michal</first><last>Kren</last></author>
      <pages>52–57</pages>
      <abstract>The paper overviews the state of implementation of the Czech National Corpus (CNC) in all the main areas of its operation : <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus compilation</a>, <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a>, <a href="https://en.wikipedia.org/wiki/Application_software">application development</a> and user services. As the focus is on the recent development, some of the areas are described in more detail than the others. Close attention is paid to the <a href="https://en.wikipedia.org/wiki/Data_collection">data collection</a> and, in particular, to the description of <a href="https://en.wikipedia.org/wiki/Web_application_development">web application development</a>. This is not only because <a href="https://en.wikipedia.org/wiki/Numerical_control">CNC</a> has recently seen a significant progress in this area, but also because we believe that end-user web applications shape the way linguists and other scholars think about the language data and about the range of possibilities they offer. This consideration is even more important given the variability of the <a href="https://en.wikipedia.org/wiki/Numerical_analysis">CNC corpora</a>.</abstract>
      <url hash="ef7eed8e">2020.cmlc-1.8</url>
      <language>eng</language>
      <bibkey>kren-2020-czech</bibkey>
    </paper>
    </volume>
</collection>