<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.restup">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the Workshop on Resources and Techniques for User and Author Profiling in Abusive Language</booktitle>
      <editor><first>Johanna</first><last>Monti</last></editor>
      <editor><first>Valerio</first><last>Basile</last></editor>
      <editor><first>Maria Pia Di</first><last>Buono</last></editor>
      <editor><first>Raffaele</first><last>Manna</last></editor>
      <editor><first>Antonio</first><last>Pascucci</last></editor>
      <editor><first>Sara</first><last>Tonelli</last></editor>
      <publisher>European Language Resources Association (ELRA)</publisher>
      <address>Marseille, France</address>
      <month>May</month>
      <year>2020</year>
      <isbn>979-10-95546-49-8</isbn>
    </meta>
    <frontmatter>
      <url hash="e3c78bbf">2020.restup-1.0</url>
      <bibkey>restup-2020-resources</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Profiling Bots, Fake News Spreaders and Haters</title>
      <author><first>Paolo</first><last>Rosso</last></author>
      <pages>1</pages>
      <abstract>Author profiling studies how language is shared by people. Stylometry techniques help in identifying aspects such as gender, age, <a href="https://en.wikipedia.org/wiki/First_language">native language</a>, or even <a href="https://en.wikipedia.org/wiki/Personality">personality</a>. Author profiling is a problem of growing importance, not only in marketing and forensics, but also in <a href="https://en.wikipedia.org/wiki/Computer_security">cybersecurity</a>. The aim is not only to identify users whose messages are potential threats from a terrorism viewpoint but also those whose messages are a threat from a social exclusion perspective because containing <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a>, <a href="https://en.wikipedia.org/wiki/Cyberbullying">cyberbullying</a> etc. Bots often play a key role in spreading <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a>, as well as <a href="https://en.wikipedia.org/wiki/Fake_news">fake news</a>, with the purpose of polarizing the public opinion with respect to controversial issues like <a href="https://en.wikipedia.org/wiki/Brexit">Brexit</a> or the <a href="https://en.wikipedia.org/wiki/2017_Catalan_independence_referendum">Catalan referendum</a>. For instance, the authors of a recent study about the 1 Oct 2017 Catalan referendum, showed that in a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> with 3.6 million tweets, about 23.6 % of tweets were produced by <a href="https://en.wikipedia.org/wiki/Internet_bot">bots</a>. The target of these <a href="https://en.wikipedia.org/wiki/Internet_bot">bots</a> were pro-independence influencers that were sent negative, emotional and aggressive hateful tweets with hashtags such as # sonunesbesties (i.e. # theyareanimals). Since 2013 at the PAN Lab at CLEF (https://pan.webis.de/) we have addressed several aspects of <a href="https://en.wikipedia.org/wiki/Author_profiling">author profiling</a> in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. In 2019 we investigated the feasibility of distinguishing whether the author of a <a href="https://en.wikipedia.org/wiki/Twitter">Twitter feed</a> is a bot, while this year we are addressing the problem of profiling those authors that are more likely to spread <a href="https://en.wikipedia.org/wiki/Fake_news">fake news</a> in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> because they did in the past. We aim at identifying possible <a href="https://en.wikipedia.org/wiki/Fake_news">fake news spreaders</a> as a first step towards preventing <a href="https://en.wikipedia.org/wiki/Fake_news">fake news</a> from being propagated among online users (fake news aim to polarize the public opinion and may contain hate speech). In 2021 we specifically aim at addressing the challenging problem of profiling haters in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> in order to monitor abusive language and prevent cases of <a href="https://en.wikipedia.org/wiki/Social_exclusion">social exclusion</a> in order to combat, for instance, <a href="https://en.wikipedia.org/wiki/Racism">racism</a>, <a href="https://en.wikipedia.org/wiki/Xenophobia">xenophobia</a> and <a href="https://en.wikipedia.org/wiki/Misogyny">misogyny</a>. Although we already started addressing the problem of detecting hate speech when targets are immigrants or women at the HatEval shared task in SemEval-2019, and when targets are women also in the Automatic Misogyny Identification tasks at IberEval-2018, Evalita-2018 and Evalita-2020, it was not done from an author profiling perspective. At the end of the keynote, I will present some insights in order to stress the importance of monitoring abusive language in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>, for instance, in foreseeing sexual crimes. In fact, previous studies confirmed that a correlation might lay between the yearly per capita rate of rape and the misogynistic language used in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>.</abstract>
      <url hash="32e4815b">2020.restup-1.1</url>
      <language>eng</language>
      <bibkey>rosso-2020-profiling</bibkey>
    </paper>
    <paper id="2">
      <title>An Indian Language Social Media Collection for Hate and Offensive Speech<fixed-case>I</fixed-case>ndian Language Social Media Collection for Hate and Offensive Speech</title>
      <author><first>Anita</first><last>Saroj</last></author>
      <author><first>Sukomal</first><last>Pal</last></author>
      <pages>2–8</pages>
      <abstract>In <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>, people express themselves every day on issues that affect their lives. During the <a href="https://en.wikipedia.org/wiki/Elections_in_Pakistan">parliamentary elections</a>, people’s interaction with the candidates in social media posts reflects a lot of social trends in a charged atmosphere. People’s likes and dislikes on leaders, <a href="https://en.wikipedia.org/wiki/Political_party">political parties</a> and their stands often become subject of hate and offensive posts. We collected social media posts in <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a> and <a href="https://en.wikipedia.org/wiki/English_language">English</a> from <a href="https://en.wikipedia.org/wiki/Facebook">Facebook</a> and <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> during the run-up to the parliamentary election 2019 of India (PEI data-2019). We created a dataset for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> into three categories : <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a>, offensive and not hate, or not offensive. We report here the initial results of sentiment classification for the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> using different <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a>.</abstract>
      <url hash="c9930b33">2020.restup-1.2</url>
      <language>eng</language>
      <bibkey>saroj-pal-2020-indian</bibkey>
    </paper>
    </volume>
</collection>