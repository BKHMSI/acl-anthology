<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.gwc">
  <volume id="1" ingest-date="2021-02-07">
    <meta>
      <booktitle>Proceedings of the 11th Global Wordnet Conference</booktitle>
      <editor><first>Piek</first><last>Vossen</last></editor>
      <editor><first>Christiane</first><last>Fellbaum</last></editor>
      <publisher>Global Wordnet Association</publisher>
      <address>University of South Africa (UNISA)</address>
      <month>January</month>
      <year>2021</year>
      <url hash="edc87ddd">2021.gwc-1</url>
    </meta>
    <frontmatter>
      <url hash="392ac3ba">2021.gwc-1.0</url>
      <bibkey>gwc-2021-global</bibkey>
    </frontmatter>
    <paper id="1">
      <title>On Universal Colexifications</title>
      <author><first>Hongchang</first><last>Bao</last></author>
      <author><first>Bradley</first><last>Hauer</last></author>
      <author><first>Grzegorz</first><last>Kondrak</last></author>
      <pages>1–7</pages>
      <abstract>Colexification occurs when two distinct concepts are lexified by the same word. The term covers both <a href="https://en.wikipedia.org/wiki/Polysemy">polysemy</a> and <a href="https://en.wikipedia.org/wiki/Homonym">homonymy</a>. We posit and investigate the hypothesis that no pair of <a href="https://en.wikipedia.org/wiki/Concept">concepts</a> are colexified in every language. We test our hypothesis by analyzing colexification data from <a href="https://en.wikipedia.org/wiki/BabelNet">BabelNet</a>, Open Multilingual WordNet, and CLICS. The results show that our hypothesis is supported by over 99.9 % of colexified concept pairs in these three <a href="https://en.wikipedia.org/wiki/Lexical_resource">lexical resources</a>.</abstract>
      <url hash="e0a4555c">2021.gwc-1.1</url>
      <bibkey>bao-etal-2021-universal</bibkey>
    </paper>
    <paper id="3">
      <title>Practical Approach on Implementation of WordNets for <a href="https://en.wikipedia.org/wiki/Languages_of_South_Africa">South African Languages</a><fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>ets for <fixed-case>S</fixed-case>outh <fixed-case>A</fixed-case>frican Languages</title>
      <author><first>Tshephisho Joseph</first><last>Sefara</last></author>
      <author><first>Tumisho Billson</first><last>Mokgonyane</last></author>
      <author><first>Vukosi</first><last>Marivate</last></author>
      <pages>20–25</pages>
      <abstract>This paper proposes the implementation of WordNets for five South African languages, namely, <a href="https://en.wikipedia.org/wiki/Northern_Sotho_language">Sepedi</a>, <a href="https://en.wikipedia.org/wiki/Tswana_language">Setswana</a>, <a href="https://en.wikipedia.org/wiki/Tshivenda_language">Tshivenda</a>, <a href="https://en.wikipedia.org/wiki/Zulu_language">isiZulu</a> and <a href="https://en.wikipedia.org/wiki/Xhosa_language">isiXhosa</a> to be added to open multilingual WordNets (OMW) on natural language toolkit (NLTK). The African WordNets are converted from Princeton WordNet (PWN) 2.0 to 3.0 to match the synsets in PWN 3.0. After conversion, there were 7157, 11972, 1288, 6380, and 9460 lemmas for <a href="https://en.wikipedia.org/wiki/Northern_Sotho_language">Sepedi</a>, <a href="https://en.wikipedia.org/wiki/Tswana_language">Setswana</a>, <a href="https://en.wikipedia.org/wiki/Tshivenda_language">Tshivenda</a>, <a href="https://en.wikipedia.org/wiki/Zulu_language">isiZulu</a> and isiX- hosa respectively. Setswana, <a href="https://en.wikipedia.org/wiki/Xhosa_language">isiXhosa</a>, <a href="https://en.wikipedia.org/wiki/Northern_Sotho_language">Sepedi</a> contains more lemmas compared to 8 languages in OMW and <a href="https://en.wikipedia.org/wiki/Zulu_language">isiZulu</a> contains more lemmas compared to 7 languages in OMW. A library has been published for continuous development of African WordNets in OMW using <a href="https://en.wikipedia.org/wiki/NLTK">NLTK</a>.</abstract>
      <url hash="4239dc71">2021.gwc-1.3</url>
      <bibkey>sefara-etal-2021-practical</bibkey>
      <pwccode url="https://github.com/josephsefara/africanwordnet" additional="false">josephsefara/africanwordnet</pwccode>
    </paper>
    <paper id="6">
      <title>Ask2Transformers : Zero-Shot Domain labelling with Pretrained Language Models<fixed-case>A</fixed-case>sk2<fixed-case>T</fixed-case>ransformers: Zero-Shot Domain labelling with Pretrained Language Models</title>
      <author><first>Oscar</first><last>Sainz</last></author>
      <author><first>German</first><last>Rigau</last></author>
      <pages>44–52</pages>
      <abstract>In this paper we present a system that exploits different pre-trained Language Models for assigning domain labels to WordNet synsets without any kind of supervision. Furthermore, the <a href="https://en.wikipedia.org/wiki/System">system</a> is not restricted to use a particular set of <a href="https://en.wikipedia.org/wiki/Domain_name">domain labels</a>. We exploit the knowledge encoded within different off-the-shelf pre-trained Language Models and task formulations to infer the domain label of a particular WordNet definition. The proposed zero-shot system achieves a new state-of-the-art on the English dataset used in the evaluation.</abstract>
      <url hash="d8affe52">2021.gwc-1.6</url>
      <bibkey>sainz-rigau-2021-ask2transformers</bibkey>
    </paper>
    <paper id="9">
      <title>Monolingual Word Sense Alignment as a Classification Problem</title>
      <author><first>Sina</first><last>Ahmadi</last></author>
      <author><first>John P.</first><last>McCrae</last></author>
      <pages>73–80</pages>
      <abstract>Words are defined based on their meanings in various ways in different resources. Aligning word senses across monolingual lexicographic resources increases domain coverage and enables integration and incorporation of data. In this paper, we explore the application of classification methods using manually-extracted features along with representation learning techniques in the task of word sense alignment and semantic relationship detection. We demonstrate that the performance of classification methods dramatically varies based on the type of semantic relationships due to the nature of the task but outperforms the previous experiments.</abstract>
      <url hash="c7363d23">2021.gwc-1.9</url>
      <bibkey>ahmadi-mccrae-2021-monolingual</bibkey>
    </paper>
    <paper id="11">
      <title>The GlobalWordNet Formats : Updates for 2020<fixed-case>G</fixed-case>lobal<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et Formats: Updates for 2020</title>
      <author><first>John P.</first><last>McCrae</last></author>
      <author><first>Michael Wayne</first><last>Goodman</last></author>
      <author><first>Francis</first><last>Bond</last></author>
      <author><first>Alexandre</first><last>Rademaker</last></author>
      <author><first>Ewa</first><last>Rudnicka</last></author>
      <author><first>Luis Morgado Da</first><last>Costa</last></author>
      <pages>91–99</pages>
      <abstract>The Global Wordnet Formats have been introduced to enable wordnets to have a common representation that can be integrated through the Global WordNet Grid. As a result of their adoption, a number of shortcomings of the <a href="https://en.wikipedia.org/wiki/File_format">format</a> were identified, and in this paper we describe the extensions to the <a href="https://en.wikipedia.org/wiki/File_format">formats</a> that address these issues. These include : ordering of senses, dependencies between wordnets, pronunciation, syntactic modelling, relations, sense keys, <a href="https://en.wikipedia.org/wiki/Metadata">metadata</a> and RDF support. Furthermore, we provide some perspectives on how these changes help in the integration of <a href="https://en.wikipedia.org/wiki/Wordnet">wordnets</a>.</abstract>
      <url hash="37765de7">2021.gwc-1.11</url>
      <bibkey>mccrae-etal-2021-globalwordnet</bibkey>
      <pwccode url="https://github.com/globalwordnet/english-wordnet" additional="false">globalwordnet/english-wordnet</pwccode>
    </paper>
    <paper id="13">
      <title>Semantic Analysis of Verb-Noun Derivation in Princeton WordNet<fixed-case>P</fixed-case>rinceton <fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et</title>
      <author><first>Verginica</first><last>Mititelu</last></author>
      <author><first>Svetlozara</first><last>Leseva</last></author>
      <author><first>Ivelina</first><last>Stoyanova</last></author>
      <pages>108–117</pages>
      <abstract>We present here the results of a morphosemantic analysis of the verb-noun pairs in the Princeton WordNet as reflected in the standoff file containing pairs annotated with a set of 14 semantic relations. We have automatically distinguished between <a href="https://en.wikipedia.org/wiki/Zero-derivation">zero-derivation</a> and affixal derivation in the <a href="https://en.wikipedia.org/wiki/Data">data</a> and identified the <a href="https://en.wikipedia.org/wiki/Affix">affixes</a> and manually checked the results. The data show that for each semantic relation an <a href="https://en.wikipedia.org/wiki/Affix">affix</a> prevails in creating new words, although we can not talk about their specificity with respect to such a <a href="https://en.wikipedia.org/wiki/Binary_relation">relation</a>. Moreover, certain pairs of verb-noun semantic primes are better represented for each semantic relation, and some semantic clusters (in the form of WordNet subtrees) take shape as a result. We thus employ a large-scale data-driven linguistically motivated analysis afforded by the rich derivational and morphosemantic description in <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a> to the end of capturing finer regularities in the process of derivation as represented in the semantic properties of the words involved and as reflected in the structure of the lexicon.</abstract>
      <url hash="084d70ae">2021.gwc-1.13</url>
      <bibkey>mititelu-etal-2021-semantic</bibkey>
    </paper>
    <paper id="22">
      <title>OdeNet : Compiling a GermanWordNet from other Resources<fixed-case>O</fixed-case>de<fixed-case>N</fixed-case>et: Compiling a <fixed-case>G</fixed-case>erman<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et from other Resources</title>
      <author><first>Melanie</first><last>Siegel</last></author>
      <author><first>Francis</first><last>Bond</last></author>
      <pages>192–198</pages>
      <abstract>The <a href="https://en.wikipedia.org/wiki/Princeton_WordNet">Princeton WordNet</a> for the <a href="https://en.wikipedia.org/wiki/English_language">English language</a> has been used worldwide in NLP projects for many years. With the OMW initiative, <a href="https://en.wikipedia.org/wiki/Wordnet">wordnets</a> for different languages of the world are being linked via identifiers. The parallel development and linking allows new multilingual application perspectives. The development of a <a href="https://en.wikipedia.org/wiki/Wordnet">wordnet</a> for the <a href="https://en.wikipedia.org/wiki/German_language">German language</a> is also in this context. To save development time, existing resources were combined and recompiled. The result was then evaluated and improved. In a relatively short time a resource was created that can be used in projects and continuously improved and extended.</abstract>
      <url hash="18ec63f1">2021.gwc-1.22</url>
      <bibkey>siegel-bond-2021-odenet</bibkey>
    </paper>
    <paper id="24">
      <title>Text Document Clustering : <a href="https://en.wikipedia.org/wiki/Wordnet">Wordnet</a> vs. TF-IDF vs. Word Embeddings<fixed-case>W</fixed-case>ordnet vs. <fixed-case>TF</fixed-case>-<fixed-case>IDF</fixed-case> vs. Word Embeddings</title>
      <author><first>Michał</first><last>Marcińczuk</last></author>
      <author><first>Mateusz</first><last>Gniewkowski</last></author>
      <author><first>Tomasz</first><last>Walkowiak</last></author>
      <author><first>Marcin</first><last>Będkowski</last></author>
      <pages>207–214</pages>
      <abstract>In the paper, we deal with the problem of unsupervised text document clustering for the <a href="https://en.wikipedia.org/wiki/Polish_language">Polish language</a>. Our goal is to compare the modern approaches based on <a href="https://en.wikipedia.org/wiki/Language_model">language modeling</a> (doc2vec and BERT) with the classical <a href="https://en.wikipedia.org/wiki/List_of_programming_languages_by_type">ones</a>, i.e., <a href="https://en.wikipedia.org/wiki/TF-IDF">TF-IDF</a> and wordnet-based. The experiments are conducted on three <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> containing qualification descriptions. The experiments’ results showed that wordnet-based similarity measures could compete and even outperform modern embedding-based approaches.</abstract>
      <url hash="11fd5f7d">2021.gwc-1.24</url>
      <bibkey>marcinczuk-etal-2021-text</bibkey>
    </paper>
    <paper id="26">
      <title>Neural Language Models vs Wordnet-based Semantically Enriched Representation in CST Relation Recognition<fixed-case>W</fixed-case>ordnet-based Semantically Enriched Representation in <fixed-case>CST</fixed-case> Relation Recognition</title>
      <author><first>Arkadiusz</first><last>Janz</last></author>
      <author><first>Maciej</first><last>Piasecki</last></author>
      <author><first>Piotr</first><last>Wątorski</last></author>
      <pages>223–233</pages>
      <abstract>Neural language models, including transformer-based models, that are pre-trained on very large corpora became a common way to represent text in various tasks, including recognition of textual semantic relations, e.g. Cross-document Structure Theory. Pre-trained models are usually fine tuned to downstream tasks and the obtained vectors are used as an input for deep neural classifiers. No linguistic knowledge obtained from resources and tools is utilised. In this paper we compare such universal approaches with a combination of rich graph-based linguistically motivated sentence representation and a typical neural network classifier applied to a task of recognition of CST relation in <a href="https://en.wikipedia.org/wiki/Polish_language">Polish</a>. The representation describes selected levels of the sentence structure including description of lexical meanings on the basis of the wordnet (plWordNet) synsets and connected SUMO concepts. The obtained results show that in the case of difficult relations and medium size training corpus semantically enriched text representation leads to significantly better results.</abstract>
      <url hash="0703aac0">2021.gwc-1.26</url>
      <bibkey>janz-etal-2021-neural</bibkey>
    </paper>
    <paper id="27">
      <title>What is on <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a> that is not in <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a>? A Preliminary Analysis on the TwitterAAE Corpus<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et? A Preliminary Analysis on the <fixed-case>T</fixed-case>witter<fixed-case>AAE</fixed-case> Corpus</title>
      <author><first>Cecilia</first><last>Domingo</last></author>
      <author><first>Tatiana</first><last>Gonzalez-Ferrero</last></author>
      <author><first>Itziar</first><last>Gonzalez-Dios</last></author>
      <pages>234–242</pages>
      <abstract>Natural Language Processing tools and resources have been so far mainly created and trained for standard varieties of language. Nowadays, with the use of large amounts of data gathered from <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>, other varieties and registers need to be processed, which may present other challenges and difficulties. In this work, we focus on <a href="https://en.wikipedia.org/wiki/English_language">English</a> and we present a preliminary analysis by comparing the TwitterAAE corpus, which is annotated for ethnicity, and <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a> by quantifying and explaining the online language that <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a> misses.</abstract>
      <url hash="684077a4">2021.gwc-1.27</url>
      <bibkey>domingo-etal-2021-social</bibkey>
    </paper>
    <paper id="30">
      <title>Toward the creation of <a href="https://en.wikipedia.org/wiki/WordNet">WordNets</a> for ancient Indo-European languages<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>ets for ancient <fixed-case>I</fixed-case>ndo-<fixed-case>E</fixed-case>uropean languages</title>
      <author><first>Erica</first><last>Biagetti</last></author>
      <author><first>Chiara</first><last>Zanchi</last></author>
      <author><first>William Michael</first><last>Short</last></author>
      <pages>258–266</pages>
      <abstract>This paper presents the work in progress toward the creation of a family of WordNets for <a href="https://en.wikipedia.org/wiki/Sanskrit">Sanskrit</a>, <a href="https://en.wikipedia.org/wiki/Ancient_Greek">Ancient Greek</a>, and <a href="https://en.wikipedia.org/wiki/Latin">Latin</a>. Building on previous attempts in the field, we elaborate these efforts bridging together WordNet relational semantics with theories of meaning from <a href="https://en.wikipedia.org/wiki/Cognitive_linguistics">Cognitive Linguistics</a>. We discuss some of the innovations we have introduced to the WordNet architecture, to better capture the polysemy of words, as well as Indo-European language family-specific features. We conclude the paper framing our work within the larger picture of resources available for ancient languages and showing that WordNet-backed search tools have the potential to re-define the kinds of questions that can be asked of ancient language corpora.</abstract>
      <url hash="77766339">2021.gwc-1.30</url>
      <bibkey>biagetti-etal-2021-toward</bibkey>
    </paper>
    <paper id="32">
      <title>Teaching Through Tagging   Interactive Lexical Semantics</title>
      <author><first>Francis</first><last>Bond</last></author>
      <author><first>Andrew</first><last>Devadason</last></author>
      <author><first>Melissa Rui Lin</first><last>Teo</last></author>
      <author><first>Luís Morgado</first><last>da Costa</last></author>
      <pages>273–283</pages>
      <abstract>In this paper we discuss an ongoing effort to enrich students’ learning by involving them in sense tagging. The main goal is to lead students to discover how we can represent meaning and where the limits of our current theories lie. A subsidiary goal is to create sense tagged corpora and an accompanying linked lexicon (in our case wordnets). We present the results of tagging several texts and suggest some ways in which the tagging process could be improved. Two authors of this paper present their own experience as students. Overall, students reported that they found the <a href="https://en.wikipedia.org/wiki/Tag_(metadata)">tagging</a> an enriching experience. The annotated corpora and changes to the <a href="https://en.wikipedia.org/wiki/Wordnet">wordnet</a> are made available through the NTU multilingual corpus and associated wordnets (NTU-MC).</abstract>
      <url hash="35765cef">2021.gwc-1.32</url>
      <bibkey>bond-etal-2021-teaching</bibkey>
    </paper>
    </volume>
</collection>