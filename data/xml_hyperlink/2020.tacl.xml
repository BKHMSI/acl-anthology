<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.tacl">
  <volume id="1">
    <meta>
      <booktitle>Transactions of the Association for Computational Linguistics, Volume 8</booktitle>
      <editor><last>Johnson</last><first>Mark</first></editor>
      <editor><last>Roark</last><first>Brian</first></editor>
      <editor><last>Nenkova</last><first>Ani</first></editor>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
      <year>2020</year>
    </meta>
    <frontmatter>
      <bibkey>tacl-2020-transactions</bibkey>
    </frontmatter>
    <paper id="2">
      <title>AMR-To-Text Generation with Graph Transformer<fixed-case>AMR</fixed-case>-To-Text Generation with Graph Transformer</title>
      <author><first>Tianming</first><last>Wang</last></author>
      <author><first>Xiaojun</first><last>Wan</last></author>
      <author><first>Hanqi</first><last>Jin</last></author>
      <doi>10.1162/tacl_a_00297</doi>
      <abstract>Abstract meaning representation (AMR)-to-text generation is the challenging task of generating natural language texts from AMR graphs, where <a href="https://en.wikipedia.org/wiki/Vertex_(graph_theory)">nodes</a> represent concepts and <a href="https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms">edges</a> denote relations. The current state-of-the-art methods use graph-to-sequence models ; however, they still can not significantly outperform the previous sequence-to-sequence models or statistical approaches. In this paper, we propose a novel graph-to-sequence model (Graph Transformer) to address this task. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> directly encodes the AMR graphs and learns the <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">node representations</a>. A pairwise interaction function is used for computing the semantic relations between the concepts. Moreover, <a href="https://en.wikipedia.org/wiki/Attentional_control">attention mechanisms</a> are used for aggregating the information from the incoming and outgoing neighbors, which help the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> to capture the semantic information effectively. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms the state-of-the-art <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">neural approach</a> by 1.5 BLEU points on LDC2015E86 and 4.8 BLEU points on LDC2017T10 and achieves new state-of-the-art performances.</abstract>
      <pages>19–33</pages>
      <url hash="9dce31b7">2020.tacl-1.2</url>
      <bibkey>wang-etal-2020-amr</bibkey>
    </paper>
    <paper id="4">
      <title>Membership Inference Attacks on Sequence-to-Sequence Models : Is My Data In Your Machine Translation System?<fixed-case>I</fixed-case>s My Data In Your Machine Translation System?</title>
      <author><first>Sorami</first><last>Hisamoto</last></author>
      <author><first>Matt</first><last>Post</last></author>
      <author><first>Kevin</first><last>Duh</last></author>
      <doi>10.1162/tacl_a_00299</doi>
      <abstract>Data privacy is an important issue for <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a> as a service providers. We focus on the problem of membership inference attacks : Given a data sample and black-box access to a <a href="https://en.wikipedia.org/wiki/Statistical_model">model’s API</a>, determine whether the sample existed in the model’s training data. Our contribution is an investigation of this problem in the context of sequence-to-sequence models, which are important in applications such as <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> and <a href="https://en.wikipedia.org/wiki/Closed-circuit_television">video captioning</a>. We define the membership inference problem for sequence generation, provide an open dataset based on state-of-the-art machine translation models, and report initial results on whether these models leak private information against several kinds of membership inference attacks.</abstract>
      <pages>49–63</pages>
      <url hash="dd95e987">2020.tacl-1.4</url>
      <bibkey>hisamoto-etal-2020-membership</bibkey>
      <pwccode url="https://github.com/sorami/TACL-Membership" additional="false">sorami/TACL-Membership</pwccode>
    </paper>
    <paper id="5">
      <title>SpanBERT : Improving Pre-training by Representing and Predicting Spans<fixed-case>S</fixed-case>pan<fixed-case>BERT</fixed-case>: Improving Pre-training by Representing and Predicting Spans</title>
      <author><first>Mandar</first><last>Joshi</last></author>
      <author><first>Danqi</first><last>Chen</last></author>
      <author><first>Yinhan</first><last>Liu</last></author>
      <author><first>Daniel S.</first><last>Weld</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <author><first>Omer</first><last>Levy</last></author>
      <doi>10.1162/tacl_a_00300</doi>
      <abstract>We present SpanBERT, a pre-training method that is designed to better represent and predict spans of text. Our approach extends BERT by (1) masking contiguous random spans, rather than random tokens, and (2) training the span boundary representations to predict the entire content of the masked span, without relying on the individual token representations within it. SpanBERT consistently outperforms <a href="https://en.wikipedia.org/wiki/BERT">BERT</a> and our better-tuned baselines, with substantial gains on span selection tasks such as <a href="https://en.wikipedia.org/wiki/Question_answering">question answering</a> and <a href="https://en.wikipedia.org/wiki/Coreference_resolution">coreference resolution</a>. In particular, with the same training data and model size as BERTlarge, our single <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> obtains 94.6 % and 88.7 % <a href="https://en.wikipedia.org/wiki/F-number">F1</a> on SQuAD 1.1 and 2.0 respectively. We also achieve a new state of the art on the OntoNotes coreference resolution task (79.6 % F1), strong performance on the TACRED relation extraction benchmark, and even gains on GLUE.1</abstract>
      <pages>64–77</pages>
      <url hash="27aaf55c">2020.tacl-1.5</url>
      <bibkey>joshi-etal-2020-spanbert</bibkey>
      <pwccode url="https://github.com/facebookresearch/SpanBERT" additional="true">facebookresearch/SpanBERT</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/cola">CoLA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2012-1">CoNLL-2012</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/hotpotqa">HotpotQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mrpc">MRPC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mrqa-2019">MRQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/natural-questions">Natural Questions</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/newsqa">NewsQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ontonotes-5-0">OntoNotes 5.0</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/qnli">QNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/quora-question-pairs">Quora Question Pairs</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/rte">RTE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/re-tacred">Re-TACRED</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sts-benchmark">STS Benchmark</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/searchqa">SearchQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/superglue">SuperGLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/tacred">TACRED</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/triviaqa">TriviaQA</pwcdataset>
    </paper>
    <paper id="7">
      <title>A Knowledge-Enhanced Pretraining Model for Commonsense Story Generation</title>
      <author><first>Jian</first><last>Guan</last></author>
      <author><first>Fei</first><last>Huang</last></author>
      <author><first>Zhihao</first><last>Zhao</last></author>
      <author><first>Xiaoyan</first><last>Zhu</last></author>
      <author><first>Minlie</first><last>Huang</last></author>
      <doi>10.1162/tacl_a_00302</doi>
      <abstract>Story generation, namely, generating a reasonable story from a leading context, is an important but challenging task. In spite of the success in modeling fluency and local coherence, existing neural language generation models (e.g., GPT-2) still suffer from repetition, logic conflicts, and lack of long-range coherence in generated stories. We conjecture that this is because of the difficulty of associating relevant <a href="https://en.wikipedia.org/wiki/Commonsense_knowledge">commonsense knowledge</a>, understanding the <a href="https://en.wikipedia.org/wiki/Causality">causal relationships</a>, and planning entities and events with proper temporal order. In this paper, we devise a knowledge-enhanced pretraining model for commonsense story generation. We propose to utilize <a href="https://en.wikipedia.org/wiki/Commonsense_knowledge">commonsense knowledge</a> from external knowledge bases to generate reasonable stories. To further capture the causal and temporal dependencies between the sentences in a reasonable story, we use <a href="https://en.wikipedia.org/wiki/Multi-task_learning">multi-task learning</a>, which combines a discriminative objective to distinguish true and fake stories during <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a>. Automatic and manual evaluation shows that our model can generate more reasonable stories than state-of-the-art baselines, particularly in terms of logic and global coherence.</abstract>
      <pages>93–108</pages>
      <url hash="c075234a">2020.tacl-1.7</url>
      <bibkey>guan-etal-2020-knowledge</bibkey>
      <pwccode url="https://github.com/thu-coai/CommonsenseStoryGen" additional="false">thu-coai/CommonsenseStoryGen</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/atomic">ATOMIC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/rocstories">ROCStories</pwcdataset>
    </paper>
    <paper id="8">
      <title>Improving Candidate Generation for Low-resource Cross-lingual Entity Linking</title>
      <author><first>Shuyan</first><last>Zhou</last></author>
      <author><first>Shruti</first><last>Rijhwani</last></author>
      <author><first>John</first><last>Wieting</last></author>
      <author><first>Jaime</first><last>Carbonell</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <doi>10.1162/tacl_a_00303</doi>
      <abstract>Cross-lingual entity linking (XEL) is the task of finding referents in a target-language knowledge base (KB) for mentions extracted from source-language texts. The first step of (X)EL is candidate generation, which retrieves a list of plausible candidate entities from the target-language KB for each mention. Approaches based on resources from <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a> have proven successful in the realm of relatively high-resource languages, but these do not extend well to low-resource languages with few, if any, <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia pages</a>. Recently, transfer learning methods have been shown to reduce the demand for resources in the low-resource languages by utilizing resources in closely related languages, but the performance still lags far behind their high-resource counterparts. In this paper, we first assess the problems faced by current entity candidate generation methods for low-resource XEL, then propose three improvements that (1) reduce the disconnect between entity mentions and KB entries, and (2) improve the robustness of the model to low-resource scenarios. The methods are simple, but effective : We experiment with our approach on seven XEL datasets and find that they yield an average gain of 16.9 % in Top-30 gold candidate recall, compared with state-of-the-art baselines. Our improved <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> also yields an average gain of 7.9 % in in-KB accuracy of end-to-end XEL.1</abstract>
      <pages>109–124</pages>
      <url hash="74d04e8d">2020.tacl-1.8</url>
      <bibkey>zhou-etal-2020-improving-candidate</bibkey>
      <pwccode url="https://github.com/shuyanzhou/pbel_plus" additional="false">shuyanzhou/pbel_plus</pwccode>
    </paper>
    <paper id="11">
      <title>Theoretical Limitations of Self-Attention in Neural Sequence Models</title>
      <author><first>Michael</first><last>Hahn</last></author>
      <doi>10.1162/tacl_a_00306</doi>
      <abstract>Transformers are emerging as the new workhorse of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>, showing great success across tasks. Unlike <a href="https://en.wikipedia.org/wiki/Linear_time-invariant_system">LSTMs</a>, <a href="https://en.wikipedia.org/wiki/Transformer">transformers</a> process input sequences entirely through self-attention. Previous work has suggested that the computational capabilities of self-attention to process hierarchical structures are limited. In this work, we mathematically investigate the computational power of self-attention to model <a href="https://en.wikipedia.org/wiki/Formal_language">formal languages</a>. Across both soft and hard attention, we show strong theoretical limitations of the computational abilities of self-attention, finding that it can not model periodic finite-state languages, nor hierarchical structure, unless the number of layers or heads increases with input length. These limitations seem surprising given the practical success of self-attention and the prominent role assigned to hierarchical structure in <a href="https://en.wikipedia.org/wiki/Linguistics">linguistics</a>, suggesting that <a href="https://en.wikipedia.org/wiki/Natural_language">natural language</a> can be approximated well with models that are too weak for the formal languages typically assumed in theoretical linguistics.</abstract>
      <pages>156–171</pages>
      <url hash="7be349b5">2020.tacl-1.11</url>
      <bibkey>hahn-2020-theoretical</bibkey>
    </paper>
    <paper id="14">
      <title>Acoustic-Prosodic and Lexical Cues to Deception and Trust : Deciphering How People Detect Lies</title>
      <author><first>Xi (Leslie)</first><last>Chen</last></author>
      <author><first>Sarah Ita</first><last>Levitan</last></author>
      <author><first>Michelle</first><last>Levine</last></author>
      <author><first>Marko</first><last>Mandic</last></author>
      <author><first>Julia</first><last>Hirschberg</last></author>
      <doi>10.1162/tacl_a_00311</doi>
      <abstract>Humans rarely perform better than chance at <a href="https://en.wikipedia.org/wiki/Lie_detection">lie detection</a>. To better understand human perception of deception, we created a game framework, LieCatcher, to collect ratings of perceived deception using a large corpus of deceptive and truthful interviews. We analyzed the acoustic-prosodic and linguistic characteristics of language trusted and mistrusted by raters and compared these to characteristics of actual truthful and deceptive language to understand how perception aligns with reality. With this data we built <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> to automatically distinguish <a href="https://en.wikipedia.org/wiki/Trust_(social_science)">trusted</a> from mistrusted speech, achieving an F1 of 66.1 %. We next evaluated whether the strategies raters said they used to discriminate between truthful and deceptive responses were in fact useful. Our results show that, although several prosodic and lexical features were consistently perceived as trustworthy, they were not reliable cues. Also, the <a href="https://en.wikipedia.org/wiki/Strategy">strategies</a> that judges reported using in deception detection were not helpful for the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. Our work sheds light on the nature of trusted language and provides insight into the challenging problem of human deception detection.</abstract>
      <pages>199–214</pages>
      <url hash="d0dfd22b">2020.tacl-1.14</url>
      <bibkey>chen-etal-2020-acoustic</bibkey>
    </paper>
    </volume>
</collection>