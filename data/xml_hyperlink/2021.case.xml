<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.case">
  <volume id="1" ingest-date="2021-07-25">
    <meta>
      <booktitle>Proceedings of the 4th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2021)</booktitle>
      <editor><first>Ali</first><last>Hürriyetoğlu</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>August</month>
      <year>2021</year>
      <url hash="2fadeb05">2021.case-1</url>
    </meta>
    <frontmatter>
      <url hash="4bc787bc">2021.case-1.0</url>
      <bibkey>case-2021-challenges</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2021): Workshop and Shared Task Report<fixed-case>CASE</fixed-case> 2021): Workshop and Shared Task Report</title>
      <author><first>Ali</first><last>Hürriyetoğlu</last></author>
      <author><first>Hristo</first><last>Tanev</last></author>
      <author><first>Vanni</first><last>Zavarella</last></author>
      <author><first>Jakub</first><last>Piskorski</last></author>
      <author><first>Reyyan</first><last>Yeniterzi</last></author>
      <author><first>Osman</first><last>Mutlu</last></author>
      <author><first>Deniz</first><last>Yuret</last></author>
      <author><first>Aline</first><last>Villavicencio</last></author>
      <pages>1–9</pages>
      <abstract>This workshop is the fourth issue of a series of workshops on automatic extraction of socio-political events from news, organized by the Emerging Market Welfare Project, with the support of the Joint Research Centre of the European Commission and with contributions from many other prominent scholars in this field. The purpose of this series of workshops is to foster research and development of reliable, valid, robust, and practical solutions for automatically detecting descriptions of socio-political events, such as <a href="https://en.wikipedia.org/wiki/Protest">protests</a>, <a href="https://en.wikipedia.org/wiki/Riot">riots</a>, <a href="https://en.wikipedia.org/wiki/War">wars</a> and <a href="https://en.wikipedia.org/wiki/War">armed conflicts</a>, in text streams. This year workshop contributors make use of the state-of-the-art NLP technologies, such as <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a>, Word Embeddings and Transformers and cover a wide range of topics from text classification to news bias detection. Around 40 teams have registered and 15 teams contributed to three tasks that are i) multilingual protest news detection detection, ii) fine-grained classification of socio-political events, and iii) discovering Black Lives Matter protest events. The workshop also highlights two keynote and four invited talks about various aspects of creating event data sets and multi- and cross-lingual machine learning in few- and zero-shot settings.</abstract>
      <url hash="730ae684">2021.case-1.1</url>
      <doi>10.18653/v1/2021.case-1.1</doi>
      <bibkey>hurriyetoglu-etal-2021-challenges</bibkey>
    </paper>
    <paper id="2">
      <title>Keynote Abstract : Events on a Global Scale : Towards Language-Agnostic Event Extraction</title>
      <author><first>Elizabeth</first><last>Boschee</last></author>
      <pages>10</pages>
      <abstract>Event extraction is a challenging and exciting task in the world of <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a> &amp; <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. The breadth of events of possible interest, the speed at which surrounding socio-political event contexts evolve, and the complexities involved in generating representative annotated data all contribute to this challenge. One particular dimension of difficulty is the intrinsically global nature of events : many downstream use cases for <a href="https://en.wikipedia.org/wiki/Event_extraction">event extraction</a> involve reporting not just in a few major languages but in a much broader context. The languages of interest for even a fixed <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> may still shift from day to day, e.g. when a disease emerges in an unexpected location. Early <a href="https://en.wikipedia.org/wiki/Methodology">approaches</a> to multi-lingual event extraction (e.g. ACE) relied wholly on supervised data provided in each language of interest. Later approaches leveraged the success of <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> to side-step the issue, simply translating foreign-language content to <a href="https://en.wikipedia.org/wiki/English_language">English</a> and deploying <a href="https://en.wikipedia.org/wiki/English_language">English models</a> on the result (often leaving some significant portion of the original content behind). Most recently, however, the community has begun to shown significant progress applying zero-shot transfer techniques to the problem, developing models using supervised English data but decoding in a foreign language without translation, typically using embedding spaces specifically designed to capture multi-lingual semantic content. In this talk I will discuss multiple dimensions of these promising new approaches and the linguistic representations that underlie them. I will compare them with approaches based on <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> (as well as with models trained using in-language training data, where available), and discuss their strengths and weaknesses in different contexts, including the amount of English / foreign bitext available and the nature of the target event ontology. I will also discuss possible future directions with an eye to improving the quality of <a href="https://en.wikipedia.org/wiki/Event_extraction">event extraction</a> no matter its source around the globe.</abstract>
      <url hash="7e5e8eb6">2021.case-1.2</url>
      <doi>10.18653/v1/2021.case-1.2</doi>
      <bibkey>boschee-2021-keynote</bibkey>
    </paper>
    <paper id="3">
      <title>Keynote Abstract : <a href="https://en.wikipedia.org/wiki/Machine_learning">Machine Learning</a> in Conflict Studies : Reflections on Ethics, Collaboration, and Ongoing Challenges</title>
      <author><first>Kristine</first><last>Eck</last></author>
      <pages>11</pages>
      <abstract>Advances in <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a> are nothing short of revolutionary in their potential to analyze massive amounts of data and in doing so, create new <a href="https://en.wikipedia.org/wiki/Knowledge_base">knowledge bases</a>. But there is a responsibility in wielding the power to analyze these <a href="https://en.wikipedia.org/wiki/Data">data</a> since the public attributes a high degree of confidence to results which are based on <a href="https://en.wikipedia.org/wiki/Big_data">big datasets</a>. In this keynote, I will first address our ethical imperative as scholars to get it right. This imperative relates not only to model precision but also to the quality of the underlying data, and to whether the <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> inadvertently reproduce or obscure political biases in the source material. In considering the ethical imperative to get it right, it is also important to define what is right : what is considered an acceptable threshold for <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> success needs to be understood in light of the project’s objectives. I then reflect on the different topics and data which are sourced in this field. Much of the existing research has focused on identifying <a href="https://en.wikipedia.org/wiki/Conflict_(process)">conflict events</a> (e.g. battles), but scholars are also increasingly turning to ML approaches to address other facets of the conflict environment. Conflict event extraction has long been a challenge for the natural language processing (NLP) community because it requires sophisticated methods for defining <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">event ontologies</a>, creating language resources, and developing algorithmic approaches. NLP machine-learning tools are ill-adapted to the complex, often messy, and diverse data generated during conflicts. Relative to other types of NLP text corpora, conflicts tend to generate less textual data, and texts are generated non-systematically. Conflict-related texts are often lexically idiosyncratic and tend to be written differently across actors, periods, and conflicts. Event definition and <a href="https://en.wikipedia.org/wiki/Adjudication">adjudication</a> present tough challenges in the context of conflict corpora. Topics which rely on other types of <a href="https://en.wikipedia.org/wiki/Data">data</a> may be better-suited to NLP and machine learning methods. For example, <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> and other social media data lend themselves well to studying <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a>, <a href="https://en.wikipedia.org/wiki/Public_opinion">public opinion</a>, <a href="https://en.wikipedia.org/wiki/Social_polarization">social polarization</a>, or discursive aspects of conflictual environments. Likewise, government-produced policy documents have typically been analyzed with historical, qualitative methods but their standardized formats and quantity suggest that ML methods can provide new traction. ML approaches may also allow scholars to exploit <a href="https://en.wikipedia.org/wiki/Primary_source">local sources</a> and <a href="https://en.wikipedia.org/wiki/Multilingualism">multi-language sources</a> to a greater degree than has been possible. Many challenges remain, and these are best addressed in collaborative projects which build on interdisciplinary expertise. Classification projects need to be anchored in the theoretical interests of scholars of <a href="https://en.wikipedia.org/wiki/Political_violence">political violence</a> if the data they produce are to be put to analytical use. There are few <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontologies</a> for <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> that adequately reflect conflict researchers’ interests, which highlights the need for conceptual as well as technical development.</abstract>
      <url hash="25e1115b">2021.case-1.3</url>
      <doi>10.18653/v1/2021.case-1.3</doi>
      <bibkey>eck-2021-keynote</bibkey>
    </paper>
    <paper id="9">
      <title>Extracting Events from Industrial Incident Reports</title>
      <author><first>Nitin</first><last>Ramrakhiyani</last></author>
      <author><first>Swapnil</first><last>Hingmire</last></author>
      <author><first>Sangameshwar</first><last>Patil</last></author>
      <author><first>Alok</first><last>Kumar</last></author>
      <author><first>Girish</first><last>Palshikar</last></author>
      <pages>58–67</pages>
      <abstract>Incidents in industries have huge social and political impact and minimizing the consequent damage has been a high priority. However, automated analysis of repositories of incident reports has remained a challenge. In this paper, we focus on automatically extracting <a href="https://en.wikipedia.org/wiki/Event_(probability_theory)">events</a> from <a href="https://en.wikipedia.org/wiki/Incident_report">incident reports</a>. Due to absence of event annotated datasets for industrial incidents we employ a transfer learning based approach which is shown to outperform several baselines. We further provide detailed analysis regarding effect of increase in pre-training data and provide explainability of why pre-training improves the performance.</abstract>
      <url hash="1ce6ac61">2021.case-1.9</url>
      <doi>10.18653/v1/2021.case-1.9</doi>
      <bibkey>ramrakhiyani-etal-2021-extracting</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/nombank">NomBank</pwcdataset>
    </paper>
    <paper id="11">
      <title>Multilingual Protest News Detection-Shared Task 1, CASE 2021<fixed-case>CASE</fixed-case> 2021</title>
      <author><first>Ali</first><last>Hürriyetoğlu</last></author>
      <author><first>Osman</first><last>Mutlu</last></author>
      <author><first>Erdem</first><last>Yörük</last></author>
      <author><first>Farhana Ferdousi</first><last>Liza</last></author>
      <author><first>Ritesh</first><last>Kumar</last></author>
      <author><first>Shyam</first><last>Ratan</last></author>
      <pages>79–91</pages>
      <abstract>Benchmarking state-of-the-art text classification and information extraction systems in multilingual, cross-lingual, few-shot, and zero-shot settings for socio-political event information collection is achieved in the scope of the shared task Socio-political and Crisis Events Detection at the workshop CASE @ ACL-IJCNLP 2021. Socio-political event data is utilized for national and international policy- and decision-making. Therefore, the reliability and validity of these <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> are of the utmost importance. We split the shared task into three parts to address the three aspects of <a href="https://en.wikipedia.org/wiki/Data_collection">data collection</a> (Task 1), fine-grained semantic classification (Task 2), and <a href="https://en.wikipedia.org/wiki/Evaluation">evaluation</a> (Task 3). Task 1, which is the focus of this report, is on multilingual protest news detection and comprises four subtasks that are document classification (subtask 1), sentence classification (subtask 2), event sentence coreference identification (subtask 3), and event extraction (subtask 4). All subtasks had <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a>, and <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a> for both training and evaluation data. Data in <a href="https://en.wikipedia.org/wiki/Hindi">Hindi language</a> was available only for the evaluation of subtask 1. The majority of the submissions, which are 238 in total, are created using multi- and cross-lingual approaches. Best scores are above 77.27 F1-macro for subtask 1, above 85.32 F1-macro for subtask 2, above 84.23 CoNLL 2012 average score for subtask 3, and above 66.20 F1-macro for subtask 4 in all evaluation settings.</abstract>
      <url hash="1dfe2342">2021.case-1.11</url>
      <doi>10.18653/v1/2021.case-1.11</doi>
      <bibkey>hurriyetoglu-etal-2021-multilingual</bibkey>
    </paper>
    <paper id="13">
      <title>IIITT at CASE 2021 Task 1 : Leveraging Pretrained Language Models for Multilingual Protest Detection<fixed-case>IIITT</fixed-case> at <fixed-case>CASE</fixed-case> 2021 Task 1: Leveraging Pretrained Language Models for Multilingual Protest Detection</title>
      <author><first>Pawan</first><last>Kalyan</last></author>
      <author><first>Duddukunta</first><last>Reddy</last></author>
      <author><first>Adeep</first><last>Hande</last></author>
      <author><first>Ruba</first><last>Priyadharshini</last></author>
      <author><first>Ratnasingam</first><last>Sakuntharaj</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <pages>98–104</pages>
      <abstract>In a world abounding in constant protests resulting from events like a global pandemic, <a href="https://en.wikipedia.org/wiki/Climate_change">climate change</a>, religious or political conflicts, there has always been a need to detect events / protests before getting amplified by <a href="https://en.wikipedia.org/wiki/News_media">news media</a> or <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. This paper demonstrates our work on the sentence classification subtask of multilingual protest detection in CASE@ACL-IJCNLP 2021. We approached this task by employing various multilingual pre-trained transformer models to classify if any sentence contains information about an event that has transpired or not. We performed soft voting over the <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a>, achieving the best results among the <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a>, accomplishing a macro F1-Score of 0.8291, 0.7578, and 0.7951 in <a href="https://en.wikipedia.org/wiki/English_language">English</a>, Spanish, and <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a>, respectively.</abstract>
      <url hash="548f4fea">2021.case-1.13</url>
      <doi>10.18653/v1/2021.case-1.13</doi>
      <bibkey>kalyan-etal-2021-iiitt</bibkey>
      <pwccode url="https://github.com/adeeph/case-2021-task-1" additional="false">adeeph/case-2021-task-1</pwccode>
    </paper>
    <paper id="14">
      <title>NUS-IDS at CASE 2021 Task 1 : Improving Multilingual Event Sentence Coreference Identification With Linguistic Information<fixed-case>NUS</fixed-case>-<fixed-case>IDS</fixed-case> at <fixed-case>CASE</fixed-case> 2021 Task 1: Improving Multilingual Event Sentence Coreference Identification With Linguistic Information</title>
      <author><first>Fiona Anting</first><last>Tan</last></author>
      <author><first>Sujatha Das</first><last>Gollapalli</last></author>
      <author><first>See-Kiong</first><last>Ng</last></author>
      <pages>105–112</pages>
      <abstract>Event Sentence Coreference Identification (ESCI) aims to cluster event sentences that refer to the same event together for <a href="https://en.wikipedia.org/wiki/Information_extraction">information extraction</a>. We describe our ESCI solution developed for the ACL-CASE 2021 shared tasks on the detection and classification of socio-political and crisis event information in a multilingual setting. For a given article, our proposed pipeline comprises of an accurate sentence pair classifier that identifies coreferent sentence pairs and subsequently uses these predicted probabilities to cluster sentences into groups. Sentence pair representations are constructed from fine-tuned BERT embeddings plus POS embeddings fed through a BiLSTM model, and combined with linguistic-based lexical and semantic similarities between sentences. Our best <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> ranked 2nd, 1st and 2nd and obtained CoNLL F1 scores of 81.20 %, 93.03 %, 83.15 % for the English, Portuguese and Spanish test sets respectively in the <a href="https://en.wikipedia.org/wiki/American_Lacrosse_League">ACL-CASE 2021 competition</a>.</abstract>
      <url hash="39a44101">2021.case-1.14</url>
      <doi>10.18653/v1/2021.case-1.14</doi>
      <bibkey>tan-etal-2021-nus</bibkey>
      <pwccode url="https://github.com/nus-ids/eventsentencecoref" additional="false">nus-ids/eventsentencecoref</pwccode>
    </paper>
    <paper id="18">
      <title>IBM MNLP IE at CASE 2021 Task 1 : Multigranular and Multilingual Event Detection on Protest News<fixed-case>IBM</fixed-case> <fixed-case>MNLP</fixed-case> <fixed-case>IE</fixed-case> at <fixed-case>CASE</fixed-case> 2021 Task 1: Multigranular and Multilingual Event Detection on Protest News</title>
      <author><first>Parul</first><last>Awasthy</last></author>
      <author><first>Jian</first><last>Ni</last></author>
      <author><first>Ken</first><last>Barker</last></author>
      <author><first>Radu</first><last>Florian</last></author>
      <pages>138–146</pages>
      <abstract>In this paper, we present the event detection models and systems we have developed for Multilingual Protest News Detection-Shared Task 1 at CASE 2021. The shared task has 4 subtasks which cover event detection at different granularity levels (from document level to token level) and across multiple languages (English, <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a>, <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a> and Spanish). To handle data from multiple languages, we use a multilingual transformer-based language model (XLM-R) as the input text encoder. We apply a variety of techniques and build several transformer-based models that perform consistently well across all the subtasks and languages. Our <a href="https://en.wikipedia.org/wiki/System">systems</a> achieve an average <a href="https://en.wikipedia.org/wiki/F1_(classification)">F_1 score</a> of 81.2. Out of thirteen subtask-language tracks, our submissions rank 1st in nine and 2nd in four tracks.</abstract>
      <url hash="bf723387">2021.case-1.18</url>
      <doi>10.18653/v1/2021.case-1.18</doi>
      <bibkey>awasthy-etal-2021-ibm</bibkey>
    </paper>
    <paper id="19">
      <title>ALEM at CASE 2021 Task 1 : Multilingual Text Classification on News Articles<fixed-case>ALEM</fixed-case> at <fixed-case>CASE</fixed-case> 2021 Task 1: Multilingual Text Classification on News Articles</title>
      <author><first>Alaeddin</first><last>Gürel</last></author>
      <author><first>Emre</first><last>Emin</last></author>
      <pages>147–151</pages>
      <abstract>We participated CASE shared task in ACL-IJCNLP 2021. This paper is a summary of our experiments and ideas about this shared task. For each subtask we shared our <a href="https://en.wikipedia.org/wiki/Methodology">approach</a>, successful and failed methods and our thoughts about them. We submit our results once for every subtask, except for subtask3, in task submission system and present scores based on our validation set formed from given training samples in this paper. Techniques and models we mentioned includes BERT, Multilingual BERT, <a href="https://en.wikipedia.org/wiki/Oversampling">oversampling</a>, <a href="https://en.wikipedia.org/wiki/Undersampling">undersampling</a>, <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a> and their implications with each other. Most of the experiments we came up with were not completed, as time did not permit, but we share them here as we plan to do them as suggested in the future work part of document.</abstract>
      <url hash="99afb34c">2021.case-1.19</url>
      <doi>10.18653/v1/2021.case-1.19</doi>
      <bibkey>gurel-emin-2021-alem</bibkey>
    </paper>
    <paper id="21">
      <title>AMU-EURANOVA at CASE 2021 Task 1 : Assessing the stability of multilingual BERT<fixed-case>AMU</fixed-case>-<fixed-case>EURANOVA</fixed-case> at <fixed-case>CASE</fixed-case> 2021 Task 1: Assessing the stability of multilingual <fixed-case>BERT</fixed-case></title>
      <author><first>Léo</first><last>Bouscarrat</last></author>
      <author><first>Antoine</first><last>Bonnefoy</last></author>
      <author><first>Cécile</first><last>Capponi</last></author>
      <author><first>Carlos</first><last>Ramisch</last></author>
      <pages>161–170</pages>
      <abstract>This paper explains our participation in task 1 of the CASE 2021 shared task. This <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> is about multilingual event extraction from <a href="https://en.wikipedia.org/wiki/News">news</a>. We focused on sub-task 4, event information extraction. This sub-task has a small training dataset and we fine-tuned a multilingual BERT to solve this <a href="https://en.wikipedia.org/wiki/Task_(computing)">sub-task</a>. We studied the instability problem on the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and tried to mitigate it.</abstract>
      <url hash="54d722de">2021.case-1.21</url>
      <doi>10.18653/v1/2021.case-1.21</doi>
      <bibkey>bouscarrat-etal-2021-amu</bibkey>
      <pwccode url="https://github.com/euranova/AMU-EURANOVA-CASE-2021" additional="false">euranova/AMU-EURANOVA-CASE-2021</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2002">CoNLL 2002</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
    </paper>
    <paper id="22">
      <title>Team DaDeFrNi at CASE 2021 Task 1 : Document and Sentence Classification for Protest Event Detection<fixed-case>D</fixed-case>a<fixed-case>D</fixed-case>e<fixed-case>F</fixed-case>r<fixed-case>N</fixed-case>i” at <fixed-case>CASE</fixed-case> 2021 Task 1: Document and Sentence Classification for Protest Event Detection</title>
      <author><first>Francesco</first><last>Re</last></author>
      <author><first>Daniel</first><last>Vegh</last></author>
      <author><first>Dennis</first><last>Atzenhofer</last></author>
      <author><first>Niklas</first><last>Stoehr</last></author>
      <pages>171–178</pages>
      <abstract>This paper accompanies our top-performing submission to the CASE 2021 shared task, which is hosted at the workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text. Subtasks 1 and 2 of Task 1 concern the classification of <a href="https://en.wikipedia.org/wiki/Article_(publishing)">newspaper articles</a> and sentences into conflict versus not conflict-related in four different languages. Our model performs competitively in both subtasks (up to 0.8662 macro F1), obtaining the highest score of all contributions for subtask 1 on Hindi articles (0.7877 macro F1). We describe all experiments conducted with the XLM-RoBERTa (XLM-R) model and report results obtained in each binary classification task. We propose supplementing the original training data with additional data on political conflict events. In addition, we provide an analysis of <a href="https://en.wikipedia.org/wiki/Grammatical_number">unigram probability estimates</a> and <a href="https://en.wikipedia.org/wiki/Geographic_data_and_information">geospatial references</a> contained within the original training corpus.</abstract>
      <url hash="b2261046">2021.case-1.22</url>
      <doi>10.18653/v1/2021.case-1.22</doi>
      <bibkey>re-etal-2021-team</bibkey>
    </paper>
    <paper id="23">
      <title>Fine-grained Event Classification in News-like Text Snippets-Shared Task 2, CASE 2021<fixed-case>CASE</fixed-case> 2021</title>
      <author><first>Jacek</first><last>Haneczok</last></author>
      <author><first>Guillaume</first><last>Jacquet</last></author>
      <author><first>Jakub</first><last>Piskorski</last></author>
      <author><first>Nicolas</first><last>Stefanovitch</last></author>
      <pages>179–192</pages>
      <abstract>This paper describes the Shared Task on Fine-grained Event Classification in News-like Text Snippets. The Shared Task is divided into three sub-tasks : (a) classification of text snippets reporting socio-political events (25 classes) for which vast amount of training data exists, although exhibiting different structure and style vis-a-vis test data, (b) enhancement to a generalized zero-shot learning problem, where 3 additional event types were introduced in advance, but without any training data (‘unseen’ classes), and (c) further extension, which introduced 2 additional event types, announced shortly prior to the evaluation phase. The reported Shared Task focuses on classification of events in English texts and is organized as part of the Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2021), co-located with the ACL-IJCNLP 2021 Conference. Four teams participated in the task. Best performing systems for the three aforementioned sub-tasks achieved 83.9 %, 79.7 % and 77.1 % weighted F1 scores respectively.</abstract>
      <url hash="70dd2284">2021.case-1.23</url>
      <doi>10.18653/v1/2021.case-1.23</doi>
      <bibkey>haneczok-etal-2021-fine</bibkey>
    </paper>
    <paper id="25">
      <title>CASE 2021 Task 2 : Zero-Shot Classification of Fine-Grained Sociopolitical Events with Transformer Models<fixed-case>CASE</fixed-case> 2021 Task 2: Zero-Shot Classification of Fine-Grained Sociopolitical Events with Transformer Models</title>
      <author><first>Benjamin J.</first><last>Radford</last></author>
      <pages>203–207</pages>
      <abstract>We introduce a <a href="https://en.wikipedia.org/wiki/Methodology">method</a> for the classification of texts into fine-grained categories of sociopolitical events. This particular method is responsive to all three Subtasks of Task 2, Fine-Grained Classification of Socio-Political Events, introduced at the CASE workshop of ACL-IJCNLP 2021. We frame Task 2 as textual entailment : given an input text and a candidate event class (query), the model predicts whether the text describes an event of the given type. The <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> is able to correctly classify in-sample event types with an average <a href="https://en.wikipedia.org/wiki/F-number">F1-score</a> of 0.74 but struggles with some out-of-sample event types. Despite this, the <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> shows promise for the zero-shot identification of certain sociopolitical events by achieving an F1-score of 0.52 on one wholly out-of-sample event class.</abstract>
      <url hash="4bf88429">2021.case-1.25</url>
      <doi>10.18653/v1/2021.case-1.25</doi>
      <bibkey>radford-2021-case</bibkey>
      <revision id="1" href="2021.case-1.25v1" hash="089355ad" />
      <revision id="2" href="2021.case-1.25v2" hash="4bf88429" date="2021-08-12">Corrected a typo in Table 2</revision>
    </paper>
    </volume>
</collection>