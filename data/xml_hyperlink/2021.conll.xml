<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.conll">
  <volume id="1" ingest-date="2021-10-28">
    <meta>
      <booktitle>Proceedings of the 25th Conference on Computational Natural Language Learning</booktitle>
      <editor><first>Arianna</first><last>Bisazza</last></editor>
      <editor><first>Omri</first><last>Abend</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>November</month>
      <year>2021</year>
    </meta>
    <frontmatter>
      <url hash="a00cd227">2021.conll-1.0</url>
      <bibkey>conll-2021-natural</bibkey>
    </frontmatter>
    <paper id="1">
      <title>It’s our fault ! : Insights Into Users’ Understanding and Interaction With an Explanatory Collaborative Dialog System</title>
      <author><first>Katharina</first><last>Weitz</last></author>
      <author><first>Lindsey</first><last>Vanderlyn</last></author>
      <author><first>Ngoc Thang</first><last>Vu</last></author>
      <author><first>Elisabeth</first><last>André</last></author>
      <pages>1–16</pages>
      <abstract>Human-AI collaboration, a long standing goal in <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">AI</a>, refers to a partnership where a human and artificial intelligence work together towards a shared goal. Collaborative dialog allows human-AI teams to communicate and leverage strengths from both partners. To design collaborative dialog systems, it is important to understand what mental models users form about their AI-dialog partners, however, how users perceive these <a href="https://en.wikipedia.org/wiki/System">systems</a> is not fully understood. In this study, we designed a novel, collaborative, communication-based puzzle game and explanatory dialog system. We created a public corpus from 117 conversations and post-surveys and used this to analyze what <a href="https://en.wikipedia.org/wiki/Mental_model">mental models</a> users formed. Key takeaways include : Even when users were not engaged in the <a href="https://en.wikipedia.org/wiki/Game">game</a>, they perceived the AI-dialog partner as intelligent and likeable, implying they saw it as a partner separate from the game. This was further supported by users often overestimating the <a href="https://en.wikipedia.org/wiki/System">system</a>’s abilities and projecting human-like attributes which led to miscommunications. We conclude that creating shared mental models between users and <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">AI systems</a> is important to achieving successful dialogs. We propose that our insights on mental models and miscommunication, the <a href="https://en.wikipedia.org/wiki/Game">game</a>, and our <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> provide useful tools for designing collaborative dialog systems.</abstract>
      <url hash="25e22930">2021.conll-1.1</url>
      <bibkey>weitz-etal-2021-fault</bibkey>
      <doi>10.18653/v1/2021.conll-1.1</doi>
    </paper>
    <paper id="5">
      <title>On <a href="https://en.wikipedia.org/wiki/Language_model">Language Models</a> for Creoles</title>
      <author><first>Heather</first><last>Lent</last></author>
      <author><first>Emanuele</first><last>Bugliarello</last></author>
      <author><first>Miryam</first><last>de Lhoneux</last></author>
      <author><first>Chen</first><last>Qiu</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>58–71</pages>
      <abstract>Creole languages such as <a href="https://en.wikipedia.org/wiki/Nigerian_Pidgin_English">Nigerian Pidgin English</a> and <a href="https://en.wikipedia.org/wiki/Haitian_Creole">Haitian Creole</a> are under-resourced and largely ignored in the NLP literature. Creoles typically result from the fusion of a foreign language with multiple local languages, and what grammatical and lexical features are transferred to the <a href="https://en.wikipedia.org/wiki/Creole_language">creole</a> is a complex process. While <a href="https://en.wikipedia.org/wiki/Creole_language">creoles</a> are generally stable, the prominence of some features may be much stronger with certain demographics or in some linguistic situations. This paper makes several contributions : We collect existing corpora and release models for <a href="https://en.wikipedia.org/wiki/Haitian_Creole">Haitian Creole</a>, <a href="https://en.wikipedia.org/wiki/Nigerian_Pidgin_English">Nigerian Pidgin English</a>, and <a href="https://en.wikipedia.org/wiki/Singaporean_English">Singaporean Colloquial English</a>. We evaluate these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> on intrinsic and extrinsic tasks. Motivated by the above literature, we compare standard language models with distributionally robust ones and find that, somewhat surprisingly, the standard language models are superior to the distributionally robust ones. We investigate whether this is an effect of <a href="https://en.wikipedia.org/wiki/Parameterized_complexity">over-parameterization</a> or relative distributional stability, and find that the difference persists in the absence of <a href="https://en.wikipedia.org/wiki/Parameterized_complexity">over-parameterization</a>, and that drift is limited, confirming the relative stability of <a href="https://en.wikipedia.org/wiki/Creole_language">creole languages</a>.</abstract>
      <url hash="32c6b62b">2021.conll-1.5</url>
      <bibkey>lent-etal-2021-language</bibkey>
      <doi>10.18653/v1/2021.conll-1.5</doi>
      <pwccode url="https://github.com/hclent/creole-dro" additional="false">hclent/creole-dro</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wilds">Wilds</pwcdataset>
    </paper>
    <paper id="11">
      <title>Enriching Language Models with Visually-grounded Word Vectors and the Lancaster Sensorimotor Norms<fixed-case>L</fixed-case>ancaster Sensorimotor Norms</title>
      <author><first>Casey</first><last>Kennington</last></author>
      <pages>148–157</pages>
      <abstract>Language models are trained only on text despite the fact that humans learn their first language in a highly interactive and multimodal environment where the first set of learned words are largely concrete, denoting physical entities and embodied states. To enrich language models with some of this missing experience, we leverage two sources of information : (1) the Lancaster Sensorimotor norms, which provide ratings (means and standard deviations) for over 40,000 English words along several dimensions of embodiment, and which capture the extent to which something is experienced across 11 different sensory modalities, and (2) vectors from coefficients of binary classifiers trained on images for the BERT vocabulary. We pre-trained the ELECTRA model and fine-tuned the RoBERTa model with these two sources of information then evaluate using the established GLUE benchmark and the Visual Dialog benchmark. We find that enriching <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> with the Lancaster norms and image vectors improves results in both tasks, with some implications for robust <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> that capture holistic linguistic meaning in a language learning context.</abstract>
      <url hash="18495466">2021.conll-1.11</url>
      <bibkey>kennington-2021-enriching</bibkey>
      <doi>10.18653/v1/2021.conll-1.11</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptual-captions">Conceptual Captions</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visdial">VisDial</pwcdataset>
    </paper>
    <paper id="15">
      <title>Counterfactual Interventions Reveal the Causal Effect of Relative Clause Representations on Agreement Prediction</title>
      <author><first>Shauli</first><last>Ravfogel</last></author>
      <author><first>Grusha</first><last>Prasad</last></author>
      <author><first>Tal</first><last>Linzen</last></author>
      <author><first>Yoav</first><last>Goldberg</last></author>
      <pages>194–209</pages>
      <abstract>When language models process syntactically complex sentences, do they use their representations of syntax in a manner that is consistent with the grammar of the language? We propose AlterRep, an intervention-based method to address this question. For any linguistic feature of a given sentence, AlterRep generates counterfactual representations by altering how the <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">feature</a> is encoded, while leaving in- tact all other aspects of the original <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">representation</a>. By measuring the change in a <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a>’s word prediction behavior when these counterfactual representations are substituted for the original ones, we can draw conclusions about the causal effect of the linguistic feature in question on the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a>’s behavior. We apply this method to study how BERT models of different sizes process relative clauses (RCs). We find that BERT variants use RC boundary information during <a href="https://en.wikipedia.org/wiki/Word_prediction">word prediction</a> in a manner that is consistent with the rules of English grammar ; this RC boundary information generalizes to a considerable extent across different RC types, suggesting that BERT represents RCs as an abstract linguistic category.</abstract>
      <url hash="bcd5f605">2021.conll-1.15</url>
      <bibkey>ravfogel-etal-2021-counterfactual</bibkey>
      <doi>10.18653/v1/2021.conll-1.15</doi>
    </paper>
    <paper id="16">
      <title>Who’s on First? : Probing the Learning and Representation Capabilities of Language Models on Deterministic Closed Domains</title>
      <author><first>David</first><last>Demeter</last></author>
      <author><first>Doug</first><last>Downey</last></author>
      <pages>210–222</pages>
      <abstract>The capabilities of today’s <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing systems</a> are typically evaluated using large datasets of curated questions and answers. While these are critical benchmarks of progress, they also suffer from weakness due to <a href="https://en.wikipedia.org/wiki/Distribution_(mathematics)">artificial distributions</a> and <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">incomplete knowledge</a>. Artifacts arising from artificial distributions can overstate <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> performance, while incomplete knowledge limits fine-grained analysis. In this work, we introduce a complementary benchmarking approach based on SimPlified Language Activity Traces (SPLAT). SPLATs are corpora of language encodings of activity in some closed domain (we study traces from chess and baseball games in this work). SPLAT datasets use naturally-arising distributions, allow the generation of question-answer pairs at scale, and afford complete knowledge in their closed domains. We show that <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> of three different architectures can answer questions about <a href="https://en.wikipedia.org/wiki/State_(polity)">world states</a> using only verb-like encodings of activity. Our approach is extensible to new <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> and additional question-answering tasks.</abstract>
      <url hash="51efaf81">2021.conll-1.16</url>
      <bibkey>demeter-downey-2021-whos</bibkey>
      <doi>10.18653/v1/2021.conll-1.16</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/coqa">CoQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/babi-1">bAbI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/decanlp">decaNLP</pwcdataset>
    </paper>
    <paper id="17">
      <title>Data Augmentation of Incorporating Real Error Patterns and Linguistic Knowledge for Grammatical Error Correction</title>
      <author><first>Xia</first><last>Li</last></author>
      <author><first>Junyi</first><last>He</last></author>
      <pages>223–233</pages>
      <abstract>Data augmentation aims at expanding training data with clean text using noising schemes to improve the performance of <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">grammatical error correction (GEC)</a>. In practice, there are a great number of real error patterns in the manually annotated training data. We argue that these real error patterns can be introduced into clean text to effectively generate more real and high quality synthetic data, which is not fully explored by previous studies. Moreover, we also find that linguistic knowledge can be incorporated into <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a> for generating more representative and more diverse <a href="https://en.wikipedia.org/wiki/Synthetic_data">synthetic data</a>. In this paper, we propose a novel data augmentation method that fully considers the real error patterns and the linguistic knowledge for the GEC task. We conduct extensive experiments on public data sets and the experimental results show that our method outperforms several strong baselines with far less external unlabeled clean text data, highlighting its extraordinary effectiveness in the GEC task that lacks large-scale labeled training data.</abstract>
      <url hash="548cf5a9">2021.conll-1.17</url>
      <bibkey>li-he-2021-data</bibkey>
      <doi>10.18653/v1/2021.conll-1.17</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/billion-word-benchmark">Billion Word Benchmark</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/fce">FCE</pwcdataset>
    </paper>
    <paper id="19">
      <title>A Multilingual Benchmark for Probing Negation-Awareness with Minimal Pairs</title>
      <author><first>Mareike</first><last>Hartmann</last></author>
      <author><first>Miryam</first><last>de Lhoneux</last></author>
      <author><first>Daniel</first><last>Hershcovich</last></author>
      <author><first>Yova</first><last>Kementchedjhieva</last></author>
      <author><first>Lukas</first><last>Nielsen</last></author>
      <author><first>Chen</first><last>Qiu</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>244–257</pages>
      <abstract>Negation is one of the most fundamental concepts in human cognition and language, and several natural language inference (NLI) probes have been designed to investigate pretrained language models’ ability to detect and reason with <a href="https://en.wikipedia.org/wiki/Affirmation_and_negation">negation</a>. However, the existing probing datasets are limited to English only, and do not enable controlled probing of performance in the absence or presence of <a href="https://en.wikipedia.org/wiki/Negation">negation</a>. In response, we present a multilingual (English, Bulgarian, German, French and Chinese) benchmark collection of NLI examples that are grammatical and correctly labeled, as a result of manual inspection and reformulation. We use the benchmark to probe the negation-awareness of multilingual language models and find that models that correctly predict examples with negation cues, often fail to correctly predict their counter-examples without negation cues, even when the cues are irrelevant for semantic inference.</abstract>
      <url hash="b5dee3ad">2021.conll-1.19</url>
      <bibkey>hartmann-etal-2021-multilingual</bibkey>
      <doi>10.18653/v1/2021.conll-1.19</doi>
      <pwccode url="https://github.com/mahartmann/negationminpairs" additional="false">mahartmann/negationminpairs</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="23">
      <title>A Coarse-to-Fine Labeling Framework for Joint Word Segmentation, POS Tagging, and Constituent Parsing<fixed-case>POS</fixed-case> Tagging, and Constituent Parsing</title>
      <author><first>Yang</first><last>Hou</last></author>
      <author><first>Houquan</first><last>Zhou</last></author>
      <author><first>Zhenghua</first><last>Li</last></author>
      <author><first>Yu</first><last>Zhang</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <author><first>Zhefeng</first><last>Wang</last></author>
      <author><first>Baoxing</first><last>Huai</last></author>
      <author><first>Nicholas Jing</first><last>Yuan</last></author>
      <pages>290–299</pages>
      <abstract>The most straightforward approach to joint word segmentation (WS), part-of-speech (POS) tagging, and constituent parsing is converting a word-level tree into a char-level tree, which, however, leads to two severe challenges. First, a larger label set (e.g.,   600) and longer inputs both increase computational costs. Second, it is difficult to rule out illegal trees containing conflicting production rules, which is important for reliable model evaluation. If a POS tag (like VV) is above a phrase tag (like VP) in the output tree, it becomes quite complex to decide word boundaries. To deal with both challenges, this work proposes a two-stage coarse-to-fine labeling framework for joint WS-POS-PAR. In the coarse labeling stage, the joint model outputs a bracketed tree, in which each node corresponds to one of four labels (i.e., phrase, subphrase, word, subword). The <a href="https://en.wikipedia.org/wiki/Tree_(data_structure)">tree</a> is guaranteed to be legal via constrained CKY decoding. In the fine labeling stage, the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> expands each coarse label into a final label (such as VP, VP *, VV, VV *). Experiments on Chinese Penn Treebank 5.1 and 7.0 show that our joint model consistently outperforms the <a href="https://en.wikipedia.org/wiki/Pipeline_(software)">pipeline approach</a> on both settings of <a href="https://en.wikipedia.org/wiki/W/o">w/o</a> and <a href="https://en.wikipedia.org/wiki/BERT">w/ BERT</a>, and achieves new state-of-the-art performance.</abstract>
      <url hash="c09860d3">2021.conll-1.23</url>
      <bibkey>hou-etal-2021-coarse</bibkey>
      <doi>10.18653/v1/2021.conll-1.23</doi>
      <pwccode url="https://github.com/ironsword666/jointparser" additional="false">ironsword666/jointparser</pwccode>
    </paper>
    <paper id="24">
      <title>Understanding the Extent to which Content Quality Metrics Measure the Information Quality of Summaries</title>
      <author><first>Daniel</first><last>Deutsch</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>300–309</pages>
      <abstract>Reference-based metrics such as <a href="https://en.wikipedia.org/wiki/ROUGE_(metric)">ROUGE</a> or BERTScore evaluate the content quality of a summary by comparing the summary to a reference. Ideally, this comparison should measure the summary’s information quality by calculating how much information the summaries have in common. In this work, we analyze the token alignments used by ROUGE and BERTScore to compare summaries and argue that their scores largely can not be interpreted as measuring information overlap. Rather, they are better estimates of the extent to which the summaries discuss the same topics. Further, we provide evidence that this result holds true for many other summarization evaluation metrics. The consequence of this result is that the most frequently used summarization evaluation metrics do not align with the community’s research goal, to generate summaries with high-quality information. However, we conclude by demonstrating that a recently proposed <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metric</a>, QAEval, which scores summaries using <a href="https://en.wikipedia.org/wiki/Question_answering">question-answering</a>, appears to better capture <a href="https://en.wikipedia.org/wiki/Information_quality">information quality</a> than current evaluations, highlighting a direction for future research.</abstract>
      <url hash="c39f1355">2021.conll-1.24</url>
      <bibkey>deutsch-roth-2021-understanding</bibkey>
      <doi>10.18653/v1/2021.conll-1.24</doi>
    </paper>
    <paper id="25">
      <title>Summary-Source Proposition-level Alignment : Task, Datasets and Supervised Baseline</title>
      <author><first>Ori</first><last>Ernst</last></author>
      <author><first>Ori</first><last>Shapira</last></author>
      <author><first>Ramakanth</first><last>Pasunuru</last></author>
      <author><first>Michael</first><last>Lepioshkin</last></author>
      <author><first>Jacob</first><last>Goldberger</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <author><first>Ido</first><last>Dagan</last></author>
      <pages>310–322</pages>
      <abstract>Aligning sentences in a reference summary with their counterparts in source documents was shown as a useful auxiliary summarization task, notably for generating training data for <a href="https://en.wikipedia.org/wiki/Salience_(neuroscience)">salience detection</a>. Despite its assessed utility, the alignment step was mostly approached with heuristic unsupervised methods, typically ROUGE-based, and was never independently optimized or evaluated. In this paper, we propose establishing summary-source alignment as an explicit task, while introducing two major novelties : (1) applying it at the more accurate proposition span level, and (2) approaching it as a supervised classification task. To that end, we created a novel <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training dataset</a> for proposition-level alignment, derived automatically from available summarization evaluation data. In addition, we crowdsourced dev and test datasets, enabling model development and proper evaluation. Utilizing these data, we present a supervised proposition alignment baseline model, showing improved alignment-quality over the unsupervised approach.</abstract>
      <url hash="e9ca9b2e">2021.conll-1.25</url>
      <bibkey>ernst-etal-2021-summary</bibkey>
      <doi>10.18653/v1/2021.conll-1.25</doi>
      <pwccode url="https://github.com/oriern/SuperPAL" additional="false">oriern/SuperPAL</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/multi-news">Multi-News</pwcdataset>
    </paper>
    <paper id="27">
      <title>Imposing Relation Structure in Language-Model Embeddings Using Contrastive Learning</title>
      <author><first>Christos</first><last>Theodoropoulos</last></author>
      <author><first>James</first><last>Henderson</last></author>
      <author><first>Andrei Catalin</first><last>Coman</last></author>
      <author><first>Marie-Francine</first><last>Moens</last></author>
      <pages>337–348</pages>
      <abstract>Though language model text embeddings have revolutionized NLP research, their ability to capture high-level semantic information, such as relations between entities in text, is limited. In this paper, we propose a novel contrastive learning framework that trains <a href="https://en.wikipedia.org/wiki/Sentence_embedding">sentence embeddings</a> to encode the relations in a <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph structure</a>. Given a sentence (unstructured text) and its <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph</a>, we use contrastive learning to impose relation-related structure on the token level representations of the sentence obtained with a CharacterBERT (El Boukkouri et al., 2020) model. The resulting relation-aware sentence embeddings achieve state-of-the-art results on the relation extraction task using only a simple KNN classifier, thereby demonstrating the success of the proposed method. Additional visualization by a tSNE analysis shows the effectiveness of the learned <a href="https://en.wikipedia.org/wiki/Representation_space">representation space</a> compared to baselines. Furthermore, we show that we can learn a different space for <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>, again using a contrastive learning objective, and demonstrate how to successfully combine both representation spaces in an entity-relation task.</abstract>
      <url hash="71988cb1">2021.conll-1.27</url>
      <bibkey>theodoropoulos-etal-2021-imposing</bibkey>
      <doi>10.18653/v1/2021.conll-1.27</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/ade-corpus">Adverse Drug Events (ADE) Corpus</pwcdataset>
    </paper>
    <paper id="29">
      <title>Pragmatic competence of pre-trained language models through the lens of discourse connectives</title>
      <author><first>Lalchand</first><last>Pandia</last></author>
      <author><first>Yan</first><last>Cong</last></author>
      <author><first>Allyson</first><last>Ettinger</last></author>
      <pages>367–379</pages>
      <abstract>As pre-trained language models (LMs) continue to dominate <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>, it is increasingly important that we understand the depth of language capabilities in these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>. In this paper, we target pre-trained LMs’ competence in <a href="https://en.wikipedia.org/wiki/Pragmatics">pragmatics</a>, with a focus on <a href="https://en.wikipedia.org/wiki/Pragmatics">pragmatics</a> relating to discourse connectives. We formulate cloze-style tests using a combination of naturally-occurring data and controlled inputs drawn from <a href="https://en.wikipedia.org/wiki/Psycholinguistics">psycholinguistics</a>. We focus on testing <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a>’ ability to use pragmatic cues to predict discourse connectives, <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a>’ ability to understand implicatures relating to connectives, and the extent to which <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> show humanlike preferences regarding temporal dynamics of connectives. We find that although models predict connectives reasonably well in the context of naturally-occurring data, when we control contexts to isolate high-level pragmatic cues, model sensitivity is much lower. Models also do not show substantial humanlike temporal preferences. Overall, the findings suggest that at present, dominant pre-training paradigms do not result in substantial pragmatic competence in our models.</abstract>
      <url hash="f0c810df">2021.conll-1.29</url>
      <bibkey>pandia-etal-2021-pragmatic</bibkey>
      <doi>10.18653/v1/2021.conll-1.29</doi>
    </paper>
    <paper id="32">
      <title>Scaffolded input promotes atomic organization in the recurrent neural network language model</title>
      <author><first>Philip A.</first><last>Huebner</last></author>
      <author><first>Jon A.</first><last>Willits</last></author>
      <pages>408–422</pages>
      <abstract>The recurrent neural network (RNN) language model is a powerful tool for learning arbitrary sequential dependencies in language data. Despite its enormous success in representing <a href="https://en.wikipedia.org/wiki/Lexical_item">lexical sequences</a>, little is known about the quality of the <a href="https://en.wikipedia.org/wiki/Lexical_item">lexical representations</a> that it acquires. In this work, we conjecture that it is straightforward to extract <a href="https://en.wikipedia.org/wiki/Lexical_analysis">lexical representations</a> (i.e. static word embeddings) from an RNN, but that the amount of semantic information that is encoded is limited when lexical items in the training data provide redundant semantic information. We conceptualize this limitation of the RNN as a failure to learn atomic internal states-states which capture information relevant to single word types without being influenced by redundant information provided by words with which they co-occur. Using a corpus of artificial language, we verify that redundancy in the training data yields non-atomic internal states, and propose a novel method for inducing atomic internal states. We show that 1) our method successfully induces atomic internal organization in controlled experiments, and 2) under more realistic conditions in which the training consists of child-directed language, application of our method improves the performance of lexical representations on a downstream semantic categorization task.</abstract>
      <url hash="5b2e87c6">2021.conll-1.32</url>
      <bibkey>huebner-willits-2021-scaffolded</bibkey>
      <doi>10.18653/v1/2021.conll-1.32</doi>
    </paper>
    <paper id="35">
      <title>Relation-aware Bidirectional Path Reasoning for Commonsense Question Answering</title>
      <author><first>Junxing</first><last>Wang</last></author>
      <author><first>Xinyi</first><last>Li</last></author>
      <author><first>Zhen</first><last>Tan</last></author>
      <author><first>Xiang</first><last>Zhao</last></author>
      <author><first>Weidong</first><last>Xiao</last></author>
      <pages>445–453</pages>
      <abstract>Commonsense Question Answering is an important natural language processing (NLP) task that aims to predict the correct answer to a question through <a href="https://en.wikipedia.org/wiki/Commonsense_reasoning">commonsense reasoning</a>. Previous studies utilize pre-trained models on large-scale corpora such as BERT, or perform <a href="https://en.wikipedia.org/wiki/Reason">reasoning</a> on <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graphs</a>. However, these methods do not explicitly model the <a href="https://en.wikipedia.org/wiki/Binary_relation">relations</a> that connect entities, which are informational and can be used to enhance <a href="https://en.wikipedia.org/wiki/Reason">reasoning</a>. To address this issue, we propose a relation-aware reasoning method. Our method uses a relation-aware graph neural network to capture the rich contextual information from both entities and relations. Compared with methods that use fixed relation embeddings from pre-trained models, our model dynamically updates relations with contextual information from a multi-source subgraph, built from multiple external knowledge sources. The enhanced representations of relations are then fed to a bidirectional reasoning module. A bidirectional attention mechanism is applied between the question sequence and the paths that connect entities, which provides us with transparent interpretability. Experimental results on the CommonsenseQA dataset illustrate that our method results in significant improvements over the baselines while also providing clear reasoning paths.<i>relations</i> that connect entities, which are informational and can be used to enhance reasoning. To address this issue, we propose a relation-aware reasoning method. Our method uses a relation-aware graph neural network to capture the rich contextual information from both entities and relations. Compared with methods that use fixed relation embeddings from pre-trained models, our model dynamically updates relations with contextual information from a multi-source subgraph, built from multiple external knowledge sources. The enhanced representations of relations are then fed to a bidirectional reasoning module. A bidirectional attention mechanism is applied between the question sequence and the paths that connect entities, which provides us with transparent interpretability. Experimental results on the CommonsenseQA dataset illustrate that our method results in significant improvements over the baselines while also providing clear reasoning paths.</abstract>
      <url hash="235c3f2d">2021.conll-1.35</url>
      <bibkey>wang-etal-2021-relation</bibkey>
      <doi>10.18653/v1/2021.conll-1.35</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/commonsenseqa">CommonsenseQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
    </paper>
    <paper id="38">
      <title>Commonsense Knowledge in <a href="https://en.wikipedia.org/wiki/Word_association">Word Associations</a> and ConceptNet<fixed-case>C</fixed-case>oncept<fixed-case>N</fixed-case>et</title>
      <author><first>Chunhua</first><last>Liu</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <author><first>Lea</first><last>Frermann</last></author>
      <pages>481–495</pages>
      <abstract>Humans use countless basic, shared facts about the world to efficiently navigate in their environment. This <a href="https://en.wikipedia.org/wiki/Commonsense_knowledge">commonsense knowledge</a> is rarely communicated explicitly, however, understanding how <a href="https://en.wikipedia.org/wiki/Commonsense_knowledge">commonsense knowledge</a> is represented in different paradigms is important for (a) a deeper understanding of human cognition and (b) augmenting automatic reasoning systems. This paper presents an in-depth comparison of two large-scale resources of general knowledge : <a href="https://en.wikipedia.org/wiki/ConceptNet">ConceptNet</a>, an engineered relational database, and SWOW, a <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graph</a> derived from crowd-sourced word associations. We examine the structure, overlap and differences between the two <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graphs</a>, as well as the extent of situational commonsense knowledge present in the two <a href="https://en.wikipedia.org/wiki/Factors_of_production">resources</a>. We finally show empirically that both resources improve downstream task performance on commonsense reasoning benchmarks over text-only baselines, suggesting that large-scale word association data, which have been obtained for several languages through crowd-sourcing, can be a valuable complement to curated knowledge graphs.</abstract>
      <url hash="c036cde7">2021.conll-1.38</url>
      <bibkey>liu-etal-2021-commonsense</bibkey>
      <doi>10.18653/v1/2021.conll-1.38</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/atomic">ATOMIC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/commonsenseqa">CommonsenseQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mcscript">MCScript</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/openbookqa">OpenBookQA</pwcdataset>
    </paper>
    <paper id="39">
      <title>Cross-document Event Identity via Dense Annotation</title>
      <author><first>Adithya</first><last>Pratapa</last></author>
      <author><first>Zhengzhong</first><last>Liu</last></author>
      <author><first>Kimihiro</first><last>Hasegawa</last></author>
      <author><first>Linwei</first><last>Li</last></author>
      <author><first>Yukari</first><last>Yamakawa</last></author>
      <author><first>Shikun</first><last>Zhang</last></author>
      <author><first>Teruko</first><last>Mitamura</last></author>
      <pages>496–517</pages>
      <abstract>In this paper, we study the identity of textual events from different documents. While the complex nature of event identity is previously studied (Hovy et al., 2013), the case of events across documents is unclear. Prior work on cross-document event coreference has two main drawbacks. First, they restrict the <a href="https://en.wikipedia.org/wiki/Annotation">annotations</a> to a limited set of event types. Second, they insufficiently tackle the concept of event identity. Such annotation setup reduces the pool of event mentions and prevents one from considering the possibility of quasi-identity relations. We propose a dense annotation approach for cross-document event coreference, comprising a rich source of event mentions and a dense annotation effort between related document pairs. To this end, we design a new annotation workflow with careful quality control and an easy-to-use annotation interface. In addition to the links, we further collect overlapping event contexts, including time, location, and participants, to shed some light on the relation between <a href="https://en.wikipedia.org/wiki/Identity_(social_science)">identity decisions</a> and context. We present an open-access dataset for cross-document event coreference, CDEC-WN, collected from English Wikinews and open-source our annotation toolkit to encourage further research on cross-document tasks.</abstract>
      <url hash="7d643b29">2021.conll-1.39</url>
      <bibkey>pratapa-etal-2021-cross</bibkey>
      <doi>10.18653/v1/2021.conll-1.39</doi>
      <pwccode url="https://github.com/adithya7/cdec-wikinews" additional="false">adithya7/cdec-wikinews</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/ecb">ECB+</pwcdataset>
    </paper>
    <paper id="41">
      <title>Negation-Instance Based Evaluation of End-to-End Negation Resolution</title>
      <author><first>Elizaveta</first><last>Sineva</last></author>
      <author><first>Stefan</first><last>Grünewald</last></author>
      <author><first>Annemarie</first><last>Friedrich</last></author>
      <author><first>Jonas</first><last>Kuhn</last></author>
      <pages>528–543</pages>
      <abstract>In this paper, we revisit the task of negation resolution, which includes the subtasks of cue detection (e.g. not, never) and scope resolution. In the context of previous shared tasks, a variety of evaluation metrics have been proposed. Subsequent works usually use different subsets of these, including variations and custom implementations, rendering meaningful comparisons between systems difficult. Examining the problem both from a linguistic perspective and from a downstream viewpoint, we here argue for a negation-instance based approach to evaluating negation resolution. Our proposed <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> correspond to expectations over per-instance scores and hence are intuitively interpretable. To render research comparable and to foster future work, we provide results for a set of current state-of-the-art systems for negation resolution on three English corpora, and make our implementation of the evaluation scripts publicly available.</abstract>
      <url hash="a1f1ddc1">2021.conll-1.41</url>
      <bibkey>sineva-etal-2021-negation</bibkey>
      <doi>10.18653/v1/2021.conll-1.41</doi>
      <pwccode url="https://github.com/boschresearch/negation_resolution_evaluation_conll2021" additional="false">boschresearch/negation_resolution_evaluation_conll2021</pwccode>
    </paper>
    <paper id="42">
      <title>Controlling Prosody in End-to-End TTS : A Case Study on Contrastive Focus Generation<fixed-case>TTS</fixed-case>: A Case Study on Contrastive Focus Generation</title>
      <author><first>Siddique</first><last>Latif</last></author>
      <author><first>Inyoung</first><last>Kim</last></author>
      <author><first>Ioan</first><last>Calapodescu</last></author>
      <author><first>Laurent</first><last>Besacier</last></author>
      <pages>544–551</pages>
      <abstract>While End-2-End Text-to-Speech (TTS) has made significant progresses over the past few years, these systems still lack intuitive user controls over <a href="https://en.wikipedia.org/wiki/Prosody_(linguistics)">prosody</a>. For instance, generating <a href="https://en.wikipedia.org/wiki/Speech">speech</a> with fine-grained prosody control (prosodic prominence, contextually appropriate emotions) is still an open challenge. In this paper, we investigate whether we can control <a href="https://en.wikipedia.org/wiki/Prosody_(linguistics)">prosody</a> directly from the input text, in order to code information related to contrastive focus which emphasizes a specific word that is contrary to the presuppositions of the interlocutor. We build and share a specific <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> for this purpose and show that it allows to train a TTS system were this fine-grained prosodic feature can be correctly conveyed using control tokens. Our evaluation compares synthetic and natural utterances and shows that prosodic patterns of contrastive focus (variations of Fo, Intensity and Duration) can be learnt accurately. Such a milestone is important to allow, for example, <a href="https://en.wikipedia.org/wiki/Smart_speaker">smart speakers</a> to be programmatically controlled in terms of output prosody.</abstract>
      <url hash="1ea87db4">2021.conll-1.42</url>
      <bibkey>latif-etal-2021-controlling</bibkey>
      <doi>10.18653/v1/2021.conll-1.42</doi>
    </paper>
    <paper id="43">
      <title>A Large-scale Comprehensive Abusiveness Detection Dataset with Multifaceted Labels from Reddit<fixed-case>R</fixed-case>eddit</title>
      <author><first>Hoyun</first><last>Song</last></author>
      <author><first>Soo Hyun</first><last>Ryu</last></author>
      <author><first>Huije</first><last>Lee</last></author>
      <author><first>Jong</first><last>Park</last></author>
      <pages>552–561</pages>
      <abstract>As users in <a href="https://en.wikipedia.org/wiki/Online_community">online communities</a> suffer from severe side effects of <a href="https://en.wikipedia.org/wiki/Abuse">abusive language</a>, many researchers attempted to detect abusive texts from <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>, presenting several <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> for such detection. However, none of them contain both comprehensive labels and contextual information, which are essential for thoroughly detecting all kinds of abusiveness from texts, since datasets with such fine-grained features demand a significant amount of <a href="https://en.wikipedia.org/wiki/Annotation">annotations</a>, leading to much increased <a href="https://en.wikipedia.org/wiki/Complexity">complexity</a>. In this paper, we propose a Comprehensive Abusiveness Detection Dataset (CADD), collected from the English Reddit posts, with multifaceted labels and contexts. Our <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> is annotated hierarchically for an efficient <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a> through <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourcing</a> on a large-scale. We also empirically explore the characteristics of our <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and provide a detailed analysis for novel insights. The results of our experiments with strong pre-trained natural language understanding models on our <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> show that our <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> gives rise to meaningful performance, assuring its practicality for abusive language detection.</abstract>
      <url hash="beecf2a8">2021.conll-1.43</url>
      <bibkey>song-etal-2021-large</bibkey>
      <doi>10.18653/v1/2021.conll-1.43</doi>
      <pwccode url="https://github.com/nlpcl-lab/cadd_dataset" additional="false">nlpcl-lab/cadd_dataset</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/hate-speech">Hate Speech</pwcdataset>
    </paper>
    <paper id="51">
      <title>Predicting non-native speech perception using the Perceptual Assimilation Model and state-of-the-art acoustic models</title>
      <author><first>Juliette</first><last>Millet</last></author>
      <author><first>Ioana</first><last>Chitoran</last></author>
      <author><first>Ewan</first><last>Dunbar</last></author>
      <pages>661–673</pages>
      <abstract>Our <a href="https://en.wikipedia.org/wiki/First_language">native language</a> influences the way we perceive <a href="https://en.wikipedia.org/wiki/Phone_(phonetics)">speech sounds</a>, affecting our ability to discriminate non-native sounds. We compare two ideas about the influence of the <a href="https://en.wikipedia.org/wiki/First_language">native language</a> on <a href="https://en.wikipedia.org/wiki/Speech_perception">speech perception</a> : the Perceptual Assimilation Model, which appeals to a mental classification of sounds into native phoneme categories, versus the idea that rich, fine-grained phonetic representations tuned to the statistics of the native language, are sufficient. We operationalise this idea using representations from two state-of-the-art speech models, a Dirichlet process Gaussian mixture model and the more recent wav2vec 2.0 model. We present a new, open dataset of French- and English-speaking participants’ speech perception behaviour for 61 vowel sounds from six languages. We show that phoneme assimilation is a better predictor than fine-grained phonetic modelling, both for the discrimination behaviour as a whole, and for predicting differences in discriminability associated with differences in native language background. We also show that wav2vec 2.0, while not good at capturing the effects of <a href="https://en.wikipedia.org/wiki/First_language">native language</a> on <a href="https://en.wikipedia.org/wiki/Speech_perception">speech perception</a>, is complementary to information about native phoneme assimilation, and provides a good model of low-level phonetic representations, supporting the idea that both categorical and fine-grained perception are used during <a href="https://en.wikipedia.org/wiki/Speech_perception">speech perception</a>.</abstract>
      <url hash="97724f5f">2021.conll-1.51</url>
      <bibkey>millet-etal-2021-predicting</bibkey>
      <doi>10.18653/v1/2021.conll-1.51</doi>
    </paper>
    </volume>
</collection>