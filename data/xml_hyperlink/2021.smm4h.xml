<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.smm4h">
  <volume id="1" ingest-date="2021-05-24">
    <meta>
      <booktitle>Proceedings of the Sixth Social Media Mining for Health (#SMM4H) Workshop and Shared Task</booktitle>
      <editor><first>Arjun</first><last>Magge</last></editor>
      <editor><first>Ari</first><last>Klein</last></editor>
      <editor><first>Antonio</first><last>Miranda-Escalada</last></editor>
      <editor><first>Mohammed Ali</first><last>Al-garadi</last></editor>
      <editor><first>Ilseyar</first><last>Alimova</last></editor>
      <editor><first>Zulfat</first><last>Miftahutdinov</last></editor>
      <editor><first>Eulalia</first><last>Farre-Maduell</last></editor>
      <editor><first>Salvador Lima</first><last>Lopez</last></editor>
      <editor><first>Ivan</first><last>Flores</last></editor>
      <editor><first>Karen</first><last>O'Connor</last></editor>
      <editor><first>Davy</first><last>Weissenbacher</last></editor>
      <editor><first>Elena</first><last>Tutubalina</last></editor>
      <editor><first>Abeed</first><last>Sarker</last></editor>
      <editor><first>Juan M</first><last>Banda</last></editor>
      <editor><first>Martin</first><last>Krallinger</last></editor>
      <editor><first>Graciela</first><last>Gonzalez-Hernandez</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Mexico City, Mexico</address>
      <month>June</month>
      <year>2021</year>
      <url hash="85c83d62">2021.smm4h-1</url>
    </meta>
    <frontmatter>
      <url hash="dd6d7630">2021.smm4h-1.0</url>
      <bibkey>smm4h-2021-social</bibkey>
    </frontmatter>
    <paper id="2">
      <title>View Distillation with Unlabeled Data for Extracting Adverse Drug Effects from User-Generated Data</title>
      <author><first>Payam</first><last>Karisani</last></author>
      <author><first>Jinho D.</first><last>Choi</last></author>
      <author><first>Li</first><last>Xiong</last></author>
      <pages>7–12</pages>
      <abstract>We present an <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> based on multi-layer transformers for identifying Adverse Drug Reactions (ADR) in social media data. Our model relies on the properties of the problem and the characteristics of contextual word embeddings to extract two views from documents. Then a <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> is trained on each view to label a set of unlabeled documents to be used as an initializer for a new <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> in the other view. Finally, the initialized classifier in each view is further trained using the initial training examples. We evaluated our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> in the largest publicly available ADR dataset. The experiments testify that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> significantly outperforms the transformer-based models pretrained on domain-specific data.</abstract>
      <url hash="dca91337">2021.smm4h-1.2</url>
      <doi>10.18653/v1/2021.smm4h-1.2</doi>
      <bibkey>karisani-etal-2021-view</bibkey>
    </paper>
    <paper id="3">
      <title>The ProfNER shared task on automatic recognition of occupation mentions in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> : systems, evaluation, guidelines, embeddings and corpora<fixed-case>P</fixed-case>rof<fixed-case>NER</fixed-case> shared task on automatic recognition of occupation mentions in social media: systems, evaluation, guidelines, embeddings and corpora</title>
      <author><first>Antonio</first><last>Miranda-Escalada</last></author>
      <author><first>Eulàlia</first><last>Farré-Maduell</last></author>
      <author><first>Salvador</first><last>Lima-López</last></author>
      <author><first>Luis</first><last>Gascó</last></author>
      <author><first>Vicent</first><last>Briva-Iglesias</last></author>
      <author><first>Marvin</first><last>Agüero-Torales</last></author>
      <author><first>Martin</first><last>Krallinger</last></author>
      <pages>13–20</pages>
      <abstract>Detection of occupations in texts is relevant for a range of important application scenarios, like <a href="https://en.wikipedia.org/wiki/Competitive_intelligence">competitive intelligence</a>, sociodemographic analysis, legal NLP or health-related occupational data mining. Despite the importance and heterogeneous data types that mention <a href="https://en.wikipedia.org/wiki/Job">occupations</a>, <a href="https://en.wikipedia.org/wiki/Text_mining">text mining</a> efforts to recognize them have been limited. This is due to the lack of clear annotation guidelines and high-quality Gold Standard corpora. Social media data can be regarded as a relevant source of information for real-time monitoring of at-risk occupational groups in the context of <a href="https://en.wikipedia.org/wiki/Pandemic">pandemics</a> like the COVID-19 one, facilitating intervention strategies for occupations in direct contact with infectious agents or affected by mental health issues. To evaluate current NLP methods and to generate resources, we have organized the ProfNER track at SMM4H 2021, providing ProfNER participants with a Gold Standard corpus of manually annotated tweets (human IAA of 0.919) following annotation guidelines available in <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a> and <a href="https://en.wikipedia.org/wiki/English_language">English</a>, an occupation gazetteer, a machine-translated version of <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a>, and FastText embeddings. Out of 35 registered teams, 11 submitted a total of 27 runs. Best-performing participants built <a href="https://en.wikipedia.org/wiki/System">systems</a> based on recent <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP technologies</a> (e.g. transformers) and achieved 0.93 <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> in Text Classification and 0.839 in <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">Named Entity Recognition</a>. Corpus : https://doi.org/10.5281/zenodo.4309356</abstract>
      <url hash="e48e2e6a">2021.smm4h-1.3</url>
      <doi>10.18653/v1/2021.smm4h-1.3</doi>
      <bibkey>miranda-escalada-etal-2021-profner</bibkey>
    </paper>
    <paper id="7">
      <title>Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets</title>
      <author><first>George-Andrei</first><last>Dima</last></author>
      <author><first>Dumitru-Clementin</first><last>Cercel</last></author>
      <author><first>Mihai</first><last>Dascalu</last></author>
      <pages>44–51</pages>
      <abstract>This paper presents our contribution to the <a href="https://en.wikipedia.org/wiki/Social_media_mining">Social Media Mining</a> for Health Applications Shared Task 2021. We addressed all the three subtasks of Task 1 : Subtask A (classification of tweets containing adverse effects), Subtask B (extraction of text spans containing adverse effects) and Subtask C (adverse effects resolution). We explored various pre-trained transformer-based language models and we focused on a multi-task training architecture. For the first subtask, we also applied adversarial augmentation techniques and we formed model ensembles in order to improve the <a href="https://en.wikipedia.org/wiki/Robustness_(computer_science)">robustness</a> of the prediction. Our system ranked first at Subtask B with 0.51 F1 score, 0.514 <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">precision</a> and 0.514 recall. For Subtask A we obtained 0.44 <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">F1 score</a>, 0.49 <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">precision</a> and 0.39 recall and for Subtask C we obtained 0.16 <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">F1 score</a> with 0.16 <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">precision</a> and 0.17 recall.</abstract>
      <url hash="a7a8d292">2021.smm4h-1.7</url>
      <doi>10.18653/v1/2021.smm4h-1.7</doi>
      <bibkey>dima-etal-2021-transformer</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/smm4h">SMM4H</pwcdataset>
    </paper>
    <paper id="10">
      <title>UACH-INAOE at SMM4H : a BERT based approach for classification of COVID-19 Twitter posts<fixed-case>UACH</fixed-case>-<fixed-case>INAOE</fixed-case> at <fixed-case>SMM</fixed-case>4<fixed-case>H</fixed-case>: a <fixed-case>BERT</fixed-case> based approach for classification of <fixed-case>COVID</fixed-case>-19 <fixed-case>T</fixed-case>witter posts</title>
      <author><first>Alberto</first><last>Valdes</last></author>
      <author><first>Jesus</first><last>Lopez</last></author>
      <author><first>Manuel</first><last>Montes</last></author>
      <pages>65–68</pages>
      <abstract>This work describes the participation of the Universidad Autnoma de Chihuahua-Instituto Nacional de Astrofsica, ptica y Electrnica team at the Social Media Mining for Health Applications (SMM4H) 2021 shared task. Our team participated in task 5 and 6, both focused on the automatic classification of Twitter posts related to COVID-19. Task 5 was oriented on solving a binary classification problem, trying to identify self-reporting tweets of potential cases of COVID-19. Task 6 objective was to classify tweets containing COVID-19 symptoms. For both tasks we used <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> based on bidirectional encoder representations from transformers (BERT). Our objective was to determine if a <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> pretrained on a corpus in the domain of interest can outperform one trained on a much larger general domain corpus. Our F1 results were encouraging, 0.77 and 0.95 for task 5 and 6 respectively, having achieved the highest score among all the participants in the latter.</abstract>
      <url hash="2893b80e">2021.smm4h-1.10</url>
      <doi>10.18653/v1/2021.smm4h-1.10</doi>
      <bibkey>valdes-etal-2021-uach</bibkey>
    </paper>
    <paper id="12">
      <title>Word Embeddings, <a href="https://en.wikipedia.org/wiki/Cosine_similarity">Cosine Similarity</a> and <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a> for Identification of Professions &amp; Occupations in Health-related Social Media</title>
      <author><first>Sergio</first><last>Santamaría Carrasco</last></author>
      <author><first>Roberto</first><last>Cuervo Rosillo</last></author>
      <pages>74–76</pages>
      <abstract>ProfNER-ST focuses on the recognition of professions and occupations from <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> using Spanish data. Our participation is based on a combination of word-level embeddings, including pre-trained Spanish BERT, as well as cosine similarity computed over a subset of entities that serve as input for an encoder-decoder architecture with attention mechanism. Finally, our best score achieved an F1-measure of 0.823 in the official test set.</abstract>
      <url hash="569439cf">2021.smm4h-1.12</url>
      <doi>10.18653/v1/2021.smm4h-1.12</doi>
      <bibkey>santamaria-carrasco-cuervo-rosillo-2021-word</bibkey>
    </paper>
    <paper id="16">
      <title>A Joint Training Approach to Tweet Classification and Adverse Effect Extraction and Normalization for SMM4H 2021<fixed-case>SMM</fixed-case>4<fixed-case>H</fixed-case> 2021</title>
      <author><first>Mohab</first><last>Elkaref</last></author>
      <author><first>Lamiece</first><last>Hassan</last></author>
      <pages>91–94</pages>
      <abstract>In this work we describe our submissions to the Social Media Mining for Health (SMM4H) 2021 Shared Task. We investigated the effectiveness of a joint training approach to Task 1, specifically classification, extraction and normalization of Adverse Drug Effect (ADE) mentions in English tweets. Our approach performed well on the normalization task, achieving an above average f1 score of 24 %, but less so on <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> and extraction, with f1 scores of 22 % and 37 % respectively. Our experiments also showed that a larger dataset with more negative results led to stronger results than a smaller more balanced dataset, even when both datasets have the same positive examples. Finally we also submitted a tuned BERT model for Task 6 : Classification of Covid-19 tweets containing symptoms, which achieved an above average f1 score of 96 %.</abstract>
      <url hash="afac2480">2021.smm4h-1.16</url>
      <doi>10.18653/v1/2021.smm4h-1.16</doi>
      <bibkey>elkaref-hassan-2021-joint</bibkey>
    </paper>
    <paper id="20">
      <title>Identification of profession &amp; occupation in Health-related Social Media using tweets in Spanish<fixed-case>S</fixed-case>panish</title>
      <author><first>Victoria</first><last>Pachón</last></author>
      <author><first>Jacinto</first><last>Mata Vázquez</last></author>
      <author><first>Juan Luís</first><last>Domínguez Olmedo</last></author>
      <pages>105–107</pages>
      <abstract>In this paper we present our approach and system description on Task 7a in ProfNer-ST : Identification of profession &amp; occupation in Health related Social Media. Our main contribution is to show the effectiveness of using BETO-Spanish BERT as a model based on transformers pretrained with a Spanish Corpus for classification tasks. In our experiments we compared several <a href="https://en.wikipedia.org/wiki/Computer_architecture">architectures</a> based on <a href="https://en.wikipedia.org/wiki/Transformer">transformers</a> with others based on classical <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning algorithms</a>. With this <a href="https://en.wikipedia.org/wiki/Software_development_process">approach</a>, we achieved an F1-score of 0.92 in the evaluation process.</abstract>
      <url hash="eef81079">2021.smm4h-1.20</url>
      <doi>10.18653/v1/2021.smm4h-1.20</doi>
      <bibkey>pachon-etal-2021-identification</bibkey>
    </paper>
    <paper id="23">
      <title>UoB at ProfNER 2021 : Data Augmentation for Classification Using <a href="https://en.wikipedia.org/wiki/Machine_translation">Machine Translation</a><fixed-case>U</fixed-case>o<fixed-case>B</fixed-case> at <fixed-case>P</fixed-case>rof<fixed-case>NER</fixed-case> 2021: Data Augmentation for Classification Using Machine Translation</title>
      <author><first>Frances Adriana</first><last>Laureano De Leon</last></author>
      <author><first>Harish</first><last>Tayyar Madabushi</last></author>
      <author><first>Mark</first><last>Lee</last></author>
      <pages>115–117</pages>
      <abstract>This paper describes the participation of the UoB-NLP team in the ProfNER-ST shared subtask 7a. The <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> was aimed at detecting the mention of professions in social media text. Our team experimented with two methods of improving the performance of pre-trained models : Specifically, we experimented with <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a> through <a href="https://en.wikipedia.org/wiki/Translation">translation</a> and the merging of multiple language inputs to meet the objective of the task. While the best performing model on the test data consisted of mBERT fine-tuned on augmented data using <a href="https://en.wikipedia.org/wiki/Back-translation">back-translation</a>, the improvement is minor possibly because multi-lingual pre-trained models such as mBERT already have access to the kind of information provided through <a href="https://en.wikipedia.org/wiki/Back-translation">back-translation and bilingual data</a>.</abstract>
      <url hash="a1cb734e">2021.smm4h-1.23</url>
      <doi>10.18653/v1/2021.smm4h-1.23</doi>
      <bibkey>laureano-de-leon-etal-2021-uob</bibkey>
    </paper>
    <paper id="26">
      <title>PAII-NLP at SMM4H 2021 : Joint Extraction and Normalization of Adverse Drug Effect Mentions in Tweets<fixed-case>PAII</fixed-case>-<fixed-case>NLP</fixed-case> at <fixed-case>SMM</fixed-case>4<fixed-case>H</fixed-case> 2021: Joint Extraction and Normalization of Adverse Drug Effect Mentions in Tweets</title>
      <author><first>Zongcheng</first><last>Ji</last></author>
      <author><first>Tian</first><last>Xia</last></author>
      <author><first>Mei</first><last>Han</last></author>
      <pages>126–127</pages>
      <abstract>This paper describes our system developed for the subtask 1c of the sixth Social Media Mining for Health Applications (SMM4H) shared task in 2021. The aim of the subtask is to recognize the adverse drug effect (ADE) mentions from tweets and normalize the identified mentions to their mapping MedDRA preferred term IDs. Our system is based on a neural transition-based joint model, which is to perform <a href="https://en.wikipedia.org/wiki/Computer_vision">recognition</a> and <a href="https://en.wikipedia.org/wiki/Normalization_(statistics)">normalization</a> simultaneously. Our final two submissions outperform the average F1 score by 1-2 %.</abstract>
      <url hash="0fa069ec">2021.smm4h-1.26</url>
      <doi>10.18653/v1/2021.smm4h-1.26</doi>
      <bibkey>ji-etal-2021-paii</bibkey>
    </paper>
    </volume>
</collection>