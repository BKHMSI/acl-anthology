<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.hackashop">
  <volume id="1" ingest-date="2021-04-19">
    <meta>
      <booktitle>Proceedings of the EACL Hackashop on News Media Content Analysis and Automated Report Generation</booktitle>
      <editor><first>Hannu</first><last>Toivonen</last></editor>
      <editor><first>Michele</first><last>Boggia</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>April</month>
      <year>2021</year>
    </meta>
    <frontmatter>
      <url hash="30c5e14d">2021.hackashop-1.0</url>
      <bibkey>hackashop-2021-eacl</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Adversarial Training for News Stance Detection : Leveraging Signals from a Multi-Genre Corpus.</title>
      <author><first>Costanza</first><last>Conforti</last></author>
      <author><first>Jakob</first><last>Berndt</last></author>
      <author><first>Marco</first><last>Basaldella</last></author>
      <author><first>Mohammad Taher</first><last>Pilehvar</last></author>
      <author><first>Chryssi</first><last>Giannitsarou</last></author>
      <author><first>Flavio</first><last>Toxvaerd</last></author>
      <author><first>Nigel</first><last>Collier</last></author>
      <pages>1–7</pages>
      <abstract>Cross-target generalization constitutes an important issue for news Stance Detection (SD). In this short paper, we investigate adversarial cross-genre SD, where knowledge from annotated user-generated data is leveraged to improve news SD on targets unseen during training. We implement a BERT-based adversarial network and show experimental performance improvements over a set of strong <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baselines</a>. Given the abundance of user-generated data, which are considerably less expensive to retrieve and annotate than <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a>, this constitutes a promising research direction.</abstract>
      <url hash="1f6761b2">2021.hackashop-1.1</url>
      <bibkey>conforti-etal-2021-adversarial</bibkey>
    </paper>
    <paper id="10">
      <title>Aligning Estonian and Russian news industry keywords with the help of subtitle translations and an environmental thesaurus<fixed-case>E</fixed-case>stonian and <fixed-case>R</fixed-case>ussian news industry keywords with the help of subtitle translations and an environmental thesaurus</title>
      <author><first>Andraž</first><last>Repar</last></author>
      <author><first>Andrej</first><last>Shumakov</last></author>
      <pages>71–75</pages>
      <abstract>This paper presents the implementation of a bilingual term alignment approach developed by Repar et al. (2019) to a dataset of unaligned Estonian and Russian keywords which were manually assigned by journalists to describe the article topic. We started by separating the dataset into Estonian and Russian tags based on whether they are written in the Latin or Cyrillic script. Then we selected the available language-specific resources necessary for the <a href="https://en.wikipedia.org/wiki/Alignment_system">alignment system</a> to work. Despite the domains of the language-specific resources (subtitles and environment) not matching the domain of the dataset (news articles), we were able to achieve respectable results with manual evaluation indicating that almost 3/4 of the aligned keyword pairs are at least partial matches.</abstract>
      <url hash="c67461bb">2021.hackashop-1.10</url>
      <bibkey>repar-shumakov-2021-aligning</bibkey>
    </paper>
    <paper id="12">
      <title>Comment Section <a href="https://en.wikipedia.org/wiki/Personalization">Personalization</a> : Algorithmic, Interface, and Interaction Design</title>
      <author><first>Yixue</first><last>Wang</last></author>
      <pages>84–88</pages>
      <abstract>Comment sections allow users to share their personal experiences, discuss and form different opinions, and build communities out of organic conversations. However, many comment sections present chronological ranking to all users. In this paper, I discuss personalization approaches in comment sections based on different objectives for newsrooms and researchers to consider. I propose algorithmic and interface designs when personalizing the presentation of comments based on different objectives including <a href="https://en.wikipedia.org/wiki/Relevance">relevance</a>, <a href="https://en.wikipedia.org/wiki/Diversity_(politics)">diversity</a>, and education / background information. I further explain how <a href="https://en.wikipedia.org/wiki/Transparency_(behavior)">transparency</a>, user control, and comment type diversity could help users most benefit from the personalized interacting experience.</abstract>
      <url hash="fb016a8e">2021.hackashop-1.12</url>
      <bibkey>wang-2021-comment</bibkey>
    </paper>
    <paper id="14">
      <title>EMBEDDIA Tools, Datasets and Challenges : Resources and Hackathon Contributions<fixed-case>EMBEDDIA</fixed-case> Tools, Datasets and Challenges: Resources and Hackathon Contributions</title>
      <author><first>Senja</first><last>Pollak</last></author>
      <author><first>Marko</first><last>Robnik-Šikonja</last></author>
      <author><first>Matthew</first><last>Purver</last></author>
      <author><first>Michele</first><last>Boggia</last></author>
      <author><first>Ravi</first><last>Shekhar</last></author>
      <author><first>Marko</first><last>Pranjić</last></author>
      <author><first>Salla</first><last>Salmela</last></author>
      <author><first>Ivar</first><last>Krustok</last></author>
      <author><first>Tarmo</first><last>Paju</last></author>
      <author><first>Carl-Gustav</first><last>Linden</last></author>
      <author><first>Leo</first><last>Leppänen</last></author>
      <author><first>Elaine</first><last>Zosa</last></author>
      <author><first>Matej</first><last>Ulčar</last></author>
      <author><first>Linda</first><last>Freienthal</last></author>
      <author><first>Silver</first><last>Traat</last></author>
      <author><first>Luis Adrián</first><last>Cabrera-Diego</last></author>
      <author><first>Matej</first><last>Martinc</last></author>
      <author><first>Nada</first><last>Lavrač</last></author>
      <author><first>Blaž</first><last>Škrlj</last></author>
      <author><first>Martin</first><last>Žnidaršič</last></author>
      <author><first>Andraž</first><last>Pelicon</last></author>
      <author><first>Boshko</first><last>Koloski</last></author>
      <author><first>Vid</first><last>Podpečan</last></author>
      <author><first>Janez</first><last>Kranjc</last></author>
      <author><first>Shane</first><last>Sheehan</last></author>
      <author><first>Emanuela</first><last>Boros</last></author>
      <author><first>Jose G.</first><last>Moreno</last></author>
      <author><first>Antoine</first><last>Doucet</last></author>
      <author><first>Hannu</first><last>Toivonen</last></author>
      <pages>99–109</pages>
      <abstract>This paper presents tools and data sources collected and released by the EMBEDDIA project, supported by the European Union’s Horizon 2020 research and innovation program. The collected resources were offered to participants of a <a href="https://en.wikipedia.org/wiki/Hackathon">hackathon</a> organized as part of the EACL Hackashop on News Media Content Analysis and Automated Report Generation in February 2021. The <a href="https://en.wikipedia.org/wiki/Hackathon">hackathon</a> had six participating teams who addressed different challenges, either from the list of proposed challenges or their own news-industry-related tasks. This paper goes beyond the scope of the <a href="https://en.wikipedia.org/wiki/Hackathon">hackathon</a>, as it brings together in a coherent and compact form most of the resources developed, collected and released by the EMBEDDIA project. Moreover, it constitutes a handy source for <a href="https://en.wikipedia.org/wiki/News_media">news media industry</a> and researchers in the fields of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a> and <a href="https://en.wikipedia.org/wiki/Social_science">Social Science</a>.</abstract>
      <url hash="956a7f13">2021.hackashop-1.14</url>
      <bibkey>pollak-etal-2021-embeddia</bibkey>
    </paper>
    <paper id="15">
      <title>A COVID-19 news coverage mood map of Europe<fixed-case>COVID</fixed-case>-19 news coverage mood map of <fixed-case>E</fixed-case>urope</title>
      <author><first>Frankie</first><last>Robertson</last></author>
      <author><first>Jarkko</first><last>Lagus</last></author>
      <author><first>Kaisla</first><last>Kajava</last></author>
      <pages>110–115</pages>
      <abstract>We present a COVID-19 news dashboard which visualizes sentiment in pandemic news coverage in different languages across Europe. The dashboard shows analyses for positive / neutral / negative sentiment and <a href="https://en.wikipedia.org/wiki/Morality">moral sentiment</a> for <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a> across countries and languages. First we extract <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a> from news-crawl. Then we use a pre-trained multilingual BERT model for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> of news article headlines and a dictionary and word vectors -based method for moral sentiment analysis of news articles. The resulting dashboard gives a unified overview of news events on COVID-19 news overall sentiment, and the region and language of publication from the period starting from the beginning of January 2020 to the end of January 2021.</abstract>
      <url hash="a33c2c51">2021.hackashop-1.15</url>
      <bibkey>robertson-etal-2021-covid</bibkey>
    </paper>
    <paper id="16">
      <title>Interesting cross-border news discovery using cross-lingual article linking and document similarity</title>
      <author><first>Boshko</first><last>Koloski</last></author>
      <author><first>Elaine</first><last>Zosa</last></author>
      <author><first>Timen</first><last>Stepišnik-Perdih</last></author>
      <author><first>Blaž</first><last>Škrlj</last></author>
      <author><first>Tarmo</first><last>Paju</last></author>
      <author><first>Senja</first><last>Pollak</last></author>
      <pages>116–120</pages>
      <abstract>Team Name : team-8 Embeddia Tool : Cross-Lingual Document Retrieval Zosa et al. Dataset : Estonian and Latvian news datasets abstract : Contemporary news media face increasing amounts of available data that can be of use when prioritizing, selecting and discovering new news. In this work we propose a <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> for retrieving interesting articles in a cross-border news discovery setting. More specifically, we explore how a set of seed documents in <a href="https://en.wikipedia.org/wiki/Estonian_language">Estonian</a> can be projected in Latvian document space and serve as a basis for discovery of novel interesting pieces of Latvian news that would interest Estonian readers. The proposed methodology was evaluated by Estonian journalist who confirmed that in the best setting, from top 10 retrieved Latvian documents, half of them represent news that are potentially interesting to be taken by the Estonian media house and presented to Estonian readers.</abstract>
      <url hash="275a0935">2021.hackashop-1.16</url>
      <bibkey>koloski-etal-2021-interesting</bibkey>
    </paper>
    </volume>
</collection>