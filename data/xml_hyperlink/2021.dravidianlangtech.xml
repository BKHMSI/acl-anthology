<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.dravidianlangtech">
  <volume id="1" ingest-date="2021-04-19">
    <meta>
      <booktitle>Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages</booktitle>
      <editor><first>Bharathi Raja</first><last>Chakravarthi</last></editor>
      <editor><first>Ruba</first><last>Priyadharshini</last></editor>
      <editor><first>Anand</first><last>Kumar M</last></editor>
      <editor><first>Parameswari</first><last>Krishnamurthy</last></editor>
      <editor><first>Elizabeth</first><last>Sherly</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Kyiv</address>
      <month>April</month>
      <year>2021</year>
    </meta>
    <frontmatter>
      <url hash="b92e3684">2021.dravidianlangtech-1.0</url>
      <bibkey>dravidianlangtech-2021-speech</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Towards Offensive Language Identification for Dravidian Languages<fixed-case>D</fixed-case>ravidian Languages</title>
      <author><first>Siva</first><last>Sai</last></author>
      <author><first>Yashvardhan</first><last>Sharma</last></author>
      <pages>18–27</pages>
      <abstract>Offensive speech identification in countries like <a href="https://en.wikipedia.org/wiki/India">India</a> poses several challenges due to the usage of code-mixed and romanized variants of multiple languages by the users in their posts on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. The challenge of offensive language identification on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> for <a href="https://en.wikipedia.org/wiki/Dravidian_languages">Dravidian languages</a> is harder, considering the low resources available for the same. In this paper, we explored the zero-shot learning and few-shot learning paradigms based on multilingual language models for offensive speech detection in code-mixed and romanized variants of three Dravidian languages-Malayalam, <a href="https://en.wikipedia.org/wiki/Tamil_language">Tamil</a>, and <a href="https://en.wikipedia.org/wiki/Kannada">Kannada</a>. We propose a novel and flexible approach of selective translation and <a href="https://en.wikipedia.org/wiki/Transliteration">transliteration</a> to reap better results from fine-tuning and ensembling multilingual transformer networks like XLMRoBERTa and mBERT. We implemented pretrained, fine-tuned, and ensembled versions of XLM-RoBERTa for offensive speech classification. Further, we experimented with interlanguage, inter-task, and multi-task transfer learning techniques to leverage the rich resources available for offensive speech identification in the <a href="https://en.wikipedia.org/wiki/English_language">English language</a> and to enrich the models with <a href="https://en.wikipedia.org/wiki/Knowledge_transfer">knowledge transfer</a> from related tasks. The proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> yielded good results and are promising for effective offensive speech identification in low resource settings.</abstract>
      <url hash="3f6afca2">2021.dravidianlangtech-1.3</url>
      <attachment type="Software" hash="08081334">2021.dravidianlangtech-1.3.Software.zip</attachment>
      <bibkey>sai-sharma-2021-towards</bibkey>
      <pwccode url="https://github.com/sivaandme/tolidl_dravidianlangtech_eacl_2021" additional="false">sivaandme/tolidl_dravidianlangtech_eacl_2021</pwccode>
    </paper>
    <paper id="4">
      <title>Sentiment Classification of Code-Mixed Tweets using Bi-Directional RNN and Language Tags<fixed-case>RNN</fixed-case> and Language Tags</title>
      <author><first>Sainik</first><last>Mahata</last></author>
      <author><first>Dipankar</first><last>Das</last></author>
      <author><first>Sivaji</first><last>Bandyopadhyay</last></author>
      <pages>28–35</pages>
      <abstract>Sentiment analysis tools and <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> have been developed extensively throughout the years, for <a href="https://en.wikipedia.org/wiki/Languages_of_Europe">European languages</a>. In contrast, similar <a href="https://en.wikipedia.org/wiki/Tool">tools</a> for <a href="https://en.wikipedia.org/wiki/Languages_of_India">Indian Languages</a> are scarce. This is because, state-of-the-art pre-processing tools like POS tagger, shallow parsers, etc., are not readily available for <a href="https://en.wikipedia.org/wiki/Languages_of_India">Indian languages</a>. Although, such working tools for Indian languages, like <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a> and <a href="https://en.wikipedia.org/wiki/Bengali_language">Bengali</a>, that are spoken by the majority of the population, are available, finding the same for less spoken languages like, <a href="https://en.wikipedia.org/wiki/Tamil_language">Tamil</a>, <a href="https://en.wikipedia.org/wiki/Telugu_language">Telugu</a>, and <a href="https://en.wikipedia.org/wiki/Malayalam">Malayalam</a>, is difficult. Moreover, due to the advent of <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>, the multi-lingual population of India, who are comfortable with both <a href="https://en.wikipedia.org/wiki/English_language">English</a> ad their regional language, prefer to communicate by mixing both languages. This gives rise to massive code-mixed content and automatically annotating them with their respective sentiment labels becomes a challenging task. In this work, we take up a similar challenge of developing a <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis model</a> that can work with English-Tamil code-mixed data. The proposed work tries to solve this by using bi-directional LSTMs along with <a href="https://en.wikipedia.org/wiki/Tag_(metadata)">language tagging</a>. Other traditional methods, based on classical machine learning algorithms have also been discussed in the literature, and they also act as the baseline systems to which we will compare our Neural Network based model. The performance of the developed <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a>, based on Neural Network architecture, garnered <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">precision</a>, <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall</a>, and F1 scores of 0.59, 0.66, and 0.58 respectively.</abstract>
      <url hash="c9f9f121">2021.dravidianlangtech-1.4</url>
      <attachment type="Software" hash="f31cfd86">2021.dravidianlangtech-1.4.Software.zip</attachment>
      <bibkey>mahata-etal-2021-sentiment</bibkey>
    </paper>
    <paper id="11">
      <title>Task-Oriented Dialog Systems for Dravidian Languages<fixed-case>D</fixed-case>ravidian Languages</title>
      <author><first>Tushar</first><last>Kanakagiri</last></author>
      <author><first>Karthik</first><last>Radhakrishnan</last></author>
      <pages>85–93</pages>
      <abstract>Task-oriented dialog systems help a user achieve a particular goal by parsing user requests to execute a particular action. These systems typically require copious amounts of training data to effectively understand the user intent and its corresponding slots. Acquiring large training corpora requires significant manual effort in annotation, rendering its construction infeasible for low-resource languages. In this paper, we present a two-step approach for automatically constructing task-oriented dialogue data in such <a href="https://en.wikipedia.org/wiki/Programming_language">languages</a> by making use of annotated data from high resource languages. First, we use a machine translation (MT) system to translate the utterance and slot information to the target language. Second, we use token prefix matching and mBERT based semantic matching to align the slot tokens to the corresponding tokens in the utterance. We hand-curate a new test dataset in two low-resource Dravidian languages and show the significance and impact of our training dataset construction using a state-of-the-art mBERT model-achieving a Slot F1 of 81.51 (Kannada) and 78.82 (Tamil) on our test sets.</abstract>
      <url hash="9a041745">2021.dravidianlangtech-1.11</url>
      <attachment type="Software" hash="4029e3a8">2021.dravidianlangtech-1.11.Software.zip</attachment>
      <bibkey>kanakagiri-radhakrishnan-2021-task</bibkey>
    </paper>
    <paper id="12">
      <title>A Survey on <a href="https://en.wikipedia.org/wiki/Paralinguistics">Paralinguistics</a> in Tamil Speech Processing<fixed-case>T</fixed-case>amil Speech Processing</title>
      <author><first>Anosha</first><last>Ignatius</last></author>
      <author><first>Uthayasanker</first><last>Thayasivam</last></author>
      <pages>94–99</pages>
      <abstract>Speech carries not only the semantic content but also the paralinguistic information which captures the <a href="https://en.wikipedia.org/wiki/Style_(sociolinguistics)">speaking style</a>. Speaker traits and <a href="https://en.wikipedia.org/wiki/Emotion">emotional states</a> affect how words are being spoken. The research on paralinguistic information is an emerging field in speech and language processing and it has many potential applications including <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech recognition</a>, speaker identification and verification, <a href="https://en.wikipedia.org/wiki/Emotion_recognition">emotion recognition</a> and accent recognition. Among them, there is a significant interest in <a href="https://en.wikipedia.org/wiki/Emotion_recognition">emotion recognition</a> from <a href="https://en.wikipedia.org/wiki/Speech">speech</a>. A detailed study of paralinguistic information present in speech signal and an overview of research work related to speech emotion for <a href="https://en.wikipedia.org/wiki/Tamil_language">Tamil Language</a> is presented in this paper.</abstract>
      <url hash="783d58b8">2021.dravidianlangtech-1.12</url>
      <bibkey>ignatius-thayasivam-2021-survey</bibkey>
    </paper>
    <paper id="13">
      <title>Is this Enough?-Evaluation of Malayalam Wordnet<fixed-case>M</fixed-case>alayalam <fixed-case>W</fixed-case>ordnet</title>
      <author><first>Nandu</first><last>Chandran Nair</last></author>
      <author><first>Maria-chiara</first><last>Giangregorio</last></author>
      <author><first>Fausto</first><last>Giunchiglia</last></author>
      <pages>100–108</pages>
      <abstract>Quality of a product is the degree to which a product meets the customer’s expectation, which must also be valid for the case of lexical semantic resources. Conducting a periodic evaluation of resources is essential to ensure if the resources meet a native speaker’s expectations and free from errors. This paper defines the possible mistakes in a lexical semantic resource and explains the steps applied to quantify Malayalam wordnet quality. Malayalam is one of the classical languages of India. We hope to subset the less quality part of the <a href="https://en.wikipedia.org/wiki/Wordnet">wordnet</a> and perform <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourcing</a> to make it better.</abstract>
      <url hash="c0828890">2021.dravidianlangtech-1.13</url>
      <attachment type="Software" hash="ce1a16a2">2021.dravidianlangtech-1.13.Software.zip</attachment>
      <bibkey>chandran-nair-etal-2021-enough</bibkey>
    </paper>
    <paper id="14">
      <title>LA-SACo : A Study of Learning Approaches for Sentiments Analysis inCode-Mixing Texts<fixed-case>LA</fixed-case>-<fixed-case>SAC</fixed-case>o: A Study of Learning Approaches for Sentiments Analysis in<fixed-case>C</fixed-case>ode-Mixing Texts</title>
      <author><first>Fazlourrahman</first><last>Balouchzahi</last></author>
      <author><first>H L</first><last>Shashirekha</last></author>
      <pages>109–118</pages>
      <abstract>Substantial amount of text data which is increasingly being generated and shared on the internet and <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> every second affect the society positively or negatively almost in any aspect of online world and also business and industries. Sentiments / opinions / reviews’ of users posted on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> are the valuable information that have motivated researchers to analyze them to get better insight and feedbacks about any product such as a video in <a href="https://en.wikipedia.org/wiki/Instagram">Instagram</a>, a movie in <a href="https://en.wikipedia.org/wiki/Netflix">Netflix</a>, or even new brand car introduced by BMW. Sentiments are usually written using a combination of languages such as <a href="https://en.wikipedia.org/wiki/English_language">English</a> which is resource rich and regional languages such as <a href="https://en.wikipedia.org/wiki/Tamil_language">Tamil</a>, <a href="https://en.wikipedia.org/wiki/Kannada">Kannada</a>, <a href="https://en.wikipedia.org/wiki/Malayalam">Malayalam</a>, etc. which are resource poor. However, due to technical constraints, many users prefer to pen their opinions in <a href="https://en.wikipedia.org/wiki/Roman_script">Roman script</a>. These kinds of texts written in two or more languages using a common language script or different language scripts are called code-mixing texts. Code-mixed texts are increasing day-by-day with the increase in the number of users depending on various online platforms. Analyzing such texts pose a real challenge for the researchers. In view of the challenges posed by the code-mixed texts, this paper describes three proposed models namely, SACo-Ensemble, SACo-Keras, and SACo-ULMFiT using Machine Learning (ML), Deep Learning (DL), and Transfer Learning (TL) approaches respectively for the task of Sentiments Analysis in Tamil-English and Malayalam-English code-mixed texts.</abstract>
      <url hash="74b7ee63">2021.dravidianlangtech-1.14</url>
      <attachment type="Software" hash="64818c3e">2021.dravidianlangtech-1.14.Software.zip</attachment>
      <bibkey>balouchzahi-shashirekha-2021-la</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/dakshina">Dakshina</pwcdataset>
    </paper>
    <paper id="16">
      <title>Findings of the Shared Task on Troll Meme Classification in Tamil<fixed-case>T</fixed-case>amil</title>
      <author><first>Shardul</first><last>Suryawanshi</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <pages>126–132</pages>
      <abstract>The <a href="https://en.wikipedia.org/wiki/Internet">internet</a> has facilitated its user-base with a platform to communicate and express their views without any censorship. On the other hand, this <a href="https://en.wikipedia.org/wiki/Freedom_of_speech">freedom of expression</a> or <a href="https://en.wikipedia.org/wiki/Freedom_of_speech">free speech</a> can be abused by its user or a troll to demean an individual or a group. Demeaning people based on their gender, <a href="https://en.wikipedia.org/wiki/Sexual_orientation">sexual orientation</a>, religious believes or any other characteristics trolling could cause great distress in the online community. Hence, the content posted by a <a href="https://en.wikipedia.org/wiki/Internet_troll">troll</a> needs to be identified and dealt with before causing any more damage. Amongst all the forms of troll content, <a href="https://en.wikipedia.org/wiki/Meme">memes</a> are most prevalent due to their popularity and ability to propagate across cultures. A <a href="https://en.wikipedia.org/wiki/Internet_troll">troll</a> uses a <a href="https://en.wikipedia.org/wiki/Internet_meme">meme</a> to demean, attack or offend its targetted audience. In this shared task, we provide a resource (TamilMemes) that could be used to train a system capable of identifying a troll meme in the <a href="https://en.wikipedia.org/wiki/Tamil_language">Tamil language</a>. In our TamilMemes dataset, each meme has been categorized into either a <a href="https://en.wikipedia.org/wiki/Internet_troll">troll</a> or a not_troll class. Along with the meme images, we also provided the Latin transcripted text from memes. We received 10 system submissions from the participants which were evaluated using the weighted average F1-score. The <a href="https://en.wikipedia.org/wiki/System">system</a> with the weighted average F1-score of 0.55 secured the first rank.</abstract>
      <url hash="add32867">2021.dravidianlangtech-1.16</url>
      <bibkey>suryawanshi-chakravarthi-2021-findings</bibkey>
    </paper>
    <paper id="17">
      <title>Findings of the Shared Task on Offensive Language Identification in <a href="https://en.wikipedia.org/wiki/Tamil_language">Tamil</a>, <a href="https://en.wikipedia.org/wiki/Malayalam">Malayalam</a>, and <a href="https://en.wikipedia.org/wiki/Kannada">Kannada</a><fixed-case>T</fixed-case>amil, <fixed-case>M</fixed-case>alayalam, and <fixed-case>K</fixed-case>annada</title>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <author><first>Ruba</first><last>Priyadharshini</last></author>
      <author><first>Navya</first><last>Jose</last></author>
      <author><first>Anand</first><last>Kumar M</last></author>
      <author><first>Thomas</first><last>Mandl</last></author>
      <author><first>Prasanna Kumar</first><last>Kumaresan</last></author>
      <author><first>Rahul</first><last>Ponnusamy</last></author>
      <author><first>Hariharan</first><last>R L</last></author>
      <author><first>John P.</first><last>McCrae</last></author>
      <author><first>Elizabeth</first><last>Sherly</last></author>
      <pages>133–145</pages>
      <abstract>Detecting <a href="https://en.wikipedia.org/wiki/Profanity">offensive language</a> in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> in <a href="https://en.wikipedia.org/wiki/Language_localisation">local languages</a> is critical for moderating user-generated content. Thus, the field of offensive language identification in under-resourced Tamil, <a href="https://en.wikipedia.org/wiki/Malayalam">Malayalam</a> and <a href="https://en.wikipedia.org/wiki/Kannada">Kannada languages</a> are essential. As the <a href="https://en.wikipedia.org/wiki/User-generated_content">user-generated content</a> is more code-mixed and not well studied for under-resourced languages, it is imperative to create resources and conduct benchmarking studies to encourage research in under-resourced Dravidian languages. We created a shared task on offensive language detection in <a href="https://en.wikipedia.org/wiki/Dravidian_languages">Dravidian languages</a>. We summarize here the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> for this challenge which are openly available at https://competitions.codalab.org/competitions/27654, and present an overview of the <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">methods</a> and the results of the competing systems.</abstract>
      <url hash="f1a38b6e">2021.dravidianlangtech-1.17</url>
      <bibkey>chakravarthi-etal-2021-findings-shared</bibkey>
    </paper>
    <paper id="18">
      <title>GX@DravidianLangTech-EACL2021 : Multilingual Neural Machine Translation and <a href="https://en.wikipedia.org/wiki/Back-translation">Back-translation</a><fixed-case>GX</fixed-case>@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>EACL</fixed-case>2021: Multilingual Neural Machine Translation and Back-translation</title>
      <author><first>Wanying</first><last>Xie</last></author>
      <pages>146–153</pages>
      <abstract>In this paper, we describe the GX system in the EACL2021 shared task on machine translation in <a href="https://en.wikipedia.org/wiki/Dravidian_languages">Dravidian languages</a>. Given the low amount of parallel training data, We adopt two methods to improve the overall performance : (1) multilingual translation, we use a shared encoder-decoder multilingual translation model handling multiple languages simultaneously to facilitate the translation performance of these languages ; (2) back-translation, we collected other open-source parallel and monolingual data and apply back-translation to benefit from the monolingual data. The experimental results show that we can achieve satisfactory <a href="https://en.wikipedia.org/wiki/Translation">translation</a> results in these <a href="https://en.wikipedia.org/wiki/Dravidian_languages">Dravidian languages</a> and rank first in English-Telugu and Tamil-Telugu translation.</abstract>
      <url hash="0f7d597e">2021.dravidianlangtech-1.18</url>
      <attachment type="Software" hash="c00cd1d1">2021.dravidianlangtech-1.18.Software.zip</attachment>
      <attachment type="Dataset" hash="3df2f2ff">2021.dravidianlangtech-1.18.Dataset.zip</attachment>
      <bibkey>xie-2021-gx</bibkey>
    </paper>
    <paper id="20">
      <title>Simon @ DravidianLangTech-EACL2021 : Detecting Offensive Content in Kannada Language<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>EACL</fixed-case>2021: Detecting Offensive Content in <fixed-case>K</fixed-case>annada Language</title>
      <author><first>Qinyu</first><last>Que</last></author>
      <pages>160–163</pages>
      <abstract>This article introduces the system for the shared task of Offensive Language Identification in Dravidian Languages-EACL 2021. The world’s information technology develops at a high speed. People are used to expressing their views and opinions on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. This leads to a lot of <a href="https://en.wikipedia.org/wiki/Profanity">offensive language</a> on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. As people become more dependent on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>, the detection of offensive language becomes more and more necessary. This shared task is in three languages : <a href="https://en.wikipedia.org/wiki/Tamil_language">Tamil</a>, <a href="https://en.wikipedia.org/wiki/Malayalam">Malayalam</a>, and <a href="https://en.wikipedia.org/wiki/Kannada">Kannada</a>. Our team takes part in the Kannada language task. To accomplish the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, we use the XLM-Roberta model for pre-training. But the capabilities of the XLM-Roberta model do not satisfy us in terms of statement information collection. So we made some tweaks to the output of this <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>. In this paper, we describe the <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> and experiments for accomplishing the task of the <a href="https://en.wikipedia.org/wiki/Kannada">Kannada language</a>.</abstract>
      <url hash="949b9d6b">2021.dravidianlangtech-1.20</url>
      <attachment type="Software" hash="cacbc4a0">2021.dravidianlangtech-1.20.Software.zip</attachment>
      <bibkey>que-2021-simon</bibkey>
    </paper>
    <paper id="26">
      <title>Hypers@DravidianLangTech-EACL2021 : Offensive language identification in Dravidian code-mixed YouTube Comments and Posts<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>EACL</fixed-case>2021: Offensive language identification in <fixed-case>D</fixed-case>ravidian code-mixed <fixed-case>Y</fixed-case>ou<fixed-case>T</fixed-case>ube Comments and Posts</title>
      <author><first>Charangan</first><last>Vasantharajan</last></author>
      <author><first>Uthayasanker</first><last>Thayasivam</last></author>
      <pages>195–202</pages>
      <abstract>Code-Mixed Offensive contents are used pervasively in social media posts in the last few years. Consequently, gained the significant attraction of the research community for identifying the different forms of such <a href="https://en.wikipedia.org/wiki/Content_(media)">content</a> (e.g., <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a>, and sentiments) and contributed to the creation of datasets. Most of the recent studies deal with high-resource languages (e.g., English) due to many publicly available datasets, and by the lack of dataset in low-resource anguages, those studies are slightly involved in these <a href="https://en.wikipedia.org/wiki/Language">languages</a>. Therefore, this study has the focus on offensive language identification on code-mixed low-resourced Dravidian languages such as <a href="https://en.wikipedia.org/wiki/Tamil_language">Tamil</a>, <a href="https://en.wikipedia.org/wiki/Kannada">Kannada</a>, and <a href="https://en.wikipedia.org/wiki/Malayalam">Malayalam</a> using the bidirectional approach and fine-tuning strategies. According to the leaderboard, the proposed model got a 0.96 <a href="https://en.wikipedia.org/wiki/FIVB_World_Rankings">F1-score</a> for <a href="https://en.wikipedia.org/wiki/Malayalam">Malayalam</a>, 0.73 <a href="https://en.wikipedia.org/wiki/FIVB_World_Rankings">F1-score</a> for <a href="https://en.wikipedia.org/wiki/Tamil_language">Tamil</a>, and 0.70 <a href="https://en.wikipedia.org/wiki/FIVB_World_Rankings">F1-score</a> for <a href="https://en.wikipedia.org/wiki/Kannada">Kannada</a> in the bench-mark. Moreover, in the view of multilingual models, this modal ranked 3rd and achieved favorable results and confirmed the model as the best among all systems submitted to these shared tasks in these three languages.</abstract>
      <url hash="0b747938">2021.dravidianlangtech-1.26</url>
      <attachment type="Software" hash="3abd65e7">2021.dravidianlangtech-1.26.Software.zip</attachment>
      <bibkey>vasantharajan-thayasivam-2021-hypers</bibkey>
    </paper>
    <paper id="29">
      <title>ZYJ123@DravidianLangTech-EACL2021 : Offensive Language Identification based on XLM-RoBERTa with DPCNN<fixed-case>ZYJ</fixed-case>123@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>EACL</fixed-case>2021: Offensive Language Identification based on <fixed-case>XLM</fixed-case>-<fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a with <fixed-case>DPCNN</fixed-case></title>
      <author><first>Yingjia</first><last>Zhao</last></author>
      <author><first>Xin</first><last>Tao</last></author>
      <pages>216–221</pages>
      <abstract>The development of online media platforms has given users more opportunities to post and comment freely, but the negative impact of <a href="https://en.wikipedia.org/wiki/Profanity">offensive language</a> has become increasingly apparent. It is very necessary for the automatic identification system of offensive language. This paper describes our work on the task of Offensive Language Identification in Dravidian language-EACL 2021. To complete this task, we propose a <a href="https://en.wikipedia.org/wiki/System">system</a> based on the multilingual model XLM-Roberta and DPCNN. The test results on the official test data set confirm the effectiveness of our <a href="https://en.wikipedia.org/wiki/System">system</a>. The <a href="https://en.wikipedia.org/wiki/Weighted_arithmetic_mean">weighted average F1-score</a> of <a href="https://en.wikipedia.org/wiki/Kannada">Kannada</a>, <a href="https://en.wikipedia.org/wiki/Malayalam">Malayalam</a>, and <a href="https://en.wikipedia.org/wiki/Tami_language">Tami language</a> are 0.69, 0.92, and 0.76 respectively, ranked 6th, 6th, and 3rd</abstract>
      <url hash="155ffbbb">2021.dravidianlangtech-1.29</url>
      <attachment type="Software" hash="adbbfa1f">2021.dravidianlangtech-1.29.Software.zip</attachment>
      <bibkey>zhao-tao-2021-zyj123</bibkey>
    </paper>
    <paper id="32">
      <title>CUSATNLP@DravidianLangTech-EACL2021 : Language Agnostic Classification of Offensive Content in Tweets<fixed-case>CUSATNLP</fixed-case>@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>EACL</fixed-case>2021:Language Agnostic Classification of Offensive Content in Tweets</title>
      <author><first>Sara</first><last>Renjit</last></author>
      <author><first>Sumam Mary</first><last>Idicula</last></author>
      <pages>236–242</pages>
      <abstract>Identifying offensive information from <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> is a vital <a href="https://en.wikipedia.org/wiki/Language_processing_in_the_brain">language processing task</a>. This task concentrated more on <a href="https://en.wikipedia.org/wiki/English_language">English</a> and other foreign languages these days. In this shared task on Offensive Language Identification in <a href="https://en.wikipedia.org/wiki/Dravidian_languages">Dravidian Languages</a>, in the First Workshop of Speech and Language Technologies for <a href="https://en.wikipedia.org/wiki/Dravidian_languages">Dravidian Languages</a> in EACL 2021, the aim is to identify offensive content from code mixed Dravidian Languages Kannada, Malayalam, and Tamil. Our team used language agnostic BERT (Bidirectional Encoder Representation from Transformers) for <a href="https://en.wikipedia.org/wiki/Sentence_embedding">sentence embedding</a> and a Softmax classifier. The language-agnostic representation based classification helped obtain good performance for all the three languages, out of which results for the <a href="https://en.wikipedia.org/wiki/Malayalam">Malayalam language</a> are good enough to obtain a third position among the participating teams.</abstract>
      <url hash="a51816d3">2021.dravidianlangtech-1.32</url>
      <attachment type="Software" hash="b1886780">2021.dravidianlangtech-1.32.Software.zip</attachment>
      <bibkey>renjit-idicula-2021-cusatnlp</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/olid">OLID</pwcdataset>
    </paper>
    <paper id="40">
      <title>Maoqin @ DravidianLangTech-EACL2021 : The Application of Transformer-Based Model<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>EACL</fixed-case>2021: The Application of Transformer-Based Model</title>
      <author><first>Maoqin</first><last>Yang</last></author>
      <pages>281–286</pages>
      <abstract>This paper describes the result of team-Maoqin at DravidianLangTech-EACL2021. The provided task consists of three languages(Tamil, Malayalam, and Kannada), I only participate in one of the language task-Malayalam. The goal of this task is to identify offensive language content of the code-mixed dataset of comments / posts in Dravidian Languages (Tamil-English, Malayalam-English, and Kannada-English) collected from <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. This is a <a href="https://en.wikipedia.org/wiki/Comparison_and_contrast_of_classification_schemes_in_linguistics_and_metadata">classification task</a> at the comment / post level. Given a Youtube comment, systems have to classify it into Not-offensive, Offensive-untargeted, Offensive-targeted-individual, Offensive-targeted-group, Offensive-targeted-other, or Not-in-indented-language. I use the transformer-based language model with BiGRU-Attention to complete this task. To prove the validity of the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>, I also use some other neural network models for comparison. And finally, the team ranks 5th in this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> with a weighted average F1 score of 0.93 on the private leader board.</abstract>
      <url hash="82c26192">2021.dravidianlangtech-1.40</url>
      <attachment type="Software" hash="13ddadaf">2021.dravidianlangtech-1.40.Software.zip</attachment>
      <attachment type="Dataset" hash="6a0cfa42">2021.dravidianlangtech-1.40.Dataset.zip</attachment>
      <bibkey>yang-2021-maoqin</bibkey>
    </paper>
    <paper id="41">
      <title>Simon @ DravidianLangTech-EACL2021 : Meme Classification for Tamil with BERT<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>EACL</fixed-case>2021: Meme Classification for <fixed-case>T</fixed-case>amil with <fixed-case>BERT</fixed-case></title>
      <author><first>Qinyu</first><last>Que</last></author>
      <pages>287–290</pages>
      <abstract>In this paper, we introduce the <a href="https://en.wikipedia.org/wiki/System">system</a> for the task of meme classification for <a href="https://en.wikipedia.org/wiki/Tamil_language">Tamil</a>, submitted by our team. In today’s society, <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> has become an important platform for people to communicate. We use <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> to share information about ourselves and express our views on things. It has gradually developed a unique form of <a href="https://en.wikipedia.org/wiki/Emotional_expression">emotional expression</a> on <a href="https://en.wikipedia.org/wiki/Internet_meme">social media   meme</a>. The <a href="https://en.wikipedia.org/wiki/Meme">meme</a> is an expression that is often ironic. This also gives the meme a unique sense of humor. But it’s not just positive content on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. There’s also a lot of <a href="https://en.wikipedia.org/wiki/Profanity">offensive content</a>. Meme’s unique expression makes <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> often used by some users to post offensive content. Therefore, it is very urgent to detect the offensive content of the meme. Our team uses the natural language processing method to classify the offensive content of the meme. Our team combines the BERT model with the CNN to improve the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>’s ability to collect statement information. Finally, the F1-score of our team in the official test set is 0.49, and our method ranks 5th.</abstract>
      <url hash="49218d9c">2021.dravidianlangtech-1.41</url>
      <attachment type="Software" hash="b1295902">2021.dravidianlangtech-1.41.Software.zip</attachment>
      <bibkey>que-2021-simon-dravidianlangtech</bibkey>
    </paper>
    <paper id="45">
      <title>SSNCSE_NLP@DravidianLangTech-EACL2021 : Offensive Language Identification on Multilingual Code Mixing Text<fixed-case>SSNCSE</fixed-case>_<fixed-case>NLP</fixed-case>@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>EACL</fixed-case>2021: Offensive Language Identification on Multilingual Code Mixing Text</title>
      <author><first>Bharathi</first><last>B</last></author>
      <author><first>Agnusimmaculate Silvia</first><last>A</last></author>
      <pages>313–318</pages>
      <abstract>Social networks made a huge impact in almost all fields in recent years. Text messaging through the <a href="https://en.wikipedia.org/wiki/Internet">Internet</a> or <a href="https://en.wikipedia.org/wiki/Mobile_phone">cellular phones</a> has become a major medium of personal and commercial communication. Everyday we have to deal with <a href="https://en.wikipedia.org/wiki/Text_messaging">texts</a>, <a href="https://en.wikipedia.org/wiki/Email">emails</a> or different types of messages in which there are a variety of attacks and abusive phrases. It is the moderator’s decision which comments to remove from the platform because of violations and which ones to keep but an automatic software for detecting abusive languages would be useful in recent days. In this paper we describe an automatic offensive language identification from <a href="https://en.wikipedia.org/wiki/Dravidian_languages">Dravidian languages</a> with various <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning algorithms</a>. This is work is shared task in DravidanLangTech-EACL2021. The goal of this task is to identify offensive language content of the code-mixed dataset of comments / posts in Dravidian Languages ((Tamil-English, Malayalam-English, and Kannada-English)) collected from <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. This work explains the submissions made by SSNCSE_NLP in DravidanLangTech-EACL2021 Code-mix tasks for Offensive language detection. We achieve F1 scores of 0.95 for <a href="https://en.wikipedia.org/wiki/Malayalam">Malayalam</a>, 0.7 for <a href="https://en.wikipedia.org/wiki/Kannada">Kannada</a> and 0.73 for task2-Tamil on the test-set.</abstract>
      <url hash="9c046cd9">2021.dravidianlangtech-1.45</url>
      <attachment type="Software" hash="1a71520a">2021.dravidianlangtech-1.45.Software.zip</attachment>
      <bibkey>b-a-2021-ssncse</bibkey>
    </paper>
    <paper id="47">
      <title>MUCS@DravidianLangTech-EACL2021 : COOLI-Code-Mixing Offensive Language Identification<fixed-case>MUCS</fixed-case>@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>EACL</fixed-case>2021:<fixed-case>COOLI</fixed-case>-Code-Mixing Offensive Language Identification</title>
      <author><first>Fazlourrahman</first><last>Balouchzahi</last></author>
      <author><first>Aparna</first><last>B K</last></author>
      <author><first>H L</first><last>Shashirekha</last></author>
      <pages>323–329</pages>
      <abstract>This paper describes the models submitted by the team MUCS for Offensive Language Identification in Dravidian Languages-EACL 2021 shared task that aims at identifying and classifying code-mixed texts of three language pairs namely, Kannada-English (Kn-En), Malayalam-English (Ma-En), and Tamil-English (Ta-En) into six predefined categories (5 categories in Ma-En language pair). Two models, namely, COOLI-Ensemble and COOLI-Keras are trained with the char sequences extracted from the sentences combined with words as features. Out of the two proposed models, COOLI-Ensemble model (best among our models) obtained first rank for Ma-En language pair with 0.97 weighted F1-score and fourth and sixth ranks with 0.75 and 0.69 weighted F1-score for Ta-En and Kn-En language pairs respectively.</abstract>
      <url hash="e3ceb3f5">2021.dravidianlangtech-1.47</url>
      <attachment type="Software" hash="fcfa40d4">2021.dravidianlangtech-1.47.Software.zip</attachment>
      <bibkey>balouchzahi-etal-2021-mucs</bibkey>
    </paper>
    <paper id="51">
      <title>OffTamil@DravideanLangTech-EASL2021 : Offensive Language Identification in Tamil Text<fixed-case>O</fixed-case>ff<fixed-case>T</fixed-case>amil@<fixed-case>D</fixed-case>ravidean<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>EASL</fixed-case>2021: Offensive Language Identification in <fixed-case>T</fixed-case>amil Text</title>
      <author><first>Disne</first><last>Sivalingam</last></author>
      <author><first>Sajeetha</first><last>Thavareesan</last></author>
      <pages>346–351</pages>
      <abstract>In the last few decades, Code-Mixed Offensive texts are used penetratingly in social media posts. Social media platforms and <a href="https://en.wikipedia.org/wiki/Online_community">online communities</a> showed much interest on offensive text identification in recent years. Consequently, research community is also interested in identifying such content and also contributed to the development of corpora. Many publicly available corpora are there for research on identifying offensive text written in <a href="https://en.wikipedia.org/wiki/English_language">English language</a> but rare for low resourced languages like <a href="https://en.wikipedia.org/wiki/Tamil_language">Tamil</a>. The first code-mixed offensive text for <a href="https://en.wikipedia.org/wiki/Dravidian_languages">Dravidian languages</a> are developed by shared task organizers which is used for this study. This study focused on offensive language identification on code-mixed low-resourced Dravidian language Tamil using four classifiers (Support Vector Machine, random forest, k- Nearest Neighbour and Naive Bayes) using chi2 feature selection technique along with BoW and TF-IDF feature representation techniques using different combinations of n-grams. This proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieved an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 76.96 % while using linear SVM with TF-IDF feature representation technique.</abstract>
      <url hash="6d5562be">2021.dravidianlangtech-1.51</url>
      <bibkey>sivalingam-thavareesan-2021-offtamil</bibkey>
    </paper>
    </volume>
</collection>