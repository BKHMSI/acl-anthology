<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.deelio">
  <volume id="1" ingest-date="2020-11-06">
    <meta>
      <booktitle>Proceedings of Deep Learning Inside Out (DeeLIO): The First Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</booktitle>
      <editor><first>Eneko</first><last>Agirre</last></editor>
      <editor><first>Marianna</first><last>Apidianaki</last></editor>
      <editor><first>Ivan</first><last>Vulić</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>November</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="ebbcf132">2020.deelio-1.0</url>
      <bibkey>deelio-2020-deep</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Generalization to Mitigate Synonym Substitution Attacks</title>
      <author><first>Basemah</first><last>Alshemali</last></author>
      <author><first>Jugal</first><last>Kalita</last></author>
      <pages>20–28</pages>
      <abstract>Studies have shown that deep neural networks (DNNs) are vulnerable to adversarial examples   perturbed inputs that cause DNN-based models to produce incorrect results. One robust adversarial attack in the NLP domain is the synonym substitution. In attacks of this variety, the adversary substitutes words with <a href="https://en.wikipedia.org/wiki/Synonym">synonyms</a>. Since synonym substitution perturbations aim to satisfy all lexical, grammatical, and semantic constraints, they are difficult to detect with automatic syntax check as well as by humans. In this paper, we propose a structure-free defensive method that is capable of improving the performance of DNN-based models with both clean and adversarial data. Our findings show that replacing the embeddings of the important words in the input samples with the average of their synonyms’ embeddings can significantly improve the generalization of DNN-based classifiers. By doing so, we reduce <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">model sensitivity</a> to particular words in the input samples. Our results indicate that the proposed defense is not only capable of defending against adversarial attacks, but is also capable of improving the performance of DNN-based models when tested on benign data. On average, the proposed defense improved the classification accuracy of the CNN and Bi-LSTM models by 41.30 % and 55.66 %, respectively, when tested under adversarial attacks. Extended investigation shows that our defensive method can improve the robustness of nonneural models, achieving an average of 17.62 % and 22.93 % classification accuracy increase on the SVM and XGBoost models, respectively. The proposed defensive method has also shown an average of 26.60 % <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification accuracy</a> improvement when tested with the infamous BERT model.</abstract>
      <url hash="d831f583">2020.deelio-1.3</url>
      <doi>10.18653/v1/2020.deelio-1.3</doi>
      <video href="https://slideslive.com/38939726" />
      <bibkey>alshemali-kalita-2020-generalization</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
    </paper>
    </volume>
</collection>