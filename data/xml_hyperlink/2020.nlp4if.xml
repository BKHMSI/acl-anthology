<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.nlp4if">
  <volume id="1" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the 3rd NLP4IF Workshop on NLP for Internet Freedom: Censorship, Disinformation, and Propaganda</booktitle>
      <editor><first>Giovanni</first><last>Da San Martino</last></editor>
      <editor><first>Chris</first><last>Brew</last></editor>
      <editor><first>Giovanni Luca</first><last>Ciampaglia</last></editor>
      <editor><first>Anna</first><last>Feldman</last></editor>
      <editor><first>Chris</first><last>Leberknight</last></editor>
      <editor><first>Preslav</first><last>Nakov</last></editor>
      <publisher>International Committee on Computational Linguistics (ICCL)</publisher>
      <address>Barcelona, Spain (Online)</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="6daf5611">2020.nlp4if-1.0</url>
      <bibkey>nlp4if-2020-nlp4if</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Two Stage Transformer Model for COVID-19 Fake News Detection and Fact Checking<fixed-case>COVID</fixed-case>-19 Fake News Detection and Fact Checking</title>
      <author><first>Rutvik</first><last>Vijjali</last></author>
      <author><first>Prathyush</first><last>Potluri</last></author>
      <author><first>Siddharth</first><last>Kumar</last></author>
      <author><first>Sundeep</first><last>Teki</last></author>
      <pages>1–10</pages>
      <abstract>The rapid advancement of technology in <a href="https://en.wikipedia.org/wiki/Online_communication">online communication</a> via <a href="https://en.wikipedia.org/wiki/Social_media">social media platforms</a> has led to a prolific rise in the spread of <a href="https://en.wikipedia.org/wiki/Misinformation">misinformation</a> and <a href="https://en.wikipedia.org/wiki/Fake_news">fake news</a>. Fake news is especially rampant in the current COVID-19 pandemic, leading to people believing in false and potentially harmful claims and stories. Detecting <a href="https://en.wikipedia.org/wiki/Fake_news">fake news</a> quickly can alleviate the spread of panic, chaos and potential health hazards. We developed a two stage automated pipeline for COVID-19 fake news detection using state of the art <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning models</a> for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. The first <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> leverages a novel <a href="https://en.wikipedia.org/wiki/Fact-checking">fact checking algorithm</a> that retrieves the most relevant facts concerning user queries about particular COVID-19 claims. The second model verifies the level of truth in the queried claim by computing the textual entailment between the claim and the true facts retrieved from a manually curated COVID-19 dataset. The dataset is based on a publicly available knowledge source consisting of more than 5000 COVID-19 false claims and verified explanations, a subset of which was internally annotated and cross-validated to train and evaluate our models. We evaluate a series of <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> based on classical text-based features to more contextual Transformer based models and observe that a model pipeline based on BERT and ALBERT for the two stages respectively yields the best results.</abstract>
      <url hash="6a49755e">2020.nlp4if-1.1</url>
      <bibkey>vijjali-etal-2020-two</bibkey>
      <pwccode url="https://github.com/rutvikvijjali/COVID-19-Claims-Dataset" additional="false">rutvikvijjali/COVID-19-Claims-Dataset</pwccode>
    </paper>
    <paper id="2">
      <title>Measuring Alignment to Authoritarian State Media as Framing Bias</title>
      <author><first>Timothy</first><last>Niven</last></author>
      <author><first>Hung-Yu</first><last>Kao</last></author>
      <pages>11–21</pages>
      <abstract>We introduce what is to the best of our knowledge a new task in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> : measuring alignment to authoritarian state media. We operationalize alignment in terms of sociological definitions of <a href="https://en.wikipedia.org/wiki/Media_bias">media bias</a>. We take as a case study the alignment of four <a href="https://en.wikipedia.org/wiki/Media_of_Taiwan">Taiwanese media outlets</a> to the <a href="https://en.wikipedia.org/wiki/State_media">Chinese Communist Party state media</a>. We present the results of an initial investigation using the frequency of words in psychologically meaningful categories. Our findings suggest that the chosen word categories correlate with <a href="https://en.wikipedia.org/wiki/Framing_(social_sciences)">framing choices</a>. We develop a calculation method that yields reasonable results for measuring <a href="https://en.wikipedia.org/wiki/Sequence_alignment">alignment</a>, agreeing well with the known labels. We confirm that our method does capture event selection bias, but whether it captures <a href="https://en.wikipedia.org/wiki/Framing_bias">framing bias</a> requires further investigation.</abstract>
      <url hash="08146601">2020.nlp4if-1.2</url>
      <bibkey>niven-kao-2020-measuring</bibkey>
      <pwccode url="https://github.com/doublethinklab/nlp4if2020p" additional="false">doublethinklab/nlp4if2020p</pwccode>
    </paper>
    </volume>
</collection>