<?xml version='1.0' encoding='utf-8'?>
<collection id="S18">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of The 12th International Workshop on Semantic Evaluation</booktitle>
      <url hash="aca7e30c">S18-1</url>
      <editor><first>Marianna</first> <last>Apidianaki</last></editor>
      <editor><first>Saif M.</first> <last>Mohammad</last></editor>
      <editor><first>Jonathan</first> <last>May</last></editor>
      <editor><first>Ekaterina</first> <last>Shutova</last></editor>
      <editor><first>Steven</first> <last>Bethard</last></editor>
      <editor><first>Marine</first> <last>Carpuat</last></editor>
      <doi>10.18653/v1/S18-1</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>New Orleans, Louisiana</address>
      <month>June</month>
      <year>2018</year>
    </meta>
    <frontmatter>
      <url hash="2d27ee37">S18-1000</url>
      <bibkey>semeval-2018-international</bibkey>
    </frontmatter>
    <paper id="1">
      <title>SemEval-2018 Task 1 : Affect in Tweets<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Affect in Tweets</title>
      <author><first>Saif</first> <last>Mohammad</last></author>
      <author><first>Felipe</first> <last>Bravo-Marquez</last></author>
      <author><first>Mohammad</first> <last>Salameh</last></author>
      <author><first>Svetlana</first> <last>Kiritchenko</last></author>
      <pages>1–17</pages>
      <abstract>We present the SemEval-2018 Task 1 : Affect in Tweets, which includes an array of subtasks on inferring the affectual state of a person from their tweet. For each <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, we created labeled data from <a href="https://en.wikipedia.org/wiki/English_language">English</a>, Arabic, and Spanish tweets. The individual tasks are : 1. emotion intensity regression, 2. emotion intensity ordinal classification, 3. valence (sentiment) regression, 4. valence ordinal classification, and 5. <a href="https://en.wikipedia.org/wiki/Emotion_classification">emotion classification</a>. Seventy-five teams (about 200 team members) participated in the shared task. We summarize the <a href="https://en.wikipedia.org/wiki/Methodology">methods</a>, resources, and tools used by the participating teams, with a focus on the techniques and resources that are particularly useful. We also analyze <a href="https://en.wikipedia.org/wiki/System">systems</a> for consistent bias towards a particular race or gender. The data is made freely available to further improve our understanding of how people convey emotions through language.</abstract>
      <attachment type="note" hash="b776485c">S18-1001.Notes.pdf</attachment>
      <url hash="95040a83">S18-1001</url>
      <doi>10.18653/v1/S18-1001</doi>
      <bibkey>mohammad-etal-2018-semeval</bibkey>
    </paper>
    <paper id="2">
      <title>SeerNet at SemEval-2018 Task 1 : Domain Adaptation for Affect in Tweets<fixed-case>S</fixed-case>eer<fixed-case>N</fixed-case>et at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Domain Adaptation for Affect in Tweets</title>
      <author><first>Venkatesh</first> <last>Duppada</last></author>
      <author><first>Royal</first> <last>Jain</last></author>
      <author><first>Sushant</first> <last>Hiray</last></author>
      <pages>18–23</pages>
      <abstract>The paper describes the best performing <a href="https://en.wikipedia.org/wiki/System">system</a> for the SemEval-2018 Affect in Tweets(English) sub-tasks. The system focuses on the <a href="https://en.wikipedia.org/wiki/Ordinal_data">ordinal classification</a> and regression sub-tasks for <a href="https://en.wikipedia.org/wiki/Valence_(psychology)">valence</a> and <a href="https://en.wikipedia.org/wiki/Emotion">emotion</a>. For ordinal classification valence is classified into 7 different classes ranging from -3 to 3 whereas <a href="https://en.wikipedia.org/wiki/Emotion">emotion</a> is classified into 4 different classes 0 to 3 separately for each <a href="https://en.wikipedia.org/wiki/Emotion">emotion</a> namely <a href="https://en.wikipedia.org/wiki/Anger">anger</a>, <a href="https://en.wikipedia.org/wiki/Fear">fear</a>, joy and sadness. The <a href="https://en.wikipedia.org/wiki/Regression_analysis">regression sub-tasks</a> estimate the <a href="https://en.wikipedia.org/wiki/Valence_(psychology)">intensity of valence</a> and each <a href="https://en.wikipedia.org/wiki/Emotion">emotion</a>. The <a href="https://en.wikipedia.org/wiki/System">system</a> performs <a href="https://en.wikipedia.org/wiki/Domain_adaptation">domain adaptation</a> of 4 different models and creates an <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble</a> to give the final prediction. The proposed <a href="https://en.wikipedia.org/wiki/System">system</a> achieved 1stposition out of 75 teams which participated in the fore-mentioned sub-tasks. We outperform the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline model</a> by margins ranging from 49.2 % to 76.4 %, thus, pushing the state-of-the-art significantly.</abstract>
      <url hash="8dc38e23">S18-1002</url>
      <doi>10.18653/v1/S18-1002</doi>
      <bibkey>duppada-etal-2018-seernet</bibkey>
    </paper>
    <paper id="3">
      <title>SemEval 2018 Task 2 : Multilingual Emoji Prediction<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val 2018 Task 2: Multilingual Emoji Prediction</title>
      <author><first>Francesco</first> <last>Barbieri</last></author>
      <author><first>Jose</first> <last>Camacho-Collados</last></author>
      <author><first>Francesco</first> <last>Ronzano</last></author>
      <author><first>Luis</first> <last>Espinosa-Anke</last></author>
      <author><first>Miguel</first> <last>Ballesteros</last></author>
      <author><first>Valerio</first> <last>Basile</last></author>
      <author><first>Viviana</first> <last>Patti</last></author>
      <author><first>Horacio</first> <last>Saggion</last></author>
      <pages>24–33</pages>
      <abstract>This paper describes the results of the first Shared Task on Multilingual Emoji Prediction, organized as part of SemEval 2018. Given the text of a tweet, the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> consists of predicting the most likely <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a> to be used along such tweet. Two <a href="https://en.wikipedia.org/wiki/Task_(project_management)">subtasks</a> were proposed, one for <a href="https://en.wikipedia.org/wiki/English_language">English</a> and one for <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, and participants were allowed to submit a <a href="https://en.wikipedia.org/wiki/System">system</a> run to one or both <a href="https://en.wikipedia.org/wiki/Task_(project_management)">subtasks</a>. In total, 49 teams participated to the <a href="https://en.wikipedia.org/wiki/English_language">English subtask</a> and 22 teams submitted a <a href="https://en.wikipedia.org/wiki/System">system</a> run to the <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish subtask</a>. Evaluation was carried out emoji-wise, and the final <a href="https://en.wikipedia.org/wiki/Ranking">ranking</a> was based on macro F-Score. Data and further information about this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> can be found at.<url>https://competitions.codalab.org/competitions/17344</url>.
    </abstract>
      <url hash="cb4c9b23">S18-1003</url>
      <doi>10.18653/v1/S18-1003</doi>
      <bibkey>barbieri-etal-2018-semeval</bibkey>
    </paper>
    <paper id="4">
      <title>Tbingen-Oslo at SemEval-2018 Task 2 : SVMs perform better than RNNs in Emoji Prediction<fixed-case>T</fixed-case>übingen-<fixed-case>O</fixed-case>slo at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: <fixed-case>SVM</fixed-case>s perform better than <fixed-case>RNN</fixed-case>s in Emoji Prediction</title>
      <author><first>Çağrı</first> <last>Çöltekin</last></author>
      <author><first>Taraka</first> <last>Rama</last></author>
      <pages>34–38</pages>
      <abstract>This paper describes our participation in the SemEval-2018 task Multilingual Emoji Prediction. We participated in both English and Spanish subtasks, experimenting with support vector machines (SVMs) and <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural networks</a>. Our SVM classifier obtained the top rank in both subtasks with macro-averaged F1-measures of 35.99 % for <a href="https://en.wikipedia.org/wiki/English_language">English</a> and 22.36 % for Spanish data sets. Similar to a few earlier attempts, the results with <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a> were not on par with linear SVMs.</abstract>
      <url hash="5ba5771a">S18-1004</url>
      <doi>10.18653/v1/S18-1004</doi>
      <bibkey>coltekin-rama-2018-tubingen</bibkey>
    </paper>
    <paper id="5">
      <title>SemEval-2018 Task 3 : Irony Detection in English Tweets<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Irony Detection in <fixed-case>E</fixed-case>nglish Tweets</title>
      <author><first>Cynthia</first> <last>Van Hee</last></author>
      <author><first>Els</first> <last>Lefever</last></author>
      <author><first>Véronique</first> <last>Hoste</last></author>
      <pages>39–50</pages>
      <abstract>This paper presents the first shared task on <a href="https://en.wikipedia.org/wiki/Irony">irony detection</a> : given a tweet, automatic natural language processing systems should determine whether the tweet is ironic (Task A) and which type of <a href="https://en.wikipedia.org/wiki/Irony">irony</a> (if any) is expressed (Task B). The ironic tweets were collected using irony-related hashtags (i.e. # irony, # sarcasm, # not) and were subsequently manually annotated to minimise the amount of noise in the corpus. Prior to distributing the data, <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a> that were used to collect the tweets were removed from the corpus. For both tasks, a <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training corpus</a> of 3,834 tweets was provided, as well as a <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">test set</a> containing 784 tweets. Our shared tasks received submissions from 43 teams for the binary classification Task A and from 31 teams for the multiclass Task B. The highest classification scores obtained for both subtasks are respectively F1= 0.71 and F1= 0.51 and demonstrate that fine-grained irony classification is much more challenging than binary irony detection.</abstract>
      <url hash="922bb73b">S18-1005</url>
      <doi>10.18653/v1/S18-1005</doi>
      <bibkey>van-hee-etal-2018-semeval</bibkey>
    </paper>
    <paper id="6">
      <title>THU_NGN at SemEval-2018 Task 3 : Tweet Irony Detection with Densely connected LSTM and Multi-task Learning<fixed-case>THU</fixed-case>_<fixed-case>NGN</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Tweet Irony Detection with Densely connected <fixed-case>LSTM</fixed-case> and Multi-task Learning</title>
      <author><first>Chuhan</first> <last>Wu</last></author>
      <author><first>Fangzhao</first> <last>Wu</last></author>
      <author><first>Sixing</first> <last>Wu</last></author>
      <author><first>Junxin</first> <last>Liu</last></author>
      <author><first>Zhigang</first> <last>Yuan</last></author>
      <author><first>Yongfeng</first> <last>Huang</last></author>
      <pages>51–56</pages>
      <abstract>Detecting irony is an important task to mine fine-grained information from social web messages. Therefore, the Semeval-2018 task 3 is aimed to detect the ironic tweets (subtask A) and their ironic types (subtask B). In order to address this task, we propose a <a href="https://en.wikipedia.org/wiki/System">system</a> based on a densely connected LSTM network with multi-task learning strategy. In our dense LSTM model, each layer will take all outputs from previous layers as input. The last LSTM layer will output the hidden representations of texts, and they will be used in three classification task. In addition, we incorporate several types of features to improve the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> performance. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieved an <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> of 70.54 (ranked 2/43) in the subtask A and 49.47 (ranked 3/29) in the subtask B. The experimental results validate the effectiveness of our <a href="https://en.wikipedia.org/wiki/System">system</a>.</abstract>
      <url hash="ee790bcf">S18-1006</url>
      <doi>10.18653/v1/S18-1006</doi>
      <bibkey>wu-etal-2018-thu</bibkey>
    </paper>
    <paper id="7">
      <title>SemEval 2018 Task 4 : Character Identification on Multiparty Dialogues<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val 2018 Task 4: Character Identification on Multiparty Dialogues</title>
      <author><first>Jinho D.</first> <last>Choi</last></author>
      <author><first>Henry Y.</first> <last>Chen</last></author>
      <pages>57–64</pages>
      <abstract>Character identification is a task of <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity linking</a> that finds the global entity of each personal mention in multiparty dialogue. For this task, the first two seasons of the popular TV show Friends are annotated, comprising a total of 448 dialogues, 15,709 mentions, and 401 entities. The personal mentions are detected from <a href="https://en.wikipedia.org/wiki/Character_(arts)">nominals</a> referring to certain characters in the show, and the <a href="https://en.wikipedia.org/wiki/Non-physical_entity">entities</a> are collected from the list of all characters in those two seasons of the show. This <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> is challenging because it requires the identification of characters that are mentioned but may not be active during the conversation. Among 90 + participants, four of them submitted their system outputs and showed strengths in different aspects about the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. Thorough analyses of the <a href="https://en.wikipedia.org/wiki/Distributed_database">distributed datasets</a>, <a href="https://en.wikipedia.org/wiki/System">system outputs</a>, and comparative studies are also provided. To facilitate the momentum, we create an open-source project for this task and publicly release a larger and cleaner dataset, hoping to support researchers for more enhanced modeling.</abstract>
      <url hash="31495e3b">S18-1007</url>
      <doi>10.18653/v1/S18-1007</doi>
      <bibkey>choi-chen-2018-semeval</bibkey>
    </paper>
    <paper id="8">
      <title>AMORE-UPF at SemEval-2018 Task 4 : BiLSTM with Entity Library<fixed-case>AMORE</fixed-case>-<fixed-case>UPF</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 4: <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case> with Entity Library</title>
      <author><first>Laura</first> <last>Aina</last></author>
      <author><first>Carina</first> <last>Silberer</last></author>
      <author><first>Ionut-Teodor</first> <last>Sorodoc</last></author>
      <author><first>Matthijs</first> <last>Westera</last></author>
      <author><first>Gemma</first> <last>Boleda</last></author>
      <pages>65–69</pages>
      <abstract>This paper describes our winning contribution to SemEval 2018 Task 4 : Character Identification on Multiparty Dialogues. It is a simple, standard <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> with one key innovation, an <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity library</a>. Our results show that this <a href="https://en.wikipedia.org/wiki/Innovation">innovation</a> greatly facilitates the identification of infrequent characters. Because of the generic nature of our model, this finding is potentially relevant to any task that requires the effective learning from sparse or imbalanced data.</abstract>
      <url hash="4ffebdd6">S18-1008</url>
      <doi>10.18653/v1/S18-1008</doi>
      <bibkey>aina-etal-2018-amore</bibkey>
      <pwccode url="https://github.com/amore-upf/semeval2018-task4" additional="false">amore-upf/semeval2018-task4</pwccode>
    </paper>
    <paper id="10">
      <title>KOI at SemEval-2018 Task 5 : Building Knowledge Graph of Incidents<fixed-case>KOI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 5: Building Knowledge Graph of Incidents</title>
      <author><first>Paramita</first> <last>Mirza</last></author>
      <author><first>Fariz</first> <last>Darari</last></author>
      <author><first>Rahmad</first> <last>Mahendra</last></author>
      <pages>81–87</pages>
      <abstract>We present KOI (Knowledge of Incidents), a system that given <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a> as input, builds a knowledge graph (KOI-KG) of incidental events. KOI-KG can then be used to efficiently answer questions such How many killing incidents happened in 2017 that involve Sean? The required steps in building the KG include : (i) document preprocessing involving <a href="https://en.wikipedia.org/wiki/Word-sense_disambiguation">word sense disambiguation</a>, <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named-entity recognition</a>, temporal expression recognition and normalization, and <a href="https://en.wikipedia.org/wiki/Semantic_role_labeling">semantic role labeling</a> ; (ii) incidental event extraction and coreference resolution via document clustering ; and (iii) KG construction and population.</abstract>
      <url hash="1b927609">S18-1010</url>
      <doi>10.18653/v1/S18-1010</doi>
      <bibkey>mirza-etal-2018-koi</bibkey>
    </paper>
    <paper id="13">
      <title>NEUROSENT-PDI at SemEval-2018 Task 1 : Leveraging a Multi-Domain Sentiment Model for Inferring Polarity in Micro-blog Text<fixed-case>NEUROSENT</fixed-case>-<fixed-case>PDI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Leveraging a Multi-Domain Sentiment Model for Inferring Polarity in Micro-blog Text</title>
      <author><first>Mauro</first> <last>Dragoni</last></author>
      <pages>102–108</pages>
      <abstract>This paper describes the NeuroSent system that participated in SemEval 2018 Task 1. Our <a href="https://en.wikipedia.org/wiki/System">system</a> takes a supervised approach that builds on <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a> and <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>. Word embeddings were built by starting from a repository of user generated reviews. Thus, they are specific for sentiment analysis tasks. Then, <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> are converted in the corresponding <a href="https://en.wikipedia.org/wiki/Vector_graphics">vector representation</a> and given as input to the <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> with the aim of learning the different <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> contained in each emotion taken into account by the SemEval task. The output layer has been adapted based on the characteristics of each subtask. Preliminary results obtained on the provided <a href="https://en.wikipedia.org/wiki/Training_set">training set</a> are encouraging for pursuing the investigation into this direction.</abstract>
      <url hash="338b38ae">S18-1013</url>
      <doi>10.18653/v1/S18-1013</doi>
      <bibkey>dragoni-2018-neurosent</bibkey>
    </paper>
    <paper id="14">
      <title>FOI DSS at SemEval-2018 Task 1 : Combining LSTM States, Embeddings, and Lexical Features for Affect Analysis<fixed-case>FOI</fixed-case> <fixed-case>DSS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Combining <fixed-case>LSTM</fixed-case> States, Embeddings, and Lexical Features for Affect Analysis</title>
      <author><first>Maja</first> <last>Karasalo</last></author>
      <author><first>Mattias</first> <last>Nilsson</last></author>
      <author><first>Magnus</first> <last>Rosell</last></author>
      <author><first>Ulrika</first> <last>Wickenberg Bolin</last></author>
      <pages>109–115</pages>
      <abstract>This paper describes the system used and results obtained for team FOI DSS at SemEval-2018 Task 1 : Affect In Tweets. The team participated in all English language subtasks, with a method utilizing transfer learning from LSTM nets trained on large sentiment datasets combined with embeddings and lexical features. For four out of five subtasks, the <a href="https://en.wikipedia.org/wiki/System">system</a> performed in the range of 92-95 % of the winning systems, in terms of the <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">competition metrics</a>. Analysis of the results suggests that improved <a href="https://en.wikipedia.org/wiki/Data_pre-processing">pre-processing</a> and addition of more <a href="https://en.wikipedia.org/wiki/Lexical_item">lexical features</a> may further elevate performance.</abstract>
      <url hash="f973a54b">S18-1014</url>
      <doi>10.18653/v1/S18-1014</doi>
      <bibkey>karasalo-etal-2018-foi</bibkey>
    </paper>
    <paper id="15">
      <title>NLPZZX at SemEval-2018 Task 1 : Using Ensemble Method for Emotion and Sentiment Intensity Determination<fixed-case>NLPZZX</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Using Ensemble Method for Emotion and Sentiment Intensity Determination</title>
      <author><first>Zhengxin</first> <last>Zhang</last></author>
      <author><first>Qimin</first> <last>Zhou</last></author>
      <author><first>Hao</first> <last>Wu</last></author>
      <pages>116–122</pages>
      <abstract>In this paper, we put forward a <a href="https://en.wikipedia.org/wiki/System">system</a> that competed at SemEval-2018 Task 1 : Affect in Tweets. Our <a href="https://en.wikipedia.org/wiki/System">system</a> uses a simple yet effective <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble method</a> which combines several <a href="https://en.wikipedia.org/wiki/Neural_circuit">neural network components</a>. We participate in two subtasks for English tweets : EI-reg and V-reg. For two subtasks, different combinations of <a href="https://en.wikipedia.org/wiki/Neural_circuit">neural components</a> are examined. For EI-reg, our system achieves an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 0.727 in <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson Correlation Coefficient</a> (all instances) and an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 0.555 in <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson Correlation Coefficient</a> (0.5-1). For V-reg, the achieved accuracy scores are respectively 0.835 and 0.670</abstract>
      <url hash="615972b3">S18-1015</url>
      <doi>10.18653/v1/S18-1015</doi>
      <bibkey>zhang-etal-2018-nlpzzx</bibkey>
    </paper>
    <paper id="16">
      <title>LT3 at SemEval-2018 Task 1 : A classifier chain to detect emotions in tweets<fixed-case>LT</fixed-case>3 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: A classifier chain to detect emotions in tweets</title>
      <author><first>Luna</first> <last>De Bruyne</last></author>
      <author><first>Orphée</first> <last>De Clercq</last></author>
      <author><first>Véronique</first> <last>Hoste</last></author>
      <pages>123–127</pages>
      <abstract>This paper presents an emotion classification system for English tweets, submitted for the SemEval shared task on Affect in Tweets, subtask 5 : Detecting Emotions. The system combines <a href="https://en.wikipedia.org/wiki/Lexicon">lexicon</a>, <a href="https://en.wikipedia.org/wiki/N-gram">n-gram</a>, style, syntactic and semantic features. For this multi-class multi-label problem, we created a classifier chain. This is an ensemble of eleven <a href="https://en.wikipedia.org/wiki/Binary_classification">binary classifiers</a>, one for each possible <a href="https://en.wikipedia.org/wiki/Emotion_classification">emotion category</a>, where each model gets the predictions of the preceding models as additional <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>. The predicted labels are combined to get a multi-label representation of the predictions. Our <a href="https://en.wikipedia.org/wiki/System">system</a> was ranked eleventh among thirty five participating teams, with a <a href="https://en.wikipedia.org/wiki/Jaccard">Jaccard accuracy</a> of 52.0 % and macro- and micro-average F1-scores of 49.3 % and 64.0 %, respectively.</abstract>
      <url hash="bd71f42a">S18-1016</url>
      <doi>10.18653/v1/S18-1016</doi>
      <bibkey>de-bruyne-etal-2018-lt3</bibkey>
    </paper>
    <paper id="17">
      <title>SINAI at SemEval-2018 Task 1 : Emotion Recognition in Tweets<fixed-case>SINAI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Emotion Recognition in Tweets</title>
      <author><first>Flor Miriam</first> <last>Plaza-del-Arco</last></author>
      <author><first>Salud María</first> <last>Jiménez-Zafra</last></author>
      <author><first>Maite</first> <last>Martin</last></author>
      <author><first>L. Alfonso</first> <last>Ureña-López</last></author>
      <pages>128–132</pages>
      <abstract>Emotion classification is a new task that combines several disciplines including <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">Artificial Intelligence</a> and <a href="https://en.wikipedia.org/wiki/Psychology">Psychology</a>, although <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a> is perhaps the most challenging area. In this paper, we describe our participation in SemEval-2018 Task1 : Affect in Tweets. In particular, we have participated in EI-oc, EI-reg and E-c subtasks for English and Spanish languages.</abstract>
      <url hash="4aaffdc7">S18-1017</url>
      <doi>10.18653/v1/S18-1017</doi>
      <bibkey>plaza-del-arco-etal-2018-sinai</bibkey>
    </paper>
    <paper id="20">
      <title>INGEOTEC at SemEval-2018 Task 1 : EvoMSA and TC for Sentiment Analysis<fixed-case>INGEOTEC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: <fixed-case>E</fixed-case>vo<fixed-case>MSA</fixed-case> and μ<fixed-case>TC</fixed-case> for Sentiment Analysis</title>
      <author><first>Mario</first> <last>Graff</last></author>
      <author><first>Sabino</first> <last>Miranda-Jiménez</last></author>
      <author><first>Eric S.</first> <last>Tellez</last></author>
      <author><first>Daniela</first> <last>Moctezuma</last></author>
      <pages>146–150</pages>
      <abstract>This paper describes our participation in Affective Tweets task for emotional intensity and sentiment intensity subtasks for English, Spanish, and Arabic languages. We used two approaches, TC and EvoMSA. The first one is a generic text categorization and regression system ; and the second one, a two-stage architecture for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a>. Both approaches are multilingual and domain independent.</abstract>
      <url hash="553aebf3">S18-1020</url>
      <doi>10.18653/v1/S18-1020</doi>
      <bibkey>graff-etal-2018-ingeotec</bibkey>
    </paper>
    <paper id="24">
      <title>Tw-StAR at SemEval-2018 Task 1 : Preprocessing Impact on Multi-label Emotion Classification<fixed-case>S</fixed-case>t<fixed-case>AR</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Preprocessing Impact on Multi-label Emotion Classification</title>
      <author><first>Hala</first> <last>Mulki</last></author>
      <author><first>Chedi</first> <last>Bechikh Ali</last></author>
      <author><first>Hatem</first> <last>Haddad</last></author>
      <author><first>Ismail</first> <last>Babaoğlu</last></author>
      <pages>167–171</pages>
      <abstract>In this paper, we describe our contribution in SemEval-2018 contest. We tackled task 1 Affect in <a href="https://en.wikipedia.org/wiki/Twitter">Tweets</a>, subtask E-c Detecting Emotions (multi-label classification). A multilabel classification system Tw-StAR was developed to recognize the emotions embedded in Arabic, English and Spanish tweets. To handle the multi-label classification problem via traditional classifiers, we employed the binary relevance transformation strategy while a TF-IDF scheme was used to generate the tweets’ features. We investigated using single and combinations of several preprocessing tasks to further improve the performance. The results showed that specific combinations of preprocessing tasks could significantly improve the evaluation measures. This has been later emphasized by the official results as our system ranked 3rd for both Arabic and Spanish datasets and 14th for the English dataset.</abstract>
      <url hash="d276e67c">S18-1024</url>
      <doi>10.18653/v1/S18-1024</doi>
      <bibkey>mulki-etal-2018-tw</bibkey>
    </paper>
    <paper id="26">
      <title>EmoIntens Tracker at SemEval-2018 Task 1 : Emotional Intensity Levels in # Tweets<fixed-case>E</fixed-case>mo<fixed-case>I</fixed-case>ntens Tracker at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Emotional Intensity Levels in #Tweets</title>
      <author><first>Ramona-Andreea</first> <last>Turcu</last></author>
      <author><first>Sandra Maria</first> <last>Amarandei</last></author>
      <author><first>Iuliana-Alexandra</first> <last>Flescan-Lovin-Arseni</last></author>
      <author><first>Daniela</first> <last>Gifu</last></author>
      <author><first>Diana</first> <last>Trandabat</last></author>
      <pages>177–180</pages>
      <abstract>The Affect in Tweets task is centered on emotions categorization and evaluation matrix using multi-language tweets (English and Spanish). In this research, SemEval Affect dataset was preprocessed, categorized, and evaluated accordingly (precision, <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall</a>, and accuracy). The system described in this paper is based on the implementation of supervised machine learning (Naive Bayes, KNN and SVM), deep learning (NN Tensor Flow model), and decision trees algorithms.</abstract>
      <url hash="6e41d05b">S18-1026</url>
      <doi>10.18653/v1/S18-1026</doi>
      <bibkey>turcu-etal-2018-emointens</bibkey>
    </paper>
    <paper id="28">
      <title>THU_NGN at SemEval-2018 Task 1 : Fine-grained Tweet Sentiment Intensity Analysis with Attention CNN-LSTM<fixed-case>THU</fixed-case>_<fixed-case>NGN</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Fine-grained Tweet Sentiment Intensity Analysis with Attention <fixed-case>CNN</fixed-case>-<fixed-case>LSTM</fixed-case></title>
      <author><first>Chuhan</first> <last>Wu</last></author>
      <author><first>Fangzhao</first> <last>Wu</last></author>
      <author><first>Junxin</first> <last>Liu</last></author>
      <author><first>Zhigang</first> <last>Yuan</last></author>
      <author><first>Sixing</first> <last>Wu</last></author>
      <author><first>Yongfeng</first> <last>Huang</last></author>
      <pages>186–192</pages>
      <abstract>Traditional sentiment analysis approaches mainly focus on classifying the sentiment polarities or emotion categories of texts. However, <a href="https://en.wikipedia.org/wiki/Information_technology">they</a> ca n’t exploit the <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment intensity information</a>. Therefore, the SemEval-2018 Task 1 is aimed to automatically determine the intensity of emotions or sentiment of tweets to mine fine-grained sentiment information. In order to address this task, we propose a <a href="https://en.wikipedia.org/wiki/System">system</a> based on an attention CNN-LSTM model. In our <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a>, LSTM is used to extract the long-term contextual information from texts. We apply <a href="https://en.wikipedia.org/wiki/Attentional_control">attention techniques</a> to selecting this <a href="https://en.wikipedia.org/wiki/Information">information</a>. A CNN layer with different size of kernels is used to extract local features. The dense layers take the pooled CNN feature maps and predict the intensity scores. Our system reaches average Pearson correlation score of 0.722 (ranked 12/48) in emotion intensity regression task, and 0.810 in valence regression task (ranked 15/38). It indicates that our <a href="https://en.wikipedia.org/wiki/System">system</a> can be further extended.</abstract>
      <url hash="efa50a03">S18-1028</url>
      <doi>10.18653/v1/S18-1028</doi>
      <bibkey>wu-etal-2018-thu-ngn</bibkey>
    </paper>
    <paper id="29">
      <title>EiTAKA at SemEval-2018 Task 1 : An Ensemble of N-Channels ConvNet and XGboost Regressors for Emotion Analysis of Tweets<fixed-case>E</fixed-case>i<fixed-case>TAKA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: An Ensemble of N-Channels <fixed-case>C</fixed-case>onv<fixed-case>N</fixed-case>et and <fixed-case>XG</fixed-case>boost Regressors for Emotion Analysis of Tweets</title>
      <author><first>Mohammed</first> <last>Jabreel</last></author>
      <author id="antonio-moreno-ribas"><first>Antonio</first> <last>Moreno</last></author>
      <pages>193–199</pages>
      <abstract>This paper describes our <a href="https://en.wikipedia.org/wiki/System">system</a> that has been used in Task1 Affect in Tweets. We combine two different approaches. The first one called N-Stream ConvNets, which is a deep learning approach where the second one is XGboost regressor based on a set of embedding and lexicons based features. Our system was evaluated on the testing sets of the tasks outperforming all other approaches for the Arabic version of valence intensity regression task and valence ordinal classification task.</abstract>
      <url hash="d018ae55">S18-1029</url>
      <doi>10.18653/v1/S18-1029</doi>
      <bibkey>jabreel-moreno-2018-eitaka</bibkey>
    </paper>
    <paper id="30">
      <title>CENTEMENT at SemEval-2018 Task 1 : Classification of Tweets using Multiple Thresholds with Self-correction and Weighted Conditional Probabilities<fixed-case>CENTEMENT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Classification of Tweets using Multiple Thresholds with Self-correction and Weighted Conditional Probabilities</title>
      <author><first>Tariq</first> <last>Ahmad</last></author>
      <author><first>Allan</first> <last>Ramsay</last></author>
      <author><first>Hanady</first> <last>Ahmed</last></author>
      <pages>200–204</pages>
      <abstract>In this paper we present our contribution to SemEval-2018, a classifier for classifying multi-label emotions of Arabic and English tweets. We attempted Affect in <a href="https://en.wikipedia.org/wiki/Twitter">Tweets</a>, specifically Task E-c : Detecting Emotions (multi-label classification). Our method is based on preprocessing the <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> and creating <a href="https://en.wikipedia.org/wiki/Vector_space">word vectors</a> combined with a self correction step to remove <a href="https://en.wikipedia.org/wiki/Image_noise">noise</a>. We also make use of emotion specific thresholds. The final submission was selected upon the best performance achieved, selected when using a range of thresholds. Our system was evaluated on the Arabic and English datasets provided for the task by the competition organisers, where it ranked 2nd for the Arabic dataset (out of 14 entries) and 12th for the English dataset (out of 35 entries).</abstract>
      <url hash="569e10b4">S18-1030</url>
      <doi>10.18653/v1/S18-1030</doi>
      <bibkey>ahmad-etal-2018-centement</bibkey>
    </paper>
    <paper id="31">
      <title>Yuan at SemEval-2018 Task 1 : Tweets Emotion Intensity Prediction using Ensemble Recurrent Neural Network<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Tweets Emotion Intensity Prediction using Ensemble Recurrent Neural Network</title>
      <author><first>Min</first> <last>Wang</last></author>
      <author><first>Xiaobing</first> <last>Zhou</last></author>
      <pages>205–209</pages>
      <abstract>We perform the LSTM and BiLSTM model for the emotion intensity prediction. We only join the third subtask in Task 1 : Affect in Tweets. Our system rank 6th among all the teams.</abstract>
      <url hash="2c32ddc4">S18-1031</url>
      <doi>10.18653/v1/S18-1031</doi>
      <bibkey>wang-zhou-2018-yuan</bibkey>
    </paper>
    <paper id="33">
      <title>Amobee at SemEval-2018 Task 1 : GRU Neural Network with a CNN Attention Mechanism for Sentiment Classification<fixed-case>A</fixed-case>mobee at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: <fixed-case>GRU</fixed-case> Neural Network with a <fixed-case>CNN</fixed-case> Attention Mechanism for Sentiment Classification</title>
      <author><first>Alon</first> <last>Rozental</last></author>
      <author><first>Daniel</first> <last>Fleischer</last></author>
      <pages>218–225</pages>
      <abstract>This paper describes the participation of Amobee in the shared sentiment analysis task at SemEval 2018. We participated in all the English sub-tasks and the Spanish valence tasks. Our system consists of three parts : training task-specific word embeddings, training a model consisting of gated-recurrent-units (GRU) with a convolution neural network (CNN) attention mechanism and training stacking-based ensembles for each of the sub-tasks. Our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> reached the 3rd and 1st places in the valence ordinal classification sub-tasks in <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, respectively.</abstract>
      <url hash="52cebc84">S18-1033</url>
      <doi>10.18653/v1/S18-1033</doi>
      <bibkey>rozental-fleischer-2018-amobee</bibkey>
    </paper>
    <paper id="35">
      <title>ECNU at SemEval-2018 Task 1 : Emotion Intensity Prediction Using Effective Features and Machine Learning Models<fixed-case>ECNU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Emotion Intensity Prediction Using Effective Features and Machine Learning Models</title>
      <author><first>Huimin</first> <last>Xu</last></author>
      <author><first>Man</first> <last>Lan</last></author>
      <author><first>Yuanbin</first> <last>Wu</last></author>
      <pages>231–235</pages>
      <abstract>This paper describes our submissions to SemEval 2018 task 1. The <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> is affect intensity prediction in <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a>, including five <a href="https://en.wikipedia.org/wiki/Task_(project_management)">subtasks</a>. We participated in all subtasks of <a href="https://en.wikipedia.org/wiki/Twitter">English tweets</a>. We extracted several traditional <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>, sentiment lexicon, emotion lexicon and domain specific features from tweets, adopted supervised machine learning algorithms to perform emotion intensity prediction.</abstract>
      <url hash="ebf5b535">S18-1035</url>
      <doi>10.18653/v1/S18-1035</doi>
      <bibkey>xu-etal-2018-ecnu</bibkey>
    </paper>
    <paper id="37">
      <title>NTUA-SLP at SemEval-2018 Task 1 : Predicting Affective Content in Tweets with Deep Attentive RNNs and Transfer Learning<fixed-case>NTUA</fixed-case>-<fixed-case>SLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Predicting Affective Content in Tweets with Deep Attentive <fixed-case>RNN</fixed-case>s and Transfer Learning</title>
      <author><first>Christos</first> <last>Baziotis</last></author>
      <author><first>Athanasiou</first> <last>Nikolaos</last></author>
      <author><first>Alexandra</first> <last>Chronopoulou</last></author>
      <author><first>Athanasia</first> <last>Kolovou</last></author>
      <author><first>Georgios</first> <last>Paraskevopoulos</last></author>
      <author><first>Nikolaos</first> <last>Ellinas</last></author>
      <author><first>Shrikanth</first> <last>Narayanan</last></author>
      <author><first>Alexandros</first> <last>Potamianos</last></author>
      <pages>245–255</pages>
      <abstract>In this paper we present deep-learning models that submitted to the SemEval-2018 Task 1 competition : Affect in Tweets. We participated in all subtasks for <a href="https://en.wikipedia.org/wiki/Twitter">English tweets</a>. We propose a Bi-LSTM architecture equipped with a multi-layer self attention mechanism. The attention mechanism improves the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> performance and allows us to identify salient words in <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a>, as well as gain insight into the <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> making them more interpretable. Our model utilizes a set of word2vec word embeddings trained on a large collection of 550 million Twitter messages, augmented by a set of word affective features. Due to the limited amount of task-specific training data, we opted for a transfer learning approach by pretraining the Bi-LSTMs on the dataset of Semeval 2017, Task 4A. The proposed approach ranked 1st in Subtask E Multi-Label Emotion Classification, 2nd in Subtask A Emotion Intensity Regression and achieved competitive results in other subtasks.</abstract>
      <url hash="e2322e38">S18-1037</url>
      <doi>10.18653/v1/S18-1037</doi>
      <bibkey>baziotis-etal-2018-ntua</bibkey>
      <pwccode url="" additional="true" />
    </paper>
    <paper id="38">
      <title>CrystalFeel at SemEval-2018 Task 1 : Understanding and Detecting Emotion Intensity using Affective Lexicons<fixed-case>C</fixed-case>rystal<fixed-case>F</fixed-case>eel at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Understanding and Detecting Emotion Intensity using Affective Lexicons</title>
      <author><first>Raj Kumar</first> <last>Gupta</last></author>
      <author><first>Yinping</first> <last>Yang</last></author>
      <pages>256–263</pages>
      <abstract>While sentiment and emotion analysis has received a considerable amount of research attention, the notion of understanding and detecting the intensity of emotions is relatively less explored. This paper describes a <a href="https://en.wikipedia.org/wiki/System">system</a> developed for predicting emotion intensity in <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a>. Given a Twitter message, CrystalFeel uses features derived from parts-of-speech, n-grams, word embedding, and multiple affective lexicons including Opinion Lexicon, SentiStrength, AFFIN, NRC Emotion &amp; Hash Emotion, and our in-house developed EI Lexicons to predict the degree of the intensity associated with fear, anger, sadness, and joy in the tweet. We found that including the affective lexicons-based features allowed the system to obtain strong prediction performance, while revealing interesting emotion word-level and message-level associations. On gold test data, CrystalFeel obtained <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson correlations</a> of 0.717 on average emotion intensity and of 0.816 on <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment intensity</a>.</abstract>
      <url hash="14e01a62">S18-1038</url>
      <doi>10.18653/v1/S18-1038</doi>
      <bibkey>gupta-yang-2018-crystalfeel</bibkey>
    </paper>
    <paper id="39">
      <title>PlusEmo2Vec at SemEval-2018 Task 1 : Exploiting emotion knowledge from <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a> and # hashtags<fixed-case>P</fixed-case>lus<fixed-case>E</fixed-case>mo2<fixed-case>V</fixed-case>ec at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Exploiting emotion knowledge from emoji and #hashtags</title>
      <author><first>Ji Ho</first> <last>Park</last></author>
      <author><first>Peng</first> <last>Xu</last></author>
      <author><first>Pascale</first> <last>Fung</last></author>
      <pages>264–272</pages>
      <abstract>This paper describes our <a href="https://en.wikipedia.org/wiki/System">system</a> that has been submitted to SemEval-2018 Task 1 : Affect in Tweets (AIT) to solve five subtasks. We focus on modeling both sentence and word level representations of emotion inside texts through large distantly labeled corpora with <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a> and <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a>. We transfer the emotional knowledge by exploiting neural network models as <a href="https://en.wikipedia.org/wiki/Feature_extraction">feature extractors</a> and use these representations for traditional machine learning models such as support vector regression (SVR) and <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a> to solve the competition tasks. Our <a href="https://en.wikipedia.org/wiki/System">system</a> is placed among the Top3 for all subtasks we participated.</abstract>
      <url hash="3610cc5a">S18-1039</url>
      <doi>10.18653/v1/S18-1039</doi>
      <bibkey>park-etal-2018-plusemo2vec</bibkey>
    </paper>
    <paper id="40">
      <title>YNU-HPCC at SemEval-2018 Task 1 : BiLSTM with Attention based Sentiment Analysis for Affect in Tweets<fixed-case>YNU</fixed-case>-<fixed-case>HPCC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case> with Attention based Sentiment Analysis for Affect in Tweets</title>
      <author><first>You</first> <last>Zhang</last></author>
      <author><first>Jin</first> <last>Wang</last></author>
      <author><first>Xuejie</first> <last>Zhang</last></author>
      <pages>273–278</pages>
      <abstract>We implemented the <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment system</a> in all five subtasks for <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>. All subtasks involve emotion or sentiment intensity prediction (regression and ordinal classification) and emotions determining (multi-labels classification). The useful BiLSTM (Bidirectional Long-Short Term Memory) model with attention mechanism was mainly applied for our <a href="https://en.wikipedia.org/wiki/System">system</a>. We use BiLSTM in order to get word information extracted from both directions. The attention mechanism was used to find the contribution of each word for improving the scores. Furthermore, based on BiLSTMATT (BiLSTM with attention mechanism) a few deep-learning algorithms were employed for different subtasks. For regression and ordinal classification tasks we used <a href="https://en.wikipedia.org/wiki/Domain_adaptation">domain adaptation</a> and ensemble learning methods to leverage base model. While a single base model was used for <a href="https://en.wikipedia.org/wiki/Task_(computing)">multi-labels task</a>.</abstract>
      <url hash="ab404bc9">S18-1040</url>
      <doi>10.18653/v1/S18-1040</doi>
      <bibkey>zhang-etal-2018-ynu</bibkey>
    </paper>
    <paper id="41">
      <title>UG18 at SemEval-2018 Task 1 : Generating Additional Training Data for Predicting Emotion Intensity in <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a><fixed-case>UG</fixed-case>18 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Generating Additional Training Data for Predicting Emotion Intensity in <fixed-case>S</fixed-case>panish</title>
      <author><first>Marloes</first> <last>Kuijper</last></author>
      <author><first>Mike</first> <last>van Lenthe</last></author>
      <author><first>Rik</first> <last>van Noord</last></author>
      <pages>279–285</pages>
      <abstract>The present study describes our submission to SemEval 2018 Task 1 : Affect in <a href="https://en.wikipedia.org/wiki/Twitter">Tweets</a>. Our Spanish-only approach aimed to demonstrate that it is beneficial to automatically generate additional training data by (i) translating training data from other languages and (ii) applying a semi-supervised learning method. We find strong support for both approaches, with those <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> outperforming our regular models in all subtasks. However, creating a stepwise ensemble of different <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> as opposed to simply averaging did not result in an increase in performance. We placed second (EI-Reg), second (EI-Oc), fourth (V-Reg) and fifth (V-Oc) in the four Spanish subtasks we participated in.</abstract>
      <url hash="611ce3e7">S18-1041</url>
      <doi>10.18653/v1/S18-1041</doi>
      <bibkey>kuijper-etal-2018-ug18</bibkey>
    </paper>
    <paper id="42">
      <title>ISCLAB at SemEval-2018 Task 1 : UIR-Miner for Affect in Tweets<fixed-case>ISCLAB</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: <fixed-case>UIR</fixed-case>-Miner for Affect in Tweets</title>
      <author><first>Meng</first> <last>Li</last></author>
      <author><first>Zhenyuan</first> <last>Dong</last></author>
      <author><first>Zhihao</first> <last>Fan</last></author>
      <author><first>Kongming</first> <last>Meng</last></author>
      <author><first>Jinghua</first> <last>Cao</last></author>
      <author><first>Guanqi</first> <last>Ding</last></author>
      <author><first>Yuhan</first> <last>Liu</last></author>
      <author><first>Jiawei</first> <last>Shan</last></author>
      <author><first>Binyang</first> <last>Li</last></author>
      <pages>286–290</pages>
      <abstract>This paper presents a UIR-Miner system for emotion and sentiment analysis evaluation in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> in SemEval 2018. Our system consists of three main modules : preprocessing module, stacking module to solve the intensity prediction of emotion and sentiment, LSTM network module to solve multi-label classification, and the hierarchical attention network module for solving emotion and sentiment classification problem. According to the <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> of SemEval 2018, our system gets the final scores of 0.636, 0.531, 0.731, 0.708, and 0.408 on 5 subtasks, respectively.</abstract>
      <url hash="bf56840d">S18-1042</url>
      <doi>10.18653/v1/S18-1042</doi>
      <bibkey>li-etal-2018-isclab</bibkey>
    </paper>
    <paper id="43">
      <title>TCS Research at SemEval-2018 Task 1 : Learning Robust Representations using Multi-Attention Architecture<fixed-case>TCS</fixed-case> Research at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Learning Robust Representations using Multi-Attention Architecture</title>
      <author><first>Hardik</first> <last>Meisheri</last></author>
      <author><first>Lipika</first> <last>Dey</last></author>
      <pages>291–299</pages>
      <abstract>This paper presents system description of our submission to the SemEval-2018 task-1 : Affect in tweets for the <a href="https://en.wikipedia.org/wiki/English_language">English language</a>. We combine three different <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> generated using <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning models</a> and traditional methods in support vector machines to create a unified ensemble system. A robust representation of a tweet is learned using a multi-attention based architecture which uses a mixture of different pre-trained embeddings. In addition to this analysis of different <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> is also presented. Our <a href="https://en.wikipedia.org/wiki/System">system</a> ranked 2nd, 5th, and 7th in different subtasks among 75 teams.</abstract>
      <url hash="c7e740da">S18-1043</url>
      <doi>10.18653/v1/S18-1043</doi>
      <bibkey>meisheri-dey-2018-tcs</bibkey>
    </paper>
    <paper id="44">
      <title>DMCB at SemEval-2018 Task 1 : Transfer Learning of Sentiment Classification Using Group LSTM for Emotion Intensity prediction<fixed-case>DMCB</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Transfer Learning of Sentiment Classification Using Group <fixed-case>LSTM</fixed-case> for Emotion Intensity prediction</title>
      <author><first>Youngmin</first> <last>Kim</last></author>
      <author><first>Hyunju</first> <last>Lee</last></author>
      <pages>300–304</pages>
      <abstract>This paper describes a system attended in the SemEval-2018 Task 1 Affect in <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> that predicts emotional intensities. We use Group LSTM with an attention model and <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> with sentiment classification data as a source data (SemEval 2017 Task 4a). A transfer model structure consists of a source domain and a target domain. Additionally, we try a new dropout that is applied to LSTMs in the Group LSTM. Our <a href="https://en.wikipedia.org/wiki/System">system</a> ranked 8th at the subtask 1a (emotion intensity regression). We also show various results with different <a href="https://en.wikipedia.org/wiki/Computer_architecture">architectures</a> in the source, target and transfer models.</abstract>
      <url hash="76078495">S18-1044</url>
      <doi>10.18653/v1/S18-1044</doi>
      <bibkey>kim-lee-2018-dmcb</bibkey>
    </paper>
    <paper id="45">
      <title>DeepMiner at SemEval-2018 Task 1 : Emotion Intensity Recognition Using <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Representation Learning</a><fixed-case>D</fixed-case>eep<fixed-case>M</fixed-case>iner at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Emotion Intensity Recognition Using Deep Representation Learning</title>
      <author><first>Habibeh</first> <last>Naderi</last></author>
      <author><first>Behrouz</first> <last>Haji Soleimani</last></author>
      <author><first>Saif</first> <last>Mohammad</last></author>
      <author><first>Svetlana</first> <last>Kiritchenko</last></author>
      <author><first>Stan</first> <last>Matwin</last></author>
      <pages>305–312</pages>
      <abstract>In this paper, we propose a <a href="https://en.wikipedia.org/wiki/Regression_analysis">regression system</a> to infer the emotion intensity of a tweet. We develop a multi-aspect feature learning mechanism to capture the most discriminative semantic features of a tweet as well as the emotion information conveyed by each word in it. We combine six types of feature groups : (1) a tweet representation learned by an LSTM deep neural network on the training data, (2) a tweet representation learned by an LSTM network on a large corpus of tweets that contain emotion words (a distant supervision corpus), (3) word embeddings trained on the distant supervision corpus and averaged over all words in a tweet, (4) word and character n-grams, (5) features derived from various sentiment and emotion lexicons, and (6) other hand-crafted features. As part of the word embedding training, we also learn the distributed representations of multi-word expressions (MWEs) and negated forms of words. An SVR regressor is then trained over the full set of <a href="https://en.wikipedia.org/wiki/Feature_(computer_vision)">features</a>. We evaluate the effectiveness of our ensemble feature sets on the SemEval-2018 Task 1 datasets and achieve a <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson correlation</a> of 72 % on the task of tweet emotion intensity prediction.</abstract>
      <url hash="9df5a176">S18-1045</url>
      <doi>10.18653/v1/S18-1045</doi>
      <bibkey>naderi-etal-2018-deepminer</bibkey>
    </paper>
    <paper id="46">
      <title>Zewen at SemEval-2018 Task 1 : An Ensemble Model for Affect Prediction in Tweets<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: An Ensemble Model for Affect Prediction in Tweets</title>
      <author><first>Zewen</first> <last>Chi</last></author>
      <author><first>Heyan</first> <last>Huang</last></author>
      <author><first>Jiangui</first> <last>Chen</last></author>
      <author><first>Hao</first> <last>Wu</last></author>
      <author><first>Ran</first> <last>Wei</last></author>
      <pages>313–318</pages>
      <abstract>This paper presents a method for Affect in Tweets, which is the task to automatically determine the intensity of emotions and intensity of sentiment of tweets. The term <a href="https://en.wikipedia.org/wiki/Affect_(psychology)">affect</a> refers to emotion-related categories such as <a href="https://en.wikipedia.org/wiki/Anger">anger</a>, <a href="https://en.wikipedia.org/wiki/Fear">fear</a>, etc. Intensity of emo-tions need to be quantified into a real valued score in [ 0, 1 ]. We propose an en-semble system including four different deep learning methods which are CNN, Bidirectional LSTM (BLSTM), LSTM-CNN and a CNN-based Attention model (CA). Our system gets an <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">average Pearson correlation score</a> of 0.682 in the subtask EI-reg and an <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">average Pearson correlation score</a> of 0.784 in subtask V-reg, which ranks 17th among 48 systems in EI-reg and 19th among 38 systems in V-reg.</abstract>
      <url hash="1a0e2b7e">S18-1046</url>
      <doi>10.18653/v1/S18-1046</doi>
      <bibkey>chi-etal-2018-zewen</bibkey>
    </paper>
    <paper id="55">
      <title>ARB-SEN at SemEval-2018 Task1 : A New Set of Features for Enhancing the Sentiment Intensity Prediction in Arabic Tweets<fixed-case>ARB</fixed-case>-<fixed-case>SEN</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task1: A New Set of Features for Enhancing the Sentiment Intensity Prediction in <fixed-case>A</fixed-case>rabic Tweets</title>
      <author><first>El Moatez Billah</first> <last>Nagoudi</last></author>
      <pages>364–368</pages>
      <abstract>This article describes our proposed Arabic Sentiment Analysis system named ARB-SEN. This system is designed for the International Workshop on Semantic Evaluation 2018 (SemEval-2018), Task1 : Affect in Tweets. ARB-SEN proposes two <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised models</a> to estimate the <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment intensity</a> in <a href="https://en.wikipedia.org/wiki/Twitter">Arabic tweets</a>. Both models use a set of features including sentiment lexicon, <a href="https://en.wikipedia.org/wiki/Affirmation_and_negation">negation</a>, <a href="https://en.wikipedia.org/wiki/Word_embedding">word embedding</a> and emotion symbols features. Our <a href="https://en.wikipedia.org/wiki/System">system</a> combines these <a href="https://en.wikipedia.org/wiki/Software_feature">features</a> to assist the <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis task</a>. ARB-SEN system achieves a <a href="https://en.wikipedia.org/wiki/Correlation_and_dependence">correlation score</a> of 0.720, ranking 6th among all participants in the valence intensity regression (V-reg) for the Arabic sub-task organized within the SemEval 2018 evaluation campaign.</abstract>
      <url hash="8e1f8e04">S18-1055</url>
      <doi>10.18653/v1/S18-1055</doi>
      <bibkey>nagoudi-2018-arb</bibkey>
    </paper>
    <paper id="56">
      <title>psyML at SemEval-2018 Task 1 : Transfer Learning for Sentiment and Emotion Analysis<fixed-case>ML</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Transfer Learning for Sentiment and Emotion Analysis</title>
      <author><first>Grace</first> <last>Gee</last></author>
      <author><first>Eugene</first> <last>Wang</last></author>
      <pages>369–376</pages>
      <abstract>In this paper, we describe the first attempt to perform <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> from <a href="https://en.wikipedia.org/wiki/Sentimentality">sentiment</a> to <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a>. Our system employs Long Short-Term Memory (LSTM) networks, including bidirectional LSTM (biLSTM) and LSTM with attention mechanism. We perform <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> by first pre-training the LSTM networks on <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment data</a> before concatenating the penultimate layers of these <a href="https://en.wikipedia.org/wiki/Computer_network">networks</a> into a single vector as input to new dense layers. For the E-c subtask, we utilize a novel approach to train <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> for correlated emotion classes. Our system performs 4/48, 3/39, 8/38, 4/37, 4/35 on all English subtasks EI-reg, EI-oc, V-reg, V-oc, E-c of SemEval 2018 Task 1 : Affect in Tweets.</abstract>
      <url hash="30d57bd8">S18-1056</url>
      <doi>10.18653/v1/S18-1056</doi>
      <bibkey>gee-wang-2018-psyml</bibkey>
    </paper>
    <paper id="57">
      <title>UIUC at SemEval-2018 Task 1 : Recognizing Affect with Ensemble Models<fixed-case>UIUC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Recognizing Affect with Ensemble Models</title>
      <author><first>Abhishek Avinash</first> <last>Narwekar</last></author>
      <author><first>Roxana</first> <last>Girju</last></author>
      <pages>377–384</pages>
      <abstract>Our submission to the SemEval-2018 Task1 : Affect in Tweets shared task competition is a supervised learning model relying on standard lexicon features coupled with word embedding features. We used an ensemble of diverse models, including <a href="https://en.wikipedia.org/wiki/Random_forest">random forests</a>, gradient boosted trees, and <a href="https://en.wikipedia.org/wiki/Linear_model">linear models</a>, corrected for training-development set mismatch. We submitted the system’s output for subtasks 1 (emotion intensity prediction), 2 (emotion ordinal classification), 3 (valence intensity regression) and 4 (valence ordinal classification), for English tweets. We placed 25th, 19th, 24th and 15th in the four subtasks respectively. The baseline considered was an SVM (Support Vector Machines) model with linear kernel on the lexicon and embedding based features. Our <a href="https://en.wikipedia.org/wiki/System">system</a>’s final performance measured in <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson correlation scores</a> outperformed the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a> by a margin of 2.2 % to 14.6 % across all tasks.</abstract>
      <url hash="2dc5f5ad">S18-1057</url>
      <doi>10.18653/v1/S18-1057</doi>
      <bibkey>narwekar-girju-2018-uiuc</bibkey>
    </paper>
    <paper id="58">
      <title>KU-MTL at SemEval-2018 Task 1 : Multi-task Identification of Affect in Tweets<fixed-case>KU</fixed-case>-<fixed-case>MTL</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Multi-task Identification of Affect in Tweets</title>
      <author><first>Thomas</first> <last>Nyegaard-Signori</last></author>
      <author><first>Casper Veistrup</first> <last>Helms</last></author>
      <author><first>Johannes</first> <last>Bjerva</last></author>
      <author><first>Isabelle</first> <last>Augenstein</last></author>
      <pages>385–389</pages>
      <abstract>We take a multi-task learning approach to the shared Task 1 at SemEval-2018. The general idea concerning the model structure is to use as little external data as possible in order to preserve the task relatedness and reduce <a href="https://en.wikipedia.org/wiki/Complexity">complexity</a>. We employ <a href="https://en.wikipedia.org/wiki/Multi-task_learning">multi-task learning</a> with hard parameter sharing to exploit the relatedness between sub-tasks. As a base model, we use a standard <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network</a> for both the classification and regression subtasks. Our system ranks 32nd out of 48 participants with a <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson score</a> of 0.557 in the first subtask, and 20th out of 35 in the fifth subtask with an accuracy score of 0.464.</abstract>
      <url hash="3caf8855">S18-1058</url>
      <doi>10.18653/v1/S18-1058</doi>
      <bibkey>nyegaard-signori-etal-2018-ku</bibkey>
    </paper>
    <paper id="59">
      <title>EmoNLP at SemEval-2018 Task 2 : English Emoji Prediction with Gradient Boosting Regression Tree Method and Bidirectional LSTM<fixed-case>E</fixed-case>mo<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: <fixed-case>E</fixed-case>nglish Emoji Prediction with Gradient Boosting Regression Tree Method and Bidirectional <fixed-case>LSTM</fixed-case></title>
      <author><first>Man</first> <last>Liu</last></author>
      <pages>390–394</pages>
      <abstract>This paper describes our <a href="https://en.wikipedia.org/wiki/System">system</a> used in the English Emoji Prediction Task 2 at the SemEval-2018. Our system is based on two supervised machine learning algorithms : Gradient Boosting Regression Tree Method (GBM) and Bidirectional Long Short-term Memory Network (BLSTM). Besides the common features, we extract various lexicon and syntactic features from external resources. After comparing the results of two <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a>, GBM is chosen for the final evaluation.</abstract>
      <url hash="8cb13ca1">S18-1059</url>
      <doi>10.18653/v1/S18-1059</doi>
      <bibkey>liu-2018-emonlp</bibkey>
    </paper>
    <paper id="60">
      <title>UMDSub at SemEval-2018 Task 2 : Multilingual Emoji Prediction Multi-channel Convolutional Neural Network on Subword Embedding<fixed-case>UMDS</fixed-case>ub at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Multilingual Emoji Prediction Multi-channel Convolutional Neural Network on Subword Embedding</title>
      <author><first>Zhenduo</first> <last>Wang</last></author>
      <author><first>Ted</first> <last>Pedersen</last></author>
      <pages>395–399</pages>
      <abstract>This paper describes the UMDSub system that participated in Task 2 of SemEval-2018. We developed a system that predicts an <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a> given the raw text in a English tweet. The system is a Multi-channel Convolutional Neural Network based on subword embeddings for the representation of tweets. This <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> improves on character or word based methods by about 2 %. Our <a href="https://en.wikipedia.org/wiki/System">system</a> placed 21st of 48 participating systems in the official evaluation.</abstract>
      <url hash="21b93b9e">S18-1060</url>
      <doi>10.18653/v1/S18-1060</doi>
      <bibkey>wang-pedersen-2018-umdsub</bibkey>
    </paper>
    <paper id="61">
      <title>UMDuluth-CS8761 at SemEval-2018 Task 2 : Emojis : Too many Choices?<fixed-case>UMD</fixed-case>uluth-<fixed-case>CS</fixed-case>8761 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Emojis: Too many Choices?</title>
      <author><first>Jonathan</first> <last>Beaulieu</last></author>
      <author><first>Dennis</first> <last>Asamoah Owusu</last></author>
      <pages>400–404</pages>
      <abstract>In this paper, we present our system for assigning an <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a> to a tweet based on the text. Each tweet was originally posted with an <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a> which the task providers removed. Our task was to decide out of 20 <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a>, which originally came with the tweet. Two <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> were provided-one in <a href="https://en.wikipedia.org/wiki/English_language">English</a> and the other in <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>. We treated the <a href="https://en.wikipedia.org/wiki/Task_(computing)">task</a> as a standard classification task with the emojis as our classes and the tweets as our documents. Our best performing system used a <a href="https://en.wikipedia.org/wiki/Bag_of_words_model">Bag of Words model</a> with a Linear Support Vector Machine as its’ classifier. We achieved a macro F1 score of 32.73 % for the English data and 17.98 % for the Spanish data.</abstract>
      <url hash="eba2d25e">S18-1061</url>
      <doi>10.18653/v1/S18-1061</doi>
      <bibkey>beaulieu-asamoah-owusu-2018-umduluth</bibkey>
    </paper>
    <paper id="63">
      <title>THU_NGN at SemEval-2018 Task 2 : Residual CNN-LSTM Network with Attention for English Emoji Prediction<fixed-case>THU</fixed-case>_<fixed-case>NGN</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Residual <fixed-case>CNN</fixed-case>-<fixed-case>LSTM</fixed-case> Network with Attention for <fixed-case>E</fixed-case>nglish Emoji Prediction</title>
      <author><first>Chuhan</first> <last>Wu</last></author>
      <author><first>Fangzhao</first> <last>Wu</last></author>
      <author><first>Sixing</first> <last>Wu</last></author>
      <author><first>Zhigang</first> <last>Yuan</last></author>
      <author><first>Junxin</first> <last>Liu</last></author>
      <author><first>Yongfeng</first> <last>Huang</last></author>
      <pages>410–414</pages>
      <abstract>Emojis are widely used by <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> and social network users when posting their messages. It is important to study the relationships between messages and <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a>. Thus, in SemEval-2018 Task 2 an interesting and challenging <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> is proposed, i.e., predicting which <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a> are evoked by <a href="https://en.wikipedia.org/wiki/Twitter">text-based tweets</a>. We propose a residual CNN-LSTM with attention (RCLA) model for this task. Our model combines CNN and LSTM layers to capture both local and long-range contextual information for tweet representation. In addition, attention mechanism is used to select important components. Besides, residual connection is applied to CNN layers to facilitate the training of <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a>. We also incorporated additional <a href="https://en.wikipedia.org/wiki/Software_feature">features</a> such as POS tags and sentiment features extracted from <a href="https://en.wikipedia.org/wiki/Lexicon">lexicons</a>. Our model achieved 30.25 % macro-averaged F-score in the first subtask (i.e., emoji prediction in English), ranking 7th out of 48 participants.<b>RCLA</b>) model
      for this task. Our model combines CNN and LSTM layers to capture
      both local and long-range contextual information for tweet
      representation.  In addition, attention mechanism is used to
      select important components.  Besides, residual connection is
      applied to CNN layers to facilitate the training of neural
      networks. We also incorporated additional features such as POS
      tags and sentiment features extracted from lexicons. Our model
      achieved 30.25% macro-averaged F-score in the first subtask
      (i.e., emoji prediction in English), ranking 7th out of 48
      participants.
    </abstract>
      <url hash="cbf6e073">S18-1063</url>
      <doi>10.18653/v1/S18-1063</doi>
      <bibkey>wu-etal-2018-thu-ngn-semeval</bibkey>
    </paper>
    <paper id="64">
      <title># TeamINF at SemEval-2018 Task 2 : Emoji Prediction in Tweets<fixed-case>T</fixed-case>eam<fixed-case>INF</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Emoji Prediction in Tweets</title>
      <author><first>Alison</first> <last>Ribeiro</last></author>
      <author><first>Nádia</first> <last>Silva</last></author>
      <pages>415–418</pages>
      <abstract>In this paper, we describe a <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> to predict <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a> in <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a>. Our approach is based on the classic <a href="https://en.wikipedia.org/wiki/Bag-of-words_model">bag-of-words model</a> in conjunction with <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>. The used <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification algorithm</a> was <a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic Regression</a>. This <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> was used and evaluated in the context of the SemEval 2018 challenge (task 2, subtask 1).</abstract>
      <url hash="715b9c04">S18-1064</url>
      <doi>10.18653/v1/S18-1064</doi>
      <bibkey>ribeiro-silva-2018-teaminf</bibkey>
    </paper>
    <paper id="65">
      <title>EICA Team at SemEval-2018 Task 2 : Semantic and Metadata-based Features for Multilingual Emoji Prediction<fixed-case>EICA</fixed-case> Team at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Semantic and Metadata-based Features for Multilingual Emoji Prediction</title>
      <author><first>Yufei</first> <last>Xie</last></author>
      <author><first>Qingqing</first> <last>Song</last></author>
      <pages>419–422</pages>
      <abstract>The advent of <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> has brought along a novel way of communication where <a href="https://en.wikipedia.org/wiki/Meaning_(linguistics)">meaning</a> is composed by combining short text messages and visual enhancements, the so-called <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a>. We describe our <a href="https://en.wikipedia.org/wiki/System">system</a> for participating in SemEval-2018 Task 2 on Multilingual Emoji Prediction. Our approach relies on combining a rich set of various types of <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> : <a href="https://en.wikipedia.org/wiki/Semantic_Web">semantic</a> and <a href="https://en.wikipedia.org/wiki/Metadata">metadata</a>. The most important types turned out to be the <a href="https://en.wikipedia.org/wiki/Metadata">metadata feature</a>. In subtask 1 : Emoji Prediction in <a href="https://en.wikipedia.org/wiki/English_language">English</a>, our primary submission obtain a <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">MAP</a> of 16.45, <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">Precision</a> of 31.557, <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">Recall</a> of 16.771 and <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">Accuracy</a> of 30.992.</abstract>
      <url hash="413e29f5">S18-1065</url>
      <doi>10.18653/v1/S18-1065</doi>
      <bibkey>xie-song-2018-eica</bibkey>
    </paper>
    <paper id="66">
      <title>EmojiIt at SemEval-2018 Task 2 : An Effective Attention-Based Recurrent Neural Network Model for Emoji Prediction with Characters Gated Words<fixed-case>E</fixed-case>moji<fixed-case>I</fixed-case>t at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: An Effective Attention-Based Recurrent Neural Network Model for Emoji Prediction with Characters Gated Words</title>
      <author><last>Chen</last> <first>Shiyun</first></author>
      <author><last>Wang</last> <first>Maoquan</first></author>
      <author><last>He</last> <first>Liang</first></author>
      <pages>423–427</pages>
      <abstract>This paper presents our single model to Subtask 1 of SemEval 2018 Task 2 : Emoji Prediction in <a href="https://en.wikipedia.org/wiki/English_language">English</a>. In order to predict the <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a> that may be contained in a tweet, the basic model we use is an attention-based recurrent neural network which has achieved satisfactory performs in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language processing</a>. Considering the text comes from <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>, it contains many discrepant abbreviations and online terms, we also combine word-level and character-level word vector embedding to better handling the words not appear in the vocabulary. Our single model1 achieved 29.50 % Macro F-score in test data and ranks 9th among 48 teams.</abstract>
      <url hash="6439765e">S18-1066</url>
      <attachment type="note" hash="ef33e4cb">S18-1066.Notes.pdf</attachment>
      <doi>10.18653/v1/S18-1066</doi>
      <bibkey>chen-etal-2018-emojiit</bibkey>
    </paper>
    <paper id="67">
      <title>Peperomia at SemEval-2018 Task 2 : Vector Similarity Based Approach for Emoji Prediction<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Vector Similarity Based Approach for Emoji Prediction</title>
      <author><first>Jing</first> <last>Chen</last></author>
      <author><first>Dechuan</first> <last>Yang</last></author>
      <author><first>Xilian</first> <last>Li</last></author>
      <author><first>Wei</first> <last>Chen</last></author>
      <author><first>Tengjiao</first> <last>Wang</last></author>
      <pages>428–432</pages>
      <abstract>This paper describes our participation in SemEval 2018 Task 2 : Multilingual Emoji Prediction, in which participants are asked to predict a tweet’s most associated <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a> from 20 emojis. Instead of regarding <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> as a 20-class classification problem we regard <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> as a text similarity problem. We propose a vector similarity based approach for this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. First the distributed representation (tweet vector) for each tweet is generated, then the similarity between this tweet vector and each emoji’s embedding is evaluated. The most similar <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a> is chosen as the predicted label. Experimental results show that our approach performs comparably with the classification approach and shows its advantage in classifying <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a> with similar semantic meaning.</abstract>
      <url hash="dbf16eb8">S18-1067</url>
      <doi>10.18653/v1/S18-1067</doi>
      <bibkey>chen-etal-2018-peperomia</bibkey>
    </paper>
    <paper id="69">
      <title>NTUA-SLP at SemEval-2018 Task 2 : Predicting Emojis using RNNs with Context-aware Attention<fixed-case>NTUA</fixed-case>-<fixed-case>SLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Predicting Emojis using <fixed-case>RNN</fixed-case>s with Context-aware Attention</title>
      <author><first>Christos</first> <last>Baziotis</last></author>
      <author><first>Athanasiou</first> <last>Nikolaos</last></author>
      <author><first>Athanasia</first> <last>Kolovou</last></author>
      <author><first>Georgios</first> <last>Paraskevopoulos</last></author>
      <author><first>Nikolaos</first> <last>Ellinas</last></author>
      <author><first>Alexandros</first> <last>Potamianos</last></author>
      <pages>438–444</pages>
      <abstract>In this paper we present a <a href="https://en.wikipedia.org/wiki/Deep_learning">deep-learning model</a> that competed at SemEval-2018 Task 2 Multilingual Emoji Prediction. We participated in subtask A, in which we are called to predict the most likely associated emoji in English tweets. The proposed architecture relies on a Long Short-Term Memory network, augmented with an attention mechanism, that conditions the weight of each word, on a context vector which is taken as the aggregation of a tweet’s meaning. Moreover, we initialize the embedding layer of our model, with word2vec word embeddings, pretrained on a dataset of 550 million English tweets. Finally, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> does not rely on hand-crafted features or <a href="https://en.wikipedia.org/wiki/Lexicon">lexicons</a> and is trained end-to-end with <a href="https://en.wikipedia.org/wiki/Backpropagation">back-propagation</a>. We ranked 2nd out of 48 teams.</abstract>
      <url hash="ba7b9f90">S18-1069</url>
      <doi>10.18653/v1/S18-1069</doi>
      <bibkey>baziotis-etal-2018-ntua-slp</bibkey>
      <pwccode url="" additional="true" />
    </paper>
    <paper id="70">
      <title>Hatching Chick at SemEval-2018 Task 2 : Multilingual Emoji Prediction<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Multilingual Emoji Prediction</title>
      <author><first>Joël</first> <last>Coster</last></author>
      <author><first>Reinder Gerard</first> <last>van Dalen</last></author>
      <author><first>Nathalie Adriënne Jacqueline</first> <last>Stierman</last></author>
      <pages>445–448</pages>
      <abstract>As part of a SemEval 2018 shared task an attempt was made to build a system capable of predicting the occurence of a language’s most frequently used <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a> in Tweets. Specifically, <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> for English and Spanish data were created and trained on 500.000 and 100.000 tweets respectively. In order to create these models, first a <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regressor</a>, a sequential LSTM, a random forest regressor and a SVM were tested. The <a href="https://en.wikipedia.org/wiki/Second-generation_programming_language">latter</a> was found to perform best and therefore optimized individually for both languages. During developmet <a href="https://en.wikipedia.org/wiki/F-number">f1-scores</a> of 61 and 82 were obtained for English and Spanish data respectively, in comparison, <a href="https://en.wikipedia.org/wiki/F-number">f1-scores</a> on the official evaluation data were 21 and 18. The significant decrease in performance during <a href="https://en.wikipedia.org/wiki/Evaluation">evaluation</a> might be explained by <a href="https://en.wikipedia.org/wiki/Overfitting">overfitting</a> during development and might therefore have partially be prevented by using <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">cross-validation</a>. Over all, <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a> which occur in a very specific context such as a <a href="https://en.wikipedia.org/wiki/Christmas_tree">Christmas tree</a> were found to be most predictable.</abstract>
      <url hash="15b1565b">S18-1070</url>
      <doi>10.18653/v1/S18-1070</doi>
      <bibkey>coster-etal-2018-hatching</bibkey>
    </paper>
    <paper id="71">
      <title>EPUTION at SemEval-2018 Task 2 : Emoji Prediction with User Adaption<fixed-case>EPUTION</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Emoji Prediction with User Adaption</title>
      <author><first>Liyuan</first> <last>Zhou</last></author>
      <author><first>Qiongkai</first> <last>Xu</last></author>
      <author><first>Hanna</first> <last>Suominen</last></author>
      <author><first>Tom</first> <last>Gedeon</last></author>
      <pages>449–453</pages>
      <abstract>This paper describes our approach, called EPUTION, for the open trial of the SemEval- 2018 Task 2, Multilingual Emoji Prediction. The task relates to using <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>   more precisely, <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>   with its aim to predict the most likely associated <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a> of a tweet. Our solution for this text classification problem explores the idea of <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> for adapting the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> based on users’ tweeting history. Our experiments show that our user-adaption method improves <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> results by more than 6 per cent on the macro-averaged F1. Thus, our paper provides evidence for the rationality of enriching the original <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> longitudinally with user behaviors and transferring the lessons learned from corresponding users to specific instances.</abstract>
      <attachment type="note" hash="1ad2c50c">S18-1071.Notes.pdf</attachment>
      <url hash="17734302">S18-1071</url>
      <doi>10.18653/v1/S18-1071</doi>
      <bibkey>zhou-etal-2018-epution</bibkey>
    </paper>
    <paper id="72">
      <title>PickleTeam ! at SemEval-2018 Task 2 : English and Spanish Emoji Prediction from Tweets<fixed-case>P</fixed-case>ickle<fixed-case>T</fixed-case>eam! at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: <fixed-case>E</fixed-case>nglish and <fixed-case>S</fixed-case>panish Emoji Prediction from Tweets</title>
      <author><first>Daphne</first> <last>Groot</last></author>
      <author><first>Rémon</first> <last>Kruizinga</last></author>
      <author><first>Hennie</first> <last>Veldthuis</last></author>
      <author><first>Simon</first> <last>de Wit</last></author>
      <author><first>Hessel</first> <last>Haagsma</last></author>
      <pages>454–458</pages>
      <abstract>We present a system for emoji prediction on English and Spanish tweets, prepared for the SemEval-2018 task on Multilingual Emoji Prediction. We compared the performance of an SVM, LSTM and an <a href="https://en.wikipedia.org/wiki/Musical_ensemble">ensemble</a> of these two. We found the <a href="https://en.wikipedia.org/wiki/Speech_recognition">SVM</a> performed best on our development set with an accuracy of 61.3 % for <a href="https://en.wikipedia.org/wiki/English_language">English</a> and 83 % for <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>. The features used for the SVM are lowercased word n-grams in the range of 1 to 20, tokenised by a TweetTokenizer and stripped of stop words. On the test set, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieved an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 34 % on <a href="https://en.wikipedia.org/wiki/English_language">English</a>, with a slightly lower score of 29.7 % accuracy on <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>.</abstract>
      <url hash="8a9c12ee">S18-1072</url>
      <doi>10.18653/v1/S18-1072</doi>
      <bibkey>groot-etal-2018-pickleteam</bibkey>
    </paper>
    <paper id="73">
      <title>YNU-HPCC at SemEval-2018 Task 2 : Multi-ensemble Bi-GRU Model with Attention Mechanism for Multilingual Emoji Prediction<fixed-case>YNU</fixed-case>-<fixed-case>HPCC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Multi-ensemble <fixed-case>B</fixed-case>i-<fixed-case>GRU</fixed-case> Model with Attention Mechanism for Multilingual Emoji Prediction</title>
      <author><first>Nan</first> <last>Wang</last></author>
      <author><first>Jin</first> <last>Wang</last></author>
      <author><first>Xuejie</first> <last>Zhang</last></author>
      <pages>459–465</pages>
      <abstract>This paper describes our approach to SemEval-2018 Task 2, which aims to predict the most likely associated <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a>, given a tweet in <a href="https://en.wikipedia.org/wiki/English_language">English</a> or <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>. We normalized text-based tweets during pre-processing, following which we utilized a bi-directional gated recurrent unit with an attention mechanism to build our base model. Multi-models with or without class weights were trained for the <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble methods</a>. We boosted models without <a href="https://en.wikipedia.org/wiki/Weight_function">class weights</a>, and only strong boost classifiers were identified. In our <a href="https://en.wikipedia.org/wiki/System">system</a>, not only was a boosting method used, but we also took advantage of the voting ensemble method to enhance our final <a href="https://en.wikipedia.org/wiki/System">system</a> result. Our method demonstrated an obvious improvement of approximately 3 % of the macro F1 score in <a href="https://en.wikipedia.org/wiki/English_language">English</a> and 2 % in <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>.</abstract>
      <url hash="ef8d95d1">S18-1073</url>
      <doi>10.18653/v1/S18-1073</doi>
      <bibkey>wang-etal-2018-ynu</bibkey>
    </paper>
    <paper id="74">
      <title>DUTH at SemEval-2018 Task 2 : Emoji Prediction in Tweets<fixed-case>DUTH</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Emoji Prediction in Tweets</title>
      <author><first>Dimitrios</first> <last>Effrosynidis</last></author>
      <author><first>Georgios</first> <last>Peikos</last></author>
      <author><first>Symeon</first> <last>Symeonidis</last></author>
      <author><first>Avi</first> <last>Arampatzis</last></author>
      <pages>466–469</pages>
      <abstract>This paper describes the approach that was developed for SemEval 2018 Task 2 (Multilingual Emoji Prediction) by the DUTH Team. First, we employed a combination of pre-processing techniques to reduce the noise of tweets and produce a number of features. Then, we built several <a href="https://en.wikipedia.org/wiki/N-gram">N-grams</a>, to represent the combination of word and emojis. Finally, we trained our <a href="https://en.wikipedia.org/wiki/System">system</a> with a tuned LinearSVC classifier. Our approach in the <a href="https://en.wikipedia.org/wiki/2010_FIFA_World_Cup">leaderboard</a> ranked 18th amongst 48 teams.</abstract>
      <url hash="efccb393">S18-1074</url>
      <doi>10.18653/v1/S18-1074</doi>
      <bibkey>effrosynidis-etal-2018-duth</bibkey>
    </paper>
    <paper id="77">
      <title>Duluth UROP at SemEval-2018 Task 2 : Multilingual Emoji Prediction with Ensemble Learning and Oversampling<fixed-case>D</fixed-case>uluth <fixed-case>UROP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Multilingual Emoji Prediction with Ensemble Learning and Oversampling</title>
      <author><first>Shuning</first> <last>Jin</last></author>
      <author><first>Ted</first> <last>Pedersen</last></author>
      <pages>482–485</pages>
      <abstract>This paper describes the Duluth UROP systems that participated in SemEval2018 Task 2, Multilingual Emoji Prediction. We relied on a variety of ensembles made up of classifiers using <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">Naive Bayes</a>, <a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic Regression</a>, and Random Forests. We used unigram and bigram features and tried to offset the <a href="https://en.wikipedia.org/wiki/Skewness">skewness</a> of the data through the use of oversampling. Our task evaluation results place us 19th of 48 systems in the <a href="https://en.wikipedia.org/wiki/English_language">English evaluation</a>, and 5th of 21 in the <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>. After the evaluation we realized that some simple changes to our pre-processing could significantly improve our results. After making these changes we attained results that would have placed us sixth in the <a href="https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language">English evaluation</a>, and second in the <a href="https://en.wikipedia.org/wiki/Spanish_as_a_second_or_foreign_language">Spanish</a>.</abstract>
      <url hash="242988f8">S18-1077</url>
      <doi>10.18653/v1/S18-1077</doi>
      <bibkey>jin-pedersen-2018-duluth</bibkey>
      <pwccode url="https://github.com/shuningjin/SemEval2018-Task2-EmojiDetection" additional="false">shuningjin/SemEval2018-Task2-EmojiDetection</pwccode>
    </paper>
    <paper id="78">
      <title>CENNLP at SemEval-2018 Task 2 : Enhanced Distributed Representation of Text using Target Classes for Emoji Prediction Representation<fixed-case>CENNLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Enhanced Distributed Representation of Text using Target Classes for Emoji Prediction Representation</title>
      <author><first>Naveen</first> <last>J R</last></author>
      <author><first>Hariharan</first> <last>V</last></author>
      <author><first>Barathi</first> <last>Ganesh H. B.</last></author>
      <author><first>Anand</first> <last>Kumar M</last></author>
      <author><first>Soman</first> <last>K P</last></author>
      <pages>486–490</pages>
      <abstract>Emoji is one of the fastest growing language   in <a href="https://en.wikipedia.org/wiki/Popular_culture">pop-culture</a>, especially in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> and it is very unlikely for its usage to decrease. These are generally used to bring an extra level of meaning to the texts, posted on <a href="https://en.wikipedia.org/wiki/Social_media">social media platforms</a>. Providing such an added info, gives more insights to the <a href="https://en.wikipedia.org/wiki/Plain_text">plain text</a>, arising to hidden interpretation within the text. This paper explains our analysis on Task 2,   Multilingual Emoji Prediction sharedtask conducted by Semeval-2018. In the task, a predicted <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a> based on a piece of Twitter text are labelled under 20 different classes (most commonly used emojis) where these <a href="https://en.wikipedia.org/wiki/Class_(computer_programming)">classes</a> are learnt and further predicted are made for unseen Twitter text. In this work, we have experimented and analysed emojis predicted based on Twitter text, as a classification problem where the entailing <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a> is considered as a label for every individual text data. We have implemented this using distributed representation of text through <a href="https://en.wikipedia.org/wiki/FastText">fastText</a>. Also, we have made an effort to demonstrate how fastText framework can be useful in case of emoji prediction. This <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> is divide into two subtask, they are based on dataset presented in two different languages English and <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>.</abstract>
      <url hash="d2d95ccc">S18-1078</url>
      <doi>10.18653/v1/S18-1078</doi>
      <bibkey>j-r-etal-2018-cennlp-semeval</bibkey>
    </paper>
    <paper id="81">
      <title>LIS at SemEval-2018 Task 2 : Mixing Word Embeddings and Bag of Features for Multilingual Emoji Prediction<fixed-case>LIS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Mixing Word Embeddings and Bag of Features for Multilingual Emoji Prediction</title>
      <author><first>Gaël</first> <last>Guibon</last></author>
      <author><first>Magalie</first> <last>Ochs</last></author>
      <author><first>Patrice</first> <last>Bellot</last></author>
      <pages>502–506</pages>
      <abstract>In this paper we present the <a href="https://en.wikipedia.org/wiki/System">system</a> submitted to the SemEval2018 task2 : Multilingual Emoji Prediction. Our system approaches both languages as being equal by first ; considering word embeddings associated to automatically computed features of different types, then by applying bagging algorithm RandomForest to predict the <a href="https://en.wikipedia.org/wiki/Emoji">emoji</a> of a tweet.</abstract>
      <url hash="1598ca93">S18-1081</url>
      <doi>10.18653/v1/S18-1081</doi>
      <bibkey>guibon-etal-2018-lis</bibkey>
    </paper>
    <paper id="82">
      <title>ALANIS at SemEval-2018 Task 3 : A Feature Engineering Approach to Irony Detection in English Tweets<fixed-case>ALANIS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: A Feature Engineering Approach to Irony Detection in <fixed-case>E</fixed-case>nglish Tweets</title>
      <author><first>Kevin</first> <last>Swanberg</last></author>
      <author><first>Madiha</first> <last>Mirza</last></author>
      <author><first>Ted</first> <last>Pedersen</last></author>
      <author><first>Zhenduo</first> <last>Wang</last></author>
      <pages>507–511</pages>
      <abstract>This paper describes the ALANIS system that participated in Task 3 of SemEval-2018. We develop a system for detection of irony, as well as the detection of three types of <a href="https://en.wikipedia.org/wiki/Irony">irony</a> : verbal polar irony, other verbal irony, and situational irony. The system uses a <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression model</a> in subtask A and a voted classifier system with manually developed <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> to identify ironic tweets. This <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> improves on a naive bayes baseline by about 8 percent on training set.</abstract>
      <url hash="aa3f5e45">S18-1082</url>
      <doi>10.18653/v1/S18-1082</doi>
      <bibkey>swanberg-etal-2018-alanis</bibkey>
    </paper>
    <paper id="84">
      <title>UWB at SemEval-2018 Task 3 : Irony detection in English tweets<fixed-case>UWB</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Irony detection in <fixed-case>E</fixed-case>nglish tweets</title>
      <author><first>Tomáš</first> <last>Hercig</last></author>
      <pages>520–524</pages>
      <abstract>This paper describes our system created for the SemEval-2018 Task 3 : Irony detection in English tweets. Our strongly constrained <a href="https://en.wikipedia.org/wiki/System">system</a> uses only the provided training data without any additional external resources. Our system is based on <a href="https://en.wikipedia.org/wiki/Maximum_entropy_classifier">Maximum Entropy classifier</a> and various features using <a href="https://en.wikipedia.org/wiki/Parse_tree">parse tree</a>, POS tags, and morphological features. Even without additional <a href="https://en.wikipedia.org/wiki/Lexicon">lexicons</a> and <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> we achieved fourth place in Subtask A and seventh in Subtask B in terms of accuracy.</abstract>
      <url hash="badd8b53">S18-1084</url>
      <doi>10.18653/v1/S18-1084</doi>
      <bibkey>hercig-2018-uwb</bibkey>
    </paper>
    <paper id="85">
      <title>NIHRIO at SemEval-2018 Task 3 : A Simple and Accurate Neural Network Model for Irony Detection in Twitter<fixed-case>NIHRIO</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: A Simple and Accurate Neural Network Model for Irony Detection in <fixed-case>T</fixed-case>witter</title>
      <author><first>Thanh</first> <last>Vu</last></author>
      <author><first>Dat Quoc</first> <last>Nguyen</last></author>
      <author><first>Xuan-Son</first> <last>Vu</last></author>
      <author><first>Dai Quoc</first> <last>Nguyen</last></author>
      <author><first>Michael</first> <last>Catt</last></author>
      <author><first>Michael</first> <last>Trenell</last></author>
      <pages>525–530</pages>
      <abstract>This paper describes our NIHRIO system for SemEval-2018 Task 3 Irony detection in English tweets. We propose to use a simple neural network architecture of Multilayer Perceptron with various types of input features including : lexical, syntactic, semantic and polarity features. Our system achieves very high performance in both subtasks of binary and multi-class irony detection in <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a>. In particular, we rank at least fourth using the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy metric</a> and sixth using the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">F1 metric</a>. Our code is available at :<url>https://github.com/NIHRIO/IronyDetectionInTwitter</url>
      </abstract>
      <url hash="2b0db811">S18-1085</url>
      <doi>10.18653/v1/S18-1085</doi>
      <bibkey>vu-etal-2018-nihrio</bibkey>
      <pwccode url="https://github.com/NIHRIO/IronyDetectionInTwitter" additional="false">NIHRIO/IronyDetectionInTwitter</pwccode>
    </paper>
    <paper id="86">
      <title>LDR at SemEval-2018 Task 3 : A Low Dimensional Text Representation for Irony Detection<fixed-case>LDR</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: A Low Dimensional Text Representation for Irony Detection</title>
      <author><first>Bilal</first> <last>Ghanem</last></author>
      <author><first>Francisco</first> <last>Rangel</last></author>
      <author><first>Paolo</first> <last>Rosso</last></author>
      <pages>531–536</pages>
      <abstract>In this paper we describe our participation in the SemEval-2018 task 3 Shared Task on Irony Detection. We have approached the task with our low dimensionality representation method (LDR), which exploits low dimensional features extracted from text on the basis of the occurrence probability of the words depending on each class. Our intuition is that words in ironic texts have different probability of occurrence than in non-ironic ones. Our <a href="https://en.wikipedia.org/wiki/Design_of_experiments">approach</a> obtained acceptable results in both subtasks A and B. We have performed an error analysis that shows the difference on correct and incorrect classified tweets.</abstract>
      <url hash="ca8a046e">S18-1086</url>
      <doi>10.18653/v1/S18-1086</doi>
      <bibkey>ghanem-etal-2018-ldr</bibkey>
    </paper>
    <paper id="88">
      <title>PunFields at SemEval-2018 Task 3 : Detecting Irony by Tools of Humor Analysis<fixed-case>P</fixed-case>un<fixed-case>F</fixed-case>ields at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Detecting Irony by Tools of Humor Analysis</title>
      <author><first>Elena</first> <last>Mikhalkova</last></author>
      <author><first>Yuri</first> <last>Karyakin</last></author>
      <author><first>Alexander</first> <last>Voronov</last></author>
      <author><first>Dmitry</first> <last>Grigoriev</last></author>
      <author><first>Artem</first> <last>Leoznov</last></author>
      <pages>541–545</pages>
      <abstract>The paper describes our search for a universal algorithm of detecting intentional lexical ambiguity in different forms of creative language. At SemEval-2018 Task 3, we used PunFields, the system of automatic analysis of English puns that we introduced at SemEval-2017, to detect irony in tweets. Preliminary tests showed that <a href="https://en.wikipedia.org/wiki/It_(2017_film)">it</a> can reach the score of F1=0.596. However, at the competition, its result was F1=0.549.</abstract>
      <url hash="a7bafdcd">S18-1088</url>
      <doi>10.18653/v1/S18-1088</doi>
      <bibkey>mikhalkova-etal-2018-punfields</bibkey>
    </paper>
    <paper id="89">
      <title>HashCount at SemEval-2018 Task 3 : Concatenative Featurization of Tweet and Hashtags for Irony Detection<fixed-case>H</fixed-case>ash<fixed-case>C</fixed-case>ount at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Concatenative Featurization of Tweet and Hashtags for Irony Detection</title>
      <author><first>Won Ik</first> <last>Cho</last></author>
      <author><first>Woo Hyun</first> <last>Kang</last></author>
      <author><first>Nam Soo</first> <last>Kim</last></author>
      <pages>546–552</pages>
      <abstract>This paper proposes a novel feature extraction process for SemEval task 3 : Irony detection in English tweets. The proposed system incorporates a concatenative featurization of tweet and <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a>, which helps distinguishing between the irony-related and the other components. The system embeds tweets into a <a href="https://en.wikipedia.org/wiki/Vector_space">vector sequence</a> with widely used pretrained word vectors, partially using a character embedding for the words that are out of vocabulary. Identification was performed with BiLSTM and CNN classifiers, achieving F1 score of 0.5939 (23/42) and 0.3925 (10/28) each for the binary and the multi-class case, respectively. The <a href="https://en.wikipedia.org/wiki/Reliability_(statistics)">reliability</a> of the proposed scheme was verified by analyzing the Gold test data, which demonstrates how <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a> can be taken into account when identifying various types of <a href="https://en.wikipedia.org/wiki/Irony">irony</a>.</abstract>
      <url hash="0830d953">S18-1089</url>
      <doi>10.18653/v1/S18-1089</doi>
      <bibkey>cho-etal-2018-hashcount</bibkey>
    </paper>
    <paper id="90">
      <title>WLV at SemEval-2018 Task 3 : Dissecting Tweets in Search of Irony<fixed-case>WLV</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Dissecting Tweets in Search of Irony</title>
      <author><first>Omid</first> <last>Rohanian</last></author>
      <author><first>Shiva</first> <last>Taslimipoor</last></author>
      <author><first>Richard</first> <last>Evans</last></author>
      <author><first>Ruslan</first> <last>Mitkov</last></author>
      <pages>553–559</pages>
      <abstract>This paper describes the systems submitted to SemEval 2018 Task 3 Irony detection in English tweets for both subtasks A and B. The first system leveraging a combination of <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment</a>, distributional semantic, and text surface features is ranked third among 44 teams according to the official leaderboard of the subtask A. The second <a href="https://en.wikipedia.org/wiki/Formal_system">system</a> with slightly different representation of the <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> ranked ninth in subtask B. We present a <a href="https://en.wikipedia.org/wiki/Methodology">method</a> that entails decomposing tweets into separate parts. Searching for <a href="https://en.wikipedia.org/wiki/Contrast_(vision)">contrast</a> within the constituents of a tweet is an integral part of our <a href="https://en.wikipedia.org/wiki/System">system</a>. We embrace an extensive definition of <a href="https://en.wikipedia.org/wiki/Contrast_(linguistics)">contrast</a> which leads to a vast coverage in detecting ironic content.</abstract>
      <url hash="13a80ed7">S18-1090</url>
      <doi>10.18653/v1/S18-1090</doi>
      <bibkey>rohanian-etal-2018-wlv</bibkey>
    </paper>
    <paper id="95">
      <title>Irony Detector at SemEval-2018 Task 3 : Irony Detection in English Tweets using Word Graph<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Irony Detection in <fixed-case>E</fixed-case>nglish Tweets using Word Graph</title>
      <author><first>Usman</first> <last>Ahmed</last></author>
      <author><first>Lubna</first> <last>Zafar</last></author>
      <author><first>Faiza</first> <last>Qayyum</last></author>
      <author><first>Muhammad</first> <last>Arshad Islam</last></author>
      <pages>581–586</pages>
      <abstract>This paper describes the Irony detection system that participates in SemEval-2018 Task 3 : Irony detection in English tweets. The <a href="https://en.wikipedia.org/wiki/System">system</a> participated in the subtasks A and B. This paper discusses the results of our <a href="https://en.wikipedia.org/wiki/System">system</a> in the development, evaluation and post evaluation. Each class in the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> is represented as <a href="https://en.wikipedia.org/wiki/Directed_graph">directed unweighted graphs</a>. Then, the comparison is carried out with each <a href="https://en.wikipedia.org/wiki/Class_graph">class graph</a> which results in a <a href="https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics)">vector</a>. This <a href="https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics)">vector</a> is used as <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> by <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning algorithm</a>. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is evaluated on a hold on strategy. The organizers randomly split 80 % (3,833 instances) training set (provided to the participant in training their system) and testing set 20%(958 instances). The test set is reserved to evaluate the performance of participants systems. During the evaluation, our <a href="https://en.wikipedia.org/wiki/System">system</a> ranked 23 in the Coda Lab result of the subtask A (binary class problem). The binary class system achieves <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> 0.6135, <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a> 0.5091, <a href="https://en.wikipedia.org/wiki/Precision_and_recall">recall</a> 0.7170 and F measure 0.5955. The subtask B (multi-class problem) system is ranked 22 in Coda Lab results. The multiclass model achieves the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> 0.4158, <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a> 0.4055, <a href="https://en.wikipedia.org/wiki/Precision_and_recall">recall</a> 0.3526 and <a href="https://en.wikipedia.org/wiki/F-number">f measure</a> 0.3101.</abstract>
      <url hash="09677fa1">S18-1095</url>
      <doi>10.18653/v1/S18-1095</doi>
      <bibkey>ahmed-etal-2018-irony</bibkey>
    </paper>
    <paper id="96">
      <title>Lancaster at SemEval-2018 Task 3 : Investigating Ironic Features in English Tweets<fixed-case>L</fixed-case>ancaster at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Investigating Ironic Features in <fixed-case>E</fixed-case>nglish Tweets</title>
      <author><first>Edward</first> <last>Dearden</last></author>
      <author><first>Alistair</first> <last>Baron</last></author>
      <pages>587–593</pages>
      <abstract>This paper describes the <a href="https://en.wikipedia.org/wiki/System">system</a> we submitted to SemEval-2018 Task 3. The aim of the system is to distinguish between irony and non-irony in English tweets. We create a targeted feature set and analyse how different <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> are useful in the task of irony detection, achieving an F1-score of 0.5914. The analysis of individual features provides insight that may be useful in future attempts at detecting <a href="https://en.wikipedia.org/wiki/Irony">irony</a> in <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a>.</abstract>
      <url hash="28cd350b">S18-1096</url>
      <doi>10.18653/v1/S18-1096</doi>
      <bibkey>dearden-baron-2018-lancaster</bibkey>
    </paper>
    <paper id="97">
      <title>INAOE-UPV at SemEval-2018 Task 3 : An Ensemble Approach for Irony Detection in Twitter<fixed-case>INAOE</fixed-case>-<fixed-case>UPV</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: An Ensemble Approach for Irony Detection in <fixed-case>T</fixed-case>witter</title>
      <author><first>Delia Irazú</first> <last>Hernández Farías</last></author>
      <author><first>Fernando</first> <last>Sánchez-Vega</last></author>
      <author><first>Manuel</first> <last>Montes-y-Gómez</last></author>
      <author><first>Paolo</first> <last>Rosso</last></author>
      <pages>594–599</pages>
      <abstract>This paper describes an <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble approach</a> to the SemEval-2018 Task 3. The proposed method is composed of two renowned methods in <a href="https://en.wikipedia.org/wiki/Text_classification">text classification</a> together with a novel approach for capturing ironic content by exploiting a tailored lexicon for irony detection. We experimented with different <a href="https://en.wikipedia.org/wiki/Ensemble_cast">ensemble settings</a>. The obtained results show that our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> has a good performance for detecting the presence of ironic content in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>.</abstract>
      <url hash="f15111f7">S18-1097</url>
      <doi>10.18653/v1/S18-1097</doi>
      <bibkey>hernandez-farias-etal-2018-inaoe</bibkey>
    </paper>
    <paper id="99">
      <title>KLUEnicorn at SemEval-2018 Task 3 : A Naive Approach to Irony Detection<fixed-case>KLUE</fixed-case>nicorn at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: A Naive Approach to Irony Detection</title>
      <author><first>Luise</first> <last>Dürlich</last></author>
      <pages>607–612</pages>
      <abstract>This paper describes the KLUEnicorn system submitted to the SemEval-2018 task on Irony detection in English tweets. The proposed system uses a <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">naive Bayes classifier</a> to exploit rather simple lexical, pragmatical and semantical features as well as sentiment. It further takes a closer look at different adverb categories and <a href="https://en.wikipedia.org/wiki/Named_entity">named entities</a> and factors in word-embedding information.</abstract>
      <url hash="90c27989">S18-1099</url>
      <doi>10.18653/v1/S18-1099</doi>
      <bibkey>durlich-2018-kluenicorn</bibkey>
    </paper>
    <paper id="101">
      <title>YNU-HPCC at SemEval-2018 Task 3 : Ensemble Neural Network Models for Irony Detection on Twitter<fixed-case>YNU</fixed-case>-<fixed-case>HPCC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Ensemble Neural Network Models for Irony Detection on <fixed-case>T</fixed-case>witter</title>
      <author><first>Bo</first> <last>Peng</last></author>
      <author><first>Jin</first> <last>Wang</last></author>
      <author><first>Xuejie</first> <last>Zhang</last></author>
      <pages>622–627</pages>
      <abstract>This paper describe the <a href="https://en.wikipedia.org/wiki/System">system</a> we proposed to participate the first year of Irony detection in English tweets competition. Previous works demonstrate that LSTMs models have achieved remarkable performance in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> ; besides, combining multiple classification from various individual classifiers in general is more powerful than a single classification. In order to obtain more precision classification of irony detection, our system trained several individual neural network classifiers and combined their results according to the ensemble-learning algorithm.</abstract>
      <url hash="254099e5">S18-1101</url>
      <doi>10.18653/v1/S18-1101</doi>
      <bibkey>peng-etal-2018-ynu</bibkey>
    </paper>
    <paper id="102">
      <title>Binarizer at SemEval-2018 Task 3 : Parsing dependency and <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> for irony detection<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Parsing dependency and deep learning for irony detection</title>
      <author><first>Nishant</first> <last>Nikhil</last></author>
      <author><first>Muktabh</first> <last>Mayank Srivastava</last></author>
      <pages>628–632</pages>
      <abstract>In this paper, we describe the system submitted for the SemEval 2018 Task 3 (Irony detection in English tweets) Subtask A by the team Binarizer. Irony detection is a key task for many natural language processing works. Our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> treats ironical tweets to consist of smaller parts containing different <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a>. We break down tweets into separate phrases using a <a href="https://en.wikipedia.org/wiki/Dependency_grammar">dependency parser</a>. We then embed those phrases using an LSTM-based neural network model which is pre-trained to predict <a href="https://en.wikipedia.org/wiki/Emoticon">emoticons</a> for tweets. Finally, we train a <a href="https://en.wikipedia.org/wiki/Connectivity_(graph_theory)">fully-connected network</a> to achieve <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a>.</abstract>
      <url hash="856feebe">S18-1102</url>
      <doi>10.18653/v1/S18-1102</doi>
      <bibkey>nikhil-mayank-srivastava-2018-binarizer</bibkey>
    </paper>
    <paper id="105">
      <title>ValenTO at SemEval-2018 Task 3 : Exploring the Role of Affective Content for Detecting Irony in English Tweets<fixed-case>V</fixed-case>alen<fixed-case>TO</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Exploring the Role of Affective Content for Detecting Irony in <fixed-case>E</fixed-case>nglish Tweets</title>
      <author><first>Delia Irazú</first> <last>Hernández Farías</last></author>
      <author><first>Viviana</first> <last>Patti</last></author>
      <author><first>Paolo</first> <last>Rosso</last></author>
      <pages>643–648</pages>
      <abstract>In this paper we describe the system used by the ValenTO team in the shared task on Irony Detection in English Tweets at SemEval 2018. The system takes as starting point emotIDM, an irony detection model that explores the use of affective features based on a wide range of lexical resources available for <a href="https://en.wikipedia.org/wiki/English_language">English</a>, reflecting different facets of affect. We experimented with different settings, by exploiting different <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> and <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>, and participated both to the binary irony detection task and to the task devoted to distinguish among different types of <a href="https://en.wikipedia.org/wiki/Irony">irony</a>. We report on the results obtained by our system both in a constrained setting and unconstrained setting, where we explored the impact of using additional data in the training phase, such as corpora annotated for the presence of <a href="https://en.wikipedia.org/wiki/Irony">irony</a> or <a href="https://en.wikipedia.org/wiki/Sarcasm">sarcasm</a> from the <a href="https://en.wikipedia.org/wiki/State_of_the_art">state of the art</a>. Overall, the performance of our <a href="https://en.wikipedia.org/wiki/System">system</a> seems to validate the important role that affective information has for identifying ironic content in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>.</abstract>
      <url hash="0bfedaa3">S18-1105</url>
      <doi>10.18653/v1/S18-1105</doi>
      <bibkey>hernandez-farias-etal-2018-valento</bibkey>
    </paper>
    <paper id="108">
      <title>NewsReader at SemEval-2018 Task 5 : Counting events by reasoning over event-centric-knowledge-graphs<fixed-case>N</fixed-case>ews<fixed-case>R</fixed-case>eader at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 5: Counting events by reasoning over event-centric-knowledge-graphs</title>
      <author><first>Piek</first> <last>Vossen</last></author>
      <pages>660–666</pages>
      <abstract>In this paper, we describe the participation of the NewsReader system in the SemEval-2018 Task 5 on Counting Events and Participants in the Long Tail. NewsReader is a generic <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised text processing system</a> that detects events with participants, time and place to generate Event Centric Knowledge Graphs (ECKGs). We minimally adapted these ECKGs to establish a baseline performance for the <a href="https://en.wikipedia.org/wiki/Task_(computing)">task</a>. We first use the ECKGs to establish which documents report on the same incident and what event mentions are coreferential. Next, we aggregate ECKGs across coreferential mentions and use the aggregated knowledge to answer the questions of the task. Our participation tests the quality of NewsReader to create ECKGs, as well as the potential of ECKGs to establish event identity and reason over the result to answer the task queries.</abstract>
      <url hash="0de7ff68">S18-1108</url>
      <doi>10.18653/v1/S18-1108</doi>
      <bibkey>vossen-2018-newsreader</bibkey>
    </paper>
    <paper id="113">
      <title>SemEval-2018 Task 8 : Semantic Extraction from CybersecUrity REports using Natural Language Processing (SecureNLP)<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 8: Semantic Extraction from <fixed-case>C</fixed-case>ybersec<fixed-case>U</fixed-case>rity <fixed-case>RE</fixed-case>ports using Natural Language Processing (<fixed-case>S</fixed-case>ecure<fixed-case>NLP</fixed-case>)</title>
      <author><first>Peter</first> <last>Phandi</last></author>
      <author><first>Amila</first> <last>Silva</last></author>
      <author><first>Wei</first> <last>Lu</last></author>
      <pages>697–706</pages>
      <abstract>This paper describes the <a href="https://en.wikipedia.org/wiki/SemEval">SemEval 2018 shared task</a> on semantic extraction from cybersecurity reports, which is introduced for the first time as a shared task on <a href="https://en.wikipedia.org/wiki/SemEval">SemEval</a>. This task comprises four SubTasks done incrementally to predict the characteristics of a specific malware using cybersecurity reports. To the best of our knowledge, we introduce the world’s largest publicly available dataset of annotated malware reports in this task. This <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> received in total 18 submissions from 9 participating teams.</abstract>
      <url hash="8bd299c0">S18-1113</url>
      <doi>10.18653/v1/S18-1113</doi>
      <bibkey>phandi-etal-2018-semeval</bibkey>
    </paper>
    <paper id="114">
      <title>DM_NLP at SemEval-2018 Task 8 : neural sequence labeling with linguistic features<fixed-case>DM</fixed-case>_<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 8: neural sequence labeling with linguistic features</title>
      <author><first>Chunping</first> <last>Ma</last></author>
      <author><first>Huafei</first> <last>Zheng</last></author>
      <author><first>Pengjun</first> <last>Xie</last></author>
      <author><first>Chen</first> <last>Li</last></author>
      <author><first>Linlin</first> <last>Li</last></author>
      <author><first>Luo</first> <last>Si</last></author>
      <pages>707–711</pages>
      <abstract>This paper describes our submissions for SemEval-2018 Task 8 : Semantic Extraction from CybersecUrity REports using <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>. The DM_NLP participated in two subtasks : SubTask 1 classifies if a sentence is useful for inferring malware actions and capabilities, and SubTask 2 predicts token labels (Action, Entity, Modifier and Others) for a given malware-related sentence. Since we leverage results of Subtask 2 directly to infer the result of Subtask 1, the paper focus on the system solving Subtask 2. By taking Subtask 2 as a sequence labeling task, our system relies on a <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network</a> named BiLSTM-CNN-CRF with rich linguistic features, such as POS tags, dependency parsing labels, chunking labels, NER labels, Brown clustering. Our <a href="https://en.wikipedia.org/wiki/System">system</a> achieved the highest F1 score in both token level and phrase level.</abstract>
      <url hash="fa6627a9">S18-1114</url>
      <doi>10.18653/v1/S18-1114</doi>
      <bibkey>ma-etal-2018-dm</bibkey>
    </paper>
    <paper id="115">
      <title>SemEval-2018 Task 9 : Hypernym Discovery<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 9: Hypernym Discovery</title>
      <author><first>Jose</first> <last>Camacho-Collados</last></author>
      <author><first>Claudio</first> <last>Delli Bovi</last></author>
      <author><first>Luis</first> <last>Espinosa-Anke</last></author>
      <author><first>Sergio</first> <last>Oramas</last></author>
      <author><first>Tommaso</first> <last>Pasini</last></author>
      <author><first>Enrico</first> <last>Santus</last></author>
      <author><first>Vered</first> <last>Shwartz</last></author>
      <author><first>Roberto</first> <last>Navigli</last></author>
      <author><first>Horacio</first> <last>Saggion</last></author>
      <pages>712–724</pages>
      <abstract>This paper describes the SemEval 2018 Shared Task on Hypernym Discovery. We put forward this task as a complementary benchmark for modeling <a href="https://en.wikipedia.org/wiki/Hypernymy">hypernymy</a>, a problem which has traditionally been cast as a binary classification task, taking a pair of candidate words as input. Instead, our reformulated task is defined as follows : given an input term, retrieve (or discover) its suitable <a href="https://en.wikipedia.org/wiki/Hypernym">hypernyms</a> from a target corpus. We proposed five different subtasks covering three languages (English, Spanish, and Italian), and two specific domains of knowledge in English (Medical and Music). Participants were allowed to compete in any or all of the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">subtasks</a>. Overall, a total of 11 teams participated, with a total of 39 different systems submitted through all subtasks. Data, results and further information about the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> can be found at.<url>https://competitions.codalab.org/competitions/17119</url>.
    </abstract>
      <url hash="c1cf581f">S18-1115</url>
      <doi>10.18653/v1/S18-1115</doi>
      <bibkey>camacho-collados-etal-2018-semeval</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2018-task-9-hypernym-discovery">SemEval-2018 Task 9: Hypernym Discovery</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/yago">YAGO</pwcdataset>
    </paper>
    <paper id="117">
      <title>SemEval-2018 Task 10 : Capturing Discriminative Attributes<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Capturing Discriminative Attributes</title>
      <author><first>Alicia</first> <last>Krebs</last></author>
      <author><first>Alessandro</first> <last>Lenci</last></author>
      <author><first>Denis</first> <last>Paperno</last></author>
      <pages>732–740</pages>
      <abstract>This paper describes the SemEval 2018 Task 10 on Capturing Discriminative Attributes. Participants were asked to identify whether an attribute could help discriminate between two concepts. For example, a successful <a href="https://en.wikipedia.org/wiki/System">system</a> should determine that ‘urine’ is a discriminating feature in the word pair ‘kidney’, ‘bone’. The aim of the task is to better evaluate the capabilities of state of the art semantic models, beyond pure semantic similarity. The <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> attracted submissions from 21 teams, and the best <a href="https://en.wikipedia.org/wiki/System">system</a> achieved a 0.75 F1 score.</abstract>
      <url hash="34de5cec">S18-1117</url>
      <doi>10.18653/v1/S18-1117</doi>
      <bibkey>krebs-etal-2018-semeval</bibkey>
    </paper>
    <paper id="119">
      <title>SemEval-2018 Task 11 : <a href="https://en.wikipedia.org/wiki/Machine_learning">Machine Comprehension</a> Using Commonsense Knowledge<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 11: Machine Comprehension Using Commonsense Knowledge</title>
      <author><first>Simon</first> <last>Ostermann</last></author>
      <author><first>Michael</first> <last>Roth</last></author>
      <author><first>Ashutosh</first> <last>Modi</last></author>
      <author><first>Stefan</first> <last>Thater</last></author>
      <author><first>Manfred</first> <last>Pinkal</last></author>
      <pages>747–757</pages>
      <abstract>This report summarizes the results of the SemEval 2018 task on <a href="https://en.wikipedia.org/wiki/Machine_learning">machine comprehension</a> using <a href="https://en.wikipedia.org/wiki/Commonsense_knowledge">commonsense knowledge</a>. For this machine comprehension task, we created a new <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>, MCScript. It contains a high number of questions that require <a href="https://en.wikipedia.org/wiki/Commonsense_knowledge">commonsense knowledge</a> for finding the correct answer. 11 teams from 4 different countries participated in this shared <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, most of them used neural approaches. The best performing <a href="https://en.wikipedia.org/wiki/System">system</a> achieves an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 83.95 %, outperforming the <a href="https://en.wikipedia.org/wiki/Baseline_(medicine)">baselines</a> by a large margin, but still far from the <a href="https://en.wikipedia.org/wiki/Upper_and_lower_bounds">human upper bound</a>, which was found to be at 98 %.</abstract>
      <url hash="19e9ab5a">S18-1119</url>
      <doi>10.18653/v1/S18-1119</doi>
      <bibkey>ostermann-etal-2018-semeval</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mcscript">MCScript</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mctest">MCTest</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/newsqa">NewsQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/race">RACE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/triviaqa">TriviaQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/babi-1">bAbI</pwcdataset>
    </paper>
    <paper id="120">
      <title>Yuanfudao at SemEval-2018 Task 11 : Three-way Attention and Relational Knowledge for Commonsense Machine Comprehension<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 11: Three-way Attention and Relational Knowledge for Commonsense Machine Comprehension</title>
      <author><first>Liang</first> <last>Wang</last></author>
      <author><first>Meng</first> <last>Sun</last></author>
      <author><first>Wei</first> <last>Zhao</last></author>
      <author><first>Kewei</first> <last>Shen</last></author>
      <author><first>Jingming</first> <last>Liu</last></author>
      <pages>758–762</pages>
      <abstract>This paper describes our <a href="https://en.wikipedia.org/wiki/System">system</a> for SemEval-2018 Task 11 : <a href="https://en.wikipedia.org/wiki/Machine_learning">Machine Comprehension</a> using Commonsense Knowledge. We use Three-way Attentive Networks (TriAN) to model interactions between the passage, question and answers. To incorporate <a href="https://en.wikipedia.org/wiki/Commonsense_knowledge">commonsense knowledge</a>, we augment the input with relation embedding from the graph of general knowledge ConceptNet. As a result, our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves state-of-the-art performance with 83.95 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> on the official test data. Code is publicly available at.<url>https://github.com/intfloat/commonsense-rc</url>.
    </abstract>
      <url hash="7a23223b">S18-1120</url>
      <doi>10.18653/v1/S18-1120</doi>
      <bibkey>wang-etal-2018-yuanfudao</bibkey>
      <pwccode url="https://github.com/intfloat/commonsense-rc" additional="true">intfloat/commonsense-rc</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/race">RACE</pwcdataset>
    </paper>
    <paper id="121">
      <title>SemEval-2018 Task 12 : The Argument Reasoning Comprehension Task<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: The Argument Reasoning Comprehension Task</title>
      <author><first>Ivan</first> <last>Habernal</last></author>
      <author><first>Henning</first> <last>Wachsmuth</last></author>
      <author><first>Iryna</first> <last>Gurevych</last></author>
      <author><first>Benno</first> <last>Stein</last></author>
      <pages>763–772</pages>
      <abstract>A natural language argument is composed of a claim as well as reasons given as premises for the claim. The warrant explaining the reasoning is usually left implicit, as it is clear from the context and common sense. This makes a <a href="https://en.wikipedia.org/wiki/Comprehension_(logic)">comprehension of arguments</a> easy for humans but hard for machines. This paper summarizes the first shared <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> on argument reasoning comprehension. Given a premise and a claim along with some topic information, the goal was to automatically identify the correct warrant among two candidates that are plausible and lexically close, but in fact imply opposite claims. We describe the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> with 1970 instances that we built for the task, and we outline the 21 computational approaches that participated, most of which used <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a>. The results reveal the <a href="https://en.wikipedia.org/wiki/Computational_complexity_theory">complexity</a> of the <a href="https://en.wikipedia.org/wiki/Computational_complexity_theory">task</a>, with many approaches hardly improving over the <a href="https://en.wikipedia.org/wiki/Random_variable">random accuracy</a> of about 0.5. Still, the best observed accuracy (0.712) underlines the principle feasibility of <a href="https://en.wikipedia.org/wiki/Warrant_(law)">identifying warrants</a>. Our analysis indicates that an inclusion of <a href="https://en.wikipedia.org/wiki/Knowledge">external knowledge</a> is key to <a href="https://en.wikipedia.org/wiki/Understanding">reasoning comprehension</a>.</abstract>
      <url hash="6ae6ad14">S18-1121</url>
      <doi>10.18653/v1/S18-1121</doi>
      <bibkey>habernal-etal-2018-semeval</bibkey>
    </paper>
    <paper id="122">
      <title>GIST at SemEval-2018 Task 12 : A network transferring inference knowledge to Argument Reasoning Comprehension task<fixed-case>GIST</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: A network transferring inference knowledge to Argument Reasoning Comprehension task</title>
      <author><first>HongSeok</first> <last>Choi</last></author>
      <author><first>Hyunju</first> <last>Lee</last></author>
      <pages>773–777</pages>
      <abstract>This paper describes our GIST team system that participated in SemEval-2018 Argument Reasoning Comprehension task (Task 12). Here, we address two challenging factors : unstated common senses and two lexically close warrants that lead to contradicting claims. A key idea for our <a href="https://en.wikipedia.org/wiki/System">system</a> is full use of <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> from the Natural Language Inference (NLI) task to this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. We used Enhanced Sequential Inference Model (ESIM) to learn the NLI dataset. We describe how to use ESIM for <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> to choose correct warrant through a proposed <a href="https://en.wikipedia.org/wiki/System">system</a>. We show comparable results through ablation experiments. Our <a href="https://en.wikipedia.org/wiki/System">system</a> ranked 1st among 22 systems, outperforming all the <a href="https://en.wikipedia.org/wiki/System">systems</a> more than 10 %.</abstract>
      <url hash="18861404">S18-1122</url>
      <doi>10.18653/v1/S18-1122</doi>
      <bibkey>choi-lee-2018-gist</bibkey>
      <pwccode url="https://github.com/hongking9/SemEval-2018-task12" additional="false">hongking9/SemEval-2018-task12</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="123">
      <title>LightRel at SemEval-2018 Task 7 : Lightweight and Fast Relation Classification<fixed-case>L</fixed-case>ight<fixed-case>R</fixed-case>el at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Lightweight and Fast Relation Classification</title>
      <author><first>Tyler</first> <last>Renslow</last></author>
      <author><first>Günter</first> <last>Neumann</last></author>
      <pages>778–782</pages>
      <abstract>We present LightRel, a lightweight and fast relation classifier. Our goal is to develop a high baseline for different relation extraction tasks. By defining only very few data-internal, word-level features and external knowledge sources in the form of word clusters and <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>, we train a fast and simple <a href="https://en.wikipedia.org/wiki/Linear_classifier">linear classifier</a></abstract>
      <url hash="4e9b5b4a">S18-1123</url>
      <doi>10.18653/v1/S18-1123</doi>
      <bibkey>renslow-neumann-2018-lightrel</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2010-task-8">SemEval-2010 Task 8</pwcdataset>
    </paper>
    <paper id="124">
      <title>OhioState at SemEval-2018 Task 7 : Exploiting Data Augmentation for Relation Classification in Scientific Papers Using Piecewise Convolutional Neural Networks<fixed-case>O</fixed-case>hio<fixed-case>S</fixed-case>tate at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Exploiting Data Augmentation for Relation Classification in Scientific Papers Using Piecewise Convolutional Neural Networks</title>
      <author><first>Dushyanta</first> <last>Dhyani</last></author>
      <pages>783–787</pages>
      <abstract>We describe our system for SemEval-2018 Shared Task on Semantic Relation Extraction and Classification in Scientific Papers where we focus on the Classification task. Our simple piecewise convolution neural encoder performs decently in an end to end manner. A simple inter-task data augmentation significantly boosts the performance of the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>. Our best-performing systems stood 8th out of 20 teams on the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification task</a> on <a href="https://en.wikipedia.org/wiki/Noisy_data">noisy data</a> and 12th out of 28 teams on the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification task</a> on clean data.</abstract>
      <url hash="c58346d4">S18-1124</url>
      <doi>10.18653/v1/S18-1124</doi>
      <bibkey>dhyani-2018-ohiostate</bibkey>
    </paper>
    <paper id="126">
      <title>UC3M-NII Team at SemEval-2018 Task 7 : Semantic Relation Classification in Scientific Papers via Convolutional Neural Network<fixed-case>UC</fixed-case>3<fixed-case>M</fixed-case>-<fixed-case>NII</fixed-case> Team at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Semantic Relation Classification in Scientific Papers via Convolutional Neural Network</title>
      <author><first>Víctor</first> <last>Suárez-Paniagua</last></author>
      <author><first>Isabel</first> <last>Segura-Bedmar</last></author>
      <author><first>Akiko</first> <last>Aizawa</last></author>
      <pages>793–797</pages>
      <abstract>This paper reports our participation for SemEval-2018 Task 7 on extraction and classification of relationships between entities in <a href="https://en.wikipedia.org/wiki/Scientific_literature">scientific papers</a>. Our approach is based on the use of a Convolutional Neural Network (CNN) trained on350 abstract with manually annotated entities and relations. Our hypothesis is that this deep learning model can be applied to extract and classify relations between entities for <a href="https://en.wikipedia.org/wiki/Scientific_literature">scientific papers</a> at the same time. We use the Part-of-Speech and the distances to the target entities as part of the embedding for each word and we blind all the entities by marker names. In addition, we use <a href="https://en.wikipedia.org/wiki/Sampling_(statistics)">sampling techniques</a> to overcome the imbalance issues of this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>. Our <a href="https://en.wikipedia.org/wiki/Computer_architecture">architecture</a> obtained an F1-score of 35.4 % for the relation extraction task and 18.5 % for the relation classification task with a basic configuration of the one step CNN.</abstract>
      <url hash="aac62a4a">S18-1126</url>
      <doi>10.18653/v1/S18-1126</doi>
      <bibkey>suarez-paniagua-etal-2018-uc3m</bibkey>
    </paper>
    <paper id="127">
      <title>MIT-MEDG at SemEval-2018 Task 7 : Semantic Relation Classification via Convolution Neural Network<fixed-case>MIT</fixed-case>-<fixed-case>MEDG</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Semantic Relation Classification via Convolution Neural Network</title>
      <author><first>Di</first> <last>Jin</last></author>
      <author><first>Franck</first> <last>Dernoncourt</last></author>
      <author><first>Elena</first> <last>Sergeeva</last></author>
      <author><first>Matthew</first> <last>McDermott</last></author>
      <author><first>Geeticka</first> <last>Chauhan</last></author>
      <pages>798–804</pages>
      <abstract>SemEval 2018 Task 7 tasked participants to build a <a href="https://en.wikipedia.org/wiki/System">system</a> to classify two entities within a sentence into one of the 6 possible relation types. We tested 3 classes of <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> : Linear classifiers, Long Short-Term Memory (LSTM) models, and Convolutional Neural Network (CNN) models. Ultimately, the CNN model class proved most performant, so we specialized to this <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> for our final submissions. We improved performance beyond a vanilla CNN by including a variant of negative sampling, using custom <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> learned over a corpus of ACL articles, training over corpora of both <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> 1.1 and 1.2, using reversed feature, using part of context words beyond the entity pairs and using <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble methods</a> to improve our final predictions. We also tested attention based pooling, up-sampling, and <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a>, but none improved performance. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieved rank 6 out of 28 (macro-averaged F1-score : 72.7) in subtask 1.1, and rank 4 out of 20 (macro F1 : 80.6) in subtask 1.2.</abstract>
      <url hash="432eddf1">S18-1127</url>
      <doi>10.18653/v1/S18-1127</doi>
      <bibkey>jin-etal-2018-mit</bibkey>
    </paper>
    <paper id="128">
      <title>SIRIUS-LTG-UiO at SemEval-2018 Task 7 : Convolutional Neural Networks with Shortest Dependency Paths for Semantic Relation Extraction and Classification in Scientific Papers<fixed-case>SIRIUS</fixed-case>-<fixed-case>LTG</fixed-case>-<fixed-case>U</fixed-case>i<fixed-case>O</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Convolutional Neural Networks with Shortest Dependency Paths for Semantic Relation Extraction and Classification in Scientific Papers</title>
      <author><first>Farhad</first> <last>Nooralahzadeh</last></author>
      <author><first>Lilja</first> <last>Øvrelid</last></author>
      <author><first>Jan Tore</first> <last>Lønning</last></author>
      <pages>805–810</pages>
      <abstract>This article presents the SIRIUS-LTG-UiO system for the SemEval 2018 Task 7 on Semantic Relation Extraction and Classification in Scientific Papers. First we extract the shortest dependency path (sdp) between two entities, then we introduce a convolutional neural network (CNN) which takes the shortest dependency path embeddings as input and performs relation classification with differing objectives for each subtask of the shared task. This approach achieved overall F1 scores of 76.7 and 83.2 for <a href="https://en.wikipedia.org/wiki/Relation_(database)">relation classification</a> on clean and noisy data, respectively. Furthermore, for combined relation extraction and classification on <a href="https://en.wikipedia.org/wiki/Data_integrity">clean data</a>, it obtained <a href="https://en.wikipedia.org/wiki/F-number">F1 scores</a> of 37.4 and 33.6 for each phase. Our <a href="https://en.wikipedia.org/wiki/System">system</a> ranks 3rd in all three sub-tasks of the shared task.</abstract>
      <url hash="a926772d">S18-1128</url>
      <doi>10.18653/v1/S18-1128</doi>
      <bibkey>nooralahzadeh-etal-2018-sirius</bibkey>
    </paper>
    <paper id="131">
      <title>Texterra at SemEval-2018 Task 7 : Exploiting Syntactic Information for Relation Extraction and Classification in Scientific Papers<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Exploiting Syntactic Information for Relation Extraction and Classification in Scientific Papers</title>
      <author><first>Andrey</first> <last>Sysoev</last></author>
      <author><first>Vladimir</first> <last>Mayorov</last></author>
      <pages>821–825</pages>
      <abstract>In this work we evaluate applicability of <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity pair models</a> and neural network architectures for relation extraction and classification in scientific papers at SemEval-2018. We carry out experiments with representing entity pairs through sentence tokens and through shortest path in dependency tree, comparing approaches based on convolutional and recurrent neural networks. With convolutional network applied to shortest path in dependency tree we managed to be ranked eighth in subtask 1.1 (clean data), ninth in 1.2 (noisy data). Similar model applied to separate parts of the <a href="https://en.wikipedia.org/wiki/Shortest_path_problem">shortest path</a> was mounted to ninth (extraction track) and seventh (classification track) positions in subtask 2 ranking.</abstract>
      <url hash="3023bc3e">S18-1131</url>
      <doi>10.18653/v1/S18-1131</doi>
      <bibkey>sysoev-mayorov-2018-texterra</bibkey>
    </paper>
    <paper id="132">
      <title>UniMa at SemEval-2018 Task 7 : Semantic Relation Extraction and Classification from Scientific Publications<fixed-case>U</fixed-case>ni<fixed-case>M</fixed-case>a at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Semantic Relation Extraction and Classification from Scientific Publications</title>
      <author><first>Thorsten</first> <last>Keiper</last></author>
      <author><first>Zhonghao</first> <last>Lyu</last></author>
      <author><first>Sara</first> <last>Pooladzadeh</last></author>
      <author><first>Yuan</first> <last>Xu</last></author>
      <author><first>Jingyi</first> <last>Zhang</last></author>
      <author><first>Anne</first> <last>Lauscher</last></author>
      <author><first>Simone Paolo</first> <last>Ponzetto</last></author>
      <pages>826–830</pages>
      <abstract>Large repositories of scientific literature call for the development of robust methods to extract information from <a href="https://en.wikipedia.org/wiki/Academic_publishing">scholarly papers</a>. This <a href="https://en.wikipedia.org/wiki/Problem_solving">problem</a> is addressed by the SemEval 2018 Task 7 on extracting and classifying relations found within <a href="https://en.wikipedia.org/wiki/Scientific_literature">scientific publications</a>. In this paper, we present a feature-based and a deep learning-based approach to the task and discuss the results of the system runs that we submitted for evaluation.</abstract>
      <url hash="235910cb">S18-1132</url>
      <doi>10.18653/v1/S18-1132</doi>
      <bibkey>keiper-etal-2018-unima</bibkey>
    </paper>
    <paper id="134">
      <title>ClaiRE at SemEval-2018 Task 7 : Classification of Relations using Embeddings<fixed-case>C</fixed-case>lai<fixed-case>RE</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Classification of Relations using Embeddings</title>
      <author><first>Lena</first> <last>Hettinger</last></author>
      <author><first>Alexander</first> <last>Dallmann</last></author>
      <author><first>Albin</first> <last>Zehe</last></author>
      <author><first>Thomas</first> <last>Niebler</last></author>
      <author><first>Andreas</first> <last>Hotho</last></author>
      <pages>836–841</pages>
      <abstract>In this paper we describe our <a href="https://en.wikipedia.org/wiki/System">system</a> for SemEval-2018 Task 7 on classification of semantic relations in <a href="https://en.wikipedia.org/wiki/Scientific_literature">scientific literature</a> for clean (subtask 1.1) and noisy data (subtask 1.2). We compare two models for classification, a C-LSTM which utilizes only <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> and an SVM that also takes handcrafted features into account. To adapt to the domain of science we train <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> on <a href="https://en.wikipedia.org/wiki/Scientific_literature">scientific papers</a> collected from arXiv.org. The hand-crafted features consist of lexical features to model the semantic relations as well as the entities between which the relation holds. Classification of Relations using Embeddings (ClaiRE) achieved an F1 score of 74.89 % for the first subtask and 78.39 % for the second.</abstract>
      <url hash="5bfbefc2">S18-1134</url>
      <doi>10.18653/v1/S18-1134</doi>
      <bibkey>hettinger-etal-2018-claire</bibkey>
    </paper>
    <paper id="138">
      <title>NTNU at SemEval-2018 Task 7 : Classifier Ensembling for Semantic Relation Identification and Classification in Scientific Papers<fixed-case>NTNU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Classifier Ensembling for Semantic Relation Identification and Classification in Scientific Papers</title>
      <author><first>Biswanath</first> <last>Barik</last></author>
      <author><first>Utpal Kumar</first> <last>Sikdar</last></author>
      <author><first>Björn</first> <last>Gambäck</last></author>
      <pages>858–862</pages>
      <abstract>The paper presents NTNU’s contribution to SemEval-2018 Task 7 on relation identification and classification. The class weights and parameters of five alternative supervised classifiers were optimized through <a href="https://en.wikipedia.org/wiki/Grid_search">grid search</a> and <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">cross-validation</a>. The outputs of the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> were combined through <a href="https://en.wikipedia.org/wiki/Voting">voting</a> for the final prediction. A wide variety of <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> were explored, with the most informative identified by <a href="https://en.wikipedia.org/wiki/Feature_selection">feature selection</a>. The best setting achieved F1 scores of 47.4 % and 66.0 % in the relation classification subtasks 1.1 and 1.2. For relation identification and classification in subtask 2, it achieved F1 scores of 33.9 % and 17.0 %,</abstract>
      <url hash="414c121d">S18-1138</url>
      <doi>10.18653/v1/S18-1138</doi>
      <bibkey>barik-etal-2018-ntnu</bibkey>
    </paper>
    <paper id="139">
      <title>Talla at SemEval-2018 Task 7 : Hybrid Loss Optimization for Relation Classification using Convolutional Neural Networks<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Hybrid Loss Optimization for Relation Classification using Convolutional Neural Networks</title>
      <author><first>Bhanu</first> <last>Pratap</last></author>
      <author><first>Daniel</first> <last>Shank</last></author>
      <author><first>Oladipo</first> <last>Ositelu</last></author>
      <author><first>Byron</first> <last>Galbraith</last></author>
      <pages>863–867</pages>
      <abstract>This paper describes our approach to SemEval-2018 Task 7   given an entity-tagged text from the ACL Anthology corpus, identify and classify pairs of entities that have one of six possible semantic relationships. Our model consists of a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a> leveraging pre-trained word embeddings, unlabeled ACL-abstracts, and multiple window sizes to automatically learn useful features from entity-tagged sentences. We also experiment with a hybrid loss function, a combination of cross-entropy loss and ranking loss, to boost the separation in classification scores. Lastly, we include WordNet-based features to further improve the performance of our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>. Our best <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves an F1(macro) score of 74.2 and 84.8 on subtasks 1.1 and 1.2, respectively.</abstract>
      <url hash="f905abb9">S18-1139</url>
      <doi>10.18653/v1/S18-1139</doi>
      <bibkey>pratap-etal-2018-talla</bibkey>
    </paper>
    <paper id="140">
      <title>TeamDL at SemEval-2018 Task 8 : Cybersecurity Text Analysis using <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Network</a> and Conditional Random Fields<fixed-case>T</fixed-case>eam<fixed-case>DL</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 8: Cybersecurity Text Analysis using Convolutional Neural Network and Conditional Random Fields</title>
      <author><first>Manikandan</first> <last>R</last></author>
      <author><first>Krishna</first> <last>Madgula</last></author>
      <author><first>Snehanshu</first> <last>Saha</last></author>
      <pages>868–873</pages>
      <abstract>In this work we present our participation to SemEval-2018 Task 8 subtasks 1 &amp; 2 respectively. We developed Convolution Neural Network system for malware sentence classification (subtask 1) and Conditional Random Fields system for malware token label prediction (subtask 2). We experimented with couple of word embedding strategies, feature sets and achieved competitive performance across the two subtasks. For subtask 1 We experimented with two category of word embeddings namely native embeddings and task specific embedding using Word2vec and Glove algorithms. Native Embeddings : All words including the unknown ones that are randomly initialized use embeddings from original Word2vec / Glove models. Task specific : The embeddings are generated by training Word2vec / Glove algorithms on sentences from MalwareTextDB We found that glove outperforms rest of embeddings for subtask 1. For subtask 2, we used N-grams of size 6, previous, next tokens and labels, <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">features</a> giving disjunctions of words anywhere in the left or right, word shape features, word lemma of current, previous and next words, word-tag pair features, POS tags, prefix and suffixes.</abstract>
      <url hash="aed91bba">S18-1140</url>
      <doi>10.18653/v1/S18-1140</doi>
      <bibkey>r-etal-2018-teamdl</bibkey>
    </paper>
    <paper id="141">
      <title>HCCL at SemEval-2018 Task 8 : An End-to-End System for Sequence Labeling from Cybersecurity Reports<fixed-case>HCCL</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 8: An End-to-End System for Sequence Labeling from Cybersecurity Reports</title>
      <author><first>Mingming</first> <last>Fu</last></author>
      <author><first>Xuemin</first> <last>Zhao</last></author>
      <author><first>Yonghong</first> <last>Yan</last></author>
      <pages>874–877</pages>
      <abstract>This paper describes HCCL team systems that participated in SemEval 2018 Task 8 : SecureNLP (Semantic Extraction from cybersecurity reports using NLP). To solve the problem, our team applied a neural network architecture that benefits from both word and character level representaions automatically, by using combination of Bi-directional LSTM, CNN and CRF (Ma and Hovy, 2016). Our system is truly end-to-end, requiring no <a href="https://en.wikipedia.org/wiki/Feature_engineering">feature engineering</a> or <a href="https://en.wikipedia.org/wiki/Data_preprocessing">data preprocessing</a>, and we ranked 4th in the subtask 1, 7th in the subtask2 and 3rd in the SubTask2-relaxed.</abstract>
      <url hash="c5f5ff5a">S18-1141</url>
      <doi>10.18653/v1/S18-1141</doi>
      <bibkey>fu-etal-2018-hccl</bibkey>
    </paper>
    <paper id="142">
      <title>UMBC at SemEval-2018 Task 8 : Understanding Text about Malware<fixed-case>UMBC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 8: Understanding Text about Malware</title>
      <author><first>Ankur</first> <last>Padia</last></author>
      <author><first>Arpita</first> <last>Roy</last></author>
      <author><first>Taneeya</first> <last>Satyapanich</last></author>
      <author><first>Francis</first> <last>Ferraro</last></author>
      <author><first>Shimei</first> <last>Pan</last></author>
      <author><first>Youngja</first> <last>Park</last></author>
      <author><first>Anupam</first> <last>Joshi</last></author>
      <author><first>Tim</first> <last>Finin</last></author>
      <pages>878–884</pages>
      <abstract>We describe the systems developed by the UMBC team for 2018 SemEval Task 8, SecureNLP (Semantic Extraction from CybersecUrity REports using Natural Language Processing). We participated in three of the sub-tasks : (1) classifying sentences as being relevant or irrelevant to malware, (2) predicting token labels for sentences, and (4) predicting attribute labels from the Malware Attribute Enumeration and Characterization vocabulary for defining malware characteristics. We achieve <a href="https://en.wikipedia.org/wiki/F-number">F1 score</a> of 50.34/18.0 (dev / test), 22.23 (test-data), and 31.98 (test-data) for Task1, Task2 and Task2 respectively. We also make our cybersecurity embeddings publicly available at.<url>http://bit.ly/cyber2vec</url>.
    </abstract>
      <url hash="d5cba936">S18-1142</url>
      <doi>10.18653/v1/S18-1142</doi>
      <bibkey>padia-etal-2018-umbc</bibkey>
    </paper>
    <paper id="143">
      <title>Villani at SemEval-2018 Task 8 : Semantic Extraction from Cybersecurity Reports using <a href="https://en.wikipedia.org/wiki/Representation_learning">Representation Learning</a><fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 8: Semantic Extraction from Cybersecurity Reports using Representation Learning</title>
      <author><first>Pablo</first> <last>Loyola</last></author>
      <author><first>Kugamoorthy</first> <last>Gajananan</last></author>
      <author><first>Yuji</first> <last>Watanabe</last></author>
      <author><first>Fumiko</first> <last>Satoh</last></author>
      <pages>885–889</pages>
      <abstract>In this paper, we describe our proposal for the task of Semantic Extraction from Cybersecurity Reports. The goal is to explore if <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing methods</a> can provide relevant and actionable knowledge to contribute to better understand <a href="https://en.wikipedia.org/wiki/Malice_(law)">malicious behavior</a>. Our method consists of an attention-based Bi-LSTM which achieved competitive performance of 0.57 for the Subtask 1. In the due process we also present ablation studies across multiple embeddings and their level of representation and also report the strategies we used to mitigate the extreme imbalance between classes.</abstract>
      <url hash="c0d6214b">S18-1143</url>
      <doi>10.18653/v1/S18-1143</doi>
      <bibkey>loyola-etal-2018-villani</bibkey>
    </paper>
    <paper id="145">
      <title>Digital Operatives at SemEval-2018 Task 8 : Using dependency features for malware NLP<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 8: Using dependency features for malware <fixed-case>NLP</fixed-case></title>
      <author><first>Chris</first> <last>Brew</last></author>
      <pages>894–897</pages>
      <abstract>The four sub-tasks of SecureNLP build towards a capability for quickly highlighting critical information from malware reports, such as the specific actions taken by a malware sample. Digital Operatives (DO) submitted to sub-tasks 1 and 2, using standard text analysis technology (text classification for sub-task 1, and a CRF for sub-task 2). Performance is broadly competitive with other submitted <a href="https://en.wikipedia.org/wiki/System">systems</a> on sub-task 1 and weak on sub-task 2. The annotation guidelines for the intermediate sub-tasks create a linkage to the final <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, which is both an annotation challenge and a potentially useful feature of the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. The methods that DO chose do not attempt to make use of this <a href="https://en.wikipedia.org/wiki/Linkage_(mechanical)">linkage</a>, which may be a missed opportunity. This motivates a post-hoc error analysis. It appears that the annotation task is very hard, and that in some cases both deep conceptual knowledge and substantial surrounding context are needed in order to correctly classify sentences.</abstract>
      <url hash="5f711ab7">S18-1145</url>
      <doi>10.18653/v1/S18-1145</doi>
      <bibkey>brew-2018-digital</bibkey>
    </paper>
    <paper id="147">
      <title>SJTU-NLP at SemEval-2018 Task 9 : Neural Hypernym Discovery with Term Embeddings<fixed-case>SJTU</fixed-case>-<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 9: Neural Hypernym Discovery with Term Embeddings</title>
      <author><first>Zhuosheng</first> <last>Zhang</last></author>
      <author><first>Jiangtong</first> <last>Li</last></author>
      <author><first>Hai</first> <last>Zhao</last></author>
      <author><first>Bingjie</first> <last>Tang</last></author>
      <pages>903–908</pages>
      <abstract>This paper describes a hypernym discovery system for our participation in the SemEval-2018 Task 9, which aims to discover the best (set of) candidate hypernyms for input concepts or entities, given the search space of a pre-defined vocabulary. We introduce a <a href="https://en.wikipedia.org/wiki/Neural_network">neural network architecture</a> for the concerned task and empirically study various neural network models to build the representations in latent space for words and phrases. The evaluated models include <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a>, long-short term memory network, <a href="https://en.wikipedia.org/wiki/Gated_recurrent_unit">gated recurrent unit</a> and recurrent convolutional neural network. We also explore different embedding methods, including <a href="https://en.wikipedia.org/wiki/Word_embedding">word embedding</a> and sense embedding for better performance.</abstract>
      <url hash="01e746eb">S18-1147</url>
      <doi>10.18653/v1/S18-1147</doi>
      <bibkey>zhang-etal-2018-sjtu</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2018-task-9-hypernym-discovery">SemEval-2018 Task 9: Hypernym Discovery</pwcdataset>
    </paper>
    <paper id="148">
      <title>NLP_HZ at SemEval-2018 Task 9 : a Nearest Neighbor Approach<fixed-case>NLP</fixed-case>_<fixed-case>HZ</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 9: a Nearest Neighbor Approach</title>
      <author><first>Wei</first> <last>Qiu</last></author>
      <author><first>Mosha</first> <last>Chen</last></author>
      <author><first>Linlin</first> <last>Li</last></author>
      <author><first>Luo</first> <last>Si</last></author>
      <pages>909–913</pages>
      <abstract>Hypernym discovery aims to discover the hypernym word sets given a <a href="https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy">hyponym word</a> and proper corpus. This paper proposes a simple but effective method for the discovery of hypernym sets based on <a href="https://en.wikipedia.org/wiki/Word_embedding">word embedding</a>, which can be used to measure the contextual similarities between words. Given a test <a href="https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy">hyponym word</a>, we get its hypernym lists by computing the similarities between the <a href="https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy">hyponym word</a> and words in the training data, and fill the test word’s hypernym lists with the hypernym list in the training set of the nearest similarity distance to the test word. In SemEval 2018 task9, our results, achieve 1st on <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, 2nd on <a href="https://en.wikipedia.org/wiki/Italian_language">Italian</a>, 6th on <a href="https://en.wikipedia.org/wiki/English_language">English</a> in the metric of MAP.</abstract>
      <url hash="f5a08a25">S18-1148</url>
      <doi>10.18653/v1/S18-1148</doi>
      <bibkey>qiu-etal-2018-nlp</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2018-task-9-hypernym-discovery">SemEval-2018 Task 9: Hypernym Discovery</pwcdataset>
    </paper>
    <paper id="149">
      <title>UMDuluth-CS8761 at SemEval-2018 Task9 : Hypernym Discovery using Hearst Patterns, Co-occurrence frequencies and Word Embeddings<fixed-case>UMD</fixed-case>uluth-<fixed-case>CS</fixed-case>8761 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task9: Hypernym Discovery using Hearst Patterns, Co-occurrence frequencies and Word Embeddings</title>
      <author><first>Arshia Zernab</first> <last>Hassan</last></author>
      <author><first>Manikya Swathi</first> <last>Vallabhajosyula</last></author>
      <author><first>Ted</first> <last>Pedersen</last></author>
      <pages>914–918</pages>
      <abstract>Hypernym Discovery is the task of identifying potential <a href="https://en.wikipedia.org/wiki/Hypernym">hypernyms</a> for a given term. A <a href="https://en.wikipedia.org/wiki/Hypernym">hypernym</a> is a more generalized word that is super-ordinate to more specific words. This paper explores several approaches that rely on co-occurrence frequencies of word pairs, Hearst Patterns based on regular expressions, and word embeddings created from the UMBC corpus. Our system <a href="https://en.wikipedia.org/wiki/Charles_Babbage">Babbage</a> participated in Subtask 1A for <a href="https://en.wikipedia.org/wiki/English_language">English</a> and placed 6th of 19 systems when identifying concept hypernyms, and 12th of 18 systems for entity hypernyms.</abstract>
      <url hash="948705cf">S18-1149</url>
      <doi>10.18653/v1/S18-1149</doi>
      <bibkey>hassan-etal-2018-umduluth</bibkey>
    </paper>
    <paper id="150">
      <title>EXPR at SemEval-2018 Task 9 : A Combined Approach for Hypernym Discovery<fixed-case>EXPR</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 9: A Combined Approach for Hypernym Discovery</title>
      <author><first>Ahmad</first> <last>Issa Alaa Aldine</last></author>
      <author><first>Mounira</first> <last>Harzallah</last></author>
      <author><first>Giuseppe</first> <last>Berio</last></author>
      <author><first>Nicolas</first> <last>Béchet</last></author>
      <author><first>Ahmad</first> <last>Faour</last></author>
      <pages>919–923</pages>
      <abstract>In this paper, we present our proposed <a href="https://en.wikipedia.org/wiki/System">system</a> (EXPR) to participate in the hypernym discovery task of SemEval 2018. The <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> addresses the challenge of discovering hypernym relations from a <a href="https://en.wikipedia.org/wiki/Text_corpus">text corpus</a>. Our proposal is a combined approach of path-based technique and distributional technique. We use dependency parser on a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> to extract candidate hypernyms and represent their dependency paths as a <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">feature vector</a>. The <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">feature vector</a> is concatenated with a <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">feature vector</a> obtained using Wikipedia pre-trained term embedding model. The concatenated feature vector fits a supervised machine learning method to learn a <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier model</a>. This <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is able to classify new candidate hypernyms as <a href="https://en.wikipedia.org/wiki/Hypernym">hypernym</a> or not. Our <a href="https://en.wikipedia.org/wiki/System">system</a> performs well to discover new <a href="https://en.wikipedia.org/wiki/Hypernym">hypernyms</a> not defined in gold hypernyms.</abstract>
      <url hash="c396abd8">S18-1150</url>
      <doi>10.18653/v1/S18-1150</doi>
      <bibkey>issa-alaa-aldine-etal-2018-expr</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2018-task-9-hypernym-discovery">SemEval-2018 Task 9: Hypernym Discovery</pwcdataset>
    </paper>
    <paper id="154">
      <title>Meaning_space at SemEval-2018 Task 10 : Combining explicitly encoded knowledge with information extracted from word embeddings<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Combining explicitly encoded knowledge with information extracted from word embeddings</title>
      <author><first>Pia</first> <last>Sommerauer</last></author>
      <author><first>Antske</first> <last>Fokkens</last></author>
      <author><first>Piek</first> <last>Vossen</last></author>
      <pages>940–946</pages>
      <abstract>This paper presents the two systems submitted by the meaning space team in Task 10 of the SemEval competition 2018 entitled Capturing discriminative attributes. The systems consist of combinations of approaches exploiting explicitly encoded knowledge about concepts in <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a> and information encoded in distributional semantic vectors. Rather than aiming for high performance, we explore which kind of <a href="https://en.wikipedia.org/wiki/Semantic_property">semantic knowledge</a> is best captured by different methods. The results indicate that WordNet glosses on different levels of the <a href="https://en.wikipedia.org/wiki/Hierarchy">hierarchy</a> capture many attributes relevant for this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. In combination with exploiting word embedding similarities, this source of information yielded our best results. Our best performing <a href="https://en.wikipedia.org/wiki/System">system</a> ranked 5th out of 13 final ranks. Our analysis yields insights into the different kinds of attributes represented by different sources of knowledge.</abstract>
      <url hash="2c9c2249">S18-1154</url>
      <doi>10.18653/v1/S18-1154</doi>
      <bibkey>sommerauer-etal-2018-meaning</bibkey>
    </paper>
    <paper id="156">
      <title>CitiusNLP at SemEval-2018 Task 10 : The Use of Transparent Distributional Models and Salient Contexts to Discriminate Word Attributes<fixed-case>C</fixed-case>itius<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: The Use of Transparent Distributional Models and Salient Contexts to Discriminate Word Attributes</title>
      <author><first>Pablo</first> <last>Gamallo</last></author>
      <pages>953–957</pages>
      <abstract>This article describes the <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised strategy</a> submitted by the CitiusNLP team to the SemEval 2018 Task 10, a task which consists of predict whether a word is a discriminative attribute between two other words. Our strategy relies on the correspondence between discriminative attributes and relevant contexts of a word. More precisely, the method uses transparent distributional models to extract salient contexts of words which are identified as discriminative attributes. The <a href="https://en.wikipedia.org/wiki/System">system</a> performance reaches about 70 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> when it is applied on the development dataset, but its <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> goes down (63 %) on the official test dataset.</abstract>
      <url hash="b755760b">S18-1156</url>
      <doi>10.18653/v1/S18-1156</doi>
      <bibkey>gamallo-2018-citiusnlp</bibkey>
    </paper>
    <paper id="157">
      <title>THU_NGN at SemEval-2018 Task 10 : Capturing Discriminative Attributes with MLP-CNN model<fixed-case>THU</fixed-case>_<fixed-case>NGN</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Capturing Discriminative Attributes with <fixed-case>MLP</fixed-case>-<fixed-case>CNN</fixed-case> model</title>
      <author><first>Chuhan</first> <last>Wu</last></author>
      <author><first>Fangzhao</first> <last>Wu</last></author>
      <author><first>Sixing</first> <last>Wu</last></author>
      <author><first>Zhigang</first> <last>Yuan</last></author>
      <author><first>Yongfeng</first> <last>Huang</last></author>
      <pages>958–962</pages>
      <abstract>Existing semantic models are capable of identifying the semantic similarity of words. However, it’s hard for these <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> to discriminate between a word and another similar word. Thus, the aim of SemEval-2018 Task 10 is to predict whether a word is a discriminative attribute between two concepts. In this task, we apply a multilayer perceptron (MLP)-convolutional neural network (CNN) model to identify whether an attribute is discriminative. The CNNs are used to extract low-level features from the inputs. The MLP takes both the flatten CNN maps and inputs to predict the labels. The evaluation F-score of our <a href="https://en.wikipedia.org/wiki/System">system</a> on the test set is 0.629 (ranked 15th), which indicates that our <a href="https://en.wikipedia.org/wiki/System">system</a> still needs to be improved. However, the behaviours of our <a href="https://en.wikipedia.org/wiki/System">system</a> in our experiments provide useful information, which can help to improve the collective understanding of this novel <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>.</abstract>
      <url hash="810b24ea">S18-1157</url>
      <doi>10.18653/v1/S18-1157</doi>
      <bibkey>wu-etal-2018-thu-ngn-semeval-2018</bibkey>
    </paper>
    <paper id="158">
      <title>ALB at SemEval-2018 Task 10 : A System for Capturing Discriminative Attributes<fixed-case>ALB</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: A System for Capturing Discriminative Attributes</title>
      <author><first>Bogdan</first> <last>Dumitru</last></author>
      <author><first>Alina Maria</first> <last>Ciobanu</last></author>
      <author><first>Liviu P.</first> <last>Dinu</last></author>
      <pages>963–967</pages>
      <abstract>Semantic difference detection attempts to capture whether a word is a discriminative attribute between two other words. For example, the discriminative feature red characterizes the first word from the (apple, banana) pair, but not the second. Modeling semantic difference is essential for <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">language understanding systems</a>, as it provides useful information for identifying particular aspects of <a href="https://en.wikipedia.org/wiki/Word_sense">word senses</a>. This paper describes our <a href="https://en.wikipedia.org/wiki/System">system</a> implementation (the ALB system of the NLP@Unibuc team) for the 10th task of the SemEval 2018 workshop, Capturing Discriminative Attributes. We propose a method for semantic difference detection that uses an SVM classifier with <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> based on co-occurrence counts and shallow semantic parsing, achieving 0.63 F1 score in the competition.</abstract>
      <url hash="c70ae7bc">S18-1158</url>
      <doi>10.18653/v1/S18-1158</doi>
      <bibkey>dumitru-etal-2018-alb</bibkey>
    </paper>
    <paper id="159">
      <title>ELiRF-UPV at SemEval-2018 Task 10 : Capturing Discriminative Attributes with Knowledge Graphs and Wikipedia<fixed-case>EL</fixed-case>i<fixed-case>RF</fixed-case>-<fixed-case>UPV</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Capturing Discriminative Attributes with Knowledge Graphs and <fixed-case>W</fixed-case>ikipedia</title>
      <author><first>José-Ángel</first> <last>González</last></author>
      <author><first>Lluís-F.</first> <last>Hurtado</last></author>
      <author><first>Encarna</first> <last>Segarra</last></author>
      <author><first>Ferran</first> <last>Pla</last></author>
      <pages>968–971</pages>
      <abstract>This paper describes the participation of ELiRF-UPV team at task 10, Capturing Discriminative Attributes, of SemEval-2018. Our best approach consists of using <a href="https://en.wikipedia.org/wiki/ConceptNet">ConceptNet</a>, <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a> and NumberBatch embeddings in order to stablish relationships between concepts and attributes. Furthermore, this <a href="https://en.wikipedia.org/wiki/System">system</a> achieves competitive results in the official evaluation.</abstract>
      <url hash="84ff5880">S18-1159</url>
      <doi>10.18653/v1/S18-1159</doi>
      <bibkey>gonzalez-etal-2018-elirf-upv</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
    </paper>
    <paper id="160">
      <title>Wolves at SemEval-2018 Task 10 : Semantic Discrimination based on Knowledge and Association<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Semantic Discrimination based on Knowledge and Association</title>
      <author><first>Shiva</first> <last>Taslimipoor</last></author>
      <author><first>Omid</first> <last>Rohanian</last></author>
      <author><first>Le An</first> <last>Ha</last></author>
      <author><first>Gloria</first> <last>Corpas Pastor</last></author>
      <author><first>Ruslan</first> <last>Mitkov</last></author>
      <pages>972–976</pages>
      <abstract>This paper describes the <a href="https://en.wikipedia.org/wiki/System">system</a> submitted to SemEval 2018 shared task 10 ‘Capturing Dicriminative Attributes’. We use a combination of knowledge-based and co-occurrence features to capture the semantic difference between two words in relation to an attribute. We define scores based on association measures, <a href="https://en.wikipedia.org/wiki/Grammatical_number">ngram counts</a>, word similarity, and ConceptNet relations. The <a href="https://en.wikipedia.org/wiki/System">system</a> is ranked 4th (joint) on the official leaderboard of the task.</abstract>
      <url hash="f9067449">S18-1160</url>
      <doi>10.18653/v1/S18-1160</doi>
      <bibkey>taslimipoor-etal-2018-wolves</bibkey>
    </paper>
    <paper id="162">
      <title>Luminoso at SemEval-2018 Task 10 : Distinguishing Attributes Using Text Corpora and Relational Knowledge<fixed-case>L</fixed-case>uminoso at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Distinguishing Attributes Using Text Corpora and Relational Knowledge</title>
      <author><first>Robyn</first> <last>Speer</last></author>
      <author><first>Joanna</first> <last>Lowry-Duda</last></author>
      <pages>985–989</pages>
      <abstract>Luminoso participated in the SemEval 2018 task on Capturing Discriminative Attributes with a system based on <a href="https://en.wikipedia.org/wiki/ConceptNet">ConceptNet</a>, an open knowledge graph focused on <a href="https://en.wikipedia.org/wiki/General_knowledge">general knowledge</a>. In this paper, we describe how we trained a <a href="https://en.wikipedia.org/wiki/Linear_classifier">linear classifier</a> on a small number of semantically-informed features to achieve an F1 score of 0.7368 on the task, close to the task’s high score of 0.75.</abstract>
      <url hash="aade300c">S18-1162</url>
      <doi>10.18653/v1/S18-1162</doi>
      <revision id="1" href="S18-1162v1" hash="8b47f741" />
      <revision id="2" href="S18-1162v2" hash="aade300c">No description of the changes were recorded.</revision>
      <bibkey>speer-lowry-duda-2018-luminoso</bibkey>
      <pwccode url="https://github.com/LuminosoInsight/semeval-discriminatt" additional="false">LuminosoInsight/semeval-discriminatt</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
    </paper>
    <paper id="163">
      <title>BomJi at SemEval-2018 Task 10 : Combining Vector-, Pattern- and Graph-based Information to Identify Discriminative Attributes<fixed-case>B</fixed-case>om<fixed-case>J</fixed-case>i at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Combining Vector-, Pattern- and Graph-based Information to Identify Discriminative Attributes</title>
      <author><first>Enrico</first> <last>Santus</last></author>
      <author><first>Chris</first> <last>Biemann</last></author>
      <author><first>Emmanuele</first> <last>Chersoni</last></author>
      <pages>990–994</pages>
      <abstract>This paper describes BomJi, a <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised system</a> for capturing discriminative attributes in word pairs (e.g. yellow as discriminative for banana over watermelon). The system relies on an XGB classifier trained on carefully engineered graph-, pattern- and word embedding-based features. It participated in the SemEval-2018 Task 10 on Capturing Discriminative Attributes, achieving an F1 score of 0.73 and ranking 2nd out of 26 participant systems.</abstract>
      <url hash="a817b805">S18-1163</url>
      <doi>10.18653/v1/S18-1163</doi>
      <bibkey>santus-etal-2018-bomji</bibkey>
    </paper>
    <paper id="164">
      <title>Igevorse at SemEval-2018 Task 10 : Exploring an Impact of Word Embeddings Concatenation for Capturing Discriminative Attributes<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Exploring an Impact of Word Embeddings Concatenation for Capturing Discriminative Attributes</title>
      <author><first>Maxim</first> <last>Grishin</last></author>
      <pages>995–998</pages>
      <abstract>This paper presents a comparison of several approaches for capturing discriminative attributes and considers an impact of <a href="https://en.wikipedia.org/wiki/Concatenation">concatenation</a> of several <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> of different nature on the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> performance. A similarity-based method is proposed and compared with classical machine learning approaches. It is shown that this method outperforms others on all the considered word vector models and there is a performance increase when concatenated datasets are used.</abstract>
      <url hash="e0d86f6d">S18-1164</url>
      <doi>10.18653/v1/S18-1164</doi>
      <bibkey>grishin-2018-igevorse</bibkey>
    </paper>
    <paper id="166">
      <title>AmritaNLP at SemEval-2018 Task 10 : Capturing discriminative attributes using convolution neural network over global vector representation.<fixed-case>A</fixed-case>mrita<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Capturing discriminative attributes using convolution neural network over global vector representation.</title>
      <author><first>Vivek</first> <last>Vinayan</last></author>
      <author><first>Anand</first> <last>Kumar M</last></author>
      <author><first>Soman</first> <last>K P</last></author>
      <pages>1003–1007</pages>
      <abstract>The Capturing Discriminative Attributes sharedtask is the tenth <a href="https://en.wikipedia.org/wiki/Task_(computing)">task</a>, conjoint with SemEval2018. The task is to predict if a word can capture distinguishing attributes of one word from another. We use GloVe word embedding, pre-trained on openly sourced corpus for this task. A base <a href="https://en.wikipedia.org/wiki/Representation_(mathematics)">representation</a> is initially established over varied dimensions. These representations are evaluated based on validation scores over two <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>, first on an SVM based classifier and second on a one dimension CNN model. The scores are used to further develop the <a href="https://en.wikipedia.org/wiki/Representation_(mathematics)">representation</a> with vector combinations, by considering various distance measures. These measures correspond to offset vectors which are concatenated as <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>, mainly to improve upon the F1score, with the best <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>. The <a href="https://en.wikipedia.org/wiki/Software_feature">features</a> are then further tuned on the validation scores, to achieve highest F1score. Our evaluation narrowed down to two <a href="https://en.wikipedia.org/wiki/Representation_(mathematics)">representations</a>, classified on CNN models, having a total dimension length of 1204 &amp; 1203 for the final submissions. Of the two, the latter feature representation delivered our best F1score of 0.658024 (as per result).</abstract>
      <url hash="59281a54">S18-1166</url>
      <doi>10.18653/v1/S18-1166</doi>
      <bibkey>vinayan-etal-2018-amritanlp</bibkey>
    </paper>
    <paper id="167">
      <title>Discriminator at SemEval-2018 Task 10 : Minimally Supervised Discrimination<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Minimally Supervised Discrimination</title>
      <author><first>Artur</first> <last>Kulmizev</last></author>
      <author><first>Mostafa</first> <last>Abdou</last></author>
      <author><first>Vinit</first> <last>Ravishankar</last></author>
      <author><first>Malvina</first> <last>Nissim</last></author>
      <pages>1008–1012</pages>
      <abstract>We participated to the SemEval-2018 shared task on capturing discriminative attributes (Task 10) with a simple system that ranked 8th amongst the 26 teams that took part in the evaluation. Our final score was 0.67, which is competitive with the winning score of 0.75, particularly given that our <a href="https://en.wikipedia.org/wiki/System">system</a> is a zero-shot system that requires no training and minimal parameter optimisation. In addition to describing the submitted <a href="https://en.wikipedia.org/wiki/System">system</a>, and discussing the implications of the relative success of such a <a href="https://en.wikipedia.org/wiki/System">system</a> on this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, we also report on other, more complex models we experimented with.</abstract>
      <url hash="fd6187fe">S18-1167</url>
      <doi>10.18653/v1/S18-1167</doi>
      <bibkey>kulmizev-etal-2018-discriminator</bibkey>
    </paper>
    <paper id="170">
      <title>UMD at SemEval-2018 Task 10 : Can Word Embeddings Capture Discriminative Attributes?<fixed-case>UMD</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Can Word Embeddings Capture Discriminative Attributes?</title>
      <author><first>Alexander</first> <last>Zhang</last></author>
      <author><first>Marine</first> <last>Carpuat</last></author>
      <pages>1022–1026</pages>
      <abstract>We describe the University of Maryland’s submission to SemEval-018 Task 10, Capturing Discriminative Attributes : given word triples (w1, w2, d), the goal is to determine whether d is a discriminating attribute belonging to w1 but not w2. Our study aims to determine whether <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> can address this challenging task. Our submission casts this <a href="https://en.wikipedia.org/wiki/Problem_solving">problem</a> as supervised binary classification using only word embedding features. Using a gaussian SVM model trained only on <a href="https://en.wikipedia.org/wiki/Data_validation">validation data</a> results in an <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> of 60 %. We also show that cosine similarity features are more effective, both in <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised systems</a> (F-score of 65 %) and <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised systems</a> (F-score of 67 %).</abstract>
      <url hash="39c3d201">S18-1170</url>
      <doi>10.18653/v1/S18-1170</doi>
      <bibkey>zhang-carpuat-2018-umd</bibkey>
    </paper>
    <paper id="171">
      <title>NTU NLP Lab System at SemEval-2018 Task 10 : Verifying Semantic Differences by Integrating Distributional Information and Expert Knowledge<fixed-case>NTU</fixed-case> <fixed-case>NLP</fixed-case> Lab System at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Verifying Semantic Differences by Integrating Distributional Information and Expert Knowledge</title>
      <author><first>Yow-Ting</first> <last>Shiue</last></author>
      <author><first>Hen-Hsen</first> <last>Huang</last></author>
      <author><first>Hsin-Hsi</first> <last>Chen</last></author>
      <pages>1027–1033</pages>
      <abstract>This paper presents the NTU NLP Lab system for the SemEval-2018 Capturing Discriminative Attributes task. Word embeddings, pointwise mutual information (PMI), ConceptNet edges and shortest path lengths are utilized as input features to build binary classifiers to tell whether an attribute is discriminative for a pair of concepts. Our <a href="https://en.wikipedia.org/wiki/Neural_network">neural network model</a> reaches about 73 % F1 score on the test set and ranks the 3rd in the task. Though the <a href="https://en.wikipedia.org/wiki/Attribute_(computing)">attributes</a> to deal with in this task are all visual, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> are not provided with any <a href="https://en.wikipedia.org/wiki/Image">image data</a>. The results indicate that <a href="https://en.wikipedia.org/wiki/Visual_system">visual information</a> can be derived from <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">textual data</a>.</abstract>
      <url hash="2b673176">S18-1171</url>
      <doi>10.18653/v1/S18-1171</doi>
      <bibkey>shiue-etal-2018-ntu</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imagenet">ImageNet</pwcdataset>
    </paper>
    <paper id="172">
      <title>ELiRF-UPV at SemEval-2018 Task 11 : Machine Comprehension using Commonsense Knowledge<fixed-case>EL</fixed-case>i<fixed-case>RF</fixed-case>-<fixed-case>UPV</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 11: Machine Comprehension using Commonsense Knowledge</title>
      <author><first>José-Ángel</first> <last>González</last></author>
      <author><first>Lluís-F.</first> <last>Hurtado</last></author>
      <author><first>Encarna</first> <last>Segarra</last></author>
      <author><first>Ferran</first> <last>Pla</last></author>
      <pages>1034–1037</pages>
      <abstract>This paper describes the participation of ELiRF-UPV team at task 11, <a href="https://en.wikipedia.org/wiki/Machine_learning">Machine Comprehension</a> using Commonsense Knowledge, of SemEval-2018. Our approach is based on the use of word embeddings, NumberBatch Embeddings, and a Deep Learning architecture to find the best answer for the multiple-choice questions based on the narrative text. The results obtained are in line with those obtained by the other participants and they encourage us to continue working on this problem.</abstract>
      <url hash="3c998991">S18-1172</url>
      <doi>10.18653/v1/S18-1172</doi>
      <bibkey>gonzalez-etal-2018-elirf-upv-semeval</bibkey>
    </paper>
    <paper id="174">
      <title>YNU_Deep at SemEval-2018 Task 11 : An Ensemble of Attention-based BiLSTM Models for Machine Comprehension<fixed-case>YNU</fixed-case>_<fixed-case>D</fixed-case>eep at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 11: An Ensemble of Attention-based <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case> Models for Machine Comprehension</title>
      <author><first>Peng</first> <last>Ding</last></author>
      <author><first>Xiaobing</first> <last>Zhou</last></author>
      <pages>1043–1047</pages>
      <abstract>We firstly use GloVe to learn the distributed representations automatically from the instance, question and answer triples. Then an attentionbased Bidirectional LSTM (BiLSTM) model is used to encode the triples. We also perform a simple <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble method</a> to improve the effectiveness of our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>. The <a href="https://en.wikipedia.org/wiki/System">system</a> we developed obtains an encouraging result on this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. It achieves the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> 0.7472 on the test set. We rank 5th according to the official ranking.</abstract>
      <url hash="b0592a20">S18-1174</url>
      <doi>10.18653/v1/S18-1174</doi>
      <bibkey>ding-zhou-2018-ynu</bibkey>
    </paper>
    <paper id="176">
      <title>CSReader at SemEval-2018 Task 11 : Multiple Choice Question Answering as Textual Entailment<fixed-case>CSR</fixed-case>eader at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 11: Multiple Choice Question Answering as Textual Entailment</title>
      <author><first>Zhengping</first> <last>Jiang</last></author>
      <author><first>Qi</first> <last>Sun</last></author>
      <pages>1053–1057</pages>
      <abstract>In this document we present an end-to-end machine reading comprehension system that solves multiple choice questions with a textual entailment perspective. Since some of the knowledge required is not explicitly mentioned in the text, we try to exploit commonsense knowledge by using pretrained word embeddings during contextual embeddings and by dynamically generating a weighted representation of related script knowledge. In the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> two kinds of prediction structure are ensembled, and the final <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of our <a href="https://en.wikipedia.org/wiki/System">system</a> is 10 percent higher than the naiive baseline.</abstract>
      <url hash="59357af1">S18-1176</url>
      <doi>10.18653/v1/S18-1176</doi>
      <bibkey>jiang-sun-2018-csreader</bibkey>
    </paper>
    <paper id="177">
      <title>YNU-HPCC at Semeval-2018 Task 11 : Using an Attention-based CNN-LSTM for Machine Comprehension using Commonsense Knowledge<fixed-case>YNU</fixed-case>-<fixed-case>HPCC</fixed-case> at <fixed-case>S</fixed-case>emeval-2018 Task 11: Using an Attention-based <fixed-case>CNN</fixed-case>-<fixed-case>LSTM</fixed-case> for Machine Comprehension using Commonsense Knowledge</title>
      <author><first>Hang</first> <last>Yuan</last></author>
      <author><first>Jin</first> <last>Wang</last></author>
      <author><first>Xuejie</first> <last>Zhang</last></author>
      <pages>1058–1062</pages>
      <abstract>This shared task is a typical <a href="https://en.wikipedia.org/wiki/Question_answering">question answering task</a>. Compared with the normal question and answer system, it needs to give the answer to the question based on the text provided. The essence of the problem is actually <a href="https://en.wikipedia.org/wiki/Reading_comprehension">reading comprehension</a>. Typically, there are several questions for each text that correspond to it. And for each question, there are two candidate answers (and only one of them is correct). To solve this problem, the usual approach is to use <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural networks (CNN)</a> and <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network (RNN)</a> or their improved models (such as long short-term memory (LSTM)). In this paper, an attention-based CNN-LSTM model is proposed for this task. By adding an <a href="https://en.wikipedia.org/wiki/Attentional_control">attention mechanism</a> and combining the two <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>, this experimental result has been significantly improved.</abstract>
      <url hash="06f64a25">S18-1177</url>
      <doi>10.18653/v1/S18-1177</doi>
      <bibkey>yuan-etal-2018-ynu</bibkey>
    </paper>
    <paper id="178">
      <title>Jiangnan at SemEval-2018 Task 11 : Deep Neural Network with Attention Method for Machine Comprehension Task<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 11: Deep Neural Network with Attention Method for Machine Comprehension Task</title>
      <author><first>Jiangnan</first> <last>Xia</last></author>
      <pages>1063–1067</pages>
      <abstract>This paper describes our submission for the International Workshop on Semantic Evaluation (SemEval-2018) shared task 11 Machine Comprehension using Commonsense Knowledge (Ostermann et al., 2018b). We use a deep neural network model to choose the correct answer from the candidate answers pair when the document and question are given. The interactions between document, question and answers are modeled by attention mechanism and a variety of manual features are used to improve <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> performance. We also use CoVe (McCann et al., 2017) as an external source of knowledge which is not mentioned in the document. As a result, our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves 80.91 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> on the test data, which is on the third place of the leaderboard.</abstract>
      <url hash="c226ed6c">S18-1178</url>
      <doi>10.18653/v1/S18-1178</doi>
      <bibkey>xia-2018-jiangnan</bibkey>
    </paper>
    <paper id="180">
      <title>Lyb3b at SemEval-2018 Task 11 : Machine Comprehension Task using Deep Learning Models<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 11: Machine Comprehension Task using Deep Learning Models</title>
      <author><first>Yongbin</first> <last>Li</last></author>
      <author><first>Xiaobing</first> <last>Zhou</last></author>
      <pages>1073–1077</pages>
      <abstract>Machine Comprehension of text is a typical Natural Language Processing task which remains an elusive challenge. This paper is to solve the task 11 of SemEval-2018, <a href="https://en.wikipedia.org/wiki/Machine_learning">Machine Comprehension</a> using Commonsense Knowledge task. We use deep learning model to solve the problem. We build distributed word embedding of text, question and answering respectively instead of manually extracting features by linguistic tools. Meanwhile, we use a series of frameworks such as CNN model, LSTM model, LSTM with attention model and biLSTM with attention model for processing word vector. Experiments demonstrate the superior performance of biLSTM with attention framework compared to other <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>. We also delete high frequency words and combine <a href="https://en.wikipedia.org/wiki/Word_vector">word vector and data augmentation methods</a>, achieved a certain effect. The approach we proposed rank 6th in official results, with <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy rate</a> of 0.7437 in test dataset.</abstract>
      <url hash="5488f63e">S18-1180</url>
      <doi>10.18653/v1/S18-1180</doi>
      <bibkey>li-zhou-2018-lyb3b</bibkey>
    </paper>
    <paper id="181">
      <title>MITRE at SemEval-2018 Task 11 : Commonsense Reasoning without Commonsense Knowledge<fixed-case>MITRE</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 11: Commonsense Reasoning without Commonsense Knowledge</title>
      <author><first>Elizabeth</first> <last>Merkhofer</last></author>
      <author><first>John</first> <last>Henderson</last></author>
      <author><first>David</first> <last>Bloom</last></author>
      <author><first>Laura</first> <last>Strickhart</last></author>
      <author><first>Guido</first> <last>Zarrella</last></author>
      <pages>1078–1082</pages>
      <abstract>This paper describes MITRE’s participation in SemEval-2018 Task 11 : Machine Comprehension using Commonsense Knowledge. The techniques explored range from simple bag-of-ngrams classifiers to neural architectures with varied attention and alignment mechanisms. Logistic regression ties the <a href="https://en.wikipedia.org/wiki/System">systems</a> together into an <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble</a> submitted for evaluation. The resulting <a href="https://en.wikipedia.org/wiki/System">system</a> answers <a href="https://en.wikipedia.org/wiki/Reading_comprehension">reading comprehension questions</a> with 82.27 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>.</abstract>
      <url hash="8a899252">S18-1181</url>
      <doi>10.18653/v1/S18-1181</doi>
      <bibkey>merkhofer-etal-2018-mitre</bibkey>
    </paper>
    <paper id="182">
      <title>SNU_IDS at SemEval-2018 Task 12 : Sentence Encoder with Contextualized Vectors for Argument Reasoning Comprehension<fixed-case>SNU</fixed-case>_<fixed-case>IDS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: Sentence Encoder with Contextualized Vectors for Argument Reasoning Comprehension</title>
      <author><first>Taeuk</first> <last>Kim</last></author>
      <author><first>Jihun</first> <last>Choi</last></author>
      <author><first>Sang-goo</first> <last>Lee</last></author>
      <pages>1083–1088</pages>
      <abstract>We present a novel neural architecture for the Argument Reasoning Comprehension task of SemEval 2018. It is a simple <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> consisting of three parts, collectively judging whether the logic built on a set of given sentences (a claim, reason, and warrant) is plausible or not. The model utilizes contextualized word vectors pre-trained on large machine translation (MT) datasets as a form of <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a>, which can help to mitigate the lack of training data. Quantitative analysis shows that simply leveraging LSTMs trained on MT datasets outperforms several baselines and non-transferred models, achieving accuracies of about 70 % on the development set and about 60 % on the test set.</abstract>
      <url hash="158aea38">S18-1182</url>
      <doi>10.18653/v1/S18-1182</doi>
      <bibkey>kim-etal-2018-snu</bibkey>
      <pwccode url="https://github.com/galsang/SemEval2018-task12" additional="false">galsang/SemEval2018-task12</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="183">
      <title>ITNLP-ARC at SemEval-2018 Task 12 : Argument Reasoning Comprehension with Attention<fixed-case>ITNLP</fixed-case>-<fixed-case>ARC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: Argument Reasoning Comprehension with Attention</title>
      <author><first>Wenjie</first> <last>Liu</last></author>
      <author><first>Chengjie</first> <last>Sun</last></author>
      <author><first>Lei</first> <last>Lin</last></author>
      <author><first>Bingquan</first> <last>Liu</last></author>
      <pages>1089–1093</pages>
      <abstract>Reasoning is a very important topic and has many important applications in the field of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. Semantic Evaluation (SemEval) 2018 Task 12 The Argument Reasoning Comprehension committed to research <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language reasoning</a>. In this task, we proposed a novel argument reasoning comprehension system, ITNLP-ARC, which use Neural Networks technology to solve this problem. In our system, the LSTM model is involved to encode both the premise sentences and the warrant sentences. The attention model is used to merge the two premise sentence vectors. Through comparing the similarity between the <a href="https://en.wikipedia.org/wiki/Attention">attention vector</a> and each of the two warrant vectors, we choose the one with higher similarity as our system’s final answer.</abstract>
      <url hash="6b4476fe">S18-1183</url>
      <doi>10.18653/v1/S18-1183</doi>
      <bibkey>liu-etal-2018-itnlp</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="184">
      <title>ECNU at SemEval-2018 Task 12 : An End-to-End Attention-based Neural Network for the Argument Reasoning Comprehension Task<fixed-case>ECNU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: An End-to-End Attention-based Neural Network for the Argument Reasoning Comprehension Task</title>
      <author><first>Junfeng</first> <last>Tian</last></author>
      <author><first>Man</first> <last>Lan</last></author>
      <author><first>Yuanbin</first> <last>Wu</last></author>
      <pages>1094–1098</pages>
      <abstract>This paper presents our submissions to SemEval 2018 Task 12 : the Argument Reasoning Comprehension Task. We investigate an end-to-end attention-based neural network to represent the two lexically close candidate warrants. On the one hand, we extract their different parts as attention vectors to obtain distinguishable representations. On the other hand, we use their surrounds (i.e., claim, reason, debate context) as another <a href="https://en.wikipedia.org/wiki/Attention">attention vectors</a> to get contextual representations, which work as final clues to select the correct warrant. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves 60.4 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and ranks 3rd among 22 participating systems.</abstract>
      <url hash="77ac67cd">S18-1184</url>
      <doi>10.18653/v1/S18-1184</doi>
      <bibkey>tian-etal-2018-ecnu</bibkey>
    </paper>
    <paper id="185">
      <title>NLITrans at SemEval-2018 Task 12 : Transfer of Semantic Knowledge for Argument Comprehension<fixed-case>NLIT</fixed-case>rans at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: Transfer of Semantic Knowledge for Argument Comprehension</title>
      <author><first>Timothy</first> <last>Niven</last></author>
      <author><first>Hung-Yu</first> <last>Kao</last></author>
      <pages>1099–1103</pages>
      <abstract>The Argument Reasoning Comprehension Task is a difficult challenge requiring significant <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">language understanding</a> and complex reasoning over <a href="https://en.wikipedia.org/wiki/Epistemology">world knowledge</a>. We focus on transfer of a sentence encoder to bootstrap more complicated architectures given the small size of the dataset. Our best model uses a pre-trained BiLSTM to encode input sentences, learns task-specific features for the argument and warrants, then performs independent argument-warrant matching. This <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves mean test set accuracy of 61.31 %. Encoder transfer yields a significant gain to our best <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> over random initialization. Sharing parameters for independent warrant evaluation provides regularization and effectively doubles the size of the dataset. We demonstrate that <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">regularization</a> comes from ignoring statistical correlations between warrant positions. We also report an experiment with our best <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> that only matches warrants to reasons, ignoring claims. Performance is still competitive, suggesting that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is not necessarily learning the intended task.</abstract>
      <url hash="4441c9ce">S18-1185</url>
      <doi>10.18653/v1/S18-1185</doi>
      <bibkey>niven-kao-2018-nlitrans</bibkey>
      <pwccode url="https://github.com/IKMLab/arct" additional="false">IKMLab/arct</pwccode>
    </paper>
    <paper id="186">
      <title>BLCU_NLP at SemEval-2018 Task 12 : An Ensemble Model for Argument Reasoning Based on Hierarchical Attention<fixed-case>BLCU</fixed-case>_<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: An Ensemble Model for Argument Reasoning Based on Hierarchical Attention</title>
      <author><first>Meiqian</first> <last>Zhao</last></author>
      <author><first>Chunhua</first> <last>Liu</last></author>
      <author><first>Lu</first> <last>Liu</last></author>
      <author><first>Yan</first> <last>Zhao</last></author>
      <author><first>Dong</first> <last>Yu</last></author>
      <pages>1104–1108</pages>
      <abstract>To comprehend an argument and fill the gap between claims and reasons, it is vital to find the implicit supporting warrants behind. In this paper, we propose a hierarchical attention model to identify the right warrant which explains why the reason stands for the claim. Our model focuses not only on the similar part between warrants and other information but also on the contradictory part between two opposing warrants. In addition, we use the ensemble method for different <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 61 %, ranking second in this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. Experimental results demonstrate that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is effective to make correct choices.</abstract>
      <url hash="c14de464">S18-1186</url>
      <doi>10.18653/v1/S18-1186</doi>
      <bibkey>zhao-etal-2018-blcu</bibkey>
    </paper>
    <paper id="189">
      <title>YNU Deep at SemEval-2018 Task 12 : A BiLSTM Model with Neural Attention for Argument Reasoning Comprehension<fixed-case>YNU</fixed-case> Deep at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: A <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case> Model with Neural Attention for Argument Reasoning Comprehension</title>
      <author><first>Peng</first> <last>Ding</last></author>
      <author><first>Xiaobing</first> <last>Zhou</last></author>
      <pages>1120–1123</pages>
      <abstract>This paper describes the system submitted to SemEval-2018 Task 12 (The Argument Reasoning Comprehension Task). Enabling a computer to understand a text so that it can answer comprehension questions is still a challenging goal of <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP</a>. We propose a Bidirectional LSTM (BiLSTM) model that reads two sentences separated by a delimiter to determine which warrant is correct. We extend this <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> with a neural attention mechanism that encourages the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> to make reasoning over the given claims and reasons. Officially released results show that our <a href="https://en.wikipedia.org/wiki/System">system</a> ranks 6th among 22 submissions to this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>.</abstract>
      <url hash="60c8cf31">S18-1189</url>
      <doi>10.18653/v1/S18-1189</doi>
      <bibkey>ding-zhou-2018-ynu-deep</bibkey>
    </paper>
    <paper id="190">
      <title>UniMelb at SemEval-2018 Task 12 : Generative Implication using LSTMs, Siamese Networks and Semantic Representations with Synonym Fuzzing<fixed-case>U</fixed-case>ni<fixed-case>M</fixed-case>elb at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: Generative Implication using <fixed-case>LSTM</fixed-case>s, <fixed-case>S</fixed-case>iamese Networks and Semantic Representations with Synonym Fuzzing</title>
      <author><first>Anirudh</first> <last>Joshi</last></author>
      <author><first>Tim</first> <last>Baldwin</last></author>
      <author><first>Richard O.</first> <last>Sinnott</last></author>
      <author><first>Cecile</first> <last>Paris</last></author>
      <pages>1124–1128</pages>
      <abstract>This paper describes a warrant classification system for SemEval 2018 Task 12, that attempts to learn semantic representations of reasons, claims and warrants. The system consists of 3 stacked LSTMs : one for the reason, one for the claim, and one shared Siamese Network for the 2 candidate warrants. Our main contribution is to force the embeddings into a shared feature space using vector operations, semantic similarity classification, Siamese networks, and <a href="https://en.wikipedia.org/wiki/Multi-task_learning">multi-task learning</a>. In doing so, we learn a form of generative implication, in encoding implication interrelationships between reasons, claims, and the associated correct and incorrect warrants. We augment the limited data in the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> further by utilizing WordNet synonym fuzzing. When applied to SemEval 2018 Task 12, our <a href="https://en.wikipedia.org/wiki/System">system</a> performs well on the development data, and officially ranked 8th among 21 teams.</abstract>
      <url hash="a382f263">S18-1190</url>
      <doi>10.18653/v1/S18-1190</doi>
      <bibkey>joshi-etal-2018-unimelb</bibkey>
    </paper>
    <paper id="191">
      <title>Joker at SemEval-2018 Task 12 : The Argument Reasoning Comprehension with Neural Attention<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: The Argument Reasoning Comprehension with Neural Attention</title>
      <author><last>Sui</last> <first>Guobin</first></author>
      <author><last>Chao</last> <first>Wenhan</first></author>
      <author><last>Luo</last> <first>Zhunchen</first></author>
      <pages>1129–1132</pages>
      <abstract>This paper describes a classification system that participated in the SemEval-2018 Task 12 : The Argument Reasoning Comprehension Task. Briefly the task can be described as that a natural language argument is what we have, with reason, claim, and correct and incorrect warrants, and we need to choose the correct warrant. In order to make fully understand of the <a href="https://en.wikipedia.org/wiki/Semantics">semantic information</a> of the sentences, we proposed a neural network architecture with <a href="https://en.wikipedia.org/wiki/Attentional_control">attention mechanism</a> to achieve this goal. Besides we try to introduce <a href="https://en.wikipedia.org/wiki/Index_term">keywords</a> into the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> to improve <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>. Finally the proposed <a href="https://en.wikipedia.org/wiki/System">system</a> achieved 5th place among 22 participating systems</abstract>
      <url hash="2464d0ae">S18-1191</url>
      <doi>10.18653/v1/S18-1191</doi>
      <bibkey>sui-etal-2018-joker</bibkey>
    </paper>
    <paper id="194">
      <title>TRANSRW at SemEval-2018 Task 12 : Transforming Semantic Representations for Argument Reasoning Comprehension<fixed-case>TRANSRW</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: Transforming Semantic Representations for Argument Reasoning Comprehension</title>
      <author><first>Zhimin</first> <last>Chen</last></author>
      <author><first>Wei</first> <last>Song</last></author>
      <author><first>Lizhen</first> <last>Liu</last></author>
      <pages>1142–1145</pages>
      <abstract>This paper describes our <a href="https://en.wikipedia.org/wiki/System">system</a> in SemEval-2018 task 12 : Argument Reasoning Comprehension. The task is to select the correct warrant that explains reasoning of a particular argument consisting of a claim and a reason. The main idea of our methods is based on the assumption that the semantic composition of the reason and the warrant should be close to the semantic representation of the corresponding claim. We propose two neural network models. The first <a href="https://en.wikipedia.org/wiki/Monotonic_function">one</a> considers two warrant candidates simultaneously, while the second <a href="https://en.wikipedia.org/wiki/Monotonic_function">one</a> processes each candidate separately and then chooses the best one. We also incorporate sentiment polarity by assuming that there are kinds of sentiment associations between the reason, the warrant and the claim. The experiments show that the first <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> is more effective and sentiment polarity is useful.</abstract>
      <url hash="b28328b3">S18-1194</url>
      <doi>10.18653/v1/S18-1194</doi>
      <bibkey>chen-etal-2018-transrw</bibkey>
    </paper>
  </volume>
  <volume id="2">
    <meta>
      <booktitle>Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics</booktitle>
      <url hash="78ba5d5e">S18-2</url>
      <editor><first>Malvina</first> <last>Nissim</last></editor>
      <editor><first>Jonathan</first> <last>Berant</last></editor>
      <editor><first>Alessandro</first> <last>Lenci</last></editor>
      <doi>10.18653/v1/S18-2</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>New Orleans, Louisiana</address>
      <month>June</month>
      <year>2018</year>
    </meta>
    <frontmatter>
      <url hash="25e979dc">S18-2000</url>
      <bibkey>semeval-2018-joint</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Resolving Event Coreference with <a href="https://en.wikipedia.org/wiki/Supervised_learning">Supervised Representation Learning</a> and Clustering-Oriented Regularization</title>
      <author><first>Kian</first> <last>Kenyon-Dean</last></author>
      <author><first>Jackie Chi Kit</first> <last>Cheung</last></author>
      <author><first>Doina</first> <last>Precup</last></author>
      <pages>1–10</pages>
      <abstract>We present an approach to event coreference resolution by developing a general <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> for <a href="https://en.wikipedia.org/wiki/Cluster_analysis">clustering</a> that uses <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised representation learning</a>. We propose a neural network architecture with novel Clustering-Oriented Regularization (CORE) terms in the <a href="https://en.wikipedia.org/wiki/Loss_function">objective function</a>. These terms encourage the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> to create embeddings of event mentions that are amenable to <a href="https://en.wikipedia.org/wiki/Cluster_analysis">clustering</a>. We then use <a href="https://en.wikipedia.org/wiki/Agglomerative_clustering">agglomerative clustering</a> on these <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> to build event coreference chains. For both within- and cross-document coreference on the ECB+ corpus, our model obtains better results than models that require significantly more pre-annotated information. This work provides insight and motivating results for a new general approach to solving coreference and clustering problems with <a href="https://en.wikipedia.org/wiki/Representation_learning">representation learning</a>.</abstract>
      <url hash="9eacb95e">S18-2001</url>
      <doi>10.18653/v1/S18-2001</doi>
      <bibkey>kenyon-dean-etal-2018-resolving</bibkey>
      <pwccode url="https://github.com/kiankd/events" additional="false">kiankd/events</pwccode>
    </paper>
    <paper id="2">
      <title>Learning distributed event representations with a multi-task approach</title>
      <author><first>Xudong</first> <last>Hong</last></author>
      <author><first>Asad</first> <last>Sayeed</last></author>
      <author><first>Vera</first> <last>Demberg</last></author>
      <pages>11–21</pages>
      <abstract>Human world knowledge contains information about prototypical events and their participants and locations. In this paper, we train the first models using <a href="https://en.wikipedia.org/wiki/Multi-task_learning">multi-task learning</a> that can both predict missing event participants and also perform semantic role classification based on semantic plausibility. Our best-performing <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is an improvement over the previous <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a> on thematic fit modelling tasks. The event embeddings learned by the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> can additionally be used effectively in an event similarity task, also outperforming the <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a>.</abstract>
      <url hash="f61e3151">S18-2002</url>
      <doi>10.18653/v1/S18-2002</doi>
      <bibkey>hong-etal-2018-learning</bibkey>
    </paper>
    <paper id="3">
      <title>Assessing Meaning Components in German Complex Verbs : A Collection of Source-Target Domains and Directionality<fixed-case>G</fixed-case>erman Complex Verbs: A Collection of Source-Target Domains and Directionality</title>
      <author><first>Sabine</first> <last>Schulte im Walde</last></author>
      <author><first>Maximilian</first> <last>Köper</last></author>
      <author><first>Sylvia</first> <last>Springorum</last></author>
      <pages>22–32</pages>
      <abstract>This paper presents a collection to assess <a href="https://en.wikipedia.org/wiki/Meaning_(linguistics)">meaning components</a> in German complex verbs, which frequently undergo <a href="https://en.wikipedia.org/wiki/Semantic_change">meaning shifts</a>. We use a novel strategy to obtain source and target domain characterisations via sentence generation rather than sentence annotation. A selection of <a href="https://en.wikipedia.org/wiki/Arrow_(symbol)">arrows</a> adds spatial directional information to the generated contexts. We provide a broad qualitative description of the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>, and a series of standard <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> experiments verifies the quantitative reliability of the presented resource. The setup for collecting the meaning components is applicable also to other languages, regarding complex verbs as well as other language-specific targets that involve meaning shifts.</abstract>
      <url hash="7b804ed2">S18-2003</url>
      <doi>10.18653/v1/S18-2003</doi>
      <bibkey>schulte-im-walde-etal-2018-assessing</bibkey>
    </paper>
    <paper id="7">
      <title>Mixing Context Granularities for Improved Entity Linking on Question Answering Data across Entity Categories</title>
      <author><first>Daniil</first> <last>Sorokin</last></author>
      <author><first>Iryna</first> <last>Gurevych</last></author>
      <pages>65–75</pages>
      <abstract>The first stage of every knowledge base question answering approach is to link entities in the input question. We investigate <a href="https://en.wikipedia.org/wiki/Entity_linking">entity linking</a> in the context of <a href="https://en.wikipedia.org/wiki/Question_answering">question answering task</a> and present a jointly optimized neural architecture for entity mention detection and entity disambiguation that models the surrounding context on different levels of granularity. We use the Wikidata knowledge base and available question answering datasets to create benchmarks for <a href="https://en.wikipedia.org/wiki/Entity_linking">entity linking</a> on question answering data. Our approach outperforms the previous state-of-the-art <a href="https://en.wikipedia.org/wiki/System">system</a> on this <a href="https://en.wikipedia.org/wiki/Data">data</a>, resulting in an average 8 % improvement of the final score. We further demonstrate that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> delivers a strong performance across different entity categories.</abstract>
      <url hash="4864b567">S18-2007</url>
      <doi>10.18653/v1/S18-2007</doi>
      <bibkey>sorokin-gurevych-2018-mixing</bibkey>
      <pwccode url="https://github.com/UKPLab/starsem2018-entity-linking" additional="false">UKPLab/starsem2018-entity-linking</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/webquestions">WebQuestions</pwcdataset>
    </paper>
    <paper id="8">
      <title>Quantitative Semantic Variation in the Contexts of Concrete and Abstract Words</title>
      <author><first>Daniela</first> <last>Naumann</last></author>
      <author><first>Diego</first> <last>Frassinelli</last></author>
      <author><first>Sabine</first> <last>Schulte im Walde</last></author>
      <pages>76–85</pages>
      <abstract>Across disciplines, researchers are eager to gain insight into empirical features of <a href="https://en.wikipedia.org/wiki/Abstract_and_concrete">abstract vs. concrete concepts</a>. In this work, we provide a detailed characterisation of the distributional nature of <a href="https://en.wikipedia.org/wiki/Abstract_and_concrete">abstract and concrete words</a> across 16,620 <a href="https://en.wikipedia.org/wiki/English_nouns">English nouns</a>, verbs and adjectives. Specifically, we investigate the following questions : (1) What is the distribution of concreteness in the contexts of concrete and abstract target words? (2) What are the differences between concrete and abstract words in terms of contextual semantic diversity? (3) How does the <a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)">entropy</a> of concrete and abstract word contexts differ? Overall, our studies show consistent differences in the distributional representation of concrete and abstract words, thus challenging existing theories of cognition and providing a more fine-grained description of their nature.</abstract>
      <url hash="907c91aa">S18-2008</url>
      <doi>10.18653/v1/S18-2008</doi>
      <bibkey>naumann-etal-2018-quantitative</bibkey>
    </paper>
    <paper id="10">
      <title>The Limitations of Cross-language Word Embeddings Evaluation</title>
      <author><first>Amir</first> <last>Bakarov</last></author>
      <author><first>Roman</first> <last>Suvorov</last></author>
      <author><first>Ilya</first> <last>Sochenkov</last></author>
      <pages>94–100</pages>
      <abstract>The aim of this work is to explore the possible limitations of existing <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> of cross-language word embeddings evaluation, addressing the lack of correlation between intrinsic and extrinsic cross-language evaluation methods. To prove this hypothesis, we construct English-Russian datasets for extrinsic and intrinsic evaluation tasks and compare performances of 5 different cross-language models on them. The results say that the scores even on different <a href="https://en.wikipedia.org/wiki/Benchmark_(computing)">intrinsic benchmarks</a> do not correlate to each other. We can conclude that the use of human references as ground truth for cross-language word embeddings is not proper unless one does not understand how do <a href="https://en.wikipedia.org/wiki/First_language">native speakers</a> process <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> in their cognition.</abstract>
      <url hash="b5b95a20">S18-2010</url>
      <doi>10.18653/v1/S18-2010</doi>
      <bibkey>bakarov-etal-2018-limitations</bibkey>
      <pwccode url="https://github.com/bakarov/cross-lang-embeddings" additional="false">bakarov/cross-lang-embeddings</pwccode>
    </paper>
    <paper id="11">
      <title>How Gender and Skin Tone Modifiers Affect Emoji Semantics in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a><fixed-case>T</fixed-case>witter</title>
      <author><first>Francesco</first> <last>Barbieri</last></author>
      <author><first>Jose</first> <last>Camacho-Collados</last></author>
      <pages>101–106</pages>
      <abstract>In this paper we analyze the use of <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a> in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> with respect to <a href="https://en.wikipedia.org/wiki/Gender">gender</a> and <a href="https://en.wikipedia.org/wiki/Human_skin_color">skin tone</a>. By gathering a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> of over twenty two million tweets from United States some findings are clearly highlighted after performing a simple frequency-based analysis. Moreover, we carry out a <a href="https://en.wikipedia.org/wiki/Semantic_analysis_(linguistics)">semantic analysis</a> on the usage of <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a> and their modifiers (e.g. gender and skin tone) by embedding all <a href="https://en.wikipedia.org/wiki/Word">words</a>, <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a> and modifiers into the same <a href="https://en.wikipedia.org/wiki/Vector_space">vector space</a>. Our analyses reveal that some <a href="https://en.wikipedia.org/wiki/Stereotype">stereotypes</a> related to the <a href="https://en.wikipedia.org/wiki/Human_skin_color">skin color</a> and gender seem to be reflected on the use of these modifiers. For example, <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a> representing <a href="https://en.wikipedia.org/wiki/List_of_gestures">hand gestures</a> are more widely utilized with lighter skin tones, and the usage across <a href="https://en.wikipedia.org/wiki/Human_skin_color">skin tones</a> differs significantly. At the same time, the vector corresponding to the male modifier tends to be semantically close to <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a> related to business or technology, whereas their female counterparts appear closer to <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a> about love or makeup.</abstract>
      <url hash="327e0759">S18-2011</url>
      <doi>10.18653/v1/S18-2011</doi>
      <bibkey>barbieri-camacho-collados-2018-gender</bibkey>
      <pwccode url="https://github.com/fvancesco/emoji_modifiers" additional="false">fvancesco/emoji_modifiers</pwccode>
    </paper>
    <paper id="14">
      <title>Learning Patient Representations from Text</title>
      <author><first>Dmitriy</first> <last>Dligach</last></author>
      <author><first>Timothy</first> <last>Miller</last></author>
      <pages>119–123</pages>
      <abstract>Mining <a href="https://en.wikipedia.org/wiki/Electronic_health_record">electronic health records</a> for patients who satisfy a set of predefined criteria is known in <a href="https://en.wikipedia.org/wiki/Health_informatics">medical informatics</a> as <a href="https://en.wikipedia.org/wiki/Phenotype">phenotyping</a>. Phenotyping has numerous applications such as <a href="https://en.wikipedia.org/wiki/Prediction">outcome prediction</a>, clinical trial recruitment, and <a href="https://en.wikipedia.org/wiki/Retrospective">retrospective studies</a>. Supervised machine learning for <a href="https://en.wikipedia.org/wiki/Phenotype">phenotyping</a> typically relies on sparse patient representations such as <a href="https://en.wikipedia.org/wiki/Bag-of-words">bag-of-words</a>. We consider an alternative that involves learning patient representations. We develop a <a href="https://en.wikipedia.org/wiki/Neural_network">neural network model</a> for learning patient representations and show that the learned <a href="https://en.wikipedia.org/wiki/Mental_representation">representations</a> are general enough to obtain state-of-the-art performance on a standard comorbidity detection task.</abstract>
      <url hash="2d079f55">S18-2014</url>
      <doi>10.18653/v1/S18-2014</doi>
      <bibkey>dligach-miller-2018-learning</bibkey>
      <pwccode url="https://github.com/dmitriydligach/starsem2018-patient-representations" additional="false">dmitriydligach/starsem2018-patient-representations</pwccode>
    </paper>
    <paper id="15">
      <title>Polarity Computations in Flexible Categorial Grammar</title>
      <author><first>Hai</first> <last>Hu</last></author>
      <author><first>Larry</first> <last>Moss</last></author>
      <pages>124–129</pages>
      <abstract>This paper shows how to take parse trees in CCG and algorithmically find the polarities of all the constituents. Our work uses the well-known polarization principle corresponding to <a href="https://en.wikipedia.org/wiki/Function_application">function application</a>, and we have extended this with principles for type raising and composition. We provide an <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a>, extending the polarity marking algorithm of van Benthem. We discuss how our <a href="https://en.wikipedia.org/wiki/System">system</a> works in practice, taking input from the <a href="https://en.wikipedia.org/wiki/Compiler-compiler">C&amp;C parser</a>.</abstract>
      <url hash="8c345d0c">S18-2015</url>
      <doi>10.18653/v1/S18-2015</doi>
      <bibkey>hu-moss-2018-polarity</bibkey>
      <pwccode url="https://github.com/huhailinguist/ccg2mono" additional="false">huhailinguist/ccg2mono</pwccode>
    </paper>
    <paper id="17">
      <title>Halo : Learning Semantics-Aware Representations for Cross-Lingual Information Extraction<fixed-case>H</fixed-case>alo: Learning Semantics-Aware Representations for Cross-Lingual Information Extraction</title>
      <author><first>Hongyuan</first> <last>Mei</last></author>
      <author><first>Sheng</first> <last>Zhang</last></author>
      <author><first>Kevin</first> <last>Duh</last></author>
      <author><first>Benjamin</first> <last>Van Durme</last></author>
      <pages>142–147</pages>
      <abstract>Cross-lingual information extraction (CLIE) is an important and challenging <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, especially in low resource scenarios. To tackle this challenge, we propose a training method, called Halo, which enforces the local region of each hidden state of a neural model to only generate target tokens with the same semantic structure tag. This simple but powerful technique enables a neural model to learn semantics-aware representations that are robust to <a href="https://en.wikipedia.org/wiki/Noise_(signal_processing)">noise</a>, without introducing any extra parameter, thus yielding better <a href="https://en.wikipedia.org/wiki/Generalization">generalization</a> in both high and low resource settings.<i>Halo</i>, which enforces the local region of each hidden state of a neural model
      to only generate target tokens with the same semantic structure tag. This
      simple but powerful technique enables a neural model to learn
      semantics-aware representations that are robust to noise, without
      introducing any extra parameter, thus yielding better generalization in
      both high and low resource settings.
    </abstract>
      <url hash="11aa2329">S18-2017</url>
      <doi>10.18653/v1/S18-2017</doi>
      <bibkey>mei-etal-2018-halo</bibkey>
    </paper>
    <paper id="19">
      <title>Predicting Word Embeddings Variability</title>
      <author><first>Bénédicte</first> <last>Pierrejean</last></author>
      <author><first>Ludovic</first> <last>Tanguy</last></author>
      <pages>154–159</pages>
      <abstract>Neural word embeddings models (such as those built with word2vec) are known to have stability problems : when retraining a model with the exact same hyperparameters, words neighborhoods may change. We propose a method to estimate such variation, based on the overlap of neighbors of a given word in two <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> trained with identical <a href="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)">hyperparameters</a>. We show that this inherent variation is not negligible, and that it does not affect every word in the same way. We examine the influence of several features that are intrinsic to a word, corpus or embedding model and provide a methodology that can predict the variability (and as such, reliability) of a word representation in a semantic vector space.</abstract>
      <url hash="366bbcdd">S18-2019</url>
      <doi>10.18653/v1/S18-2019</doi>
      <bibkey>pierrejean-tanguy-2018-predicting</bibkey>
    </paper>
    <paper id="20">
      <title>Integrating Multiplicative Features into Supervised Distributional Methods for <a href="https://en.wikipedia.org/wiki/Lexical_analysis">Lexical Entailment</a></title>
      <author><first>Tu</first> <last>Vu</last></author>
      <author><first>Vered</first> <last>Shwartz</last></author>
      <pages>160–166</pages>
      <abstract>Supervised distributional methods are applied successfully in lexical entailment, but recent work questioned whether these methods actually learn a relation between two words. Specifically, Levy et al. (2015) claimed that <a href="https://en.wikipedia.org/wiki/Linear_classifier">linear classifiers</a> learn only separate properties of each word. We suggest a cheap and easy way to boost the performance of these <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">methods</a> by integrating multiplicative features into commonly used <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">representations</a>. We provide an extensive evaluation with different <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> and evaluation setups, and suggest a suitable evaluation setup for the task, eliminating biases existing in previous ones.</abstract>
      <url hash="c68397a4">S18-2020</url>
      <doi>10.18653/v1/S18-2020</doi>
      <bibkey>vu-shwartz-2018-integrating</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/evalution">EVALution</pwcdataset>
    </paper>
    <paper id="21">
      <title>Deep Affix Features Improve Neural Named Entity Recognizers</title>
      <author><first>Vikas</first> <last>Yadav</last></author>
      <author><first>Rebecca</first> <last>Sharp</last></author>
      <author><first>Steven</first> <last>Bethard</last></author>
      <pages>167–172</pages>
      <abstract>We propose a practical model for named entity recognition (NER) that combines word and character-level information with a specific learned representation of the prefixes and suffixes of the word. We apply this approach to multilingual and multi-domain NER and show that it achieves state of the art results on the CoNLL 2002 Spanish and Dutch and CoNLL 2003 German NER datasets, consistently achieving 1.5-2.3 percent over the state of the art without relying on any dictionary features. Additionally, we show improvement on SemEval 2013 task 9.1 DrugNER, achieving state of the art results on the MedLine dataset and the second best results overall (-1.3 % from state of the art). We also establish a new benchmark on the I2B2 2010 Clinical NER dataset with 84.70 <a href="https://en.wikipedia.org/wiki/F-score">F-score</a>.</abstract>
      <url hash="c0fc9cd8">S18-2021</url>
      <doi>10.18653/v1/S18-2021</doi>
      <bibkey>yadav-etal-2018-deep</bibkey>
      <pwccode url="https://github.com/vikas95/Pref_Suff_Span_NN" additional="false">vikas95/Pref_Suff_Span_NN</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2002">CoNLL 2002</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
    </paper>
    <paper id="23">
      <title>Hypothesis Only Baselines in Natural Language Inference</title>
      <author><first>Adam</first> <last>Poliak</last></author>
      <author><first>Jason</first> <last>Naradowsky</last></author>
      <author><first>Aparajita</first> <last>Haldar</last></author>
      <author><first>Rachel</first> <last>Rudinger</last></author>
      <author><first>Benjamin</first> <last>Van Durme</last></author>
      <pages>180–191</pages>
      <abstract>We propose a hypothesis only baseline for diagnosing Natural Language Inference (NLI). Especially when an NLI dataset assumes inference is occurring based purely on the relationship between a context and a hypothesis, it follows that assessing entailment relations while ignoring the provided context is a degenerate solution. Yet, through experiments on 10 distinct NLI datasets, we find that this approach, which we refer to as a hypothesis-only model, is able to significantly outperform a majority-class baseline across a number of NLI datasets. Our analysis suggests that statistical irregularities may allow a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> to perform NLI in some datasets beyond what should be achievable without access to the context.</abstract>
      <url hash="d2c72451">S18-2023</url>
      <doi>10.18653/v1/S18-2023</doi>
      <bibkey>poliak-etal-2018-hypothesis</bibkey>
      <pwccode url="https://github.com/azpoliak/hypothesis-only-NLI" additional="false">azpoliak/hypothesis-only-NLI</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/flickr30k">Flickr30k</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sick">SICK</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="25">
      <title>Term Definitions Help Hypernymy Detection</title>
      <author><first>Wenpeng</first> <last>Yin</last></author>
      <author><first>Dan</first> <last>Roth</last></author>
      <pages>203–213</pages>
      <abstract>Existing methods of hypernymy detection mainly rely on statistics over a big corpus, either mining some co-occurring patterns like animals such as cats or embedding words of interest into context-aware vectors. These approaches are therefore limited by the availability of a large enough corpus that can cover all terms of interest and provide sufficient contextual information to represent their meaning. In this work, we propose a new paradigm, HyperDef, for hypernymy detection   expressing word meaning by encoding word definitions, along with context driven representation. This has two main benefits : (i) Definitional sentences express (sense-specific) corpus-independent meanings of words, hence definition-driven approaches enable strong generalization   once trained, the model is expected to work well in open-domain testbeds ; (ii) Global context from a large corpus and definitions provide complementary information for words. Consequently, our model, HyperDef, once trained on task-agnostic data, gets state-of-the-art results in multiple benchmarks</abstract>
      <url hash="8d7e76f0">S18-2025</url>
      <doi>10.18653/v1/S18-2025</doi>
      <bibkey>yin-roth-2018-term</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/dbpedia">DBpedia</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/evalution">EVALution</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/yago">YAGO</pwcdataset>
    </paper>
    <paper id="26">
      <title>Agree or Disagree : Predicting Judgments on Nuanced Assertions</title>
      <author><first>Michael</first> <last>Wojatzki</last></author>
      <author><first>Torsten</first> <last>Zesch</last></author>
      <author><first>Saif</first> <last>Mohammad</last></author>
      <author><first>Svetlana</first> <last>Kiritchenko</last></author>
      <pages>214–224</pages>
      <abstract>Being able to predict whether people agree or disagree with an assertion (i.e. an explicit, self-contained statement) has several applications ranging from predicting how many people will like or dislike a social media post to classifying posts based on whether they are in accordance with a particular point of view. We formalize this as two NLP tasks : predicting judgments of (i) individuals and (ii) groups based on the text of the assertion and previous judgments. We evaluate a wide range of approaches on a crowdsourced data set containing over 100,000 judgments on over 2,000 assertions. We find that predicting individual judgments is a hard task with our best results only slightly exceeding a majority baseline, but that judgments of groups can be more reliably predicted using a Siamese neural network, which outperforms all other approaches by a wide margin.</abstract>
      <url hash="b2e59d87">S18-2026</url>
      <doi>10.18653/v1/S18-2026</doi>
      <bibkey>wojatzki-etal-2018-agree</bibkey>
      <pwccode url="https://github.com/muchafel/judgmentPrediction" additional="false">muchafel/judgmentPrediction</pwccode>
    </paper>
    <paper id="29">
      <title>Measuring Frame Instance Relatedness</title>
      <author><first>Valerio</first> <last>Basile</last></author>
      <author><first>Roque</first> <last>Lopez Condori</last></author>
      <author><first>Elena</first> <last>Cabrio</last></author>
      <pages>245–254</pages>
      <abstract>Frame semantics is a well-established <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> to represent the <a href="https://en.wikipedia.org/wiki/Semantics">meaning of natural language</a> in <a href="https://en.wikipedia.org/wiki/Computational_semantics">computational terms</a>. In this work, we aim to propose a quantitative measure of relatedness between pairs of frame instances. We test our method on a dataset of sentence pairs, highlighting the correlation between our <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metric</a> and human judgments of semantic similarity. Furthermore, we propose an application of our <a href="https://en.wikipedia.org/wiki/Measure_(mathematics)">measure</a> for clustering frame instances to extract prototypical knowledge from <a href="https://en.wikipedia.org/wiki/Natural_language">natural language</a>.</abstract>
      <url hash="11f1e222">S18-2029</url>
      <doi>10.18653/v1/S18-2029</doi>
      <bibkey>basile-etal-2018-measuring</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
    </paper>
    <paper id="30">
      <title>Solving Feature Sparseness in Text Classification using Core-Periphery Decomposition</title>
      <author><first>Xia</first> <last>Cui</last></author>
      <author><first>Sadamori</first> <last>Kojaku</last></author>
      <author><first>Naoki</first> <last>Masuda</last></author>
      <author><first>Danushka</first> <last>Bollegala</last></author>
      <pages>255–264</pages>
      <abstract>Feature sparseness is a problem common to cross-domain and short-text classification tasks. To overcome this feature sparseness problem, we propose a novel method based on graph decomposition to find candidate <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> for expanding feature vectors. Specifically, we first create a feature-relatedness graph, which is subsequently decomposed into core-periphery (CP) pairs and use the peripheries as the expansion candidates of the cores. We expand both training and test instances using the computed related features and use them to train a <a href="https://en.wikipedia.org/wiki/Text_classification">text classifier</a>. We observe that prioritising <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> that are common to both training and test instances as cores during the <a href="https://en.wikipedia.org/wiki/CP_decomposition">CP decomposition</a> to further improve the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of text classification. We evaluate the proposed CP-decomposition-based feature expansion method on benchmark datasets for cross-domain sentiment classification and short-text classification. Our experimental results show that the proposed method consistently outperforms all baselines on short-text classification tasks, and perform competitively with pivot-based cross-domain sentiment classification methods.</abstract>
      <url hash="e55eee70">S18-2030</url>
      <doi>10.18653/v1/S18-2030</doi>
      <bibkey>cui-etal-2018-solving</bibkey>
    </paper>
    </volume>
</collection>