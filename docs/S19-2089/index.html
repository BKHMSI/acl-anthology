<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>TuEval at SemEval-2019 Task 5 : LSTM Approach to Hate Speech Detection in English and SpanishTuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="TuEval at SemEval-2019 Task 5 : LSTM Approach to Hate Speech Detection in English and SpanishTuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish" name=citation_title><meta content="Mihai Manolescu" name=citation_author><meta content="Denise Löfflad" name=citation_author><meta content="Adham Nasser Mohamed Saber" name=citation_author><meta content="Masoumeh Moradipour Tari" name=citation_author><meta content="Proceedings of the 13th International Workshop on Semantic Evaluation" name=citation_conference_title><meta content="2019/6" name=citation_publication_date><meta content="https://aclanthology.org/S19-2089.pdf" name=citation_pdf_url><meta content="498" name=citation_firstpage><meta content="502" name=citation_lastpage><meta content="10.18653/v1/S19-2089" name=citation_doi><meta property="og:title" content="TuEval at SemEval-2019 Task 5 : LSTM Approach to Hate Speech Detection in English and SpanishTuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish"><meta property="og:image" content="https://aclanthology.org/thumb/S19-2089.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/S19-2089"><meta property="og:description" content="Mihai Manolescu, Denise Löfflad, Adham Nasser Mohamed Saber, Masoumeh Moradipour Tari. Proceedings of the 13th International Workshop on Semantic Evaluation. 2019."><link rel=canonical href=https://aclanthology.org/S19-2089></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/S19-2089.pdf>TuEval at SemEval-2019 Task 5 : LSTM Approach to Hate Speech Detection in English and Spanish<span class=acl-fixed-case>T</span>u<span class=acl-fixed-case>E</span>val at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2019 Task 5: <span class=acl-fixed-case>LSTM</span> Approach to Hate Speech Detection in <span class=acl-fixed-case>E</span>nglish and <span class=acl-fixed-case>S</span>panish</a>
<a id=af_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval by SemEval-2019 Opdrag 5: LSTM toegang na Hate Speech Deteksie in Engels en Spaanse</a>
<a id=am_title style=display:none href=https://aclanthology.org/S19-2089.pdf>አድራሻ</a>
<a id=ar_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval في SemEval-2019 المهمة 5: نهج LSTM للكشف عن الكلام الذي يحض على الكراهية باللغتين الإنجليزية والإسبانية</a>
<a id=az_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</a>
<a id=bg_title style=display:none href=https://aclanthology.org/S19-2089.pdf>Задача 5: Подход към откриването на речта на омразата на английски и испански език</a>
<a id=bn_title style=display:none href=https://aclanthology.org/S19-2089.pdf>সেমইভাল-২০১৯ কাজের টুইভাল: এলএসএম ইংরেজি ও স্প্যানিশ ভাষায় ঘৃণা প্রকাশের জন্য যাওয়ার পথ</a>
<a id=bo_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</a>
<a id=bs_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval na semiEval-2019 Task 5: LSTM pristup otkrivanju govora mržnje na engleskom i španjolskom</a>
<a id=ca_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval a SemEval-2019 tasca 5: LSTM Approach to Hate Speech Detection en anglès i espanyol</a>
<a id=cs_title style=display:none href=https://aclanthology.org/S19-2089.pdf>Úkol 5: LSTM přístup k detekci nenávisti řeči v angličtině a španělštině</a>
<a id=da_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval på SemEval-2019 Opgave 5: LSTM tilgang til hade tale detektering på engelsk og spansk</a>
<a id=de_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval bei SemEval-2019 Aufgabe 5: LSTM Ansatz zur Hassspracherkennung in Englisch und Spanisch</a>
<a id=el_title style=display:none href=https://aclanthology.org/S19-2089.pdf>Εργασία 5: Προσέγγιση για την ανίχνευση ομιλίας μίσους στα Αγγλικά και Ισπανικά</a>
<a id=es_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval en SemEval-2019 Tarea 5: Enfoque de LSTM para la detección del discurso de odio en inglés y español</a>
<a id=et_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval SemEval-2019 Ülesanne 5: LSTM lähenemine vihkamise kõne tuvastamisele inglise ja hispaania keeles</a>
<a id=fa_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval at SemEval-2019 Task 5: LSTM Approach to hate speech detection in English and Spanish</a>
<a id=fi_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval SemEval-2019 Tehtävä 5: LSTM-lähestymistapa vihapuheen havaitsemiseen englanniksi ja espanjaksi</a>
<a id=fl_title style=display:none href=https://aclanthology.org/S19-2089.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval au SEMEVAL-2019 Tâche 5 : Approche LSTM de la détection des discours haineux en anglais et en espagnol</a>
<a id=ga_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval ag SemEval-2019 Tasc 5: Cur Chuige LSTM i leith Brath Cainte i mBéarla agus i Spáinnis</a>
<a id=ha_title style=display:none href=https://aclanthology.org/S19-2089.pdf>QScriptBreakpointsModel</a>
<a id=he_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval ב SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</a>
<a id=hi_title style=display:none href=https://aclanthology.org/S19-2089.pdf>SemEval-2019 कार्य 5 में TuEval: अंग्रेजी और स्पेनिश में हेट स्पीच डिटेक्शन के लिए LSTM दृष्टिकोण</a>
<a id=hr_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval na semiEval-2019 zadatak 5: LSTM pristup otkrivanju govora mržnje na engleskom i španjolskom</a>
<a id=hu_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval a SemEval-2019 5. feladat: LSTM megközelítés a gyűlölet beszédfelismerésére angol és spanyol nyelven</a>
<a id=hy_title style=display:none href=https://aclanthology.org/S19-2089.pdf>Tuewal-ը սեմյալ 2019-ի 5. հանձնարարությունում. LSMT մոտեցումը ատելության խոսքի հայտնաբերելուն անգլերենով և իսպաներենով</a>
<a id=id_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</a>
<a id=is_title style=display:none href=https://aclanthology.org/S19-2089.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval al SemEval-2019 Task 5: L'approccio LSTM al rilevamento del parlato in inglese e spagnolo</a>
<a id=ja_title style=display:none href=https://aclanthology.org/S19-2089.pdf>SemEval -2019のTuEvalタスク5 ：英語とスペイン語でのヘイトスピーチ検出へのLSTMアプローチ</a>
<a id=jv_title style=display:none href=https://aclanthology.org/S19-2089.pdf>Tuinval nang seminval-2011 task 5: LTT M Method to Dese Speakch detection in French and Spanish</a>
<a id=ka_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval semiEval-2019 პარამეტრი 5: LSTM დახმარება წარმოდგენისთვის სიტყვების განახსნა ინგლისური და სპანელი</a>
<a id=kk_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval at semiEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</a>
<a id=ko_title style=display:none href=https://aclanthology.org/S19-2089.pdf>SemEval-2019의 TuEval 퀘스트 5: LSTM 방법으로 영어와 스페인어에서 증오의 음성을 검출</a>
<a id=lt_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</a>
<a id=mk_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval на SemEval-2019 задача 5: LSTM Approach to Hate Speech Detection на англиски и шпански</a>
<a id=ml_title style=display:none href=https://aclanthology.org/S19-2089.pdf>സെമ്എവാല്‍- 2019 ടാസ്ക് 5: എംഎസ്റ്റിം ഇംഗ്ലീഷും സ്പാനിഷും ഇംഗ്ലീഷും വെറുപ്പുള്ള സംസാര ഡിറ്റീഷന്‍</a>
<a id=mn_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</a>
<a id=ms_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</a>
<a id=mt_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</a>
<a id=nl_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval op SemEval-2019 Taak 5: LSTM aanpak van haatspraakdetectie in het Engels en Spaans</a>
<a id=no_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval ved semiEval-2019 oppgåve 5: LSTM-tilnærming til hatt-taleoppdaging på engelsk og spansk</a>
<a id=pl_title style=display:none href=https://aclanthology.org/S19-2089.pdf>Zadanie 5: Podejście LSTM do wykrywania mowy nienawiści w języku angielskim i hiszpańskim</a>
<a id=pt_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval no SemEval-2019 Tarefa 5: Abordagem LSTM para Detecção de Discurso de Ódio em Inglês e Espanhol</a>
<a id=ro_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval la SemEval-2019 Sarcina 5: Abordarea LSTM pentru detectarea vorbirii urâte în limba engleză și spaniolă</a>
<a id=ru_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval на SemEval-2019 Задача 5: Подход LSTM к обнаружению ненавистнической речи на английском и испанском языках</a>
<a id=si_title style=display:none href=https://aclanthology.org/S19-2089.pdf>Tueval at semeval-2019 Job 5: LSTM approach to Hate Talk Detection in English and Sphere</a>
<a id=sk_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval na SemEval-2019 Naloga 5: pristop LSTM k odkrivanju sovražnega govora v angleščini in španščini</a>
<a id=so_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in Ingiriis and Isbanish</a>
<a id=sq_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</a>
<a id=sr_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval na semiEval-2019 Task 5: LSTM pristup otkrivanju govora mržnje na engleskom i španjolskom</a>
<a id=sv_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval på SemEval-2019 Uppgift 5: LSTM-metoden för att hata taldetektering på engelska och spanska</a>
<a id=sw_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval katika kazi ya SemEval-2019 5: LSTM Kuelekea Kutambua Hotuba ya Hati kwa Kiingereza na Kihispania</a>
<a id=ta_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</a>
<a id=tr_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</a>
<a id=uk_title style=display:none href=https://aclanthology.org/S19-2089.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/S19-2089.pdf>ٹوئوئل-2019 ٹاکس 5 میں ٹوئوئل: LSTM انگلیسی اور اسپانیایی میں دشمنی بات شناسایے کے لئے تقریبا ہے</a>
<a id=uz_title style=display:none href=https://aclanthology.org/S19-2089.pdf>SemEval- 2019 Vazifa 5: LSTM Approach to Hate Speech Detection Ingliz va Ispanchaga</a>
<a id=vi_title style=display:none href=https://aclanthology.org/S19-2089.pdf>TuEval tại SemEvl-209 Task 5: LSTM tiếp cận đến ghét diễn văn bằng tiếng Anh và Tây Ban Nha</a>
<a id=zh_title style=display:none href=https://aclanthology.org/S19-2089.pdf>周一在SemEval-2019务5:LSTM英语与西班牙语仇言检法</a></h2><p class=lead><a href=/people/m/mihai-manolescu/>Mihai Manolescu</a>,
<a href=/people/d/denise-lofflad/>Denise Löfflad</a>,
<a href=/people/a/adham-nasser-mohamed-saber/>Adham Nasser Mohamed Saber</a>,
<a href=/people/m/masoumeh-moradipour-tari/>Masoumeh Moradipour Tari</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>The detection of <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a>, especially in online platforms and <a href=https://en.wikipedia.org/wiki/Internet_forum>forums</a>, is quickly becoming a hot topic as anti-hate speech legislation begins to be applied to public discourse online. The HatEval shared task was created with this in mind ; participants were expected to develop a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> capable of determining whether or not input (in this case, Twitter datasets in English and Spanish) could be considered <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a> (designated as Task A), if they were aggressive, and whether the tweet was targeting an individual, or speaking generally (Task B). We approached this task by creating an <a href=https://en.wikipedia.org/wiki/Linear_time-invariant_system>LSTM model</a> with an <a href=https://en.wikipedia.org/wiki/Embedding>embedding layer</a>. We found that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performed considerably better on <a href=https://en.wikipedia.org/wiki/English_language>English language input</a> when compared to <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish language input</a>. In <a href=https://en.wikipedia.org/wiki/English_language>English</a>, we achieved an <a href=https://en.wikipedia.org/wiki/Standard_score>F1-Score</a> of 0.466 for Task A and 0.462 for Task B ; In <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, we achieved scores of 0.617 and 0.612 on Task A and Task B, respectively.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Die opdekking van haatspraak, veral in onlineplatforme en forume, word gou 'n warm onderwerp as anti-haatspraat wetgewing begin toepassing word op openbare diskursie online. Die HatEval gedeelde taak is geskep met hierdie in gedagte; Deelnaders was verwag om 'n model te ontwikkel wat moontlik is om te bepaal of nie invoer (in hierdie geval, Twitter datastelle in Engels en Spaanse) van haatspraak (as Opdrag A aangestel word), as hulle aggressief was, en of die tweet 'n individueel, of gewoonlik (Taak B) te doen. Ons het hierdie taak toegekom deur 'n LSTM model te skep met 'n inbêer laag. Ons het gevind dat ons model beter uitgevoer het op Engels taal ingevoer wanneer vergelyk word met Spaanse taal ingevoer. In Engels het ons 'n F1-Telling van 0.466 bereik vir Taak A en 0.462 vir Taak B; In Spaanse, ons het rekening 0.617 en 0.612 op Opdrag A en Opdrag B, respektief.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>የጥል ንግግር፣ በተለይም የበይነመረብ መድረክ እና ፎርማቶች ውስጥ፣ የጥል ንግግር ሕግ በመስመር የህዝብ ንግግር ለመጠቀም ሲጀምር ፈጥኖ ትኩሳት ጉዳይ ሆነዋል፡፡ የሐቴዌል ስራ በዚህ ምክንያት ተፈጠረ፤ ተጋሪዎቹ የኢንጂልኛ እና ስፓኒሽ ቋንቋ ውስጥ የTwitter ዳታተር ቋንቋ (ስክ A) የተጠቃሚ ንግግር (ማድረግ A) ቢሆኑ፣ ትዊተር አንድ ሰው ወይም በሙሉ የሚናገር ቢሆን (ስራ B) የጥል ንግግር መሆኑን ማረጋገጥ የሚችል ምሳሌ መፍጠር ተስፋ ያደርጋል፡፡ አዲስ ደረጃን በመፍጠር የLSTM ምሳሌ አቀረብን፡፡ ምሳሌያችን ከስፓኒሽ ቋንቋ ጥያቄ በተደረገ ጊዜ በንግግሊዘኛ ቋንቋ ውስጥ እጅግ የበለጠ እንደተደረገ አግኝተናል፡፡ በንግግሊዝኛ የስራ አ እና 0.462 ለስራ B F1-ነጥብ አግኝተናል፡፡ In Spanish, we achieved scores of 0.617 and 0.612 on Task A and Task B, respectively.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>أصبح الكشف عن خطاب الكراهية ، لا سيما في المنصات والمنتديات عبر الإنترنت ، موضوعًا ساخنًا سريعًا حيث بدأ تطبيق تشريعات مكافحة خطاب الكراهية على الخطاب العام عبر الإنترنت. تم إنشاء مهمة HatEval المشتركة مع وضع ذلك في الاعتبار ؛ كان من المتوقع أن يطور المشاركون نموذجًا قادرًا على تحديد ما إذا كانت المدخلات (في هذه الحالة ، مجموعات بيانات Twitter باللغتين الإنجليزية والإسبانية) يمكن اعتبارها كلامًا يحض على الكراهية (تم تحديدها كمهمة أ) ، إذا كانت عدوانية ، وما إذا كانت التغريدة تستهدف فردي ، أو يتحدث بشكل عام (المهمة ب). لقد تعاملنا مع هذه المهمة من خلال إنشاء نموذج LSTM بطبقة التضمين. وجدنا أن نموذجنا كان يعمل بشكل أفضل في إدخال اللغة الإنجليزية عند مقارنته بإدخال اللغة الإسبانية. في اللغة الإنجليزية ، حققنا درجة F1 من 0.466 للمهمة A و 0.462 للمهمة B ؛ في الإسبانية ، حققنا درجات 0.617 و 0.612 في المهمة أ والمهمة ب ، على التوالي.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nefrət sözlərinin, özlərinə də onlayn platformlarında və forumlarda, tezliklə nifrət sözlərinin qarşısındaki qanunların online sözlərinə uyğunlanmasına başladığı üçün isti bir məsəl olar. HatEval bu işi düşünüb yaratdı. İşkilərin daxil olmasını müəyyən edə biləcəyi bir modeli təmizləməsi gözlənilmişdi (bu halda, Twitter veri quruları İngilis və İspanyol dilində, İngilis və İspanyol dilində, İngilis dilində və İspanyol dilində) nifrət sözləri (A Task kimi təşkil edilmişdi), əgər təşkil edilmiş olsalar və ya tweet individu Biz bu işə yaxınlaşdıq, LSTM modeli inşa etmək üçün. Bizim modellərimiz İspanyol dili girişi ilə qarşılaşdığı zaman İngiliz dili girişində çox yaxşı işlədi. İngilizce dilində, B işi üçün A və 0.462 işi üçün F1-Score nəsib etdik. İspanyolca, işin A və Task B barəsində 0.617 və 0.612 nöqtələrini qəbul etdik.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Откриването на речта на омразата, особено в онлайн платформи и форуми, бързо се превръща в гореща тема, тъй като законодателството против речта на омразата започва да се прилага към публичния дискурс онлайн. Споделената задача на ХатЕвал е създадена с това предвид; от участниците се очаква да разработят модел, който да определи дали въвеждането (в този случай набори от данни на английски и испански език) може да се счита за реч на омразата (определена като задача А), дали те са агресивни и дали туитът е насочен към индивид или говори общо (задача Б). Ние подходихме към тази задача чрез създаване на модел с вграден слой. Открихме, че нашият модел се представя значително по-добре при въвеждането на английски език в сравнение с въвеждането на испански език. На английски език постигнахме оценка от 0,466 за задача А и 0,462 за задача Б; На испански език постигнахме резултати от 0,617 и 0,612 съответно по задача А и задача Б.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>বিশেষ করে অনলাইন প্লাটফর্ম এবং ফোরামে ঘৃণা ভাষণের আবিষ্কার হচ্ছে তারা দ্রুত একটি গরম বিষয়ে পরিণত হচ্ছে যেহেতু ঘৃণা বিরোধী বক্তৃতা বিরোধী হাটিভাল শেয়ার কর্মসূচি এই মাথায় তৈরি করা হয়েছে; অংশগ্রহণকারীদের আশা করা হয়েছিল যে একটি মডেল তৈরি করতে পারে যা সিদ্ধান্ত নির্ধারণ করতে সক্ষম হবে কিনা (এই ক্ষেত্রে টুইটার ডাটাটাসেট ইংরেজী ও স্প্যানিশ ভাষায়) ঘৃণা ভাষণ বিবেচন আমরা এলস্টিএম মডেল তৈরি করে এই কাজের কাছে এসেছিলাম, যেখানে একটি বিভিন্ন স্তর তৈরি করেছিলাম। আমরা পেয়েছি যে স্প্যানিশ ভাষার ইনপুটের তুলনায় আমাদের মডেল অনেক ভালো করেছিল। ইংরেজি ভাষায় আমরা কাজ A এবং 0.462 টাকা বির জন্য একটি F1-স্কোর অর্জন করেছি; স্প্যানিশ ভাষায় আমরা কাজ A এবং কাজ বিরুদ্ধে ০. 617 এবং 0.612 স্কোর অর্জন করেছি।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>དྲ་ཐོག་དང་གླེང་སྡོམ་དང་འཆར་བརྗོད་ཀྱི་གཏམ་བཤེར་གྱི་རྟོགས་བཤེར་ནི་འགྱུར་མཁན་དུ་ཆགས་པ་དང་། ཁོང་གིས་ཤེས་བྱ་རྣམས་གཅིག་མཐུན་གྱི་ལས་འགུལ་དེ་སེམས་སུ་འཇུག་བྱས་པ་ཡིན། ཞུགས་མི་མང་གིས་གསལ་བཤད་ན་མིན་པའི་མིག་ལམ་ཞིག་དཔག་འཛིན་བྱེད་རྒྱུ་དང་མིན་འདུག ང་ཚོས་ཀྱིས་མཐུད་སྒྲིག་བང་རིམ་ལ་LSTM་རྣམ་པ ང་ཚོས་རང་གི་མ་དབྱིབས་དབྱིབས་ཡིག་གི་སྐད་རིགས་ནང་བཙུགས་སྐབས་སུ་མཐུན་རྐྱེན་བྱས་པ་ཡིན། In English, we achieved an F1-Score of 0.466 for Task A and 0.462 for Task B; for Task B སྐད་ཡིག་གི་ནང་དུ་ང་ཚོ་རྒྱལ་ཁབ་འགྲོ་བ་ཡིན། འགྲོ་བ་དང་ལས་འགུལ་བཞིན་པའི་གྲངས་ཀ་འགྲོ་བ་ཡིན།</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Otkrivanje govora mržnje, posebno na internetskim platformama i forumima, brzo postaje vruća tema jer se zakonodavstvo o govoru protiv mržnje počinje primjenjivati na javne diskursije na internetu. HatEval je podijeljen zadatak stvoren na umu s tim; Očekivalo se da će učesnici razviti model sposoban za utvrđivanje da li ulaz (u tom slučaju, Twitter podaci na engleskom i španjolskom) mogli biti smatrani govorom mržnje (izrađenim kao Task A), ako su agresivni, i da li je tweet ciljao pojedincu ili govoreći općenito (Task B). Prišli smo ovom zadatku stvarajući LSTM model sa ugrađenim slojem. Pronašli smo da je naš model izvršio mnogo bolje u odnosu na ulaz engleskog jezika u usporedbi sa ulazom španjolskog jezika. Na engleskom jeziku, postigli smo F1-Score od 0,466 za zadatak A i 0,462 za zadatak B; Na španjolskom smo postigli rezultate 0,617 i 0,612 na zadatku A i zadatku B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La detecció del discurs d'odi, especialment en plataformes i fòrums en línia, s'està convertint ràpidament en un tema calent, mentre la llei contra l'odi comença a aplicar-se al discurs públic en línia. La tasca compartida HatEval va ser creata amb això a la ment; s'esperava que els participants desenvolupin un model capaç de determinar si les entrades (en aquest cas, els conjunts de dades de Twitter en anglès i espanyol) podrien ser considerades discursos d'odi (designats com a tasca A), si eren agressives, i si la tweet mirava a un individu o parlava en general (tasca B). Vam abordar aquesta tasca creant un model LSTM amb una capa incorporadora. Vam descobrir que el nostre model va funcionar considerablement millor en l'entrada en anglès en comparació amb l'entrada en espanyol. En anglès, vam aconseguir una puntuació F1 de 0,466 per la tasca A i 0,462 per la tasca B; In Spanish, we achieved scores of 0.617 and 0.612 on Task A and Task B, respectively.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Odhalování nenávistných projevů, zejména na online platformách a fórech, se rychle stává žhavým tématem, protože legislativa proti nenávistným projevům se začíná aplikovat na veřejný diskurz online. Společný úkol HatEval byl vytvořen s tímto ohledem; Od účastníků se očekávalo, že vyvinou model schopný určit, zda lze vstup (v tomto případě datové sady Twitteru v angličtině a španělštině) považovat za nenávistnou řeč (označené jako úkol A), zda jsou agresivní a zda se tweet zaměřil na jednotlivce, nebo obecně mluví (Úkol B). K tomuto úkolu jsme přistupovali vytvořením LSTM modelu s vkládací vrstvou. Zjistili jsme, že náš model vedl výrazně lepší na vstupu anglického jazyka ve srovnání se španělským jazykem. V angličtině jsme dosáhli F1 skóre 0.466 pro úkol A a 0.462 pro úkol B; Ve španělštině jsme dosáhli bodů 0.617 a 0.612 u úkolu A a úkolu B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Afsløringen af hadefulde taler, især i onlineplatforme og fora, er hurtigt ved at blive et varmt emne, da anti-hadefulde talelovgivninger begynder at blive anvendt på den offentlige diskurs online. HatEval delte opgave blev skabt med dette i tankerne; Deltagerne forventedes at udvikle en model, der kunne afgøre, om input (i dette tilfælde Twitter-datasæt på engelsk og spansk) kunne betragtes som hadefuld tale (betegnet som opgave A), om de var aggressive, og om tweetet var rettet mod en person eller generelt (opgave B). Vi nåede denne opgave ved at skabe en LSTM model med et integreringslag. Vi fandt ud af, at vores model fungerede betydeligt bedre på engelsk sproginput sammenlignet med spansk sproginput. På engelsk opnåede vi en F1-score på 0,466 for opgave A og 0,462 for opgave B; På spansk opnåede vi scorer på henholdsvis 0,617 og 0,612 på opgave A og opgave B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Die Erkennung von Hassreden, insbesondere in Online-Plattformen und Foren, wird schnell zu einem heißen Thema, da Anti-Hass-Redegesetzgebung beginnt, auf den öffentlichen Diskurs online anzuwenden. Die gemeinsame Aufgabe von HatEval wurde in diesem Sinne geschaffen; Von den Teilnehmern wurde erwartet, dass sie ein Modell entwickeln, das bestimmen kann, ob Eingaben (in diesem Fall Twitter-Datensätze auf Englisch und Spanisch) als Hassrede (als Aufgabe A bezeichnet) angesehen werden können, ob sie aggressiv sind und ob der Tweet auf eine Person abzielt oder allgemein gesprochen wurde (Aufgabe B). Wir näherten uns dieser Aufgabe, indem wir ein LSTM-Modell mit einer Einbettungsebene erstellt haben. Wir fanden heraus, dass unser Modell wesentlich besser auf Englisch eingegeben wurde als auf Spanisch. Auf Englisch erreichten wir einen F1-Score von 0.466 für Aufgabe A und 0.462 für Aufgabe B; Auf Spanisch erreichten wir Punkte von 0.617 und 0.612 bei Task A bzw. Task B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Η ανίχνευση της ρητορικής μίσους, ειδικά σε διαδικτυακές πλατφόρμες και φόρουμ, γίνεται γρήγορα καυτό θέμα καθώς η νομοθεσία περί ρητορικής μίσους αρχίζει να εφαρμόζεται στον δημόσιο διάλογο στο διαδίκτυο. Το κοινό έργο της HatEval δημιουργήθηκε με αυτό κατά νου. Αναμένεται από τους συμμετέχοντες να αναπτύξουν ένα μοντέλο ικανό να καθορίσει αν η εισαγωγή (σε αυτή την περίπτωση, σύνολα δεδομένων Twitter στα αγγλικά και ισπανικά) θα μπορούσε να θεωρηθεί ρητορική μίσους (που ορίζεται ως εργασία Α), αν ήταν επιθετική και αν το tweet στόχευε ένα άτομο ή μιλούσε γενικά (εργασία Β). Προσεγγίσαμε αυτό το έργο δημιουργώντας ένα μοντέλο με ένα στρώμα ενσωμάτωσης. Διαπιστώσαμε ότι το μοντέλο μας αποδίδει σημαντικά καλύτερα στην εισαγωγή της αγγλικής γλώσσας σε σύγκριση με την εισαγωγή της ισπανικής γλώσσας. Στα αγγλικά, πετύχαμε έναν δείκτη F1 0.466 για την εργασία A και 0.462 για την εργασία B. Στα ισπανικά, πετύχαμε βαθμολογίες 0.617 και 0.612 για την εργασία Α και την εργασία Β αντίστοιχα.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La detección de la incitación al odio, especialmente en plataformas y foros en línea, se está convirtiendo rápidamente en un tema candente a medida que la legislación contra la incitación al odio comienza a aplicarse al discurso público en línea. La tarea compartida HatEval se creó con esto en mente; se esperaba que los participantes desarrollaran un modelo capaz de determinar si los aportes (en este caso, los conjuntos de datos de Twitter en inglés y español) podían considerarse discurso de odio (designado como Tarea A), si eran agresivos y si el tuit era dirigirse a una persona o hablar en general (Tarea B). Abordamos esta tarea creando un modelo LSTM con una capa de incrustación. Descubrimos que nuestro modelo tuvo un rendimiento considerablemente mejor en la entrada del idioma inglés en comparación con la entrada en español. En inglés, logramos una puntuación F1 de 0.466 para la Tarea A y 0.462 para la Tarea B; en español, logramos puntuaciones de 0.617 y 0.612 en la Tarea A y la Tarea B, respectivamente.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vihakõne avastamine, eriti veebiplatvormides ja foorumites, on kiiresti muutumas kuumaks teemaks, kuna vihakõne vastu võitlevaid õigusakte hakatakse kohaldama avaliku diskursuse suhtes internetis. Seda silmas pidades loodi HatEvali jagatud ülesanne; osalejatelt oodati, et nad töötaksid välja mudeli, mis võimaldaks kindlaks määrata, kas sisestust (antud juhul Twitteri andmekogumeid inglise ja hispaania keeles) võib pidada vihakõneks (nimetatud ülesandeks A), kas nad on agressiivsed ja kas säuts on suunatud üksikisikule või räägib üldiselt (ülesanne B). Me lähenesime sellele ülesandele, luues LSTM mudeli koos manustamiskihiga. Leidsime, et meie mudel oli inglise keele sisestuses oluliselt parem kui hispaania keele sisestus. Inglise keeles saavutasime F1-skoori 0,466 ülesande A ja 0,462 ülesande B puhul; Hispaania keeles saavutasime tulemused vastavalt 0,617 ja 0,612 ülesandes A ja B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>کشف سخنرانی از نفرت، مخصوصا در platformهای آنلاین و فورموس، سریع به عنوان قوانین ضد نفرت سخنرانی شروع می‌کند که بر صحبت عمومی آنلاین کاربرد می‌شود. این کار را با این ذهن آفریده شده است. شرکتگران انتظار داشته بودند که یک مدل قادر به تصمیم گرفتن ورودی (در این مورد، مجموعه داده‌های توئیتر به انگلیسی و اسپانیایی) سخنرانی ناخوشایند (نامیده شده به عنوان وظیفه A) را توسعه کنند، و اگر توئیت یک فرد را هدف می‌دهد یا در کلی صحبت می‌کند (وظیفه B). ما با ایجاد یک مدل LSTM با یک لایه وارد کردن به این کار نزدیک شدیم. ما فهمیدیم که مدل ما در ورودی زبان انگلیسی با ورودی زبان اسپانیایی بسیار بهتر انجام داده است. در انگلیسی، ما یک نمونه F1-از 0.466 برای وظیفه A و 0.462 برای وظیفه B رسیدیم. در اسپانیایی، به طور مستقیما امتیاز 0.617 و 0.612 در کار A و کار B رسیدیم.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vihanpuheen havaitsemisesta erityisesti verkkoalustoilla ja foorumeilla on nopeasti tulossa kuuma aihe, kun vihapuheen vastaista lainsäädäntöä aletaan soveltaa julkiseen keskusteluun verkossa. HatEvalin yhteinen tehtävä luotiin tätä silmällä pitäen; Osallistujien odotettiin kehittävän malli, jolla pystytään määrittämään, voidaanko syöttöä (tässä tapauksessa Twitterin englannin- ja espanjankieliset tietoaineistot) pitää vihapuheena (nimetty tehtäväksi A), ovatko he aggressiivisia ja kohdistuuko tweetti yksilöön vai puhuuko yleisesti (tehtävä B). Lähestyimme tätä tehtävää luomalla LSTM-mallin upotuskerroksella. Havaitsimme, että mallimme suoriutui huomattavasti paremmin englannin kielen syötteessä kuin espanjan kielen syötteessä. Englanniksi saavutimme F1-pisteet 0,466 tehtävässä A ja 0,462 tehtävässä B. Espanjaksi saavutimme pisteet 0,617 tehtävässä A ja 0,612 tehtävässä B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La détection des discours de haine, en particulier sur les plateformes et les forums en ligne, devient rapidement un sujet brûlant alors que la législation anti-discours de haine commence à s'appliquer au discours public en ligne. La tâche partagée HatEval a été créée dans cet esprit ; les participants devaient développer un modèle capable de déterminer si les entrées (dans ce cas, les ensembles de données Twitter en anglais et en espagnol) pouvaient être considérées comme des discours haineux (désigné comme tâche A), s'ils étaient agressifs, et si le tweet était cibler un individu, ou parler de manière générale (tâche B). Nous avons abordé cette tâche en créant un modèle LSTM avec une couche d'intégration. Nous avons constaté que notre modèle fonctionnait considérablement mieux sur la saisie en anglais que sur la saisie en espagnol. En anglais, nous avons obtenu un score F1 de 0,466 pour la tâche A et de 0,462 pour la tâche B ; en espagnol, nous avons obtenu des scores de 0,617 et 0,612 pour la tâche A et la tâche B, respectivement.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tá braite fuathchaint, go háirithe ar ardáin agus fóraim ar líne, ag éirí go han-tapa mar ábhar mór le rá de réir mar a thosaíonn reachtaíocht cainte frith-fuath a chur i bhfeidhm ar dhioscúrsa poiblí ar líne. Cruthaíodh an tasc roinnte HatEval leis seo san áireamh; bhíothas ag súil go bhforbródh rannpháirtithe samhail a bheadh in ann a chinneadh an bhféadfaí nó nach bhféadfaí ionchur (sa chás seo, tacair sonraí Twitter i mBéarla agus i Spáinnis) a mheas mar fhuathchaint (ainmnithe mar Thasc A), má bhí siad ionsaitheach, agus an raibh an tweet dírithe ar duine aonair, nó ag labhairt go ginearálta (Tasc B). Thugamar faoin tasc seo trí mhúnla LSTM a chruthú le ciseal leabaithe. Fuaireamar amach gur fheidhmigh ár samhail i bhfad níos fearr ar ionchur Béarla i gcomparáid le hionchur sa Spáinnis. I mBéarla, bhaineamar amach Scór F1 de 0.466 do Thasc A agus 0.462 do Thasc B; Sa Spáinnis, bhaineamar scóir 0.617 agus 0.612 amach ar Thasc A agus ar Thasc B, faoi seach.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ana gane magana na ƙi, da haske cikin majalan da jama'a masu haske, sai yana fara zama madaidaici mai hot, kamar yadda sharciyar ta fara a Apply wa magana na jamii a kusa. An halitta aikin Hateval da aka raba shi a kan wannan. Ana ƙayyade mushirikai ya motsar wani misali wanda yake iya iya ƙayyade shi, ko kuma ba a iya iya gane (a cikin wannan case, za'a iya ƙayyade mutane ta cikin Ingiriya da Kispanish) da magana na ƙyãma (aka ƙayyade su kamar Tashin A), idan sun kasance ana yi ƙyãma, kuma idan Twitter na yi amfani da wani mutum, ko kuwa ya yi magana a jumla (Taaikin B). Mun kusantar wannan aikin da Muka sami wani misali na LSSM da wani mai shiga Mun gane cewa misalinmu ya sami mai kyau a cikin cikin harshen Ingiriya idan da aka sammenliki da tsarin harshen Isspanish. @ item Spelling dictionary Ga Isbaniya, muka sami score 0,617 da 0,612 a kan aikin A da aikin B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>גילוי הנאום לשנאה, במיוחד בתחנות ופורומים באינטרנט, הופך במהירות לנושא חם כאשר חוקי הנאום נגד השנאה מתחילים להתייחס לדיוח ציבורי באינטרנט. המשימה המשותפת של האטאוול נוצרה עם זה בראש; השתתפים צפו לפתח מודל מסוגל לקבוע אם תוכנית (במקרה הזה, קבוצות מידע טוויטר באנגלית וספרדית) יכולות להיחשב נאום שנאה (נקבע בתור משימה A), אם הן היו אגרסיביות, ואם הטוויטר היתה מטרה לאדם או דיברה באופן כללי (משימה B). הגענו למשימה הזו על ידי יצירת דוגמנית LSTM עם שכבה מעורבת. מצאנו שהמודל שלנו הצליח הרבה יותר טוב בהכניסה של שפה אנגלית בהשוואה להכניסה של שפה ספרדית. באנגלית השגנו נקודת F1 של 0.466 למשימה A ו-0.462 למשימה B; בספרדית, השגנו נקודות של 0.617 ו-0.612 על משימה A וממשימה B, בהתאם.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>नफरत भाषण का पता लगाना, विशेष रूप से ऑनलाइन प्लेटफार्मों और मंचों में, जल्दी से एक गर्म विषय बन रहा है क्योंकि विरोधी नफरत भाषण कानून को ऑनलाइन सार्वजनिक प्रवचन पर लागू किया जाना शुरू हो जाता है। HatEval साझा कार्य को इस बात को ध्यान में रखते हुए बनाया गया था; प्रतिभागियों को यह निर्धारित करने में सक्षम एक मॉडल विकसित करने की उम्मीद थी कि इनपुट (इस मामले में, अंग्रेजी और स्पेनिश में ट्विटर डेटासेट) को हेट स्पीच (टास्क ए के रूप में नामित) माना जा सकता है या नहीं, अगर वे आक्रामक थे, और क्या ट्वीट किसी व्यक्ति को लक्षित कर रहा था, या आम तौर पर बोल रहा था (टास्क बी)। हमने एक एम्बेडिंग परत के साथ एक एलएसटीएम मॉडल बनाकर इस कार्य से संपर्क किया। हमने पाया कि हमारे मॉडल ने स्पेनिश भाषा इनपुट की तुलना में अंग्रेजी भाषा इनपुट पर काफी बेहतर प्रदर्शन किया। अंग्रेजी में, हमने कार्य A के लिए 0.466 और कार्य B के लिए 0.462 का F1-स्कोर प्राप्त किया; स्पेनिश में, हमने टास्क ए और टास्क बी पर क्रमशः 0.617 और 0.612 का स्कोर हासिल किया।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Otkrivanje govora mržnje, posebno na internetskim platformama i forumima, brzo postaje vruća tema jer se zakonodavstvo o govoru protiv mržnje počinje primjenjivati na javne diskursije na internetu. HatEval zajednički zadatak je stvoren na umu s tim; Očekivalo se da će učesnici razviti model sposoban za utvrđivanje da li ulaz (u tom slučaju, Twitter podaci na engleskom i španjolskom) smatrati govorem mržnje (izraženim kao zadatak A), ako su agresivni, i da li je tweet ciljao pojedincu ili govoreći općenito (zadatak B). Prišli smo ovom zadatku stvarajući LSTM model sa ugrađenim slojem. Našli smo da je naš model izvršio značajno bolje u odnosu na ulaz engleskog jezika u usporedbi s ulazom španjolskog jezika. Na engleskom jeziku postigli smo F1-Score od 0,466 za zadatak A i 0,462 za zadatak B; Na španjolskom smo postigli rezultate 0,617 i 0,612 na zadatku A i zadatku B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A gyűlöletbeszéd felismerése, különösen az online platformokon és fórumokon, gyorsan forró témává válik, mivel a gyűlöletbeszéd elleni jogszabályok kezdenek alkalmazni az online nyilvános diskurzusra. A HatEval megosztott feladatot ezzel szem előtt tartva hozták létre; A résztvevőktől elvárták, hogy olyan modellt dolgozzanak ki, amely meghatározza, hogy a bevitel (ebben az esetben angol és spanyol Twitter adatkészletek) gyűlöletbeszédnek tekinthető-e (A feladatként jelölt), agresszív-e, és hogy a tweet egy személyt céloz-e, vagy általánosan beszél (B feladat). Ezt a feladatot egy beágyazó réteggel ellátott LSTM modell létrehozásával közelítettük meg. Megállapítottuk, hogy modellünk jelentősen jobban teljesített az angol nyelvű bevitel tekintetében, mint a spanyol nyelvű bevitel. Angolul 1 pontszámot értünk el az A feladatnál, a B feladatnál pedig 0,462 pontszámot; Spanyolul 0,617 és 0,612 pontszámot értünk el az A és B feladaton.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ատելության խոսքի հայտնաբերումը, հատկապես առցանց պլատֆորմերում և ֆորմերում, արագ դառնում է տաք թեմա, քանի որ ատելության դեմ խոսքի օրենսդրությունը սկսում է կիրառվել առցանց հանրային խոսքի համար: Հաթեվալ ընդհանուր խնդիրը ստեղծվել է այս մտքում, մասնակիցները ակնկալում էին, որ կզարգացնեն մոդել, որը կկարողանա որոշել, թե արդյոք ներմուծը (այս դեպքում Թվիթերի տվյալների համակարգերը անգլերենում և իսպաներեն) կարելի է համարվել ատելության ելույթ (որը կոչվում է Ա-ի առաջադրանք), եթե նրանք ագրեսիվ են, և արդյոք Թվիթերը նպատակ Մենք մոտեցանք այս խնդիրը ստեղծելով LSMT մոդել ներգրավված շերտի հետ: Մենք հայտնաբերեցինք, որ մեր մոդելը շատ ավելի լավ էր աշխատում անգլերեն լեզվի ներմուծների վրա, համեմատած իսպաներեն լեզվի ներմուծների վրա: Անգլերենում մենք հասանք 0.466-ի F1-գնահատականի A-ի և 0.462-ի B-ի համար: Իսպաներեն մենք հասանք 0,617 և 0,612 գնահատականների A և B խնդիրներում:</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Deteksi pidato kebencian, terutama di platform dan forum online, cepat menjadi topik panas karena undang-undang pidato anti kebencian mulai diaplikasikan pada pidato publik online. Tugas bersama HatEval diciptakan dengan ini dalam pikiran; peserta diharapkan untuk mengembangkan model yang mampu menentukan apakah input (dalam kasus ini, set data Twitter dalam bahasa Inggris dan Spanyol) dapat dianggap pidato kebencian (ditentukan sebagai Tugas A), jika mereka agresif, dan apakah tweet menargetkan individu, atau berbicara secara umum (Tugas B). Kami mendekati tugas ini dengan menciptakan model LSTM dengan lapisan penerbangan. We found that our model performed considerably better on English language input when compared to Spanish language input. Dalam bahasa Inggris, kami mencapai nilai F1 0,466 untuk Tugas A dan 0,462 untuk Tugas B; In Spanish, we achieved scores of 0.617 and 0.612 on Task A and Task B, respectively.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>L'individuazione del discorso d'odio, soprattutto nelle piattaforme e nei forum online, sta rapidamente diventando un argomento caldo, poiché la legislazione anti-odio del discorso inizia ad essere applicata al discorso pubblico online. Il compito condiviso di HatEval è stato creato con questo in mente; Ci si aspettava che i partecipanti sviluppassero un modello in grado di determinare se l'input (in questo caso, i dataset di Twitter in inglese e spagnolo) potessero essere considerati discorsi di odio (designati come Task A), se fossero aggressivi, e se il tweet fosse rivolto a un individuo, o parlando in generale (Task B). Abbiamo affrontato questo compito creando un modello LSTM con un livello embedding. Abbiamo scoperto che il nostro modello ha funzionato notevolmente meglio sull'input in lingua inglese rispetto all'input in lingua spagnola. In inglese, abbiamo ottenuto un F1-Score di 0,466 per Task A e 0,462 per Task B; In spagnolo, abbiamo ottenuto punteggi di 0,617 e 0,612 rispettivamente sul Task A e sul Task B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ヘイトスピーチの検出、特にオンラインプラットフォームやフォーラムでのヘイトスピーチの検出は、ヘイトスピーチ防止法がオンラインの公開講演に適用され始めると、すぐにホットな話題になり始めています。HatEval共有タスクは、これを念頭に置いて作成されました。参加者は、入力（この場合、英語とスペイン語のTwitterデータセット）がヘイトスピーチと見なされるかどうか（タスクAとして指定）、攻撃的であるかどうか、ツイートが個人を対象としているかどうか、または一般的に話しているかどうか（タスクB ）を判断できるモデルを開発することが期待されています。埋め込みレイヤーを持つLSTMモデルを作成することで、このタスクにアプローチしました。私たちのモデルは、スペイン語入力と比較して、英語入力でかなり優れたパフォーマンスを発揮することがわかりました。英語では、タスクAで0.466、タスクBで0.462のF 1スコアを達成しました。スペイン語では、タスクAとタスクBでそれぞれ0.617、0.612のスコアを達成しました。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Alpha Heh, Debian nganggo perusahaan Debian kang dipun nggo kuwi iki; mengko kuwi sawalih Display brightness Awak dhéwé ngewehi nggo nggawe task iki di nggawe modèl LTT M nganggo alat sing basa batir. Awak dhéwé éntuk ono model sing paling nggambar luwih apik, yakuwis seneng nggambar tarjamahan karo ingkang spanyol. Nanging Inggris, kita wis gunakake F1-Point of 0.4x6 kanggo task A lan 0.4x2 kanggo task B; Anyone</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>სხვადასხვა მპატის სიტყვას, განსაკუთრებით ინტერნეტი პლატორმებში და ფორმებში, სწრაფად იქნება სამყარო თემა, როგორც ანტი მპატის სიტყვას საკუთარი საკუთარი ინტერ HatEval სხვადასხვა საქმე იყო შექმნა ამით. მომხმარებელი იქნება მოდელის განვითარება, რომელიც შეუძლებელია განვითარება თუ არა შეიძლებელია მოდელის შესაძლებლობა (ამ შემთხვევაში, Twitter მონაცემები ინგლისური და სპანელი) შეიძლება იყოს წინაწინაწინაწინაწინაწინაწინაწინ ჩვენ ამ სამუშაო დავიწყეთ LSTM მოდელის შექმნა, რომელიც შეიძლება დავყენება. ჩვენ მივიღეთ, რომ ჩვენი მოდელი ინგლისური ენის შენახვედზე უკეთესი გავაკეთე, როდესაც სპანელი ენის შენახვედზე. ანგლისურად, ჩვენ მივიღეთ F1-Score 0.466 დავალებისთვის A და 0.462 დავალებისთვის B დავალებისთვის; სპანუალურად ჩვენ მივიღეთ 0.617 და 0.612 დავალებით A და B დავალებით.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Жұмыс сөйлеуді, әсіресе онлайн платформаларда және форумдарда, жылдам жетістік сөйлеуді қарсы сөйлеу заң онлайн істеу үшін қолданылады. HatEval ортақ тапсырмасы оқылған. Қатысушыларға қатысушылардың келтірілмегенін анықтауға мүмкіндік беретін үлгісін жасау үшін күту болды (бұндай болса, Twitter деректер қорлары ағылшын және испан тілінде) қатысу сөзі (A тапсырма ретінде анықталған), егер олар агрессивне болса, және Біз осы тапсырманы ендіру қабатты LSTM үлгісін құрып келдік. Біз үлгіміздің ағылшын тілінің келтіріміне сәйкес Испан тілінің келтіріміне салыстырып жатыр деп ойладық. Ағылшын тілінде, B тапсырмасына A және 0,462 тапсырма үшін F1-Score жеткіздік. Испан тілінде Б тапсырмасында 0,617 және 0,612 нәтижелерін жеткіздік.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>혐오 언론 입법이 온라인 공공 언어에 적용되기 시작하면서 혐오 언론의 검측은 특히 온라인 플랫폼과 포럼에서 빠르게 화제가 되고 있다.HatEval 공유 작업은 이 점을 바탕으로 만들어진 것이다.참가자들은 입력(이 예에서 영어와 스페인어의 트위터 데이터 집합)이 증오 발언(퀘스트 a로 지정)으로 볼 수 있는지, 공격성이 있는지, 이 트위터가 개인을 겨냥했는지 아니면 동일시(퀘스트 B)로 볼 수 있는지를 확인할 수 있는 모델을 개발해야 한다.내장 레이어가 있는 LSTM 모델을 생성하여 이 작업을 완료했습니다.우리는 스페인어 입력에 비해 우리의 모델이 영어 입력에 있어서 더욱 잘 표현되는 것을 발견했다.영어에서는 미션 A의 F1 성적이 0.466이고 미션 B의 F1 성적이 0.462이다.스페인어에서는 미션 A와 미션 B에서 각각 0.617, 0.612의 점수를 받았다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neapykantos kalbos aptikimas, ypač internetinėse platformose ir forumuose, greitai tampa karšta tema, nes kovos su neapykanta kalbos teisės aktai pradedami taikyti viešajai kalbai internete. HatEval bendra užduotis buvo sukurta atsižvelgiant į tai; tikėtasi, kad dalyviai parengs model į, galintį nustatyti, ar įvestis (šiuo atveju Twitter duomenų rinkiniai anglų ir ispanų kalbomis) gali būti laikomas neapykantos kalba (vadinama A užduotimi), jei jie yra agresyvūs, ir ar Twitter skirtas asmeniui, ar kalbama apskritai (B užduotis). Atlikome šią užduotį sukūrėme LSTM model į su įterpiamuoju sluoksniu. Nustatėme, kad mūsų modelis gerokai geriau atliko anglų kalbos įnašus, palyginti su ispanų kalbos įnašais. In English, we achieved an F1-Score of 0.466 for Task A and 0.462 for Task B; Ispanų kalba pasiekėme atitinkamai 0,617 ir 0,612 rezultatų A ir B užduotyse.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Детектирањето на говорот за омраза, особено на онлајн платформи и форуми, брзо станува жешка тема бидејќи легислативата против омразата почнува да се применува на јавниот дискурс онлајн. Со ова беше создадена заедничката задача на HatEval; учесниците се очекуваа да развијат модел кој може да одреди дали влогот (во овој случај, датотеките на Твитер на англиски и шпански) може да се смета за говор на омраза (назначен како задача А), ако бил агресивен, и дали твитот бил насочен кон индивидуал или зборувал генерално (задача Б). Се приближивме до оваа задача со создавање на LSTM модел со вграден слој. Најдовме дека нашиот модел успеа значително подобро на влогот на англискиот јазик во споредба со влогот на шпанскиот јазик. На англиски, постигнавме F1-Score од 0,466 за задачата А и 0,462 за задачата Б; На шпански, постигнавме оценки од 0,617 и 0,612 за задачата А и задачата Б, односно.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>വെറുപ്പ് സംസാരം കണ്ടുപിടിക്കുന്നത്, പ്രത്യേകിച്ച് ഓണ്‍ലൈന്‍ പ്ലാറ്റ്ഫോമുകളിലും ഫോര്‍മുകളിലും പ്രത്യേകിച്ച് ചൂടുള്ള വിഷയത്തിലാ ഹാറ്റെവാല്‍ പങ്കാളിയുള്ള ജോലി ഇതിന്‍റെ മനസ്സില്‍ സൃഷ്ടിച്ചിരിക്കുന്നു; participants were expected to develop a model capable of determining whether or not input (in this case, Twitter datasets in English and Spanish) could be considered hate speech (designated as Task A), if they were aggressive, and whether the tweet was targeting an individual, or speaking generally (Task B). ഞങ്ങള്‍ ഈ ജോലിയിലേക്ക് എത്തിയപ്പോള്‍ ഒരു എംഎസ്റ്റം മോഡല്‍ ഉണ്ടാക്കുന്നത് കൊണ്ടാണ്. സ്പാനിഷ് ഭാഷ ഇന്‍പുട്ടിനെക്കുറിച്ച് താല്‍പ്പര്യമായി ഞങ്ങളുടെ മോഡല്‍ ഇംഗ്ലീഷ് ഭാഷ അകത്തില്‍ വളരെ നല്ലത് പ ഇംഗ്ലീഷില്‍ ഞങ്ങള്‍ ഒരു എഫ്‌1-സ്കോര്‍ നേടിയെടുത്തു. ടാസ്ക് ബിന് വേണ്ടി ടാസ്ക് A എന്നും 0.462 എന്നിവയ്ക്കും; സ്പാനിഷില്‍ ഞങ്ങള്‍ നിര്‍ണ്ണയിക്കപ്പെട്ട സ്കോര്‍ 0.617, 0.612 ടാസ്ക് A, ടാസ്ക് ബിയില്‍ എത്തി.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Харамсалтай яриаг олох нь, ялангуяа онлайн платформ болон форумууд, хурдан үзэн ядуурлын ярианы эсрэг хууль нь нийтийн ярианы онлайн үеэр хэрэглэгдэх болно. HatEval-ын хуваалтын ажил үүнийг бодолд бий болгосон. Хэрэв оролцогчдын оролцогчдын оролцогчдын оролцоог тодорхойлох боломжтой загвар хөгжүүлэхийг хүсэж байлаа (энэ тохиолдолд Твиттер өгөгдлийн сангууд Англи болон Испан хэлний хэлний хэлний хэлний үзэн ядах хэлний хэлний хэлний хэлний хэлний хэлний хэлбэр Бид үүнийг LSTM загвар бий болгож ойртсон. Бид өөрсдийн загварын загвар Испанийн хэлний оролцоос харьцуулахад Англи хэлний оролцоонд маш сайн ажиллаж байгааг олж мэдсэн. Англи хэлний хэлээр бид Task A болон 0.462 Task B-д F1-Score хүртлээ. Испанид бид 0.617, 0.612 Task A болон Task B-ийн тоонуудыг олсон.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pengesanan ucapan kebencian, terutama dalam platform dan forum online, cepat menjadi topik yang panas kerana undang-undang ucapan anti-kebencian bermula untuk dilaksanakan pada diskors awam online. Tugas berkongsi HatEval dicipta dengan ini dalam fikiran; peserta dijangka untuk mengembangkan model yang mampu menentukan sama ada input (dalam kes ini, set data Twitter dalam bahasa Inggeris dan Sepanyol) boleh dianggap pidato kebencian (ditentukan sebagai Tugas A), jika mereka agresif, dan sama ada tweet adalah sasaran individu, atau bercakap secara umum (Tugas B). Kami mendekati tugas ini dengan mencipta model LSTM dengan lapisan penyembedding. Kami mendapati bahawa model kami dilakukan jauh lebih baik pada input bahasa Inggeris apabila dibandingkan dengan input bahasa Sepanyol. Dalam bahasa Inggeris, kita mencapai nilai F1 0.466 untuk Tugas A dan 0.462 untuk Tugas B; Dalam bahasa Sepanyol, kami mencapai skor 0.617 dan 0.612 pada Tugas A dan Tugas B, berdasarkan itu.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Is-sejba tad-diskors tal-mibegħda, speċjalment fil-pjattaformi u l-forums onlajn, qed issir malajr suġġett sħun hekk kif il-leġiżlazzjoni kontra d-diskors tal-mibegħda tibda tiġi applikata għad-diskors pubbliku onlajn. The HatEval shared task was created with this in mind; il-parteċipanti kienu mistennija jiżviluppaw mudell li jkun kapaċi jiddetermina jekk l-input (f’dan il-każ, settijiet ta’ dejta Twitter bl-Ingliż u bl-Ispanjol) jistax jitqies bħala diskors ta’ mibegħda (magħżul bħala Task A), jekk dawn kienu aggressivi, u jekk it-tweet kienx immirat lejn individwu, jew jitkellmu b’mod ġenerali (Task B). Aċċettajna dan il-kompitu billi nħolqu mudell LSTM b’saff ta’ inkorporazzjoni. Instabna li l-mudell tagħna sar konsiderevolment aħjar fuq l-input tal-lingwa Ingliża meta mqabbel mal-input tal-lingwa Spanjola. Bil-Ingliż, inkisbu Punteġġ F1 ta’ 0.466 għal Kompitu A u 0.462 għal Kompitu B; Bl-Ispanjol, kisbu punteġġi ta’ 0.617 u 0.612 fuq il-Kompitu A u l-Kompitu B, rispettivament.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Het opsporen van haatspraak, met name in online platforms en fora, wordt snel een hot topic aangezien anti-haatspraak wetgeving begint te worden toegepast op het publieke discours online. De HatEval gedeelde taak is met dit in gedachten gecreëerd; Van de deelnemers werd verwacht dat zij een model zouden ontwikkelen dat kan bepalen of invoer (in dit geval Twitter-datasets in het Engels en Spaans) als haatspraak (aangeduid als Taak A) kon worden beschouwd, of ze agressief waren en of de tweet gericht was op een individu, of in het algemeen sprak (Taak B). We benaderden deze taak door een LSTM model te maken met een embedding laag. We vonden dat ons model aanzienlijk beter presteerde op invoer in de Engelse taal in vergelijking met invoer in de Spaanse taal. In het Engels behaalden we een F1-Score van 0.466 voor Taak A en 0.462 voor Taak B; In het Spaans behaalden we scores van 0.617 en 0.612 op respectievelijk Taak A en Taak B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Oppdaging av hatespråk, spesielt i nettplattformar og forummer, er raskt å bli eit vart tema, sidan anti-hatespråk-lovgivnaden begynner å bli brukt på offentlige diskursar på nettet. HatEval delt oppgåve vart oppretta med dette i sinn. Forventa deltakarar å utvikle eit modell som kan bestemme om inndata (i dette tilfellet kan Twitter- datasett i engelsk og spansk) bli kalla som hatspråk (designert som oppgåve A), dersom dei var aggressiv, og om tweetet målet på ein individuell eller snakket vanlegvis (oppgåve B). Vi har nærmet denne oppgåva ved å laga eit LSTM-modell med eit innebygd lag. Vi fann at modellen vårt utførte mykje bedre på inndata av engelsk språk når det sammenlignet med inndata frå spansk språk. I engelsk oppnådd vi eit F1-poeng med 0,466 for oppgåve A og 0,462 for oppgåve B; I spansk oppnådd vi poeng 0,617 og 0,612 om oppgåve A og oppgåve B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Wykrywanie mowy nienawiści, zwłaszcza na platformach internetowych i forach, szybko staje się gorącym tematem, ponieważ ustawodawstwo dotyczące mowy nienawiści zaczyna być stosowane w dyskursie publicznym online. Wspólne zadanie HatEval zostało stworzone z myślą o tym; Oczekiwano, że uczestnicy opracowali model zdolny do określenia, czy wejście (w tym przypadku zbiory danych Twittera w języku angielskim i hiszpańskim) można uznać za mowę nienawiści (określoną jako zadanie A), czy były agresywne i czy tweet był skierowany do osoby, czy mówiąc ogólnie (zadanie B). Podejśliśmy do tego zadania tworząc model LSTM z warstwą osadzania. Stwierdziliśmy, że nasz model działał znacznie lepiej na wprowadzeniu języka angielskiego w porównaniu z wprowadzeniem języka hiszpańskiego. W języku angielskim osiągnęliśmy wynik F1 0.466 dla zadania A i 0.462 dla zadania B; W języku hiszpańskim osiągnęliśmy wyniki 0.617 i 0.612 odpowiednio w zadaniu A i zadaniu B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A detecção de discurso de ódio, especialmente em plataformas e fóruns on-line, está rapidamente se tornando um tema quente à medida que a legislação anti-discurso de ódio começa a ser aplicada ao discurso público on-line. A tarefa compartilhada HatEval foi criada com isso em mente; Esperava-se que os participantes desenvolvessem um modelo capaz de determinar se a entrada (neste caso, conjuntos de dados do Twitter em inglês e espanhol) poderia ou não ser considerada discurso de ódio (designado como Tarefa A), se fosse agressivo e se o tweet tinha como alvo um indivíduo, ou falando em geral (Tarefa B). Abordamos essa tarefa criando um modelo LSTM com uma camada de incorporação. Descobrimos que nosso modelo teve um desempenho consideravelmente melhor na entrada em inglês quando comparado à entrada em espanhol. Em inglês, obtivemos um F1-Score de 0,466 para a Tarefa A e 0,462 para a Tarefa B; Em espanhol, obtivemos pontuações de 0,617 e 0,612 na Tarefa A e na Tarefa B, respectivamente.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Detectarea discursului la ură, în special în platformele și forumurile online, devine rapid un subiect fierbinte, deoarece legislația anti-ură începe să fie aplicată discursului public online. Sarcina comună HatEval a fost creată având în vedere acest lucru; Se aștepta ca participanții să dezvolte un model capabil să determine dacă introducerea (în acest caz, seturile de date Twitter în limbile engleză și spaniolă) ar putea fi considerate discursuri la ură (desemnate ca sarcina A), dacă acestea erau agresive și dacă tweetul viza o persoană sau vorbea în general (sarcina B). Am abordat această sarcină prin crearea unui model LSTM cu un strat de încorporare. Am constatat că modelul nostru a performat considerabil mai bine la introducerea limbii engleze în comparație cu introducerea limbii spaniole. În limba engleză, am obținut un scor F1 de 0,466 pentru Task A și 0,462 pentru Task B; În limba spaniolă, am obținut scoruri de 0,617 și 0,612 la Task A și, respectiv, Task B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Обнаружение ненавистнических высказываний, особенно на онлайн-платформах и форумах, быстро становится горячей темой, поскольку законодательство о борьбе с ненавистническими высказываниями начинает применяться к публичному дискурсу в Интернете. Общая задача HatEval была создана с учетом этого; участники должны были разработать модель, позволяющую определить, могут ли вводимые данные (в данном случае наборы данных Twitter на английском и испанском языках) рассматриваться в качестве высказываний, разжигающих ненависть (обозначенных как Задача A), если они являются агрессивными, и нацелен ли твит на отдельного человека, или говорящих в целом (Задача B). Мы подошли к этой задаче, создав модель LSTM со слоем встраивания. Мы обнаружили, что наша модель показала значительно лучшие результаты при вводе английского языка по сравнению с вводом испанского языка. На английском языке мы достигли показателя F1 - 0,466 для задачи A и 0,462 для задачи B; На испанском языке мы достигли показателей 0,617 и 0,612 для задачи A и задачи B, соответственно.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>විශේෂයෙන් ඉන්ලයින් ප්‍රවේශනය සහ ප්‍රවේශනයේ විශේෂ කතාවක් හොයාගන්න, ඉක්මනින් වේගයෙන් විශේෂ ප්‍රවේශයක් වෙනවා Hateval කොටස් එක්ක මේක මතකයෙන් නිර්මාණය කරලා තියෙනවා; අංශිකාරීන්ට ප්‍රමාණයක් හොයාගන්න බලාපොරොත්තු වුනා ප්‍රමාණයක් නිර්මාණය කරන්න පුළුවන් (මේ විදියට, Twitter දත්ත සේට් ඉංග්‍රීසි සහ ස්පැනිස් වලින්) විරෝ අපි මේ කාර්යය සම්බන්ධ කරනවා LSTM මොඩල් හදන්න. අපි හොයාගත්තා අපේ මොඩල් ඉංග්‍රීසි භාෂාව ඇතුලට ගොඩක් හොඳයි කියලා ස්පැනිස් භාෂාව ඇතුල ඉංග්‍රීසියෙන්, අපිට F1-Score of 0.466 for Job A and 0.462 for Job B; ස්පැනිස් වලින්, අපි 0.617 සහ 0.612 වැඩ A වලින් වැඩ B වලින් ප්‍රමාණයක් ලැබුනා.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Odkrivanje sovražnega govora, zlasti na spletnih platformah in forumih, hitro postaja vroča tema, saj se začne uporabljati zakonodaja proti sovražnemu govoru na spletu. Skupna naloga HatEval je bila ustvarjena s tem v mislih; Od udeležencev se je pričakovalo, da bodo razvili model, ki bo lahko določil, ali se vnos (v tem primeru nabor podatkov Twitterja v angleščini in španščini) lahko šteje za sovražni govor (imenovan kot naloga A), ali so agresivni in ali je tvit namenjen posamezniku ali govori na splošno (naloga B). K tej nalogi smo pristopili z ustvarjanjem modela LSTM s plastjo vdelave. Ugotovili smo, da je naš model znatno boljši pri vnosu angleškega jezika v primerjavi z vnosom španskega jezika. V angleščini smo dosegli rezultat F1 0,466 za nalogo A in 0,462 za nalogo B; V španščini smo pri nalogi A dosegli oceno 0,617 oziroma 0,612 oziroma nalogi B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dhaqso u noqonaya mada kulul, sababtoo ah sharciga aan nebcaan ka jeedo ayaa laga bilaabaa in lagu codsado hadalka bulshada internetka. Shaqada HatEval la qaybsaday waxaa lagu abuuray maankan; Kuwii ka qeybqaaday waxaa la rajaynayay inuu horumariyo model awoodo inuu ogaado input ama input (taas darteed, taariikhda Twitterka ee Ingiriis iyo Isbanish) waxaa looga xisaabin karaa hadal nacayb ah (taas oo loo qoray shaqo A), haddii ay xadgudub leeyihiin iyo in twitterigu uu ku hagaajiyey mid gaar ah ama uu ku hadli karo sida caadiga ah (Task B). Waxan u dhawaaqnay sameynta model LSTM oo leh darajada burka ah. We found that our model performed considerably better on English language input when compared to Spanish language input. Ingiriiska, waxaynu helnay qiimaha F1-scorta 0.466 ee shaqo A iyo 0.462 shaqo B; Isbanishka waxaan ku gaadhnay kooxo u eg 0.617 iyo 0.612 shaqo A iyo shaqo B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Zbulimi i fjalimit të urrejtjes, veçanërisht në platforma dhe forume online, po bëhet shpejt një temë e nxehtë ndërsa legjislacioni kundër fjalimit të urrejtjes fillon të aplikohet në diskursin publik online. Detyra e përbashkët e HatEval u krijua me këtë në mendje; pjesëmarrësit priteshin të zhvillonin një model të aftë për të përcaktuar nëse input (në këtë rast, të dhënat e Twitter në anglisht dhe spanjoll) mund të konsideroheshin fjalim urrejtjeje (të caktuar si Task A), në qoftë se a to ishin agresive dhe në qoftë se tweeti ishte drejtuar në një individ apo fliste përgjithësisht (Task B). Ne iu afruam kësaj detyre duke krijuar një model LSTM me një shtresë të përfshirë. Ne zbuluam se modeli ynë u bë më mirë në hyrjen e gjuhës angleze kur krahasohet me hyrjen e gjuhës spanjolle. Në anglisht, arritëm një F1-Score prej 0.466 për Task A dhe 0.462 për Task B; In Spanish, we achieved scores of 0.617 and 0.612 on Task A and Task B, respectively.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Otkrivanje govora mržnje, posebno na internetskim platformama i forumima, brzo postaje vruća tema jer se zakonodavstvo o govoru protiv mržnje počinje primjenjivati na javne diskursije na internetu. HatEval je podijeljen zadatak stvoren na umu s tim; Očekivalo se da će sudionici razviti model sposoban za određivanje da li ulaz (u ovom slučaju, Twitter podaci na engleskom i španjolskom jeziku) mogli biti smatrani govorem mržnje (izraženim kao Task A), ako su agresivni, i da li je tweet ciljao pojedincu ili govoreći općenito (Task B). Prišli smo ovom zadatku stvarajući LSTM model sa ugrađenim slojem. Pronašli smo da je naš model mnogo bolji u odnosu na engleski jezik u usporedbi sa španjolskim jezikom. Na engleskom jeziku, postigli smo F1-Score od 0,466 za zadatak A i 0,462 za zadatak B; Na španjolskom smo postigli rezultate 0,617 i 0,612 na zadatku A i zadatku B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Upptäckten av hatpropaganda, särskilt i onlineplattformar och forum, håller snabbt på att bli ett hett ämne eftersom anti-hatpropaganda lagstiftning börjar tillämpas på offentlig debatt på nätet. HatEval delade uppgift skapades med detta i åtanke; Deltagarna förväntades utveckla en modell som kunde avgöra om inmatning (i detta fall Twitter-dataset på engelska och spanska) kunde betraktas som hatpropaganda (benämnd som uppgift A), om de var aggressiva, och om tweeten riktade sig till en individ eller talade generellt (uppgift B). Vi närmade oss denna uppgift genom att skapa en LSTM-modell med ett inbäddningslager. Vi fann att vår modell presterade betydligt bättre på engelska språkinput jämfört med spanska språkinput. På engelska uppnådde vi en F1-poäng på 0,466 för uppgift A och 0,462 för uppgift B; På spanska uppnådde vi poäng på 0,617 respektive 0,612 på uppgift A respektive uppgift B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kugundua hotuba ya chuki, hasa kwenye majukwaa na majukwaa ya mtandaoni, kwa haraka inakuwa mada yenye moto kwani sheria ya kupinga hotuba ya chuki inaanza kutumika katika mazungumzo ya umma mtandaoni. Kazi ya HatEval ilitengenezwa kwa akili hii; Washiriki walitarajiwa kutengeneza muundo wa uwezo wa kuamua ikiwa na maandishi (kwa mukhtadha huu, seti za taarifa za Twita kwa Kiingereza na Kihispania) zinaweza kuchukuliwa kuwa hotuba ya chuki (inayotengenezwa kama Task A), kama walikuwa na kibaguzi, na kama twiti hiyo ililenga mtu binafsi au kuongea kwa ujumla (Kazi B). Tumekaribia kazi hii kwa kutengeneza Mfano wa LSTM wenye kiwango cha ndani. Tumegundua kuwa muundo wetu ulifanya vizuri zaidi kwenye input wa lugha ya Kiingereza ukilinganisha na input wa lugha ya Kihispania. Kwa Kiingereza, tulipata kiwango cha F1 cha 0.466 kwa ajili ya kazi A na 0.462 kwa ajili ya kazi B; Kwa lugha ya Kihispania, tulipata vipimo vya 0.617 na 0.612 kwenye kazi A na kazi B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>வெறுப்பு பேச்சை கண்டுபிடிப்பது, குறிப்பாக இணைய தளங்களில் மற்றும் தளங்களில், விரைவாக ஒரு சூடான தலைப்பாடு ஆகிவிடுகிறது, ஏனெனில் வெறுப HatEval பகிர்ந்த பணி இந்த மனதில் உருவாக்கப்பட்டது; பங்கீட்டாளர்கள் ஒரு மாதிரி உருவாக்க வேண்டும் என்று எதிர்பார்க்கப்பட்டுள்ளார்கள் (இந்த நிலையில், ஆங்கிலம் மற்றும் ஸ்பானிஷ் மொழியில் இருந்த Twitter தரவுத்தளங்கள்) வெறுப் நாங்கள் இந்த செயலை அணுகின்றோம் ஒரு உள்ளீட்டு அடுக்கு ஒரு LSTM மாதிரி உருவாக்கினோம். ஸ்பானிஷ் மொழி உள்ளீட்டை ஒப்பிடும்போது எங்கள் மாதிரி மொழி உள்ளீட்டில் மிகவும் நல்ல செயல்பட்டது என்பதை நா ஆங்கிலத்தில், நாங்கள் பணி A மற்றும் 0. 462 பணி B க்கு ஒரு F1- மதிப்பு அடைந்தோம். ஸ்பானிஷில், நாங்கள் வேலை A மற்றும் பணி B மீது 0.617 மற்றும் 0.612 மதிப்புகளை அடைந்தோம்.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Hat çykyşyň sözlerini tanamak, ýöne-da internet platformlarynda we forumlarda, ýüzüniň ýigrenýän sözleriniň kanunlarynyň üstine ýakynlanmasyna başlaýar. Hateval bu zady aklynda bölýän zady bilen döredildi. Sahypalar üçin girişi tanamak üçin bir nusga çykarmak üçin gözlenýärdi (şu ýagdaýda, Twitter veri setirleri iñlis we español dilinde) ýigrenýän çykyşy diýip kabul edilýärdi (görev A diýip kabul edilýärdi), eger olar agresif bolsadylar we tweet bir adama maksady bolmady ýa-da umumy(B görev). Biz bu zady içeri girişi bilen LSTM nusgasyny bejererek goll etdik. Biziň nusgymyz iňlisçe dil girişinde espaňol dil girişinde has gowy gazandygyny görerdik. Iňlisçe, biz 0.466 Taýka A we 0.462 Taýka B üçin bir F1-Score ýetip bardyk; Ispanýolça 0.617 we 0.612 hasaplaryny bar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ناپسندیدہ بات کی تلاش، مخصوصاً آنلاین پلٹورم اور فورمز میں، جلد ایک گرم موضوع ہو رہی ہے جس طرح ناپسندیدہ بات کا قوانین آنلاین کی صحبت پر قائم ہوتا ہے. اس کے ذریعہ سے ہٹوئل کا کام بنایا گیا ہے شرکت کرنے والوں کی انتظار کی گئی تھی کہ ایک موڈل ایجاد کریں جس کا اختیار رکھتا تھا کہ ان کے سوال کیا جائے یا نہ ہو (اس صورت میں توئیٹ ڈاٹسٹ انگلیسی اور اسپانیایی میں) نفرت کی بات سمجھ سکتی تھی (تابع A کے نام کا نام) اگر وہ نازل ہوتی تھی، اور اگر توئیٹ ایک شخص کی هدف رکھتا تھا ہم نے اس کام کے پاس ایک ایمبڈینگ لائر کے ساتھ LSTM موڈل پیدا کر دیا۔ ہم نے پایا کہ ہمارا مدل انگلیسی زبان انپیٹ پر بہتر عمل کیا جب اسپانیایی زبان انپیٹ کے مقابلہ میں۔ انگلیسی میں ہم نے Task A اور Task B کے لئے 0.466 کی F1-Score کو پہنچا دیا۔ اسپانیایی میں ہم نے 0.617 اور 0.612 کو Task A اور Task B کے ذریعہ پہنچایا۔</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>The detection of hate speech, especially in online platforms and forums, is quickly becoming a hot topic as anti-hate speech legislation begins to be applied to public discourse online. HatEval shu miya bilan birlashtirilgan vazifa yaratildi; Bu tilda ishlatilgan shaklni ishlatish mumkin. Bu tilda, ingliz va Ispanchada Twitterning maʼlumotlar soni aniqlash mumkin (Vazifa A deb aniqlangan) deb hisoblanadi. Biz bu vazifani eng qatlam bilan LSTM modelini yaratish bilan keldik. Bizning modelimiz Ispancha tili ichiga o'xshash tilda ingliz tili ichida juda yaxshi ishlayotgan edi. Ingliz tilida biz Vazifa B uchun 0.466 vazifasi 0.462 va 0.462 uchun F1-scori topdik; Ispanchada biz vazifa A va vazifa B bilan 0.617 va 0.612 darajalarini topdik.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Việc phát hiện ngôn ngữ căm ghét, đặc biệt trong các diễn đàn trực tuyến, đang nhanh chóng trở thành một chủ đề nóng bỏng vì dự luật chống ghét ngôn ngữ bắt đầu được áp dụng vào các buổi diễn thuyết trên mạng. Đội HatEvol đã tham gia nhiệm vụ được tạo ra với ý tưởng này; Người tham dự dự sẽ phát triển một mô hình có khả năng xác định xem nội dung của Twitter (trong trường hợp này, dữ liệu trên Twitter bằng tiếng Anh và tiếng Tây B an Nha) có thể được coi là biểu diễn căm ghét (được gọi là Nhiệm vụ A), nếu họ hung hăng, và rằng tweet đã nhắm vào một cá nhân, hay nói chung (Nhiệm vụ B). Chúng tôi đã tiếp cận nhiệm vụ này bằng cách tạo một mô hình LSD với một lớp nhúng. Chúng tôi thấy mẫu của chúng tôi diễn đạt tốt hơn rất nhiều trong việc nhập tiếng Anh so với nhập ngôn ngữ Tây Ban Nha. Nói tiếng Anh, chúng tôi đã đạt được một F1-Score of 0.46 for Task A và 0.46 for Task B; Ở Tây Ban Nha, chúng tôi đã đạt được điểm số 0.67 và 0.62 về Hợp đồng A và Task B.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>随仇立法,始用于在线公共语,仇言之检,特在在线台论坛中,速成一热门话题。 HatEval共享之务,虑及此而创之; 参与者期发一模,定输(于此,英语与西班牙语之Twitter数集)可以为仇言(指为任A),苟有攻击性,与推文为私言(任B)。 开创带嵌 LSTM 模以行之。 吾见西班牙语之输也,吾形于英语者多矣。 其在英语也,AF1分为0.466,B为0.462。 西班牙语之于事,A之于事B各得其0.6170.612之数。</span></div></div><dl><dt>Anthology ID:</dt><dd>S19-2089</dd><dt>Volume:</dt><dd><a href=/volumes/S19-2/>Proceedings of the 13th International Workshop on Semantic Evaluation</a></dd><dt>Month:</dt><dd>June</dd><dt>Year:</dt><dd>2019</dd><dt>Address:</dt><dd>Minneapolis, Minnesota, USA</dd><dt>Venue:</dt><dd><a href=/venues/semeval/>SemEval</a></dd><dt>SIG:</dt><dd><a href=/sigs/siglex/>SIGLEX</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>498–502</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/S19-2089>https://aclanthology.org/S19-2089</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/S19-2089 title="To the current version of the paper by DOI">10.18653/v1/S19-2089</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">manolescu-etal-2019-tueval</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Mihai Manolescu, Denise Löfflad, Adham Nasser Mohamed Saber, and Masoumeh Moradipour Tari. 2019. <a href=https://aclanthology.org/S19-2089>TuEval at SemEval-2019 Task 5 : LSTM Approach to Hate Speech Detection in English and SpanishTuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</a>. In <i>Proceedings of the 13th International Workshop on Semantic Evaluation</i>, pages 498–502, Minneapolis, Minnesota, USA. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/S19-2089>TuEval at SemEval-2019 Task 5 : LSTM Approach to Hate Speech Detection in English and SpanishTuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</a> (Manolescu et al., SemEval 2019)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/S19-2089.pdf>https://aclanthology.org/S19-2089.pdf</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/S19-2089.pdf title="Open PDF of 'TuEval at SemEval-2019 Task 5 : LSTM Approach to Hate Speech Detection in English and SpanishTuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=TuEval+at+SemEval-2019+Task+5+%3A+LSTM+Approach+to+Hate+Speech+Detection+in+English+and+SpanishTuEval+at+SemEval-2019+Task+5%3A+LSTM+Approach+to+Hate+Speech+Detection+in+English+and+Spanish" title="Search for 'TuEval at SemEval-2019 Task 5 : LSTM Approach to Hate Speech Detection in English and SpanishTuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'TuEval at SemEval-2019 Task 5 : LSTM Approach to Hate Speech Detection in English and SpanishTuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[TuEval at SemEval-2019 Task 5 : LSTM Approach to Hate Speech Detection in English and SpanishTuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish](https://aclanthology.org/S19-2089) (Manolescu et al., SemEval 2019)</p><ul class=mt-2><li><a href=https://aclanthology.org/S19-2089>TuEval at SemEval-2019 Task 5 : LSTM Approach to Hate Speech Detection in English and SpanishTuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</a> (Manolescu et al., SemEval 2019)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Mihai Manolescu, Denise Löfflad, Adham Nasser Mohamed Saber, and Masoumeh Moradipour Tari. 2019. <a href=https://aclanthology.org/S19-2089>TuEval at SemEval-2019 Task 5 : LSTM Approach to Hate Speech Detection in English and SpanishTuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</a>. In <i>Proceedings of the 13th International Workshop on Semantic Evaluation</i>, pages 498–502, Minneapolis, Minnesota, USA. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>