<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>DebateSum : A large-scale argument mining and summarization datasetDebateSum: A large-scale argument mining and summarization dataset - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="DebateSum : A large-scale argument mining and summarization datasetDebateSum: A large-scale argument mining and summarization dataset" name=citation_title><meta content="Allen Roush" name=citation_author><meta content="Arvind Balaji" name=citation_author><meta content="Proceedings of the 7th Workshop on Argument Mining" name=citation_conference_title><meta content="2020/12" name=citation_publication_date><meta content="https://aclanthology.org/2020.argmining-1.1.pdf" name=citation_pdf_url><meta content="1" name=citation_firstpage><meta content="7" name=citation_lastpage><meta property="og:title" content="DebateSum : A large-scale argument mining and summarization datasetDebateSum: A large-scale argument mining and summarization dataset"><meta property="og:image" content="https://aclanthology.org/thumb/2020.argmining-1.1.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2020.argmining-1.1"><meta property="og:description" content="Allen Roush, Arvind Balaji. Proceedings of the 7th Workshop on Argument Mining. 2020."><link rel=canonical href=https://aclanthology.org/2020.argmining-1.1></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum : A large-scale argument mining and summarization dataset<span class=acl-fixed-case>D</span>ebate<span class=acl-fixed-case>S</span>um: A large-scale argument mining and summarization dataset</a>
<a id=af_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: ' n groot- scale argument mining en opsomming dataset</a>
<a id=am_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>Sum: A large-scale argument mining and summary data set</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: مجموعة بيانات التعدين والتلخيص على نطاق واسع</a>
<a id=az_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: A large-scale argument mining and summarization data set</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: масивен набор от данни за извличане и обобщаване на аргументи</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>বিতর্ক: A large- scale argument mining and summarization data set</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: A large-scale argument mining and summarization dataset</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: Velika skala argumenta za rudarstvo i sažetak podataka</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: Un conjunt de dades d'extracció i resum d'arguments a gran escala</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSumm: Rozsáhlá datová sada těžby argumentů a shrnutí</a>
<a id=da_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: Et stort datasæt til argumentmining og opsummering</a>
<a id=de_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSumm: Ein umfangreicher Datensatz für Argument Mining und Zusammenfassung</a>
<a id=el_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>Ένα σύνολο δεδομένων εξόρυξης και σύνοψης επιχειρημάτων μεγάλης κλίμακας</a>
<a id=es_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: un conjunto de datos de resumen y minería de argumentos a gran escala</a>
<a id=et_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: ulatuslik argumentide kaevandamise ja kokkuvõtliku andmekogum</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: یک مجموعه داده‌های ذخیره‌سازی و جمع‌سازی اردوмент مقیاس بزرگ</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: Laajamittainen argumenttien louhinta- ja yhteenvetoaineisto</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum : un ensemble de données d'exploration et de synthèse d'arguments à grande échelle</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: Tacar sonraí mianadóireachta agus achoimrithe argóinte ar mhórscála</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>Sum: A size- scale argument minining and sumarization data set</a>
<a id=he_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: מסגרת מידע מינוי ומסגרת</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: एक बड़े पैमाने पर तर्क खनन और सारांश डेटासेट</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: Velika skala argumenta za rudarstvo i sažetak podataka</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: Egy nagyszabású argumentumbányászat és összefoglaló adatkészlet</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>Դեբատես</a>
<a id=id_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: Sebuah argumen skala besar penambangan dan dataset ringkasan</a>
<a id=is_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: un set di dati di estrazione e sintesi di argomenti su larga scala</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum:大規模な引数マイニングと要約データセット</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>Sum: A big-scale argument mineing and suming dataset</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>Жөндеу</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: 대규모 논점 발굴 및 정리 데이터 세트</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebataSum: A large-scale argument mining and summarization data set</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>Дебата</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>വ്യത്യാസSum: A large- scale argument mining and summarization data set</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: Маш том хэмжээний аргументын багасгаж, хуваалтын өгөгдлийн санг</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: A large-scale argument mining and summarization dataset</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>Somma tad-dibattitu: Sett ta’ dejta dwar it-tħaffir fil-minjieri u s-sommarju ta’ argumenti fuq skala kbira</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: Een grootschalige dataset voor argumentmining en samenvatting</a>
<a id=no_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: A large-scale argument mining and summarization dataset</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: Zestaw danych eksploracji argumentów na dużą skalę i podsumowania</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: Um conjunto de dados de mineração e sumarização de argumentos em larga escala</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: Un set de date de mining și rezumare a argumentelor la scară largă</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: Масштабный набор данных для интеллектуального анализа и обобщения аргументов</a>
<a id=si_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>@ label: textbox</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: obsežen nabor podatkov o rudarjenju argumentov in povzetku</a>
<a id=so_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>Sum: A large-scale argument mining and summarisation dataset</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: Një argument në shkallë të madhe mining dhe përmbledhje të dhënash</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: Velika skala argumenta za rudarstvo i sažetanje podataka</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: En datauppsättning för utvinning och sammanfattning av argument i stor skala</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>Summary: Mjadala mkubwa wa uchimbaji madini na taarifa za muhtasari</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>விவாதம்Sum: A large- scale argument mining and summarization data set</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>Sum: A large-scale argument mining and summarization dataset</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: ایک بزرگ- اسکیل ارومین مینی اور سراسر ڈاٹ سٹ</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>DebateSum: A large-scale argument mining and summarization dataset</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>Name=giải thích Comment=Game bàn Comment</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2020.argmining-1.1.pdf>论总结:大论掘、总结数据集</a></h2><p class=lead><a href=/people/a/allen-roush/>Allen Roush</a>,
<a href=/people/a/arvind-balaji/>Arvind Balaji</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Prior work in <a href=https://en.wikipedia.org/wiki/Argument_mining>Argument Mining</a> frequently alludes to its potential applications in automatic debating systems. Despite this focus, almost no <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> or <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> exist which apply <a href=https://en.wikipedia.org/wiki/Natural-language_processing>natural language processing techniques</a> to problems found within competitive formal debate. To remedy this, we present the DebateSum dataset. DebateSum consists of 187,386 unique pieces of evidence with corresponding <a href=https://en.wikipedia.org/wiki/Argument>argument</a> and extractive summaries. DebateSum was made using <a href=https://en.wikipedia.org/wiki/Data>data</a> compiled by competitors within the <a href=https://en.wikipedia.org/wiki/National_Speech_and_Debate_Association>National Speech and Debate Association</a> over a 7year period. We train several transformer summarization models to benchmark <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> performance on DebateSum. We also introduce a set of fasttext word-vectors trained on DebateSum called debate2vec. Finally, we present a <a href=https://en.wikipedia.org/wiki/Web_search_engine>search engine</a> for this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> which is utilized extensively by members of the <a href=https://en.wikipedia.org/wiki/National_Speech_and_Debate_Association>National Speech and Debate Association</a> today. The DebateSum search engine is available to the public here : http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vorige werk in Argument Mining afgelyk aan sy potensiele toepassings in outomatiese debating stelsels. Terwyl hierdie fokus is, bestaan amper geen datastel of modele wat natuurlike taal verwerking tekniks toewend aan probleme wat binne gemeenskap formele debat gevind is nie. Om dit te herstel, laat ons die DebateSum datastel voorsien. DebateSum bestaan van 187,386 unieke stukke getuienis met ooreenstemmende argument en ekstraktiewe opsommings. DebateSum is gemaak met gebruik van data gemaak deur mededingers binne die Nasionale Spraak en Debate Associasie oor 'n 7jaar periode. Ons tref verskeie transformeerder opsomming modele na benchmark opsomming effektuur op DebateSum. Ons introduiseer ook 'n stel van vinnige teks woord- vektore wat op DebateSum geonderwerp is, wat debate2vec genoem word. Eindelik, ons stel 'n soektog masjien voor hierdie datastel wat uitbreidig gebruik word deur lede van die Nasionale Spraak en Debate Associasie vandag. Die DebateSum soektog masjien is beskikbaar vir die publiek hier: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>አስቀድሞ የአርጉም ማነሻ ሥራ በጊዜው የቻይሎችን ፕሮግራሞች በራሱ ውይይት በተጨማሪው ሲስተካከል ያቆማል፡፡ ምንም እንኳን የዚህ ምሳሌ ቢሆንም፣ በአካባቢው የቋንቋ ፕሮጀክት ቴክኖክቶችን ለመጠቀም የሚችሉ ዳታተሮች ወይም ሞዴሎች ምንም አይገኙም፡፡ To remedy this, we present the DebateSum dataset. የውይይት ጉዳይ 187,386 የተለየ ማስረጃዎችን በተቃዋሚ አዋጅ እና ውጤት አዳራሽ ነው፡፡ የውይይት ጉዳይ ከ7 ዓመት ጀምሮ በብሔራዊ ንግግር እና ክርክር ማኅበረሰብ ውስጥ የተሰበሰቡ ድረቶች የተደረገ ነው፡፡ በጥያቄ ጉዳይ ላይ አቀማመጥ ማሳየትን እናስተምረዋለን፡፡ ጥያቄ 2vec የሚባለውን የጽሑፍ ቃላት-vector እናሳውቃለን፡፡ በመጨረሻውም የብሔራዊ ንግግር እና የጥያቄ ማኅበረሰብ አባላት በሚጠቀምበት ለዚህ ዳታተር ሳንተርሚሽን እናቀርባለን፡፡ Sum search engine is available to the public here: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>كثيرًا ما يلمح العمل السابق في Argument Mining إلى تطبيقاته المحتملة في أنظمة المناقشة التلقائية. على الرغم من هذا التركيز ، لا توجد مجموعات بيانات أو نماذج تقريبًا تطبق تقنيات معالجة اللغة الطبيعية على المشكلات الموجودة في النقاش الرسمي التنافسي. لتصحيح ذلك ، نقدم مجموعة بيانات DebateSum. يتكون DebateSum من 187386 قطعة فريدة من الأدلة مع الحجة المقابلة والملخصات المستخرجة. تم إجراء DebateSum باستخدام البيانات التي جمعها المنافسون داخل الرابطة الوطنية للخطاب والمناظرة على مدار 7 سنوات. نقوم بتدريب العديد من نماذج تلخيص المحولات لقياس أداء التلخيص في DebateSum. نقدم أيضًا مجموعة من متجهات الكلمات ذات النص السريع التي تم تدريبها على DebateSum تسمى المناقشة 2vec. أخيرًا ، نقدم محرك بحث لمجموعة البيانات هذه والذي يتم استخدامه على نطاق واسع من قبل أعضاء الجمعية الوطنية للخطاب والمناظرة اليوم. محرك بحث DebateSum متاح للجمهور هنا: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Argument Mining'də əvvəlki iş çox çox olaraq özünün müzakirə sistemlərində mümkün proqramlarına bənzəyir. Bu fərqli tərzdə, təbiətli dil işləmə tekniklərini müqayisədə formal müzakirədə bulunan problemlərə istifadə edən məlumatlar və modellər yoxdur. Bunu dəyişdirmək üçün DebateSum veri qurğunu göstəririk. DebateSum 187,386 müəyyən dəlil parçaları ilə müqayisədi argument və ekstraktif toplamlar barəsindədir. DebateSum 7 il müddətində Ulusal Sözlük və Debat İşkiləri ilə birləşdirilən məlumatlardan istifadə edildi. Biz DebateSum'da bir çox transformer toplama modellərini benchmark toplama performansına təhsil edirik. Biz də DebateSum adında təhsil edilmiş, təhsil edilmiş, təhsil edilmiş, təhsil edilmiş, təhsil edilən, təhsil edilən, təhsil edilən, təhsil edilən, təhsil edilən, təhsil edilən, təhsil etdik. Sonunda, bu gün Ulusal Sözlük və Debat Asociasyonunun üyesi tarafından çox istifadə edilən verilən qurğu üçün arama maşını göstəririk. DebateSum arama motoru burada insanlara faydalanır: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Предишната работа в Аргумент Мининг често говори за потенциалните му приложения в автоматичните системи за дебати. Въпреки този фокус, почти не съществуват набори от данни или модели, които да прилагат техники за обработка на естествения език към проблеми, открити в рамките на официалните състезателни дебати. За да поправим това, представяме набора от данни. ДебатеСум се състои от 187 386 уникални доказателства със съответните аргументи и извлекателни резюмета. ДебатеСум е направен с помощта на данни, събрани от конкуренти в рамките на Националната асоциация по реч и дебат за период от 7 години. Обучаваме няколко модела за обобщаване на трансформаторите, за да сравним ефективността на обобщаване на ДебатеСум. Представяме и набор от бързи текстови вектори, обучени на ДебатеСум, наречени Дебате2vec. На последно място, представяме търсачка за този набор от данни, която се използва широко от членовете на Националната асоциация по реч и дебат днес. Търсачката е достъпна за обществеността тук: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>আর্গামেন্ট মাইনিং-এর পূর্ববর্তী কাজ স্বয়ংক্রিয়ভাবে বিতর্কের সিস্টেমে তার সম্ভাব্য অ্যাপলিকেশনগুলোর প এই মনোযোগ সত্ত্বেও প্রায় কোনো ডাটাসেট বা মডেল নেই যা প্রাকৃতিক ভাষা প্রক্রিয়ার কৌশল প্রয়োগ করে প্রতিযোগিতায় আনুষ্ঠান এটা সুস্থ করার জন্য, আমরা বিতর্কের তথ্য সেট উপস্থাপন করি। বিতর্কের সামের মধ্যে ১৮৭,৩৮৬ অনন্য প্রমাণের অংশ রয়েছে যার সাথে সংশ্লিষ্ট যুক্তি এবং বিদেশী সংক্ষেপ। জাতীয় ভাষা এবং বিতর্ক সংস্থার মধ্যে প্রতিযোগীদের তথ্য সংগ্রহ করা হয়েছে বিতর্ক সাম ৭ বছর ধরে। আমরা বেশ কয়েকটি পরিবর্তনের সারসংক্ষিপ্ত মডেল প্রশিক্ষণ দিচ্ছি বিতর্কের সারসংক্ষিপ্ত কার্যক্রমের জন্য। আমরা বিতর্ক সামে প্রশিক্ষণ প্রদান করেছি যার নাম বিতর্ক ২ভেক। Finally, we present a search engine for this dataset which is utilized extensively by members of the National Speech and Debate Association today. এখানে জনগণের জন্য বিতর্ক:Sum search ইঞ্জিন পাওয়া যাচ্ছে: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>སྒྲུབ་རྟགས་ཀྱི་སྔོན་ལྗོངས་ཀྱི་ལག་ལེན་པ་སྤྱིར་ནུས་ཡོད་པའི་ཉེར་སྤྱོད གནད་དོན་འདི་ལྟ་བུའི་ནང་དུ་བློ་གཏོང་ན་ཡིག་སྣོད་དང་མིག་དཔྱད་ཀྱང་མ་ཡོད་པ་རྐྱེན་གྱིས་སྤྲོད་ཀྱི་སྐད་ཡིག་ལས་ འདི་ཡར་དུ་གཏོང་དགོས་ན། ང་ཚོས་DebateSum ཡིག་ཆ་སྒྲིག་ཆ་འཕྲིན་དེ་སྔོན་སྒྲིག་བྱེད་དགོས། DebateSum consists of 187,386 unique pieces of evidence with corresponding argument and extractive summaries. DebateSum རྒྱལ་ཁབ་སྐྱོར་དང་ཕྱོགས་སྐྱོང་ཆེན་དག་གི་སྤྱི་ཚོགས་ཁང་གི་མཉམ་སྤྱོད་མཁན་གྱི་གནས་སྡུད་ཞིག་བེད་སྤྱད་ We train several transformer summarization models to benchmark summarization performance on DebateSum. ང་ཚོས་DebateSum(debate2vec)ནང་གི་མགྱོག་རིང་གི་ཐབས་ལམ་ལུགས་པའི་ཚིག་རྒྱུད་ཀྱི་སྒྲིག་སྟངས་བཤད་པ་ཡིན། མཐའ་མར་འཁོར་སུ། ང་ཚོས་དེ་རིང་རྒྱལ་ཁབ་ཀྱི་སྐད་ཆ་བློ་གཏོང་དང་ཆ་བློ་གཏོང་ཆེན་ཁང་གི་ཆ་འཕྲིན་འདི་ལ་འཚོལ་ འདིར་མི་མང་གིས་DebateSum འཚོལ་བཤེར་སྣུམ་འཁོར་སྐྱོད་རུང་བྱེད་པ： http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Prije posla u rudarstvu Argumenta često se ukazuje na njegove potencijalne aplikacije u sistemima automatskih debata. Uprkos ovom fokusu, skoro nema podataka ni modela koji primjenjuju prirodne tehnike obrade jezika na probleme koje su pronađene u konkurentnim formalnim debatima. Da bi to riješili, predstavljamo sastanak podataka DebateSuma. DebateSum se sastoji od 187.386 jedinstvenih dokaza s odgovarajućim argumentima i ekstraktivnim sažetkama. DebateSum je napravljen korištenjem podataka kompileraniranih konkurentima u okviru udruženja nacionalnog govora i debata tokom sedmogodišnjeg razdoblja. Vježbamo nekoliko modela sažetanja transformera za rezimetiranje rezimetara na DebateSum. Također predstavljamo niz brzog teksta rečnih vektora obučenih na DebateSum koji se zove debate2vec. Na kraju, predstavljamo pretraživač za ovaj set podataka koji se danas široko koristi članovi Nacionalne udruženje govora i debata. Pretraživač DebateSum ovdje je dostupan javnosti: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La feina anterior a Argument Mining sovint allueix a les seves aplicacions potencials en sistemes de debat automàtic. Malgrat aquest enfocament, gairebé no existeixen conjunts de dades o models que apliquen tècniques naturals de processament de llenguatges a problemes trobat en un debat formal competitiu. Per a arreglar-ho, presentem el conjunt de dades DebateSum. DebateSum consists of 187,386 unique pieces of evidence with corresponding argument and extractive summaries. DebateSum va ser fet utilitzant dades compiladas pels competidors de la National Speech and Debate Association durant un període de 7 anys. Ensenyem varis models de resum de transformadors per comparar el rendiment de resum en DebateSum. També introduim un conjunt de vectors de paraules de text ràpid entrenats en DebateSum anomenat debate2vec. Finalment, presentem un motor de cerca per aquest conjunt de dades que és utilitzat ampliament pels membres de l'Associació Nacional de Discursos i Debats avui dia. El motor de recerca DebateSum està disponible al públic aquí: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Předchozí práce v Argument Mining často naráží na jeho potenciální aplikace v automatických debatních systémech. Navzdory tomuto zaměření neexistují téměř žádné datové sady nebo modely, které by aplikovaly techniky zpracování přirozeného jazyka na problémy nalezené v rámci konkurenční formální debaty. Abychom to napravili, představujeme datovou sadu DebateSum. DebateSum se skládá z 187,386 unikátních důkazů s odpovídajícím argumentem a extraktivními shrnutími. DebateSum byl proveden na základě údajů sestavených soutěžícími v rámci Národního sdružení projevů a debat během sedmiletého období. Trénujeme několik modelů shrnutí transformátorů pro srovnání výkonu shrnutí na DebateSumu. Představujeme také sadu fasttext slovních vektorů trénovaných na DebateSumu s názvem debate2vec. Na závěr představujeme vyhledávač pro tento datový soubor, který dnes široce využívají členové Národní asociace projevů a debat. Vyhledávač DebateSum je k dispozici veřejnosti zde: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tidligere arbejde i Argument Mining hentyder ofte til dens potentielle anvendelser i automatiske debatsystemer. På trods af dette fokus findes der næsten ingen datasæt eller modeller, der anvender naturlige sprogbehandlingsteknikker på problemer, der findes inden for konkurrencedygtig formel debat. For at afhjælpe dette præsenterer vi DebateSum datasættet. DebateSum består af 187.386 unikke bevismaterialer med tilsvarende argument og ekstraktive resuméer. DebateSum blev lavet ved hjælp af data indsamlet af konkurrenter inden for National Tale and Debate Association over en 7 års periode. Vi træner flere transformatoropsummeringsmodeller til at benchmark opsummeringsydelse på Debatesum. Vi introducerer også et sæt fasttext ord-vektorer trænet på DebateSum kaldet debate2vec. Endelig præsenterer vi en søgemaskine til dette datasæt, som bruges i vid udstrækning af medlemmer af National Tale and Debate Association i dag. DebateSum søgemaskinen er tilgængelig for offentligheden her: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Frühere Arbeiten in Argument Mining verweisen häufig auf seine möglichen Anwendungen in automatischen Debattiersystemen. Trotz dieser Fokussierung gibt es kaum Datensätze oder Modelle, die natürliche Sprachverarbeitungstechniken auf Probleme anwenden, die in der kompetitiven formalen Debatte gefunden werden. Um dies zu beheben, stellen wir Ihnen den Datensatz DebateSum vor. DebateSumm besteht aus 187.386 eindeutigen Beweisstücken mit entsprechenden Argumenten und extraktiven Zusammenfassungen. DebateSum wurde anhand von Daten erstellt, die von Wettbewerbern innerhalb der National Speech and Debate Association über einen Zeitraum von sieben Jahren gesammelt wurden. Wir trainieren mehrere Transformatorzusammenfassungsmodelle, um die Zusammenfassungsleistung auf DebateSum zu benchmarken. Wir stellen auch eine Reihe von Fasttext-Wort-Vektoren vor, die auf DebateSum trainiert wurden, genannt debate2vec. Abschließend stellen wir eine Suchmaschine für diesen Datensatz vor, die heute von Mitgliedern der National Speech and Debate Association ausgiebig genutzt wird. Die DebateSum Suchmaschine steht der Öffentlichkeit hier zur Verfügung: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Οι προηγούμενες εργασίες στην εξόρυξη επιχειρημάτων συχνά αναφέρονται στις πιθανές εφαρμογές της σε συστήματα αυτόματης συζήτησης. Παρά την εστίαση αυτή, σχεδόν δεν υπάρχουν σύνολα δεδομένων ή μοντέλα που να εφαρμόζουν τεχνικές επεξεργασίας φυσικής γλώσσας σε προβλήματα που εντοπίζονται στο πλαίσιο της ανταγωνιστικής επίσημης συζήτησης. Για να διορθωθεί αυτό, παρουσιάζουμε το σύνολο δεδομένων DebateSum. Το DebateSum αποτελείται από 187,386 μοναδικά αποδεικτικά στοιχεία με αντίστοιχα επιχειρήματα και αποσπαστικές περιλήψεις. Το DebateSumm έγινε χρησιμοποιώντας δεδομένα που συγκεντρώθηκαν από ανταγωνιστές στο πλαίσιο της Εθνικής Ένωσης Ομιλίας και Συζήτηση για 7ετή περίοδο. Εκπαιδεύουμε διάφορα μοντέλα σύνοψης μετασχηματιστών για να αξιολογήσουμε την απόδοση σύνοψης στο DebateSum. Παρουσιάζουμε επίσης ένα σύνολο λέξεων που εκπαιδεύονται στο DebiteSum που ονομάζεται debate2vec. Τέλος, παρουσιάζουμε μια μηχανή αναζήτησης για αυτό το σύνολο δεδομένων που χρησιμοποιείται εκτενώς από τα μέλη του Εθνικού Συλλόγου Ομιλίας και Συζήτηση σήμερα. Η μηχανή αναζήτησης είναι διαθέσιμη στο κοινό εδώ: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>El trabajo anterior en Argument Mining con frecuencia alude a sus posibles aplicaciones en los sistemas de debate automático. A pesar de este enfoque, casi no existen conjuntos de datos o modelos que apliquen técnicas de procesamiento del lenguaje natural a los problemas que se encuentran en el debate formal competitivo. Para remediar esto, presentamos el conjunto de datos DebateSum. DebateSum consta de 187 386 piezas de evidencia únicas con el argumento correspondiente y los resúmenes extractivos. DebateSum se realizó utilizando datos recopilados por competidores dentro de la Asociación Nacional de Discurso y Debate durante un período de 7 años. Entrenamos varios modelos de resumen de transformadores para comparar el rendimiento de resumen en DebateSum. También presentamos un conjunto de vectores de palabras de texto rápido entrenados en DebateSum llamado debate2vec. Finalmente, presentamos un motor de búsqueda para este conjunto de datos que actualmente utilizan ampliamente los miembros de la Asociación Nacional de Discurso y Debate. El motor de búsqueda DebateSum está disponible para el público aquí: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Varasem töö Argument Mining viitab sageli selle võimalikele rakendustele automaatsetes arutelusüsteemides. Vaatamata sellele keskendumisele ei ole olemas peaaegu ühtegi andmekogumit ega mudelit, mis rakendaksid looduskeele töötlemise meetodeid konkurentsivõimelise ametliku arutelu käigus leitud probleemidele. Selle parandamiseks esitame DebateSumi andmekogumi. DebateSum koosneb 187 386 unikaalsest tõendist koos vastavate argumentide ja väljavõtetega. DebateSum koostati Riikliku Kõne- ja Debate Assotsiatsiooni konkurentide poolt 7 aasta jooksul koostatud andmetega. Koolitame mitmeid trafode kokkuvõtlusmudeleid, et võrdleda kokkuvõtlusmudeleid DebateSumis. Lisaks tutvustame DebateSum'is koolitatud kiirete tekstivektorite komplekti, mida nimetatakse debate2vec. Lõpuks tutvustame selle andmekogumi otsingumootorit, mida täna laialdaselt kasutavad Riikliku Kõne- ja Debate Assotsiatsiooni liikmed. Otsingumootor DebateSum on avalikkusele kättesaadav siit: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>کارهای پیشینه در آرژومینگ ذخیره اغلب به کاربردهای پتانسیل خود در سیستم مذاکره‌های خودکار ارائه می‌کند. با وجود این تمرکز، تقریباً هیچ مجموعه داده یا مدل وجود ندارد که تکنیک پردازش زبان طبیعی را برای مشکلات در بحث رسمی رقابت یافته است. برای اصلاح این، مجموعه داده‌های DebateSum را پیشنهاد می‌کنیم. DebateSum consists of 187.386 unique pieces of evidence with corresponding argument and extractive summaries. DebateSum با استفاده از داده‌ها که توسط رقابتان در مجموعه‌ی سخنرانی ملی و مجادله در طول ۷ سال مجموعه شده‌اند ساخته شده است. ما چندتا مدل جمع کردن تغییر دهنده را آموزش می‌دهیم تا عملکرد جمع کردن ابزار در DebateSum. ما همچنین مجموعه‌ای از ویکتورهای کلمه‌های سریع متن را معرفی می‌کنیم که در DebateSum به نام debate2vec آموزش داده شده است. بالاخره، ما یک موتور جستجو برای این مجموعه داده را پیشنهاد می‌کنیم که امروز توسط اعضای انجمن صحبت و توطئه ملی استفاده می‌شود. موتور جستجو DebateSum برای عمومی در اینجا موجود است: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Aiempi Argument Miningin ty繹 viittaa usein sen mahdollisiin sovelluksiin automaattisissa keskusteluj瓣rjestelmiss瓣. T瓣st瓣 huolimatta l瓣hes ei ole olemassa aineistoja tai malleja, joissa luonnollisen kielen k瓣sittelytekniikoita sovellettaisiin kilpailullisessa virallisessa keskustelussa havaittuihin ongelmiin. T瓣m瓣n korjaamiseksi esittelemme DebateSum-aineiston. DebateSum koostuu 187 386 ainutlaatuisesta todistekappaleesta, joissa on vastaavat perustelut ja tiivistelm瓣t. DebateSum toteutettiin kansallisen puhe- ja keskusteluyhdistyksen kilpailijoiden ker瓣瓣mill瓣 tiedoilla 7 vuoden ajalta. Koulutamme useita muuntajien yhteenvedon malleja vertailemaan yhteenvedon suorituskyky瓣 DebateSumissa. Esittelemme my繹s joukon DebateSumissa koulutettuja pikatekstivektoreita nimelt瓣 debate2vec. Lopuksi esittelemme t瓣m瓣n aineiston hakukoneen, jota kansallisen puhe- ja keskusteluyhdistyksen j瓣senet hy繹dynt瓣v瓣t laajasti. DebateSum-hakukone on yleis繹n saatavilla t瓣瓣lt瓣: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Les travaux antérieurs dans Argument Mining font souvent allusion à ses applications potentielles dans les systèmes de débat automatique. Malgré cette focalisation, il n'existe pratiquement aucun ensemble de données ou modèle qui applique des techniques de traitement du langage naturel à des problèmes rencontrés dans le cadre d'un débat formel compétitif. Pour y remédier, nous présentons l'ensemble de données DebateSum. DebateSum se compose de 187 386 éléments de preuve uniques avec des arguments correspondants et des résumés extractifs. DebateSum a été créé à partir de données compilées par des concurrents au sein de la National Speech and Debate Association sur une période de 7 ans. Nous entraînons plusieurs modèles de synthèse de transformateurs pour évaluer les performances de synthèse sur DebateSum. Nous introduisons également un ensemble de vecteurs de mots rapides formés sur DebateSum appelés debate2vec. Enfin, nous présentons un moteur de recherche pour cet ensemble de données qui est largement utilisé par les membres de la National Speech and Debate Association aujourd'hui. Le moteur de recherche DebateSum est accessible au public ici : http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Is minic a luann réamhobair i Mianadóireacht Argóine a fheidhmchláir ionchasacha i gcórais dhíospóireachta uathoibríocha. In ainneoin an fhócas seo, níl mórán tacair sonraí nó samhlacha ann a chuireann teicnící próiseála teanga nádúrtha i bhfeidhm ar fhadhbanna a fhaightear i ndíospóireacht fhoirmiúil iomaíoch. Chun é seo a leigheas, cuirimid an tacar sonraí DebateSum i láthair. Is éard atá i nDíospóireachtSum ná 187,386 píosa uathúil fianaise le hargóintí comhfhreagracha agus achoimrí eastóscacha. Baineadh leas as sonraí a thiomsaigh iomaitheoirí laistigh den Chumann Náisiúnta Urlabhra agus Díospóireachta thar thréimhse 7 mbliana. Cuirimid oiliúint ar roinnt samhlacha achoimrithe claochladán chun feidhmíocht achoimre a thagarmharcáil ar DebateSum. Tugaimid isteach freisin sraith de veicteoirí focal-téacs tapa oilte ar DebateSum ar a dtugtar debate2vec. Ar deireadh, cuirimid inneall cuardaigh i láthair don tacar sonraí seo a úsáideann baill an Chumainn Náisiúnta Urlabhra agus Díospóireachta go forleathan inniu. Tá inneall cuardaigh DebateSum ar fáil don phobal anseo: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kayyar aiki na Argument Mining, yana da amfani da shiryoyin ayuka masu yiwuwa a cikin tsarin mutane farat ɗaya. Babu dai da wannan fokus, don haka ba za'a iya sãmu kowa tsaro ko misãlai da ke amfani da kunnukan zartar da harshen kwanan zuwa masu zartar da su a cikin jayayi mai tsawo. QNetworkAccessFileBackend DebateSum consists of 187,386 unique pieces of evidence with the same argument and External sums. Summary was made by data composed by competitors in the National Spelling and Debate association over a 7 year. Tuna kõre wasu masu motsi na tsarin samori zuwa bonkimar ƙararin da aka yi wa DebateSum. We also introduce a set of fasttext word-vectors trained on DebateSum called debate2vec. Gani, munã gabatar da wata mashin search wa wannan set of data which is used widely by member of the National Speaker and Debate Sockety a yau. Sum search Engine na da ake iya amfani da zuwa umauman nan: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>העבודה הקודמת במכרות התווכחות הזכירה לעתים קרובות לתוכניות הפוטנציאליות שלה במערכות דיון אוטומטיות. Despite this focus, almost no datasets or models exist which apply natural language processing techniques to problems found within competitive formal debate. כדי לתקן את זה, אנחנו מציגים את קבוצת נתונים DebateSum. סכום דיבוטה מורכב מ-187,386 חתיכות ראיות יוצאות דופן עם טיעון מתאים וסרטוסים חיצוניים. DebateSum נעשה באמצעות נתונים שנאספו על ידי מתחרים בתוך ארגון הדיבורים הלאומי במשך תקופה של 7 שנים. אנחנו מאמן מספר דוגמנים של סוריזציה משתנה כדי לנקוט ביצועים של סוריזציה על DebateSum. אנחנו גם מציגים קבוצה של ווקטורי מילים טקסט מהירים מאומנים על DebateSum שנקראים debate2vec. סוף סוף, אנו מציגים מנוע חיפוש עבור קבוצת נתונים זו שמשתמשת באופן רחב על ידי חברי האיגוד הלאומי של דיבורים ודיבויים היום. מנוע חיפוש DebateSum זמין לציבור כאן: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>तर्क खनन में पूर्व कार्य अक्सर स्वचालित वाद-विवाद प्रणालियों में अपने संभावित अनुप्रयोगों को इंगित करता है। इस फोकस के बावजूद, लगभग कोई डेटासेट या मॉडल मौजूद नहीं हैं जो प्रतिस्पर्धी औपचारिक बहस के भीतर पाई जाने वाली समस्याओं के लिए प्राकृतिक भाषा प्रसंस्करण तकनीकों को लागू करते हैं। इसका समाधान करने के लिए, हम DebateSum डेटासेट प्रस्तुत करते हैं। वाद-विवादसम में इसी तर्क और निष्कर्षण सारांश के साथ सबूत के 187,386 अद्वितीय टुकड़े शामिल हैं। वाद-विवाद 7 साल की अवधि में राष्ट्रीय भाषण और वाद-विवाद संघ के भीतर प्रतियोगियों द्वारा संकलित डेटा का उपयोग करके किया गया था। हम कई ट्रांसफॉर्मर summarization मॉडल को प्रशिक्षित करने के लिए बेंचमार्क debateSum पर summarization प्रदर्शन. हम भी fasttext शब्द-वैक्टर का एक सेट बहस पर प्रशिक्षित वेक्टर परिचयUm debate2vec बुलाया. अंत में, हम इस डेटासेट के लिए एक खोज इंजन प्रस्तुत करते हैं जो आज राष्ट्रीय भाषण और बहस संघ के सदस्यों द्वारा बड़े पैमाने पर उपयोग किया जाता है। DebateSum खोज इंजन यहाँ जनता के लिए उपलब्ध है: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Prije posla u rudarstvu Argumenta često povezuje potencijalne primjene u automatskim raspravnim sustavima. Uprkos ovom fokusu, skoro nema podataka ni modela koji primjenjuju prirodne tehnike obrade jezika na probleme koje su pronađene u konkurentnom formalnom raspravu. Da bi to riješili, predstavljamo sastanak podataka DebateSuma. DebateSum se sastoji od 187 386 jedinstvenih dokaza s odgovarajućim argumentima i ekstraktivnim sažetkama. DebateSum je napravljen korištenjem podataka koje su skupili konkurenti u okviru udruženja nacionalnog govora i debata tijekom sedmogodišnjeg razdoblja. Vježbamo nekoliko modela sažetanja transformera za rezimetiranje rezimetara na DebateSum. Također predstavljamo niz brzog teksta riječi-vektori obučenih na DebateSum koji se zove debate2vec. Na kraju, predstavljamo pretraživač za ovaj set podataka koji se danas široko koristi članovi Nacionalne udruženje govora i rasprave. Pretraživač DebateSum ovdje je dostupan javnosti: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Az Argument Mining korábbi munkái gyakran utalnak a potenciális alkalmazásaira az automatikus vitarendszerekben. Ennek ellenére szinte nem létezik olyan adatkészlet vagy modell, amely természetes nyelvfeldolgozási technikákat alkalmaz a versenyképes formális vita során felmerülő problémákra. Ennek orvoslása érdekében bemutatjuk a DebateSum adatkészletet. A DebateSum 187 386 egyedi bizonyítékot tartalmaz a megfelelő érveléssel és kivonatos összefoglalókkal. A DebateSum az Országos Beszéd- és Vitaszövetség versenyzői által összeállított adatok felhasználásával készült hétéves időszak alatt. Több transzformátor összefoglaló modellt képzünk a DebateSum összefoglaló teljesítményének összehasonlítására. Bemutatjuk továbbá a DebateSum nevű fasttext szóvektorokat, amelyeket debate2vec-nek neveznek. Végül bemutatunk egy keresőmotort erre az adatkészletre, amelyet ma az Országos Beszéd- és Vitaszövetség tagjai széles körben használnak. A DebateSum keresőmotor itt érhető el a nyilvánosság számára: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Առաջին աշխատանքը Արգենտիվ հանքագործության ոլորտում հաճախ նշանակում է իր պոտենցիալ ծրագրերը ավտոմատիկ քննարկումների համակարգերում: Չնայած այս կենտրոնացումին, գրեթե ոչ մի տվյալների կամ մոդելներ չկան, որոնք օգտագործում են բնական լեզվի վերամշակման տեխնոլոգիաները մրցակցության պաշտոնական քննարկումների ընթացքում գտնվո Այս ամենը լուծելու համար մենք ներկայացնում ենք Դեբատեսում տվյալների համակարգը: ԴեբատեսSum-ը կազմում է 187,386 յուրահատուկ ապացույցներ, որոնք ունեն համապատասխան փաստարկման և արտադրողական համառոտագրություններ: ԴեբատեսSum-ը կատարվել է օգտագործելով տվյալներ, որոնք հավաքվել են ազգային խոսքի և քննարկումների ասոցիայի մրցակիցների կողմից 7 տարվա ընթացքում: Մենք վարժեցնում ենք որոշ վերափոխողների համառոտագրման մոդելներ, որպեսզի համեմատենք քննարկման համառոտագրման արդյունքները Մենք նաև ներկայացնում ենք մի շարք արագ տեքստի բառերի վեկտորներ, որոնք ուսուցանվել են Դեբատեսում, որը կոչվում է Դեբատեսում 2վեկտ: Վերջապես, մենք ներկայացնում ենք այս տվյալների համակարգի որոնման շարժիչը, որը այսօր էքսպենսիվ օգտագործվում է ազգային խոսքի և քննարկումների կազմակերպության անդամների կողմից: ԴեբատեսSum որոնման շարժիչը հասանելի է հանրության համար այստեղ: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pekerjaan sebelumnya di Argument Mining sering menyebutkan aplikasi potensialnya dalam sistem debat otomatis. Meskipun fokus ini, hampir tidak ada set data atau model yang menerapkan teknik proses bahasa alam pada masalah yang ditemukan dalam debat formal kompetitif. Untuk memperbaiki ini, kita mempersembahkan dataset DebateSum. DebateSum terdiri dari 187.386 bukti unik dengan argumen yang cocok dan ringkasan ekstraktif. DebateSum dibuat menggunakan data yang dikompilasi oleh kompetitor di dalam National Speech and Debate Association selama 7 tahun. Kami melatih beberapa model pengringkasan transformator untuk benchmark prestasi pengringkasan di DebateSum. Kami juga memperkenalkan set vektor-kata teks cepat dilatih di DebateSum disebut debate2vec. Akhirnya, kami mempersembahkan mesin pencarian untuk set data ini yang digunakan secara ekstensif oleh anggota Asosiasi Nasional Speech and Debate hari ini. Mesin pencarian DebateSum tersedia untuk masyarakat di sini: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Il lavoro precedente in Argument Mining spesso allude alle sue potenziali applicazioni nei sistemi di dibattito automatico. Nonostante questa attenzione, non esistono quasi set di dati o modelli che applichino tecniche di elaborazione del linguaggio naturale ai problemi riscontrati nel dibattito formale competitivo. Per rimediare, presentiamo il dataset DebateSum. DebateSum consiste di 187.386 pezzi unici di prova con argomenti corrispondenti e riassunti estrattivi. DebateSum è stato realizzato utilizzando dati compilati dai concorrenti all'interno dell'Associazione Nazionale Discorso e Dibattito per un periodo di 7 anni. Formiamo diversi modelli di riepilogo dei trasformatori per confrontare le prestazioni di riepilogo su DebateSum. Presentiamo anche un insieme di vettori di parole fasttext formati su DebateSum chiamati debate2vec. Infine, presentiamo un motore di ricerca per questo set di dati che viene utilizzato ampiamente dai membri della National Speech and Debate Association oggi. Il motore di ricerca DebateSum è disponibile al pubblico qui: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Argument Miningの以前の仕事では、自動ディベートシステムへの潜在的な応用について頻繁に言及しています。この焦点にもかかわらず、競争的な正式な議論の中で見つかった問題に自然言語処理技術を適用するデータセットやモデルはほとんど存在しない。これを修正するために、DebateSumデータセットを提示します。DebateSumは、187,386個のユニークな証拠と、対応する議論と抽出サマリーで構成されています。DebateSumは、National Speech and Debate Association内の競合他社が7年間にわたってまとめたデータを使用して作成されました。DebateSumでは、いくつかの変圧器の要約モデルをトレーニングして、ベンチマークの要約パフォーマンスを実現しています。また、DebateSumで訓練された、debate 2 vecと呼ばれるファストテキストのワードベクターのセットも紹介します。最後に、このデータセットの検索エンジンを提示します。この検索エンジンは、今日のNational Speech and Debate Associationのメンバーによって幅広く利用されています。DebateSum検索エンジンはhttp://www.debate.cardsで一般公開されています。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>argument Ngawe tho nggawe persok iki, amèh ora ono dataset opo model sing bisa nguasai tékno sing apik perusahaan idiomatan kanggo nggawe perusahaan seneng pisan kang diputasane resmi sakjane kanggo ngilangno iki, kita sampeyan dataset Debate Sum Debate Sum wis mungkin karo 486 unik bukun dadi nggawe karo akeh argument karo resmi extract Debate Sum wis ngawe data kompleh barêng-barêng ngenggo akèh wong sing dibenakno Perancis Nalikar kanggo Debate We've been tracking a number of transformer sumification modeles to bench sumification success on Debate Sum. Awak dhéwé nglebokake pernik nganggo masa gambar-vector seng sedhaya Debate Sum akhar deb2vec. Soale, awak dhéwé ngewehi engin kanggo nggawe dataset iki iki dipunangé luwih panelusuran kanggo wong liyo nggo Resolusi Kasal karo Debate Gosoko Debates Sum sing dibutuhke nang publik iki: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>პირველი სამუშაო აპგუმენტის მინუსაციაში მხოლოდ მისი პოცენტალური პროგრამებში ავტომატური debatური სისტემებში იყენებს. ამ ფოკუნტის განმავლობაში, პირდაპირად არ არსებობს მონაცემები ან მოდელები, რომლებიც ნაირადი ენის პროცესირების ტექნოგიების გამოყენება კონკუნტებული ფ ჱა ეა დჲ ნაოპაგთმვ რჲა, ოპვეჟრაგთმვ ევბარჟსმ ეატარა ჟვრკა. DebateSum consists of 187,386 unique pieces of evidence with corresponding argument and extractive summaries. DebateSum იქნება 7 წლის პერიოდის ნაციონალური საუბრის და განსაზღვრების აციოციაციაციაციაციაციაციაციაციაციაციაციაში კომპიკენტირებით გამოყ ჩვენ განვიყავით რამდენიმე ტრანფორმეტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრის ჩვენ ასევე შევცვალოთ სწრაფად ტექსტის სიტყვების გვექტორის სტრიქცია, რომელიც DebateSum სახელი debate2vec. საბოლოოდ, ჩვენ ამ მონაცემების ძიება მონაცემების ძიება, რომელიც დღეს ნაციონალური საუბრის და განსაკუთრების აციოციაციაციაციაციაციაციაციაციაციაცი DebateSum ძებნა მოწყობილობა აქ ადამიანებისთვის ხელსახურება: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Аргумент балауындағы алдыңғы жұмыс автоматты дебаттау жүйелерінде мүмкін қолданбаларына көптеген. Бұл көздеген қарамастан, тәуелсіздік тәуелсіздік дискуссияларында табылған мәселелерге негізінде деректер қорлары не үлгілер жоқ. Бұны түзету үшін DebateSum деректер жиынын көрсетуіміз керек. DebateSum бағдарламасының 187 386 бірнеше бөлшектері бар. Сәйкес аргументті және шығыс тұжырымдары бар. DebateSum 7 жыл бөлігінде ұлттық сөйлеу және Debate ассоциациясындағы конкурсорлар компиляцияланған деректерді қолданады. Біз DebateSum дегенде бірнеше түрлендіруші тұжырымдамасының үлгілерін бақылау үлгілерін үйренеміз. Сонымен қатар, DebateSum деген debate2vec деп аталатын тез мәтін векторлар тізімін келтіреміз. Соңында, біз бұл деректер жиынын іздеу тетігін таңдаймыз. Бүгін Ұлттық сөйлеу мен жөндеу ассоциясының мүшелері қолданылады. DebateSum іздеу тетігі мұнда көпшілік үшін бар: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>이전에 변론 발굴 분야에서 자동 변론 시스템에서의 잠재적인 응용에 대해 자주 언급했다.그럼에도 불구하고 경쟁적 공식 변론에 자연 언어 처리 기술을 적용해 발견한 문제의 데이터 집합이나 모델은 거의 없다.이 문제를 해결하기 위해 DebateSum 데이터 세트를 제공합니다.DebateSum에는 187386개의 독특한 증거와 그에 상응하는 논거와 발췌문 요약이 포함되어 있다.토론은 미국 강연변론협회(National Speech and Discussion Association)의 경쟁사들이 7년 동안 수집한 데이터를 활용해 이뤄졌다.우리는 DebateSum에서 요약 성능을 테스트하기 위해 몇 개의 변압기 요약 모형을 훈련했다.DebateSum에서 훈련된fasttext 단어 벡터도 소개했는데, 이를 debate2vec라고 부른다.마지막으로 우리는 이 데이터 집합을 위해 검색 엔진을 제공했고 오늘 전국 강연과 변론 협회의 회원들이 이 검색 엔진을 광범위하게 사용했다.DebateSum 검색엔진은 다음 위치에서 일반인이 사용할 수 있습니다.http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ankstesnis darbas Argument Mining dažnai rodo, kad jis gali būti naudojamas automatinėse diskusijų sistemose. Nepaisant to, beveik nėra duomenų rinkinių ar modelių, kurie taikytų natūralių kalbų apdorojimo metodus konkurencinėse oficialiose diskusijose nustatytoms problemoms spręsti. Norėdami tai ištaisyti, pristatysime DebateSum duomenų rinkinį. DebateSum consists of 187,386 unique pieces of evidence with corresponding argument and extractive summaries. DebateSum was made using data compiled by competitors within the National Speech and Debate Association over a 7year period. Mes rengiame keletą transformatorių santraukų modelių, kad lygintume santraukų rezultatus DebateSum. Taip pat pristatome spartaus teksto žodžių vektorių rinkinį, apmokytą DebateSum, vadinamą debate2vec. Galiausiai pristatome paieškos variklį šiam duomenų rinkiniui, kurį šiandien plačiai naudoja Nacionalinės kalbos ir diskusijų asociacijos nariai. DebateSum paieškos variklis yra prieinamas visuomenei čia: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Претходната работа во Аргументно минирање честопати наведува на нејзините потенцијални апликации во автоматски дебатирачки системи. И покрај овој фокус, речиси нема датотеки или модели кои аплицираат природни техники за обработување јазик на проблемите откриени во конкурентната формална дебата. За да го поправиме ова, ја претставуваме датотеката DebateSum. DebateSum се состои од 187.386 уникатни докази со соодветни аргументи и екстрактивни резултати. ДебататSum беше направен со користење на податоците собрани од конкурентите во рамките на Националната здруженост за говор и дебат во текот на седумгодишен период. Тренираме неколку модели за резултат на трансформаторите за да ги споредиме резултатите на резултатот на резултатот на DebateSum. We also introduce a set of fasttext word-vectors trained on DebateSum called debate2vec. Конечно, претставуваме пребарувачки мотор за овој податок кој е искористен екстремно од членовите на Националната Здружба за говор и дебат денес. Побарачкиот мотор DebateSum е достапен за јавноста тука: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ആര്‍ഗമെന്റ് മൈനിംഗില്‍ മുമ്പ് ജോലി എപ്പോഴും അതിന്റെ സാധ്യതകളുടെ പ്രയോഗങ്ങള്‍ക്ക് ഉപയോഗിക്കുന്നു ഈ ഫോക്സോക്സ് ചെയ്യുന്നതിന് ശേഷം, സ്വാഭാവികമായ ഭാഷ പ്രവര്‍ത്തിപ്പിക്കുന്ന സാങ്കേതികങ്ങള്‍ പ്രയോഗിക്കുന്നില്ല, ഇത് ശരിയാക്കാന്‍ വേണ്ടി, നമ്മള്‍ ഡെവറ്റ് ഡാറ്റാസെറ്റിനെ കാണിക്കുന്നു. വ്യത്യാസസംഖ്യ 187,386 പ്രത്യേക തെളിവുകളുടെ കൂട്ടത്തില്‍ ഉള്ളതാണ് വ്യക്തമായ തെളിവുകള്‍, വ്യത്യസ്തമായ വിവരങ്ങള്‍ ഉ നാഷണല്‍ സംസാരിക്കുന്നതിനും വിവരങ്ങള്‍ സംഘടിപ്പിക്കുന്നതിനുള്ള വിവരങ്ങള്‍ കൂട്ടിചേര്‍ക്കുന്നതിനുള്ള വിവരങ് നമ്മള്‍ കുറച്ച് മാറ്റങ്ങളുടെ സംസാരിക്കുന്ന മോഡലുകളെ പരിശീലിപ്പിക്കുന്നു We also introduce a set of fasttext word-vectors trained on DebateSum called debate2vec. അവസാനം, നമ്മള്‍ ഈ ഡാറ്റാസേറ്റിന്റെ തെരച്ചില്‍ എഞ്ചിന്‍ കാണിച്ചുകൊണ്ടിരിക്കുന്നു. ഇന്ന് നാഷണല്‍ സംസാരിക്കുന്നതും സൂമ് തെരച്ചില്‍ എഞ്ചിന്‍ ഇവിടെ ജനങ്ങള്‍ക്ക് ലഭ്യമാണ്: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Аргумент салбарын өмнөх ажил нь автоматжуулах системд автоматжуулах боломжийг ашигладаг. Энэ төвлөрөмжтэй ч, байгалийн хэл үйлдвэрлэлийн технологийг өрсөлдөөний официальны өрсөлдөөнд олсон асуудлуудад бараг ямар ч өгөгдлийн санг эсвэл загварууд байхгүй. Үүнийг сайжруулахын тулд бид DebateSum өгөгдлийн санг тайлбарлаж байна. DebateSum нь 187,386 онцгой баталгааны баримт, харьцангуй аргумент болон нэмэлт жишээлүүд байдаг. DebateSum нь 7 жилийн турш National Speech and Debate Association-ын өрсөлдөгчид зохион байгуулсан өгөгдлийг ашиглаж байв. Бид DebateSum дээр хэдэн шилжүүлэгчийн жинхэнэ загваруудыг банкмаркингийн жинхэнэ үйл ажиллагаанд сургаж байна. Мөн бид DebateSum дээр сургалтын хурдан хэмжээний үг векторуудыг "debate2vec" гэж нэрлэдэг. Эцэст нь бид өнөөдөр үндэсний яриа, Debate Association-ын гишүүн дээр маш их ашиглаж байгаа өгөгдлийн сангийн хайлтын машин бий болгож байна. DebateSum хайлтын машин энд олон нийтэд ашиглагддаг: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kerja terdahulu dalam Penyembang Argumen sering menyebutkan aplikasi potensi dalam sistem debat automatik. Walaupun fokus ini, hampir tiada set data atau model yang wujud yang melaksanakan teknik pemprosesan bahasa semulajadi kepada masalah yang ditemui dalam perdebatan rasmi kompetitif. Untuk memperbaiki ini, kami memperkenalkan set data DebateSum. DebateSum terdiri dari 187,386 bukti unik dengan argumen yang sepadan dan ringkasan ekstraktif. DebateSum dibuat menggunakan data dikumpil oleh kompetitor dalam Persatuan Perbualan dan Debat Nasional selama 7 tahun. Kami melatih beberapa model pengringkasan pengubah untuk benchmark prestasi pengringkasan pada DebateSum. Kami juga memperkenalkan set vektor perkataan teks pantas dilatih pada DebateSum yang dipanggil debate2vec. Akhirnya, kami memperkenalkan enjin gelintar untuk set data ini yang digunakan secara luas oleh ahli Persatuan Perkataan Nasional dan Debate hari ini. Enjin gelintar DebateSum tersedia untuk masyarakat di sini: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Xogħol preċedenti fil-Minjieri tal-Argumenti ta’ spiss isemmi l-applikazzjonijiet potenzjali tiegħu f’sistemi ta’ dibattitu awtomatiku. Minkejja dan il-fokus, kważi ma jeżistu l-ebda settijiet ta’ dejta jew mudelli li japplikaw tekniki ta’ pproċessar tal-lingwi naturali għal problemi li jinsabu fi ħdan dibattitu formali kompetittiv. Biex nirremedjaw dan, nippreżentaw is-sett tad-dejta DebateSum. Is-somma tad-dibattitu tikkonsisti f’187,386 biċċa evidenza unika b’argumenti korrispondenti u sommarji estrattivi. Is-somma tad-dibattitu saret bl-użu ta’ dejta miġbura mill-kompetituri fl-Assoċjazzjoni Nazzjonali tad-Diskussjoni u d-Diskussjoni fuq perjodu ta’ seba’ snin. Aħna nħarrġu bosta mudelli ta’ sommarju tat-trasformaturi biex nagħmlu referenza għall-prestazzjoni tas-sommarju dwar id-DebateSum. Aħna nintroduċu wkoll sett ta’ vetturi tal-kliem b’test mgħa ġġel imħarrġa fuq DebateSum imsejħa debate2vec. Fl-a ħħar nett, qed nippreżentaw magna ta' tiftix għal dan is-sett ta' dejta li llum hija utilizzata b'mod estensiv mill-membri tal-Assoċjazzjoni Nazzjonali tad-Diskussjoni u d-Diskussjoni. Il-magna tat-tiftix DebateSum hija disponibbli għall-pubbliku hawnhekk: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Eerder werk in Argument Mining verwijst vaak naar de mogelijke toepassingen ervan in automatische debat systemen. Ondanks deze focus bestaan er bijna geen datasets of modellen die natuurlijke taalverwerkingstechnieken toepassen op problemen die in competitief formeel debat worden aangetroffen. Om dit te verhelpen presenteren we de DebateSum dataset. DebateSum bestaat uit 187.386 unieke bewijsstukken met bijbehorende argumenten en extractieve samenvattingen. DebateSum is gemaakt met behulp van gegevens verzameld door concurrenten binnen de National Speech and Debate Association over een periode van zeven jaar. We trainen verschillende transformatorsamenvattingsmodellen om de samenvattingsprestaties op DebateSum te benchmarken. We introduceren ook een set fasttext woord-vectoren getraind op DebateSum genaamd debate2vec. Tot slot presenteren we een zoekmachine voor deze dataset die vandaag uitgebreid wordt gebruikt door leden van de National Speech and Debate Association. De DebateSum zoekmachine is beschikbaar voor het publiek hier: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Førre arbeid i argumentminering viser ofte dei potensielle programmene i dei automatiske debattsystema. Til tross på denne fokusen finst nesten ingen datasett eller modeller som brukar naturspråk-handsamingsteknikk til problemar som finst i konkurrentleg formelt debatt. For å retta dette, presenterer vi DebateSum-datasettet. DebateSum inneheld av 187,386 unike deler av beviser med tilsvarande argument og ekstraktiv samandrag. @ info Vi treng fleire sammendragsmodular for transformeringa til å lage sammendrag på DebateSum. Vi introduserer også eit sett med raskt tekst ord-vektorar trengt på DebateSum kalla debate2vec. I slutt presenterer vi eit søkjemotor for denne dataset som vert brukt utvida av medlemmer i den nasjonale tale og debattassosisjonen i dag. Søkjemotoren DebateSum er tilgjengeleg for offentlege her: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Wcześniejsze prace w Argument Mining często nawiązują do jego potencjalnych zastosowań w automatycznych systemach debaty. Pomimo tego skupienia prawie nie istnieją zbiory danych ani modele, które stosują techniki przetwarzania języka naturalnego do problemów znajdujących się w ramach konkurencyjnej debaty formalnej. Aby temu zaradzić, przedstawiamy zbiór danych DebateSum. DebateSum składa się z 187,386 unikalnych materiałów dowodowych z odpowiednim argumentem i ekstrakcyjnymi streszczeniami. DebateSum został dokonany z wykorzystaniem danych zebranych przez konkurentów w ramach Krajowego Stowarzyszenia Mowy i Debaty w ciągu 7letniego okresu. Szkolimy kilka modeli podsumowania transformatorów, aby porównać wydajność podsumowania na DebiteSum. Wprowadzamy również zestaw wektorów słów fasttext trenowanych na DebateSum zwanych debate2vec. Na koniec przedstawiamy wyszukiwarkę tego zbioru danych, która jest dziś szeroko wykorzystywana przez członków Narodowego Stowarzyszenia Mowy i Debaty. Wyszukiwarka DebateSum jest dostępna publicznie tutaj: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>O trabalho anterior em Argument Mining frequentemente alude às suas aplicações potenciais em sistemas de debate automático. Apesar desse foco, quase não existem conjuntos de dados ou modelos que apliquem técnicas de processamento de linguagem natural a problemas encontrados no debate formal competitivo. Para remediar isso, apresentamos o conjunto de dados DebateSum. O DebateSum consiste em 187.386 peças únicas de evidência com argumentos e resumos extrativos correspondentes. O DebateSum foi feito usando dados compilados por concorrentes da National Speech and Debate Association durante um período de 7 anos. Treinamos vários modelos de sumarização de transformadores para comparar o desempenho da sumarização no DebateSum. Também apresentamos um conjunto de vetores de palavras de texto rápido treinados no DebateSum chamado debate2vec. Finalmente, apresentamos um mecanismo de busca para este conjunto de dados que é amplamente utilizado pelos membros da National Speech and Debate Association hoje. O motor de busca DebateSum está disponível ao público aqui: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Lucrările anterioare în Argument Mining fac frecvent aluzie la potențialele sale aplicații în sistemele automate de dezbatere. În ciuda acestui accent, aproape nu există seturi de date sau modele care să aplice tehnici de prelucrare a limbajului natural problemelor găsite în cadrul dezbaterii formale competitive. Pentru a remedia acest lucru, vă prezentăm setul de date DebateSum. DebateSum constă din 187.386 elemente unice de probă cu argumente corespunzătoare și rezumate extractive. DebateSum a fost realizată folosind datele colectate de concurenții din cadrul Asociației Naționale de Discurs și Dezbateri pe o perioadă de 7 ani. Instruim mai multe modele de sintetizare a transformatoarelor pentru a compara performanțele de sintetizare pe DebateSum. De asemenea, introducem un set de vectori de cuvinte fasttext instruiți pe DebateSum numit debate2vec. În cele din urmă, prezentăm un motor de căutare pentru acest set de date, care este utilizat pe scară largă de membrii Asociației Naționale de Discurs și Dezbateri astăzi. Motorul de căutare DebateSum este disponibil pentru public aici: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Предыдущая работа в Argument Mining часто намекает на ее потенциальные применения в автоматических дискуссионных системах. Несмотря на эту направленность, практически не существует наборов данных или моделей, которые применяли бы методы обработки естественного языка к проблемам, обнаруженным в рамках формальных дебатов по вопросам конкуренции. Чтобы исправить это, мы представляем набор данных DebateSum. DebateSum состоит из 187 386 уникальных доказательств с соответствующими аргументами и резюме. DebateSum был сделан с использованием данных, собранных конкурентами в рамках Национальной ассоциации речи и дебатов за 7-летний период. Мы обучаем несколько моделей суммирования трансформаторов для сравнения эффективности суммирования на DebateSum. Мы также представляем набор векторов быстрых текстов, обученных на DebateSum под названием debate2vec. Наконец, мы представляем поисковую систему для этого набора данных, которая широко используется сегодня членами Национальной ассоциации речи и дебатов. Поисковая система DebateSum доступна для общественности здесь: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ප්‍රධානය මනින්ගේ ප්‍රධාන වැඩේ ස්වයංක්‍රීය විදිහට ස්වයංක්‍රීය විදිහට ප්‍රයෝජනය කරනවා. මේ අවධානය නමුත්, ස්වභාවික භාෂාව ප්‍රශ්නයක් ප්‍රශ්නයක් සම්බන්ධ විශ්නයක් තියෙන ප්‍රශ්නයක් සාම මේක හොයාගන්න, අපි දෙබට්සුම් දත්ත සෙට්ටුව පෙන්වන්න. ඩෙබට්සුම් එක්ක 187,386 විශේෂ සාක්ෂියක් තියෙන්නේ සම්බන්ධ සාක්ෂියක් සහ ප්‍රශ්නයක් සඳහා. @ info: tooltip අපි වෙනස් වෙනුවෙන් වෙනස් වෙනුවෙන් සංවේදනය විදිහට සංවේදනය විදිහට සංවේදනය කරනවා. අපි ඒවගේම වේගවේක්ටර් වචන වචන වෙක්ටර්ස් වලට දැනගන්න පුළුවන් විදියට debatSum කියලා දැනගන්න. අන්තිමේදී, අපි මේ දත්ත සෙට් වෙනුවෙන් හොයාගෙන ඉංජින් එකක් ප්‍රවේශ කරනවා අද රාජ්‍ය භාවිත සහ ඩිබේට් එක් @ info: tooltip http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Predhodno delo v Argument Mining pogosto namiguje na njegove potencialne aplikacije v avtomatskih sistemih razprave. Kljub temu poudarku skoraj ni nobenih zbirk podatkov ali modelov, ki bi uporabljali tehnike obdelave naravnega jezika pri težavah, ugotovljenih v okviru konkurenčne formalne razprave. Da bi to odpravili, predstavljamo nabor podatkov DebateSum. DebateSum je sestavljen iz 187.386 edinstvenih dokazov z ustreznimi argumenti in ekstraktivnimi povzetki. DebateSum je bil izveden na podlagi podatkov, ki so jih zbrali tekmovalci znotraj Nacionalnega združenja za govor in debato v obdobju 7 let. Usposabljamo več modelov povzetka transformatorjev za primerjavo zmogljivosti povzetka na DebateSumu. Predstavljamo tudi nabor hitrih besednih vektorjev, usposobljenih na DebateSum, imenovanih debate2vec. Na koncu predstavljamo iskalnik za ta nabor podatkov, ki ga danes obsežno uporabljajo člani Nacionalnega združenja za govor in debato. Iskalnik DebateSum je javnosti na voljo tukaj: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Shaqo horay ah ee ka shaqeynta sharciga Mining inta badan wuxuu ku qoran karaa codsigiisa suurtagalka ah nidaamka debaashka oo automatic ah. Inta kastoo ay fiirsantan noqoto, ma jirto mid dhowaad ah sawirada ama tusaalooyin ah oo u codsada qalabka baaritaanka afka dabiicadda ah si ay dhibaatooyin looga helo debaar rasmi ah. Si aan u bogsado waxan, waxaan keenaynaa sawirada macluumaadka qaramaanka. DebateSum waxaa ka mid ah 187,386 qeybood oo gaar ah oo ay ku jiraan cadaawayaasha islamarkaasna ay ku qoran yihiin xaajooyin islamarkaasna ay soo saaraan. Summada waxaa lagu sameyn jiray macluumaad ku saabsan ururka afka caalamiga ah iyo dooda muddo 7 sano ah. Waxaannu ku tababarinnaa tusaalooyin badan oo isbedelka ah si aan u benchmarkno bandhigyada dhamaanka ee DebateSum. Sidoo kale waxaynu soo bandhignaa koox safar ah oo lagu baray debate 2vec. Ugu dambaysta waxaan keenaynaa mashiinka raadinta ee sawiradan lagu isticmaalayo xubnaha ururka luqada iyo dooda ee maanta. Masruufka raadinta ee dooda Sum waxaad ka heli kartaa dadka halkan: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Prior work in Argument Mining frequently alludes to its potential applications in automatic debating systems. Megjithë këtë fokus, pothuajse nuk ekzistojnë grupe të dhënash apo modele që aplikojnë teknika natyrore të përdorimit të gjuhës ndaj problemeve të gjetura brenda debatit zyrtar konkurrues. To remedy this, we present the DebateSum dataset. DebateSum përbëhet nga 187,386 prova unike me argumente korrespondente dhe përmbledhje ekstraktive. DebateSum u bë duke përdorur të dhënat e mbledhura nga konkurentët brenda Shoqatës Kombëtare të Fjalëzimit dhe Debatit gjatë një periudhe shtatë vjeçare. Ne trajnojmë disa modele të përmbledhjes së transformuesve për të përcaktuar performancën e përmbledhjes në DebateSum. Ne prezantojmë gjithashtu një sërë vektorësh fjalësh me tekst të shpejtë të trajnuar në DebateSum të quajtur debate2vec. Më në fund, ne paraqesim një motor kërkimi për këtë set të dhënash që përdoret në mënyrë të gjerë nga anëtarët e Shoqatës Kombëtare të Fjalëzimit dhe Debatit sot. Motori i kërkimit DebateSum është në dispozicion për publikun këtu: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Prije posla u rudarstvu Argumenta često povezuje svoje potencijalne aplikacije u sistemima automatskih debata. Uprkos ovom fokusu, skoro nema podataka ni modela koji primjenjuju prirodne tehnike obrade jezika na probleme koje su pronađene u konkurentnom formalnom debatu. Da bismo ovo sredili, predstavljamo sastanak podataka DebateSuma. DebateSum se sastoji od 187.386 jedinstvenih dokaza sa odgovarajućim argumentima i ekstraktivnim sažetkama. DebateSum je napravljen korištenjem podataka koje su kompilovali konkurenti unutar Nacionalne asocijacije govora i debata tokom sedmogodišnjeg period a. Trenirali smo nekoliko modela sažetanja transformera za rezimetiranje rezimetara na DebateSum. Takoðe predstavljamo niz brzog teksta reèi-vektora obuèenih na DebateSumu koji se zove debate2vec. Na kraju, predstavljamo potragu za ovom setu podataka koja se danas široko koristi članovi Nacionalne udruženje govora i debata. Pretraživač DebateSum je dostupan javnosti ovdje: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tidigare arbete inom Argument Mining hänvisar ofta till dess potentiella tillämpningar i automatiska debattsystem. Trots detta fokus finns det nästan inga datauppsättningar eller modeller som tillämpar naturliga språkbehandlingstekniker på problem som finns inom konkurrensutsatt formell debatt. För att åtgärda detta presenterar vi datauppsättningen DebateSum. DebateSum består av 187 386 unika bevis med motsvarande argument och extraherande sammanfattningar. DebateSum gjordes med hjälp av data som sammanställts av konkurrenter inom Nationella tal- och debattförbundet under en sjuårsperiod. Vi tränar flera transformatorsammanfattningsmodeller för att jämföra sammanfattningsprocessen på DebateSum. Vi introducerar också en uppsättning snabbtext ordvektorer utbildade på DebateSum som kallas debate2vec. Slutligen presenterar vi en sökmotor för denna datamängd som används flitigt av medlemmar i Nationella tal- och debattförbundet idag. Sökmotorn DebateSum är tillgänglig för allmänheten här: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kazi ya awali katika mazingira ya Mining mara nyingi huwa inatumia matumizi yake ya uwezekano katika mifumo ya mijadala binafsi. Pamoja na lengo hili, takriban hakuna seti za data au mifano inayotumia mbinu za upasuaji wa lugha asili kwa matatizo yanayopatikana ndani ya mjadala rasmi wa ushindani. Ili kurekebisha hili, tunaweka taarifa za Mjadala. Mjadala unajumuisha vipande kipekee cha ushahidi 187,386 vya kutosha hoja na muhtasari wa kutosha. Mjadala ulifanywa kwa kutumia taarifa zilizokusanyika na washindi ndani ya Chama cha Taifa cha Hotuba na Mjadala kwa zaidi ya kipindi cha miaka 7. Tunafundisha mifano kadhaa ya muhtasari wa mabadiliko ya kiangazi ili kusambaza utendaji wa muhtasari wa mijadala ya Mjadala. Pia tunaonyesha kundi la mfululizo wa maneno yanayofundishwa kwenye Mjadala unaoitwa debate 2vec. Mwisho, tunaweka moto wa kutafuta kwa ajili ya seti hii inayotumiwa kwa kiasi kikubwa na wanachama wa Chama cha Taifa cha Hotuba na Mjadala leo. Mjadala wa utafutaji Sum unapatikana kwa umma hapa: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>தானியங்கி விவாதம் அமைப்புகளில் சாத்தியமான பயன்பாடுகளுக்கு முன் வேலை செய்யும். இந்த முன்னிறுத்தினாலும், கிட்டத்தட்ட தகவல் அமைப்புகள் அல்லது மாதிரிகள் இல்லை அது இயல்பான மொழி செயல்படுத்தும் தொழில்நுட் இதை சரிபார்க்க, நாம் விவாதத்தை காண்பிக்கிறோம். விவாதம் 187,386 தனிப்பட்ட துண்டுகள் இருக்கும் தெரியும் வார்த்தைகள் மற்றும் வெளியேறும் சுருக்கம். தேசிய பேச்சு மற்றும் விவாதிக்கு சமூகத்திற்குள் திரட்டியாளர்களால் தரவு சேகரிக்கப்பட்டுள்ளது ஒரு 7 ஆண்டுக்கு ம நாங்கள் பல மாற்றங்கள் சுருக்க மாதிரிகளை பயிற்சி செய்து விவாதத்தின் சுருக்கும் செயல்பாட்டை பென்ச்மார நாம் விவாதத்தில் பயிற்சி செய்யப்பட்ட ஒரு சில வார்த்தை - வெக்டர்களை அறிவிக்கிறோம். இறுதியில், நாம் இந்த தகவல் அமைப்புக்கான தேடுப் பொறியை கொண்டு வருகிறோம். அது நாட்டு பேச்சு மற்றும் வாதாட்டு சமூகத்தின The debate Sum search engine is available to the public here: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Argumentiň öňki işi Köçürmek üçin köplenç otomatik deblemek sistemlerinde öz potansiyeli uygulamalaryny aňsatýar. Bu fokusa rağmen, täze formal debatlarda bolan meselelere tebigy dil işlemek teknikleri ýagdaýa hiç hili maglumatlar ýok. Bunu onarmak üçin DebateSum veri setisini gösteriyoruz. DebateSum 187,386 täze bir kanıt bar we ýene-täk holasasy bilen mejbur. DebateSum Milli Speech we Debate Association'da 7 ýyl içinde rakipler tarapyndan birleştirilen maglumatlar ullanyldy. Biz DebateSum'da bir näçe täsirli terjime nusgalaryny benchmark taýýarlamak üçin öwredýäris. Ayrıca DebateSum üzerinde eğitilmiş, hızlı gelen kelime vektörleri, debate2vec olarak tanıştırıyoruz. Soňunda biz bu veri setirine gözlemek motoryny görkezýäris. Bu gün Milli Speech we Debat Association'yň üyeleri tarapyndan ullanýar DebateSum arama maşyny şu ýerde halkara ýerleşýär: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>آرمونٹ مینینگ میں پہلے کام اگلے سے اس کے امکانات کاروباروں کو اٹوٹ دیویٹ سیسٹم میں سمجھتا ہے۔ اس فوकस کے باوجود، تقریباً کوئی ڈاٹ سٹ یا نمڈل نہیں ہے جو طبیعی زبان پردازی ٹیکنیک کو مسائل میں پائی جاتی ہے جو مسائل میں پائی جاتی ہیں۔ اس کے لئے ہم DebateSum ڈیٹ سٹ کو پیش کرتے ہیں۔ DebateSum consists of 187,386 unique pieces of evidence with corresponding argument and extractive summaries. DebateSum کو 7 سال کے طول میں ملی سخنچی اور ڈیبٹ اتحادیہ کے اندر رقابت کرنے والوں کے ذریعے کامپیل کیا گیا ہے. ہم نے بہت سی تغییر دینے والی نمڈلوں کو ڈبٹ سوم پر بنچم مارک سپورٹ کرانے کے لئے آموزش دیتے ہیں. ہم نے DebateSum (DebateSum) پر آموزش کی ایک سریع لکھی ویکتروں کا مجموعہ پیش کیا ہے۔ آخر میں، ہم اس ڈیٹ سٹ کے لئے ایک تلاش انجینٹ پیش کرتے ہیں جو آج ملی سخنچی اور ڈیبٹ انجینٹ کے اعضا سے مزید استعمال کیا جاتا ہے. DebateSum تلاش انجین یہاں سب لوگوں کے لئے موجود ہے: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Argument davomida birinchi ishni ko'p doim avtomatik debating tizimlarida qo'llash mumkin. Bu fokus aytib boʻlsa, qachon doim maʼlumot setlari yoki modellar mavjud emas, bu asl tilni boshqarish tugmalarini qoʻllash uchun kompetitiv formal debatda topilmadi. Buni tizimga tayyorlash uchun debatSum maʼlumot setini koʻrsatimiz. Name Name Biz bir necha shifokorlar tahrirlash modellarini o'rganamiz Debate Sum'da qisqarish muvaffaqiyatlarini bajaramiz. Biz DebateSum (debate 2vec) deb nomlangan bir ko'plab tez-matn so'z-vektorlarini o'rganamiz. Endi biz Bu maʼlumot sahifasi uchun qidirish mashinani hosil qilamiz. Bugun bugun Taifa Speech va Debat Associations xususiyatlaridan foydalanadi. Sum search engine is available to the public here: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Việc làm trước ở Argument Mining thường nhấn mạnh về khả năng ứng dụng của nó trong các hệ thống thảo luận tự động. Mặc dù tiêu điểm này, hầu như không có bộ dữ liệu hay mô hình nào có thể áp dụng kỹ thuật xử lý ngôn ngữ tự nhiên vào những vấn đề được tìm thấy trong cuộc tranh luận sắc thường. Để sửa chữa điều này, chúng tôi giới thiệu bộ dữ liệu DebateSum. Cuộc tranh luận gồm những chứng cứ duy nhất 187,386 với các lời lẽ và bản tóm tắt khai thác tương ứng. Cuộc tranh luận được thực hiện dựa trên dữ liệu được biên tập bởi các đối thủ tại Hiệp hội Phát biểu quốc gia và Debate trong vòng bảy năm. Chúng tôi đào tạo một số mô- đun mô phỏng biến đổi để tiêu điểm kinh nghiệm tóm tắt trên DebateSum. Chúng tôi cũng giới thiệu một nhóm các nhà dịch ngữ nhanh được đào tạo trên DebiateSum được gọi là Debte2vec. Cuối cùng, chúng tôi giới thiệu một động cơ tìm kiếm cho bộ dữ liệu này được sử dụng rộng rãi bởi các thành viên của hiệp hội Phát biểu quốc gia và đàm phán hôm nay. Bộ tìm kiếm DebateSum được công bố ở đây: http://www.debate.cards</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>先于参数发掘,常讽其自辩系统之用。 虽有此注,殆无数集自然语言术用于竞争性文。 为此数集 DebateSum 。 DebateSum由187,386独证及所论摘要成。 DebateSum者,用国讲辩协会内竞争对手于7年编数为之。 练转换器摘要模样,以 DebateSum 准摘要。 引入 DebateSum 上训练之快文本词向量,谓之 debate2vec。 最后,建此数集之搜索引擎,今天下讲论协会博用此搜索引擎。 DebateSum搜索引擎可于此开公众:http://www.debate.cards</span></div></div><dl><dt>Anthology ID:</dt><dd>2020.argmining-1.1</dd><dt>Volume:</dt><dd><a href=/volumes/2020.argmining-1/>Proceedings of the 7th Workshop on Argument Mining</a></dd><dt>Month:</dt><dd>December</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/argmining/>ArgMining</a>
| <a href=/venues/coling/>COLING</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>1–7</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.argmining-1.1>https://aclanthology.org/2020.argmining-1.1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">roush-balaji-2020-debatesum</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Allen Roush and Arvind Balaji. 2020. <a href=https://aclanthology.org/2020.argmining-1.1>DebateSum : A large-scale argument mining and summarization datasetDebateSum: A large-scale argument mining and summarization dataset</a>. In <i>Proceedings of the 7th Workshop on Argument Mining</i>, pages 1–7, Online. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2020.argmining-1.1>DebateSum : A large-scale argument mining and summarization datasetDebateSum: A large-scale argument mining and summarization dataset</a> (Roush & Balaji, ArgMining 2020)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2020.argmining-1.1.pdf>https://aclanthology.org/2020.argmining-1.1.pdf</a></dd><dt>Code</dt><dd><a href=https://github.com/arvind-balaji/debate-cards><i class="fab fa-github"></i>&nbsp;arvind-balaji/debate-cards</a>
+
<a href="https://paperswithcode.com/paper/?acl=2020.argmining-1.1"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg>&nbsp;additional community code</a></dd><dt>Data</dt><dd><a href=https://paperswithcode.com/dataset/debatesum>DebateSum</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2020.argmining-1.1.pdf title="Open PDF of 'DebateSum : A large-scale argument mining and summarization datasetDebateSum: A large-scale argument mining and summarization dataset'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=DebateSum+%3A+A+large-scale+argument+mining+and+summarization+datasetDebateSum%3A+A+large-scale+argument+mining+and+summarization+dataset" title="Search for 'DebateSum : A large-scale argument mining and summarization datasetDebateSum: A large-scale argument mining and summarization dataset' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-secondary d-flex flex-wrap justify-content-center" href="https://paperswithcode.com/paper/?acl=2020.argmining-1.1" title="Code for 'DebateSum : A large-scale argument mining and summarization datasetDebateSum: A large-scale argument mining and summarization dataset' on Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-big" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg><span class="pl-sm-2 d-none d-sm-inline">Code</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'DebateSum : A large-scale argument mining and summarization datasetDebateSum: A large-scale argument mining and summarization dataset'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[DebateSum : A large-scale argument mining and summarization datasetDebateSum: A large-scale argument mining and summarization dataset](https://aclanthology.org/2020.argmining-1.1) (Roush & Balaji, ArgMining 2020)</p><ul class=mt-2><li><a href=https://aclanthology.org/2020.argmining-1.1>DebateSum : A large-scale argument mining and summarization datasetDebateSum: A large-scale argument mining and summarization dataset</a> (Roush & Balaji, ArgMining 2020)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Allen Roush and Arvind Balaji. 2020. <a href=https://aclanthology.org/2020.argmining-1.1>DebateSum : A large-scale argument mining and summarization datasetDebateSum: A large-scale argument mining and summarization dataset</a>. In <i>Proceedings of the 7th Workshop on Argument Mining</i>, pages 1–7, Online. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>