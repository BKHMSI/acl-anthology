<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Classification-based Quality Estimation : Small and Efficient Models for Real-world Applications - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Classification-based Quality Estimation : Small and Efficient Models for Real-world Applications" name=citation_title><meta content="Shuo Sun" name=citation_author><meta content="Ahmed El-Kishky" name=citation_author><meta content="Vishrav Chaudhary" name=citation_author><meta content="James Cross" name=citation_author><meta content="Lucia Specia" name=citation_author><meta content="Francisco Guzmán" name=citation_author><meta content="Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing" name=citation_conference_title><meta content="2021/11" name=citation_publication_date><meta content="https://aclanthology.org/2021.emnlp-main.474.pdf" name=citation_pdf_url><meta content="5865" name=citation_firstpage><meta content="5875" name=citation_lastpage><meta content="10.18653/v1/2021.emnlp-main.474" name=citation_doi><meta property="og:title" content="Classification-based Quality Estimation : Small and Efficient Models for Real-world Applications"><meta property="og:image" content="https://aclanthology.org/thumb/2021.emnlp-main.474.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2021.emnlp-main.474"><meta property="og:description" content="Shuo Sun, Ahmed El-Kishky, Vishrav Chaudhary, James Cross, Lucia Specia, Francisco Guzmán. Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 2021."><link rel=canonical href=https://aclanthology.org/2021.emnlp-main.474></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2021.emnlp-main.474.pdf>Classification-based Quality Estimation : Small and Efficient Models for Real-world Applications</a>
<a id=af_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Klassifikasie-gebaseerde Kwaliteit Estimatie: Klein en Effektiewe Modelle vir Werklike Wêreld Toepassinge</a>
<a id=am_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>ሁኔታ፦</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>تقدير الجودة القائم على التصنيف: نماذج صغيرة وفعالة لتطبيقات العالم الحقيقي</a>
<a id=az_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Klasifikat-tabanl캼 Q캼ymet Tahm톛si: Real-world Uygulamalar캼 칲칞칲n Ki칞ik v톛 Efficient Modell톛r</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Оценка на качеството въз основа на класификация: малки и ефективни модели за приложения в реалния свят</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>বাস্তব বিশ্বপূর্ণ অ্যাপ্লিকেশনের জন্য ছোট ও কার্যকর মোডেল</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Classification-based Quality Estimation: Small and Efficient Models for Real-world Applications</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Procjena kvalitete na temelju klasifikacije: mali i efikasni modeli za aplikacije realnog svijeta</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Estimat de qualitat basat en la classificació: Models petits i eficients per aplicacions del món real</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Klasifikační odhad kvality: malé a efektivní modely pro reálné aplikace</a>
<a id=da_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Klassificeringsbaseret kvalitetsvurdering: Små og effektive modeller for virkelige applikationer</a>
<a id=de_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Klassifikationsbasierte Qualitätsschätzung: Kleine und effiziente Modelle für reale Anwendungen</a>
<a id=el_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Αξιολόγηση ποιότητας βασισμένη στην ταξινόμηση: Μικρά και αποδοτικά μοντέλα για εφαρμογές πραγματικού κόσμου</a>
<a id=es_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Estimación de calidad basada en la clasificación: modelos pequeños y eficientes para aplicaciones del mundo real</a>
<a id=et_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Klassifikatsioonipõhine kvaliteedihinnang: väikesed ja tõhusad mudelid reaalmaailma rakenduste jaoks</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>ارزیابی کیفیت بر پایه کلاسیک: مدل کوچک و فعالیت برای کاربردهای دنیای واقعی</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Luokitukseen perustuva laatuarvio: pienet ja tehokkaat mallit reaalimaailman sovelluksiin</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Estimation de la qualité basée sur la classification : des modèles compacts et efficaces pour des applications réelles</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Meastachán Cáilíochta Bunaithe ar Aicmiú: Múnlaí Beaga agus Éifeachtúla d'Fheidhmchláir an Domhain Réadaigh</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>@ action: inmenu Go</a>
<a id=he_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>הערכת איכות מבוססת על כיסוי: דוגמנים קטנים ויעילים לתוכניות בעולם האמיתי</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>वर्गीकरण-आधारित गुणवत्ता अनुमान: वास्तविक दुनिया अनुप्रयोगों के लिए छोटे और कुशल मॉडल</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Očekivanje kvalitete na temelju klasifikacije: mali i učinkoviti modeli za aplikacije stvarnog svijeta</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Osztályozás alapú minőségbecslés: Kis és hatékony modellek a valós alkalmazásokhoz</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Կալիֆորմացիայի հիմնված որակի գնահատականը՝ փոքրիկ և արդյունավետ մոդելներ իրական աշխարհի ծրագրերի համար</a>
<a id=id_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Perkiraan Kualitas Berdasarkan Klasifikasi: Model Kecil dan Efisien untuk Aplikasi Dunia Real</a>
<a id=is_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Valutazione della qualità basata sulla classificazione: modelli piccoli ed efficienti per applicazioni reali</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>分類ベースの品質推定：現実のアプリケーションのための小さく効率的なモデル</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Ukuran</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>კლასიფიკაციის დაბათი კვალეტის განსაზღვრება: პატარა და ეფექტიური მოდელები რეალური მსოფლიო პროგრამებისთვის</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Классификациялау негіздеген сапа оқиғасы: Шындық әлемдегі қолданбалар үшін кішкентай және эффективні үлгілер</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>분류 기반의 품질 평가: 실제 응용에 사용되는 소형 고효율 모델</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Klasifikacija grindžiamas kokybės vertinimas: maži ir veiksmingi realiojo pasaulio programų pavyzdžiai</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Проценка на квалитетот базирана на класификација: Мали и ефикасни модели за реални апликации</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>ക്ലാസിസ്സിക്ഷന്‍ അടിസ്ഥാനമാക്കിയ ഗ്വാലിറ്റി എസ്റ്റിമേഷന്‍: റിയല്‍ ലോക പ്രയോഗങ്ങള്‍</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Классификацийн үндсэн чадварын төсөөлөл: Реаль дэлхийн програмын жижиг болон эффективны загварууд</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Penghargaan Kualiti Berasas Klasifikasi: Model Kecil dan Efisien untuk Aplikasi Dunia-Real</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Stima tal-Kwalità bbażata fuq il-Klassifikazzjoni: Mudelli Żgħar u Effiċjenti għall-Applikazzjonijiet fid-Dinja Reali</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Kwaliteitsschatting op basis van classificatie: Kleine en efficiënte modellen voor toepassingen in de echte wereld</a>
<a id=no_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Klassifikasjonsbasert kvalitetevaluering: Lite og effektive modeller for realske verdensprogram</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Ocena jakości oparta na klasyfikacji: małe i wydajne modele do zastosowań rzeczywistych</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Estimativa de qualidade baseada em classificação: modelos pequenos e eficientes para aplicações do mundo real</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Estimarea calității bazată pe clasificare: Modele mici și eficiente pentru aplicații din lumea reală</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Оценка качества на основе классификации: малые и эффективные модели для реальных приложений</a>
<a id=si_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>ක්ලාසිෆිකේෂන් අධිරූපය කුළුවත් අනුමාණය: පුංචි හා සක්‍රීය විද්‍යාපිත විද්‍යාපය විද්‍යා</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Ocena kakovosti na podlagi klasifikacije: majhni in učinkoviti modeli za aplikacije v realnem svetu</a>
<a id=so_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Xisaameynta takhasuska aasaasiga ah: Yar iyo Efficient Modeles for Applications Real-World</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Vlerësimi i cilësisë bazuar në klasifikim: Modele të vogla dhe efikase për aplikimet e botës reale</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Procjena kvalitete na osnovu klasifikacije: mali i efikasni modeli za aplikacije stvarnog svijeta</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Klassificeringsbaserad kvalitetsuppskattning: Små och effektiva modeller för verkliga tillämpningar</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Hisabu yenye sifa za darasa: Modeli ndogo na yenye ufanisi kwa ajili ya matumizi ya dunia halisi</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>வகைப்படுத்தல் அடிப்படையிலான தரம் கணக்கீடு: உண்மையான- உலக பயன்பாடுகளுக்கு சிறிய மற்றும் பயன்படுத்தல் மாதிரி</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>S캇n캇flandyrma G철rn철힊i Ta첵첵arlama: Ger챌ek d체n첵채 uygulamalar 체챌in ki챌i we 첵eterlik Modeller</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>کلاسیفٹ بنیاد کیلوٹی ارزش: حقیقی دنیا کے لئے چھوٹے اور عمدہ موڈل</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Comment</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>Hạng ước lượng: Cơ chế độ nhỏ và hiệu quả cho ứng dụng thế giới thực</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2021.emnlp-main.474.pdf>质量:宜用小形高效</a></h2><p class=lead><a href=/people/s/shuo-sun/>Shuo Sun</a>,
<a href=/people/a/ahmed-el-kishky/>Ahmed El-Kishky</a>,
<a href=/people/v/vishrav-chaudhary/>Vishrav Chaudhary</a>,
<a href=/people/j/james-cross/>James Cross</a>,
<a href=/people/l/lucia-specia/>Lucia Specia</a>,
<a href=/people/f/francisco-guzman/>Francisco Guzmán</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sentence-level Quality estimation (QE) of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> is traditionally formulated as a <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression task</a>, and the performance of QE models is typically measured by <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>Pearson correlation</a> with human labels. Recent QE models have achieved previously-unseen levels of correlation with human judgments, but they rely on large multilingual contextualized language models that are computationally expensive and make them infeasible for real-world applications. In this work, we evaluate several model compression techniques for QE and find that, despite their popularity in other NLP tasks, they lead to poor performance in this regression setting. We observe that a full model parameterization is required to achieve SoTA results in a <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression task</a>. However, we argue that the level of expressiveness of a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in a continuous range is unnecessary given the downstream applications of <a href=https://en.wikipedia.org/wiki/Quantum_electrodynamics>QE</a>, and show that reframing <a href=https://en.wikipedia.org/wiki/Quantum_electrodynamics>QE</a> as a classification problem and evaluating <a href=https://en.wikipedia.org/wiki/Quantum_electrodynamics>QE models</a> using classification metrics would better reflect their actual performance in real-world applications.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sentence-vlak Kwaliteit estimatie (QE) van masjien vertaling is tradisioneel formeer as 'n regresie taak, en die prestasie van QE-modelle is tipies gemeet deur Pearson korrelasie met menslike etikette. Onlangse QE-modelles het voorheen-ongesien vlakke van korrelasie met menslike oordelinge bereik, maar hulle vertrou op groot multitaalske contextualiseerde taal modelles wat rekenaasjoneel koste is en maak hulle onbeskikbaar vir reël-wêreld toepassings. In hierdie werk, ons evalueer veelvuldige model kompressie teknike vir QE en vind dat, alhoewel hulle populariteit in ander NLP-opdragte, hulle lei na arme prestasie in hierdie regresie opstelling. Ons observeer dat 'n volle model parameterisasie benodig is om Sota resultate te bereik in 'n regresie taak. Maar ons argumenteer dat die vlak van uitdrukking van 'n model in 'n voortdurende omvang onnoodsaaklik is gegee het die onderstreem toepassings van QE, en wys dat die opfrigging van QE as 'n klassifikasie probleem en die evaluering van QE modele gebruik klassifikasie metrike beter sal reflekteer hul werklike uitdrukking in regte wêreld toepassings.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>የሥርዓት ደረጃ ቁጥር (QE) የmachine ትርጓሜ በተለየ ወቅት አካባቢ ትርጉም ማድረግ ነው፣ የQE ዓይነቶች አካባቢ በተለየ በፌርሶን ከሰው ማኅበረሰብ ጋር ታካክል ነው፡፡ የቀድሞው የQE ምሳሌዎች ከሰው ፍርድ ጋር ግንኙነት ያልታወቀ ደረጃዎች አግኝተዋል፤ ነገር ግን በቋንቋ ቋንቋዎች ላይ በብዛት የከበረ እና ለእውነተኛ ዓለም ፕሮግራሞች የሚታሰቡ ብዙዎችን ምሳሌዎች ይታመካሉ፡፡ በዚህ ሥራ፣ የQE የሞዴል አካባቢ ስኮቶችን እናሳውቃለን፣ እናም ብዙዎቹ የNLP ስራቶች ምንም እንኳ ቢሆን በዚህ አካባቢ ስርዓት ውስጥ ድህነትን ለማድረግ ይሄዳሉ፡፡ ሶቲ አካሄዱን ለመግኘት የሙሉ ሞዴል ምርጫዎች እንዲያስፈልጋል እናየዋለን፡፡ ምንም እንኳን፣ የሞዴል መልዕክት በዘወትር ቁጥር የQE ፕሮግራሙን ያስፈልጋል፡፡ እናም የQE መግለጫ ጉዳይ እንዲሆን እና የQE ዓይነቶችን በመግለጫው ማተሚያዎች በመጠቀም በአካባቢው አካሄዳቸውን በአዳራዊ ዓለም ፕሮግራሞች ላይ ማረጋገጥ ይሻላል፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>تتم صياغة تقدير الجودة على مستوى الجملة (QE) للترجمة الآلية بشكل تقليدي كمهمة انحدار ، ويتم قياس أداء نماذج التيسير الكمي عادةً من خلال ارتباط بيرسون بالتسميات البشرية. حققت نماذج التيسير الكمي الحديثة مستويات غير مسبوقة من الارتباط مع الأحكام البشرية ، لكنها تعتمد على نماذج لغة سياقية متعددة اللغات باهظة الثمن من الناحية الحسابية وتجعلها غير قابلة للتطبيق في تطبيقات العالم الحقيقي. في هذا العمل ، قمنا بتقييم العديد من تقنيات الضغط النموذجية للتسهيل الكمي ووجدنا أنه على الرغم من شعبيتها في مهام البرمجة اللغوية العصبية الأخرى ، فإنها تؤدي إلى أداء ضعيف في إعداد الانحدار هذا. نلاحظ أن معلمات النموذج الكامل مطلوبة لتحقيق نتائج SoTA في مهمة الانحدار. ومع ذلك ، فإننا نجادل بأن مستوى التعبير عن نموذج في نطاق مستمر غير ضروري نظرًا للتطبيقات النهائية للتسهيل الكمي ، ونبين أن إعادة صياغة التيسير الكمي كمشكلة تصنيف وتقييم نماذج التيسير الكمي باستخدام مقاييس التصنيف سيعكس أداءها الفعلي بشكل أفضل في الواقع. تطبيقات العالم.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Makinatın çevirilməsinin sözlər-seviyyəti qiyməti (QE) sadəcə olaraq regressiya işləri olaraq formüllənir və QE modellərin performansı insan etiketləri ilə Pearson ilə ölçülür. QE modelləri əvvəlcə görmədiyimiz insan hökmləri ilə bağlantılıq seviyelərini başa düşdülər, amma onlar çox dilli müxtəlif dil modellərinə təvəkkül edirlər ki, hesaplayaraq çox qiymətli və həqiqət dünya uyğulamalarına görə onları çox çətinlikli dəlillərə bağlı edirlər. Bu işdə QE üçün bir neçə modeli sıkıştırma tekniklərini değerləşdiririk və digər NLP işlərində məşhurluqlarına baxmayaraq, onlar bu regresiya təyin etməsində zəif performansına yol açarlar. Biz görürük ki, SoTA sonuçlarını geri çəkmək məqsədilə tamamlamaq üçün tam modeli parametrizaq lazımdır. Ancaq biz müəyyən edirik ki, QE'nin düşük uygulamalarına görə model in in ifadəsi səviyyəsi həmişəlik olmaz və QE'ni klasifikasyon problemi olaraq reframiya etmək və QE modellərini klasifikasyon metriklərini istifadə etmək üçün QE modellərinin əsl performansını gerçek dünya proqramlarında daha yaxşı reframiya edər.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Оценката на качеството на машинния превод на ниво изречение традиционно се формулира като регресионна задача, а ефективността на моделите обикновено се измерва чрез корелация на Пиърсън с човешки етикети. Съвременните модели са постигнали невиждани нива на корелация с човешките преценки, но те разчитат на големи многоезични контекстуализирани езикови модели, които са изчислително скъпи и ги правят невъзможни за приложения в реалния свят. В тази работа ние оценяваме няколко техники за компресиране на модела и откриваме, че въпреки популярността им в други задачи, те водят до лоша производителност в тази регресионна настройка. Наблюдаваме, че е необходима пълна параметризация на модела, за да се постигнат резултати в регресионна задача. Въпреки това, ние твърдим, че нивото на изразителност на един модел в непрекъснат диапазон е ненужно предвид приложенията надолу по веригата на КЕ и показват, че преразглеждането на КЕ като проблем за класификация и оценяването на КЕ модели с помощта на класификационни метрици би отразило по-добре действителното им представяне в приложения от реалния свят.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>মেশিন অনুবাদের শাস্তি স্তরের মান নির্ধারণ (কিউই) ঐতিহ্যবাহীতিকভাবে শাস্তি নিয়ন্ত্রণের কাজ হিসেবে গঠন করা হয় এবং কিউই মডেলের প্রাপ্ত কার্যকলাপ সাম্প্রতিক কিউই মডেল মানুষের বিচারের সাথে মানুষের অদৃশ্য পর্যায়ের সম্পর্ক অর্জন করেছে, কিন্তু তারা বিশাল মাল্টিভাষার প্রতিযোগিতার ভাষার মডেলের উপর ন এই কাজে আমরা কিউই এর জন্য বেশ কয়েকটি মডেল প্রাপ্ত কৌশলের মূল্য দিচ্ছি এবং অন্যান্য এনএলপি কাজের জনপ্রিয় সত্ত্বেও তারা এই নিয়ন্ত্রণের ব্যবস্ আমরা দেখতে পাচ্ছি যে সোটিএ পুরোপুরি মডেলের প্যারামিটারেশনের ফলাফল পাওয়ার জন্য প্রয়োজন। তবে আমরা যুক্তি দিচ্ছি যে কিউ ইউ-এর নীচের প্রয়োজনীয় প্রয়োজনীয় প্রয়োজনীয় একটি মডেলের প্রকৃতির স্তর এবং কিউই-কে ক্লাসাফিকেশনের সমস্যা হিসেবে পুনরায় বিচ্ছিন্ন করা এবং কিউ-ই মডেল ব্যবহার কর</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sentence-level Quality estimation (QE) of machine translation is traditionally formulated as a regression task, and the performance of QE models is typically measured by Pearson correlation with human labels. It is common in modern times. འཕྲལ་མྱུར་བའི་QE མིག་དཔེ་གཞུང་གིས་མེད་པའི་སྔོན་མེད་པའི་མཐུན་རིམ In this work, we evaluate several model compression techniques for QE and find that, despite their popularity in other NLP tasks, they lead to poor performance in this regression setting. We observe that a full model parameterization is required to achieve SoTA results in a regression task. However, we argue that the level of expressiveness of a model in a continuous range is unnecessary given the downstream applications of QE, and show that reframing QE as a classification problem and evaluating QE models using classification metrics would better reflect their actual performance in real-world applications.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Očekivanje kvalitete kazne na razini (QE) prevoda mašine tradicionalno se formira kao zadatak regresije, a učinkovitost modela QE obično se mjera korelacija Pearsona sa ljudskim etiketama. Nedavni QE modeli su postigli previše nevidljive nivoe korelacije sa ljudskim osuđivanjima, ali se oslanjaju na velike multijezičke kontekstualizirane jezičke modele koje su računalno skupe i čine ih nepodnošljivim za realne aplikacije. U ovom poslu, procjenjujemo nekoliko modela tehnika kompresije za QE i otkrijemo da, uprkos njihovoj popularnosti u drugim zadacima NLP-a, oni vode do lošeg izvođenja u ovom regresiji. Primijetimo da je potrebna puna modelna parameterizacija za ostvarivanje SoTA rezultata u zadatku regresije. Međutim, tvrdimo da je nivo izrazitosti model a u kontinuiranom rasponu nepotrebno s obzirom na sledeće aplikacije QE-a, i pokazujemo da reframiranje QE kao problem klasifikacije i procjena modela QE-a koristeći klasifikacijske metrike bolje odražava njihovu stvarnu funkciju u aplikaciji realnog svijeta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>L'estimació de qualitat a nivell de sentits (QE) de la traducció màquina és tradicionalment formulada com una tasca de regressió, i el rendiment de models QE és normalment mesurat per la correlació de Pearson amb etiquetes humanes. Els models QE recents han aconseguit nivells de correlació previament invisibles amb els judicis humans, però confien en grans models de llenguatge contextualitzats multilingües que són costosos computacionalment i que els fan infeasibles per aplicacions del món real. En aquest treball, evaluem diverses tècniques de compressió de models per a QE i descobrim que, malgrat la seva popularitat en altres tasques de NLP, condueixen a un mal rendiment en aquest entorn de regressió. Observem que es requereix una paràmetrització completa del model per aconseguir els resultats de la SoTA en una tasca de regressió. Tot i així, argumentem que el nivell d'expressivitat d'un model en una gama continua és innecessari tenint en compte les aplicacions avall de QE, i demostram que reformar QE com un problem a de classificació i evaluar models QE utilitzant mètriques de classificació reflexionaria millor el seu rendiment real en aplicacions del món real.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Odhad kvality strojového překladu je tradičně formulován jako regresní úloha a výkon QE modelů je obvykle měřen Pearsonovou korelací s lidskými značkami. Nedávné QE modely dosáhly dosud neviděné úrovně korelace s lidskými úsudky, ale spoléhají na velké mnohojazyčné kontextualizované jazykové modely, které jsou výpočetně nákladné a činí je nemožnými pro reálné aplikace. V této práci hodnotíme několik modelových kompresních technik pro QE a zjišťujeme, že navzdory jejich popularitě v jiných NLP úlohách vedou k špatnému výkonu v tomto regresním nastavení. Pozorujeme, že k dosažení výsledků SOTA v regresním úkolu je nutná úplná parametrizace modelu. Nicméně argumentujeme, že úroveň expresivity modelu v kontinuálním rozsahu není zbytečná vzhledem k následným aplikacím QE, a ukazujeme, že reframování QE jako klasifikační problém a hodnocení QE modelů pomocí klasifikačních metrik by lépe odráželo jejich skutečnou výkonnost v reálných aplikacích.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kvalitetsestimering (QE) af maskinoversættelse er traditionelt formuleret som en regressionsopgave, og ydeevnen af QE modeller måles typisk ved Pearson korrelation med menneskelige etiketter. Seneste QE-modeller har opnået hidtil usete niveauer af korrelation med menneskelige vurderinger, men de er afhængige af store flersprogede kontekstualiserede sprogmodeller, der er beregningsmæssigt dyre og gør dem umulige for virkelige applikationer. I dette arbejde evaluerer vi flere modelkomprimeringsteknikker for QE og finder ud af, at de trods deres popularitet i andre NLP-opgaver fører til dårlig ydeevne i denne regressionsindstilling. Vi observerer, at en fuld model parametrisering er nødvendig for at opnå SotA resultater i en regressionsopgave. Vi hævder dog, at niveauet af udtryksevne af en model i et kontinuerligt interval er unødvendigt i betragtning af downstream applikationer af QE, og viser, at omdannelse af QE som et klassifikationsproblem og evaluering af QE modeller ved hjælp af klassifikationsmåler bedre ville afspejle deres faktiske ydeevne i virkeligheden applikationer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Die Qualitätsschätzung (QE) der maschinellen Übersetzung wird traditionell als Regressionsaufgabe formuliert, und die Leistung von QE-Modellen wird typischerweise durch Pearson-Korrelation mit Human Labels gemessen. Neuere QE-Modelle haben bisher unbekannte Korrelationen mit menschlichen Urteilen erreicht, aber sie stützen sich auf große mehrsprachige kontextualisierte Sprachmodelle, die rechenteuer sind und sie für reale Anwendungen unmöglich machen. In dieser Arbeit evaluieren wir mehrere Modellkompressionstechniken für QE und stellen fest, dass sie trotz ihrer Popularität in anderen NLP-Aufgaben zu einer schlechten Leistung in dieser Regressionseinstellung führen. Wir beobachten, dass eine vollständige Modellparametrisierung erforderlich ist, um SoTA-Ergebnisse in einer Regressionsaufgabe zu erzielen. Wir argumentieren jedoch, dass die Expressivität eines Modells in einem kontinuierlichen Bereich angesichts der nachgelagerten Anwendungen von QE überflüssig ist, und zeigen, dass die Umrahmung von QE als Klassifizierungsproblem und die Bewertung von QE-Modellen mit Klassifizierungsmetriken ihre tatsächliche Leistung in realen Anwendungen besser widerspiegeln würde.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Η εκτίμηση της ποιότητας (QE) της μηχανικής μετάφρασης διατυπώνεται παραδοσιακά ως εργασία παλινδρόμησης και η απόδοση των μοντέλων QE συνήθως μετράται με τη συσχέτιση Pearson με ανθρώπινες ετικέτες. Τα πρόσφατα μοντέλα έχουν επιτύχει άγνωστα επίπεδα συσχέτισης με ανθρώπινες κρίσεις, αλλά βασίζονται σε μεγάλα πολύγλωσσα γλωσσικά μοντέλα που είναι υπολογιστικά ακριβά και τα καθιστούν αδύνατα για εφαρμογές πραγματικού κόσμου. Σε αυτή την εργασία, αξιολογούμε διάφορες τεχνικές συμπίεσης μοντέλων για την QE και διαπιστώνουμε ότι, παρά τη δημοτικότητά τους σε άλλες εργασίες οδηγούν σε κακή απόδοση σε αυτή τη ρύθμιση παλινδρόμησης. Παρατηρούμε ότι απαιτείται πλήρης παραμετροποίηση μοντέλου για την επίτευξη αποτελεσμάτων σε μια εργασία παλινδρόμησης. Ωστόσο, υποστηρίζουμε ότι το επίπεδο εκφραστικότητας ενός μοντέλου σε συνεχή κλίμακα είναι περιττό δεδομένου των μεταγενέστερων εφαρμογών της QE, και δείχνουν ότι ο επαναπροσδιορισμός της QE ως πρόβλημα ταξινόμησης και η αξιολόγηση των μοντέλων QE χρησιμοποιώντας μετρήσεις ταξινόμησης θα αντικατοπτρίζουν καλύτερα την πραγματική τους απόδοση σε πραγματικές εφαρμογές.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La estimación de calidad (QE) a nivel de frase de la traducción automática se formula tradicionalmente como una tarea de regresión, y el rendimiento de los modelos de QE se mide normalmente mediante la correlación de Pearson con etiquetas humanas. Los modelos de QE recientes han logrado niveles de correlación nunca antes vistos con los juicios humanos, pero se basan en grandes modelos lingüísticos contextualizados multilingües que son computacionalmente caros y los hacen inviables para aplicaciones del mundo real. En este trabajo, evaluamos varias técnicas de compresión de modelos para QE y descubrimos que, a pesar de su popularidad en otras tareas de PNL, conducen a un rendimiento deficiente en esta configuración de regresión. Observamos que se requiere una parametrización completa del modelo para lograr resultados de SoTA en una tarea de regresión. Sin embargo, argumentamos que el nivel de expresividad de un modelo en un rango continuo es innecesario dadas las aplicaciones posteriores de la QE, y demostramos que replantear la QE como un problema de clasificación y evaluar los modelos de QE utilizando métricas de clasificación reflejaría mejor su rendimiento real en el mundo real. aplicaciones.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Masintõlke lausetaseme kvaliteedi hindamine (QE) on traditsiooniliselt sõnastatud regressiooniülesandena ja QE mudelite jõudlust mõõdetakse tavaliselt Pearsoni korrelatsiooni abil inimmärgistega. Hiljutised QE mudelid on saavutanud varem nähtamatu korrelatsiooni inimotsustega, kuid nad tuginevad suurtele mitmekeelsetele kontekstualiseeritud keelemudelitele, mis on arvutuslikult kallid ja muudavad need reaalsete rakenduste jaoks teostamatuks. Käesolevas töös hindame mitmeid mudeli kompressioonimeetodeid QE jaoks ja leiame, et vaatamata nende populaarsusele teistes NLP ülesannetes põhjustavad need halva jõudluse selles regressiooniseadises. Märgime, et SoTA tulemuste saavutamiseks regressiooniülesandes on vaja täielikku mudeli parametriseerimist. Siiski väidame, et pidevas vahemikus oleva mudeli väljendusvõime tase ei ole vajalik, arvestades QE järgnevaid rakendusi, ning näitame, et QE ümberkujundamine klassifitseerimisprobleemina ja QE mudelite hindamine klassifitseerimismõõdikute abil peegeldaks paremini nende tegelikku jõudlust reaalmaailma rakendustes.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ارزیابی کیفیت سخنرانی (QE) ترجمه دستگاه به طور سنتی به عنوان یک کار بازگشت فرمول می‌شود و عملکرد مدل QE معمولاً توسط ارتباط پیرسون با نقاشی انسان اندازه می‌شود. مدلهای QE اخیراً سطح متقابل قابل قابل قابل قابلیت انسانی پیش از این به دست آورده اند، ولی آنها بر مدلهای زیادی متقابل زبانی متقابل اعتماد دارند که با محاسبات گرون هستند و آنها را برای کاربردهای دنیای واقعی ناتوان سازند. در این کار، ما چندین تکنیک فشار فشار فشار مدل برای QE ارزیابی می‌کنیم و می‌بینیم که، با وجود شهرت آنها در کار های دیگر NLP، آنها به عملکرد بدی در این تنظیم افشاری رخ می‌دهند. ما مشاهده می‌کنیم که یک پارامتریزی مدل کامل برای رسیدن نتیجه‌های SoTA در یک کار تجاوز نیاز دارد. با این حال، ما بحث می‌کنیم که سطح استفاده از یک مدل در یک منطقه دائمی لازم نیست به عنوان کاربردهای پایین QE، و نشان می‌دهیم که بازسازی QE به عنوان یک مشکل شناسایی و ارزیابی مدل QE با استفاده از متریک‌های شناسایی بهتر انجام واقعیشان را در کاربردهای دنیای واقعی نشان می‌دهد.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Konekäännöksen lausetason laadunarviointi (QE) on perinteisesti muotoiltu regressiotehtäväksi, ja QE-mallien suorituskykyä mitataan tyypillisesti Pearsonin korrelaatiolla inhimillisten etikettien kanssa. Viimeaikaiset laadunvarmistusmallit ovat saavuttaneet ennennäkemättömät korrelaatiotasot ihmisten arviointien kanssa, mutta ne perustuvat suuriin monikielisiin kontekstualisoituihin kielimalleihin, jotka ovat laskennallisesti kalliita ja tekevät niistä mahdottomia toteuttaa todellisia sovelluksia. Tässä työssä arvioimme useita mallikompressiotekniikoita QE:lle ja havaitsimme, että huolimatta niiden suosiosta muissa NLP-tehtävissä, ne johtavat huonoon suorituskykyyn tässä regressioasetuksessa. Havaitsemme, että koko mallin parametrisointi on tarpeen SoTA-tulosten saavuttamiseksi regressiotehtävässä. Väitämme kuitenkin, että jatkuvalla alueella olevan mallin ekspressiivisyyden taso on tarpeeton ottaen huomioon QE:n loppupään sovellukset, ja osoitamme, että QE:n uudelleenjäsentäminen luokitusongelmaksi ja QE:n mallien arviointi luokitusmittareilla heijastaisi paremmin niiden todellista suorituskykyä reaalimaailman sovelluksissa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>L'estimation de la qualité (QE) au niveau de la phrase de la traduction automatique est traditionnellement formulée comme une tâche de régression, et la performance des modèles QE est généralement mesurée par la corrélation de Pearson avec les étiquettes humaines. Les récents modèles d'assouplissement quantitatif ont atteint des niveaux inédits de corrélation avec les jugements humains, mais ils s'appuient sur de grands modèles linguistiques contextualisés multilingues qui sont coûteux en termes de calcul et les rendent impossibles à appliquer dans le monde réel. Dans ce travail, nous évaluons plusieurs techniques de compression de modèle pour l'assouplissement quantitatif et constatons que, malgré leur popularité dans d'autres tâches de PNL, elles conduisent à de mauvaises performances dans ce paramètre de régression. Nous observons qu'un paramétrage complet du modèle est nécessaire pour obtenir les résultats SOtA dans une tâche de régression. Cependant, nous soutenons que le niveau d'expressivité d'un modèle dans une plage continue n'est pas nécessaire compte tenu des applications en aval de l'assouplissement quantitatif, et nous montrons que le recadrage de l'assouplissement quantitatif en tant que problème de classification et l'évaluation des modèles QE à l'aide de métriques de classification refléteraient mieux leur performance réelle applications.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Go traidisiúnta foirmítear Meastachán Cáilíochta ar leibhéal na habairte (QE) ar aistriúchán meaisín mar thasc aischéimnithe, agus de ghnáth déantar feidhmíocht na múnlaí QE a thomhas trí chomhghaol Pearson le lipéid dhaonna. Tá leibhéil chomhghaolmhaireachta le breithiúnais dhaonna bainte amach ag samhlacha QE le déanaí nach bhfacthas riamh cheana, ach braitheann siad ar mhúnlaí móra ilteangacha teanga comhthéacsúla atá costasach ó thaobh ríomhaireacht de agus a fhágann nach féidir iad a úsáid le haghaidh feidhmeanna sa saol fíor. San obair seo, déanaimid meastóireacht ar roinnt teicnící comhbhrú samhlacha le haghaidh QE agus aimsímid, in ainneoin a n-éilimh i dtascanna NLP eile, go n-eascraíonn siad drochfheidhmíocht sa suíomh aischéimnithí seo. Breathnaímid go bhfuil gá le samhailpharaiméadarú iomlán chun torthaí SoTA a bhaint amach i dtasc cúlchéimnithe. Áitímid, áfach, nach bhfuil gá le leibhéal sainráite múnla i raon leanúnach i bhfianaise iarratais iartheachtacha QE, agus léirímid go léireodh níos fearr a bhfeidhmíocht iarbhír i bhfíor-fheidhmíocht dá ndéanfaí athfhrámáil ar QE mar fhadhb aicmithe agus trí mhúnlaí QE a mheas ag baint úsáide as méadracht aicmithe. iarratais domhan.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ana ƙayyade Tsarin-daraja na fassarar kwamfyutan (QU) na fassarar maɓalli an danne shi a ƙidãya kamar wani aikin regression, kuma gyaran misalin QEyi ana ƙaddara shi a bayan a ƙayyade Pearson da aka yi danganta da alama na mutum. A yanzu masu motsi na QU na sami da daraja wanda ba'a sani ba ta gabãni, sunã mãsu husũma da hukuncin mutãne, kuma sunã dõgara a kan misãlai masu yawa na harshen mulki-mulki waɗanda ke ƙidãya masu nau'i da lissafi kuma sunã sanya su an yi musamman da shiryoyin ayuka masu shiryuwa na dũniya. Daga wannan aikin, Munã ƙaddara misãlai masu ƙaranci wa QET kuma munã gane, kuma, kõ da yaushe umakinsu na cikin aikin NLP, sai su yi matalauci a cikin wannan tsarin damu. Muna ganin cewa an buƙata tsari cikakken misãlai dõmin ya sãmu matsalar SoTA cikin aikin da za'a rajista. Amma, Munã jãyayya cẽwa, gwargwadon maganar wata misalin da ke cikin hanyarsa mai daidai ba na da amfani ba a ga shirin ayuka na QEki na ƙarƙashin kwamfyuta, kuma za mu nuna cewa tsarin QEki kamar wata fitina na na fassarar kuma ana canza misãlai na QU da amfani da metrici mai fassarawa, zai fi canza mafarinsa a cikin shiryoyin-duniya.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>הערכת איכות רמת המשפטים (QE) של התרגום המכונית מתייצבת במסורתית כמשימה חזרה, והביצועים של דוגמנים QE מתמדדים בדרך כלל על ידי הקשר של פירסון עם תוויות אנושיות. דוגמני QE האחרונים השיגו רמות של שיתוף בלתי נראות קודם עם שיפוטים אנושיים, אך הם סומכים על דוגמני שפת רבות-שפותיים גדולים שקשורים במחשבות יקרים והופכים אותם בלתי אפשריים לתוכניות בעולם האמיתי. בעבודה הזו, אנו מעריכים כמה טכניקות דחיסה של QE ומצאים שלמרות הפופולריות שלהם במשימות NLP אחרות, הן מובילות לביצוע גרוע בסביבה זו של גידול. We observe that a full model parameterization is required to achieve SoTA results in a regression task. בכל אופן, אנחנו טוענים שרמה של ביטוי של מודל במטווח ממשיך אינה הכרחית בהתחשב באימונים למטה של QE, ולהראות שהשינוי QE בתור בעיה מסווג והעריכה של מודלים QE באמצעות מטריות מסווג עדיף להשקף את היציאה האמיתית שלהם באימונים בעולם האמיתי.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>मशीन अनुवाद के वाक्य-स्तर गुणवत्ता अनुमान (क्यूई) को पारंपरिक रूप से एक प्रतिगमन कार्य के रूप में तैयार किया जाता है, और क्यूई मॉडल के प्रदर्शन को आमतौर पर मानव लेबल के साथ पियर्सन सहसंबंध द्वारा मापा जाता है। हाल के क्यूई मॉडल ने मानव निर्णयों के साथ सहसंबंध के पहले-अनदेखे स्तरों को प्राप्त किया है, लेकिन वे बड़े बहुभाषी प्रासंगिक भाषा मॉडल पर भरोसा करते हैं जो कम्प्यूटेशनल रूप से महंगे हैं और उन्हें वास्तविक दुनिया के अनुप्रयोगों के लिए अव्यवहार्य बनाते हैं। इस काम में, हम क्यूई के लिए कई मॉडल संपीड़न तकनीकों का मूल्यांकन करते हैं और पाते हैं कि, अन्य एनएलपी कार्यों में उनकी लोकप्रियता के बावजूद, वे इस प्रतिगमन सेटिंग में खराब प्रदर्शन का कारण बनते हैं। हम देखते हैं कि प्रतिगमन कार्य में SoTA परिणामों को प्राप्त करने के लिए एक पूर्ण मॉडल पैरामीटराइजेशन की आवश्यकता होती है। हालांकि, हम तर्क देते हैं कि एक निरंतर सीमा में एक मॉडल की अभिव्यंजकता का स्तर क्यूई के डाउनस्ट्रीम अनुप्रयोगों को देखते हुए अनावश्यक है, और यह दर्शाता है कि क्यूई को वर्गीकरण समस्या के रूप में फिर से तैयार करना और वर्गीकरण मीट्रिक का उपयोग करके क्यूई मॉडल का मूल्यांकन करना वास्तविक दुनिया के अनुप्रयोगों में उनके वास्तविक प्रदर्शन को बेहतर ढंग से प्रतिबिंबित करेगा।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Procjenjivanje kvalitete na razini kazne (QE) prevoda stroja tradicionalno se formulira kao zadatak regresije, a učinkovitost modela QE obično se mjera korelacija Pearsona s ljudskim etiketama. Skorašnji QE modeli su postigli ranije nevidljive razine korelacije s ljudskim osuđivanjima, ali se oslanjaju na velike multijezičke kontekstualizirane jezičke modele koje su računalno skupe i čine ih neprijateljima za realne aplikacije. U ovom poslu, procjenjujemo nekoliko modela tehnika kompresije za QE i otkrijemo da, uprkos popularnosti drugih zadataka NLP-a, oni vode do lošeg učinka u ovom regresijskom postavljanju. Primijetimo da je potrebna puna modelna parameterizacija kako bi postigla rezultate SoTA u zadatku regresije. Međutim, tvrdimo da je razina izrazitosti model a u kontinuiranom rasponu nepotrebna s obzirom na snimke primjene QE-a, i pokazujemo da je reframiranje QE kao problem klasifikacije i procjena modela QE-a koristeći klasifikacijske metrike bolje odražavalo njihovu stvarnu funkciju u primjenama stvarnog svijeta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A gépi fordítás mondatszintű minőségbecslését (QE) hagyományosan regressziós feladatként fogalmazzák meg, a QE modellek teljesítményét pedig jellemzően Pearson korrelációval mérik az emberi címkékkel. A legújabb QE modellek korábban nem látott korrelációt értek el az emberi ítéletekkel, de nagy többnyelvű kontextuális nyelvi modellekre támaszkodnak, amelyek számítástechnikailag drágák és a valós alkalmazások számára nem megfelelőek. Ebben a munkában több modell tömörítési technikát értékelünk a QE számára, és megállapítjuk, hogy annak ellenére, hogy népszerűségük más NLP feladatokban, ezek rossz teljesítményhez vezetnek ebben a regressziós beállításban. Megfigyeljük, hogy teljes modellparaméterezésre van szükség ahhoz, hogy a SotA regressziós feladatot eredményezzen. Azonban azzal érvelünk, hogy egy modell folyamatos tartományban való kifejezőképességének szintje szükségtelen, tekintettel a minőségi minőségbiztosítás downstream alkalmazásaira, és megmutatjuk, hogy a minőségbiztosítási problémának átalakítása és a minőségbiztosítási modellek osztályozási mutatók alkalmazásával való értékelése jobban tükrözné a valós alkalmazásokban való tényleges teljesítményüket.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Մեքենայի թարգմանման արտահայտության մակարդակի որակի գնահատումը (QE) ավանդական կերպով ձևավորվում է որպես ռեգրեսիոն խնդիր, և QE մոդելների արտադրողությունը սովորաբար չափում է Փարսոնի հարաբերակցության միջոցով մարդկային պիտակների հետ: Վերջին QE մոդելները հասել են մարդկային դատողությունների հետ նախկինում անտեսանելի հաղորդակցման մակարդակին, բայց նրանք հիմնված են մեծ բազմալեզու կոնտեքստիալ լեզվի մոդելների վրա, որոնք հաշվարկների առումով թանկ են և դարձնում դրանք անհասանելի իրական աշխարհի ծրագրերի Այս աշխատանքի ընթացքում մենք գնահատում ենք QE-ի համար բազմաթիվ մոդելներ ընդգծելու մեթոդներ և հայտնաբերում ենք, որ չնայած նրանց հայտնի լինելուն այլ ՆԼՊ-ի խնդիրներում, դրանք հանգեցնում են վատ արտադրողությունների այս ռեգրեսիայի Մենք նկատում ենք, որ անհրաժեշտ է ամբողջ մոդելի պարամետրիզացիա, որպեսզի հասնենք ՍոԹԱ-ի արդյունքները վերադառնալու խնդրի մեջ: Այնուամենայնիվ, մենք փաստարկում ենք, որ շարունակական տարածքում մոդելի արտահայտության մակարդակը անհրաժեշտ է հաշվի առնելով QE-ի հետագա ծրագրերը, և ցույց են տալիս, որ QE-ի վերափոխումը որպես դասակարգման խնդիր և QE-ի մոդելների գնահատումը օգտագործելով դասակարգման մետրիկներ ավելի լա</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Perkiraan kualitas tingkat kalimat (QE) dari terjemahan mesin secara tradisional ditentukan sebagai tugas regresi, dan prestasi model QE biasanya diukur oleh korelasi Pearson dengan label manusia. Model QE baru-baru ini telah mencapai tingkat korelasi yang belum pernah terlihat dengan penilaian manusia, tetapi mereka bergantung pada model bahasa multibahasa kontekstualisasi besar yang mahal secara komputasi dan membuat mereka tidak dapat disembunyikan untuk aplikasi dunia nyata. Dalam pekerjaan ini, kami mengevaluasi beberapa teknik kompresi model untuk QE dan menemukan bahwa, meskipun popularitas mereka dalam tugas lainnya NLP, mereka menyebabkan prestasi buruk dalam setting regresi ini. Kami memperhatikan bahwa parameterisasi model lengkap diperlukan untuk mencapai hasil SoTA dalam tugas regresi. Namun, kami menyangka bahwa tingkat ekspresivitas model dalam jangkauan terus menerus tidak diperlukan karena aplikasi turun dari QE, dan menunjukkan bahwa reframing QE sebagai masalah klasifikasi dan mengevaluasi model QE menggunakan metrik klasifikasi akan lebih baik merefleksikan prestasi mereka sebenarnya dalam aplikasi dunia nyata.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La stima della qualità (QE) della traduzione automatica è tradizionalmente formulata come un compito di regressione e le prestazioni dei modelli QE sono tipicamente misurate dalla correlazione Pearson con le etichette umane. I recenti modelli QE hanno raggiunto livelli di correlazione inediti con i giudizi umani, ma si basano su grandi modelli linguistici contestualizzati multilingue che sono computazionalmente costosi e li rendono impossibili per le applicazioni del mondo reale. In questo lavoro, valutiamo diverse tecniche di compressione del modello per QE e scopriamo che, nonostante la loro popolarità in altre attività NLP, portano a scarse prestazioni in questa impostazione di regressione. Osserviamo che è necessaria una parametrizzazione completa del modello per ottenere risultati SoTA in un compito di regressione. Tuttavia, sosteniamo che il livello di espressività di un modello in un intervallo continuo non sia necessario, date le applicazioni a valle del QE, e mostriamo che riformulare il QE come problema di classificazione e valutare i modelli QE utilizzando metriche di classificazione rifletterebbe meglio le loro prestazioni effettive nelle applicazioni del mondo reale.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>機械翻訳の文章レベルの品質推定（ QE ）は、伝統的に回帰タスクとして策定され、QEモデルのパフォーマンスは、典型的には、人間のラベルとのピアソン相関によって測定されます。 最近のQEモデルは、人間の判断との以前には見られなかったレベルの相関を達成していますが、計算コストが高く、現実のアプリケーションでは実現不可能な大規模な多言語コンテキスト化された言語モデルに依存しています。 この研究では、QEのためのいくつかのモデル圧縮技術を評価し、他のNLPタスクで人気があるにもかかわらず、この回帰設定ではパフォーマンスが低下することを発見しました。 回帰タスクでSoTA結果を達成するには、完全なモデルパラメータ化が必要であることがわかります。 しかし、我々は、QEの下流アプリケーションを考慮すると、モデルの連続した範囲での表現性のレベルは不要であると主張し、QEを分類問題として再フレーム化し、分類指標を使用してQEモデルを評価することは、実際のアプリケーションでの実際のパフォーマンスをよりよく反映することが示されている。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ukuran model de R&E dumateng sing perusahaan kelangan mat sampeyan karo perusahaan hukum dumateng, nguasai supoyo kuwi model multi-lenguangkap multi-lenguangkap model sing kelangan karo akeh komputasi akeh akeh dumateng, lan akeh dumateng sumulapakan kanggo aplikasi versi dumateng. Nang iki trabah, kita deweke nggawe sistem sing perusahaan kanggo ngilanggar-sistem model sing perusahaan kanggo Kemerdekaan kanggo ngerasakno. bah ngono popularno sing ngendalikno NLP sing wis ngerasakno, padha iso nggawe barang ngendalikno Regresyon iki. Monday Nanging, awak dhéwé nggalaksi banjuré kesempresan pangan ning model sing bisa dumadhi iki, nik awak dhéwé aplikasi downtream ning kE kuwi nggawe barang kelas nêmên iki bakal terus nggawe sistem sing kelas nêmên karo akeh model sing titimpen Nêmên iki dadi sing bisa nggawe barang kelas nêmên.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>მანქანის გარგულისხმების კვალეტური განსაზღვრება (QE) სამუშაო სიტყვების განსაზღვრება როგორც რეგრესიის რაოდენობა, და QE მოდელების გამოსაზღვრება ტიპონალურად მოზღვრება Pearson კორელაცია QE მოდელები უკვე უკვე უკვე უკვე უკვე უკვე უკვე უკვე უკვე უკვე უკვე უკვე უკვე უკვე უკვე უკვე უკვე უკვე უკვე უკვე უკვე უკვე სიტყვის მოდელების შესახებ, ამ სამუშაოში, ჩვენ QE-სთვის რამდენიმე მოდელური კომპრესიის ტექნექციები გავამუშავებთ და აღმოჩნეთ, რომ, სხვა NLP სამუშაოში, ისინი გავამუშავებენ ცოტა კომპრე ჩვენ დავხედავთ, რომ სრულ მოდელური პარამეტრიზაცია საჭიროა SoTA წარმოდგენისთვის რეგრესიის დავალებაში. თუმცა, ჩვენ აღმოჩნეთ, რომ მოდელის გამოსახულებელობის დონე მუშაობაში QE-ის ჩვენებაში უნდა უნდა იყოს, რომ QE-ს კლასიფიკაციის პრობლემა და QE მოდელის გამოსახულებაში კლასიფიკაციის მეტრიკის გამოყენებაში უფრო უფრო უნდა გა</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Компьютердің сөз деңгейінің сапасы бағалауы (QE) әдетте регрессия тапсырмасы ретінде формулады, және QE үлгілерін әдетте Pearson коррелациясы адамдар жарлықтарымен өлшейтін болады. Жуырдағы QE үлгілері адамдардың түсініктемелерімен алдын- ала көрсетілмеген қатынас деңгейіне жеткізді, бірақ олар компьютерлік үлкен көп тілдер үлгілікті тілдер үлгілеріне тұрады, оларды шын әлемді қолдан Бұл жұмыс ішінде QE үшін бірнеше түрлі компрессия техникаларын бағалап, басқа NLP тапсырмаларындағы мәліметтеріне қарай, олар регрессия параметрлерінде өзгертілмейді. Біз SoTA нәтижесін регрессия тапсырмасына жеткізу үшін толық үлгі параметрлерін қажет етеді деп белгіледік. Бірақ, біз үлгісінің дұрыс аумағындағы үлгіліктер деңгейі QE бағдарламаларының төменгі қолданбаларына келтірілмейді деп айтып, QE классификациялық мәселесі ретінде және QE моделдерін классификациялық метрикалық қолданбаларының шынды</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>기계 번역의 문장급 품질 평가(QE)는 전통적으로 회귀 임무로 묘사되고 QE모델의 성능은 보통 인간 라벨의 필슨과 관련성을 통해 평가된다.최근의 양적완화 모델은 이전에 볼 수 없었던 인간의 판단과 관련된 정도에 이르렀지만 대형 다국어 어경화 언어 모델에 의존하기 때문에 이런 모델의 계산 원가가 매우 높아 실제 응용에 적용되지 않는다.이 작업에서 우리는QE에 사용되는 몇 가지 모델 압축 기술을 평가했고 다른 NLP 작업에서 인기가 많지만 이러한 회귀 설정에서 비교적 나쁜 성능을 초래할 수 있음을 발견했다.회귀 임무에서 SoTA 결과를 실현하려면 완전한 모델 매개 변수화가 필요하다는 것을 관찰했다.그러나 우리는 양적완화의 하류 응용을 감안하면 모델이 연속적인 범위 내에서 표현 수준이 불필요하다고 생각한다. 또한 양적완화를 하나의 분류 문제로 다시 정의하고 분류도량으로 양적완화모델을 평가하면 실제 응용에서의 실제 성능을 더욱 잘 반영할 수 있다고 본다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mašininio vertimo kokybės vertinimas (QE) nuosprendžių lygiu tradiciškai formuluojamas kaip regresijos užduotis, o QE modelių veiksmingumas paprastai matuojamas pagal Pearson koreliaciją su žmogaus etiketėmis. Pastaraisiais QE modeliais buvo pasiektas anksčiau nematomas koreliacijos su žmogaus sprendimais lygis, tačiau jie grindžiami dideliais daugiakalbiais kontekstiniu kalbų modeliais, kurie yra skaičiavimo požiūriu brangūs ir sudaro juos neįmanomas naudoti realiajame pasaulyje. Šiame darbe vertiname keletą modelių kompresijos metodų QE atžvilgiu ir nustatome, kad nepaisant jų populiarumo kitose NLP užduotyse, šios regresijos sąlygomis jos daro prastus rezultatus. Pastebėjome, kad norint pasiekti SoTA rezultatus būtina atlikti visišką modelio parametrizavimą. Tačiau mes teigiame, kad modelio išraiškumo lygis nuolatiniame intervale yra nereikalingas atsižvelgiant į tolesnes QE taikymo sritis, ir rodome, kad QE pertvarkymas kaip klasifikacijos problem a ir QE modelių vertinimas naudojant klasifikacijos metrijas geriau atspindėtų jų faktinį veiksmingumą realaus pasaulio taikymo srityse.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Проценката на квалитетот на нивото на реченици (QE) на машинскиот превод традиционално се формулира како регресна задача, а изведбата на моделите на QE е обично мерена со корелација на Пирсон со човечките етикети. Неодамнешните модели на QE постигнаа претходно невидени нивоа на корелација со човечките пресуди, но тие се потпираат на големи мултијазични контекстуализирани јазички модели кои се пресметувачки скапи и ги прават неприфатливи за реални апликации. In this work, we evaluate several model compression techniques for QE and find that, despite their popularity in other NLP tasks, they lead to poor performance in this regression setting. Забележуваме дека е потребна целосна параметризација на моделот за да се постигне СоTA резултат на регресна задача. Сепак, тврдиме дека нивото на експресивност на моделот во континуиран период е непотребно со оглед на понатамошните апликации на QE, и покажуваме дека рефирмирањето на QE како класификациски проблем и евалуирањето на QE моделите со користење на класификациските метрики подобро би ги одразувало нивните реални успешности во ре</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>മെഷിന്‍ പരിഭാഷക്കുറിച്ചുള്ള ശിക്ഷ- നില വ്യവസ്ഥ (ക്യൂയി) പരിശോധനത്തിന്റെ പാഠമായി രീക്രഷന്‍ ജോലിയായി രൂപപ്പെടുത്തിയിരിക്കുന്നു. ക്യൂ അടുത്തിടെ ക്യൂ ഇ മോഡലുകള്‍ മുമ്പ് മനുഷ്യരുടെ വിധികളുമായി ബന്ധപ്പെടാത്ത നിലങ്ങളില്‍ എത്തിയിരിക്കുന്നു. പക്ഷെ അവരതില്‍ ആശ്രയിക്കുന്നു വലിയ മണ്ണില്‍ കണ ഈ പ്രവര്‍ത്തനത്തില്‍, ക്യൂയിക്കുവേണ്ടി കുറച്ച് മോഡല്‍ സമ്പൂര്‍ണ്ണമായ സാങ്കേതികവിദ്യകള്‍ വിലാസപ്പെടുത്തുന്നു. മറ്റു NLP ജോലികളില്‍ സോട്ടാവിന്റെ ഫലങ്ങള്‍ പൂര്‍ണ്ണമായ മോഡല്‍ പരാമീറ്ററേഷന്‍ ആവശ്യമാണെന്ന് ഞങ്ങള്‍ കാണുന്നു. എന്നാലും, നിലനില്‍ക്കുന്ന ഒരു മോഡലിന്‍റെ പ്രകടനത്തിന്‍റെ നിലപാട് ക്യൂയിയുടെ താഴ്വരയുടെ പ്രയോഗങ്ങള്‍ക്ക് ആവശ്യമില്ല എന്നും ക്യൂയിയെ ക്ലാസ്ഫിക്ഷന്‍ പ്രശ്നമാക്കുന്നതും ക്യൂ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Машины хөрөнгө оруулалтын хэмжээний хэмжээний качест тооцоолол (QE) нь уламжлалтаар регрессийн даалгавар гэж тооцоолж байна. QE загварын үйл ажиллагаа нь ихэвчлэн Персон хүн төрөлхтний etiketтэй холбоотой хэмж Сүүлийн үеийн QE загварууд хүн төрөлхтний шүүмжлэлтэй холбоотой хэмжээний түвшинд өмнө нь харагдаагүй түвшинд хүргэсэн байна. Гэхдээ тэд маш олон хэлний орчин үеийн хэл загваруудыг тооцоолж маш үнэтэй, бодит ертөнцийн хэр Энэ ажил дээр бид QE-ийн хэдэн загварын даралтын технологийг үнэлгээд бусад NLP даалгаврууд дээр нэр хүндрэлтэй байсан ч, тэд бусад сэтгэл хөдлөлт дээр ядуу үйл ажиллагааг хүргэж чадна. Бид SoTA-ын үр дүнг сэтгэл хөдлөлийн үйлдлийн үр дүнд бүрэн загварын параметрийг олох хэрэгтэй гэдгийг анзаарлаа. Гэхдээ бид үргэлжлүүлэх хэмжээнд загварын илэрхийллийн түвшин нь QE-ийн доорх хэрэглээнд хэрэггүй гэдгийг хэлж байна. QE-г хуваалцах асуудал болгон, QE-ийн загварыг хуваалцах нь хуваалцах хэмжээний метрикийг ашиглан хуваалцах нь бодит ертөнцийн хэрэглээнд илүү үр</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Perkiraan Kualiti Aras-perkataan (QE) terjemahan mesin secara tradisional dibentuk sebagai tugas regresi, dan prestasi model QE biasanya diukur oleh korelasi Pearson dengan label manusia. Model QE baru-baru ini telah mencapai tahap korelasi yang belum pernah terlihat dengan penilaian manusia, tetapi mereka bergantung pada model bahasa berbagai bahasa yang terkontekstualisasi besar yang secara komputasi mahal dan menjadikannya tidak dapat disembunyikan untuk aplikasi dunia nyata. Dalam kerja ini, kami menilai beberapa teknik pemampatan model untuk QE dan mendapati bahawa walaupun popularitas mereka dalam tugas NLP lain, mereka membawa kepada prestasi yang buruk dalam seting regresi ini. We observe that a full model parameterization is required to achieve SoTA results in a regression task. Namun, kami menyangka bahawa aras ekspresif model dalam julat berterusan tidak diperlukan kerana aplikasi turun QE, dan menunjukkan bahawa mengubah QE sebagai masalah klasifikasi dan menilai model QE menggunakan metrik klasifikasi akan lebih baik mencerminkan prestasi sebenar mereka dalam aplikasi dunia nyata.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>L-istima tal-kwalità fil-livell tas-sentenza (QE) tat-traduzzjoni bil-magna tradizzjonalment hija fformulata bħala kompitu ta’ rigressjoni, u l-prestazzjoni tal-mudelli QE tipikament titkejjel bil-korrelazzjoni ta’ Pearson mat-tikketti umani. Il-mudelli reċenti tal-QE kisbu livelli ta’ korrelazzjoni li ma dehrux qabel mas-sentenzi umani, iżda jiddependu fuq mudelli kbar multilingwi kuntestwalizzati tal-lingwa li huma għaljin b’mod komputattiv u jagħmluhom infeżibbli għall-applikazzjonijiet tad-dinja reali. F’dan ix-xogħol, aħna jevalwaw diversi metodi ta’ kompressjoni mudelli għall-QE u nsibu li, minkejja l-popolarità tagħhom f’kompiti oħra tal-NLP, dawn iwasslu għal prestazzjoni ħażina f’dan l-ambjent ta’ rigressjoni. Aħna ninnota li hija meħtieġa parametrizzazzjoni sħiħa tal-mudell biex jinkiseb SoTA tirriżulta f’kompitu ta’ rigressjoni. Madankollu, a ħna jargumentaw li l-livell ta’ espressività ta’ mudell f’firxa kontinwa mhuwiex meħtieġ minħabba l-applikazzjonijiet downstream ta’ QE, u juru li r-riformulazzjoni ta’ QE bħala problem a ta’ klassifikazzjoni u l-evalwazzjoni ta’ mudelli QE bl-użu ta’ metriċi ta’ klassifikazzjoni jirriflettu aħjar il-prestazzjoni attwali tagħhom fl-applikazzjonijiet tad-dinja reali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kwaliteitsschatting (QE) van machinevertaling wordt traditioneel geformuleerd als een regressietaak, en de prestaties van QE-modellen worden meestal gemeten door Pearson-correlatie met menselijke labels. Recente QE-modellen hebben eerder ongekende niveaus van correlatie met menselijke oordelen bereikt, maar ze vertrouwen op grote meertalige contextualiseerde taalmodellen die rekenkundig duur zijn en ze onuitvoerbaar maken voor toepassingen in de echte wereld. In dit werk evalueren we verschillende modelcompressietechnieken voor QE en vinden we dat, ondanks hun populariteit in andere NLP-taken, ze leiden tot slechte prestaties in deze regressie-instelling. We zien dat een volledige modelparametrisering vereist is om SotA resultaten te bereiken in een regressietaak. We stellen echter voor dat het niveau van expressiviteit van een model in een continue waaier overbodig is gezien de downstream toepassingen van QE, en tonen aan dat het herschikken van QE als een classificatieprobleem en het evalueren van QE modellen met behulp van classificatiemetrics hun werkelijke prestaties in real-world toepassingen beter zouden weerspiegelen.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Estimasjon av setningsnivå kvalitet (QE) av maskinsomsetjinga er tradisjonell formert som regresjonsverkt, og utviklinga av QE-modeller er vanlegvis målt av Pearson-korrelasjon med menneske etikettar. Nyleg brukte QE-modeller har oppnådd tidlegare ukjende korrelasjonsnivåar med menneske sprøytebrukar, men dei er på stor fleirspråk kontekstualiserte språk-modeller som er datamaskinen dyrt og gjer dei infeksibel for verkelege programmer. I denne arbeida evaluerer vi fleire modeller komprimeringsteknikk for QE og finn at, selv om populariteten i andre NLP-oppgåver, fører dei til dårlig utvikling i denne regresjonsinnstillingane. Vi observerer at ein fullstendig modellparameterisering er nødvendig for å oppnå SoTA-resultat i ei regresjonsbehandling. Men vi argumenterer at nivået av uttrykket av eit modell i eit kontinuerleg område er unnecessar gitt nedstrekkprogrammet av QE, og viser at reframering av QE som eit klassifikasjonsproblem og evaluering av QE-modeller med klassifikasjonsmeterikk vil betre refleksera sine faktiske uttrykk i verdens program.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ocena jakości (QE) tłumaczenia maszynowego jest tradycyjnie formułowana jako zadanie regresyjne, a wydajność modeli QE jest zazwyczaj mierzona korelacją Pearsona z etykietami ludzkimi. Najnowsze modele QE osiągnęły niewidoczny wcześniej poziom korelacji z osądami ludzkimi, ale opierają się na dużych wielojęzycznych kontekstualizowanych modelach językowych, które są kosztowne obliczeniowo i sprawiają, że są niewykonalne dla aplikacji w świecie rzeczywistym. W niniejszej pracy oceniamy kilka technik kompresji modeli dla QE i stwierdzimy, że pomimo ich popularności w innych zadaniach NLP, prowadzą one do słabej wydajności w tym ustawieniu regresji. Obserwujemy, że do osiągnięcia wyników SoTA w zadaniu regresji wymagana jest pełna parametryzacja modelu. Uważamy jednak, że poziom ekspresywności modelu w ciągłym zakresie jest niepotrzebny biorąc pod uwagę dalsze zastosowania QE i pokazujemy, że przekształcenie QE jako problemu klasyfikacyjnego i ocena modeli QE za pomocą wskaźników klasyfikacyjnych lepiej odzwierciedlałoby ich rzeczywistą wydajność w aplikacjach rzeczywistych.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A estimativa de qualidade em nível de sentença (QE) da tradução automática é tradicionalmente formulada como uma tarefa de regressão, e o desempenho dos modelos de QE é normalmente medido pela correlação de Pearson com rótulos humanos. Modelos de QE recentes alcançaram níveis nunca vistos de correlação com julgamentos humanos, mas eles contam com grandes modelos de linguagem contextualizada multilíngue que são computacionalmente caros e os tornam inviáveis para aplicações do mundo real. Neste trabalho, avaliamos várias técnicas de compressão de modelo para QE e descobrimos que, apesar de sua popularidade em outras tarefas de PNL, elas levam a um desempenho ruim nessa configuração de regressão. Observamos que uma parametrização completa do modelo é necessária para obter resultados SoTA em uma tarefa de regressão. No entanto, argumentamos que o nível de expressividade de um modelo em um intervalo contínuo é desnecessário, dadas as aplicações downstream do QE, e mostramos que reformular o QE como um problema de classificação e avaliar os modelos de QE usando métricas de classificação refletiria melhor seu desempenho real em condições reais. aplicações mundiais.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Estimarea calității (QE) a traducerii automate este formulată în mod tradițional ca o sarcină de regresie, iar performanța modelelor QE este de obicei măsurată prin corelația Pearson cu etichetele umane. Modelele QE recente au atins niveluri nevăzute anterior de corelație cu judecățile umane, dar se bazează pe modele lingvistice contextualizate multilingve mari, care sunt costisitoare din punct de vedere computațional și le fac imposibile pentru aplicațiile din lumea reală. În această lucrare, evaluăm mai multe tehnici de compresie a modelului pentru QE și constatăm că, în ciuda popularității lor în alte sarcini PNL, ele duc la performanțe slabe în această setare de regresie. Observăm că este necesară o parametrizare completă a modelului pentru a obține rezultatele SoTA într-o sarcină de regresie. Cu toate acestea, susținem că nivelul de expresivitate al unui model într-o gamă continuă nu este necesar având în vedere aplicațiile din aval ale QE și arătăm că reformarea QE ca problemă de clasificare și evaluarea modelelor QE folosind metrici de clasificare ar reflecta mai bine performanța lor reală în aplicațiile din lumea reală.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Оценка качества на уровне предложения (QE) машинного перевода традиционно формулируется как задача регрессии, и производительность моделей QE обычно измеряется корреляцией Пирсона с человеческими метками. Недавние модели QE достигли ранее невидимых уровней корреляции с человеческими суждениями, но они опираются на большие многоязычные контекстуализированные языковые модели, которые являются вычислительно дорогими и делают их невыполнимыми для реальных приложений. В этой работе мы оцениваем несколько методов сжатия моделей для QE и обнаруживаем, что, несмотря на их популярность в других задачах NLP, они приводят к плохой производительности в этой настройке регрессии. Мы наблюдаем, что для достижения результатов SoTA в задаче регрессии требуется полная параметризация модели. Тем не менее, мы утверждаем, что уровень экспрессивности модели в непрерывном диапазоне не является необходимым, учитывая последующее применение QE, и показываем, что переформатирование QE как проблемы классификации и оценка моделей QE с использованием метрик классификации лучше отражали бы их фактическую производительность в реальных приложениях.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>වාර්තාව-ස්තූති කුළුවත් අවශ්‍යය (QE) පද්ධතිය පද්ධතියෙන් වාර්තාව ප්‍රමාණය වෙනුවෙන් ප්‍රමාණයක් වෙනුවෙන් සූදානම් කරනවා, සහ Q මිනිස්සු විශ්වාසයෙන් වැඩි භාෂාව ප්‍රතිභාවිත විශ්වාස කරපු භාෂාව මොඩේල් වලින් පරීක්ෂණයෙන් ගොඩක් බලාපොරොත්තු වෙන්න පුළුවන මේ වැඩේ අපි QE වෙනුවෙන් මොඩල් සංකීර්ණ විද්‍යාවක් විශ්වාස කරනවා ඒ වගේම හොයාගන්නවා ඒක, අනිත් NLP වැඩේ ඔවුන්ගේ ප්‍රමාණය, ඔ අපි බලාපොරොත්තු කරනවා සම්පූර්ණ මොඩල් ප්‍රමාණයක් අවශ්‍යයි SoTA ප්‍රතිචාරයක් ප්‍රතිචාරයක් වෙන නමුත්, අපි ප්‍රශ්නය කරනවා කියලා නිතරම් ප්‍රශ්නයක් ප්‍රශ්නයක් තියෙන්නේ QE වලින් විශ්වාස කරපු ප්‍රශ්නයක් වගේ QE විශ්වාස කරපු ප්‍රශ්නයක් වගේ ප්‍රශ්න</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ocena kakovosti (QE) strojnega prevajanja na ravni stavka je tradicionalno oblikovana kot regresijska naloga, učinkovitost modelov QE pa se običajno meri s Pearsonovo korelacijo s človeškimi oznakami. Nedavni modeli QE so dosegli prej nevidne stopnje korelacije s človeškimi presojami, vendar se zanašajo na velike večjezične kontekstualizirane jezikovne modele, ki so računalniško dragi in jih naredijo neizvedljivi za aplikacije v realnem svetu. V tem delu smo ocenili več tehnik kompresije modelov za QE in ugotovili, da kljub njihovi priljubljenosti pri drugih nalogah NLP vodijo do slabe zmogljivosti v tej regresijski nastavitvi. Opazujemo, da je za dosego rezultatov SoTA v regresijski nalogi potrebna popolna parametrizacija modela. Vendar pa trdimo, da raven izraznosti modela v neprekinjenem obsegu ni potrebna glede na nadaljnje aplikacije QE, in pokažemo, da bi preoblikovanje QE kot problem razvrščanja in vrednotenje modelov QE z uporabo klasifikacijskih metrik bolje odražalo njihovo dejansko uspešnost v aplikacijah realnega sveta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Qiimeynta qalabka qiyaastiisa (QE) ee turjumaadda machine waa sida shaqada regression, waxaana lagu qiyaasaa tusaalaha QE sida caadiga ah loo qiyaasay Pearson oo la xiriira calaamadaha dadka. Tusaalooyinka QE waxay gaadheen heerarka hore oo aan la arkaynin ee la xiriira xukummada dadka, laakiin waxay isku halleeyaan tusaalooyin badan oo luuqadaha kala duduwan oo xisaabta qaali ah, waxayna ka dhigaan kuwa aan dhibaataysan codsiga caalamiga ah. Markaas waxan, waxaynu qiimeynaynaa qalabka hoos-dhigista ee QE, waxaana helaynaa in kastoo ay popularity ku leeyihiin shaqaalaha kale ee NLP, waxay ku hogaansamaan tababar miskiin ah marka loo sameeyo qorsheyntan. Waxaynu aragnaa in lagu baahan yahay qaab sameynta oo dhan si uu SoTA u gaadho uu u sameeyo shaqada dib u celinta. Si kastaba ha ahaatee waxaynu ka fekeraynaa in heerka muusikada daboolka oo joogtada ah looma baahna in la siiyo codsiyada QE-ka hooseeya, waxaana tusinayaa in QE-ka dhigista dhibaato fasax ah iyo qiimeynaya modelalka QE-ka isticmaalka midibka fasaxa waxaa haboon in ay ka fikiraan muuqashadooda dhabta ah ee lagu sameeyo codsiyada caalamiga ah.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vlerësimi i kualitetit në nivelin e gjykimeve (QE) i përkthimit të makinës është formuluar tradicionalisht si një detyrë regresive dhe performanca e modeleve QE vlerësohet tipikisht nga korrelacioni i Pearsonit me etiketat njerëzore. Modelet e fundit të QE kanë arritur nivele korrelacioni të padukshme më parë me gjykimet njerëzore, por ato mbështeten në modele të mëdha gjuhësh të kontekstualizuara shumëgjuhësore që janë llogarisht të shtrenjta dhe i bëjnë të papërshtatshëm për aplikimet e botës reale. Në këtë punë, ne vlerësojmë disa teknika të kompresimit të modelit për QE dhe zbulojmë se pavarësisht nga popullariteti i tyre në detyra të tjera NLP, ato shpien në performancë të dobët në këtë ambient regresioni. Ne vëzhgojmë se një parametrizim i plotë i modelit është i nevojshëm për të arritur rezultatet e SoTA në një detyrë regresive. However, we argue that the level of expressiveness of a model in a continuous range is unnecessary given the downstream applications of QE, and show that reframing QE as a classification problem and evaluating QE models using classification metrics would better reflect their actual performance in real-world applications.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Procjenjivanje kvalitete kazne (QE) prevoda mašine je tradicionalno formulisano kao zadatak regresije, a provedba modela QE obično se mjera od korelacije Pearsona sa ljudskim etiketama. Skorašnji QE modeli su postigli previše nevidljive nivoe korelacije sa ljudskim osuđivanjima, ali se oslanjaju na velike multijezičke kontekstualizacije jezičkih modela koji su kompjuterski skupi i čine ih nevidljivim za realne aplikacije. U ovom poslu, procjenjujemo nekoliko modela tehnika kompresije za QE i otkrijemo da, uprkos njihovoj popularnosti u drugim zadacima NLP-a, oni vode do lošeg izvođenja u ovom regresiji. Primišljamo da je potrebna puna modelna parameterizacija za ostvarivanje SoTA rezultata u zadatku regresije. Međutim, tvrdimo da je nivo izrazitosti model a u kontinualnom rasponu nepotrebno s obzirom na sledeće aplikacije QE-a, i pokazujemo da reframiranje QE kao problem klasifikacije i procjena modela QE koristeći klasifikacijske metrike bolje odražava njihovu stvarnu funkciju u realnim aplikacijama.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kvalitetsuppskattning (QE) av maskinöversättning formuleras traditionellt som en regressionsuppgift, och prestandan hos QE-modeller mäts vanligtvis genom Pearson korrelation med mänskliga etiketter. Nya QE-modeller har uppnått tidigare okända nivåer av korrelation med mänskliga bedömningar, men de förlitar sig på stora flerspråkiga kontextuella språkmodeller som är beräkningsmässigt dyra och gör dem omöjliga för verkliga tillämpningar. I detta arbete utvärderar vi flera modellkomprimeringstekniker för QE och upptäcker att de, trots deras popularitet i andra NLP-uppgifter, leder till dålig prestanda i denna regressionsinställning. Vi observerar att en fullständig modellparametrering krävs för att uppnå SoTA resultat i en regressionsuppgift. Vi hävdar dock att nivån på uttrycksfullhet hos en modell i ett kontinuerligt intervall är onödig med tanke på efterföljande tillämpningar av QE, och visar att omdefiniering av QE som ett klassificeringsproblem och utvärdering av QE-modeller med hjälp av klassificeringsmetoder bättre skulle återspegla deras faktiska prestanda i verkliga applikationer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Takwimu ya kiwango cha kiwango cha hukumu (QE) ya tafsiri ya mashine imetengenezwa kwa kawaida kama kazi ya kudhibiti, na utendaji wa miundo mbinu za QE kwa kawaida unapimiwa na Pearson kuhusiana na mabango ya binadamu. Mradi wa hivi karibuni wa QE umepata kiwango ambacho hakifikiri kilichopita cha kuhusiana na maamuzi ya binadamu, lakini wanategemea mifano makubwa ya lugha za lugha ambazo ni ghali kwa hisabati na kuwafanya hivyo kuwa na madhara kwa matumizi halisi ya dunia. Katika kazi hii, tunatathmini mbinu kadhaa za kompyuta za kisasa kwa ajili ya QE na tunagundua kwamba, pamoja na umaarufu wao katika kazi nyingine za NLP, wanapelekea utendaji mdogo katika mazingira haya ya ukandamizaji. Tunaona kuwa upasuaji wa mifano kamili unahitajika kupata matokeo ya SoTA katika kazi ya upinzani. However, we argue that the level of expressiveness of a model in a continuous range is unnecessary given the downstream applications of QE, and show that reframing QE as a classification problem and evaluating QE models using classification metrics would better reflect their actual performance in real-world applications.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>கணினி மொழிபெயர்ப்பின் வாக்கு- நிலையின் தரம் மதிப்பு (QE) பாரமிக்கப்பட்டுள்ளது மறும் QE மாதிரிகளின் செயல்பாடு மனித சிட்டைகளுடன் இணைப்பாக அளவிடப்படுக சமீபத்தில் QE மாதிரிகள் முன்னால் மறைக்கப்படாத மட்டத்தில் மனித விதிப்புகளுடன் தொடர்புடைய நிலைகளை அடைந்துவிட்டன, ஆனால் அவர்கள் பெரிய மொழி பாதிக்கப்பட்ட மாதி இந்த வேலையில், நாம் QE க்கான பல மாதிரி சுருக்கும் தொழில்நுட்பத்தை மதிப்பீடு செய்கிறோம் மற்றும் NLP பணிகளில் அவர்களுடைய மகிழ்ச்சியை நாம் பார்க்கிறோம் ஒரு முழு மாதிரி அளபுருவை சோடா முடிவு செய்ய வேண்டும் என்று. ஆனால், நாம் தொடர்ந்து வரையில் ஒரு மாதிரியின் வெளிப்பாட்டின் நிலையின் தேவையான கியூயியின் கீழே நீர் பயன்பாடு</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Maşynyň terjimesiniň derejesi Quality Taýýarlama (QE) Ýakynda QE nusgalary öňünden görä görä görünmeden adamlaryň judgamlary bilen ylalaşyk derejesine ýetip bardylar, ýöne olar kalkularyň has baglany ýagdaýda örän uly dil nusgalaryna ynanýarlar we olary hakyky dünýäde uygulamalar üçin iň ýaramaz bolýarlar. Bu işde biz QE üçin birnäçe nusga hasaplanjak tekniklerini deňleýäris we bular, başga NLP işlerinde tanyşyklarynyň ýöne, ol regressiýa düzeninde erbet etmäge sebep edýärler. Biz SoTA netijesini regresiýa buýrukynda ýetmek üçin tam nusga parameteriýasynyň gereklidigini gözləýäris. Ýöne, biz düzgün bir görnüşde bir nusgyň özüniň görnüşiniň derejesi QE'iň a şaky uygulamalaryna gerek däldir we QE nusgasyny klasifikasyýa meselesi hökmünde çykarmak we klasifikasyýa metriklerden ullanýan nusgasyny gowurak dünýä uygulamalarynda gözleýändigini görkeýäris.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ماشین کی ترجمہ کی سنت-سطح کی کیفیت کا ارزش (QE) کو سنتی طور پر ریگرس کے کام کے طور پر فرمول کیا جاتا ہے، اور QE نمڈلوں کی عملکرد عمدہ طور پر پررسون کی نسبت انسان لیبل کے ساتھ اندازہ کیا جاتا ہے. اچھی QE موڈلے پہلے لوگوں کے فیصلے کے ساتھ غیر دیکھے سطح کی تعلق پہنچ چکے ہیں، لیکن وہ بہت سی زبان کی متوسط زبان موڈلے پر بھروسہ رکھتے ہیں جو کامپیوتروں سے گران ہیں اور ان کو حقیقی دنیا کی کاربریوں کے لئے ناپسند بناتے ہیں. اس کام میں ہم نے QE کے لئے چند موڈل کمپرس ٹیکنیک کا ارزش کیا ہے اور یہ دیکھتے ہیں کہ ان کے علائم دوسرے NLP کے کاموں میں ان کے علائم بھی ہیں، وہ اس رسرسوائی تنظیمات میں کمزور عملکرد تک پہنچاتے ہیں۔ ہم دیکھتے ہیں کہ ایک پورا موڈل پارامتریزی کی ضرورت ہے سوٹا کا نتیجہ ایک دوسری روش کا کام پہنچانے کے لئے۔ لیکن ہم argue that the level of expressiveness of a model in a continuous range is unnecessary given to the downstream applications of QE, and show that QE reframing as a classification problem and evaluating QE models using classification metrics would better reflect their actual performance in real-world applications.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Name Yaqinda QE modellari odamlar bilan bog'liq bo'lgan odamlar darajaga yetishdi, lekin ular hisoblash qiymatida qiymati bo'lgan katta tillar modellariga ishlatadi va ularni halik dunyo dasturlari uchun qo'llanmagan. Bu ishda biz QE uchun bir necha model kompyuterni qiymatimiz va boshqa NLP vazifalarida jamiyatlarni ko'rib chiqarishimiz mumkin va ular bu boshqa narsalarning ko'proq bajarishga ega bo'ladi. We observe that a full model parameterization is required to achieve SoTA results in a regression task. Lekin biz murakkab qilamiz, davom etilgan modelning darajasi QE dasturlari kerak emas, va QE dasturlarini tasdiqlash muammosi deb ko'rsatish mumkin va klassifik metrikalarni yordamida QE modellarini qiymatish mumkin, ularning haliy dunyo dasturlarida ishlashning jarayonlarini tasavvur qilishi kerak.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bộ đánh giá cấp đánh giá chất lượng (QE) của bộ dịch cỗ máy thường được phát triển như một nhiệm vụ hồi phục, và khả năng ứng dụng của mô hình QE thường được đo bằng cách so sánh giữa Pearson và nhãn con người. Những mô hình QE gần đây đã đạt được mức độ tương quan không ai thấy trước đây với phán quyết con người, nhưng chúng dựa trên các mô hình ngôn ngữ ngữ ngữ ngữ ngữ ngữ ngữ ngữ ngữ ngữ ngữ ngữ ngữ rộng lớn, Tính đắt đỏ và khiến chúng không thể thực tế được. Trong công việc này, chúng tôi đánh giá các kỹ thuật nén mô hình cho Qt và tìm thấy rằng, mặc dù họ nổi tiếng trong các công việc Njala khác, chúng có hiệu quả kém trong môi trường phục hồi. Chúng tôi lưu ý rằng cần thiết một mô phỏng bằng phương pháp đo lường đầy đủ để đạt được thành quả của SothA ở nhiệm vụ phục hồi. Tuy nhiên, chúng tôi cho rằng mức độ biểu lộ của mô hình trong phạm vi liên tục là không cần thiết với các ứng dụng phụ của năng lượng QE, và cho thấy rằng chất QE khúc xạ như một vấn đề phân hạng và đánh giá mô hình QE sử dụng thiết lập cấp độ phân hạng sẽ phù hợp hơn với khả năng thực tại của chúng trong các ứng dụng thế giới thực.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>古者,机器翻译之句(QE)度为归任,QE形之性常以Pearson与人相关性。 近者QE已成前所未见者,与人相关性平,然其依于多言上下文语,成本于算,而不可于用。 凡此诸事,估QE数形压缩术,虽在他NLP甚受欢迎,归置中致不佳。 吾观其归 SoTA 而须全形参数化。 然吾以为鉴于QE之下流,连范围模型之表现力水平不足,明将QE更为分类而用分类指标评估QE形将益见其实用之实也。</span></div></div><dl><dt>Anthology ID:</dt><dd>2021.emnlp-main.474</dd><dt>Volume:</dt><dd><a href=/volumes/2021.emnlp-main/>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></dd><dt>Month:</dt><dd>November</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Online and Punta Cana, Dominican Republic</dd><dt>Venue:</dt><dd><a href=/venues/emnlp/>EMNLP</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>5865–5875</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.emnlp-main.474>https://aclanthology.org/2021.emnlp-main.474</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/2021.emnlp-main.474 title="To the current version of the paper by DOI">10.18653/v1/2021.emnlp-main.474</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">sun-etal-2021-classification</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Shuo Sun, Ahmed El-Kishky, Vishrav Chaudhary, James Cross, Lucia Specia, and Francisco Guzmán. 2021. <a href=https://aclanthology.org/2021.emnlp-main.474>Classification-based Quality Estimation : Small and Efficient Models for Real-world Applications</a>. In <i>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</i>, pages 5865–5875, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2021.emnlp-main.474>Classification-based Quality Estimation : Small and Efficient Models for Real-world Applications</a> (Sun et al., EMNLP 2021)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.emnlp-main.474.pdf>https://aclanthology.org/2021.emnlp-main.474.pdf</a></dd><dt>Data</dt><dd><a href=https://paperswithcode.com/dataset/mlqe-pe>MLQE-PE</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.emnlp-main.474.pdf title="Open PDF of 'Classification-based Quality Estimation : Small and Efficient Models for Real-world Applications'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Classification-based+Quality+Estimation+%3A+Small+and+Efficient+Models+for+Real-world+Applications" title="Search for 'Classification-based Quality Estimation : Small and Efficient Models for Real-world Applications' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Classification-based Quality Estimation : Small and Efficient Models for Real-world Applications'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Classification-based Quality Estimation : Small and Efficient Models for Real-world Applications](https://aclanthology.org/2021.emnlp-main.474) (Sun et al., EMNLP 2021)</p><ul class=mt-2><li><a href=https://aclanthology.org/2021.emnlp-main.474>Classification-based Quality Estimation : Small and Efficient Models for Real-world Applications</a> (Sun et al., EMNLP 2021)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Shuo Sun, Ahmed El-Kishky, Vishrav Chaudhary, James Cross, Lucia Specia, and Francisco Guzmán. 2021. <a href=https://aclanthology.org/2021.emnlp-main.474>Classification-based Quality Estimation : Small and Efficient Models for Real-world Applications</a>. In <i>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</i>, pages 5865–5875, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>