<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Parsing Argumentative Structure in English-as-Foreign-Language EssaysEnglish-as-Foreign-Language Essays - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Parsing Argumentative Structure in English-as-Foreign-Language EssaysEnglish-as-Foreign-Language Essays" name=citation_title><meta content="Jan Wira Gotama Putra" name=citation_author><meta content="Simone Teufel" name=citation_author><meta content="Takenobu Tokunaga" name=citation_author><meta content="Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications" name=citation_conference_title><meta content="2021/4" name=citation_publication_date><meta content="https://aclanthology.org/2021.bea-1.10.pdf" name=citation_pdf_url><meta content="97" name=citation_firstpage><meta content="109" name=citation_lastpage><meta property="og:title" content="Parsing Argumentative Structure in English-as-Foreign-Language EssaysEnglish-as-Foreign-Language Essays"><meta property="og:image" content="https://aclanthology.org/thumb/2021.bea-1.10.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2021.bea-1.10"><meta property="og:description" content="Jan Wira Gotama Putra, Simone Teufel, Takenobu Tokunaga. Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications. 2021."><link rel=canonical href=https://aclanthology.org/2021.bea-1.10></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2021.bea-1.10.pdf>Parsing Argumentative Structure in English-as-Foreign-Language Essays<span class=acl-fixed-case>E</span>nglish-as-Foreign-Language Essays</a>
<a id=af_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Verwerking Argumentatiewe struktuur in Engels-as-Foreign-Language Essays</a>
<a id=am_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>አርማኔት</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>تحليل البنية الجدلية في مقالات اللغة الإنجليزية كلغة أجنبية</a>
<a id=az_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>İngilizce-as-Foreign-Language Essays olaraq Argumentative Structure analizə edilir</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Разглеждане на аргументативната структура в английски-чуждоезикови есета</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>ইংরেজি- as-পররাষ্ট্র ভাষায় আর্গুমেন্টিভ ক্ষেত্র পার্সিং করা হচ্ছে</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Parsing Argumentative Structure in English-as-Foreign-Language Essays</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Parsing Argumentative Structure in English-as-Foreign-Language Essays</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Analitzar l'estructura argumentativa en els exàmens anglès-com-estranger</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Analýza argumentativní struktury v esejích angličtiny jako cizího jazyka</a>
<a id=da_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Parsing Argumentative Structure in English-as-Foreign-Language Essays</a>
<a id=de_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Analyse der argumentativen Struktur in englischsprachigen Essays</a>
<a id=el_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Ανάλυση της επιχειρηματολογικής δομής σε δοκίμια αγγλικής ως ξένης γλώσσας</a>
<a id=es_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Análisis de la estructura argumentativa en ensayos de inglés como lengua extranjera</a>
<a id=et_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Argumentatiivse struktuuri parsimine inglise keelena võõrkeelsetes esseetes</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>تحلیل ساختار Argumentative in English-as-Foreign-Language Essays</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Argumentatiivisen rakenteen jäsentäminen englanninkielisissä esseissä</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Analyse De La Structure Argumentative En Anglais Langue Étrangère Essais</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Struchtúr Argóinteach a Pharsáil i mBéarla-mar-Earrach-Aistí</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>KCharselect unicode block name</a>
<a id=he_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>מעבדת מבנה מסכים במבחנים בשפה זרה אנגלית</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>पार्सिंग तर्कपूर्ण संरचना में अंग्रेजी के रूप में विदेशी भाषा निबंध</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Parsing Argumentative Structure in English-as-Foreign-Language Essays</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Argumentatív struktúra értelmezése angol mint idegen nyelvű esszékben</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Արգեմենտատիվ կառուցվածքը վերլուծում անգլերեն-որպես-արտաքին-լեզվի թեսսերում</a>
<a id=id_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Menganalisis Struktur Argumentatif dalam Ujian Bahasa Inggris-sebagai-Bahasa asing</a>
<a id=is_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Parsing Argumentative Structure in English-as-Foreign-Language Essays</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>英語と外国語のエッセイにおける議論構造の解析</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Parasing argument structural in French-as-Remote-Language Associations</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>აპდუმენტეტიური სტრუქტურაცია ანგლისური-as-Foreign-Language Essays</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Аргументтік құрылғыны ағылшын тілінде талдау</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>영어 의논문 의논문 구조 해석</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Argumentacinės struktūros analizavimas anglų kalbos testuose</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Аргументација на аргументативната структура во тестовите на англиски како странски јазик</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>ഇംഗ്ലീഷ്- as- വിദേശ- ഭാഷ എസ്സില്‍ അര്‍ഗമെന്റിവ് സ്ട്രൂട്ടേറ്റ്</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Parsing Argumentative Structure in English-as-Foreign-Language Essays</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Menghurai Struktur Argumentatif dalam Ujian Bahasa Inggeris-sebagai-Luar-Bahasa</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Parsing Argumentative Structure in English-as-Foreign-Language Essays</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Analyse van argumentatieve structuur in essays over Engels als vreemde taal</a>
<a id=no_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Tolking av argumentativ struktur i engelsk-as-Foreign-Language Essays</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Analiza struktury argumentatywnej w esejach o języku angielskim jako obcym</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Analisando a estrutura argumentativa em ensaios de inglês como língua estrangeira</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Analizarea structurii argumentative în eseurile de limbă engleză ca limbă străină</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Анализ аргументативной структуры в эссе на английском и иностранном языках</a>
<a id=si_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>ප්‍රශ්ණාත්මක සංස්කරණය ඉංග්‍රීසිය-as-බාර්ජික-භාෂාවයේ ප්‍රශ්ණය</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Razdelava argumentativne strukture v angleškem jeziku kot tujem jeziku</a>
<a id=so_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Barsashada jardiinada hagitaanka ku qoran Ingiriis-as-Foreign-language Essays</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Parsing Argumentative Structure in English-as-Foreign-Language Essays</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Parsing Argumentative Structure in English-as-Foreign-Language Essays</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Tolkning av argumentativ struktur i engelska-som-främmande-språk essäer</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Mradi wa Kiingereza kwa lugha ya Kigeni na Kigeni Essa</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>ஆங்கிலம்- as- Foreign- Language Essays</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Argumentatik Structure in English-as-Foreign-Language Essays</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>انگلیسی-as-Foreign-Language Essays میں آرگومنٹیٹ ساختاری پارسینگ</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Name</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>Cấu trúc Argumentive in English-as-Foreign-Language Essays</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2021.bea-1.10.pdf>解析英语为外语论文证结</a></h2><p class=lead><a href=/people/j/jan-wira-gotama-putra/>Jan Wira Gotama Putra</a>,
<a href=/people/s/simone-teufel/>Simone Teufel</a>,
<a href=/people/t/takenobu-tokunaga/>Takenobu Tokunaga</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy. The <a href=https://en.wikipedia.org/wiki/Parsing>parsing process</a> consists of two steps, linking related sentences and then labelling their relations. We experiment with several deep learning architectures to address each <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a> independently. In the sentence linking task, a biaffine model performed the best. In the relation labelling task, a fine-tuned BERT model performed the best. Two sentence encoders are employed, and we observed that non-fine-tuning models generally performed better when using Sentence-BERT as opposed to BERT encoder. We trained our models using two types of parallel texts : original noisy EFL essays and those improved by annotators, then evaluate them on the original <a href=https://en.wikipedia.org/wiki/Essay>essays</a>. The experiment shows that an end-to-end in-domain system achieved an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of.341. On the other hand, the cross-domain system achieved 94 % performance of the in-domain system. This signals that well-written texts can also be useful to train argument mining system for noisy texts.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Hierdie papier stel 'n studie op die verwerking van die argumentatiewe struktuur in Engelske as-vreemde-taal (EFL) essays, wat inherent geluid is. Die verwerking proses bestaan van twee stappe, verbind verwante setnings en dan etiket hulle verwante. Ons eksperimenteer met verskeie diep leer arkitektuur om elke taak onveilig te adres. In die seting wat die taak verbind het, het 'n biaffine model die beste uitgevoer. In die verwanting etiketting taak, het 'n fyn- tuned BERT model die beste uitgevoer. Twee setkoders word gebruik, en ons het aanhou dat nie-fin-tuning-modele generelik beter uitgevoer het wanneer Sentence-BERT gebruik word as teen BERT-koder. Ons het ons modele opgelei met twee tipes parallele teks: oorspronklike geluide EFL eseë en die wat deur annotators verbeter is, dan evalueer hulle op die oorspronklike eseë. Die eksperiment vertoon dat 'n end- to- end in- domain stelsel ' n presies van .341 bereik het. Op die ander kant het die kruisdomein stelsel 94% effektuur van die in-domein stelsel bereik. Hierdie signale wat goed geskrywe teks ook nuttig kan wees om argument mining stelsel te tref vir geluide teks.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ይህ ገጽ የኢንጂልኛ-እንደ እንግዳ ቋንቋ (EFL) የግል ቋንቋ-ቋንቋ-የቋንቋ-ቋንቋን የግንኙነት አካባቢ ግንኙነትን ማግኘት የሚያስፈልገውን ትምህርት ያቀርባል፡፡ የፓርላማው ፕሮጀክት ሁለት ደረጃዎች ነው፣ የግንኙነት ቃላትን እና ግንኙነታቸውን በማሳመር ነው፡፡ ለሁሉም ስራ ነፃ ለማነጋገር በብዙ ጥልቅ ትምህርት መሠረታዎችን እናሞክራለን፡፡ በቁጥጥር የሚታያየው ስራ፣ የፊፊን ሞዴል የተሻለ ነው፡፡ በተግባር ስራ ላይ የተሻለ የBERT ሞዴል የተሻለ ነው፡፡ ሁለትም የፍርድ የፊደል ቀለሞች ይሞክራሉ፣ የBERT ኮድ በተቃወመ ጊዜ የፍርድ-BERT ኮድ በተደረገ ጊዜ የተሻለ የፊደል ሞዴል እንደተደረገ አየን፡፡ የሁለት ዓይነት መልዕክቶች በተለያዩ ጽሑፎችን አስተማርነው፤ የኢ.አ.አ.አ.ለ.አ.ለ.አ.አ.ለ.አ.አ.አ.ለ.አ.አ.አ.አ.አ.አ.ለ.አ.አ.አ. The experiment shows that an end-to-end in-domain system achieved an accuracy of .341. በሌላው ክፍል የዶሜን ስርዓት 94 በመቶ ድምፅ አግኝቷል፡፡ ይህች ሲልክ መልካም የተጻፈ ጽሑፎች እና የድምፅ ጽሑፎችን ለመጠቀም የአጋራጆች ዋና ማጭበር ሲስተም ይጠቅማል፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>تقدم هذه الورقة دراسة حول تحليل البنية الجدلية في مقالات اللغة الإنجليزية كلغة أجنبية (EFL) ، والتي هي بطبيعتها صاخبة. تتكون عملية التحليل من خطوتين ، ربط الجمل ذات الصلة ثم تصنيف العلاقات بينهما. نجرب العديد من بنيات التعلم العميق لمعالجة كل مهمة على حدة. في مهمة ربط الجملة ، كان أداء نموذج بيافيني هو الأفضل. في مهمة وضع العلامات على العلاقة ، كان أداء نموذج BERT الدقيق هو الأفضل. يتم استخدام جملتين من التشفير ، ولاحظنا أن النماذج غير الدقيقة كانت تؤدي بشكل عام أداءً أفضل عند استخدام Sentence-BERT بدلاً من مشفر BERT. قمنا بتدريب نماذجنا باستخدام نوعين من النصوص المتوازية: مقالات اللغة الإنجليزية كلغة أجنبية الصاخبة الأصلية وتلك التي تم تحسينها بواسطة المعلقين ، ثم قم بتقييمهم على المقالات الأصلية. تُظهر التجربة أن نظام النطاق الشامل قد حقق دقة 341. من ناحية أخرى ، حقق النظام عبر المجال أداء 94٪ للنظام داخل المجال. يشير هذا إلى أن النصوص المكتوبة جيدًا يمكن أن تكون مفيدة أيضًا في تدريب نظام التنقيب عن الحجج للنصوص المزعجة.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bu kağıt İngilis dilində-Dışarı dilində (EFL) essaylarında müzakirçi strukturlarını ayırmaq haqqında bir təhsil göstərir. Analizasyon prosesi iki adımdır, əlaqəsiz cümlələri bağlayır və sonra onların əlaqələrini etiketləyir. Biz hər işi təmizlə çəkmək üçün çox derin öyrənmə arhitektarlarıyla imtahana çəkirik. İşləri bağlayıb cümlədə, bir biafin modeli ən yaxşı işlədi. İlişkisi etiketləmə işində, BERT modeli ən yaxşı işlədi. İki cümləlik kodlayıcısı istifadə edilir, və biz BERT kodlayıcısı ilə əlavə etdikdə çox yaxşı işlədiklərini gördük. Biz modellərimizi iki türü paralel metin vasitəsilə təhsil etdik: orijinal səslü EFL essayları və annotatorların təhsil edilənlər, sonra onları orijinal essaylarda təhsil edirik. Bu təcrübə göstərir ki, domeinin sonu-sonu sisteminin .341 dəqiqliyinə nail oldu. Digər tərəfindən, çox domena sistemi domena sisteminin 94% performansını qəbul etdi. Bu sinyallər, yaxşı yazılmış mətnlər də səsl mətnlər üçün arqümət madenci sistemini təhsil etmək üçün faydalı olar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Настоящата статия представя проучване за анализиране на аргументативната структура в есетата на английски като чужд език (ЕФЛ), които по своята същност са шумни. Процесът на анализиране се състои от две стъпки, свързване на свързаните изречения и след това етикетиране на техните взаимоотношения. Експериментираме с няколко архитектури за дълбоко обучение, за да се справим самостоятелно с всяка задача. В задачата за свързване на изречения биафинов модел се представи най-добре. В задачата по отношение на етикетирането най-добре се представи фино настроеният модел BERT. Използват се два кодера на изречения и забелязахме, че моделите с нефина настройка обикновено се представят по-добре при използване на кодера за разлика от кодера за изречение. Обучихме моделите си, използвайки два типа паралелни текстове: оригинални шумни есета и тези подобрени с анотатори, след което ги оценяваме на оригиналните есета. Експериментът показва, че система от край до край е постигнала точност от 0,341. От друга страна, междудомейнната система постига 94% производителност на вътрешната система. Това сигнализира, че добре написаните текстове също могат да бъдат полезни за обучение на система за аргументи за шумни текстове.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>এই পত্রিকাটি ইংরেজী হিসেবে বিদেশী ভাষায় যুক্তিগত কাঠামো পার্স করার বিষয়টি একটি গবেষণা উপস্থাপন করেছে, যা অন্তর্ভুক্ত শব্দ। পার্সিং প্রক্রিয়ার মধ্যে দুই পদক্ষেপ রয়েছে, যার সাথে সম্পর্কিত শাস্তি লিঙ্ক করে এবং তারপর তাদের সম্পর্কের আমরা বেশ কয়েকটি গভীর শিক্ষা শিক্ষা প্রতিটি কাজের স্বাধীন ভাবে কথা বলার পরীক্ষা করছি। এই বাক্যে লিঙ্ক করা কাজে একটি বিফিন মডেল সবচেয়ে ভালো করেছে। সম্পর্কের ল্যাবেলিং কাজের মধ্যে একটি ভালো ভালো ভালো ভাবে বেরেট মডেল শুরু করেছে। দুই শাস্তি এনকোডার ব্যবহার করা হয়েছে এবং আমরা দেখেছি যে শাস্তি বিবের্ট এনকোডার বিরুদ্ধে ব্যবহার করার বিরুদ্ধে সাধারণত ভালো কাজ করা ন আমরা আমাদের মডেল দুটি ধরনের প্যারালেল লেখা ব্যবহার করে প্রশিক্ষণ প্রশিক্ষণ দিয়েছি: প্রাথমিক শব্দ ইএফএল প্রসেস এবং যারা শিক্ষার্থীদের এই পরীক্ষাটি দেখাচ্ছে যে ডোমেইনের শেষ পর্যন্ত শেষ ব্যবস্থা সঠিকভাবে পৌঁছেছে। অন্যদিকে, ক্রিস্ট ডোমেইন সিস্টেমের ৯৪% পালন করেছে। এই সিগন্যালটি দেখাচ্ছে যে ভাল লিখিত লেখাগুলো শব্দ লেখার জন্য যুক্ত মিনিং সিস্টেম প্রশিক্ষণের জন্যে উপ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ཤོག་བྱང་འདིས་ཨིན་ཡིག་གི་སྐད་ཡིག་ནང་གི་སྒྲུབ་གཏོང་གི་བཟོ་བསམ་ཞིག་བྱེད་སྐབས་ལྟ་བུ་མངོན་འཆར་ཡོད། དབྱེ་ཞིབ་ཀྱི་ལས་སྦྱོར་དེའི་གྲལ་ཐེངས་གཉིས་ལས་འབྲེལ་བ་ཡིན་པའི་ཚིག་རྟགས་དང་ཁོང་གི་འབྲེལ་བ ང་ཚོས་རེ་བོ་སོ་སོའི་ལས་འགུལ་གྱི་ཁྱད་ཆོས་སོ་སོའི་བཟོ་བརྩིས་གཞི་འདྲ་བྱེད་མ་ཐུབ། ཚིག མཐུན་འབྲེལ་གྱི་ཤོག་བྱང་ཀི་ལས་འགུལ་གྱི་ནང་དུ། ཚད་ལྡན་པའི་BERT མིག་དཔེ་ཞིག་ནི་སྐྱོན་ཤོས་ཡོད། ཚིག ང་ཚོས་མིག་གཟུགས་རིས་འདི་དག་གི་དབྱེ་བ་གཉིས་དབྱེ་བ་གི་ཡིག སྒེར་ཞུ་གིས་domain་ཐོག་མཐའ་མཇུག་གསུམ་དུ་མཐོང་བ་ཡིན།341 On the other hand, the cross-domain system achieved 94% performance of the in-domain system. This signals that well-written texts can also be useful to train argument mining system for noisy texts.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ovaj papir predstavlja studiju o razmatranju argumentativne strukture na esejima engleskog kao stranog jezika (EFL), koje su inherentno bučne. Proces analize se sastoji od dva koraka, povezujući povezane rečenice i onda označavajući njihove odnose. Eksperimentiramo sa nekoliko dubokih arhitektura učenja da se riješimo svakom zadatku nezavisno. U rečenici povezujući zadatak, model biafina je izvršio najbolje. U zadatku označavanja odnosa, dobro određeni model BERT izvršio je najbolje. Dva kodera rečenice su zaposlena, a mi smo primijetili da modeli koji nisu ispravni, obično su bolje izvršili kada su koristili kaznu-BERT u suprotnosti sa koderom BERT-a. Obučavali smo naše modele koristeći dvije vrste paralelnih tekstova: originalne bučne EFL eseje i one koje su poboljšale annotatori, a onda ih procjenjivali na originalnim esejima. Eksperiment pokazuje da je sistem kraja do kraja u domenu postigao tačnost od .341. S druge strane, sistem krstodomena postigao je 94% učinkovitosti sustava u domenu. Ovi signali su da dobro napisani teksti mogu biti korisni i za treniranje rudarskog sustava argumenta za bučne tekstove.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Aquest paper presenta un estudi sobre l'analització de l'estructura argumentativa en els assats anglès-com-estrangers (EFL), que són inherentment sorollosos. El procés d'analització consisteix en dos passos, enllaçant frases relacionades i etiquetant les seves relacions. Experimentem amb diverses arquitectures d'aprenentatge profund per abordar cada tasca de manera independent. In the sentence linking task, a biaffine model performed the best. En la tasca d'etiquetar les relacions, un model BERT ajustat va fer el millor. S'utilitzen dos codificadors de frases, i vam observar que els models no fins ajustes generalment van funcionar millor quan utilitzen Sentence-BERT en comptes del codificador BERT. Vam treinar els nostres models fent servir dos tipus de textos parallels: els assaig original sorollós EFL i els millorats pels anotators, i després els vam evaluar en els assaig originals. L'experiment mostra que un sistema de domini final a final va aconseguir una precisió de .341. D'altra banda, el sistema transdomínic va aconseguir un 94% de rendiment del sistema intradomínic. Això indica que els textos ben escrits també poden ser útils per entrenar el sistema de mineria d'arguments per a textos ruidosos.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tento článek představuje studii o analýze argumentativní struktury v esejích angličtiny jako cizího jazyka (EFL), které jsou z podstaty hlučné. Proces parsování se skládá ze dvou kroků, propojení souvisejících vět a následně označení jejich vztahů. Experimentujeme s několika architekturami hlubokého učení, abychom řešili každý úkol nezávisle. Ve větě propojující úkol, biafinový model vedl nejlépe. Při úkolu označování vztahů nejlépe fungoval jemně vyladěný model BERT. Používají se dva snímače vět a pozorovali jsme, že modely bez jemného ladění většinou fungují lépe při použití Sentence-BERT než BERT snímač. Naše modely jsme trénovali pomocí dvou typů paralelních textů: originálních hlučných EFL esejí a těch, které vylepšují anotátory, a poté je vyhodnocují na originálních esejích. Experiment ukazuje, že end-to-end in-domain systém dosáhl přesnosti .341. Na druhou stranu, cross-domain systém dosáhl 94% výkonnosti in-domain systému. To signalizuje, že dobře napsané texty mohou být také užitečné pro trénink argument mining systému pro hlučné texty.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Denne artikel præsenterer en undersøgelse af analyse af argumentationsstrukturen i engelsk-som-fremmedsprog (EFL) essays, som i sig selv er støjende. Analyseprocessen består af to trin, der forbinder relaterede sætninger og derefter mærker deres relationer. Vi eksperimenterer med flere deep learning arkitekturer for at løse hver opgave uafhængigt. I sætningsforbindelsesopgaven klarede en biaffine model sig bedst. I forbindelse med mærkning af relationer klarede en finjusteret BERT-model sig bedst. Der anvendes to sætningskodere, og vi bemærkede, at ikke-finjusterende modeller generelt klarede sig bedre ved brug af Sentence-BERT i modsætning til BERT encoder. Vi trænede vores modeller ved hjælp af to typer parallelle tekster: originale støjende EFL essays og dem forbedret af kommentatorer, og derefter evaluere dem på de originale essays. Eksperimentet viser, at et end-to-end in-domain system opnåede en nøjagtighed på .341. På den anden side opnåede systemet på tværs af domæner 94% ydeevne af det in-domæne system. Dette signalerer, at velskrevne tekster også kan være nyttige til at træne argument mining system til støjende tekster.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Diese Arbeit stellt eine Studie zur Analyse der argumentativen Struktur in Englisch-als-Fremdsprache (EFL) Essays vor, die inhärent lauter sind. Der Parsing-Prozess besteht aus zwei Schritten, die verwandte Sätze verknüpfen und dann ihre Beziehungen kennzeichnen. Wir experimentieren mit mehreren Deep Learning Architekturen, um jede Aufgabe unabhängig zu lösen. In der Satzverknüpfungsaufgabe zeigte sich ein Biaffinmodell am besten. Bei der Beziehungsbeschriftung zeigte sich ein fein abgestimmtes BERT-Modell am besten. Es werden zwei Satzkodierer eingesetzt, und wir haben beobachtet, dass nicht-Feinabstimmungsmodelle im Allgemeinen besser abschneiden, wenn SatzBERT verwendet wird als BERT-Kodierer. Wir trainierten unsere Modelle mit zwei Arten von parallelen Texten: Original-geräuschvolle EFL-Essays und diejenigen, die durch Annotatoren verbessert wurden, und evaluieren sie dann auf den Originalessays. Das Experiment zeigt, dass ein End-to-End In-Domain System eine Genauigkeit von .341 erreicht hat. Auf der anderen Seite erzielte das domänenübergreifende System 94% Leistung des Domänensystems. Dies signalisiert, dass gut geschriebene Texte auch nützlich sein können, um Argument Mining System für laute Texte zu trainieren.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Η παρούσα εργασία παρουσιάζει μια μελέτη για την ανάλυση της επιχειρηματολογικής δομής σε δοκίμια αγγλικά-ως-ξένης γλώσσας (EFL), τα οποία είναι εγγενώς θορυβώδη. Η διαδικασία ανάλυσης αποτελείται από δύο βήματα, που συνδέουν σχετικές προτάσεις και στη συνέχεια επισημαίνουν τις σχέσεις τους. Πειραματιζόμαστε με διάφορες αρχιτεκτονικές βαθιάς μάθησης για να αντιμετωπίσουμε κάθε εργασία ανεξάρτητα. Στην εργασία σύνδεσης της πρότασης, ένα μοντέλο διφίνης πέτυχε το καλύτερο. Στην εργασία επισήμανσης σχέσης, ένα εκλεπτυσμένο μοντέλο πέτυχε καλύτερα. Χρησιμοποιούνται δύο κωδικοποιητές προτάσεων και παρατηρήσαμε ότι τα μοντέλα μη συντονισμού γενικά αποδίδουν καλύτερα όταν χρησιμοποιούν πρόταση-BERT σε αντίθεση με τον κωδικοποιητή BERT. Εκπαιδευτήκαμε τα μοντέλα μας χρησιμοποιώντας δύο τύπους παράλληλων κειμένων: πρωτότυπα θορυβώδη δοκίμια και αυτά που βελτιώθηκαν από σχολιαστές και μετά τα αξιολογήσαμε στα πρωτότυπα δοκίμια. Το πείραμα δείχνει ότι ένα ολοκληρωμένο σύστημα στον τομέα πέτυχε ακρίβεια .341. Από την άλλη πλευρά, το σύστημα μεταξύ τομέων πέτυχε 94% απόδοση του συστήματος εντός τομέα. Αυτό σηματοδοτεί ότι τα καλά γραπτά κείμενα μπορούν επίσης να είναι χρήσιμα για την εκπαίδευση του συστήματος εξόρυξης επιχειρημάτων για θορυβώδη κείμενα.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Este artículo presenta un estudio sobre el análisis de la estructura argumentativa en ensayos de inglés como lengua extranjera (EFL), que son inherentemente ruidosos. El proceso de análisis consta de dos pasos, vincular oraciones relacionadas y luego etiquetar sus relaciones. Experimentamos con varias arquitecturas de aprendizaje profundo para abordar cada tarea de forma independiente. En la tarea de vinculación de oraciones, un modelo biafín obtuvo el mejor rendimiento. En la tarea de etiquetado de relaciones, un modelo BERT ajustado fue el que mejor funcionó. Se emplean codificadores de dos oraciones, y observamos que los modelos sin ajuste fino generalmente funcionan mejor cuando se usa el codificador Sentence-BERT en lugar del codificador BERT. Entrenamos nuestros modelos utilizando dos tipos de textos paralelos: ensayos originales de EFL ruidosos y aquellos mejorados por anotadores, y luego los evaluamos en los ensayos originales. El experimento muestra que un sistema de dominio de extremo a extremo logró una precisión de .341. Por otro lado, el sistema entre dominios logró un rendimiento del 94% del sistema dentro del dominio. Esto indica que los textos bien escritos también pueden ser útiles para entrenar el sistema de minería de argumentos para textos ruidosos.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Käesolevas töös esitatakse uuring inglise kui võõrkeele esseede argumentatiivse struktuuri parsimise kohta, mis on olemuslikult lärmakad. Parsimisprotsess koosneb kahest etapist, sidudes seotud laused ja märgistades seejärel nende suhted. Me eksperimenteerime mitme sügavõppe arhitektuuriga, et iga ülesande lahendada iseseisvalt. Lausete sidumise ülesandes oli parim biafiin mudel. Märgistamisega seotud ülesande puhul oli parim tulemus täpsustatud BERTi mudel. Kasutatakse kahte lausekodeerijat ja täheldasime, et mittepeenhäälestuslikud mudelid toimivad üldiselt paremini Sentence-BERT kasutamisel kui BERT kodeerija. Koolitasime oma mudeleid kahte tüüpi paralleelsete tekstide abil: originaalsed mürakad EFL esseed ja parandatud annotatorid, seejärel hindame neid originaalsete esseede põhjal. Katse näitab, et domeenisisene süsteem saavutas täpsuse 0,341. Teisest küljest saavutas valdkondadevaheline süsteem 94% jõudluse valdkonnasisest süsteemist. See annab märku, et hästi kirjutatud tekstid võivad olla kasulikud ka argumentide kaevandamise süsteemi koolitamiseks mürakate tekstide jaoks.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>این کاغذ یک مطالعه در مورد بررسی ساختار مطمئنی در امتحان انگلیسی به عنوان زبان خارجی (EFL) را نشان می دهد که در اصل صدا است. فرایند جدا کردن از دو قدم است که جمله‌های ارتباطی را ارتباط می‌دهد و بعدش رابطه‌هایشان را برچسب می‌کند. ما با چند معماری عمیق یادگیری آزمایش می کنیم تا هر کار را به خصوصی بررسی کنیم. در جمله مرتبط کار، یک مدل طبیعی بهترین عمل کرد. در وظیفه برچسب ارتباط، یک مدل BERT خوب تنظیم شده بهترین عمل کرد. دو تنظیم‌کننده‌ی عبارت استفاده می‌شوند، و ما متوجه شدیم که مدل‌های غیر تنظیم‌کننده‌ای عموماً بهتر انجام می‌دهند وقتی استفاده از عبارت-BERT در مقابل رمز‌کننده BERT انجام می‌دهند. ما مدل‌هایمان را با استفاده از دو نوع متن parallel آموزش دادیم: رسی‌های صوتی EFL و آن‌ها که توسط آهنگ‌کنندگان بهتر شده‌اند، سپس آنها را در رسی‌های اصلی ارزیابی می‌کنیم. این آزمایش نشان می دهد که یک سیستم پایان و پایان در دومین دقیقاتی از .341 رسیده است. از طریق دیگر، سیستم‌های مختلف دامنه‌ای 94 درصد عملکرد سیستم دامنه‌ای را به دست آورد. این سیگنال‌ها که متن‌های خوب نوشته می‌توانند برای آموزش سیستم خریدن مدارک برای متن‌های صوتی استفاده کنند.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tämä artikkeli esittelee tutkimuksen argumentatiivisen rakenteen jäsentämisestä englanti vieraana kielenä -esseissä, jotka ovat luonnostaan meluisia. Analysointiprosessi koostuu kahdesta vaiheesta, jotka yhdistävät toisiinsa liittyvät lauseet ja merkitsevät niiden suhteet. Kokeilemme useita syväoppimisen arkkitehtuureja kunkin tehtävän käsittelemiseksi itsenäisesti. Lausekkeen linkitystehtävässä biafiinimalli suoriutui parhaiten. Suhteeseen merkitsemistä koskevassa tehtävässä parhaiten suoriutui hienosäädetty BERT-malli. Käytössä on kaksi lauseenkooderia, ja havaitsimme, että ei-hienosäätömallit suoriutuivat yleensä paremmin Sentence-BERT-kooderilla kuin BERT-kooderilla. Koulutimme mallit kahdentyyppisillä rinnakkaisilla teksteillä: alkuperäisillä noisy EFL esseillä ja kommentaattoreilla parannelluilla esseillä, minkä jälkeen arvioimme niitä alkuperäisillä esseillä. Koe osoittaa, että kokonaisvaltainen verkkotunnusjärjestelmä saavutti tarkkuuden 0,341. Toisaalta toimialojen välinen järjestelmä saavutti 94% suorituskykyä toimialojen sisäisestä järjestelmästä. Tämä osoittaa, että hyvin kirjoitetut tekstit voivat olla hyödyllisiä myös argumenttien louhintajärjestelmän kouluttamisessa meluisille teksteille.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Cet article présente une étude sur l'analyse de la structure argumentative dans les dissertations en anglais langue étrangère (EFL), qui sont intrinsèquement bruyantes. Le processus d'analyse se compose de deux étapes : relier les phrases associées et étiqueter leurs relations. Nous testons plusieurs architectures de deep learning pour traiter chaque tâche de manière indépendante. Dans la tâche de liaison de phrases, c'est un modèle biaffine qui a donné les meilleurs résultats. Dans la tâche d'étiquetage des relations, c'est un modèle BERT affiné qui a donné les meilleurs résultats. Deux encodeurs de phrases sont utilisés, et nous avons observé que les modèles sans réglage fin donnaient généralement de meilleurs résultats avec l'encodeur Sentence-BERT par opposition au codeur BERT. Nous avons formé nos modèles à l'aide de deux types de textes parallèles : les essais originaux bruités EFL et ceux améliorés par des annotateurs, puis nous les évaluons sur les dissertations originales. L'expérience montre qu'un système dans le domaine de bout en bout a atteint une précision de 0,341. D'autre part, le système inter-domaines a atteint 94 % de performances du système dans le domaine. Cela indique que des textes bien écrits peuvent également être utiles pour entraîner le système d'exploration d'arguments pour les textes bruyants.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Cuireann an páipéar seo i láthair staidéar ar an struchtúr argóinteach in aistí Béarla mar theanga iasachta (EFL) a pharsáil, atá fuaimiúil go bunúsach. Tá dhá chéim sa phróiseas parsála, ag nascadh abairtí gaolmhara agus ansin ag lipéadú a gcaidreamh. Bainimid triail as roinnt ailtireachtaí domhainfhoghlama chun tabhairt faoi gach tasc go neamhspleách. Sa tasc nascadh abairtí, samhail biaifín ab fhearr. Maidir leis an tasc maidir le lipéadú an choibhneasa, múnla BERT mionchoigeartaithe ab fhearr. Fostaítear dhá ionchódóir pianbhreithe, agus thugamar faoi deara gur éirigh níos fearr le samhlacha neamh-mhionchoigeartaithe go ginearálta nuair a bhí Pianbhreithe-BERT in úsáid seachas ionchódóir CRET. Chuireamar oiliúint ar ár múnlaí ag baint úsáide as dhá chineál téacs comhthreomhar: bun-aistí torannacha EFL agus iad siúd a d'fheabhsaigh anótálaithe, ansin déan iad a mheas ar na bun-aistí. Léiríonn an turgnamh gur bhain córas in-fhearainn ceann go ceann amach cruinneas .341. Ar an láimh eile, bhain an córas tras-fearainn feidhmíocht 94% den chóras in-fearainn amach. Léiríonn sé seo gur féidir le téacsanna dea-scríofa a bheith úsáideach freisin chun córas mianadóireachta argóintí a oiliúint le haghaidh téacsanna callánacha.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Wannan takardan na bãyar da wani littãfi a kan parse muhimmanci cikin harshen Ingiriya-as-kigenre (EFL), wanda ke cikin sauti. @ action: button We experiment with several deep learning architectures to address each task independently. A cikin aikin da ke haɗi zuwa maganar, wata misali mai biyafi ya sami mafi kyaun. In the related labelin job, a mai kyau-tuned BERT Model ya samar da mafi kyaun. An yi amfani da kodi biyu na maganar, kuma ba mu gani ba cewa misãlai masu tunkuɗe wa-mai kyau a samu'a da mafiya kyau idan an yi amfani da Cincin-BERT kamar da ya motsa kodi na BERT. Kuma ba mu sanar da misalinmu da misalin misalin misalin biyu masu daidaita: makaranti na farko na EFL da waɗanda aka samar da su, sa'an nan kuma ka ƙaddara su a cikin takardar farko. Tafiyar da ke nuna cewa ƙari zuwa-ƙari cikin-guda ya sami tsari na .341. Ga da hagu, na'urar-ɗamfyuta ta sãmu 94% na'urar tsarin da ke cikin guda. Wannan ayukan ayuka da aka rubũta rubutu masu iya amfani da shi, ya zama mai amfani ga tunkuɗe tsarin sundin da aka yi wa matsayin sauti.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy. תהליך המחקר מורכב משני צעדים, הקשר משפטים קשורים ואז סימן את מערכת היחסים שלהם. אנחנו מנסים עם כמה ארכיטקטורות למידה עמוקה כדי להתמודד עם כל משימה באופן עצמאי. במשפט הקשר משימה, דוגמנית ביאפין ביצעה את הטוב ביותר. במשימת התיקון, מודל BERT מעוצבן ביצע את הטוב ביותר. שני קודדים משפטים משתמשים, ואנחנו שמנו לב שדוגמנים לא מתאימים בדרך כלל ביצעו טוב יותר כשהשתמשו בשימוש בשימוש בשימוש בשימוש בשימוש במקום קודד BERT. אימנו את הדוגמנים שלנו באמצעות שני סוגים של טקסטים מקבילים: מאמרים מקוריים רעשים EFL ואלה ששותפים על ידי ציונים, ואז מעריכים אותם על המאמרים המקוריים. הניסוי מראה שמערכת בתחום של סוף אל סוף השיגה מדויקה של .341. מצד שני, מערכת התחום השיגה 94% ביצועים של מערכת התחום. זה מסמן שטקסטים נכתבים היטב יכולים להיות שימושיים גם לאמן מערכת כירות טיעונים לטקסטים רעשים.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>यह पेपर अंग्रेजी-विदेशी-भाषा (ईएफएल) निबंधों में तर्कसंगत संरचना को पार्स करने पर एक अध्ययन प्रस्तुत करता है, जो स्वाभाविक रूप से शोर कर रहे हैं। पार्सिंग प्रक्रिया में दो चरण होते हैं, संबंधित वाक्यों को जोड़ना और फिर उनके संबंधों को लेबल करना। हम स्वतंत्र रूप से प्रत्येक कार्य को संबोधित करने के लिए कई गहरे सीखने के आर्किटेक्चर के साथ प्रयोग करते हैं। वाक्य जोड़ने के कार्य में, एक biaffine मॉडल ने सबसे अच्छा प्रदर्शन किया। संबंध लेबलिंग कार्य में, एक ठीक-ठाक BERT मॉडल ने सबसे अच्छा प्रदर्शन किया। दो वाक्य एनकोडर नियोजित हैं, और हमने देखा कि गैर-ठीक-ट्यूनिंग मॉडल ने आमतौर पर BERT एन्कोडर के विपरीत वाक्य-BERT का उपयोग करते समय बेहतर प्रदर्शन किया। हमने दो प्रकार के समानांतर ग्रंथों का उपयोग करके अपने मॉडल को प्रशिक्षित किया: मूल शोर ईएफएल निबंध और एनोटेटर द्वारा सुधार किए गए, फिर मूल निबंधों पर उनका मूल्यांकन करें। प्रयोग से पता चलता है कि एक एंड-टू-एंड इन-डोमेन सिस्टम ने .341 की सटीकता हासिल की। दूसरी ओर, क्रॉस-डोमेन सिस्टम ने इन-डोमेन सिस्टम का 94% प्रदर्शन हासिल किया। यह संकेत देता है कि अच्छी तरह से लिखे गए ग्रंथों को शोर ग्रंथों के लिए तर्क खनन प्रणाली को प्रशिक्षित करने के लिए भी उपयोगी हो सकता है।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ovaj papir predstavlja ispitivanje o razmatranju argumentativne strukture na esejima engleskog kao stranog jezika (EFL), koje su inherentno bučne. Proces razmatranja sastoji se od dva koraka, povezujući povezane rečenice i onda označavajući njihove odnose. Eksperimentiramo s nekoliko dubokih arhitektura učenja da se riješimo svakom zadatku nezavisno. U rečenici povezujući zadatak, model biafina je izvršio najbolje. U zadatku označavanja odnosa, najbolje je izvršio dobar model BERT-a. Dva kodera rečenice su zaposlena, a mi smo primijetili da modeli koji nisu ispravni prilagođavali općenito ispunjavaju bolje kada koriste kaznu-BERT suprotno koderu BERT-a. Obučavali smo naše modele koristeći dvije vrste paralelnih tekstova: originalne bučne eseje EFL-a i one koje su poboljšale annotatori, a onda ih procijeniti na originalnim esejima. Eksperiment pokazuje da je sustav kraja do kraja u domenu postigao to čnost od .341. S druge strane, sustav prekršnog domena postigao je 94% učinkovitosti sustava domena. Ovi signali su da dobro napisani teksti mogu biti korisni i za obuku rudarskog sustava argumentacija za bučne tekste.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ez a tanulmány bemutatja az angol mint idegen nyelvű (EFL) esszék argumentációs struktúrájának elemzését, amelyek eredendően zajosak. Az elemzési folyamat két lépésből áll, összekapcsolja a kapcsolódó mondatokat, majd megjelöli a kapcsolataikat. Számos mélytanulási architektúrával kísérletezünk, hogy minden feladatot önállóan kezeljük. A mondatkötési feladatban a biaffine modell teljesítette a legjobbat. A kapcsolatcímkézési feladat során egy finomhangolt BERT modell teljesített a legjobban. Két mondatkódolót alkalmazunk, és megfigyeltük, hogy a nem finomhangoló modellek általában jobban teljesítenek a Sentence-BERT használatával szemben a BERT kódolóval. Modelljeinket kétféle párhuzamos szövegből készítettük: eredeti zajos EFL esszék és kommentátorok által fejlesztett esszék segítségével, majd értékeltük őket az eredeti esszékben. A kísérlet azt mutatja, hogy egy teljes körű domain rendszer .341 pontosságot ért el. Másrészről a cross-domain rendszer 94%-os teljesítményt ért el az in-domain rendszer. Ez azt jelzi, hogy a jól megírt szövegek hasznosak lehetnek a zajos szövegek argumentumbányászati rendszerének kiképzéséhez.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Այս հոդվածը ներկայացնում է մի ուսումնասիրություն անգլերեն-օտար-լեզու (EFL) էսսեների արտահայտության վերլուծության մասին, որոնք բնական աղմուկ են: Փորձարկման գործընթացը կազմված է երկու քայլ, կապելով կապված նախադասությունները և հետո պիտակելով նրանց հարաբերությունները: Մենք փորձում ենք մի քանի խորը ուսուցման ճարտարապետությունների հետ յուրաքանչյուր խնդիր անկախ լուծելու համար: Արտահայտությունը կապված նախադասության մեջ երկաֆինի մոդելը լավագույնն արեց: Ինչ վերաբերում է պիտակավորման խնդրին, լավագույնը կատարեց բարձրացված BERT մոդելը: Երկու նախադասություն կոդավորիչներ են օգտագործվում, և մենք նկատեցինք, որ ոչ բարձրակարգման մոդելները սովորաբար ավելի լավ են աշխատում օգտագործելով նախադասություն-BER-ը, ի հակադրություն BER-ի կոդավորիչը: Մենք ուսուցանում էինք մեր մոդելները երկու տեսակի զուգահեռ տեքստերի օգտագործելով' սկզբնական աղմկոտ EFL էսսեները, որոնք բարելավվել են annoտորների կողմից, հետո գնահատում ենք դրանք սկզբնական էսսերի վրա: Փորձը ցույց է տալիս, որ տիեզերքի վերջ-վերջ համակարգը հասավ .341 ճշգրիտության: Մյուս կողմից, տիեզերական համակարգը հասավ տիեզերական համակարգի 94 տոկոսի արդյունավետության: Սա ազդանշան է տալիս, որ լավ գրված տեքստերը կարող են օգտակար լինել նաև աղմկոտ տեքստերի համար բանավեճերի հանքային համակարգի ուսումնասիրելու համար:</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy. Proses penghuraian terdiri dari dua langkah, menghubungkan kalimat yang berhubungan dan kemudian mengetikkan hubungan mereka. Kami eksperimen dengan beberapa arsitektur belajar dalam untuk mengatasi setiap tugas secara independen. Dalam kalimat yang menghubungkan tugas, model biaffine melakukan yang terbaik. Dalam tugas etiket hubungan, model BERT yang disesuaikan lebih baik. Dua pengkode kalimat digunakan, dan kami memperhatikan bahwa model non-fine-tuning biasanya berhasil lebih baik ketika menggunakan Sentence-BERT daripada BERT pengekode. Kami melatih model kami menggunakan dua jenis teks paralel: essai EFL bunyi asli dan yang diperbaiki oleh annotator, kemudian mengevaluasinya pada essai asli. Eksperimen menunjukkan bahwa sistem domain akhir-akhir mencapai akurasi .341. Di sisi lain, sistem cross-domain mencapai prestasi 94% dari sistem in-domain. Sinyal ini bahwa teks yang ditulis dengan baik juga dapat berguna untuk melatih sistem pertambangan argumen untuk teks yang berisik.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Questo articolo presenta uno studio sull'analisi della struttura argomentativa nei saggi inglese come lingua straniera (EFL), che sono intrinsecamente rumorosi. Il processo di analisi consiste in due fasi, collegando frasi correlate e poi etichettando le loro relazioni. Sperimentiamo diverse architetture di deep learning per affrontare ogni compito in modo indipendente. Nell'attività di collegamento delle frasi, un modello biaffine ha eseguito il meglio. Nel compito di etichettatura delle relazioni, un modello BERT perfezionato ha dato il meglio. Vengono impiegati due encoder di frase e abbiamo osservato che i modelli non-fine-tuning generalmente hanno prestazioni migliori quando si utilizza Sentence-BERT rispetto all'encoder BERT. Abbiamo formato i nostri modelli utilizzando due tipi di testi paralleli: saggi EFL originali rumorosi e quelli migliorati dagli annotatori, per poi valutarli sui saggi originali. L'esperimento mostra che un sistema end-to-end in-domain ha raggiunto una precisione di .341. D'altra parte, il sistema cross-domain ha raggiunto il 94% delle prestazioni del sistema in-domain. Questo indica che i testi ben scritti possono anche essere utili per addestrare il sistema di estrazione di argomenti per i testi rumorosi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>本稿では、本質的に騒がしい英語-外国語（ EFL ）エッセイにおける議論構造の構文解析に関する研究を紹介する。 構文解析プロセスは、関連する文をリンクし、それらの関係をラベル付けする2つのステップで構成されています。 私たちは、それぞれの課題に独立して対処するために、いくつかの深層学習アーキテクチャを実験しています。 文のリンクタスクでは、バイアフィンモデルが最高のパフォーマンスを発揮しました。 関係ラベリングタスクでは、微調整されたBERTモデルが最良のパフォーマンスを発揮しました。 ２つの文章エンコーダが採用されており、非微調整モデルは一般的に、ＢＥＲＴエンコーダとは対照的に、Ｓｅｎｔｅｎｃｅ － ＢＥＲＴを使用する場合により良いパフォーマンスを発揮することが観察された。 私たちは、オリジナルのノイズの多いEFLエッセイと、アノテーターによって改善されたものの2種類のパラレルテキストを使用してモデルをトレーニングし、オリジナルのエッセイで評価しました。 この実験では、エンドツーエンドのドメイン内システムが.341の精度を達成したことが示されています。 一方、クロスドメインシステムは、インドメインシステムの94 ％のパフォーマンスを達成しました。 これは、よく書かれたテキストが、ノイズの多いテキストのための引数マイニングシステムをトレーニングするのにも役立つことを示しています。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Perkara iki nambah urip nggambar kelas pirsak nggawe tarjamahan seneng nggagal-ingkang kaya-nglanggar sapa-kenir (eFL). Genjer Awak dhéwé éntuk karo akeh akeh juter architecture kanggo sabên seneng nggawe gerakan sakjane. Nang papat nggambar task, supoyo biaFin nambah sing luwih apik. Nambah tengahane nggambar nggambar, model BERT wis ngawe barang apik. Yo wis rampung koder sing nggunakake ditambah, lan ampuhi awak dhéwé ngerasah model sing gak bener-ne-tuning nggawe barang luwih dumadhi kanggo nggunakake Sentense-BERT dumadhi karo koder BERT. Awak dhéwé éntuk sistem sing beraksi perusahaan dengané sampeyan kelangan iki: iso nggawe barang kegambar uwong, lan uwong sing nyebutaké awak dhéwé, njuk ujarané awak dhéwé sisayé surat sing uwong. The pilot show that an end-to-end in-domain System success an exact of .34 1. In the second hand, the inter-domain System met 1994% success of the in-domain System. structural navigation</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ეს დოკუმენტი აჩვენებს აპრინტიგური სტრუქტურის პარასუზაციის შესახებ ინგლისური ენის (EFL) ესესიში, რომლებიც არსებობით ბუნდა. პროცესი განაწერების შეფარდება ორი ნაწილის შეფარდება, შემდეგ შეფარდებული სიტყვების დაკავშირება და შემდეგ მათი შესახებ. ჩვენ ექსპერიმენტირებით რამდენიმე ძალიან სწავლის აქტიქტიკურებით, რომელიც ყოველ რაოდენობას განცემულად გადავუწყ ბიფინის მოდელეში ყველაზე უკეთესი მონაცემები გავაკეთეთ. შესაბამისი მარტიკის დავალებაში, BERT მოდელის შესაბამისი შესაბამისი შესაბამისი შესაბამისი მოდელია. ორი სიტყვების კოდერები მომხმარებულია, და ჩვენ დავხედავთ, რომ არაფერი კოდერების მოდელები უფრო უფრო მუშაობენ, როდესაც გამოყენება ბერტი კოდერების განმავლობაში. ჩვენ ჩვენი მოდელების შესწავლით ორი ტიპის პარალელი ტექსტის გამოყენებით: ორიგინალური ფუნქციური EFL ესეები და ისინი, რომლებიც ანტოტოტორიების შესაძლებელება, შემდეგ დავამუშავ ექსპერიმენტი ჩვენებს, რომ საკუთარი დასრულებული დომინის სისტემა დასრულებულია.341. მეორე მხოლოდ, კრესომინის სისტემა 94% მოქმედება დომინის სისტემას. ეს სიგნალეები, რომლებიც ძალიან წერტილი ტექსტი შეუძლია იყოს საჭირო სისტემის მინდომის სისტემის შესაბამისთვის.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Бұл қағаз ағылшын тілі (EFL) ретінде аргументациялық құрылғыны талдау туралы зерттеулерді көрсетеді. Бұл аргументалдық құрылғылар әдетте дыбыс болып тұрады. Бұл талдау процесі екі қадам болып, сілтемелерді сілтемелеу және оның қатынасын жарлықтау. Біз әрбір тапсырманы тәуелді өзгерту үшін бірнеше түсінік оқыту архитектураларымен тәжірибедік. Тапсырманы сілтемелеу үшін биафин үлгісі ең жақсы орындалды. Қатысушылық жарлықтау тапсырмасында BERT үлгісін жақсы орындады. Екі сөз кодері жұмыс істейді. Біз BERT кодеріне қарсы сөз- BERT кодеріне қарсы жақсы орындалатын үлгілер үлгілерін көрдік. Біз үлгілерімізді екі түрлі параллель мәтінді қолдануға үйрендік: бастапқы дыбыс EFL ессейлері және жаңартушылары жасалды, содан кейін оларды бастапқы ессейлерде оқу. Тәжірибе домендегі соңындағы соңындағы жүйе .341 деген дұрыстығын жеткізді. Біріншіден, домен жүйесінің 94% жылдамдығын жеткізді. Бұл мәтіндердің жақсы жазылған сигналдары, сондай-ақ, дыбыс мәтіндер үшін аргументтің бағыттау жүйесін оқыту үшін пайдалы болады.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>본고는 영어가 외국어(EFL)로서의 문장 중의 논문 구조를 분석 연구하였다.해석 과정은 두 가지 절차를 포함하여 관련 문장을 연결한 다음에 그것들의 관계를 표시한다.우리는 각 임무를 독립적으로 해결하기 위해 몇 가지 심도 있는 학습 체계 구조를 시도했다.문장 연결 작업 중 아분 모형보다 표현이 가장 좋다.관계 표기 작업 중 미세한 버트 모형이 가장 잘 나타난다.우리는 두 개의 문장 인코더를 사용했고, 문장 BERT 인코더가 아닌 문장 BERT를 사용할 때, 비미세 모형이 일반적으로 더 잘 표현되는 것을 관찰했다.우리는 두 가지 평행 텍스트를 사용하여 우리의 모델을 훈련시켰다. 그것이 바로 원시 시끄러운 EFL 문장과 주석자가 개선한 문장이다. 그리고 원시 문장에서 그것들을 평가한다.실험에 의하면 끝에서 끝까지 시스템의 정밀도는 0.341에 이르렀다.다른 한편, 도메인 간 시스템의 성능은 도메인 내 시스템의 94%에 달한다.좋은 텍스트를 쓰는 것도 소음 텍스트를 훈련하는 파라미터 발굴 시스템에 사용될 수 있다는 뜻이다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Šiame dokumente pateikiamas tyrimas dėl argumentacinės struktūros analizavimo anglų-kaip-užsienio kalbos (EFL) egzaminuose, kurie iš esmės yra triukšmingi. The parsing process consists of two steps, linking related sentences and then labelling their relations. Eksperimentuojame su keliomis gilaus mokymosi architektūromis, kad kiekviena užduotis būtų sprendžiama nepriklausomai. Kalbant apie užduotį, susijusią su sakiniu, biffino modelis atliko geriausią rezultatą. In the relation labelling task, a fine-tuned BERT model performed the best. Naudojami du sakiniai koduojantys kodai ir pastebėjome, kad nereguliuojantys modeliai paprastai geriau veikia naudojant sentence-BERT, o ne BERT koduojantį kodą. Mokėjome savo modelius naudojant dviejų rūšių lygiagrečius tekstus: originalius triukšmingus EFL esejus ir tuos, kuriuos patobulino anotatoriai, tada juos vertiname pagal originalius esejus. Eksperimentas rodo, kad iš vienos srities į kitą sistema pasiekė .341 tikslumą. Kita vertus, tarpdomeninė sistema pasiekė 94 % domeninės sistemos veiklos rezultatų. Tai rodo, kad gerai rašyti tekstai taip pat gali būti naudingi argument ų gavybos sistemai apmokyti triukšmingiems tekstams.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Овој весник претставува студија за анализирање на аргументативната структура на есеите на англиски-како-странски јазик (ЕФЛ), кои се природно гласни. Процесот на анализирање се состои од два чекори, поврзувајќи ги поврзаните реченици и потоа означувајќи ги нивните односи. Експериментираме со неколку архитектури за длабоко учење за да се справиме со секоја задача независно. Во реченицата која ја поврзува задачата, биафинскиот модел беше најдобар. Во врска со задачата за етикетирање на односите, фино прилагоден модел BERT го изврши најдоброто. Употребени се два кодери на реченици, и ние забележавме дека нефинетираните модели генерално работеа подобро кога се користи реченица-BERT во спротивност на BERT кодерот. Ги трениравме нашите модели користејќи два вида паралелни тексти: оригинални бучни есеи ЕФЛ и оние подобрени од анотаторите, потоа ги проценуваме на оригиналните есеи. Експериментот покажува дека системот од крај до крај во домен постигнал точност од .341. Од друга страна, крстодомениот систем постигна 94 отсто од резултатите на системот во домените. Ова сигнализира дека добро напишаните тексти, исто така, можат да бидат корисни за обука на системот за рудање аргументи за бучни тексти.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy. പാര്‍സിംഗ് പ്രക്രിയയില്‍ രണ്ടു പടികള്‍ ഉണ്ട്, ബന്ധപ്പെട്ട വാക്കുകള്‍ ബന്ധപ്പെടുത്തുന്നു, പിന്നെ അവരുടെ ബന എല്ലാ ജോലിയെയും സ്വാതന്ത്ര്യമായി സംസാരിക്കാന്‍ ആഴമുള്ള പഠിക്കുന്ന ആര്‍ക്കിട്ടുകള്‍ കൊണ് വാക്കില്‍ ബന്ധപ്പെടുത്തുന്ന ജോലിയില്‍ ഒരു ബിഫിന്‍ മോഡല്‍ ഏറ്റവും നല്ലത് പ്രവര്‍ത്തിച്ചു. ബന്ധപ്പെടുത്തുന്ന ജോലിയില്‍, നല്ലൊരു ബെര്‍ട്ടി മോഡല്‍ ഏറ്റവും നല്ലത് പ്രവര്‍ത്തിച്ചു. രണ്ട് വാക്കുകളുടെ കോഡോര്‍ഡുകള്‍ ഉപയോഗിച്ചിരിക്കുന്നു, ബെര്‍ട്ടി കോഡോര്‍ഡിനെതിരെ ഉപയോഗിക്കുമ്പോള്‍ സെന്‍സ്-ബെര്‍ട്ടി ഉപയോ നമ്മുടെ മോഡലുകള്‍ രണ്ടു തരം പാരാലില്‍ ടെക്സ്റ്റുകള്‍ ഉപയോഗിച്ച് ഞങ്ങള്‍ പരിശീലിപ്പിച്ചു: ആദ്യമായ യെഎഫ്എല്‍ ലേസ്സുകള്‍ ഉയര്‍ത്തുന്നതും അ പരീക്ഷണം കാണിച്ചുകൊണ്ടിരിക്കുന്നത് ഡൊമെയിന്‍ സിസ്റ്റത്തിന്റെ അവസാനത്തിലേക്ക് അവസാനിക്കുന്നതാ മറുവശത്ത്, ക്രിസ്റ്റ് ഡൊമെയിന്‍ സിസ്റ്റം 94% പ്രവര്‍ത്തിപ്പിച്ചു. നല്ല എഴുതിയ ടെക്സ്റ്റുകള്‍ ശബ്ദമുള്ള വാക്കുകള്‍ക്ക് വേണ്ടി ആര്‍ഗ്യുമിനിങ്ങ് മൈനിങ്ങ് സിസ്റ്റം പരി</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Энэ цаас Англи хэл болон гадаад хэл (EFL) эссийн аргументын бүтцийг хуваалцах талаар судалж байна. Энэ нь үнэхээр чимээгүй. Тайлбарлах процесс нь хоёр алхам, харилцааны өгүүлбэр холбоотой, дараа нь харилцааныг тэмдэглэдэг. Бид олон гүн гүнзгий суралцах архитектурууддаа ажил бүрийг өөрсдөө зохицуулахын тулд туршилт хийдэг. Үүний дараа ажлыг холбох үед биефин загвар хамгийн сайн хийсэн. Хариулт маркингийн ажил дээр BERT загвар хамгийн сайн хийсэн. Хоёр өгүүлбэр коддогч ажиллаж байгаа. Бид BERT коддогч эсрэгээр Sentence-BERT-ийг ашиглах үед илүү сайн ажиллаж байгааг анзаарсан. Бид моделуудыг хоёр төрлийн параллел текст ашиглан сургалтын загвар өгсөн. Үнэндээ чимээгүй EFL эссийг ашиглаж байлаа. Энэ туршилт нь холбооны төгсгөл-төгсгөл систем нь .341-ийн тодорхойлолтой болсон. Нөгөө талаар, холбоотой систем нь холбоотой системийн 94% ажиллагааг гаргасан. Үнэндээ сайн бичигдсэн бичигдсэн мөн аргументын хөрөнгө оруулах системийг сонсогдож чадна.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kertas ini memperkenalkan kajian mengenai hurai struktur argumensif dalam esei bahasa Inggeris-sebagai-asing (EFL), yang secara nyata bunyi. Proses penghuraian terdiri dari dua langkah, menghubungkan kalimat berkaitan dan kemudian mengetikkan hubungan mereka. Kami eksperimen dengan beberapa arkitektur belajar dalam untuk mengatasi setiap tugas secara independen. Dalam perkataan yang menghubungkan tugas, model biaffin melakukan yang terbaik. Dalam tugas penandaan hubungan, model BERT ditetapkan yang terbaik dilakukan. Dua pengekod kalimat digunakan, dan kami memperhatikan bahawa model bukan-penyesuaian biasanya dilakukan lebih baik bila menggunakan pengekod kalimat-BERT daripada pengekod BERT. Kami melatih model kami menggunakan dua jenis teks selari: esei EFL bunyi asal dan yang diperbaiki oleh annotator, kemudian menilainya pada esei asal. Eksperimen menunjukkan bahawa sistem domain akhir-akhir mencapai ketepatan .341. Di sisi lain, sistem cross-domain mencapai prestasi 94% sistem dalam-domain. Ini memberi isyarat bahawa teks yang ditulis dengan baik juga boleh berguna untuk melatih sistem pertambangan argumen untuk teks bunyi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy. Il-proċess ta’ analiżi jikkonsisti f’żewġ passi, li jgħaqqdu sentenzi relatati u mbagħad jikkettaw ir-relazzjonijiet tagħhom. Aħna ninsperimentaw b’diversi arkitetturi ta’ tagħlim profond biex nindirizzaw kull kompitu b’mod indipendenti. Fis-sentenza li tgħaqqad il-kompitu, mudell biffin wettaq l-a ħjar. Fil-kompitu tat-tikkettar tar-relazzjoni, mudell BERT irfinat wettaq l-a ħjar. Jintużaw żewġ kodifikaturi tas-sentenzi, u osservajna li mudelli mhux ta’ rfinar ġeneralment kienu aħjar meta ntużaw Sentenza-BERT minflok l-kodifikatur BERT. Taħriġna l-mudelli tagħna bl-użu ta’ żewġ tipi ta’ testi paralleli: essays oriġinali storbjużi tal-EFL u dawk imtejba mill-annotaturi, imbagħad ivvalutawhom fuq l-essays oriġinali. L-esperiment juri li sistema f’dominju minn tarf sa tarf kisbet preċiżjoni ta’ .341. Min-naħa l-oħra, is-sistema cross-domain kisbet prestazzjoni ta’ 94% tas-sistema in-domain. Dan jindika li testi miktuba sew jistgħu jkunu utli wkoll biex titħarreġ is-sistema tal-minjieri tal-argumenti għal testi storbjużi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dit artikel presenteert een studie over het parsen van de argumentatieve structuur in Engels-als-vreemde-taal (EFL) essays, die inherent luidruchtig zijn. Het parsing proces bestaat uit twee stappen, het koppelen van verwante zinnen en vervolgens het labelen van hun relaties. We experimenteren met verschillende deep learning architecturen om elke taak onafhankelijk aan te pakken. In de zinskoppelingstaak presteerde een biaffine model het beste. Bij de relatielabelstructuur presteerde een verfijnd BERT-model het beste. Er worden twee zinnencoders gebruikt, en we zagen dat niet-fine-tuning modellen over het algemeen beter presteerden bij het gebruik van Sentence-BERT in tegenstelling tot BERT encoder. We hebben onze modellen getraind met behulp van twee soorten parallelle teksten: originele noise EFL essays en die verbeterd door annotators, en ze vervolgens geëvalueerd op de originele essays. Het experiment toont aan dat een end-to-end in-domein systeem een nauwkeurigheid van .341 bereikte. Aan de andere kant behaalde het domeinoverschrijdende systeem 94% prestaties van het in-domein systeem. Dit geeft aan dat goed geschreven teksten ook nuttig kunnen zijn om argument mining systeem te trainen voor lawaaierige teksten.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Denne papiret viser ein studie om tolking av argumentativ strukturen i engelske som fremst språk (EFL), som er eigentleg støy. Tolkingsprosessen inneheld to steg, lenkjer relaterte setningar og så merker forholdet sine. Vi eksperimenterer med fleire dype læringsarkitektur for å handtera kvar oppgåve uavhengig. I setningen som lenkjer oppgåva, utførte ein biaffinmodell den beste. I forhold til merkelappen utførte ein fint BERT-modell best. To setningskooderar er arbeida, og vi observerte at ikkje-finnstillingsmodeller vanlegvis utførte bedre når sentences-BERT brukar i motsetning til BERT-kodar. Vi treng modellen våre med to typar parallelle tekstar: originale støy EFL-essane og dei forbetra av annotatorar, og deretter evaluer dei på originale essane. Eksperimentet viser at ein ende- til- slutt- domenesystemet oppnådd eit nøyaktig av .341. På den andre siden oppnådd krysdomenesystemet 94% utviklinga i domenesystemet. Dette signaler at skrivne tekstar kan også vera nyttig for å trena argument-miningssystem for støytekstar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>W artykule przedstawiono badanie analizy struktury argumentatywnej w esejach o języku angielskim jako obcym (EFL), które są z natury hałaśliwe. Proces parsowania składa się z dwóch etapów, łączenia powiązanych zdań, a następnie oznaczania ich relacji. Eksperymentujemy z kilkoma architekturami głębokiego uczenia, aby rozwiązać każde zadanie niezależnie. W zadaniu łączącym zdanie najlepiej sprawdził się model biafinowy. W zadaniu etykietowania relacji najlepiej sprawdził się dopracowany model BERT. Zastosowane są dwa kodery zdań, a my zauważyliśmy, że modele niedostrajające się zazwyczaj sprawdzają się lepiej przy użyciu kodera zdań-BERT w przeciwieństwie do kodera BERT. Szkoliliśmy nasze modele z wykorzystaniem dwóch rodzajów tekstów równoległych: oryginalnych szumownych esejów EFL oraz tych ulepszonych przez adnotatorów, a następnie oceniamy je na oryginalnych esejach. Eksperyment pokazuje, że kompleksowy system w domenie osiągnął dokładność .341. Z drugiej strony system między domenami osiągnął 94% wydajności systemu wewnątrz domeny. Sygnalizuje to, że dobrze napisane teksty mogą być również przydatne do treningu systemu wydobywania argumentów dla głośnych tekstów.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Este artigo apresenta um estudo sobre a análise da estrutura argumentativa em ensaios de inglês como língua estrangeira (EFL), que são inerentemente barulhentos. O processo de análise sintática consiste em duas etapas, vinculando sentenças relacionadas e, em seguida, rotulando suas relações. Experimentamos várias arquiteturas de aprendizado profundo para abordar cada tarefa de forma independente. Na tarefa de ligação de frases, um modelo biafino teve o melhor desempenho. Na tarefa de rotulagem de relação, um modelo BERT ajustado teve o melhor desempenho. Dois codificadores de sentença são empregados e observamos que os modelos sem ajuste fino geralmente tiveram melhor desempenho ao usar o codificador Sentence-BERT em oposição ao codificador BERT. Treinamos nossos modelos usando dois tipos de textos paralelos: ensaios originais de EFL barulhentos e aqueles aprimorados por anotadores, então os avaliamos nos ensaios originais. O experimento mostra que um sistema no domínio de ponta a ponta alcançou uma precisão de 0,341. Por outro lado, o sistema cross-domain alcançou 94% de desempenho do sistema in-domain. Isso sinaliza que textos bem escritos também podem ser úteis para treinar o sistema de mineração de argumentos para textos ruidosos.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Lucrarea prezintă un studiu privind analizarea structurii argumentative în eseurile de limbă engleză ca limbă străină (EFL), care sunt inerent zgomotoase. Procesul de analizare constă în două etape, care leagă propozițiile conexe și apoi etichetează relațiile lor. Experimentăm cu mai multe arhitecturi de învățare profundă pentru a aborda fiecare sarcină independent. În sarcina de legătură a propozițiilor, un model de biafine a performat cel mai bine. În sarcina de etichetare a relațiilor, un model BERT reglat fin a performat cel mai bine. Sunt utilizate două codificatoare de propoziții și am observat că modelele non-reglare fină au performat în general mai bine atunci când utilizați Sentence-BERT, spre deosebire de codificatorul BERT. Ne-am instruit modelele folosind două tipuri de texte paralele: eseurile EFL originale zgomotoase și cele îmbunătățite de adnotatori, apoi le-am evaluat pe eseurile originale. Experimentul arată că un sistem end-to-end în domeniu a atins o precizie de .341. Pe de altă parte, sistemul cross-domeniu a obținut o performanță de 94% a sistemului in-domeniu. Acest lucru semnalează că textele bine scrise pot fi, de asemenea, utile pentru instruirea sistemului de mining de argumente pentru texte zgomotoase.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>В данной работе представлено исследование по анализу аргументативной структуры в эссе на английском языке как иностранном (EFL), которые по своей сути являются шумными. Процесс синтаксического анализа состоит из двух этапов, соединяющих соответствующие предложения, а затем обозначающих их отношения. Мы экспериментируем с несколькими архитектурами глубокого обучения, чтобы решать каждую задачу самостоятельно. В задаче связывания предложений модель биаффина показала лучшие результаты. В задаче маркировки отношений лучше всего работала тонко настроенная модель BERT. Используются два кодера предложений, и мы заметили, что модели без точной настройки, как правило, работают лучше при использовании Sentence-BERT в отличие от кодера BERT. Мы обучали наши модели, используя два типа параллельных текстов: оригинальные шумные эссе EFL и улучшенные аннотаторами, а затем оценивали их по оригинальным эссе. Эксперимент показывает, что сквозная внутридоменная система достигла точности .341. С другой стороны, междоменная система достигла 94% производительности внутридоменной системы. Это сигнализирует о том, что хорошо написанные тексты также могут быть полезны для обучения системы майнинга аргументов для шумных текстов.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>මේ පත්තු ප්‍රදේශයක් ඉංග්‍රීසි භාෂාවක් වලින් ප්‍රශ්නයක් විශ්ලේෂණය කරනවා, ඒ වගේම ප්‍රශ්නයක් විශ්ලේෂණය ක විශ්ලේෂණ ප්‍රක්‍රියාව සම්බන්ධතාවක් දෙකක් තියෙනවා, සම්බන්ධතාවක් සම්බන්ධතාවක් සම්බන්ධ අපි ගොඩක් ගොඩක් ඉගෙන ගන්න සිද්ධ විද්‍යාපාරයෙන් පරීක්ෂණය කරනවා හැම වැඩක්ම ස්වයංක්‍ර වාක්ය සම්බන්ධ වෙන්න වැඩේ බියාෆින් නිර්මාණයක් හොඳම වැඩ කළා. සම්බන්ධ ලේබිල් කාර්යයෙන්, හොඳම BERT මොඩල් එකක් වැඩ කරනවා. වාක්යෙන් කෝඩාර් දෙකක් වැඩ කරලා තියෙනවා, ඒ වගේම අපි බලාපොරොත්තු කරලා තියෙනවා කියලා කියලා, සමාන්‍යයෙන්ම නොවිශ්වාසික අපි අපේ මොඩල් එක්ක ප්‍රකාර දෙකක් ප්‍රයෝජනය කරන්න පුළුවන් විදිහට ප්‍රයෝජනය කරලා තියෙන්නේ: ප්‍රධාන ශබ්ද EFL විදිහට සහ අනු පරීක්ෂණය පෙන්වන්නේ අවසානයෙන් අවසානයෙන් අවසානයෙන් ඉවරයි. ඩොමේන් පද්ධතියෙන් හරියට .341 වලින් අනිත් පැත්තෙන්, ක්‍රීස් ඩෝමින් පද්ධතියේ ප්‍රවේශ පද්ධතියේ 94% ක්‍රියාත්මක පරීක්ෂණය ලබාගත මේ සංඥානය හොඳට ලියපු පාළුවත් ප්‍රයෝජනය වෙන්න පුළුවන් විදිහට විශ්වාස කරන්න පුළුවන්</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>V prispevku je predstavljena študija razčlenitve argumentativne strukture v esejih angleščine kot tuji jezik (EFL), ki so po sebi hrupni. Postopek razčlenitve je sestavljen iz dveh korakov, povezovanja povezanih stavkov in nato označevanja njihovih odnosov. Eksperimentiramo z več arhitekturami globokega učenja, da bi vsako nalogo obravnavali samostojno. Pri nalogi povezovanja stavkov je bil biafinski model najboljši. Pri nalogi označevanja povezav je bil najboljši prilagojen model BERT. Uporabljena sta dva kodirnika stavkov in opazili smo, da so modeli brez natančnega nastavljanja na splošno boljši pri uporabi kodirnika Sentence-BERT kot BERT. Naše modele smo usposabljali z dvema vrstama vzporednih besedil: originalnimi hrupnimi eseji EFL in tistimi, ki so jih izboljšali z opotatorji, nato pa jih ocenili na originalnih esejih. Poskus je pokazal, da je sistem od konca do konca dosegel natančnost 0,341. Po drugi strani pa je meddomenski sistem dosegel 94% zmogljivosti notranjega sistema. To kaže, da so dobro napisana besedila lahko koristna tudi za usposabljanje sistema rudarjenja argumentov za hrupna besedila.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Qoraalkan waxaa lagu qoraa waxbarasho ku saabsan baaritaanka dhismaha arrimaha ku saabsan afka Ingiriiska oo kale oo afka ajnabiga ah (EFL) oo aad u dhawaaqdaan. Baaritaanka baarlamaanka waxaa ka mid ah labo tallaabo, ku xiriira qoraalka la xiriira, markaasna la xiriira xiriirkooda. Waxaynu tijaabinaynaa meelo waxbarasho oo mool dheer ah si aan u sheekeyno shaqa kasta si xor ah. Shaqada isku xiran waxaa lagu sameeyay qaab baabuur ah oo aad ugu wanaagsan. Xiriirka sameynta shaqada, model aad u fiican BERT ayaa sameynaya waxa ugu wanaagsan. Waxaa la isticmaalaa labo qodob ah, waxaana aragnay in tusaalo aan hab-wanaagsanayn lagu sameeyo si ka fiican marka lagu isticmaalo Sentence-BERT si ka gees ah codka BERT. Tusaalooyinkayada waxaan ku tababarinnay laba nooc oo kala duduwan qoraal lambarka ah: qoraalka asalka ah ee EFL iyo kuwa horumariyey oo ka kordhisay qoraalka asalka ah, kadibna waxan ku qiimeynay qoraalka asalka ah. Imtixaanka waxaa muuqda in nidaamka ugu dhammaadka gudaha lagu dhamaado uu gaadhay saxda .341. On the other hand, the cross-domain system achieved 94% performance of the in-domain system. Xilliyadaasu waxay faa’iido u leedahay in qoraal-qoraal oo wanaagsan ay u faa’iido karto in lagu tababaro nidaamka dayactirka ee qoraalka qaylada ah.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ky dokument paraqet një studim mbi analizimin e strukturës argumentuese në esejat angleze-si-gjuhë-e huaj (EFL), të cilat janë natyrisht zhurmëshme. Procesi i analizimit përbëhet nga dy hapa, duke lidhur frazat e lidhura dhe pastaj duke etiketuar marrëdhëniet e tyre. Ne eksperimentojmë me disa arkitektura mësimi të thellë për të trajtuar çdo detyrë në mënyrë të pavarur. Në fjalimin që lidh detyrën, një model biffin bëri më të mirën. In the relation labelling task, a fine-tuned BERT model performed the best. Dy koduesit e fjalëve janë të përdorur dhe ne vëzhguam se modelet jo të rregulluara në përgjithësi funksiononin më mirë kur përdornin Sentence-BERT në vend të koduesit BERT. We trained our models using two types of parallel texts: original noisy EFL essays and those improved by annotators, then evaluate them on the original essays. Eksperimenti tregon se një sistem në domeni arriti një saktësi prej .341. Nga ana tjetër, sistemi transdomenik arriti 94% performancë të sistemit brenda domenit. Kjo sinjalizon se tekstet e shkruara mirë mund të jenë gjithashtu të dobishme për të trajnuar sistemin e minierave të argumenteve për tekste zhurmëshme.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ovaj papir predstavlja studiju o razmatranju argumentativne strukture na esejima engleskog kao stranog jezika (EFL), koje su inherentno buke. Proces analize se sastoji od dva koraka, povezujući povezane rečenice i onda označavajući njihove odnose. Eksperimentiramo sa nekoliko dubokih arhitektura učenja da se obratimo svakom zadatku nezavisno. U rečenici povezujući zadatak, model biafina je izvršio najbolje. U zadatku označavanja odnosa, dobro napravljeni model BERT izvršio je najbolje. Dva kodera rečenice su zaposlena, i primetili smo da modeli koji nisu ispravni, u običaju su bolje izvršili kada koriste kaznu-BERT u suprotnosti sa koderom BERT-a. Obučavali smo naše modele koristeći dve vrste paralelnih tekstova: originalne bučne EFL eseje i one koje su poboljšale annotatori, a onda ih procenili na originalnim esejima. Eksperiment pokazuje da je sistem kraja do kraja u domenu postigao tačnost od .341. S druge strane, sistem prekršnog domena postigao je 94% učinkovitosti sistema u domenu. Ovi signali su da dobro napisani teksti mogu biti korisni i za obuku rudarskog sistema argumentacija za bučne tekstove.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Denna uppsats presenterar en studie om tolkning av argumentationsstrukturen i engelsk-som-främmande-språk (EFL) essäer, som är i sig bullriga. Analysprocessen består av två steg, länka relaterade meningar och sedan märka deras relationer. Vi experimenterar med flera djupinlärningsarkitekturer för att hantera varje uppgift självständigt. I meningssänkningsuppgiften presterade en biaffinmodell bäst. I relationsmärkningsuppgiften presterade en finjusterad BERT-modell bäst. Två meningskoder används, och vi observerade att icke-finjusterande modeller generellt presterade bättre när man använder Sentence-BERT i motsats till BERT-encoder. Vi tränade våra modeller med två typer av parallella texter: original bullriga EFL essäer och de som förbättrats av kommentatorer, och utvärderade dem sedan på de ursprungliga essäerna. Experimentet visar att ett heltäckande domänsystem uppnådde en noggrannhet på .341. Å andra sidan uppnådde det domänöverskridande systemet 94% prestanda jämfört med domänsystemet. Detta signalerar att välskrivna texter också kan vara användbara för att träna argument mining system för bullriga texter.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy. mchakato wa wimbo huo unajumuisha hatua mbili, ukiunganisha hukumu zinazohusiana na kisha kuonyesha mahusiano yao. Tunajaribu na majengo kadhaa ya kujifunza yenye muhimu ili kuzungumza kila kazi kwa uhuru. Katika hukumu inayounganisha kazi hiyo, muundo wa upinzani uliofanya vizuri zaidi. Katika jukumu la kutangaza, modeli yenye ujuzi mzuri ya BERT ilifanya vizuri zaidi. Watu wawili wa hukumu wanatumiwa, na tuliona kuwa mifano yasiyo na mafanikio mazuri kwa ujumla ulifanya vizuri wakati wakitumia Hukumu-BERT kinyume na mfumo wa BERT. Tulifunza mifano yetu kwa kutumia aina mbili ya maandishi ya usambazaji: masomo ya asili ya EFL na zile zile zile zilizobadilishwa na wataalamu, kisha kutathmini katika matoleo ya awali. Tatizo hilo linaonyesha kwamba mwisho wa mwisho wa mfumo wa ndani ulipata ukweli wa .341. Kwa upande mwingine, mfumo wa ndani ulipata asilimia 94 ya utendaji wa mfumo wa ndani. Hii inaonyesha kuwa maandishi yaliyoandikwa vizuri yanaweza pia kuwa na manufaa ya kufundisha mfumo wa madini ya uchimbaji wa hoja kwa ajili ya ujumbe wa sauti.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy. பாடல் செயல்பாடு இரண்டு படிகளாக இருக்கும், தொடர்புடைய வாக்கியங்களை இணைத்து பின்னர் அவர்களுடைய உறவுகளை குறிப் நாம் ஒவ்வொரு செயலையும் தனித்தனியாக பேசுவதற்கு பல ஆழமான கற்றுக்கொள்ளும் அட்டவணைகளைக் கொண்டு சோ வாக்கியத்தில் இணைக்கப்பட்ட பணியில், ஒரு பிபிபின் மாதிரி சிறந்ததை செய்தார். தொடர்பு அறிவிப்பு பணியில், ஒரு நன்றாக குறிப்பிட்ட பிரெட் மாதிரி சிறந்ததை செய்தார். இரண்டு வாக்கிய குறியீடுகள் பயன்படுத்தப்படுகின்றன, பிரெட் குறியீட்டை எதிர்பார்த்து வாக்கியம்-பிரெட்டை பயன்படுத்தும் போது பொ நாங்கள் இரண்டு வகையான இணைப்பு உரைகளை பயன்படுத்தி எங்கள் மாதிரிகளுக்கு பயிற்சி செய்தோம்: இந்த சோதனையில் உள்ள முடிவு முடிவு கணினியில் சரியான .341 கிடைத்தது என்பதை காட்டுகிறது. மறுபக்கத்தில், குறுக்கும் களம் கணினியில் 94% செயல்படுத்தப்பட்டது. இந்த குறிப்புகள் ஆச்சரியமான உரைகளுக்கு ஆராய்ச்சியின் கட்டுப்பாட்டு மையம் பயிற்சிக்க பயனுள்ளதாக இருக்க</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bu kagyz iňlis dilinde (EFL) surat çykyşynyň (argümat) eserlerini çykyp biljek bir arzuw görkezýär. Açmak prosesi iki adımdır, sözleri baglaýar we soňra olaryň ilişkilerini etiketleýändir. Biz her zady özbaşdak çykmak üçin birnäçe derin öwrenme arhitekturmalary bilen synanyşýarys. Sözlemde işi baglaşdyrmak üçin, bir biaffin nusgasy iň gowy etdi. etiket täblisasynda, eňleýin etiket täblisasynda BERT nusgasy iň gowy edipdi. Iki sözlem kodçysy işledildi we biz bejerdik ki, sözlem-BERT kodçysynyň tersine ol işe yaramaz nusgalary gowurak etýändigini görnüşdik. Modellerimizi iki tür paralel metin kullanarak eğitirdik: orijinal ses EFL eserleri ve annotatorlar tarafından geliştirilen eserleri üzerinde değerlendirdik. Denemek bolup domeniň soňunda soňunda bir sistemasyň .341-yň dogrylygyny ýetip bardygyny görkezýär. On the other hand, the cross-domain system achieved 94% performance of the domain system. Bu işaretler, gowy ýazylan metinler goş metinler üçin argüm taýýarlama sistemasyny trenlemek üçin faydaly bolup biler.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>یہ کاغذ انگلیسی زبان (EFL) کے مطابق بحث کی ساختاری مطالعہ کے بارے میں ایک تحقیق پیش کرتا ہے جو اس میں آواز ہے۔ پارسینگ پرسس دو قدم سے ہے، ارتباط کے کلمات کو متصل کرتا ہے اور پھر ان کے ارتباط کا لیبل کرتا ہے. ہم بہت سی عمیق سیکھنے کی معماری کے ساتھ آزمائش کرتے ہیں ہر کام کو آزاد کے ساتھ استعمال کرنے کے لئے۔ بات کی تعلق میں ایک بیفن مدل بہترین کام کیا گیا۔ رابطہ لیبلینگ کے کام میں ایک ٹھیک تنظیم BERT موڈل بہترین عمل کرتا تھا۔ Two sentence encoders are employed, and we observed that non-fine-tuning models generally performed better when using Sentence-BERT as opposed to BERT encoder. ہم نے ہمارے مدلکوں کو دو قسم کے متعادل متقابل متقابل استعمال کر دیا تھا: اصلی صدا کی EFL رسی اور ان لوگوں کو جو annotators کے ذریعہ بہتر ہوئے تھے، پھر ان کو اصلی رسی پر ارزش کر لیا تھا. آزمائش دکھاتا ہے کہ ایک ڈومین سیسٹم میں آخر-to-end کے طور پر .341 کی دقیق پہنچ گئی۔ دوسری طرف، کرس ڈومین سیسٹم نے ڈومین سیسٹم کی 94% فعالیت پائی۔ یہ نشانیاں ہیں کہ بہترین لکھی ہوئی پیغام بھی مفید ہو سکتے ہیں کہ آواز کے پیغام کے لئے آواز منڈ سیسٹم کی تعلیم کرنے کے لئے۔</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bu qoʻllar ingliz tilida (EFL) tilida argumentative tizimni ajratish uchun o'qituvchi o'rganishni tahrirlaydi. Bu bizning huddi hamma holatdir. Name Biz har bir vazifani o'xshash o'rganish maktablari bilan o'rganamiz. Bogʻliq vazifani bir so'zda biffin modeli eng yaxshi bajarildi. Maʼlumot bajarayotganda yaxshi BERT modeli eng yaxshi bajarildi. Ikki so'zlar kodlash qoidalari ishlaydi, va biz bir necha bogʻ'liq modellarni BERT kodlash bilan foydalanayotganda umuman yaxshi bajarish mumkin. Biz modellarimizni ikki turli parallel textlardan foydalanib o'rganimiz: asl EFL maslahatlari va taʼminlovchilar orqali o'zgartirdi, keyin ularni asl yozlarida qiymatish mumkin. Imtiyozni koʻrsatish mumkin, domen tizimining oxirigi oxirigi tizimi faqat .341 tizimga yetishdi. Бошқа тарафда, cross-domen tizimi domen tizimning 94% bajarishga erishildi. Name</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tờ giấy này cung cấp một nghiên cứu về các bài luận văn của ngôn ngữ Anh-như-ngôn ngữ-ngoại-Anh (EFL) mà có âm tính rất ồn ào. Cách phân tích gồm hai bước, nối các câu liên quan và sau đó khắc định quan hệ. Chúng tôi thử vài kiến trúc về học sâu để giải quyết mọi nhiệm vụ một cách độc lập. Trong câu kết nối câu này, mô hình hai cam đã làm tốt nhất. Trong nhiệm vụ gắn kết, mô hình BERT được chỉnh cẩn thận đã làm tốt nhất. Hai câu mã hóa phần tử được sử dụng, và chúng tôi quan sát rằng các mô hình chưa được tinh chỉnh thông thường hoạt động tốt hơn khi sử dụng. Chúng tôi đã đào tạo các mẫu bằng hai loại văn bản song song song: các bài thi EFL nguyên bản và những bài viết được sửa chữa, sau đó đánh giá chúng bằng các bài luận gốc. Thí nghiệm cho thấy rằng hệ thống miền-cuối-tới-kết đã đạt độ chính xác của.341. Mặt khác, hệ thống lãnh thổ đạt được tỉ lệ ứng dụng của hệ thống nội bộ. Đây là tín hiệu cho thấy văn bản viết tốt cũng có ích để đào tạo hệ thống khai thác tranh luận cho các văn bản ồn ào.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>本文引解析英语为外语(EFL)论证结构,其质嘈杂。 解析两步驿,链接关句,然后志之。 尝试数深学架构以自立也。 句链接事,字母模形为上。 在於事,微BERT为最。 用二句编码器,吾观之,比于BERT编码器,用句BERT时,非调形常善也。 吾以两体并行本教我模样:原始嘈杂EFL论文及由注者改进论文,然后于原始论文上对其评估。 实验者,端到端域内之0.341精也。 其一,跨域统成域94%之性也。 此明文本亦可用于训练嘈杂文本者参数掘而系之。</span></div></div><dl><dt>Anthology ID:</dt><dd>2021.bea-1.10</dd><dt>Volume:</dt><dd><a href=/volumes/2021.bea-1/>Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications</a></dd><dt>Month:</dt><dd>April</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/bea/>BEA</a>
| <a href=/venues/eacl/>EACL</a></dd><dt>SIG:</dt><dd><a href=/sigs/sigedu/>SIGEDU</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>97–109</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.bea-1.10>https://aclanthology.org/2021.bea-1.10</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">putra-etal-2021-parsing</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Jan Wira Gotama Putra, Simone Teufel, and Takenobu Tokunaga. 2021. <a href=https://aclanthology.org/2021.bea-1.10>Parsing Argumentative Structure in English-as-Foreign-Language EssaysEnglish-as-Foreign-Language Essays</a>. In <i>Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications</i>, pages 97–109, Online. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2021.bea-1.10>Parsing Argumentative Structure in English-as-Foreign-Language EssaysEnglish-as-Foreign-Language Essays</a> (Putra et al., BEA 2021)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.bea-1.10.pdf>https://aclanthology.org/2021.bea-1.10.pdf</a></dd><dt>Code</dt><dd><a href=https://github.com/wiragotama/bea2021><i class="fab fa-github"></i>&nbsp;wiragotama/bea2021</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.bea-1.10.pdf title="Open PDF of 'Parsing Argumentative Structure in English-as-Foreign-Language EssaysEnglish-as-Foreign-Language Essays'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Parsing+Argumentative+Structure+in+English-as-Foreign-Language+EssaysEnglish-as-Foreign-Language+Essays" title="Search for 'Parsing Argumentative Structure in English-as-Foreign-Language EssaysEnglish-as-Foreign-Language Essays' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-secondary d-flex flex-wrap justify-content-center" href="https://paperswithcode.com/paper/?acl=2021.bea-1.10" title="Code for 'Parsing Argumentative Structure in English-as-Foreign-Language EssaysEnglish-as-Foreign-Language Essays' on Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-big" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg><span class="pl-sm-2 d-none d-sm-inline">Code</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Parsing Argumentative Structure in English-as-Foreign-Language EssaysEnglish-as-Foreign-Language Essays'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Parsing Argumentative Structure in English-as-Foreign-Language EssaysEnglish-as-Foreign-Language Essays](https://aclanthology.org/2021.bea-1.10) (Putra et al., BEA 2021)</p><ul class=mt-2><li><a href=https://aclanthology.org/2021.bea-1.10>Parsing Argumentative Structure in English-as-Foreign-Language EssaysEnglish-as-Foreign-Language Essays</a> (Putra et al., BEA 2021)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Jan Wira Gotama Putra, Simone Teufel, and Takenobu Tokunaga. 2021. <a href=https://aclanthology.org/2021.bea-1.10>Parsing Argumentative Structure in English-as-Foreign-Language EssaysEnglish-as-Foreign-Language Essays</a>. In <i>Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications</i>, pages 97–109, Online. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>