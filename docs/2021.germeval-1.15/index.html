<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>HunterSpeechLab at GermEval 2021 : Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment ClassificationHunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="HunterSpeechLab at GermEval 2021 : Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment ClassificationHunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification" name=citation_title><meta content="Subhadarshi Panda" name=citation_author><meta content="Sarah Ita Levitan" name=citation_author><meta content="Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments" name=citation_conference_title><meta content="2021/9" name=citation_publication_date><meta content="https://aclanthology.org/2021.germeval-1.15.pdf" name=citation_pdf_url><meta content="100" name=citation_firstpage><meta content="104" name=citation_lastpage><meta property="og:title" content="HunterSpeechLab at GermEval 2021 : Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment ClassificationHunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification"><meta property="og:image" content="https://aclanthology.org/thumb/2021.germeval-1.15.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2021.germeval-1.15"><meta property="og:description" content="Subhadarshi Panda, Sarah Ita Levitan. Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments. 2021."><link rel=canonical href=https://aclanthology.org/2021.germeval-1.15></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab at GermEval 2021 : Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification<span class=acl-fixed-case>H</span>unter<span class=acl-fixed-case>S</span>peech<span class=acl-fixed-case>L</span>ab at <span class=acl-fixed-case>G</span>erm<span class=acl-fixed-case>E</span>val 2021: Does Your Comment Claim A Fact? Contextualized Embeddings for <span class=acl-fixed-case>G</span>erman Fact-Claiming Comment Classification</a>
<a id=af_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab by GermEval 2021: Het u Kommentaar Claim 'n Faak? Comment</a>
<a id=am_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>Lab at GermEval 2021: Is Your Comment Claim A Fact? Comment</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab في GermEval 2021: هل يدعي تعليقك حقيقة؟ الضمانات السياقية لتصنيف تعليقات ادعاء الحقائق الألماني</a>
<a id=az_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>GermEval 2021-də HunterSpeechLab: Sizin Komutanınız bir həqiqəti iddia edir? Almanca Fakat-Klasifikası üçün Kontekst Yazılımlar</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>Лаборатория на ДжермЕвал 2021: Коментарът ви твърди ли факт? Контекстualiзирани вграждания за класификация на коментари с твърдения за факти в Германия</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>গের্মেভাল ২০২১-এ হান্টার স্পেকল্যাব: তোমার গ্লায়াম কি এক ফ্যাক্ট? Comment</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? རང་ཉིད་ཀྱི་དོན་དག་ཕྱོགས་སྒྲིག་འགོད་ཀྱི་སྣང་ཚུལ་ལྡན་རྣམ་པ</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab u GermEval 2021: Kontekstualizirani integraciji za njemačku klasifikaciju činjenica</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Embeddings Contextualized for German Fact-Claiming Comment Classification</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab na GermEval 2021: Tvrdí váš komentář fakt? Kontextualizované vložení pro klasifikaci německých faktů</a>
<a id=da_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab på GermEval 2021: Hævder din kommentar et faktum? Kontekstualiserede indlejringer til tysk fact-claying Kommentar Klassificering</a>
<a id=de_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab bei GermEval 2021: Behauptet Ihr Kommentar eine Tatsache? Kontextualisierte Einbettungen für die Klassifizierung der deutschen Faktenklausel</a>
<a id=el_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>Το σχόλιό σας ισχυρίζεται ένα γεγονός; Ενσωματώσεις πλαισίων για γερμανικά σχόλια για ισχυρισμούς γεγονότων Ταξινόμηση σχολίων</a>
<a id=es_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab en GermEval 2021: ¿Su comentario afirma ser un hecho? Incrustaciones contextualizadas para la clasificación alemana de comentarios sobre afirmaciones de hechos</a>
<a id=et_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab GermEval 2021: kas teie kommentaar väidab fakti? Saksa faktide väidetavate kommentaaride klassifitseerimise kontekstualiseeritud manustamised</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Comment</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab GermEvalissa 2021: väittääkö kommenttisi faktaa? Konteksturoidut upotukset saksankielisille faktojen väittämistä koskeville kommenteille</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab au GermEval 2021 : Votre commentaire revendique-t-il un fait ? Embeddings contextualisés pour la classification des commentaires de revendication de faits allemands</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab ag GermEval 2021: An Éilíonn Do Trácht Fíricí? Leabaithe Comhthéacsúla d'Aicmiú Tráchtanna Gearmánacha Éilimh ar Fhíricí</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>Lab at GermEal 2021: Shin The Claim A Fact? KCharselect unicode block name</a>
<a id=he_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab ב GermEval 2021: האם הערה שלך טוענת עובדה? קישורים קונטקסטוליזציונים לסיפור העובדות הגרמניות</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>GermEval 2021 में हंटरस्पीचलैब: क्या आपकी टिप्पणी एक तथ्य का दावा करती है? जर्मन तथ्य-दावा टिप्पणी वर्गीकरण के लिए संदर्भित एम्बेडिंग</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab na GermEval 2021: Comment</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab a GermEval 2021-ben: A hozzászólása tényt állít? Kontextualizált beágyazások a német tényállításhoz Comment Osztályozás</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>Hunter SpeechLab-ը, ԳերմԷվալ 2021 թվականին. արդյո՞ք ձեր մեկնաբանությունը փաստ է պահանջում: Comment</a>
<a id=id_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab di GermEval 2021: Apakah Komentar Anda Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification</a>
<a id=is_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab a GermEval 2021: il tuo commento rivendica un fatto? Integrazioni contestualizzate per la rivendicazione tedesca dei fatti</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab at GermEval 2021:あなたのコメントは事実を主張しますか？ドイツ語の事実を主張するコメント分類のための文脈化された埋め込み</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>John Doe ? Name</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Comment</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>2021 Гермевальдегі HunterSpeechLab: Түсініктемеңіздің шындығын қалайсыз ба? Неміс факт- классификациялау үшін контекстуалды ендірулерComment</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>Germ Eval 2021:당신의 댓글은 이것이 사실이라고 주장합니까?독일 사실 진술 평론 분류의 어경화 삽입</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab at GermEval 2021: Ar Jūsų komentaras reikalauja fakto? Konkstualizuotos įrangos, skirtos Vokietijos faktų pareiškimo komentarų klasifikacijai</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab на GermEval 2021: Дали вашиот коментар тврди факт? Name</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>ഗെര്‍മെവാല്‍ 2021: നിങ്ങളുടെ ക്ലായം A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>2021 оны Гермевалд ХантерСпехЛаб: Түүнийг хэлэх үнэн гэж үү? Германы Фактик-Классификацийн контекстүүд</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab di GermEval 2021: Adakah Komen anda menuntut fakta? Name</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab f’GermEval 2021: Il-Kumment tiegħek jitlob fatt? Embeddings Contextualized for German Fact-Claiming Comment Classification</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab bij GermEval 2021: Claimt uw commentaar een feit? Gecontextualiseerde embeddings voor Duitse fact-claiming Comment Classificatie</a>
<a id=no_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab på GermEval 2021: Er kommentaren din løp ein faktus? Comment</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab w GermEval 2021: Czy Twój komentarz twierdzi, że jest faktem? Kontekstualizowane osadzenia dla niemieckiej klasyfikacji komentarza faktowego</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab no GermEval 2021: seu comentário afirma um fato? Incorporações contextualizadas para classificação alemã de comentários de reivindicação de fatos</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab la GermEval 2021: Comentariul tău pretinde un fapt? Încorporări contextualizate pentru afirmarea faptelor germane Comentariu Clasificare</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab на конференции GermEval 2021: Заявляет ли ваш комментарий о факте? Контекстуализированные вложения для немецкой фактологической классификации комментариев</a>
<a id=si_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>හැන්ටර් ස්පෙච්ලේබ් ජර්ම් එවෙල් 2021 වල: ඔයාගේ ප්‍රතිචාරයක් ඇත්තද? Comment</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab na GermEvalu 2021: Ali vaš komentar trdi dejstvo? Konteksturirane vdelave za nemško razvrstitev komentarjev za trditev dejstev</a>
<a id=so_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab at GermEval 2021: Je Comment Claim A Fact? Soo wareegayaasha Jarmalka</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab në GermEval 2021: A pretendon komenti juaj një fakt? Embeddings Contextualized for German Fact-Claiming Comment Classification</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab u GermEval 2021: Kontekstualizirani integraciji za njemaèke klasifikacije èinjenica</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab på GermEval 2021: Påstår din kommentar ett faktum? Kontextualiserade inbäddningar för tyska faktagranspråk Kommentar Klassificering</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>Lab ya HunterSpeechLab kwenye GermEval 2021: Je Comment Claim A Fact? Comment</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>ஜெர்ம்Eval 2021: உங்கள் குறிப்பு A Face? Comment</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Comment</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>GermEval 2021 میں HunterSpeechLab: Does your Comment Claim A Fact? Comment</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>Lab at GermEval 2021: Your Comment Claim A Fact? Comment</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>Hunter SpeechLab ở GermEvl 2021: Bài phát biểu của anh có thực tế không? Ảnh chiếu tương ứng cho khai thác dữ liệu Đức</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2021.germeval-1.15.pdf>HunterSpeechLab在GermEval 2021上,君论称实否? 用德语事实声明注类上下文嵌之</a></h2><p class=lead><a href=/people/s/subhadarshi-panda/>Subhadarshi Panda</a>,
<a href=/people/s/sarah-ita-levitan/>Sarah Ita Levitan</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In this paper we investigate the efficacy of using contextual embeddings from multilingual BERT and <a href=https://en.wikipedia.org/wiki/German_language>German BERT</a> in identifying fact-claiming comments in <a href=https://en.wikipedia.org/wiki/German_language>German</a> on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. Additionally, we examine the impact of formulating the classification problem as a multi-task learning problem, where the model identifies toxicity and engagement of the comment in addition to identifying whether it is fact-claiming. We provide a thorough comparison of the two BERT based models compared with a logistic regression baseline and show that German BERT features trained using a multi-task objective achieves the best F1 score on the test set. This work was done as part of a submission to GermEval 2021 shared task on the identification of fact-claiming comments.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In hierdie papier ondersoek ons die effektiviteit van die gebruik van contextual inbêdings van multilinglike BERT en Duitse BERT in die identifiseer van feit-aanklaarde kommentaar in Duitse op sosiale media. In addition, we examine the impact of formulating the classification problem as a multi-task learning problem, where the model identifies toxicity and engagement of the comment in addition to identifying whether it is fact-claiming. Ons verskaf 'n groot vergelyking van die twee BERT gebaseerde modele vergelyk met 'n logistike regresie basislien en wys dat Duitse BERT funksies onderwerp deur 'n multi-taak doel bereik die beste F1 telling op die toets stel. Hierdie werk is gedoen as deel van 'n ondersoek aan GermEval 2021 gedeel taak op die identifiseer van faktuur-aansoek kommentaar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>በዚህ ገጾች ውስጥ የሁለተኛውን የብሬት ቋንቋ እና የጀርመን ብERT ውይይት በጀርመን በማኅበራዊ ሚዲያ ላይ የውሸት ጥያቄዎችን ለማረጋገጥ ጥያቄን እናሳውቃለን፡፡ በተጨማሪም፣ የግንኙነቱን መግለጫ እንደ ብዙ ትምህርት ትምህርት መሆኑን በመፍጠር ላይ እናሳያልን፤ ሞዴል የጥካት እና የመስመር ግንኙነት ማረጋገጥ እውነተኛ ጥያቄ እንደ ሆነ ማረጋገጥ ነው፡፡ በሁለቱ BERT-based ምሳሌዎች በተለየ logistic regression baseline እናሳያቸዋለን፡፡ የጀርመን BERT የብዙዎች አካሄድ በተጠቃሚ ትክክል የተማረ የF1 score በመፈተናው ደረጃ እንዲደርስ እናሳያቸዋለን፡፡ ይህ ሥራ ለጌርEval 2021 የውሸት አካባቢ ትርጉም በማግኘት ላይ የተካፈለ ስራ እንዲሆን ተደረገ፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>في هذه الورقة ، نحقق في فعالية استخدام الزخارف السياقية من BERT متعدد اللغات والألمانية BERT في تحديد التعليقات التي تدعي الحقائق باللغة الألمانية على وسائل التواصل الاجتماعي. بالإضافة إلى ذلك ، ندرس تأثير صياغة مشكلة التصنيف كمشكلة تعلم متعددة المهام ، حيث يحدد النموذج السمية والتفاعل مع التعليق بالإضافة إلى تحديد ما إذا كان يدعي الحقائق. نحن نقدم مقارنة شاملة بين النموذجين المعتمدين على BERT مقارنة بخط أساس الانحدار اللوجستي ونبين أن ميزات BERT الألمانية المدربة باستخدام هدف متعدد المهام تحقق أفضل درجة F1 في مجموعة الاختبار. تم تنفيذ هذا العمل كجزء من إرسال إلى مهمة GermEval 2021 المشتركة بشأن تحديد تعليقات ادعاء الحقائق.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bu kağıtda, çoxlu dil BERT və Alman BERT'dan müxtəlif məlumatları istifadə etmək üçün Alman dilində çoxlu məlumatları təsdiqləmək üçün istifadə edirik. Daha çox iş öyrənməsi problemi olaraq klasifikasiya problemini, modeli istifadə etmək üçün zehirliyi və şəkillərin istifadəsini təsdiq edir. Biz iki BERT tabanlı modellərin loģistiki regresiya baseline ilə qarşılaşdığı müddətli bir qarşılaşdırmağını təmin edirik və Almanca BERT özelliklərinin çoxlu işlər məqsədilə təhsil edildiyini göstəririk ki, testdə ən yaxşı F1 nöqtəsini nəsib edir. Bu işin 2021 GermEval'a paylaşdığı şəhadətlərin təsdiqlənməsi haqqında paylaşdığı işin bir parças ı olaraq etdi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>В настоящата статия изследваме ефикасността на използването на контекстуални вграждания от многоезични BERT и немски BERT за идентифициране на фактически коментари на немски език в социалните медии. Освен това изследваме въздействието на формулирането на проблема за класификация като проблем с многозадачи за учене, където моделът идентифицира токсичността и ангажираността на коментара в допълнение към идентифициране дали той е фактически претендиращ. Предлагаме задълбочено сравнение на двата модела базирани на базата на логистична регресия в сравнение с базовата линия и показваме, че германските функции, обучени с помощта на многозадача, постигат най-добрия резултат от теста. Тази работа беше направена като част от подаване на споделена задача за идентифициране на фактически коментари.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>এই পত্রিকায় আমরা সামাজিক মিডিয়ায় জার্মানের বাস্তবতা দাবী করার জন্য বিভিন্ন ভাষায় বিবের্ট এবং জার্মান বার্টি থেকে বিভিন্ন ভাষায় ব তাছাড়াও, আমরা এই ক্লাসাফিকেশনের সমস্যা গঠনের প্রভাব পরীক্ষা করি বহুক্ষেত্র-কাজের শিক্ষা সমস্যা হিসেবে, যেখানে মডেল ব্যস্ত এবং মন্তব্যের অংশগ্রহণের পর We provide a thorough comparison of the two BERT based models compared with a logistic regression baseline and show that German BERT features trained using a multi-task objective achieves the best F1 score on the test set. এই কাজটি গের্মেভাল ২০২১-এর প্রতি প্রদানের একটি অংশ হিসেবে করা হয়েছে বাস্তবতা দাবী করা মন্তব্যের পরিচিতি নিয়ে।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་སྤྱི་ཚོགས་སྐད་ཡིག་གི་BERT དང་སྐད་ཡིག་BERT་ལས་ཕན་ཚུན་ཐུག་གཏོང་ཁང་ལ་གཏོང་མཁན་གྱི་ལྟ་བ་རྟོགས་བ འོན་ཀྱང་། ང་ཚོས་དབྱེ་རིག་གི་དཀའ་ངལ་སྤྲོད་ཀྱི་ཆ་རྐྱེན་གྱི་དཀའ་ངལ་ཞིབ་དཔྱད་བྱས་ན། We provide a thorough comparison of the two BERT based models compared with a logistic regression baseline and show that German BERT features trained using a multi-task objective achieves the best F1 score on the test set. ལས་ཀ་འདི་ནི་(GermEval)སྤྱི་ཚོལ་༢༠༡༢་ལོའི་ནང་དུ་འཇུག་སྣོད་འཛིན་གྱི་ལས་ཀ་གསལ་བཤད་པ་ཞིག་ངོས་འཛིན་བྱེད་སོང་།</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>U ovom papiru istražujemo učinkovitost korištenja kontekstualnih integracija iz multijezičkih BERT i Njemačkih BERT-a u identifikaciji komentara koji tvrde činjenice na njemačkim na društvenim medijima. Osim toga, istražujemo učinak formiranja klasifikacijskog problem a kao problem sa multizadatačnim učenjem, gdje je model identificirao toksičnost i uključenje komentara, dodatno identificirao je li to činjenica. Mi pružamo temeljno usporedbu dva modela baziranog na BERT u usporedbi sa početnom linijom logističke regresije i pokazujemo da njemačka BERT karakteristika obučena koristeći cilj višezadataka postiže najbolji rezultat F1 na testu. Ovaj rad je urađen u sklopu podataka GermEval 2021. godine zajedničkom zadatku o identifikaciji komentara koji tvrde činjenice.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>En aquest paper investigam l'eficacia d'utilitzar integracions contextuals de BERT multilingüe i BERT alemanya per identificar comentaris que afirmaven fets en alemany en els mitjans socials. A més, examinem l'impacte de la formulació del problem a de classificació com un problema d'aprenentatge multitascat, on el model identifica la toxicitat i l'involucració del comentari a més d'identificar si està afirmant els fets. Ens proporcionem una comparació detallada dels dos models basats en BERT comparat amb una base de regressió logística i demostrem que les característiques alemanes de BERT entrenats fent servir un objectiu multitasc aconsegueixen el millor puntuatge F1 en el conjunt de tests. Aquesta feina va ser feta com part d'una presentació a GermEval 2021 de tasca compartida sobre la identificació de comentaris que afirmaven fets.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>V tomto článku zkoumáme efektivitu využití kontextových vložení z vícejazyčného BERT a německého BERT při identifikaci faktových komentářů v němčině na sociálních médiích. Dále zkoumáme dopad formulace klasifikačního problému jako multi-tasking learning problému, kde model identifikuje toxicitu a angažovanost komentáře a zároveň identifikuje, zda se jedná o faktické tvrzení. Poskytujeme důkladné srovnání dvou modelů založených na BERT ve srovnání s logistickou regresí základní linií a ukážeme, že německé vlastnosti BERT trénované pomocí multi-tasking objektivu dosahují nejlepšího F1 skóre v testovací sadě. Tato práce byla provedena v rámci předložení společného úkolu GermEval 2021 na identifikaci skutečnostních komentářů.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>I denne artikel undersøger vi effektiviteten af at bruge kontekstuelle indlejringer fra flersprogede BERT og tyske BERT til at identificere fakta-hævdende kommentarer på tysk på sociale medier. Derudover undersøger vi effekten af at formulere klassificeringsproblemet som et multi-task learning problem, hvor modellen identificerer toksicitet og engagement af kommentaren samt identificerer, om det er faktahævdende. Vi leverer en grundig sammenligning af de to BERT-baserede modeller sammenlignet med en logistisk regression baseline og viser, at tyske BERT-funktioner trænet ved hjælp af et multi-task mål opnår den bedste F1 score på testsættet. Dette arbejde blev udført som en del af en indsendelse til GermEval 2021 delt opgave om identifikation af faktahævdende kommentarer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In diesem Beitrag untersuchen wir die Wirksamkeit kontextueller Einbettungen von mehrsprachigen BERT und deutschen BERT bei der Identifizierung faktenbezogener Kommentare in Deutsch in sozialen Medien. Darüber hinaus untersuchen wir die Auswirkungen der Formulierung des Klassifizierungsproblems als Mehraufgaben-Lernproblem, wobei das Modell Toxizität und Engagement des Kommentars identifiziert sowie identifiziert, ob es sich um Fakten-Claiming handelt. Wir führen einen gründlichen Vergleich der beiden BERT-basierten Modelle mit einer logistischen Regressionsbasis durch und zeigen, dass deutsche BERT-Features, die mit einem Multi-Task-Ziel trainiert wurden, die beste F1-Punktzahl im Testset erzielen. Diese Arbeit wurde im Rahmen einer gemeinsamen Aufgabe an GermEval 2021 zur Identifizierung faktenbezogener Kommentare durchgeführt.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Σε αυτή την εργασία διερευνούμε την αποτελεσματικότητα της χρήσης περιεχομένων ενσωμάτωσης από πολυγλωσσικό BERT και γερμανικό BERT στον εντοπισμό ισχυριζόμενων γεγονότων σχολίων στα γερμανικά στα μέσα κοινωνικής δικτύωσης. Επιπλέον, εξετάζουμε τον αντίκτυπο της διατύπωσης του προβλήματος ταξινόμησης ως μαθησιακό πρόβλημα πολλαπλών εργασιών, όπου το μοντέλο προσδιορίζει την τοξικότητα και την εμπλοκή του σχολίου, εκτός από τον προσδιορισμό του αν είναι ισχυρισμός γεγονότων. Παρέχουμε μια εμπεριστατωμένη σύγκριση των δύο μοντέλων που βασίζονται στο BERT σε σύγκριση με μια βάση λογιστικής παλινδρόμησης και δείχνουν ότι τα γερμανικά χαρακτηριστικά του BERT που εκπαιδεύονται χρησιμοποιώντας έναν στόχο πολλαπλών εργασιών επιτυγχάνουν την καλύτερη βαθμολογία F1 στο σύνολο δοκιμών. Το έργο αυτό πραγματοποιήθηκε στο πλαίσιο μιας υποβολής στο κοινό έργο της GermEval 2021 σχετικά με τον προσδιορισμό των παρατηρήσεων που ισχυρίζονται γεγονότα.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>En este artículo investigamos la eficacia del uso de incrustaciones contextuales de BERT multilingües y BERT alemán para identificar comentarios que afirman hechos en alemán en las redes sociales. Además, examinamos el impacto de formular el problema de clasificación como un problema de aprendizaje multitarea, en el que el modelo identifica la toxicidad y el compromiso del comentario, además de identificar si se trata de una afirmación de hechos. Proporcionamos una comparación exhaustiva de los dos modelos basados en BERT en comparación con una línea de base de regresión logística y mostramos que las entidades BERT alemanas entrenadas con un objetivo multitarea logran la mejor puntuación de F1 en el conjunto de pruebas. Este trabajo se realizó como parte de una presentación a la tarea compartida de GermEval 2021 sobre la identificación de comentarios de denuncia de hechos.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Käesolevas töös uurime mitmekeelsete BERTi ja saksa BERTi kontekstipõhiste manustamiste tõhusust sotsiaalmeedias faktidele väidetavate kommentaaride tuvastamisel saksa keeles. Lisaks uurime klassifitseerimisprobleemi kui mitmeülesandelise õppeprobleemi sõnastamise mõju, kus mudel tuvastab kommentaari toksilisuse ja kaasatuse lisaks tuvastab, kas see on faktidele väidetav. Pakume põhjalikku võrdlust kahe BERT-põhise mudeli võrreldes logistilise regressiooni algväärtusega ja näitame, et Saksa BERT-funktsioonid, mis on treenitud mitme ülesandega, saavutavad testikomplekti parima F1 skoori. See töö tehti osana GermEval 2021 jagatud ülesandest tuvastada fakte väidetavad kommentaarid.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>در این کاغذ ما از استفاده از وسیله‌های متوسط از BERT و BERT متوسط آلمانی تحقیق می‌کنیم تا توضیح‌های حقیقت را در رسانه‌های اجتماعی در آلمان شناسایی کنیم. اضافه‌ای از این، ما تاثیر فرمول مشکل فرمول‌سازی را به عنوان مشکل یادگیری چندین کار تحقیق می‌کنیم، جایی که مدل سمی و مشترک توضیح را علاوه بر شناسایی که آیا آن حقیقت‌شناسی است، شناسایی می‌کند. ما یک مقایسه کامل از دو مدل بنیادی BERT را در مقایسه با یک خط بنیادی بازگشت لوژیک پیشنهاد می‌کنیم و نشان می‌دهیم که ویژه‌های BERT آلمانی با استفاده از هدف چندین کار آموزش داده شده با بهترین امتیاز F1 در مجموعه آزمایش می‌رسد. این کار به عنوان بخشی از تسلیم به جرمEval 2021 کار مشترک در مورد شناسایی توضیح‌های حقیقت‌جویی انجام شد.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tässä artikkelissa selvitämme monikielisten BERT- ja saksankielisten BERT-upotusten käytön tehokkuutta faktoja väittävien kommenttien tunnistamisessa saksaksi sosiaalisessa mediassa. Lisäksi tarkastelemme luokitteluongelman muotoilun vaikutusta monitehtäväoppimisongelmana, jossa malli tunnistaa kommentin myrkyllisyyden ja sitoutumisen sekä selvittää, onko se faktaesitys. Vertaamme perusteellisesti molempia BERT-pohjaisia malleja logistiseen regressioon ja osoitamme, että monitehtävätavoitteella koulutetut saksalaiset BERT-ominaisuudet saavuttavat parhaan F1-pisteen testisarjassa. Tämä työ tehtiin osana GermEval 2021:n jaettua tehtävää faktoja esittävien kommenttien tunnistamisesta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dans cet article, nous étudions l'efficacité de l'utilisation d'intégrations contextuelles du BERT multilingue et du BERT allemand pour identifier les commentaires factuels en allemand sur les réseaux sociaux. En outre, nous examinons l'impact de la formulation du problème de classification en tant que problème d'apprentissage multitâche, où le modèle identifie la toxicité et l'engagement du commentaire en plus de déterminer s'il s'agit d'allégations factuelles. Nous fournissons une comparaison approfondie des deux modèles basés sur BERT par rapport à une base de régression logistique et montrons que les entités BERT allemandes entraînées à l'aide d'un objectif multi-tâches obtiennent le meilleur score F1 sur l'ensemble de tests. Ce travail a été effectué dans le cadre d'une soumission à la tâche partagée GermEval 2021 sur l'identification des commentaires factuels.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sa pháipéar seo déanaimid imscrúdú ar a éifeachtaí atá sé úsáid a bhaint as leabaithe comhthéacsúla ó BERT ilteangach agus ó BERT Gearmáinise chun tráchtanna a éilíonn fíricí i nGearmáinis ar na meáin shóisialta a aithint. Ina theannta sin, scrúdaíonn muid an tionchar a bheadh ag fadhb an aicmithe a fhoirmliú mar fhadhb foghlama il-tasc, áit a n-aithnítear sa tsamhail tocsaineacht agus rannpháirtíocht na tráchtaireachta chomh maith le sainaithint an bhfuil fíoras á éileamh. Cuirimid comparáid críochnúil ar fáil idir an dá mhúnla atá bunaithe ar CRET i gcomparáid le bonnlíne aischéimnithí loighistice agus léirímid go mbaineann gnéithe BERT Gearmánacha oilte ag baint úsáide as cuspóir il-tasc an scór F1 is fearr ar an tacar tástála. Rinneadh an obair seo mar chuid d’aighneacht chuig GermEval 2021 comhthasc maidir le tuairimí a éilíonn fíricí a aithint.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A cikin wannan takarda, Munã yin ƙidãya a kan amfani da matsayin mataimaki daga multi-lingui BERT da Jajeruman BERT dõmin a gane iznin da ke faɗa gaskiya a cikin jeruman a kan mitandan jamii. Ina ƙaranci, Munã jarraba matsalar kunnuwa masu fasalin kamar wata fitina na mai amfani da aiki masu yawa, a inda motel yana gane aikin mai tozarci da kuma ana sami izni da kuma a bayan ka gane shi ko yana madaidaita. Tuna samar da misãlai biyu masu basa BERT sami da kuma a danne logistic regression Baselin kuma Muke nuna cewa karatun BERT na da amfani da abun multi-aikin ya sami mafi kyaun F1 score kan jarraba. Wannan aikin aka samar da shi kamar wani juyi zuwa Germeval 2021 mai shirin aikin da aka samu shi a kan gane na-dai-rayon.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>בעיתון הזה אנו חוקרים את היעילות של השימוש בתכניות קונטקסטיות מ-BERT רבשפותית וגרמנית BERT בזיהוי תגובות בעובדות בגרמנית על תקשורת חברתית. בנוסף, אנו בודקים את ההשפעה של התייצבות של בעיית ההקלטה כבעיה ללמוד במשימות רבות, שבו המודל מזהה רעילות ומתערבות של התערבות בנוסף לזהות אם זו טענת עובדות. אנו מספקים שיוואי יסודי של שני הדוגמנים המבוססים על BERT בהשוואה לבסיס גירוס לוגיסטי ומראים שהתכונות גרמניות BERT מאומנות באמצעות מטרה רבה משימות משיגות את הציון F1 הטוב ביותר בסט הבדיקות. העבודה הזו נעשתה כחלק מההועברה לגרמEval 2021 משימה משותפת על זיהוי העובדות טוענות עובדות.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>इस पेपर में हम सोशल मीडिया पर जर्मन में तथ्य-दावा टिप्पणियों की पहचान करने में बहुभाषी BERT और जर्मन BERT से प्रासंगिक एम्बेडिंग का उपयोग करने की प्रभावकारिता की जांच करते हैं। इसके अतिरिक्त, हम वर्गीकरण समस्या को बहु-कार्य सीखने की समस्या के रूप में तैयार करने के प्रभाव की जांच करते हैं, जहां मॉडल यह पहचानने के अलावा विषाक्तता और टिप्पणी की सगाई की पहचान करता है कि क्या यह तथ्य-दावा है। हम एक रसद प्रतिगमन आधार रेखा की तुलना में दो BERT आधारित मॉडल की पूरी तरह से तुलना प्रदान करते हैं और दिखाते हैं कि एक बहु-कार्य उद्देश्य का उपयोग करके प्रशिक्षित जर्मन BERT विशेषताएं परीक्षण सेट पर सबसे अच्छा F1 स्कोर प्राप्त करती हैं। यह काम GermEval 2021 साझा कार्य के लिए एक सबमिशन के हिस्से के रूप में किया गया था तथ्य-दावा टिप्पणियों की पहचान पर।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>U ovom papiru istražujemo djelotvornost korištenja kontekstualnih integracija iz multijezičkih BERT-a i njemačkih BERT-a u identifikaciji komentara koji tvrde činjenice na njemačkim na društvenim medijima. Osim toga, istražujemo učinak formuliranja klasifikacijskog problem a kao problem sa učenjem multizadataka, gdje je model identificirao toksičnost i uključenje komentara, dodatno identificirao je li to činjenica. Mi pružamo temeljno usporedbu dva modela baziranog na BERT u usporedbi s početnom linijom logističke regresije i pokazujemo da njemačke BERT karakteristike obučene s višezadatačnim ciljem postignu najbolji rezultat F1 na testu. Ovaj rad je učinio kao dio podataka GermEvalu 2021. godine zajedničkom zadatku o identifikaciji komentara koji tvrde činjenice.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ebben a tanulmányban a BERT és a német BERT kontextuális beágyazásainak hatékonyságát vizsgáljuk a közösségi médiában megjelenő, német nyelvű megjegyzések azonosításában. Ezenkívül megvizsgáljuk a besorolási probléma többfeladatos tanulási problémaként való megfogalmazásának hatását, ahol a modell azonosítja a megjegyzés toxicitását és elkötelezettségét, valamint azonosítja, hogy tényállításról van szó. Alapos összehasonlítást nyújtunk a két BERT alapú modell logisztikai regressziós alapjával összehasonlítva, és megmutatjuk, hogy a többfeladatos célkitűzéssel kiképzett német BERT funkciók elérik a legjobb F1 pontszámot a tesztkészleten. Ezt a munkát a GermEval 2021 közös feladatának benyújtása részeként végeztük a tényállító észrevételek azonosításával kapcsolatban.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Այս թղթի մեջ մենք ուսումնասիրում ենք, թե արդյունավետությունը օգտագործելով բազլեզու BER-ի և գերմանացի BER-ի կոնտեքստոնալ ներդրումներ' հասարակական լրատվամիջոցների մասին գերմանացի լեզվով փաստեր հայտնելու համար: Ավելին, մենք ուսումնասիրում ենք դասակարգման խնդիրը որպես բազմախնդիր ուսուցման խնդիր ձևավորելու ազդեցությունը, որտեղ մոդելը որոշում է մոտեցումների թունավորությունը և ներգրավումը, բացի նրանից, թե արդյոք այն փաստեր է պնդում: Մենք տրամադրում ենք երկու BER-ի հիմնված մոդելների հիմնական համեմատությունը, համեմատելով լոգոստիկ ռեգրեսիայի հիմնական հիմքի հետ, և ցույց ենք տալիս, որ գերմանական BER-ի առանձնահատկությունները, որոնք վարժեցվել են օգտագործելով բազմախնդիր օբ Այս աշխատանքը կատարվել է որպես մի մաս, որը ներկայացվել է Գերմ Էվալ 2021 թվականին ընդհանուր խնդիրը փաստեր պահանջող մեկնաբանությունների հայտնաբերման մասին:</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dalam kertas ini kami menyelidiki efektivitas menggunakan embedding kontekstual dari BERT berbagai bahasa dan BERT Jerman dalam mengidentifikasi komentar fakta-klaim dalam Jerman pada media sosial. Selain itu, kami memeriksa dampak dari formulasi masalah klasifikasi sebagai masalah belajar multi-tugas, di mana model mengidentifikasi toksicitas dan keterlibatan komentar selain mengidentifikasi apakah itu fakta-klaim. Kami menyediakan perbandingan teliti dari dua model berdasarkan BERT dibandingkan dengan dasar regresi logistik dan menunjukkan bahwa fitur BERT Jerman dilatih menggunakan tujuan multi-tugas mencapai skor F1 terbaik pada set tes. Kerja ini dilakukan sebagai bagian dari pengiriman kepada GermEval 2021 tugas berbagi mengenai identifikasi komentar fakta-claiming.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In questo articolo esaminiamo l'efficacia dell'utilizzo di incorporazioni contestuali di BERT multilingue e BERT tedesco nell'identificare commenti di fatto in tedesco sui social media. Inoltre, esaminiamo l'impatto della formulazione del problema di classificazione come un problema di apprendimento multi-task, dove il modello identifica la tossicità e l'engagement del commento oltre a identificare se è fact-claim. Forniamo un confronto approfondito dei due modelli basati su BERT confrontati con una base di regressione logistica e mostriamo che le caratteristiche BERT tedesche addestrate utilizzando un obiettivo multi-task raggiungono il miglior punteggio F1 sul set di test. Questo lavoro è stato svolto nell'ambito di una presentazione al compito condiviso GermEval 2021 sull'identificazione dei commenti di fatto.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>この論文では、ソーシャルメディア上のドイツ語での事実を主張するコメントを特定する際に、多言語のBERTとドイツ語のBERTからの文脈埋め込みを使用することの有効性を調査します。さらに、分類問題をマルチタスク学習問題として定式化することの影響を検討する。そこでは、モデルは毒性とコメントのエンゲージメントを特定し、それが事実主張であるかどうかを特定する。ロジスティック回帰ベースラインと比較した2つのBERTベースモデルの徹底的な比較を提供し、マルチタスク目標を使用して訓練されたドイツのBERT特徴が試験セット上で最高のF 1スコアを達成することを示します。この作業は、事実を主張するコメントの特定に関するGermEval 2021への提出の一部として行われました。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nang pepulan iki, awak dhéwé nyokot nggunakake effek nggambar embedding contextual karo multilanggar BERT karo BERT nggambar barang kelangan kuwi nggawe Komentar sapa-kedahané ning aleman nganggo media sotiane. Label Awak dhéwé ngewehke perusahaan karo model sing sampek duwé BERT sampek karo perusahaan langgambar barang nggawe barang resmi Wuhané iki wis rampun ning pating nggawe gerapakan dhe germinval 2020 ora bisa ngejaraké perusahaan anyong komentar nggawe barang-barang.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ამ დოგომაში ჩვენ შევხედავთ კონტექსტური ინბედინგიების გამოყენება მრავალენგური BERT და გერმანეთის BERT-ის განსაზღვრებით ფაქტის კონტაქტის კონტაქტის გამოყენება საზოგად დამატებით, ჩვენ კლასიფიკაციის პრობლემას ფორმულაციის შესახებ გავაკეთებთ, რომელსაც მოდელემა ტექსტიურობა და კომენტურის შესახებ განვიცნობა თუ არა ეს ფაქტის შესახებ. ჩვენ გვეყენებთ ბერტის ორი მოდელთან დამატებული მოდელების დამატებით ლოგისტიკური რეგრესის ბაზი ხაზი და ჩვენ ჩვენებთ, რომ გერმანეთი BERT ფუნქციები, რომლებიც მრავალ დავალების მიყენებული მიზეზით, გავაკ ეს სამუშაო გავაკეთებულია როგორც ჯერმEval 2021-ში გაყოფილი სამუშაო სამუშაო სამუშაო შესახებ ფაქტის კომენტრების განსაზღვრებაზე.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Бұл қағазда біз бірнеше тілді BERT және неміс BERT тілдерінің неміс мәліметтерінің жазбаларын анықтау үшін неміс мәліметтерінің жазбаларын қолдануға мүмкіндігін зерттеп отырмыз. Қосымша, біз классификациялау мәселесін бірнеше тапсырма оқыту мәселесі ретінде формуляциялау нәтижесін тексереміз. Бұл үлгі тек қандай тапсырманы анықтау үшін, мәселелердің тәсіліктерінің тоғызд Біз, логистикалық регрессия негізгі жолымен салыстырылған екі BERT негізгі үлгілерді тұрақты салыстырып, неміс BERT қасиеттері бірнеше тапсырма мақсатын қолдану арқылы бірнеше тапсырма мақсатын қолдану үшін те Бұл жұмыс 2021 жылы GermEval-ге ортақ тапсырманы таңдау үшін факты жайлы түсініктемелерді анықтау үшін ортақ тапсырманың бөлігі болды.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>본고에서 우리는 다어버트와 독일어버트의 언어 환경을 이용하여 소셜 미디어에 독일어 사실 진술 평론을 식별하는 유효성을 연구했다.그 밖에 우리는 분류 문제를 다중 임무 학습 문제로 표현하는 영향도 연구했다. 이 모델은 평론이 사실 성명인지 아닌지를 확인하는 것 외에 평론의 독성과 참여도를 확정했다.우리는 두 개의 버트 기반 모델과 논리 회귀 기선을 철저하게 비교하고 다중 임무 목표 훈련을 사용하는 독일의 버트 특징이 시험집에서 최상의 F1 점수를 얻었다는 것을 나타냈다.이 작업은 GermEval 2021 공유 임무에 제출한 일부분으로 이루어졌으며, 이 임무는 사실을 식별하고 의견을 진술하는 데 관련된다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Šiame dokumente mes tiriame, kaip veiksminga naudoti daugiakalbį BERT ir Vokietijos BERT turinčius kontekstinius įterpimus nustatant faktus teigiančias komentaras vokiečių kalba apie social in ę žiniasklaidą. Additionally, we examine the impact of formulating the classification problem as a multi-task learning problem, where the model identifies toxicity and engagement of the comment in addition to identifying whether it is fact-claiming. Mes išsamiai palyginame du BERT pagrįstus modelius, palyginti su logistinės regresijos pradiniu lygiu, ir parodome, kad Vokietijos BERT savybės, parengtos naudojant daugiafunkcinį tikslą, pasiekia geriausią bandymų rinkinio F1 rezultatą. Šis darbas buvo atliktas pateikus „GermEval 2021“ bendrą užduotį nustatyti faktus pareiškančias pastabas.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Во овој весник ја истражуваме ефикасноста на употребата на контекстни вложувања од мултијазичните БЕРТ и Германските БЕРТ во идентификацијата на коментари кои тврдат факти на германски за социјалните медиуми. Additionally, we examine the impact of formulating the classification problem as a multi-task learning problem, where the model identifies toxicity and engagement of the comment in addition to identifying whether it is fact-claiming. Ние обезбедуваме темелна споредба на двата модели базирани на БЕРТ во споредба со логистичката регресна основа и покажуваме дека германските БЕРТ карактеристики тренирани користејќи мултизадачна цел го постигнуваат најдобриот резултат F1 на тестот. Оваа работа беше направена како дел од поднесувањето на GermEval 2021 заедничка задача за идентификација на коментарите кои тврдат факти.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ഈ പത്രത്തില്‍ നമ്മള്‍ സാമൂഹ്യ മാധ്യമങ്ങളില്‍ നിന്നും പല ഭാഷകങ്ങളില്‍ നിന്നും ജര്‍മ്മന്‍ ബെര്‍ട്ടിയില്‍ നിന്നും അഭിപ്രായം ഉപയോഗിക്കുന് കൂടാതെ, ക്ലാസ്ഫിക്ഷന്‍ പ്രശ്നത്തിന്റെ പ്രഭാവം നമ്മള്‍ പരിശോധിക്കുന്നത് പല ജോലി പഠിക്കുന്ന പ്രശ്നങ്ങളായിട്ടാണ്. അതിന്റെ മോഡല്‍ വിഷയത്തിലും ഒരു ലോഗിസ്റ്റിക്ക് റിക്രഷന്‍ ബെസ്റ്റ് ബെര്‍ട്ടിന്റെ അടിസ്ഥാനത്തുള്ള രണ്ട് മോഡലുകളുടെ തുല്യമായ ഒരു തുല്യമായ തുല്യമാണ് ഞങ്ങള്‍ നല്‍കുന്നത്. പരീക്ഷണസെറ്റി ഗെര്‍മെവാല്‍ 2021-ലേക്ക് കൊടുക്കുന്നതിന്‍റെ ഒരു ഭാഗമായി ഈ ജോലി ചെയ്തതാണ് സത്യത്തിന്‍റെ അഭിപ്രായത്തിന്‍റെ തി</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Энэ цаасан дээр бид олон хэлний BERT болон Герман BERT-ын орчин үеийн төвлөрүүлэлтийг Германы нийгмийн мэдээллийн тухай мэдээллийг тодорхойлж чадахын тулд нөлөөтэй байдлыг судалж байна. Мөн бид хэлбэрийн асуудлыг олон ажлын суралцах асуудлыг тодорхойлох нөлөөг судалж байна. Загварын загвар нь тодорхойлолтой байдлыг тодорхойлдог. Үнэндээ тодорхойлдог эсэхийг тодорхойлдог. Бид Логистикийн регрессийн суурь шулуунтай харьцуулсан хоёр BERT суурь загварын жишээлбэл харьцуулж, Герман BERT нь олон ажлын зорилго ашиглан сургалтын чадварыг харуулж байна. Энэ ажил 2021 оны GermEval-д үнэндээ илэрхийлж буй комментарын тодорхойлолтын тухай хуваалцах ажлын нэг хэсэг болсон.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dalam kertas ini kami menyelidiki kegagalan menggunakan penyembedding kontekstual dari BERT berbilang bahasa dan BERT Jerman dalam mengenalpasti komentar-mengklaim fakta dalam Jerman pada media sosial. Selain itu, kami memeriksa kesan daripada membentuk masalah klasifikasi sebagai masalah pembelajaran berbilang-tugas, di mana model mengenalpasti toksiciti dan keterlibatan komentar selain mengenalpasti sama ada ia adalah fakta-claiming. Kami menyediakan perbandingan teliti dua model berdasarkan BERT dibandingkan dengan dasar regresi logistik dan menunjukkan bahawa ciri-ciri BERT Jerman dilatih menggunakan objektif berbilang-tugas mencapai skor F1 terbaik pada set ujian. This work was done as part of a submission to GermEval 2021 shared task on the identification of fact-claiming comments.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>F’dan id-dokument ninvestigaw l-effikaċja tal-użu ta’ inkorporazzjonijiet kuntestwali minn BERT multilingwi u BERT Ġermaniż fl-identifikazzjoni ta’ kummenti li jsostnu l-fatti fil-Ġermaniż dwar il-midja soċjali. Barra minn hekk, jeżaminaw l-impatt tal-formulazzjoni tal-problem a ta’ klassifikazzjoni bħala problema ta’ tagħlim b’ħafna kompiti, fejn il-mudell jidentifika t-tossiċit à u l-involviment tal-kumment flimkien mal-identifikazzjoni ta’ jekk huwiex dikjarazzjoni ta’ fatti. Aħna nipprovdu tqabbil bir-reqqa taż-żewġ mudelli bbażati fuq BERT meta mqabbel ma’ linja bażi ta’ rigressjoni loġistika u nuru li l-karatteristiċi Ġermaniżi BERT imħarrġa bl-użu ta’ objettiv multikompitu jilħqu l-a ħjar punteġġ F1 fis-sett tat-test. Dan ix-xogħol sar bħala parti minn sottomissjoni lill-GermEval 2021 kompitu komuni dwar l-identifikazzjoni ta’ kummenti li jsostnu l-fatti.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In dit artikel onderzoeken we de effectiviteit van het gebruik van contextuele embeddings van meertalige BERT en Duitse BERT bij het identificeren van feiten claimende opmerkingen in het Duits op sociale media. Daarnaast onderzoeken we de impact van het formuleren van het classificatieprobleem als een multi-task leerprobleem, waarbij het model de toxiciteit en betrokkenheid van de opmerking identificeert naast het identificeren van de fact claiming. We bieden een grondige vergelijking van de twee BERT gebaseerde modellen vergeleken met een logistieke regressie baseline en laten zien dat Duitse BERT-functies getraind met behulp van een multi-task objectief de beste F1 score op de testset behalen. Dit werk werd gedaan als onderdeel van een inzending aan GermEval 2021 gedeelde taak over het identificeren van feiten claimende opmerkingen.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>I denne papiret undersøker vi effektiviteten for å bruka kontekstiske innbygging frå fleirspråk BERT og tysk BERT i å identifisera faktiske kommentarar i tysk på sosiale media. I tillegg undersøker vi effekten til å formera klassifikasjonsprobleten som eit problem med å lære fleire oppgåver, der modellen identifiserer toksikitet og involvering av kommentaren i tillegg til å identifisera om det er faktisk opplæring. Vi tilbyr ein røyd samanlikning av dei to BERT-baserte modelane samanlikna med ein logistisk regresjonsbaselinje og viser at tysk BERT-funksjonar trengte med eit multioppgåvemål gjer det beste F1-poeng på testsettet. Dette arbeidet vart gjort som del av ein tillegg til GermEval 2021 delt oppgåve om identifiseringa av faktisk kommentarar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>W niniejszym artykule badamy skuteczność wykorzystania kontekstowych osadzeń z wielojęzycznych BERT i niemieckich BERT w identyfikacji komentarzy twierdzących fakty w języku niemieckim w mediach społecznościowych. Dodatkowo badamy wpływ sformułowania problemu klasyfikacji jako wielozadaniowego problemu uczenia się, w którym model identyfikuje toksyczność i zaangażowanie komentarza, a także identyfikuje, czy jest on twierdzący fakty. Przeprowadzamy dokładne porównanie dwóch modeli opartych na BERT w porównaniu z regresją logistyczną i pokazujemy, że niemieckie cechy BERT trenowane przy użyciu obiektu wielozadaniowego osiągają najlepszy wynik F1 w zestawie testowym. Prace te zostały wykonane w ramach zgłoszenia do GermEval 2021 wspólnego zadania dotyczącego identyfikacji uwag twierdzących fakty.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neste artigo, investigamos a eficácia do uso de embeddings contextuais de BERT multilíngue e BERT alemão na identificação de comentários de alegação de fatos em alemão nas mídias sociais. Além disso, examinamos o impacto de formular o problema de classificação como um problema de aprendizado multitarefa, onde o modelo identifica a toxicidade e o engajamento do comentário, além de identificar se é uma afirmação de fato. Fornecemos uma comparação completa dos dois modelos baseados em BERT em comparação com uma linha de base de regressão logística e mostramos que os recursos de BERT alemães treinados usando um objetivo multitarefa atingem a melhor pontuação F1 no conjunto de teste. Este trabalho foi feito como parte de uma submissão à tarefa compartilhada GermEval 2021 sobre a identificação de comentários de alegação de fatos.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>În această lucrare investigăm eficacitatea utilizării încorporărilor contextuale de la BERT multilingv și BERT german în identificarea comentariilor în limba germană pe rețelele de socializare. În plus, examinăm impactul formulării problemei de clasificare ca o problemă de învățare multi-task, în cazul în care modelul identifică toxicitatea și implicarea comentariului în plus față de identificarea dacă este o afirmație de fapt. Oferim o comparație aprofundată a celor două modele bazate pe BERT în comparație cu o bază de regresie logistică și arătăm că caracteristicile BERT germane instruite utilizând un obiectiv multi-task obțin cel mai bun scor F1 pe setul de test. Această lucrare a fost realizată în cadrul unei transmiteri către GermEval 2021 a sarcinii comune privind identificarea comentariilor care susțin fapte.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>В этой статье мы исследуем эффективность использования контекстных вложений из многоязычных BERT и German BERT в выявлении фактологических комментариев на немецком языке в социальных сетях. Кроме того, мы изучаем влияние формулирования проблемы классификации как многозадачной проблемы обучения, где модель идентифицирует токсичность и вовлеченность комментария в дополнение к определению того, является ли он фактологическим. Мы предоставляем тщательное сравнение двух моделей, основанных на BERT, по сравнению с базовой линией логистической регрессии и показываем, что немецкие функции BERT, обученные с использованием многозадачной цели, достигают лучшего балла F1 на тестовом наборе. Эта работа была выполнена в рамках представления на рассмотрение GermEval 2021 общей задачи по выявлению комментариев с изложением фактов.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>මේ පත්තරේ අපි පරීක්ෂණය කරනවා සාමාජික මිඩියාවේ ජර්මන් වල සාමාජිකයෙන් ජර්මන් වල සාමාජික ක්‍රියාත්මක ප්‍රයෝජනය කරන්න ස තවත්, අපි පරීක්ෂා කරන්නේ විශේෂණ ප්‍රශ්නයක් වගේ විශේෂණ ප්‍රශ්නයක් ගොඩක් වැඩි වැඩක් ඉගෙන ගන්න ප්‍රශ්නයක් වගේ, මොඩේල් එකේ විශ අපි BERT පරීක්ෂණයේ හොඳම F1 ස්කෝර් සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් පරීක් මේ වැඩේ ජෙර්ම් එව්ල් 2021 වලට පිළිගන්න පුළුවන් කොටසක් විදිහට කරලා තියෙන්නේ ඇත්තටම පිළිගන්න ප්‍රශ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>V tem prispevku raziskujemo učinkovitost uporabe kontekstualnih vdelav večjezičnih BERT in nemških BERT pri prepoznavanju komentarjev v nemščini na družbenih omrežjih. Poleg tega preučujemo vpliv oblikovanja klasifikacijskega problema kot večopravilnega učenja, kjer model identificira toksičnost in vključenost komentarja poleg ugotavljanja, ali gre za trditev dejstev. Zagotovili smo temeljito primerjavo obeh modelov BERT v primerjavi z izhodiščem logistične regresije in pokazali, da nemške funkcije BERT, usposobljene z večopravilnim ciljem, dosegajo najboljšo rezultato F1 v testnem naboru. To delo je bilo opravljeno v okviru predložitve skupne naloge GermEval 2021 za identifikacijo pripomb, ki trdijo dejstva.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Qoraalkan ayaannu ka baaraynaa faa’iidada isticmaalka warqadaha joogtada ah ee BERT iyo Jarmalka BERT si aan ugu ogaano commentarada warqada bulshada ee Jarmalka ah. Sidoo kale waxaynu fiirinaynaa saamaynta u sameynta dhibaatada fasaxda sida dhibaato waxbarasho badan oo kale, kaas oo modelku ku qoran yahay dhibaatada waxbarashada, taas oo ku qoran tijaabada iyo wadashada commentarka iyo sidoo kale ayan aqoonsanaynaa in ay tahay mid ku habboon. Waxaannu sameynaa tusaalaha labada BERT ee asalka ah oo la barbarbaro qoraalka regression baseline, waxaana muujinaynaa in Jarmalka BERT ay ku tababartay isticmaalka shaqo badan, waxay gaadhaa kooxda ugu wanaagsan ee F1 ee imtixaanka. Shaqodaas waxaa loo sameeyay qeyb ka mid ah warqada GermEval 2021 oo lagu sharciyey aqoonsiga commentarada xaqiiqa ah.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Në këtë letër ne hetojmë efektshmërinë e përdorimit të përfshirjeve kontekstuale nga BERT shumëgjuhëse dhe BERT gjermane në identifikimin e komenteve që pretendojnë fakte në gjermanë mbi mediat sociale. Përveç kësaj, ne shqyrtojmë ndikimin e formulimit të problem it të klasifikimit si një problem mësimi me shumë detyra, ku modeli identifikon toksicitetin dhe përfshirjen e komentit përveç identifikimit nëse është fakt-deklarim. Ne ofrojmë një krahasim të plotë të dy modeleve të bazuar në BERT krahasuar me një bazë logjistike të regresionit dhe tregojmë se funksionet gjermane të BERT të trajnuara duke përdorur një objektiv shumëdetyror arrijnë rezultatin më të mirë të F1 në grupin e testimeve. Ky punë u bë si pjesë e një paraqitjeje ndaj GermEval 2021 detyrë të përbashkët mbi identifikimin e komenteve që pretendojnë fakte.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>U ovom papiru istražujemo učinkovitost korištenja kontekstualnih integracija iz multijezičkih BERT-a i njemačkih BERT-a u identifikaciji komentara koji tvrde činjenice na njemačkim na društvenim medijima. Osim toga, istražujemo uticaj formiranja klasifikacijskog problem a kao problem sa učenjem multizadataka, gde je model identificirao toksičnost i uključenje komentara, dodatno identificirao je li to činjenica. Mi pružamo temeljno usporedbu dva modela baziranog na BERT u usporedbi sa početnom linijom logističke regresije i pokažemo da njemačka BERT karakteristika obučena koristeći cilj višezadataka postiže najbolji rezultat F1 na testu. Ovaj rad je urađen kao deo podataka GermEvalu 2021. godine zajedničkom zadatku o identifikaciji komentara koji tvrde činjenice.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>I denna uppsats undersöker vi effekten av att använda kontextuella inbäddningar från flerspråkiga BERT och tyska BERT för att identifiera fakta-hävdande kommentarer på tyska på sociala medier. Dessutom undersöker vi effekten av att formulera klassificeringsproblemet som ett inlärningsproblem med flera uppgifter, där modellen identifierar toxicitet och engagemang av kommentaren samt identifierar om det är faktagranspråk. Vi ger en grundlig jämförelse av de två BERT-baserade modellerna jämfört med en logistisk regressionsvärde och visar att tyska BERT-funktioner som tränats med ett multi-task-mål uppnår bästa F1-poäng i testuppsättningen. Detta arbete gjordes som en del av en inlämning till GermEval 2021 delad uppgift om identifiering av faktabaserade kommentarer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Katika karatasi hii tunachunguza ufanisi wa kutumia vifaa vya kimataifa kutoka kwa lugha mbalimbali vya BERT na Ujerumani BERT katika kutambua maoni yanayodai ukweli nchini Ujerumani kwenye mitandao ya kijamii. Kwa nyongeza, tunachunguza athari ya kutengeneza tatizo la kutangaza darasa kama tatizo la kujifunza kazi nyingi, ambapo model inaonyesha kuchochea na ushirikiano wa maoni hiyo pamoja na kutambua kama ni madai ya ukweli. Tunatoa ulinganisho mkubwa wa mifano miwili yenye msingi wa BERT ukilinganishwa na msingi wa ukandamizaji wa kisiasa na kuonyesha kwamba Ujerumani BERT hususani zilizofundishwa kwa kutumia lengo la kazi nyingi hufanikiwa vipimo bora vya F1 kwenye seti ya mtihani. Kazi hii ilifanyika kama sehemu ya kuutumia ujumbe wa GermEval 2021 ulishirikiana na kazi ya kutambua maoni yanayodai ukweli.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>இந்த காகிதத்தில் நாம் பல மொழி BERT மற்றும் ஜெர்மன் பிரெட்டில் இருந்து தற்போதைய முழுமையான குறிப்புகளை பயன்படுத்தும் விளைவுகளை தேடுக Additionally, we examine the impact of formulating the classification problem as a multi-task learning problem, where the model identifies toxicity and engagement of the comment in addition to identifying whether it is fact-claiming. பிரெட் அடிப்படையில் உள்ள இரண்டு பிரெட்டின் மாதிரிகளை ஒப்பிட்டுக் கொண்டு ஜெர்மன் பிரெட்டின் குணங்களை பயன்படுத்தி பல பணிக்காட்டியை பயிற்சி செய்துள் இந்த வேலை ஜெர்ம்வெல் 2021 க்கு ஒரு ஒப்பிட்ட பகிர்ந்த பணியாக செய்யப்பட்டுள்ளது உண்மையான குறிப்பிட்ட குறிப்ப</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bu kagyzda biz multi dilli BERT we Almança BERT-nyň multi dilinden duşuşyklary barlamak üçin nemesçe medýädäki suratlaryny tanyşdyrylýarys. Mundan hem, biz klasifikasiýa meseläni bir näçe-täbli öwrenme meseläsi hökmünde soraglaşýarys. Modeli çykyş etmek üçin toksyzlyk we komerniň işbirligini tanap-etmek üçin tanap berer. Biz BERT'yň iki nusgalarynyň logistik regressiýa baseline bilen karşılaşyk çykyşyny we Alman BERT'yň multi-täblik maksadyny ulanyp öwrenmegi mümkin edýän nusgalarynyň üstüne ýetip barýandygyny görkez. Bu işi 2021-nji GermEval'a gönderilýän täzeliklerini barlamak üçin paýlandy.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ہم اس کاغذ میں متوسط زبان BERT اور جرمن BERT سے متوسط انبودینگ کے استعمال کرنے کے اقتدار کی تحقیق کرتے ہیں جرمن میں سوسیل میڈیا کے ذریعے جرمن کی مثالیں معلوم کرنے کے لئے۔ اور اضافہ، ہم نے کلاسپیٹ مسئلہ کی تعلیم کے مطابق مشکل کی تأثیر کی تحقیق کی ہے، جہاں مدل سمجھ رہا ہے اور مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق م ہم نے دو BERT بنیادی موڈل کے مطابق مطابق مطابق مطابق مقایسہ کی اور دکھا دیتے ہیں کہ جرمن BERT کے مطابق multi-task موضوع کے مطابق تعلیم کی جاتی ہے ایک امتحان سٹ کے سب سے بہترین F1 اسکور کو پہنچ سکتا ہے. یہ کام جرمEval 2021 کے لئے ایک حصہ کے طور پر کیا گیا تھا جو حقیقت کی تصدیق کرنے والی کمانٹروں کے معاملہ میں شریک کام کیا گیا تھا.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bu hujjatda biz bir necha tildan BERT va Olmoncha BERT kabi xil tildan foydalanishning effektini o'rganamiz. Olmoniyadagi haqiqiqiy qo'llangan izohlarni ko'paytirish uchun o'rganamiz. Ko'pchilik, biz bir necha vazifa o'rganish muammolari sifatida darajalashtirish muammolarini ko'rib chiqaramiz. Bu yerda model to ʻgʻri va izohni aniqlaydi, bu haqiqiqiy talab qilishini anglatadi. Biz ikkita BERT asosida o'xshash modellarni o'xshash qilamiz va bir necha vazifa obʼektidan foydalanishga o'rganish imkoniyatlarni bir necha qavsga o'rganish imkoniyatlarini sinov sohasida eng eng yaxshi F1 scori bajaradi. Bu ishni GermEval 2021 ga bogʻliq vazifani aniqlash uchun ishga bajarildi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Trong tờ giấy này, chúng tôi nghiên cứu hiệu quả của việc sử dụng tác nhân ngữ chung từ BERT đa dạng và BERT Đức để xác định các bình luận về xã hội trên Đức. Thêm vào đó, chúng tôi nghiên cứu tác động của việc phát triển vấn đề phân loại thành vấn đề học tập nhiều nhiệm vụ, nơi mô hình xác định độc tính và cam kết của lời bình luận, thêm vào việc xác định xem nó có được thực tế không. Chúng tôi cung cấp một so sánh hoàn hảo với hai mô hình nền phục hồi hàng hoá được so sánh với một cơ sở hồi quy mô hàng hoá Đức và cho thấy các đặc điểm thiếu sót được huấn luyện bằng nhiều nhiệm vụ đạt được điểm F1 tốt nhất trong bộ thử nghiệm. Việc này được thực hiện như một phần của việc đệ trình cho GermEvl 2021 sẽ có nhiệm vụ chia sẻ về nhận dạng những nhận xét thực tế.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>于本文中,研用多言BERT与德语BERT上下文嵌社交媒体识德语事实声明论有效性。 又考分类为多任务学,其形定是非声明之外,定注毒参与度。 二基于BERT,与逻辑归基线周比,明用多任务之所习德国BERT试集上至F1之分也。 此其所以GermEval 2021知事实声明论议之一体也。</span></div></div><dl><dt>Anthology ID:</dt><dd>2021.germeval-1.15</dd><dt>Volume:</dt><dd><a href=/volumes/2021.germeval-1/>Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments</a></dd><dt>Month:</dt><dd>September</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Duesseldorf, Germany</dd><dt>Venue:</dt><dd><a href=/venues/germeval/>GermEval</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>100–104</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.germeval-1.15>https://aclanthology.org/2021.germeval-1.15</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">panda-levitan-2021-hunterspeechlab</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Subhadarshi Panda and Sarah Ita Levitan. 2021. <a href=https://aclanthology.org/2021.germeval-1.15>HunterSpeechLab at GermEval 2021 : Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment ClassificationHunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification</a>. In <i>Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments</i>, pages 100–104, Duesseldorf, Germany. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2021.germeval-1.15>HunterSpeechLab at GermEval 2021 : Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment ClassificationHunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification</a> (Panda & Levitan, GermEval 2021)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.germeval-1.15.pdf>https://aclanthology.org/2021.germeval-1.15.pdf</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.germeval-1.15.pdf title="Open PDF of 'HunterSpeechLab at GermEval 2021 : Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment ClassificationHunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=HunterSpeechLab+at+GermEval+2021+%3A+Does+Your+Comment+Claim+A+Fact%3F+Contextualized+Embeddings+for+German+Fact-Claiming+Comment+ClassificationHunterSpeechLab+at+GermEval+2021%3A+Does+Your+Comment+Claim+A+Fact%3F+Contextualized+Embeddings+for+German+Fact-Claiming+Comment+Classification" title="Search for 'HunterSpeechLab at GermEval 2021 : Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment ClassificationHunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'HunterSpeechLab at GermEval 2021 : Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment ClassificationHunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[HunterSpeechLab at GermEval 2021 : Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment ClassificationHunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification](https://aclanthology.org/2021.germeval-1.15) (Panda & Levitan, GermEval 2021)</p><ul class=mt-2><li><a href=https://aclanthology.org/2021.germeval-1.15>HunterSpeechLab at GermEval 2021 : Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment ClassificationHunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification</a> (Panda & Levitan, GermEval 2021)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Subhadarshi Panda and Sarah Ita Levitan. 2021. <a href=https://aclanthology.org/2021.germeval-1.15>HunterSpeechLab at GermEval 2021 : Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment ClassificationHunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification</a>. In <i>Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments</i>, pages 100–104, Duesseldorf, Germany. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>