<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Shirish Karande - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Shirish</span> <span class=font-weight-bold>Karande</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.deelio-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--deelio-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.deelio-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.deelio-1.12.OptionalSupplementaryData.pdf data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.deelio-1.12/>What BERTs and GPTs know about your brand? Probing contextual language models for affect associations<span class=acl-fixed-case>BERT</span>s and <span class=acl-fixed-case>GPT</span>s know about your brand? Probing contextual language models for affect associations</a></strong><br><a href=/people/v/vivek-srivastava/>Vivek Srivastava</a>
|
<a href=/people/s/stephen-pilli/>Stephen Pilli</a>
|
<a href=/people/s/savita-bhat/>Savita Bhat</a>
|
<a href=/people/n/niranjan-pedanekar/>Niranjan Pedanekar</a>
|
<a href=/people/s/shirish-karande/>Shirish Karande</a><br><a href=/volumes/2021.deelio-1/ class=text-muted>Proceedings of Deep Learning Inside Out (DeeLIO): The 2nd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--deelio-1--12><div class="card-body p-3 small">Investigating brand perception is fundamental to <a href=https://en.wikipedia.org/wiki/Marketing_strategy>marketing strategies</a>. In this regard, <a href=https://en.wikipedia.org/wiki/Brand_image>brand image</a>, defined by a set of attributes (Aaker, 1997), is recognized as a key element in indicating how a brand is perceived by various stakeholders such as consumers and competitors. Traditional <a href=https://en.wikipedia.org/wiki/Brand_management>approaches</a> (e.g., surveys) to monitor brand perceptions are time-consuming and inefficient. In the era of <a href=https://en.wikipedia.org/wiki/Digital_marketing>digital marketing</a>, both brand managers and consumers engage with a vast amount of <a href=https://en.wikipedia.org/wiki/Digital_marketing>digital marketing content</a>. The exponential growth of <a href=https://en.wikipedia.org/wiki/Digital_content>digital content</a> has propelled the emergence of pre-trained language models such as BERT and GPT as essential tools in solving myriads of challenges with textual data. This paper seeks to investigate the extent of brand perceptions (i.e., brand and image attribute associations) these <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> encode. We believe that any kind of bias for a brand and attribute pair may influence customer-centric downstream tasks such as <a href=https://en.wikipedia.org/wiki/Recommender_system>recommender systems</a>, <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, and <a href=https://en.wikipedia.org/wiki/Question_answering>question-answering</a>, e.g., suggesting a specific brand consistently when queried for innovative products. We use <a href=https://en.wikipedia.org/wiki/Data>synthetic data</a> and real-life data and report comparison results for five contextual LMs, viz. BERT, RoBERTa, DistilBERT, ALBERT and BART.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wat-1.19.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--wat-1--19 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.wat-1.19 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.wat-1.19/>Improving NMT via Filtered Back Translation<span class=acl-fixed-case>NMT</span> via Filtered Back Translation</a></strong><br><a href=/people/n/nikhil-jaiswal/>Nikhil Jaiswal</a>
|
<a href=/people/m/mayur-patidar/>Mayur Patidar</a>
|
<a href=/people/s/surabhi-kumari/>Surabhi Kumari</a>
|
<a href=/people/m/manasi-patwardhan/>Manasi Patwardhan</a>
|
<a href=/people/s/shirish-karande/>Shirish Karande</a>
|
<a href=/people/p/puneet-agarwal/>Puneet Agarwal</a>
|
<a href=/people/l/lovekesh-vig/>Lovekesh Vig</a><br><a href=/volumes/2020.wat-1/ class=text-muted>Proceedings of the 7th Workshop on Asian Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--wat-1--19><div class="card-body p-3 small">Document-Level Machine Translation (MT) has become an active research area among the NLP community in recent years. Unlike sentence-level MT, which translates the sentences independently, document-level MT aims to utilize <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual information</a> while translating a given source sentence. This paper demonstrates our submission (Team ID-DEEPNLP) to the Document-Level Translation task organized by WAT 2020. This task focuses on translating texts from a business dialog corpus while optionally utilizing the context present in the dialog. In our proposed approach, we utilize publicly available <a href=https://en.wikipedia.org/wiki/Parallel_corpus>parallel corpus</a> from different domains to train an open domain base NMT model. We then use monolingual target data to create filtered pseudo parallel data and employ <a href=https://en.wikipedia.org/wiki/Back-translation>Back-Translation</a> to fine-tune the base model. This is further followed by <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> on the domain-specific corpus. We also ensemble various <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> to improvise the <a href=https://en.wikipedia.org/wiki/Translation>translation</a> performance. Our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> achieve a <a href=https://en.wikipedia.org/wiki/BLEU>BLEU score</a> of 26.59 and 22.83 in an <a href=https://en.wikipedia.org/wiki/BLEU>unconstrained setting</a> and 15.10 and 10.91 in the <a href=https://en.wikipedia.org/wiki/BLEU>constrained settings</a> for <a href=https://en.wikipedia.org/wiki/BLEU>En-Ja & Ja-En direction</a>, respectively.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Shirish+Karande" title="Search for 'Shirish Karande' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/v/vivek-srivastava/ class=align-middle>Vivek Srivastava</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stephen-pilli/ class=align-middle>Stephen Pilli</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/savita-bhat/ class=align-middle>Savita Bhat</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/niranjan-pedanekar/ class=align-middle>Niranjan Pedanekar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nikhil-jaiswal/ class=align-middle>Nikhil Jaiswal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/m/mayur-patidar/ class=align-middle>Mayur Patidar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/surabhi-kumari/ class=align-middle>Surabhi Kumari</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/manasi-patwardhan/ class=align-middle>Manasi Patwardhan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/puneet-agarwal/ class=align-middle>Puneet Agarwal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lovekesh-vig/ class=align-middle>Lovekesh Vig</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/deelio/ class=align-middle>DeeLIO</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wat/ class=align-middle>WAT</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>