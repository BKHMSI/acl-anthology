<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Sivaji Bandyopadhyay - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Sivaji</span> <span class=font-weight-bold>Bandyopadhyay</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.dravidianlangtech-1.4.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.4/>Sentiment Classification of Code-Mixed Tweets using Bi-Directional RNN and Language Tags<span class=acl-fixed-case>RNN</span> and Language Tags</a></strong><br><a href=/people/s/sainik-mahata/>Sainik Mahata</a>
|
<a href=/people/d/dipankar-das/>Dipankar Das</a>
|
<a href=/people/s/sivaji-bandyopadhyay/>Sivaji Bandyopadhyay</a><br><a href=/volumes/2021.dravidianlangtech-1/ class=text-muted>Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--4><div class="card-body p-3 small">Sentiment analysis tools and <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> have been developed extensively throughout the years, for <a href=https://en.wikipedia.org/wiki/Languages_of_Europe>European languages</a>. In contrast, similar <a href=https://en.wikipedia.org/wiki/Tool>tools</a> for <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indian Languages</a> are scarce. This is because, state-of-the-art pre-processing tools like POS tagger, shallow parsers, etc., are not readily available for <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indian languages</a>. Although, such working tools for Indian languages, like <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> and <a href=https://en.wikipedia.org/wiki/Bengali_language>Bengali</a>, that are spoken by the majority of the population, are available, finding the same for less spoken languages like, <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a>, <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a>, and <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a>, is difficult. Moreover, due to the advent of <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, the multi-lingual population of India, who are comfortable with both <a href=https://en.wikipedia.org/wiki/English_language>English</a> ad their regional language, prefer to communicate by mixing both languages. This gives rise to massive code-mixed content and automatically annotating them with their respective sentiment labels becomes a challenging task. In this work, we take up a similar challenge of developing a <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis model</a> that can work with English-Tamil code-mixed data. The proposed work tries to solve this by using bi-directional LSTMs along with <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>language tagging</a>. Other traditional methods, based on classical machine learning algorithms have also been discussed in the literature, and they also act as the baseline systems to which we will compare our Neural Network based model. The performance of the developed <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a>, based on Neural Network architecture, garnered <a href=https://en.wikipedia.org/wiki/Precision_(computer_science)>precision</a>, <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a>, and F1 scores of 0.59, 0.66, and 0.58 respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mmtlrl-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mmtlrl-1.0/>Proceedings of the First Workshop on Multimodal Machine Translation for Low Resource Languages (MMTLRL 2021)</a></strong><br><a href=/people/t/thoudam-doren-singh/>Thoudam Doren Singh</a>
|
<a href=/people/c/cristina-espana-i-bonet/>Cristina España i Bonet</a>
|
<a href=/people/s/sivaji-bandyopadhyay/>Sivaji Bandyopadhyay</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a><br><a href=/volumes/2021.mmtlrl-1/ class=text-muted>Proceedings of the First Workshop on Multimodal Machine Translation for Low Resource Languages (MMTLRL 2021)</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wat-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--wat-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.wat-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.wat-1.11/>Multimodal Neural Machine Translation for English to Hindi<span class=acl-fixed-case>E</span>nglish to <span class=acl-fixed-case>H</span>indi</a></strong><br><a href=/people/s/sahinur-rahman-laskar/>Sahinur Rahman Laskar</a>
|
<a href=/people/a/abdullah-faiz-ur-rahman-khilji/>Abdullah Faiz Ur Rahman Khilji</a>
|
<a href=/people/p/partha-pakray/>Partha Pakray</a>
|
<a href=/people/s/sivaji-bandyopadhyay/>Sivaji Bandyopadhyay</a><br><a href=/volumes/2020.wat-1/ class=text-muted>Proceedings of the 7th Workshop on Asian Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--wat-1--11><div class="card-body p-3 small">Machine translation (MT) focuses on the <a href=https://en.wikipedia.org/wiki/Machine_translation>automatic translation</a> of text from one natural language to another natural language. Neural machine translation (NMT) achieves state-of-the-art results in the task of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> because of utilizing advanced deep learning techniques and handles issues like long-term dependency, and context-analysis. Nevertheless, NMT still suffers low translation quality for <a href=https://en.wikipedia.org/wiki/Linguistic_conservatism>low resource languages</a>. To encounter this challenge, the multi-modal concept comes in. The multi-modal concept combines textual and visual features to improve the translation quality of low resource languages. Moreover, the utilization of monolingual data in the pre-training step can improve the performance of the <a href=https://en.wikipedia.org/wiki/System>system</a> for low resource language translations. Workshop on Asian Translation 2020 (WAT2020) organized a translation task for multimodal translation in <a href=https://en.wikipedia.org/wiki/English_language>English</a> to <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a>. We have participated in the same in two-track submission, namely text-only and multi-modal translation with team name CNLP-NITS. The evaluated results are declared at the WAT2020 translation task, which reports that our multi-modal NMT system attained higher scores than our text-only NMT on both challenge and evaluation test set. For the challenge test data, our multi-modal neural machine translation system achieves <a href=https://en.wikipedia.org/wiki/Bilingual_Evaluation_Understudy>Bilingual Evaluation Understudy (BLEU) score</a> of 33.57, Rank-based Intuitive Bilingual Evaluation Score (RIBES) 0.754141, Adequacy-Fluency Metrics (AMFM) score 0.787320 and for evaluation test data, BLEU, RIBES, and, AMFM score of 40.51, 0.803208, and 0.820980 for English to Hindi translation respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wmt-1.135.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--wmt-1--135 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.wmt-1.135 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939575 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.wmt-1.135/>The NITS-CNLP System for the Unsupervised MT Task at WMT 2020<span class=acl-fixed-case>NITS</span>-<span class=acl-fixed-case>CNLP</span> System for the Unsupervised <span class=acl-fixed-case>MT</span> Task at <span class=acl-fixed-case>WMT</span> 2020</a></strong><br><a href=/people/s/salam-michael-singh/>Salam Michael Singh</a>
|
<a href=/people/t/thoudam-doren-singh/>Thoudam Doren Singh</a>
|
<a href=/people/s/sivaji-bandyopadhyay/>Sivaji Bandyopadhyay</a><br><a href=/volumes/2020.wmt-1/ class=text-muted>Proceedings of the Fifth Conference on Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--wmt-1--135><div class="card-body p-3 small">We describe NITS-CNLP&#8217;s submission to WMT 2020 unsupervised machine translation shared task for German language (de) to Upper Sorbian (hsb) in a constrained setting i.e, using only the data provided by the organizers. We train our <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised model</a> using monolingual data from both the languages by jointly pre-training the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> and <a href=https://en.wikipedia.org/wiki/Code>decoder</a> and fine-tune using backtranslation loss. The final model uses the source side (de) monolingual data and the target side (hsb) synthetic data as a pseudo-parallel data to train a pseudo-supervised system which is tuned using the provided development set(dev set).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.loresmt-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--loresmt-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.loresmt-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.loresmt-1.5/>Zero-Shot Neural Machine Translation : Russian-Hindi @LoResMT 2020<span class=acl-fixed-case>R</span>ussian-<span class=acl-fixed-case>H</span>indi @<span class=acl-fixed-case>L</span>o<span class=acl-fixed-case>R</span>es<span class=acl-fixed-case>MT</span> 2020</a></strong><br><a href=/people/s/sahinur-rahman-laskar/>Sahinur Rahman Laskar</a>
|
<a href=/people/a/abdullah-faiz-ur-rahman-khilji/>Abdullah Faiz Ur Rahman Khilji</a>
|
<a href=/people/p/partha-pakray/>Partha Pakray</a>
|
<a href=/people/s/sivaji-bandyopadhyay/>Sivaji Bandyopadhyay</a><br><a href=/volumes/2020.loresmt-1/ class=text-muted>Proceedings of the 3rd Workshop on Technologies for MT of Low Resource Languages</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--loresmt-1--5><div class="card-body p-3 small">Neural machine translation (NMT) is a widely accepted approach in the machine translation (MT) community, translating from one natural language to another natural language. Although, NMT shows remarkable performance in both high and low resource languages, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> needs sufficient training corpus. The availability of a <a href=https://en.wikipedia.org/wiki/Parallel_corpus>parallel corpus</a> in low resource language pairs is one of the challenging tasks in MT. To mitigate this issue, NMT attempts to utilize a monolingual corpus to get better at <a href=https://en.wikipedia.org/wiki/Translation>translation</a> for low resource language pairs. Workshop on Technologies for MT of Low Resource Languages (LoResMT 2020) organized shared tasks of low resource language pair translation using zero-shot NMT. Here, the <a href=https://en.wikipedia.org/wiki/Parallel_text>parallel corpus</a> is not used and only monolingual corpora is allowed. We have participated in the same shared task with our team name CNLP-NITS for the Russian-Hindi language pair. We have used masked sequence to sequence pre-training for language generation (MASS) with only monolingual corpus following the unsupervised NMT architecture. The evaluated results are declared at the LoResMT 2020 shared task, which reports that our system achieves the bilingual evaluation understudy (BLEU) score of 0.59, precision score of 3.43, recall score of 5.48, F-measure score of 4.22, and rank-based intuitive bilingual evaluation score (RIBES) of 0.180147 in Russian to Hindi translation. And for Hindi to Russian translation, we have achieved <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>, <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a>, <a href=https://en.wikipedia.org/wiki/Precision_and_recall>recall</a>, <a href=https://en.wikipedia.org/wiki/F-measure>F-measure</a>, and <a href=https://en.wikipedia.org/wiki/International_Bureau_of_Weights_and_Measures>RIBES score</a> of 1.11, 4.72, 4.41, 4.56, and 0.026842 respectively.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5427.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5427 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5427 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5427/>Neural Machine Translation : Hindi-Nepali<span class=acl-fixed-case>H</span>indi-<span class=acl-fixed-case>N</span>epali</a></strong><br><a href=/people/s/sahinur-rahman-laskar/>Sahinur Rahman Laskar</a>
|
<a href=/people/p/partha-pakray/>Partha Pakray</a>
|
<a href=/people/s/sivaji-bandyopadhyay/>Sivaji Bandyopadhyay</a><br><a href=/volumes/W19-54/ class=text-muted>Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5427><div class="card-body p-3 small">With the extensive use of Machine Translation (MT) technology, there is progressively interest in directly translating between pairs of similar languages. Because the main challenge is to overcome the limitation of available <a href=https://en.wikipedia.org/wiki/Parallel_computing>parallel data</a> to produce a precise MT output. Current work relies on the Neural Machine Translation (NMT) with attention mechanism for the similar language translation of WMT19 shared task in the context of Hindi-Nepali pair. The NMT systems trained the Hindi-Nepali parallel corpus and tested, analyzed in Hindi Nepali translation. The official result declared at WMT19 shared task, which shows that our NMT system obtained Bilingual Evaluation Understudy (BLEU) score 24.6 for primary configuration in Nepali to Hindi translation. Also, we have achieved <a href=https://en.wikipedia.org/wiki/BLEU>BLEU score</a> 53.7 (Hindi to Nepali) and 49.1 (Nepali to Hindi) in contrastive system type.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6418.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6418 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6418 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6418/>JUCBNMT at WMT2018 News Translation Task : Character Based Neural Machine Translation of Finnish to English<span class=acl-fixed-case>JUCBNMT</span> at <span class=acl-fixed-case>WMT</span>2018 News Translation Task: Character Based Neural Machine Translation of <span class=acl-fixed-case>F</span>innish to <span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/s/sainik-mahata/>Sainik Kumar Mahata</a>
|
<a href=/people/d/dipankar-das/>Dipankar Das</a>
|
<a href=/people/s/sivaji-bandyopadhyay/>Sivaji Bandyopadhyay</a><br><a href=/volumes/W18-64/ class=text-muted>Proceedings of the Third Conference on Machine Translation: Shared Task Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6418><div class="card-body p-3 small">In the current work, we present a description of the <a href=https://en.wikipedia.org/wiki/System>system</a> submitted to WMT 2018 News Translation Shared task. The <a href=https://en.wikipedia.org/wiki/System>system</a> was created to translate news text from <a href=https://en.wikipedia.org/wiki/Finnish_language>Finnish</a> to <a href=https://en.wikipedia.org/wiki/English_language>English</a>. The <a href=https://en.wikipedia.org/wiki/System>system</a> used a Character Based Neural Machine Translation model to accomplish the given <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. The current paper documents the preprocessing steps, the description of the submitted <a href=https://en.wikipedia.org/wiki/System>system</a> and the results produced using the same. Our <a href=https://en.wikipedia.org/wiki/System>system</a> garnered a BLEU score of 12.9.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2511.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2511 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2511 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2511/>BUCC2017 : A Hybrid Approach for Identifying Parallel Sentences in Comparable Corpora<span class=acl-fixed-case>BUCC</span>2017: A Hybrid Approach for Identifying Parallel Sentences in Comparable Corpora</a></strong><br><a href=/people/s/sainik-mahata/>Sainik Mahata</a>
|
<a href=/people/d/dipankar-das/>Dipankar Das</a>
|
<a href=/people/s/sivaji-bandyopadhyay/>Sivaji Bandyopadhyay</a><br><a href=/volumes/W17-25/ class=text-muted>Proceedings of the 10th Workshop on Building and Using Comparable Corpora</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2511><div class="card-body p-3 small">A Statistical Machine Translation (SMT) system is always trained using large parallel corpus to produce effective <a href=https://en.wikipedia.org/wiki/Translation>translation</a>. Not only is the corpus scarce, it also involves a lot of manual labor and cost. Parallel corpus can be prepared by employing comparable corpora where a pair of corpora is in two different languages pointing to the same domain. In the present work, we try to build a <a href=https://en.wikipedia.org/wiki/Parallel_corpus>parallel corpus</a> for French-English language pair from a given comparable corpus. The data and the problem set are provided as part of the shared task organized by BUCC 2017. We have proposed a system that first translates the sentences by heavily relying on <a href=https://en.wikipedia.org/wiki/Moses>Moses</a> and then group the sentences based on sentence length similarity. Finally, the one to one sentence selection was done based on Cosine Similarity algorithm.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-7500.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-7500/>Proceedings of the 14th International Conference on Natural Language Processing (<span class=acl-fixed-case>ICON</span>-2017)</a></strong><br><a href=/people/s/sivaji-bandyopadhyay/>Sivaji Bandyopadhyay</a><br><a href=/volumes/W17-75/ class=text-muted>Proceedings of the 14th International Conference on Natural Language Processing (ICON-2017)</a></span></p></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Sivaji+Bandyopadhyay" title="Search for 'Sivaji Bandyopadhyay' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/s/sainik-mahata/ class=align-middle>Sainik Mahata</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/d/dipankar-das/ class=align-middle>Dipankar Das</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/sahinur-rahman-laskar/ class=align-middle>Sahinur Rahman Laskar</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/p/partha-pakray/ class=align-middle>Partha Pakray</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/abdullah-faiz-ur-rahman-khilji/ class=align-middle>Abdullah Faiz Ur Rahman Khilji</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/t/thoudam-doren-singh/ class=align-middle>Thoudam Doren Singh</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/cristina-espana-i-bonet/ class=align-middle>Cristina España i Bonet</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/josef-van-genabith/ class=align-middle>Josef van Genabith</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/salam-michael-singh/ class=align-middle>Salam Michael Singh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/dravidianlangtech/ class=align-middle>DravidianLangTech</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wat/ class=align-middle>WAT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/mmtlrl/ class=align-middle>MMTLRL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wmt/ class=align-middle>WMT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/loresmt/ class=align-middle>loresmt</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>