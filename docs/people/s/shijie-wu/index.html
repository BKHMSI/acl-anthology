<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Shijie Wu - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Shijie</span> <span class=font-weight-bold>Wu</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.149.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--149 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.149 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.149" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.149/>Everything Is All It Takes : A Multipronged Strategy for Zero-Shot Cross-Lingual Information Extraction</a></strong><br><a href=/people/m/mahsa-yarmohammadi/>Mahsa Yarmohammadi</a>
|
<a href=/people/s/shijie-wu/>Shijie Wu</a>
|
<a href=/people/m/marc-marone/>Marc Marone</a>
|
<a href=/people/h/haoran-xu/>Haoran Xu</a>
|
<a href=/people/s/seth-ebner/>Seth Ebner</a>
|
<a href=/people/g/guanghui-qin/>Guanghui Qin</a>
|
<a href=/people/y/yunmo-chen/>Yunmo Chen</a>
|
<a href=/people/j/jialiang-guo/>Jialiang Guo</a>
|
<a href=/people/c/craig-harman/>Craig Harman</a>
|
<a href=/people/k/kenton-murray/>Kenton Murray</a>
|
<a href=/people/a/aaron-steven-white/>Aaron Steven White</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--149><div class="card-body p-3 small">Zero-shot cross-lingual information extraction (IE) describes the construction of an IE model for some target language, given existing annotations exclusively in some other language, typically <a href=https://en.wikipedia.org/wiki/English_language>English</a>. While the advance of pretrained multilingual encoders suggests an easy optimism of train on <a href=https://en.wikipedia.org/wiki/English_language>English</a>, run on any language, we find through a thorough exploration and extension of techniques that a combination of approaches, both new and old, leads to better performance than any one cross-lingual strategy in particular. We explore techniques including <a href=https://en.wikipedia.org/wiki/Projection_(linear_algebra)>data projection</a> and self-training, and how different pretrained encoders impact them. We use English-to-Arabic IE as our initial example, demonstrating strong performance in this setting for event extraction, <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>, <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a>, and dependency parsing. We then apply <a href=https://en.wikipedia.org/wiki/Projection_(linear_algebra)>data projection</a> and self-training to three tasks across eight target languages. Because no single set of techniques performs the best across all tasks, we encourage practitioners to explore various configurations of the techniques described in this work when seeking to improve on zero-shot training.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.608.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--608 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.608 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939146 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.608/>Which * BERT? A Survey Organizing Contextualized Encoders<span class=acl-fixed-case>BERT</span>? <span class=acl-fixed-case>A</span> Survey Organizing Contextualized Encoders</a></strong><br><a href=/people/p/patrick-xia/>Patrick Xia</a>
|
<a href=/people/s/shijie-wu/>Shijie Wu</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--608><div class="card-body p-3 small">Pretrained contextualized text encoders are now a staple of the NLP community. We present a survey on language representation learning with the aim of consolidating a series of shared lessons learned across a variety of recent efforts. While significant advancements continue at a rapid pace, we find that enough has now been discovered, in different directions, that we can begin to organize advances according to common themes. Through this organization, we highlight important considerations when interpreting recent contributions and choosing which <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to use.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.536.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--536 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.536 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928831 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.536/>Emerging Cross-lingual Structure in Pretrained Language Models</a></strong><br><a href=/people/a/alexis-conneau/>Alexis Conneau</a>
|
<a href=/people/s/shijie-wu/>Shijie Wu</a>
|
<a href=/people/h/haoran-li/>Haoran Li</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a>
|
<a href=/people/v/veselin-stoyanov/>Veselin Stoyanov</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--536><div class="card-body p-3 small">We study the problem of multilingual masked language modeling, i.e. the training of a single <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> on concatenated text from multiple languages, and present a detailed study of several factors that influence why these <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> are so effective for cross-lingual transfer. We show, contrary to what was previously hypothesized, that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains. The only requirement is that there are some shared parameters in the top layers of the multi-lingual encoder. To better understand this result, we also show that representations from monolingual BERT models in different languages can be aligned post-hoc quite effectively, strongly suggesting that, much like for non-contextual word embeddings, there are universal latent symmetries in the learned embedding spaces. For multilingual masked language modeling, these <a href=https://en.wikipedia.org/wiki/Symmetry>symmetries</a> are automatically discovered and aligned during the joint training process.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.695.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--695 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.695 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928868 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.695" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.695/>The Paradigm Discovery Problem</a></strong><br><a href=/people/a/alexander-erdmann/>Alexander Erdmann</a>
|
<a href=/people/m/micha-elsner/>Micha Elsner</a>
|
<a href=/people/s/shijie-wu/>Shijie Wu</a>
|
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a>
|
<a href=/people/n/nizar-habash/>Nizar Habash</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--695><div class="card-body p-3 small">This work treats the paradigm discovery problem (PDP), the task of learning an inflectional morphological system from unannotated sentences. We formalize the <a href=https://en.wikipedia.org/wiki/Programmable_Data_Processor>PDP</a> and develop evaluation metrics for judging systems. Using currently available resources, we construct datasets for the <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>. We also devise a heuristic benchmark for the <a href=https://en.wikipedia.org/wiki/Programmed_Data_Processor>PDP</a> and report empirical results on five diverse languages. Our benchmark system first makes use of <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> and <a href=https://en.wikipedia.org/wiki/String_similarity>string similarity</a> to cluster forms by cell and by <a href=https://en.wikipedia.org/wiki/Paradigm>paradigm</a>. Then, we bootstrap a neural transducer on top of the clustered data to predict words to realize the empty paradigm slots. An error analysis of our <a href=https://en.wikipedia.org/wiki/System>system</a> suggests clustering by cell across different inflection classes is the most pressing challenge for future work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929782 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.repl4nlp-1.16" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.16/>Are All Languages Created Equal in Multilingual BERT?<span class=acl-fixed-case>BERT</span>?</a></strong><br><a href=/people/s/shijie-wu/>Shijie Wu</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a><br><a href=/volumes/2020.repl4nlp-1/ class=text-muted>Proceedings of the 5th Workshop on Representation Learning for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--16><div class="card-body p-3 small">Multilingual BERT (mBERT) trained on 104 languages has shown surprisingly good cross-lingual performance on several NLP tasks, even without explicit cross-lingual signals. However, these evaluations have focused on cross-lingual transfer with high-resource languages, covering only a third of the languages covered by mBERT. We explore how mBERT performs on a much wider set of languages, focusing on the quality of representation for low-resource languages, measured by within-language performance. We consider three tasks : <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a> (99 languages), <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>Part-of-speech Tagging</a> and Dependency Parsing (54 languages each). mBERT does better than or comparable to baselines on high resource languages but does much worse for low resource languages. Furthermore, monolingual BERT models for these <a href=https://en.wikipedia.org/wiki/Language>languages</a> do even worse. Paired with similar languages, the performance gap between monolingual BERT and mBERT can be narrowed. We find that better <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> for low resource languages require more efficient pretraining techniques or more data.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4226.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4226 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4226 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4226/>The SIGMORPHON 2019 Shared Task : Morphological Analysis in Context and Cross-Lingual Transfer for <a href=https://en.wikipedia.org/wiki/Inflection>Inflection</a><span class=acl-fixed-case>SIGMORPHON</span> 2019 Shared Task: Morphological Analysis in Context and Cross-Lingual Transfer for Inflection</a></strong><br><a href=/people/a/arya-d-mccarthy/>Arya D. McCarthy</a>
|
<a href=/people/e/ekaterina-vylomova/>Ekaterina Vylomova</a>
|
<a href=/people/s/shijie-wu/>Shijie Wu</a>
|
<a href=/people/c/chaitanya-malaviya/>Chaitanya Malaviya</a>
|
<a href=/people/l/lawrence-wolf-sonkin/>Lawrence Wolf-Sonkin</a>
|
<a href=/people/g/garrett-nicolai/>Garrett Nicolai</a>
|
<a href=/people/c/christo-kirov/>Christo Kirov</a>
|
<a href=/people/m/miikka-silfverberg/>Miikka Silfverberg</a>
|
<a href=/people/s/sabrina-j-mielke/>Sabrina J. Mielke</a>
|
<a href=/people/j/jeffrey-heinz/>Jeffrey Heinz</a>
|
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a>
|
<a href=/people/m/mans-hulden/>Mans Hulden</a><br><a href=/volumes/W19-42/ class=text-muted>Proceedings of the 16th Workshop on Computational Research in Phonetics, Phonology, and Morphology</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4226><div class="card-body p-3 small">The SIGMORPHON 2019 shared task on cross-lingual transfer and contextual analysis in morphology examined transfer learning of inflection between 100 language pairs, as well as contextual lemmatization and morphosyntactic description in 66 languages. The first task evolves past years&#8217; inflection tasks by examining transfer of morphological inflection knowledge from a high-resource language to a low-resource language. This year also presents a new second challenge on <a href=https://en.wikipedia.org/wiki/Lemmatization>lemmatization</a> and morphological feature analysis in context. All submissions featured a neural component and built on either this year&#8217;s strong baselines or highly ranked systems from previous years&#8217; shared tasks. Every participating team improved in accuracy over the baselines for the inflection task (though not Levenshtein distance), and every team in the contextual analysis task improved on both state-of-the-art neural and non-neural baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1155.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1155 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1155 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/360705702 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-1155/>A Simple Joint Model for Improved Contextual Neural Lemmatization</a></strong><br><a href=/people/c/chaitanya-malaviya/>Chaitanya Malaviya</a>
|
<a href=/people/s/shijie-wu/>Shijie Wu</a>
|
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1155><div class="card-body p-3 small">English verbs have multiple forms. For instance, talk may also appear as talks, talked or talking, depending on the context. The NLP task of <a href=https://en.wikipedia.org/wiki/Lemmatization>lemmatization</a> seeks to map these diverse forms back to a canonical one, known as the lemma. We present a simple joint neural model for <a href=https://en.wikipedia.org/wiki/Lemmatization>lemmatization</a> and morphological tagging that achieves state-of-the-art results on 20 languages from the Universal Dependencies corpora. Our paper describes the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in addition to training and decoding procedures. Error analysis indicates that joint morphological tagging and <a href=https://en.wikipedia.org/wiki/Lemmatization>lemmatization</a> is especially helpful in low-resource lemmatization and languages that display a larger degree of morphological complexity.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1473.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1473 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1473 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1473" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D18-1473/>Hard Non-Monotonic Attention for Character-Level Transduction</a></strong><br><a href=/people/s/shijie-wu/>Shijie Wu</a>
|
<a href=/people/p/pamela-shapiro/>Pamela Shapiro</a>
|
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1473><div class="card-body p-3 small">Character-level string-to-string transduction is an important component of various NLP tasks. The goal is to map an input string to an output string, where the strings may be of different lengths and have characters taken from different alphabets. Recent approaches have used sequence-to-sequence models with an attention mechanism to learn which parts of the input string the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> should focus on during the generation of the output string. Both soft attention and hard monotonic attention have been used, but hard non-monotonic attention has only been used in other sequence modeling tasks and has required a stochastic approximation to compute the <a href=https://en.wikipedia.org/wiki/Gradient>gradient</a>. In this work, we introduce an exact, polynomial-time algorithm for marginalizing over the exponential number of non-monotonic alignments between two strings, showing that hard attention models can be viewed as neural reparameterizations of the classical IBM Model 1. We compare soft and hard non-monotonic attention experimentally and find that the exact <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> significantly improves performance over the <a href=https://en.wikipedia.org/wiki/Stochastic_approximation>stochastic approximation</a> and outperforms soft attention.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Shijie+Wu" title="Search for 'Shijie Wu' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/r/ryan-cotterell/ class=align-middle>Ryan Cotterell</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/b/benjamin-van-durme/ class=align-middle>Benjamin Van Durme</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mark-dredze/ class=align-middle>Mark Dredze</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/chaitanya-malaviya/ class=align-middle>Chaitanya Malaviya</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/patrick-xia/ class=align-middle>Patrick Xia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/a/alexis-conneau/ class=align-middle>Alexis Conneau</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haoran-li/ class=align-middle>Haoran Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luke-zettlemoyer/ class=align-middle>Luke Zettlemoyer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/veselin-stoyanov/ class=align-middle>Veselin Stoyanov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexander-erdmann/ class=align-middle>Alexander Erdmann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/micha-elsner/ class=align-middle>Micha Elsner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nizar-habash/ class=align-middle>Nizar Habash</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pamela-shapiro/ class=align-middle>Pamela Shapiro</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mahsa-yarmohammadi/ class=align-middle>Mahsa Yarmohammadi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marc-marone/ class=align-middle>Marc Marone</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haoran-xu/ class=align-middle>Haoran Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/seth-ebner/ class=align-middle>Seth Ebner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/guanghui-qin/ class=align-middle>Guanghui Qin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yunmo-chen/ class=align-middle>Yunmo Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jialiang-guo/ class=align-middle>Jialiang Guo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/craig-harman/ class=align-middle>Craig Harman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kenton-murray/ class=align-middle>Kenton Murray</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aaron-steven-white/ class=align-middle>Aaron Steven White</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/arya-d-mccarthy/ class=align-middle>Arya D. McCarthy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/ekaterina-vylomova/ class=align-middle>Ekaterina Vylomova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lawrence-wolf-sonkin/ class=align-middle>Lawrence Wolf-Sonkin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/garrett-nicolai/ class=align-middle>Garrett Nicolai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christo-kirov/ class=align-middle>Christo Kirov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/miikka-silfverberg/ class=align-middle>Miikka Silfverberg</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sabrina-j-mielke/ class=align-middle>Sabrina J. Mielke</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jeffrey-heinz/ class=align-middle>Jeffrey Heinz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mans-hulden/ class=align-middle>Mans Hulden</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/repl4nlp/ class=align-middle>RepL4NLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>