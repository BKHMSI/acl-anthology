<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Sayan Ghosh - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Sayan</span> <span class=font-weight-bold>Ghosh</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.43.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--43 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.43 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.emnlp-main.43.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.43" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.43/>Adversarial Scrubbing of Demographic Information for Text Classification</a></strong><br><a href=/people/s/somnath-basu-roy-chowdhury/>Somnath Basu Roy Chowdhury</a>
|
<a href=/people/s/sayan-ghosh/>Sayan Ghosh</a>
|
<a href=/people/y/yiyuan-li/>Yiyuan Li</a>
|
<a href=/people/j/junier-oliva/>Junier Oliva</a>
|
<a href=/people/s/shashank-srivastava/>Shashank Srivastava</a>
|
<a href=/people/s/snigdha-chaturvedi/>Snigdha Chaturvedi</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--43><div class="card-body p-3 small">Contextual representations learned by language models can often encode undesirable attributes, like demographic associations of the users, while being trained for an unrelated target task. We aim to scrub such undesirable attributes and learn fair representations while maintaining performance on the target <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>. In this paper, we present an adversarial learning framework Adversarial Scrubber (AdS), to debias contextual representations. We perform theoretical analysis to show that our <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> converges without leaking <a href=https://en.wikipedia.org/wiki/Demography>demographic information</a> under certain conditions. We extend previous evaluation techniques by evaluating <a href=https://en.wikipedia.org/wiki/Debiasing>debiasing</a> performance using Minimum Description Length (MDL) probing. Experimental evaluations on 8 datasets show that AdS generates <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> with minimal information about <a href=https://en.wikipedia.org/wiki/Demography>demographic attributes</a> while being maximally informative about the target task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.35.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--35 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.35 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.35/>Detecting Cross-Geographic Biases in Toxicity Modeling on <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a></a></strong><br><a href=/people/s/sayan-ghosh/>Sayan Ghosh</a>
|
<a href=/people/d/dylan-baker/>Dylan Baker</a>
|
<a href=/people/d/david-jurgens/>David Jurgens</a>
|
<a href=/people/v/vinodkumar-prabhakaran/>Vinodkumar Prabhakaran</a><br><a href=/volumes/2021.wnut-1/ class=text-muted>Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--35><div class="card-body p-3 small">Online social media platforms increasingly rely on Natural Language Processing (NLP) techniques to detect abusive content at scale in order to mitigate the harms it causes to their users. However, these techniques suffer from various sampling and association biases present in training data, often resulting in sub-par performance on content relevant to <a href=https://en.wikipedia.org/wiki/Social_exclusion>marginalized groups</a>, potentially furthering disproportionate harms towards them. Studies on such biases so far have focused on only a handful of axes of disparities and subgroups that have annotations / lexicons available. Consequently, biases concerning non-Western contexts are largely ignored in the literature. In this paper, we introduce a weakly supervised method to robustly detect lexical biases in broader geo-cultural contexts. Through a case study on a publicly available toxicity detection model, we demonstrate that our method identifies salient groups of cross-geographic errors, and, in a follow up, demonstrate that these groupings reflect human judgments of offensive and inoffensive language in those geographic contexts. We also conduct analysis of a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> trained on a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> with ground truth labels to better understand these biases, and present preliminary mitigation experiments.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1059.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1059 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1059 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234957188 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1059/>Affect-LM : A Neural Language Model for Customizable Affective Text Generation<span class=acl-fixed-case>LM</span>: A Neural Language Model for Customizable Affective Text Generation</a></strong><br><a href=/people/s/sayan-ghosh/>Sayan Ghosh</a>
|
<a href=/people/m/mathieu-chollet/>Mathieu Chollet</a>
|
<a href=/people/e/eugene-laksana/>Eugene Laksana</a>
|
<a href=/people/l/louis-philippe-morency/>Louis-Philippe Morency</a>
|
<a href=/people/s/stefan-scherer/>Stefan Scherer</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1059><div class="card-body p-3 small">Human verbal communication includes <a href=https://en.wikipedia.org/wiki/Affect_(psychology)>affective messages</a> which are conveyed through use of <a href=https://en.wikipedia.org/wiki/Emotion>emotionally colored words</a>. There has been a lot of research effort in this direction but the problem of integrating state-of-the-art neural language models with <a href=https://en.wikipedia.org/wiki/Affect_(psychology)>affective information</a> remains an area ripe for exploration. In this paper, we propose an extension to an LSTM (Long Short-Term Memory) language model for generation of conversational text, conditioned on <a href=https://en.wikipedia.org/wiki/Affect_(psychology)>affect categories</a>. Our proposed model, Affect-LM enables us to customize the degree of emotional content in generated sentences through an additional design parameter. Perception studies conducted using <a href=https://en.wikipedia.org/wiki/Amazon_Mechanical_Turk>Amazon Mechanical Turk</a> show that Affect-LM can generate naturally looking emotional sentences without sacrificing <a href=https://en.wikipedia.org/wiki/Grammaticality>grammatical correctness</a>. Affect-LM also learns affect-discriminative word representations, and perplexity experiments show that additional <a href=https://en.wikipedia.org/wiki/Affect_(psychology)>affective information</a> in conversational text can improve language model prediction.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Sayan+Ghosh" title="Search for 'Sayan Ghosh' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/m/mathieu-chollet/ class=align-middle>Mathieu Chollet</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eugene-laksana/ class=align-middle>Eugene Laksana</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/louis-philippe-morency/ class=align-middle>Louis-Philippe Morency</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stefan-scherer/ class=align-middle>Stefan Scherer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/somnath-basu-roy-chowdhury/ class=align-middle>Somnath Basu Roy Chowdhury</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/y/yiyuan-li/ class=align-middle>Yiyuan Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/junier-oliva/ class=align-middle>Junier Oliva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shashank-srivastava/ class=align-middle>Shashank Srivastava</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/snigdha-chaturvedi/ class=align-middle>Snigdha Chaturvedi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dylan-baker/ class=align-middle>Dylan Baker</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/david-jurgens/ class=align-middle>David Jurgens</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vinodkumar-prabhakaran/ class=align-middle>Vinodkumar Prabhakaran</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wnut/ class=align-middle>WNUT</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>