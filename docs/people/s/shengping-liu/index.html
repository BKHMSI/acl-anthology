<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Shengping Liu - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Shengping</span> <span class=font-weight-bold>Liu</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.284.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--284 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.284 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.284" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.284/>Biomedical Concept Normalization by Leveraging Hypernyms</a></strong><br><a href=/people/c/cheng-yan/>Cheng Yan</a>
|
<a href=/people/y/yuanzhe-zhang/>Yuanzhe Zhang</a>
|
<a href=/people/k/kang-liu/>Kang Liu</a>
|
<a href=/people/j/jun-zhao/>Jun Zhao</a>
|
<a href=/people/y/yafei-shi/>Yafei Shi</a>
|
<a href=/people/s/shengping-liu/>Shengping Liu</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--284><div class="card-body p-3 small">Biomedical Concept Normalization (BCN) is widely used in biomedical text processing as a fundamental module. Owing to numerous surface variants of biomedical concepts, BCN still remains challenging and unsolved. In this paper, we exploit biomedical concept hypernyms to facilitate BCN. We propose Biomedical Concept Normalizer with Hypernyms (BCNH), a novel framework that adopts list-wise training to make use of both hypernyms and synonyms, and also employs norm constraint on the representation of hypernym-hyponym entity pairs. The experimental results show that BCNH outperforms the previous state-of-the-art <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on the NCBI dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-demo.32.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-demo--32 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-demo.32 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-demo.32/>CroAno : A Crowd Annotation Platform for Improving Label Consistency of Chinese NER Dataset<span class=acl-fixed-case>C</span>ro<span class=acl-fixed-case>A</span>no : A Crowd Annotation Platform for Improving Label Consistency of <span class=acl-fixed-case>C</span>hinese <span class=acl-fixed-case>NER</span> Dataset</a></strong><br><a href=/people/b/baoli-zhang/>Baoli Zhang</a>
|
<a href=/people/z/zhucong-li/>Zhucong Li</a>
|
<a href=/people/z/zhen-gan/>Zhen Gan</a>
|
<a href=/people/y/yubo-chen/>Yubo Chen</a>
|
<a href=/people/j/jing-wan/>Jing Wan</a>
|
<a href=/people/k/kang-liu/>Kang Liu</a>
|
<a href=/people/j/jun-zhao/>Jun Zhao</a>
|
<a href=/people/s/shengping-liu/>Shengping Liu</a>
|
<a href=/people/y/yafei-shi/>Yafei Shi</a><br><a href=/volumes/2021.emnlp-demo/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-demo--32><div class="card-body p-3 small">In this paper, we introduce CroAno, a web-based crowd annotation platform for the Chinese named entity recognition (NER). Besides some basic features for crowd annotation like fast tagging and <a href=https://en.wikipedia.org/wiki/Data_management>data management</a>, CroAno provides a systematic solution for improving label consistency of Chinese NER dataset. 1) Disagreement Adjudicator : CroAno uses a multi-dimensional highlight mode to visualize instance-level inconsistent entities and makes the revision process user-friendly. 2) Inconsistency Detector : CroAno employs a detector to locate corpus-level label inconsistency and provides users an interface to correct inconsistent entities in batches. 3) Prediction Error Analyzer : We deconstruct the entity prediction error of the model to six fine-grained entity error types. Users can employ this <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error system</a> to detect corpus-level inconsistency from a model perspective. To validate the effectiveness of our <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a>, we use CroAno to revise two public datasets. In the two revised datasets, we get an improvement of +1.96 % and +2.57 % <a href=https://en.wikipedia.org/wiki/F-number>F1</a> respectively in model performance.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.282.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--282 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.282 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928939 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.282/>HyperCore : Hyperbolic and Co-graph Representation for Automatic ICD Coding<span class=acl-fixed-case>H</span>yper<span class=acl-fixed-case>C</span>ore: Hyperbolic and Co-graph Representation for Automatic <span class=acl-fixed-case>ICD</span> Coding</a></strong><br><a href=/people/p/pengfei-cao/>Pengfei Cao</a>
|
<a href=/people/y/yubo-chen/>Yubo Chen</a>
|
<a href=/people/k/kang-liu/>Kang Liu</a>
|
<a href=/people/j/jun-zhao/>Jun Zhao</a>
|
<a href=/people/s/shengping-liu/>Shengping Liu</a>
|
<a href=/people/w/weifeng-chong/>Weifeng Chong</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--282><div class="card-body p-3 small">The International Classification of Diseases (ICD) provides a standardized way for <a href=https://en.wikipedia.org/wiki/Medical_classification>classifying diseases</a>, which endows each disease with a unique code. ICD coding aims to assign proper ICD codes to a <a href=https://en.wikipedia.org/wiki/Medical_record>medical record</a>. Since manual coding is very laborious and prone to errors, many methods have been proposed for the automatic ICD coding task. However, most of existing <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> independently predict each code, ignoring two important characteristics : Code Hierarchy and <a href=https://en.wikipedia.org/wiki/Co-occurrence>Code Co-occurrence</a>. In this paper, we propose a Hyperbolic and Co-graph Representation method (HyperCore) to address the above problem. Specifically, we propose a hyperbolic representation method to leverage the code hierarchy. Moreover, we propose a graph convolutional network to utilize the code co-occurrence. Experimental results on two widely used datasets demonstrate that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms previous state-of-the-art methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.576.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--576 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.576 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929356 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.576/>MIE : A Medical Information Extractor towards Medical Dialogues<span class=acl-fixed-case>MIE</span>: A Medical Information Extractor towards Medical Dialogues</a></strong><br><a href=/people/y/yuanzhe-zhang/>Yuanzhe Zhang</a>
|
<a href=/people/z/zhongtao-jiang/>Zhongtao Jiang</a>
|
<a href=/people/t/tao-zhang/>Tao Zhang</a>
|
<a href=/people/s/shiwan-liu/>Shiwan Liu</a>
|
<a href=/people/j/jiarun-cao/>Jiarun Cao</a>
|
<a href=/people/k/kang-liu/>Kang Liu</a>
|
<a href=/people/s/shengping-liu/>Shengping Liu</a>
|
<a href=/people/j/jun-zhao/>Jun Zhao</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--576><div class="card-body p-3 small">Electronic Medical Records (EMRs) have become key components of modern <a href=https://en.wikipedia.org/wiki/Health_system>medical care systems</a>. Despite the merits of <a href=https://en.wikipedia.org/wiki/Electronic_health_record>EMRs</a>, many doctors suffer from writing them, which is time-consuming and tedious. We believe that automatically converting medical dialogues to <a href=https://en.wikipedia.org/wiki/Electronic_health_record>EMRs</a> can greatly reduce the burdens of doctors, and extracting information from medical dialogues is an essential step. To this end, we annotate online medical consultation dialogues in a window-sliding style, which is much easier than the sequential labeling annotation. We then propose a Medical Information Extractor (MIE) towards medical dialogues. MIE is able to extract mentioned symptoms, <a href=https://en.wikipedia.org/wiki/Surgery>surgeries</a>, <a href=https://en.wikipedia.org/wiki/Medical_test>tests</a>, other information and their corresponding status. To tackle the particular challenges of the task, MIE uses a deep matching architecture, taking dialogue turn-interaction into account. The experimental results demonstrate MIE is a promising solution to extract <a href=https://en.wikipedia.org/wiki/Medical_record>medical information</a> from doctor-patient dialogues.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1035.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1035 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1035 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1035/>Learning the Extraction Order of Multiple Relational Facts in a Sentence with <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>Reinforcement Learning</a></a></strong><br><a href=/people/x/xiangrong-zeng/>Xiangrong Zeng</a>
|
<a href=/people/s/shizhu-he/>Shizhu He</a>
|
<a href=/people/d/daojian-zeng/>Daojian Zeng</a>
|
<a href=/people/k/kang-liu/>Kang Liu</a>
|
<a href=/people/s/shengping-liu/>Shengping Liu</a>
|
<a href=/people/j/jun-zhao/>Jun Zhao</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1035><div class="card-body p-3 small">The multiple relation extraction task tries to extract all relational facts from a sentence. Existing works did n&#8217;t consider the extraction order of relational facts in a sentence. In this paper we argue that the extraction order is important in this task. To take the extraction order into consideration, we apply the <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> into a sequence-to-sequence model. The proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> could generate <a href=https://en.wikipedia.org/wiki/Relational_model>relational facts</a> freely. Widely conducted experiments on two public datasets demonstrate the efficacy of the proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a>.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1017.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1017 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1017 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/306354811 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1017" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1017/>Adversarial Transfer Learning for Chinese Named Entity Recognition with Self-Attention Mechanism<span class=acl-fixed-case>C</span>hinese Named Entity Recognition with Self-Attention Mechanism</a></strong><br><a href=/people/p/pengfei-cao/>Pengfei Cao</a>
|
<a href=/people/y/yubo-chen/>Yubo Chen</a>
|
<a href=/people/k/kang-liu/>Kang Liu</a>
|
<a href=/people/j/jun-zhao/>Jun Zhao</a>
|
<a href=/people/s/shengping-liu/>Shengping Liu</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1017><div class="card-body p-3 small">Named entity recognition (NER) is an important task in natural language processing area, which needs to determine entities boundaries and classify them into pre-defined categories. For Chinese NER task, there is only a very small amount of annotated data available. Chinese NER task and Chinese word segmentation (CWS) task have many similar word boundaries. There are also specificities in each <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. However, existing methods for Chinese NER either do not exploit word boundary information from CWS or can not filter the specific information of CWS. In this paper, we propose a novel adversarial transfer learning framework to make full use of task-shared boundaries information and prevent the task-specific features of CWS. Besides, since arbitrary character can provide important cues when predicting entity type, we exploit self-attention to explicitly capture long range dependencies between two tokens. Experimental results on two different widely used datasets show that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> significantly and consistently outperforms other state-of-the-art methods.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Shengping+Liu" title="Search for 'Shengping Liu' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/k/kang-liu/ class=align-middle>Kang Liu (刘康)</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/j/jun-zhao/ class=align-middle>Jun Zhao</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/y/yubo-chen/ class=align-middle>Yubo Chen</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/p/pengfei-cao/ class=align-middle>Pengfei Cao</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yuanzhe-zhang/ class=align-middle>Yuanzhe Zhang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/y/yafei-shi/ class=align-middle>Yafei Shi</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/w/weifeng-chong/ class=align-middle>Weifeng Chong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhongtao-jiang/ class=align-middle>Zhongtao Jiang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tao-zhang/ class=align-middle>Tao Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shiwan-liu/ class=align-middle>Shiwan Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiarun-cao/ class=align-middle>Jiarun Cao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cheng-yan/ class=align-middle>Cheng Yan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/baoli-zhang/ class=align-middle>Baoli Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhucong-li/ class=align-middle>Zhucong Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhen-gan/ class=align-middle>Zhen Gan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jing-wan/ class=align-middle>Jing Wan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiangrong-zeng/ class=align-middle>Xiangrong Zeng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shizhu-he/ class=align-middle>Shizhu He (何世柱)</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/daojian-zeng/ class=align-middle>Daojian Zeng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>