<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Sandra Kübler - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Sandra</span> <span class=font-weight-bold>Kübler</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Sandra <span class=font-weight-normal>Kuebler</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ranlp-1.182.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ranlp-1--182 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ranlp-1.182 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ranlp-1.182/>Delexicalized Cross-lingual Dependency Parsing for Xibe<span class=acl-fixed-case>X</span>ibe</a></strong><br><a href=/people/h/he-zhou/>He Zhou</a>
|
<a href=/people/s/sandra-kubler/>Sandra Kübler</a><br><a href=/volumes/2021.ranlp-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ranlp-1--182><div class="card-body p-3 small">Manually annotating a <a href=https://en.wikipedia.org/wiki/Treebank>treebank</a> is time-consuming and labor-intensive. We conduct delexicalized cross-lingual dependency parsing experiments, where we train the <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> on one language and test on our target language. As our test case, we use <a href=https://en.wikipedia.org/wiki/Xibe_language>Xibe</a>, a severely under-resourced Tungusic language. We assume that choosing a closely related language as the source language will provide better results than more distant relatives. However, it is not clear how to determine those closely related languages. We investigate three different methods : choosing the typologically closest language, using LangRank, and choosing the most similar language based on perplexity. We train parsing models on the selected languages using UDify and test on different genres of Xibe data. The results show that languages selected based on <a href=https://en.wikipedia.org/wiki/Linguistic_typology>typology</a> and perplexity scores outperform those predicted by LangRank ; <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> is the optimal source language. In determining the source language, proximity to the target language is more important than large training sizes. Parsing is also influenced by genre differences, but they have little influence as long as the training data is at least as complex as the target.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.latechclfl-1.19.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--latechclfl-1--19 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.latechclfl-1.19 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.latechclfl-1.19/>Period Classification in Chinese Historical Texts<span class=acl-fixed-case>C</span>hinese Historical Texts</a></strong><br><a href=/people/z/zuoyu-tian/>Zuoyu Tian</a>
|
<a href=/people/s/sandra-kubler/>Sandra Kübler</a><br><a href=/volumes/2021.latechclfl-1/ class=text-muted>Proceedings of the 5th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--latechclfl-1--19><div class="card-body p-3 small">In this study, we study <a href=https://en.wikipedia.org/wiki/Language_change>language change</a> in Chinese Biji by using a classification task : classifying Ancient Chinese texts by time periods. Specifically, we focus on a unique genre in <a href=https://en.wikipedia.org/wiki/Classical_Chinese_literature>classical Chinese literature</a> : <a href=https://en.wikipedia.org/wiki/Biji_(Chinese_literature)>Biji</a> (literally notebook or brush notes), i.e., collections of anecdotes, quotations, etc., anything authors consider noteworthy, <a href=https://en.wikipedia.org/wiki/Biji_(Chinese_literature)>Biji</a> span hundreds of years across many dynasties and conserve informal language in written form. For these reasons, they are regarded as a good resource for investigating <a href=https://en.wikipedia.org/wiki/Language_change>language change</a> in <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a> (Fang, 2010). In this paper, we create a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 108 Biji across four dynasties. Based on the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, we first introduce a time period classification task for <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>. Then we investigate different <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature representation methods</a> for <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a>. The results show that <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> using contextualized embeddings perform best. An analysis of the top <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> chosen by the word n-gram model (after bleaching proper nouns) confirms that these <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> are informative and correspond to observations and assumptions made by historical linguists.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.udw-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--udw-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.udw-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.udw-1.23/>Universal Dependency Treebank for Xibe<span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependency Treebank for <span class=acl-fixed-case>X</span>ibe</a></strong><br><a href=/people/h/he-zhou/>He Zhou</a>
|
<a href=/people/j/juyeon-chung/>Juyeon Chung</a>
|
<a href=/people/s/sandra-kubler/>Sandra Kübler</a>
|
<a href=/people/f/francis-tyers/>Francis Tyers</a><br><a href=/volumes/2020.udw-1/ class=text-muted>Proceedings of the Fourth Workshop on Universal Dependencies (UDW 2020)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--udw-1--23><div class="card-body p-3 small">We present our work of constructing the first <a href=https://en.wikipedia.org/wiki/Treebank>treebank</a> for the <a href=https://en.wikipedia.org/wiki/Xibe>Xibe language</a> following the Universal Dependencies (UD) annotation scheme. Xibe is a low-resourced and severely endangered Tungusic language spoken by the Xibe minority living in the Xinjiang Uygur Autonomous Region of China. We collected 810 sentences so far, including 544 sentences from a grammar book on written Xibe and 266 sentences from Cabcal News. We annotated those sentences manually from scratch. In this paper, we report the procedure of building this <a href=https://en.wikipedia.org/wiki/Treebank>treebank</a> and analyze several important annotation issues of our <a href=https://en.wikipedia.org/wiki/Treebank>treebank</a>. Finally, we propose our plans for future work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.314.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--314 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.314 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.findings-emnlp.314" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.314/>OCNLI : Original Chinese Natural Language Inference<span class=acl-fixed-case>OCNLI</span>: <span class=acl-fixed-case>O</span>riginal <span class=acl-fixed-case>C</span>hinese <span class=acl-fixed-case>N</span>atural <span class=acl-fixed-case>L</span>anguage <span class=acl-fixed-case>I</span>nference</a></strong><br><a href=/people/h/hai-hu/>Hai Hu</a>
|
<a href=/people/k/kyle-richardson/>Kyle Richardson</a>
|
<a href=/people/l/liang-xu/>Liang Xu</a>
|
<a href=/people/l/lu-li/>Lu Li</a>
|
<a href=/people/s/sandra-kubler/>Sandra Kübler</a>
|
<a href=/people/l/lawrence-s-moss/>Lawrence Moss</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--314><div class="card-body p-3 small">Despite the tremendous recent progress on <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language inference (NLI)</a>, driven largely by large-scale investment in new <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> (e.g.,SNLI, MNLI) and advances in <a href=https://en.wikipedia.org/wiki/Mathematical_model>modeling</a>, most progress has been limited to <a href=https://en.wikipedia.org/wiki/English_language>English</a> due to a lack of reliable datasets for most of the world&#8217;s languages. In this paper, we present the first large-scale NLI dataset (consisting of ~56,000 annotated sentence pairs) for <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a> called the Original <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese Natural Language Inference dataset (OCNLI)</a>. Unlike recent attempts at extending NLI to other languages, our dataset does not rely on any <a href=https://en.wikipedia.org/wiki/Automatic_translation>automatic translation</a> or non-expert annotation. Instead, we elicit <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> from native speakers specializing in <a href=https://en.wikipedia.org/wiki/Linguistics>linguistics</a>. We follow closely the annotation protocol used for MNLI, but create new strategies for eliciting diverse hypotheses. We establish several baseline results on our dataset using state-of-the-art pre-trained models for <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, and find even the best performing models to be far outpaced by human performance (~12 % absolute performance gap), making it a challenging new resource that we hope will help to accelerate progress in <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese NLU</a>. To the best of our knowledge, this is the first human-elicited MNLI-style corpus for a non-English language.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-2138.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S19-2138 data-toggle=collapse aria-expanded=false aria-controls=abstract-S19-2138 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=S19-2138" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/S19-2138/>UM-IU@LING at SemEval-2019 Task 6 : Identifying Offensive Tweets Using BERT and SVMs<span class=acl-fixed-case>UM</span>-<span class=acl-fixed-case>IU</span>@<span class=acl-fixed-case>LING</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2019 Task 6: Identifying Offensive Tweets Using <span class=acl-fixed-case>BERT</span> and <span class=acl-fixed-case>SVM</span>s</a></strong><br><a href=/people/j/jian-zhu/>Jian Zhu</a>
|
<a href=/people/z/zuoyu-tian/>Zuoyu Tian</a>
|
<a href=/people/s/sandra-kubler/>Sandra Kübler</a><br><a href=/volumes/S19-2/ class=text-muted>Proceedings of the 13th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S19-2138><div class="card-body p-3 small">This paper describes the UM-IU@LING&#8217;s system for the SemEval 2019 Task 6 : Offens-Eval. We take a mixed approach to identify and categorize <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a> in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. In subtask A, we fine-tuned a BERT based classifier to detect abusive content in <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>, achieving a macro F1 score of 0.8136 on the test data, thus reaching the 3rd rank out of 103 submissions. In subtasks B and C, we used a linear SVM with selected character n-gram features. For subtask C, our system could identify the target of abuse with a macro F1 score of 0.5243, ranking it 27th out of 65 submissions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1132.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1132 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1132 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1132/>Investigating Multilingual Abusive Language Detection : A Cautionary Tale</a></strong><br><a href=/people/k/kenneth-steimel/>Kenneth Steimel</a>
|
<a href=/people/d/daniel-dakota/>Daniel Dakota</a>
|
<a href=/people/y/yue-chen/>Yue Chen</a>
|
<a href=/people/s/sandra-kubler/>Sandra Kübler</a><br><a href=/volumes/R19-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1132><div class="card-body p-3 small">Abusive language detection has received much attention in the last years, and recent approaches perform the task in a number of different languages. We investigate which factors have an effect on multilingual settings, focusing on the compatibility of data and annotations. In the current paper, we focus on <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/German_language>German</a>. Our findings show large differences in performance between the two languages. We find that the best performance is achieved by different <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification algorithms</a>. Sampling to address class imbalance issues is detrimental for <a href=https://en.wikipedia.org/wiki/German_language>German</a> and beneficial for <a href=https://en.wikipedia.org/wiki/English_language>English</a>. The only similarity that we find is that neither data set shows clear topics when we compare the results of <a href=https://en.wikipedia.org/wiki/Topic_modeling>topic modeling</a> to the gold standard. Based on our findings, we can conclude that a multilingual optimization of classifiers is not possible even in settings where comparable data sets are used.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-1603.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-1603 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-1603 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-1603/>Detecting Syntactic Features of Translated Chinese<span class=acl-fixed-case>C</span>hinese</a></strong><br><a href=/people/h/hai-hu/>Hai Hu</a>
|
<a href=/people/w/wen-li/>Wen Li</a>
|
<a href=/people/s/sandra-kubler/>Sandra Kübler</a><br><a href=/volumes/W18-16/ class=text-muted>Proceedings of the Second Workshop on Stylistic Variation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-1603><div class="card-body p-3 small">We present a machine learning approach to distinguish texts translated to Chinese (by humans) from texts originally written in <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, with a focus on a wide range of syntactic features. Using Support Vector Machines (SVMs) as classifier on a genre-balanced corpus in translation studies of Chinese, we find that constituent parse trees and dependency triples as <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> without lexical information perform very well on the task, with an F-measure above 90 %, close to the results of lexical n-gram features, without the risk of learning topic information rather than translation features. Thus, we claim syntactic features alone can accurately distinguish <a href=https://en.wikipedia.org/wiki/Translation>translated</a> from original Chinese. Translated Chinese exhibits an increased use of determiners, subject position pronouns, NP + as NP modifiers, multiple NPs or VPs conjoined by, among other structures. We also interpret the <a href=https://en.wikipedia.org/wiki/Syntax>syntactic features</a> with reference to previous translation studies in <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, particularly the usage of <a href=https://en.wikipedia.org/wiki/Pronoun>pronouns</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5800.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5800/>Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology</a></strong><br><a href=/people/s/sandra-kubler/>Sandra Kuebler</a>
|
<a href=/people/g/garrett-nicolai/>Garrett Nicolai</a><br><a href=/volumes/W18-58/ class=text-muted>Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology</a></span></p></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Sandra+K%C3%BCbler" title="Search for 'Sandra Kübler' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/h/he-zhou/ class=align-middle>He Zhou</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/zuoyu-tian/ class=align-middle>Zuoyu Tian</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hai-hu/ class=align-middle>Hai Hu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/juyeon-chung/ class=align-middle>Juyeon Chung</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/francis-tyers/ class=align-middle>Francis Tyers</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/j/jian-zhu/ class=align-middle>Jian Zhu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kyle-richardson/ class=align-middle>Kyle Richardson</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/liang-xu/ class=align-middle>Liang Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lu-li/ class=align-middle>Lu Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lawrence-s-moss/ class=align-middle>Lawrence S. Moss</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wen-li/ class=align-middle>Wen Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/garrett-nicolai/ class=align-middle>Garrett Nicolai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kenneth-steimel/ class=align-middle>Kenneth Steimel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/daniel-dakota/ class=align-middle>Daniel Dakota</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yue-chen/ class=align-middle>Yue Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ranlp/ class=align-middle>RANLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/udw/ class=align-middle>UDW</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/latechclfl/ class=align-middle>LaTeCHCLfL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>