<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Shijin Wang - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Shijin</span> <span class=font-weight-bold>Wang</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.408.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--408 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.408 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.408/>Continual Pre-training of Language Models for Math Problem Understanding with Syntax-Aware Memory Network</a></strong><br><a href=/people/z/zheng-gong/>Zheng Gong</a>
|
<a href=/people/k/kun-zhou/>Kun Zhou</a>
|
<a href=/people/w/wayne-xin-zhao/>Xin Zhao</a>
|
<a href=/people/j/jing-sha/>Jing Sha</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/j/ji-rong-wen/>Ji-Rong Wen</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--408><div class="card-body p-3 small">In this paper, we study how to continually pre-train language models for improving the understanding of math problems. Specifically, we focus on solving a fundamental challenge in modeling math problems, how to fuse the semantics of textual description and formulas, which are highly different in essence. To address this issue, we propose a new approach called <b>COMUS</b> to <b>co</b>ntinually pre-train language models for <b>m</b>ath problem <b>u</b>nderstanding with <b>s</b>yntax-aware memory network. In this approach, we first construct the math syntax graph to model the structural semantic information, by combining the parsing trees of the text and formulas, and then design the syntax-aware memory networks to deeply fuse the features from the graph and text. With the help of syntax relations, we can model the interaction between the token from the text and its semantic-related nodes within the formulas, which is helpful to capture fine-grained semantic correlations between texts and formulas. Besides, we devise three continual pre-training tasks to further align and fuse the representations of the text and math syntax graph. Experimental results on four tasks in the math domain demonstrate the effectiveness of our approach. Our code and data are publicly available at the link: blue<url>https://github.com/RUCAIBox/COMUS</url>.</div></div><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mrqa-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mrqa-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mrqa-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mrqa-1.10/>Bilingual Alignment Pre-Training for Zero-Shot Cross-Lingual Transfer</a></strong><br><a href=/people/z/ziqing-yang/>Ziqing Yang</a>
|
<a href=/people/w/wentao-ma/>Wentao Ma</a>
|
<a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/j/jiani-ye/>Jiani Ye</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a><br><a href=/volumes/2021.mrqa-1/ class=text-muted>Proceedings of the 3rd Workshop on Machine Reading for Question Answering</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mrqa-1--10><div class="card-body p-3 small">Multilingual pre-trained models have achieved remarkable performance on cross-lingual transfer learning. Some multilingual models such as mBERT, have been pre-trained on unlabeled corpora, therefore the embeddings of different languages in the <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> may not be aligned very well. In this paper, we aim to improve the zero-shot cross-lingual transfer performance by proposing a pre-training task named Word-Exchange Aligning Model (WEAM), which uses the statistical alignment information as the prior knowledge to guide cross-lingual word prediction. We evaluate our model on multilingual machine reading comprehension task MLQA and natural language interface task XNLI. The results show that <a href=https://en.wikipedia.org/wiki/WEAM>WEAM</a> can significantly improve the zero-shot performance.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.583.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--583 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.583 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938772 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.583/>Is <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>Graph Structure</a> Necessary for Multi-hop Question Answering?<span class=acl-fixed-case>G</span>raph <span class=acl-fixed-case>S</span>tructure <span class=acl-fixed-case>N</span>ecessary for <span class=acl-fixed-case>M</span>ulti-hop <span class=acl-fixed-case>Q</span>uestion <span class=acl-fixed-case>A</span>nswering?</a></strong><br><a href=/people/n/nan-shao/>Nan Shao</a>
|
<a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--583><div class="card-body p-3 small">Recently, attempting to model texts as <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> and introducing graph neural networks to deal with it has become a trend in many <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP research areas</a>. In this paper, we investigate whether the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> is necessary for textual multi-hop reasoning. Our analysis is centered on HotpotQA. We construct a strong baseline model to establish that, with the proper use of pre-trained models, <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> may not be necessary for textual multi-hop reasoning. We point out that both <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> and <a href=https://en.wikipedia.org/wiki/Adjacency_matrix>adjacency matrix</a> are task-related prior knowledge, and graph-attention can be considered as a special case of self-attention. Experiments demonstrate that graph-attention or the entire <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> can be replaced by self-attention or Transformers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928594 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-demos.2" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.2/>TextBrewer : An Open-Source Knowledge Distillation Toolkit for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a><span class=acl-fixed-case>T</span>ext<span class=acl-fixed-case>B</span>rewer: <span class=acl-fixed-case>A</span>n <span class=acl-fixed-case>O</span>pen-<span class=acl-fixed-case>S</span>ource <span class=acl-fixed-case>K</span>nowledge <span class=acl-fixed-case>D</span>istillation <span class=acl-fixed-case>T</span>oolkit for <span class=acl-fixed-case>N</span>atural <span class=acl-fixed-case>L</span>anguage <span class=acl-fixed-case>P</span>rocessing</a></strong><br><a href=/people/z/ziqing-yang/>Ziqing Yang</a>
|
<a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/z/zhipeng-chen/>Zhipeng Chen</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a><br><a href=/volumes/2020.acl-demos/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--2><div class="card-body p-3 small">In this paper, we introduce TextBrewer, an open-source knowledge distillation toolkit designed for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. It works with different neural network models and supports various kinds of supervised learning tasks, such as <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a>, <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>, <a href=https://en.wikipedia.org/wiki/Sequence_labeling>sequence labeling</a>. TextBrewer provides a simple and uniform workflow that enables quick setting up of <a href=https://en.wikipedia.org/wiki/Distillation>distillation</a> experiments with highly flexible configurations. It offers a set of predefined distillation methods and can be extended with custom code. As a case study, we use TextBrewer to distill BERT on several typical NLP tasks. With simple configurations, we achieve results that are comparable with or even higher than the public distilled BERT models with similar numbers of parameters.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.coling-main.4" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.4/>CharBERT : Character-aware Pre-trained Language Model<span class=acl-fixed-case>C</span>har<span class=acl-fixed-case>BERT</span>: Character-aware Pre-trained Language Model</a></strong><br><a href=/people/w/wentao-ma/>Wentao Ma</a>
|
<a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/c/chenglei-si/>Chenglei Si</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--4><div class="card-body p-3 small">Most pre-trained language models (PLMs) construct word representations at subword level with Byte-Pair Encoding (BPE) or its variations, by which OOV (out-of-vocab) words are almost avoidable. However, those methods split a word into subword units and make the representation incomplete and fragile. In this paper, we propose a character-aware pre-trained language model named CharBERT improving on the previous methods (such as BERT, RoBERTa) to tackle these problems. We first construct the contextual word embedding for each token from the sequential character representations, then fuse the representations of characters and the subword representations by a novel heterogeneous interaction module. We also propose a new pre-training task named NLM (Noisy LM) for unsupervised character representation learning. We evaluate our method on <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>, sequence labeling, and text classification tasks, both on the original datasets and adversarial misspelling test sets. The experimental results show that our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> can significantly improve the performance and robustness of PLMs simultaneously.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.542.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--542 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.542 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.542/>Text Classification by Contrastive Learning and Cross-lingual Data Augmentation for Alzheimer’s Disease Detection<span class=acl-fixed-case>A</span>lzheimer’s Disease Detection</a></strong><br><a href=/people/z/zhiqiang-guo/>Zhiqiang Guo</a>
|
<a href=/people/z/zhaoci-liu/>Zhaoci Liu</a>
|
<a href=/people/z/zhenhua-ling/>Zhenhua Ling</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/l/lingjing-jin/>Lingjing Jin</a>
|
<a href=/people/y/yunxia-li/>Yunxia Li</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--542><div class="card-body p-3 small">Data scarcity is always a constraint on analyzing speech transcriptions for automatic Alzheimer&#8217;s disease (AD) detection, especially when the subjects are non-English speakers. To deal with this issue, this paper first proposes a contrastive learning method to obtain effective representations for text classification based on monolingual embeddings of BERT. Furthermore, a cross-lingual data augmentation method is designed by building autoencoders to learn the text representations shared by both languages. Experiments on a Mandarin AD corpus show that the contrastive learning method can achieve better detection accuracy than conventional CNN-based and BERTbased methods. Our cross-lingual data augmentation method also outperforms other compared methods when using another English AD corpus for augmentation. Finally, a best <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>detection accuracy</a> of 81.6 % is obtained by our proposed <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> on the Mandarin AD corpus.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1169.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1169 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1169 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1169" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1169/>Cross-Lingual Machine Reading Comprehension</a></strong><br><a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/b/bing-qin/>Bing Qin</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1169><div class="card-body p-3 small">Though the community has made great progress on Machine Reading Comprehension (MRC) task, most of the previous works are solving English-based MRC problems, and there are few efforts on other languages mainly due to the lack of large-scale training data. In this paper, we propose Cross-Lingual Machine Reading Comprehension (CLMRC) task for the languages other than English. Firstly, we present several back-translation approaches for CLMRC task which is straightforward to adopt. However, to exactly align the answer into source language is difficult and could introduce additional noise. In this context, we propose a novel model called Dual BERT, which takes advantage of the large-scale training data provided by rich-resource language (such as English) and learn the semantic relations between the passage and question in bilingual context, and then utilize the learned knowledge to improve <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> performance of low-resource language. We conduct experiments on two Chinese machine reading comprehension datasets CMRC 2018 and DRCD. The results show consistent and significant improvements over various state-of-the-art systems by a large margin, which demonstrate the potentials in CLMRC task. Resources available : https://github.com/ymcui/Cross-Lingual-MRC</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1600.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1600 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1600 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1600" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1600/>A Span-Extraction Dataset for Chinese Machine Reading Comprehension<span class=acl-fixed-case>C</span>hinese Machine Reading Comprehension</a></strong><br><a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/l/li-xiao/>Li Xiao</a>
|
<a href=/people/z/zhipeng-chen/>Zhipeng Chen</a>
|
<a href=/people/w/wentao-ma/>Wentao Ma</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1600><div class="card-body p-3 small">Machine Reading Comprehension (MRC) has become enormously popular recently and has attracted a lot of attention. However, the existing reading comprehension datasets are mostly in <a href=https://en.wikipedia.org/wiki/English_language>English</a>. In this paper, we introduce a Span-Extraction dataset for Chinese machine reading comprehension to add <a href=https://en.wikipedia.org/wiki/Language_diversity>language diversities</a> in this area. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is composed by near 20,000 real questions annotated on Wikipedia paragraphs by human experts. We also annotated a challenge set which contains the questions that need comprehensive understanding and multi-sentence inference throughout the context. We present several <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline systems</a> as well as anonymous submissions for demonstrating the difficulties in this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. With the release of the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, we hosted the Second Evaluation Workshop on Chinese Machine Reading Comprehension (CMRC 2018). We hope the release of the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> could further accelerate the Chinese machine reading comprehension research. Resources are available : https://github.com/ymcui/cmrc2018</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1010 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234953310 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1010/>Generating and Exploiting Large-scale Pseudo Training Data for Zero Pronoun Resolution</a></strong><br><a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/q/qingyu-yin/>Qingyu Yin</a>
|
<a href=/people/w/weinan-zhang/>Wei-Nan Zhang</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1010><div class="card-body p-3 small">Most existing approaches for zero pronoun resolution are heavily relying on annotated data, which is often released by shared task organizers. Therefore, the lack of annotated data becomes a major obstacle in the progress of zero pronoun resolution task. Also, it is expensive to spend manpower on labeling the data for better performance. To alleviate the problem above, in this paper, we propose a simple but novel approach to automatically generate large-scale pseudo training data for zero pronoun resolution. Furthermore, we successfully transfer the cloze-style reading comprehension neural network model into zero pronoun resolution task and propose a two-step training mechanism to overcome the gap between the pseudo training data and the real one. Experimental results show that the proposed <a href=https://en.wikipedia.org/wiki/Design_of_experiments>approach</a> significantly outperforms the state-of-the-art <a href=https://en.wikipedia.org/wiki/System>systems</a> with an absolute improvements of 3.1 % <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> on OntoNotes 5.0 data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1055.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1055 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1055 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234956590 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P17-1055" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1055/>Attention-over-Attention Neural Networks for Reading Comprehension</a></strong><br><a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/z/zhipeng-chen/>Zhipeng Chen</a>
|
<a href=/people/s/si-wei/>Si Wei</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1055><div class="card-body p-3 small">Cloze-style reading comprehension is a representative problem in mining relationship between document and query. In this paper, we present a simple but novel model called attention-over-attention reader for better solving cloze-style reading comprehension task. The proposed model aims to place another <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanism</a> over the document-level attention and induces attended attention for final answer predictions. One advantage of our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is that <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> is simpler than related works while giving excellent performance. In addition to the primary model, we also propose an N-best re-ranking strategy to double check the validity of the candidates and further improve the performance. Experimental results show that the proposed methods significantly outperform various state-of-the-art systems by a large margin in public datasets, such as <a href=https://en.wikipedia.org/wiki/CNN>CNN</a> and Children&#8217;s Book Test.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Shijin+Wang" title="Search for 'Shijin Wang' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/y/yiming-cui/ class=align-middle>Yiming Cui</a>
<span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/people/t/ting-liu/ class=align-middle>Ting Liu</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/g/guoping-hu/ class=align-middle>Guoping Hu</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/w/wanxiang-che/ class=align-middle>Wanxiang Che (车万翔)</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/w/wentao-ma/ class=align-middle>Wentao Ma</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/z/zhipeng-chen/ class=align-middle>Zhipeng Chen</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/z/ziqing-yang/ class=align-middle>Ziqing Yang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jiani-ye/ class=align-middle>Jiani Ye</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nan-shao/ class=align-middle>Nan Shao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qingyu-yin/ class=align-middle>Qingyu Yin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/weinan-zhang/ class=align-middle>Weinan Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/si-wei/ class=align-middle>Si Wei</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zheng-gong/ class=align-middle>Zheng Gong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kun-zhou/ class=align-middle>Kun Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wayne-xin-zhao/ class=align-middle>Wayne Xin Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jing-sha/ class=align-middle>Jing Sha</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/ji-rong-wen/ class=align-middle>Ji-Rong Wen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bing-qin/ class=align-middle>Bing Qin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/li-xiao/ class=align-middle>Li Xiao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chenglei-si/ class=align-middle>Chenglei Si</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhiqiang-guo/ class=align-middle>Zhiqiang Guo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhaoci-liu/ class=align-middle>Zhaoci Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhenhua-ling/ class=align-middle>Zhenhua Ling</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lingjing-jin/ class=align-middle>Lingjing Jin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yunxia-li/ class=align-middle>Yunxia Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/mrqa/ class=align-middle>MRQA</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>