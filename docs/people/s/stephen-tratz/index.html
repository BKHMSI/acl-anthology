<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Stephen Tratz - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Stephen</span> <span class=font-weight-bold>Tratz</span></h2><hr><div class=row><div class=col-lg-9><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.86.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--86 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.86 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.86/>Dialogue-AMR : Abstract Meaning Representation for Dialogue<span class=acl-fixed-case>AMR</span>: <span class=acl-fixed-case>A</span>bstract <span class=acl-fixed-case>M</span>eaning <span class=acl-fixed-case>R</span>epresentation for Dialogue</a></strong><br><a href=/people/c/claire-bonial/>Claire Bonial</a>
|
<a href=/people/l/lucia-donatelli/>Lucia Donatelli</a>
|
<a href=/people/m/mitchell-abrams/>Mitchell Abrams</a>
|
<a href=/people/s/stephanie-lukin/>Stephanie M. Lukin</a>
|
<a href=/people/s/stephen-tratz/>Stephen Tratz</a>
|
<a href=/people/m/matthew-marge/>Matthew Marge</a>
|
<a href=/people/r/ron-artstein/>Ron Artstein</a>
|
<a href=/people/d/david-traum/>David Traum</a>
|
<a href=/people/c/clare-voss/>Clare Voss</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--86><div class="card-body p-3 small">This paper describes a schema that enriches Abstract Meaning Representation (AMR) in order to provide a semantic representation for facilitating Natural Language Understanding (NLU) in dialogue systems. AMR offers a valuable level of abstraction of the propositional content of an utterance ; however, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> does not capture the illocutionary force or speaker&#8217;s intended contribution in the broader dialogue context (e.g., make a request or ask a question), nor does <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> capture <a href=https://en.wikipedia.org/wiki/Grammatical_tense>tense</a> or aspect. We explore <a href=https://en.wikipedia.org/wiki/Dialogue>dialogue</a> in the domain of <a href=https://en.wikipedia.org/wiki/Human&#8211;robot_interaction>human-robot interaction</a>, where a conversational robot is engaged in search and navigation tasks with a human partner. To address the limitations of standard AMR, we develop an inventory of speech acts suitable for our domain, and present Dialogue-AMR, an enhanced AMR that represents not only the content of an utterance, but the illocutionary force behind it, as well as <a href=https://en.wikipedia.org/wiki/Grammatical_tense>tense</a> and <a href=https://en.wikipedia.org/wiki/Grammatical_aspect>aspect</a>. To showcase the coverage of the <a href=https://en.wikipedia.org/wiki/Database_schema>schema</a>, we use both manual and automatic methods to construct the DialAMR corpusa corpus of human-robot dialogue annotated with standard AMR and our enriched Dialogue-AMR schema. Our automated methods can be used to incorporate AMR into a larger NLU pipeline supporting <a href=https://en.wikipedia.org/wiki/Human&#8211;robot_interaction>human-robot dialogue</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5901.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5901 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5901 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5901/>Dependency Tree Annotation with Mechanical Turk<span class=acl-fixed-case>M</span>echanical <span class=acl-fixed-case>T</span>urk</a></strong><br><a href=/people/s/stephen-tratz/>Stephen Tratz</a><br><a href=/volumes/D19-59/ class=text-muted>Proceedings of the First Workshop on Aggregating and Analysing Crowdsourced Annotations for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5901><div class="card-body p-3 small">Crowdsourcing is frequently employed to quickly and inexpensively obtain valuable linguistic annotations but is rarely used for <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a>, likely due to the perceived difficulty of the task and the limited training of the available workers. This paper presents what is, to the best of our knowledge, the first published use of Mechanical Turk (or similar platform) to crowdsource parse trees. We pay Turkers to construct unlabeled dependency trees for 500 English sentences using an interactive graphical dependency tree editor, collecting 10 annotations per sentence. Despite not requiring any training, several of the more prolific workers meet or exceed 90 % attachment agreement with the Penn Treebank (PTB) portion of our data, and, furthermore, for 72 % of these PTB sentences, at least one Turker produces a perfect parse. Thus, we find that, supported with a simple <a href=https://en.wikipedia.org/wiki/Graphical_user_interface>graphical interface</a>, people with presumably no prior experience can achieve surprisingly high degrees of <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. To facilitate research into aggregation techniques for complex crowdsourced annotations, we publicly release our annotated corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3322.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3322 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3322 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3322/>Augmenting Abstract Meaning Representation for <a href=https://en.wikipedia.org/wiki/Human&#8211;computer_interaction>Human-Robot Dialogue</a><span class=acl-fixed-case>A</span>bstract <span class=acl-fixed-case>M</span>eaning <span class=acl-fixed-case>R</span>epresentation for Human-Robot Dialogue</a></strong><br><a href=/people/c/claire-bonial/>Claire Bonial</a>
|
<a href=/people/l/lucia-donatelli/>Lucia Donatelli</a>
|
<a href=/people/s/stephanie-lukin/>Stephanie M. Lukin</a>
|
<a href=/people/s/stephen-tratz/>Stephen Tratz</a>
|
<a href=/people/r/ron-artstein/>Ron Artstein</a>
|
<a href=/people/d/david-traum/>David Traum</a>
|
<a href=/people/c/clare-voss/>Clare Voss</a><br><a href=/volumes/W19-33/ class=text-muted>Proceedings of the First International Workshop on Designing Meaning Representations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3322><div class="card-body p-3 small">We detail refinements made to Abstract Meaning Representation (AMR) that make the representation more suitable for supporting a situated dialogue system, where a human remotely controls a robot for purposes of <a href=https://en.wikipedia.org/wiki/Search_and_rescue>search and rescue</a> and reconnaissance. We propose 36 augmented AMRs that capture speech acts, <a href=https://en.wikipedia.org/wiki/Grammatical_tense>tense</a> and aspect, and <a href=https://en.wikipedia.org/wiki/Spatial_analysis>spatial information</a>. This linguistic information is vital for representing important distinctions, for example whether the robot has moved, is moving, or will move. We evaluate two existing AMR parsers for their performance on dialogue data. We also outline a model for graph-to-graph conversion, in which output from AMR parsers is converted into our refined AMRs. The design scheme presented here, though task-specific, is extendable for broad coverage of <a href=https://en.wikipedia.org/wiki/Speech_act>speech acts</a> using <a href=https://en.wikipedia.org/wiki/Adaptive_Multi-Rate_audio_codec>AMR</a> in future task-independent work.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-4910.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-4910 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-4910 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-4910/>Towards a Computational Lexicon for Moroccan Darija : <a href=https://en.wikipedia.org/wiki/Word>Words</a>, <a href=https://en.wikipedia.org/wiki/Idiom>Idioms</a>, and Constructions<span class=acl-fixed-case>M</span>oroccan <span class=acl-fixed-case>D</span>arija: Words, Idioms, and Constructions</a></strong><br><a href=/people/j/jamal-laoudi/>Jamal Laoudi</a>
|
<a href=/people/c/claire-bonial/>Claire Bonial</a>
|
<a href=/people/l/lucia-donatelli/>Lucia Donatelli</a>
|
<a href=/people/s/stephen-tratz/>Stephen Tratz</a>
|
<a href=/people/c/clare-voss/>Clare Voss</a><br><a href=/volumes/W18-49/ class=text-muted>Proceedings of the Joint Workshop on Linguistic Annotation, Multiword Expressions and Constructions (LAW-MWE-CxG-2018)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-4910><div class="card-body p-3 small">In this paper, we explore the challenges of building a computational lexicon for Moroccan Darija (MD), an <a href=https://en.wikipedia.org/wiki/Varieties_of_Arabic>Arabic dialect</a> spoken by over 32 million people worldwide but which only recently has begun appearing frequently in written form in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. We raise the question of what belongs in such a <a href=https://en.wikipedia.org/wiki/Lexicon>lexicon</a> and start by describing our work building traditional word-level lexicon entries with their English translations. We then discuss challenges in translating idiomatic MD text that led to creating multi-word expression lexicon entries whose meanings could not be fully derived from the individual words. Finally, we provide a preliminary exploration of <a href=https://en.wikipedia.org/wiki/Constructivism_(philosophy_of_education)>constructions</a> to be considered for inclusion in an MD constructicon by translating examples of English constructions and examining their MD counterparts.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Stephen+Tratz" title="Search for 'Stephen Tratz' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/c/claire-bonial/ class=align-middle>Claire Bonial</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/lucia-donatelli/ class=align-middle>Lucia Donatelli</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/c/clare-voss/ class=align-middle>Clare Voss</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/stephanie-lukin/ class=align-middle>Stephanie Lukin</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/ron-artstein/ class=align-middle>Ron Artstein</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/d/david-traum/ class=align-middle>David Traum</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jamal-laoudi/ class=align-middle>Jamal Laoudi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mitchell-abrams/ class=align-middle>Mitchell Abrams</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/matthew-marge/ class=align-middle>Matthew Marge</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>