<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Sebastian Padó - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Sebastian</span> <span class=font-weight-bold>Padó</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Sebastian <span class=font-weight-normal>Pado</span></p><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.findings-acl.186.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--findings-acl--186 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.findings-acl.186 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2022.findings-acl.186.software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2022.findings-acl.186/>Improving Neural Political Statement Classification with Class Hierarchical Information</a></strong><br><a href=/people/e/erenay-dayanik/>Erenay Dayanik</a>
|
<a href=/people/a/andre-blessing/>Andre Blessing</a>
|
<a href=/people/n/nico-blokker/>Nico Blokker</a>
|
<a href=/people/s/sebastian-haunss/>Sebastian Haunss</a>
|
<a href=/people/j/jonas-kuhn/>Jonas Kuhn</a>
|
<a href=/people/g/gabriella-lapesa/>Gabriella Lapesa</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Pado</a><br><a href=/volumes/2022.findings-acl/ class=text-muted>Findings of the Association for Computational Linguistics: ACL 2022</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--findings-acl--186><div class="card-body p-3 small">Many tasks in text based computational social science CSS involve \n the classification of political statements into categories based on a domain specific codebook In order to be useful for <a href=https://en.wikipedia.org/wiki/Cascading_Style_Sheets>CSS analysis</a> these categories must be fine grained The typically skewed distribution of fine grained categories however results in \n a challenging classification problem on the NLP side This paper proposes to make use of the hierarchical relations among categories typically present in such codebooks \n e.g. markets and taxation are both subcategories of economy while borders is a subcategory of security We use these ontological relations as prior knowledge to establish additional constraints on the learned model thus \n improving performance overall and in particular for infrequent categories We evaluate several lightweight variants of this intuition by extending state of the art transformer based text \n classifiers on two datasets and multiple languages We find the most consistent improvement for an <a href=https://en.wikipedia.org/wiki/Scientific_method>approach</a> based on regularization</div></div><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wassa-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wassa-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wassa-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wassa-1.5/>Emotion Ratings : How Intensity, Annotation Confidence and Agreements are Entangled</a></strong><br><a href=/people/e/enrica-troiano/>Enrica Troiano</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a>
|
<a href=/people/r/roman-klinger/>Roman Klinger</a><br><a href=/volumes/2021.wassa-1/ class=text-muted>Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wassa-1--5><div class="card-body p-3 small">When humans judge the affective content of texts, they also implicitly assess the correctness of such judgment, that is, their <a href=https://en.wikipedia.org/wiki/Confidence>confidence</a>. We hypothesize that people&#8217;s (in)confidence that they performed well in an annotation task leads to (dis)agreements among each other. If this is true, <a href=https://en.wikipedia.org/wiki/Confidence>confidence</a> may serve as a diagnostic tool for systematic differences in annotations. To probe our assumption, we conduct a study on a subset of the Corpus of Contemporary American English, in which we ask raters to distinguish neutral sentences from emotion-bearing ones, while scoring the confidence of their answers. Confidence turns out to approximate inter-annotator disagreements. Further, we find that <a href=https://en.wikipedia.org/wiki/Confidence>confidence</a> is correlated to emotion intensity : perceiving stronger affect in text prompts annotators to more certain <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performances. This insight is relevant for modelling studies of intensity, as it opens the question wether automatic regressors or <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> actually predict intensity, or rather human&#8217;s self-perceived confidence.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wassa-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wassa-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wassa-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wassa-1.6/>Disentangling Document Topic and Author Gender in Multiple Languages : Lessons for Adversarial Debiasing</a></strong><br><a href=/people/e/erenay-dayanik/>Erenay Dayanik</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a><br><a href=/volumes/2021.wassa-1/ class=text-muted>Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wassa-1--6><div class="card-body p-3 small">Text classification is a central tool in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. However, when the target classes are strongly correlated with other textual attributes, text classification models can pick up wrong <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>, leading to bad generalization and biases. In <a href=https://en.wikipedia.org/wiki/Social_media_analytics>social media analysis</a>, this problem surfaces for demographic user classes such as language, topic, or gender, which influence the generate text to a substantial extent. Adversarial training has been claimed to mitigate this problem, but thorough evaluation is missing. In this paper, we experiment with <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a> of the correlated attributes of document topic and author gender, using a novel multilingual parallel corpus of TED talk transcripts. Our findings are : (a) individual classifiers for topic and author gender are indeed biased ; (b) <a href=https://en.wikipedia.org/wiki/Debiasing>debiasing</a> with adversarial training works for topic, but breaks down for author gender ; (c) gender debiasing results differ across languages. We interpret the result in terms of feature space overlap, highlighting the role of linguistic surface realization of the target classes.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.spnlp-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--spnlp-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.spnlp-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.spnlp-1.6/>Using Hierarchical Class Structure to Improve Fine-Grained Claim Classification</a></strong><br><a href=/people/e/erenay-dayanik/>Erenay Dayanik</a>
|
<a href=/people/a/andre-blessing/>Andre Blessing</a>
|
<a href=/people/n/nico-blokker/>Nico Blokker</a>
|
<a href=/people/s/sebastian-haunss/>Sebastian Haunss</a>
|
<a href=/people/j/jonas-kuhn/>Jonas Kuhn</a>
|
<a href=/people/g/gabriella-lapesa/>Gabriella Lapesa</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a><br><a href=/volumes/2021.spnlp-1/ class=text-muted>Proceedings of the 5th Workshop on Structured Prediction for NLP (SPNLP 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--spnlp-1--6><div class="card-body p-3 small">The analysis of public debates crucially requires the classification of political demands according to hierarchical claim ontologies (e.g. for immigration, a supercategory Controlling Migration might have subcategories Asylum limit or Border installations). A major challenge for automatic claim classification is the large number and low frequency of such <a href=https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)>subclasses</a>. We address it by jointly predicting pairs of matching super- and subcategories. We operationalize this idea by (a) encoding <a href=https://en.wikipedia.org/wiki/Constraint_(mathematics)>soft constraints</a> in the claim classifier and (b) imposing <a href=https://en.wikipedia.org/wiki/Constraint_(mathematics)>hard constraints</a> via <a href=https://en.wikipedia.org/wiki/Integer_linear_programming>Integer Linear Programming</a>. Our experiments with different claim classifiers on a German immigration newspaper corpus show consistent performance increases for joint prediction, in particular for infrequent categories and discuss the complementarity of the two approaches.<i>claim ontologies</i> (e.g. for immigration, a supercategory &#8220;Controlling Migration&#8221; might have subcategories &#8220;Asylum limit&#8221; or &#8220;Border installations&#8221;). A major challenge for automatic claim classification is the large number and low frequency of such subclasses. We address it by jointly predicting pairs of matching super- and subcategories. We operationalize this idea by (a) encoding soft constraints in the claim classifier and (b) imposing hard constraints via Integer Linear Programming. Our experiments with different claim classifiers on a German immigration newspaper corpus show consistent performance increases for joint prediction, in particular for infrequent categories and discuss the complementarity of the two approaches.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpcss-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlpcss-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlpcss-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940616 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlpcss-1.3/>Swimming with the Tide? Positional Claim Detection across Political Text Types</a></strong><br><a href=/people/n/nico-blokker/>Nico Blokker</a>
|
<a href=/people/e/erenay-dayanik/>Erenay Dayanik</a>
|
<a href=/people/g/gabriella-lapesa/>Gabriella Lapesa</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a><br><a href=/volumes/2020.nlpcss-1/ class=text-muted>Proceedings of the Fourth Workshop on Natural Language Processing and Computational Social Science</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlpcss-1--3><div class="card-body p-3 small">Manifestos are official documents of political parties, providing a comprehensive topical overview of the electoral programs. Voters, however, seldom read them and often prefer other channels, such as <a href=https://en.wikipedia.org/wiki/Article_(publishing)>newspaper articles</a>, to understand the <a href=https://en.wikipedia.org/wiki/Party_platform>party positions</a> on various policy issues. The natural question to ask is how compatible these two formats (manifesto and newspaper reports) are in their representation of party positioning. We address this question with an approach that combines political science (manual annotation and analysis) and natural language processing (supervised claim identification) in a cross-text type setting : we train a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> on annotated newspaper data and test its performance on manifestos. Our findings show a) strong performance for supervised classification even across text types and b) a substantive overlap between the two formats in terms of party positioning, with differences regarding the salience of specific issues.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.384.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--384 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.384 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.384/>Lost in Back-Translation : Emotion Preservation in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a></a></strong><br><a href=/people/e/enrica-troiano/>Enrica Troiano</a>
|
<a href=/people/r/roman-klinger/>Roman Klinger</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--384><div class="card-body p-3 small">Machine translation provides powerful methods to convert text between languages, and is therefore a technology enabling a <a href=https://en.wikipedia.org/wiki/Multilingualism>multilingual world</a>. An important part of <a href=https://en.wikipedia.org/wiki/Communication>communication</a>, however, takes place at the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>non-propositional level</a> (e.g., <a href=https://en.wikipedia.org/wiki/Politeness>politeness</a>, <a href=https://en.wikipedia.org/wiki/Formality>formality</a>, emotions), and it is far from clear whether current MT methods properly translate this information. This paper investigates the specific hypothesis that the non-propositional level of emotions is at least partially lost in MT. We carry out a number of experiments in a back-translation setup and establish that (1) <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a> are indeed partially lost during translation ; (2) this tendency can be reversed almost completely with a simple re-ranking approach informed by an emotion classifier, taking advantage of diversity in the n-best list ; (3) the re-ranking approach can also be applied to change <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a>, obtaining a model for emotion style transfer. An in-depth qualitative analysis reveals that there are recurring linguistic changes through which <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a> are toned down or amplified, such as change of modality.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.104.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--104 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.104 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.104/>RiQuA : A Corpus of Rich Quotation Annotation for English Literary Text<span class=acl-fixed-case>R</span>i<span class=acl-fixed-case>Q</span>u<span class=acl-fixed-case>A</span>: A Corpus of Rich Quotation Annotation for <span class=acl-fixed-case>E</span>nglish Literary Text</a></strong><br><a href=/people/s/sean-papay/>Sean Papay</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--104><div class="card-body p-3 small">We introduce RiQuA (RIch QUotation Annotations), a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> that provides <a href=https://en.wikipedia.org/wiki/Quotation>quotations</a>, including their interpersonal structure (speakers and addressees) for English literary text. The <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> comprises 11 works of 19th-century literature that were manually doubly annotated for direct and indirect quotations. For each <a href=https://en.wikipedia.org/wiki/Quotation>quotation</a>, its span, speaker, addressee, and cue are identified (if present). This provides a rich view of dialogue structures not available from other available <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpora</a>. We detail the process of creating this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, discuss the annotation guidelines, and analyze the resulting <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> in terms of inter-annotator agreement and its properties. RiQuA, along with its annotations guidelines and associated scripts, are publicly available for use, modification, and experimentation.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-3000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-3000/>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations</a></strong><br><a href=/people/s/sebastian-pado/>Sebastian Padó</a>
|
<a href=/people/r/ruihong-huang/>Ruihong Huang</a><br><a href=/volumes/D19-3/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-0425.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-0425 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-0425 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-0425/>Frame Identification as Categorization : Exemplars vs Prototypes in Embeddingland</a></strong><br><a href=/people/j/jennifer-sikos/>Jennifer Sikos</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a><br><a href=/volumes/W19-04/ class=text-muted>Proceedings of the 13th International Conference on Computational Semantics - Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-0425><div class="card-body p-3 small">Categorization is a central capability of <a href=https://en.wikipedia.org/wiki/Cognition>human cognition</a>, and a number of <a href=https://en.wikipedia.org/wiki/Theory>theories</a> have been developed to account for properties of <a href=https://en.wikipedia.org/wiki/Categorization>categorization</a>. Even though many tasks in <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> also involve <a href=https://en.wikipedia.org/wiki/Categorization>categorization</a> of some kind, theories of <a href=https://en.wikipedia.org/wiki/Categorization>categorization</a> do not play a major role in contemporary research in <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational linguistics</a>. This paper follows the idea that embedding-based models of semantics lend themselves well to being formulated in terms of classical categorization theories. The benefit is a space of model families that enables (a) the formulation of hypotheses about the impact of major design decisions, and (b) a transparent assessment of these decisions. We instantiate this idea on the task of frame-semantic frame identification. We define four models that cross two <a href=https://en.wikipedia.org/wiki/Design_of_experiments>design variables</a> : (a) the choice of <a href=https://en.wikipedia.org/wiki/Design_of_experiments>prototype vs. exemplar categorization</a>, corresponding to different degrees of <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a> applied to the input ; and (b) the presence vs. absence of a <a href=https://en.wikipedia.org/wiki/Design_of_experiments>fine-tuning step</a>, corresponding to <a href=https://en.wikipedia.org/wiki/Design_of_experiments>generic vs. task-adaptive categorization</a>. We find that for frame identification, <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a> and task-adaptive categorization both yield substantial benefits. Our prototype-based, fine-tuned model, which combines the best choices for these variables, establishes a new state of the art in frame identification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3614 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3614 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3614/>Learning Trilingual Dictionaries for <span class=acl-fixed-case>U</span>rdu – <span class=acl-fixed-case>R</span>oman <span class=acl-fixed-case>U</span>rdu – <span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/m/moiz-rauf/>Moiz Rauf</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a><br><a href=/volumes/W19-36/ class=text-muted>Proceedings of the 2019 Workshop on Widening NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3614><div class="card-body p-3 small">In this paper, we present an effort to generate a joint Urdu, Roman Urdu and English trilingual lexicon using automated methods. We make a case for using statistical machine translation approaches and parallel corpora for dictionary creation. To this purpose, we use word alignment tools on the corpus and evaluate translations using human evaluators. Despite different writing script and considerable noise in the corpus our results show promise with over 85% accuracy of Roman Urdu&#8211;Urdu and 45% English&#8211;Urdu pairs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4816.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4816 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4816 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-4816" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-4816/>Modeling Paths for Explainable Knowledge Base Completion</a></strong><br><a href=/people/j/josua-stadelmaier/>Josua Stadelmaier</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a><br><a href=/volumes/W19-48/ class=text-muted>Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4816><div class="card-body p-3 small">A common approach in knowledge base completion (KBC) is to learn representations for entities and relations in order to infer missing facts by generalizing existing ones. A shortcoming of standard models is that they do not explain their predictions to make them verifiable easily to human inspection. In this paper, we propose the Context Path Model (CPM) which generates explanations for new facts in KBC by providing sets of context paths as supporting evidence for these triples. For example, a new triple (Theresa May, nationality, Britain) may be explained by the path (Theresa May, born in, Eastbourne, contained in, Britain). The CPM is formulated as a <a href=https://en.wikipedia.org/wiki/Wrapper_function>wrapper</a> that can be applied on top of various existing KBC models. We evaluate <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> for the well-established TransE model. We observe that its performance remains very close despite the added complexity, and that most of the paths proposed as explanations provide meaningful evidence to assess the correctness.<i>context paths</i> as supporting evidence for these triples. For example, a new triple (Theresa May, nationality, Britain) may be explained by the path (Theresa May, born in, Eastbourne, contained in, Britain). The CPM is formulated as a wrapper that can be applied on top of various existing KBC models. We evaluate it for the well-established TransE model. We observe that its performance remains very close despite the added complexity, and that most of the paths proposed as explanations provide meaningful evidence to assess the correctness.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1103.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1103 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1103 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1103/>Quotation Detection and Classification with a Corpus-Agnostic Model</a></strong><br><a href=/people/s/sean-papay/>Sean Papay</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a><br><a href=/volumes/R19-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1103><div class="card-body p-3 small">The detection of quotations (i.e., reported speech, <a href=https://en.wikipedia.org/wiki/Thought>thought</a>, and writing) has established itself as an <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP analysis task</a>. However, state-of-the-art models have been developed on the basis of specific corpora and incorpo- rate a high degree of corpus-specific assumptions and knowledge, which leads to fragmentation. In the spirit of task-agnostic modeling, we present a corpus-agnostic neural model for quotation detection and evaluate it on three <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a> that vary in language, text genre, and structural assumptions. The model (a) approaches the state-of-the-art on the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a> when using established feature sets and (b) shows reasonable performance even when us- ing solely word forms, which makes it applicable for non-standard (i.e., historical) corpora.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1391.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1391 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1391 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1391.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1391/>Crowdsourcing and Validating Event-focused Emotion Corpora for <a href=https://en.wikipedia.org/wiki/German_language>German</a> and English<span class=acl-fixed-case>G</span>erman and <span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/e/enrica-troiano/>Enrica Troiano</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a>
|
<a href=/people/r/roman-klinger/>Roman Klinger</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1391><div class="card-body p-3 small">Sentiment analysis has a range of corpora available across multiple languages. For emotion analysis, the situation is more limited, which hinders potential research on crosslingual modeling and the development of <a href=https://en.wikipedia.org/wiki/Predictive_modelling>predictive models</a> for other languages. In this paper, we fill this gap for <a href=https://en.wikipedia.org/wiki/German_language>German</a> by constructing deISEAR, a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> designed in analogy to the well-established English ISEAR emotion dataset. Motivated by Scherer&#8217;s appraisal theory, we implement a crowdsourcing experiment which consists of two steps. In step 1, participants create descriptions of <a href=https://en.wikipedia.org/wiki/Emotion>emotional events</a> for a given emotion. In step 2, five annotators assess the emotion expressed by the texts. We show that transferring an emotion classification model from the original English ISEAR to the German crowdsourced deISEAR via <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> does not, on average, cause a performance drop.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-2008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-2008 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-2008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-2008/>DERE : A Task and Domain-Independent Slot Filling Framework for Declarative Relation Extraction<span class=acl-fixed-case>DERE</span>: A Task and Domain-Independent Slot Filling Framework for Declarative Relation Extraction</a></strong><br><a href=/people/h/heike-adel/>Heike Adel</a>
|
<a href=/people/l/laura-ana-maria-oberlander/>Laura Ana Maria Bostan</a>
|
<a href=/people/s/sean-papay/>Sean Papay</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a>
|
<a href=/people/r/roman-klinger/>Roman Klinger</a><br><a href=/volumes/D18-2/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-2008><div class="card-body p-3 small">Most <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning systems</a> for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> are tailored to specific tasks. As a result, comparability of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> across tasks is missing and their applicability to new tasks is limited. This affects end users without machine learning experience as well as model developers. To address these limitations, we present DERE, a novel <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> for declarative specification and compilation of template-based information extraction. It uses a generic <a href=https://en.wikipedia.org/wiki/Specification_language>specification language</a> for the task and for data annotations in terms of spans and <a href=https://en.wikipedia.org/wiki/Frame_(artificial_intelligence)>frames</a>. This formalism enables the representation of a large variety of natural language processing challenges. The <a href=https://en.wikipedia.org/wiki/Front_and_back_ends>backend</a> can be instantiated by different <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a>, following different paradigms. The clear separation of frame specification and <a href=https://en.wikipedia.org/wiki/Modeling_language>model backend</a> will ease the implementation of new <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> and the evaluation of different <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> across different tasks. Furthermore, it simplifies <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>, joint learning across tasks and/or domains as well as the assessment of model generalizability. DERE is available as open-source software.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-1204.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-1204 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-1204 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-1204/>Addressing Low-Resource Scenarios with Character-aware Embeddings</a></strong><br><a href=/people/s/sean-papay/>Sean Papay</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a><br><a href=/volumes/W18-12/ class=text-muted>Proceedings of the Second Workshop on Subword/Character LEvel Models</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-1204><div class="card-body p-3 small">Most modern approaches to computing word embeddings assume the availability of <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpora</a> with billions of words. In this paper, we explore a setup where only <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a> with millions of words are available, and many words in any new text are out of vocabulary. This setup is both of practical interests modeling the situation for specific domains and low-resource languages and of psycholinguistic interest, since it corresponds much more closely to the actual experiences and challenges of human language learning and use. We compare standard skip-gram word embeddings with character-based embeddings on word relatedness prediction. Skip-grams excel on large corpora, while character-based embeddings do well on small corpora generally and rare and complex words specifically. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> can be combined easily.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3813.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3813 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3813 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3813/>Using <a href=https://en.wikipedia.org/wiki/Embedding>Embeddings</a> to Compare FrameNet Frames Across Languages<span class=acl-fixed-case>F</span>rame<span class=acl-fixed-case>N</span>et Frames Across Languages</a></strong><br><a href=/people/j/jennifer-sikos/>Jennifer Sikos</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a><br><a href=/volumes/W18-38/ class=text-muted>Proceedings of the First Workshop on Linguistic Resources for Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3813><div class="card-body p-3 small">Much interest in <a href=https://en.wikipedia.org/wiki/Frame_semantics_(linguistics)>Frame Semantics</a> is fueled by the substantial extent of its applicability across languages. At the same time, lexicographic studies have found that the applicability of individual frames can be diminished by cross-lingual divergences regarding <a href=https://en.wikipedia.org/wiki/Polysemy>polysemy</a>, <a href=https://en.wikipedia.org/wiki/Valency_(linguistics)>syntactic valency</a>, and <a href=https://en.wikipedia.org/wiki/Lexicalization>lexicalization</a>. Due to the large effort involved in manual investigations, there are so far no broad-coverage resources with problematic frames for any language pair. Our study investigates to what extent multilingual vector representations of frames learned from manually annotated corpora can address this need by serving as a wide coverage source for such divergences. We present a case study for the language pair English German using the FrameNet and SALSA corpora and find that inferences can be made about cross-lingual frame applicability using a vector space model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-2020.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-2020 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-2020 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-2020.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-2020/>A Named Entity Recognition Shootout for German<span class=acl-fixed-case>G</span>erman</a></strong><br><a href=/people/m/martin-riedl/>Martin Riedl</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a><br><a href=/volumes/P18-2/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-2020><div class="card-body p-3 small">We ask how to practically build a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> for German named entity recognition (NER) that performs at the state of the art for both <a href=https://en.wikipedia.org/wiki/Contemporary_history>contemporary and historical texts</a>, i.e., a big-data and a small-data scenario. The two best-performing model families are pitted against each other (linear-chain CRFs and BiLSTM) to observe the trade-off between expressiveness and data requirements. BiLSTM outperforms the <a href=https://en.wikipedia.org/wiki/Correlation_and_dependence>CRF</a> when large datasets are available and performs inferior for the smallest dataset. BiLSTMs profit substantially from <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>, which enables them to be trained on multiple corpora, resulting in a new state-of-the-art model for German NER on two contemporary German corpora (CoNLL 2003 and GermEval 2014) and two historic corpora.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2203.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2203 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2203 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2203/>Investigating the Relationship between <a href=https://en.wikipedia.org/wiki/Literary_genre>Literary Genres</a> and Emotional Plot Development</a></strong><br><a href=/people/e/evgeny-kim/>Evgeny Kim</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a>
|
<a href=/people/r/roman-klinger/>Roman Klinger</a><br><a href=/volumes/W17-22/ class=text-muted>Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2203><div class="card-body p-3 small">Literary genres are commonly viewed as being defined in terms of content and <a href=https://en.wikipedia.org/wiki/Style_(visual_arts)>stylistic features</a>. In this paper, we focus on one particular class of <a href=https://en.wikipedia.org/wiki/Lexicon>lexical features</a>, namely <a href=https://en.wikipedia.org/wiki/Emotion>emotion information</a>, and investigate the hypothesis that <a href=https://en.wikipedia.org/wiki/Emotion>emotion-related information</a> correlates with particular <a href=https://en.wikipedia.org/wiki/Genre>genres</a>. Using genre classification as a testbed, we compare a model that computes lexicon-based emotion scores globally for complete stories with a model that tracks emotion arcs through stories on a subset of Project Gutenberg with five genres. Our main findings are : (a), the global emotion model is competitive with a large-vocabulary bag-of-words genre classifier (80%F1) ; (b), the emotion arc model shows a lower performance (59 % F1) but shows complementary behavior to the global model, as indicated by a very good performance of an oracle model (94 % F1) and an improved performance of an ensemble model (84 % F1) ; (c), genres differ in the extent to which stories follow the same emotional arcs, with particularly uniform behavior for anger (mystery) and fear (adventures, romance, humor, science fiction).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5203.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5203 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5203 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-5203.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W17-5203/>Annotation, Modelling and Analysis of Fine-Grained Emotions on a Stance and Sentiment Detection Corpus</a></strong><br><a href=/people/h/hendrik-schuff/>Hendrik Schuff</a>
|
<a href=/people/j/jeremy-barnes/>Jeremy Barnes</a>
|
<a href=/people/j/julian-mohme/>Julian Mohme</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a>
|
<a href=/people/r/roman-klinger/>Roman Klinger</a><br><a href=/volumes/W17-52/ class=text-muted>Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5203><div class="card-body p-3 small">There is a rich variety of data sets for sentiment analysis (viz., polarity and subjectivity classification). For the more challenging task of detecting discrete emotions following the definitions of Ekman and Plutchik, however, there are much fewer data sets, and notably no resources for the social media domain. This paper contributes to closing this gap by extending the SemEval 2016 stance and sentiment datasetwith emotion annotation. We (a) analyse annotation reliability and annotation merging ; (b) investigate the relation between emotion annotation and the other annotation layers (stance, sentiment) ; (c) report modelling results as a baseline for future work.<i>SemEval 2016 stance and sentiment dataset</i>\n\nwith emotion annotation. We (a) analyse annotation reliability and annotation merging; (b) investigate the relation between emotion annotation and the other annotation layers (stance, sentiment); (c) report modelling results as a baseline for future work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-1014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-1014 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-1014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/S17-1014.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/S17-1014/>Does Free Word Order Hurt? Assessing the Practical Lexical Function Model for Croatian<span class=acl-fixed-case>C</span>roatian</a></strong><br><a href=/people/z/zoran-medic/>Zoran Medić</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a><br><a href=/volumes/S17-1/ class=text-muted>Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-1014><div class="card-body p-3 small">The Practical Lexical Function (PLF) model is a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> of computational distributional semantics that attempts to strike a balance between expressivity and learnability in predicting phrase meaning and shows competitive results. We investigate how well the PLF carries over to free word order languages, given that it builds on observations of predicate-argument combinations that are harder to recover in free word order languages. We evaluate variants of the PLF for <a href=https://en.wikipedia.org/wiki/Croatian_language>Croatian</a>, using a new lexical substitution dataset. We find that the PLF works about as well for <a href=https://en.wikipedia.org/wiki/Croatian_language>Croatian</a> as for <a href=https://en.wikipedia.org/wiki/English_language>English</a>, but demonstrate that its strength lies in modeling verbs, and that the free word order affects the less robust PLF variant.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-2013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-2013 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-2013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-2013/>Instances and concepts in distributional space</a></strong><br><a href=/people/g/gemma-boleda/>Gemma Boleda</a>
|
<a href=/people/a/abhijeet-gupta/>Abhijeet Gupta</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a><br><a href=/volumes/E17-2/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-2013><div class="card-body p-3 small">Instances (Mozart) are ontologically distinct from concepts or classes (composer). Natural language encompasses both, but instances have received comparatively little attention in <a href=https://en.wikipedia.org/wiki/Distributional_semantics>distributional semantics</a>. Our results show that instances and concepts differ in their <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distributional properties</a>. We also establish that <a href=https://en.wikipedia.org/wiki/Instance_(computer_science)>instantiation detection (Mozart composer)</a> is generally easier than hypernymy detection (chemist scientist), and that results on the influence of input representation do not transfer from <a href=https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy>hyponymy</a> to <a href=https://en.wikipedia.org/wiki/Instance_(computer_science)>instantiation</a>.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Sebastian+Pad%C3%B3" title="Search for 'Sebastian Padó' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/r/roman-klinger/ class=align-middle>Roman Klinger</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/s/sean-papay/ class=align-middle>Sean Papay</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/e/erenay-dayanik/ class=align-middle>Erenay Dayanık</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/n/nico-blokker/ class=align-middle>Nico Blokker</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/g/gabriella-lapesa/ class=align-middle>Gabriella Lapesa</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/e/enrica-troiano/ class=align-middle>Enrica Troiano</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/andre-blessing/ class=align-middle>André Blessing</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sebastian-haunss/ class=align-middle>Sebastian Haunss</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jonas-kuhn/ class=align-middle>Jonas Kuhn</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jennifer-sikos/ class=align-middle>Jennifer Sikos</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/evgeny-kim/ class=align-middle>Evgeny Kim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hendrik-schuff/ class=align-middle>Hendrik Schuff</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jeremy-barnes/ class=align-middle>Jeremy Barnes</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/julian-mohme/ class=align-middle>Julian Mohme</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/heike-adel/ class=align-middle>Heike Adel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/laura-ana-maria-oberlander/ class=align-middle>Laura Ana Maria Oberländer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ruihong-huang/ class=align-middle>Ruihong Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zoran-medic/ class=align-middle>Zoran Medić</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jan-snajder/ class=align-middle>Jan Šnajder</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/ngoc-thang-vu/ class=align-middle>Ngoc Thang Vu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/moiz-rauf/ class=align-middle>Moiz Rauf</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/josua-stadelmaier/ class=align-middle>Josua Stadelmaier</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gemma-boleda/ class=align-middle>Gemma Boleda</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/abhijeet-gupta/ class=align-middle>Abhijeet Gupta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/martin-riedl/ class=align-middle>Martin Riedl</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/wassa/ class=align-middle>WASSA</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/nlpcss/ class=align-middle>NLP+CSS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/spnlp/ class=align-middle>spnlp</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ranlp/ class=align-middle>RANLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>