<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Sameer Singh - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Sameer</span> <span class=font-weight-bold>Singh</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.364.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--364 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.364 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.364" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.364/>Benchmarking Scalable Methods for Streaming Cross Document Entity Coreference</a></strong><br><a href=/people/r/robert-l-logan-iv/>Robert L Logan IV</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a>
|
<a href=/people/d/dan-bikel/>Dan Bikel</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--364><div class="card-body p-3 small">Streaming cross document entity coreference (CDC) systems disambiguate mentions of named entities in a scalable manner via incremental clustering. Unlike other approaches for named entity disambiguation (e.g., entity linking), streaming CDC allows for the disambiguation of entities that are unknown at inference time. Thus, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> is well-suited for processing <a href=https://en.wikipedia.org/wiki/Stream_(computing)>streams of data</a> where new entities are frequently introduced. Despite these benefits, this task is currently difficult to study, as existing approaches are either evaluated on datasets that are no longer available, or omit other crucial details needed to ensure fair comparison. In this work, we address this issue by compiling a large benchmark adapted from existing free datasets, and performing a comprehensive evaluation of a number of novel and existing baseline models. We investigate : how to best encode <a href=https://en.wikipedia.org/wiki/Note_(typography)>mentions</a>, which clustering algorithms are most effective for grouping mentions, how models transfer to different domains, and how bounding the number of mentions tracked during <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference</a> impacts performance. Our results show that the relative performance of neural and feature-based mention encoders varies across different domains, and in most cases the best performance is achieved using a combination of both approaches. We also find that performance is minimally impacted by limiting the number of tracked mentions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.466.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--466 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.466 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.466/>Paired Examples as Indirect Supervision in Latent Decision Models</a></strong><br><a href=/people/n/nitish-gupta/>Nitish Gupta</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a>
|
<a href=/people/m/matt-gardner/>Matt Gardner</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--466><div class="card-body p-3 small">Compositional, structured models are appealing because they explicitly decompose problems and provide interpretable intermediate outputs that give confidence that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is not simply latching onto data artifacts. Learning these models is challenging, however, because end-task supervision only provides a weak indirect signal on what values the latent decisions should take. This often results in the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> failing to learn to perform the intermediate tasks correctly. In this work, we introduce a way to leverage paired examples that provide stronger cues for learning latent decisions. When two related training examples share internal substructure, we add an additional training objective to encourage consistency between their latent decisions. Such an objective does not require external supervision for the values of the latent output, or even the end task, yet provides an additional training signal to that provided by individual training examples themselves. We apply our method to improve compositional question answering using neural module networks on the DROP dataset. We explore three ways to acquire paired questions in DROP : (a) discovering naturally occurring paired examples within the dataset, (b) constructing paired examples using templates, and (c) generating paired examples using a question generation model. We empirically demonstrate that our proposed approach improves both in- and out-of-distribution generalization and leads to correct latent decision predictions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.561.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--561 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.561 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.561/>Generative Context Pair Selection for Multi-hop Question Answering</a></strong><br><a href=/people/d/dheeru-dua/>Dheeru Dua</a>
|
<a href=/people/c/cicero-dos-santos/>Cicero Nogueira dos Santos</a>
|
<a href=/people/p/patrick-ng/>Patrick Ng</a>
|
<a href=/people/b/ben-athiwaratkun/>Ben Athiwaratkun</a>
|
<a href=/people/b/bing-xiang/>Bing Xiang</a>
|
<a href=/people/m/matt-gardner/>Matt Gardner</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--561><div class="card-body p-3 small">Compositional reasoning tasks such as multi-hop question answering require <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> to learn how to make latent decisions using only weak supervision from the final answer. Crowdsourced datasets gathered for these tasks, however, often contain only a slice of the underlying task distribution, which can induce unanticipated biases such as shallow word overlap between the question and context. Recent works have shown that discriminative training results in models that exploit these underlying biases to achieve a better held-out performance, without learning the right way to reason. We propose a generative context selection model for multi-hop QA that reasons about how the given question could have been generated given a context pair and not just independent contexts. We show that on HotpotQA, while being comparable to the state-of-the-art answering performance, our proposed generative passage selection model has a better performance (4.9 % higher than baseline) on adversarial held-out set which tests robustness of <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s multi-hop reasoning capabilities.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-tutorials.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-tutorials--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-tutorials.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-tutorials.5/>Robustness and Adversarial Examples in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a></a></strong><br><a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/h/he-he/>He He</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a><br><a href=/volumes/2021.emnlp-tutorials/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-tutorials--5><div class="card-body p-3 small">Recent studies show that many NLP systems are sensitive and vulnerable to a small perturbation of inputs and do not generalize well across different datasets. This lack of <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> derails the use of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP systems</a> in real-world applications. This tutorial aims at bringing awareness of practical concerns about NLP robustness. It targets NLP researchers and practitioners who are interested in building reliable NLP systems. In particular, we will review recent studies on analyzing the weakness of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP systems</a> when facing adversarial inputs and data with a <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distribution shift</a>. We will provide the audience with a holistic view of 1) how to use adversarial examples to examine the weakness of NLP models and facilitate <a href=https://en.wikipedia.org/wiki/Debugging>debugging</a> ; 2) how to enhance the <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> of existing NLP models and defense against adversarial inputs ; and 3) how the consideration of <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> affects the real-world NLP applications used in our daily lives. We will conclude the tutorial by outlining future research directions in this area.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.13/>Concealed Data Poisoning Attacks on <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP Models</a><span class=acl-fixed-case>NLP</span> Models</a></strong><br><a href=/people/e/eric-wallace/>Eric Wallace</a>
|
<a href=/people/t/tony-zhao/>Tony Zhao</a>
|
<a href=/people/s/shi-feng/>Shi Feng</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--13><div class="card-body p-3 small">Adversarial attacks alter NLP model predictions by perturbing test-time inputs. However, it is much less understood whether, and how, predictions can be manipulated with small, concealed changes to the training data. In this work, we develop a new data poisoning attack that allows an adversary to control model predictions whenever a desired trigger phrase is present in the input. For instance, we insert 50 poison examples into a sentiment model&#8217;s training set that causes the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> to frequently predict Positive whenever the input contains James Bond. Crucially, we craft these poison examples using a gradient-based procedure so that they do not mention the trigger phrase. We also apply our poison attack to <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a> (Apple iPhone triggers negative generations) and <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> (iced coffee mistranslated as hot coffee). We conclude by proposing three defenses that can mitigate our <a href=https://en.wikipedia.org/wiki/Cyberattack>attack</a> at some cost in prediction accuracy or extra human annotation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.75.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--75 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.75 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.75" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.75/>An Empirical Comparison of Instance Attribution Methods for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a><span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/p/pouya-pezeshkpour/>Pouya Pezeshkpour</a>
|
<a href=/people/s/sarthak-jain/>Sarthak Jain</a>
|
<a href=/people/b/byron-c-wallace/>Byron Wallace</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--75><div class="card-body p-3 small">Widespread adoption of <a href=https://en.wikipedia.org/wiki/Deep_learning>deep models</a> has motivated a pressing need for approaches to interpret network outputs and to facilitate model debugging. Instance attribution methods constitute one means of accomplishing these goals by retrieving training instances that (may have) led to a particular prediction. Influence functions (IF ; Koh and Liang 2017) provide machinery for doing this by quantifying the effect that perturbing individual train instances would have on a specific test prediction. However, even approximating the <a href=https://en.wikipedia.org/wiki/Conditional_(computer_programming)>IF</a> is computationally expensive, to the degree that may be prohibitive in many cases. Might simpler approaches (e.g., retrieving train examples most similar to a given test point) perform comparably? In this work, we evaluate the degree to which different potential instance attribution agree with respect to the importance of training samples. We find that simple retrieval methods yield training instances that differ from those identified via gradient-based methods (such as IFs), but that nonetheless exhibit desirable characteristics similar to more complex attribution methods. Code for all methods and experiments in this paper is available at : https://github.com/successar/instance_attributions_NLP.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.blackboxnlp-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--blackboxnlp-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.blackboxnlp-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.blackboxnlp-1.6/>What Models Know About Their Attackers : Deriving Attacker Information From Latent Representations</a></strong><br><a href=/people/z/zhouhang-xie/>Zhouhang Xie</a>
|
<a href=/people/j/jonathan-brophy/>Jonathan Brophy</a>
|
<a href=/people/a/adam-noack/>Adam Noack</a>
|
<a href=/people/w/wencong-you/>Wencong You</a>
|
<a href=/people/k/kalyani-asthana/>Kalyani Asthana</a>
|
<a href=/people/c/carter-perkins/>Carter Perkins</a>
|
<a href=/people/s/sabrina-reis/>Sabrina Reis</a>
|
<a href=/people/z/zayd-hammoudeh/>Zayd Hammoudeh</a>
|
<a href=/people/d/daniel-lowd/>Daniel Lowd</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a><br><a href=/volumes/2021.blackboxnlp-1/ class=text-muted>Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--blackboxnlp-1--6><div class="card-body p-3 small">Adversarial attacks curated against NLP models are increasingly becoming practical threats. Although various methods have been developed to detect adversarial attacks, securing learning-based NLP systems in practice would require more than identifying and evading perturbed instances. To address these issues, we propose a new set of adversary identification tasks, Attacker Attribute Classification via Textual Analysis (AACTA), that attempts to obtain more detailed information about the attackers from adversarial texts. Specifically, given a piece of adversarial text, we hope to accomplish tasks such as localizing perturbed tokens, identifying the attacker&#8217;s access level to the target model, determining the evasion mechanism imposed, and specifying the perturbation type employed by the attacking algorithm. Our contributions are as follows : we formalize the task of classifying attacker attributes, and create a benchmark on various target models from sentiment classification and abuse detection domains. We show that signals from BERT models and target models can be used to train <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> that reveal the properties of the attacking algorithms. We demonstrate that adversarial attacks leave interpretable traces in both feature spaces of pre-trained language models and target models, making AACTA a promising direction towards more trustworthy NLP systems.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.346.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--346 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.346 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939188 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.346" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.346/>AutoPrompt : Eliciting Knowledge from Language Models with Automatically Generated Prompts<span class=acl-fixed-case>A</span>uto<span class=acl-fixed-case>P</span>rompt: <span class=acl-fixed-case>E</span>liciting <span class=acl-fixed-case>K</span>nowledge from <span class=acl-fixed-case>L</span>anguage <span class=acl-fixed-case>M</span>odels with <span class=acl-fixed-case>A</span>utomatically <span class=acl-fixed-case>G</span>enerated <span class=acl-fixed-case>P</span>rompts</a></strong><br><a href=/people/t/taylor-shin/>Taylor Shin</a>
|
<a href=/people/y/yasaman-razeghi/>Yasaman Razeghi</a>
|
<a href=/people/r/robert-l-logan-iv/>Robert L. Logan IV</a>
|
<a href=/people/e/eric-wallace/>Eric Wallace</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--346><div class="card-body p-3 small">The remarkable success of pretrained language models has motivated the study of what kinds of knowledge these <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> learn during pretraining. Reformulating tasks as fill-in-the-blanks problems (e.g., cloze tests) is a natural approach for gauging such <a href=https://en.wikipedia.org/wiki/Knowledge>knowledge</a>, however, its usage is limited by the manual effort and guesswork required to write suitable prompts. To address this, we develop AutoPrompt, an automated method to create prompts for a diverse set of tasks, based on a gradient-guided search. Using AutoPrompt, we show that masked language models (MLMs) have an inherent capability to perform <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> and natural language inference without additional parameters or <a href=https://en.wikipedia.org/wiki/Finetuning>finetuning</a>, sometimes achieving performance on par with recent state-of-the-art supervised models. We also show that our prompts elicit more accurate factual knowledge from MLMs than the manually created prompts on the LAMA benchmark, and that MLMs can be used as relation extractors more effectively than supervised relation extraction models. These results demonstrate that automatically generated prompts are a viable parameter-free alternative to existing probing methods, and as pretrained LMs become more sophisticated and capable, potentially a replacement for <a href=https://en.wikipedia.org/wiki/Finetuning>finetuning</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.528.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--528 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.528 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939212 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.528" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.528/>MOCHA : A Dataset for Training and Evaluating Generative Reading Comprehension Metrics<span class=acl-fixed-case>MOCHA</span>: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics</a></strong><br><a href=/people/a/anthony-chen/>Anthony Chen</a>
|
<a href=/people/g/gabriel-stanovsky/>Gabriel Stanovsky</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a>
|
<a href=/people/m/matt-gardner/>Matt Gardner</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--528><div class="card-body p-3 small">Posing <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> as a generation problem provides a great deal of flexibility, allowing for open-ended questions with few restrictions on possible answers. However, progress is impeded by existing generation metrics, which rely on token overlap and are agnostic to the nuances of <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>. To address this, we introduce a <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmark</a> for training and evaluating generative reading comprehension metrics : MOdeling Correctness with Human Annotations. MOCHA contains 40 K human judgement scores on model outputs from 6 diverse question answering datasets and an additional set of minimal pairs for evaluation. Using MOCHA, we train a Learned Evaluation metric for Reading Comprehension, LERC, to mimic human judgement scores. LERC outperforms baseline metrics by 10 to 36 absolute Pearson points on held-out annotations. When we evaluate robustness on minimal pairs, LERC achieves 80 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, outperforming baselines by 14 to 26 absolute percentage points while leaving significant room for improvement. MOCHA presents a challenging problem for developing accurate and robust generative reading comprehension metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.442.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--442 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.442 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><span class="align-middle mr-1" data-toggle=tooltip data-placement=bottom title="Best Overall Paper"><i class="fas fa-award"></i></span><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929272 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.442" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.442/>Beyond Accuracy : Behavioral Testing of NLP Models with CheckList<span class=acl-fixed-case>NLP</span> Models with <span class=acl-fixed-case>C</span>heck<span class=acl-fixed-case>L</span>ist</a></strong><br><a href=/people/m/marco-tulio-ribeiro/>Marco Tulio Ribeiro</a>
|
<a href=/people/t/tongshuang-wu/>Tongshuang Wu</a>
|
<a href=/people/c/carlos-guestrin/>Carlos Guestrin</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--442><div class="card-body p-3 small">Although measuring held-out accuracy has been the primary approach to evaluate <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a>, it often overestimates the performance of NLP models, while alternative approaches for evaluating <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in <a href=https://en.wikipedia.org/wiki/Software_engineering>software engineering</a>, we introduce <a href=https://en.wikipedia.org/wiki/CheckList>CheckList</a>, a task-agnostic methodology for testing NLP models. CheckList includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of <a href=https://en.wikipedia.org/wiki/CheckList>CheckList</a> with <a href=https://en.wikipedia.org/wiki/Software_testing>tests</a> for three <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>, identifying <a href=https://en.wikipedia.org/wiki/Critical_failure>critical failures</a> in both commercial and state-of-art models. In a <a href=https://en.wikipedia.org/wiki/User_study>user study</a>, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>. In another user study, NLP practitioners with <a href=https://en.wikipedia.org/wiki/CheckList>CheckList</a> created twice as many tests, and found almost three times as many bugs as users without it.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.24.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--24 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.24 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.findings-emnlp.24.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.24/>Gradient-based Analysis of NLP Models is Manipulable<span class=acl-fixed-case>NLP</span> Models is Manipulable</a></strong><br><a href=/people/j/junlin-wang/>Junlin Wang</a>
|
<a href=/people/j/jens-tuyls/>Jens Tuyls</a>
|
<a href=/people/e/eric-wallace/>Eric Wallace</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--24><div class="card-body p-3 small">Gradient-based analysis methods, such as saliency map visualizations and adversarial input perturbations, have found widespread use in interpreting neural NLP models due to their simplicity, flexibility, and most importantly, the fact that they directly reflect the model internals. In this paper, however, we demonstrate that the <a href=https://en.wikipedia.org/wiki/Gradient>gradients</a> of a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> are easily manipulable, and thus bring into question the reliability of gradient-based analyses. In particular, we merge the layers of a target <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> with a Facade Model that overwhelms the <a href=https://en.wikipedia.org/wiki/Gradient>gradients</a> without affecting the predictions. This Facade Model can be trained to have <a href=https://en.wikipedia.org/wiki/Gradient>gradients</a> that are misleading and irrelevant to the task, such as focusing only on the <a href=https://en.wikipedia.org/wiki/Stop_words>stop words</a> in the input. On a variety of NLP tasks (sentiment analysis, NLI, and QA), we show that the merged model effectively fools different analysis tools : saliency maps differ significantly from the original model&#8217;s, input reduction keeps more irrelevant input tokens, and adversarial perturbations identify unimportant tokens as being highly important.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.191.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--191 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.191 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.findings-emnlp.191.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940723 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.findings-emnlp.191" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.191/>MedICaT : A Dataset of Medical Images, Captions, and Textual References<span class=acl-fixed-case>M</span>ed<span class=acl-fixed-case>IC</span>a<span class=acl-fixed-case>T</span>: A Dataset of Medical Images, Captions, and Textual References</a></strong><br><a href=/people/s/sanjay-subramanian/>Sanjay Subramanian</a>
|
<a href=/people/l/lucy-lu-wang/>Lucy Lu Wang</a>
|
<a href=/people/b/ben-bogin/>Ben Bogin</a>
|
<a href=/people/s/sachin-mehta/>Sachin Mehta</a>
|
<a href=/people/m/madeleine-van-zuylen/>Madeleine van Zuylen</a>
|
<a href=/people/s/sravanthi-parasa/>Sravanthi Parasa</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a>
|
<a href=/people/m/matt-gardner/>Matt Gardner</a>
|
<a href=/people/h/hannaneh-hajishirzi/>Hannaneh Hajishirzi</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--191><div class="card-body p-3 small">Understanding the relationship between figures and text is key to <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific document understanding</a>. Medical figures in particular are quite complex, often consisting of several subfigures (75 % of figures in our dataset), with detailed text describing their content. Previous work studying figures in <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific papers</a> focused on classifying figure content rather than understanding how images relate to the text. To address challenges in figure retrieval and figure-to-text alignment, we introduce MedICaT, a dataset of <a href=https://en.wikipedia.org/wiki/Medical_imaging>medical images</a> in context. MedICaT consists of 217 K images from 131 K open access biomedical papers, and includes captions, inline references for 74 % of figures, and manually annotated subfigures and subcaptions for a subset of figures. Using MedICaT, we introduce the task of subfigure to subcaption alignment in compound figures and demonstrate the utility of inline references in image-text matching. Our data and code can be accessed at https://github.com/allenai/medicat.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1005 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1005.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1005" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1005/>Knowledge Enhanced Contextual Word Representations</a></strong><br><a href=/people/m/matthew-e-peters/>Matthew E. Peters</a>
|
<a href=/people/m/mark-neumann/>Mark Neumann</a>
|
<a href=/people/r/robert-logan/>Robert Logan</a>
|
<a href=/people/r/roy-schwartz/>Roy Schwartz</a>
|
<a href=/people/v/vidur-joshi/>Vidur Joshi</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1005><div class="card-body p-3 small">Contextual word representations, typically trained on unstructured, unlabeled text, do not contain any explicit grounding to real world entities and are often unable to remember facts about those entities. We propose a general method to embed multiple knowledge bases (KBs) into large scale models, and thereby enhance their representations with structured, human-curated knowledge. For each KB, we first use an integrated entity linker to retrieve relevant entity embeddings, then update contextual word representations via a form of word-to-entity attention. In contrast to previous approaches, the <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity linkers</a> and self-supervised language modeling objective are jointly trained end-to-end in a multitask setting that combines a small amount of entity linking supervision with a large amount of raw text. After integrating <a href=https://en.wikipedia.org/wiki/WordNet>WordNet</a> and a subset of <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a> into BERT, the knowledge enhanced BERT (KnowBert) demonstrates improved perplexity, ability to recall facts as measured in a probing task and downstream performance on relationship extraction, entity typing, and <a href=https://en.wikipedia.org/wiki/Word-sense_disambiguation>word sense disambiguation</a>. KnowBert&#8217;s runtime is comparable to BERT&#8217;s and <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> scales to large KBs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1534.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1534 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1534 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1534.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-1534/>Do NLP Models Know Numbers? Probing Numeracy in Embeddings<span class=acl-fixed-case>NLP</span> Models Know Numbers? Probing Numeracy in Embeddings</a></strong><br><a href=/people/e/eric-wallace/>Eric Wallace</a>
|
<a href=/people/y/yizhong-wang/>Yizhong Wang</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a>
|
<a href=/people/m/matt-gardner/>Matt Gardner</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1534><div class="card-body p-3 small">The ability to understand and work with numbers (numeracy) is critical for many complex reasoning tasks. Currently, most NLP models treat numbers in text in the same way as other tokensthey embed them as distributed vectors. Is this enough to capture <a href=https://en.wikipedia.org/wiki/Numeracy>numeracy</a>? We begin by investigating the numerical reasoning capabilities of a state-of-the-art <a href=https://en.wikipedia.org/wiki/Question_answering>question answering model</a> on the DROP dataset. We find this <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> excels on questions that require <a href=https://en.wikipedia.org/wiki/Numerical_analysis>numerical reasoning</a>, i.e., <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> already captures <a href=https://en.wikipedia.org/wiki/Numeracy>numeracy</a>. To understand how this capability emerges, we probe token embedding methods (e.g., BERT, GloVe) on synthetic list maximum, number decoding, and addition tasks. A surprising degree of <a href=https://en.wikipedia.org/wiki/Numeracy>numeracy</a> is naturally present in standard <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a>. For example, GloVe and <a href=https://en.wikipedia.org/wiki/Word2vec>word2vec</a> accurately encode <a href=https://en.wikipedia.org/wiki/Magnitude_(mathematics)>magnitude</a> for numbers up to 1,000. Furthermore, character-level embeddings are even more preciseELMo captures <a href=https://en.wikipedia.org/wiki/Numeracy>numeracy</a> the best for all pre-trained methodsbut BERT, which uses sub-word units, is less exact.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1246.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1246 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1246 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N19-1246.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1246" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N19-1246/>DROP : A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs<span class=acl-fixed-case>DROP</span>: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs</a></strong><br><a href=/people/d/dheeru-dua/>Dheeru Dua</a>
|
<a href=/people/y/yizhong-wang/>Yizhong Wang</a>
|
<a href=/people/p/pradeep-dasigi/>Pradeep Dasigi</a>
|
<a href=/people/g/gabriel-stanovsky/>Gabriel Stanovsky</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a>
|
<a href=/people/m/matt-gardner/>Matt Gardner</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1246><div class="card-body p-3 small">Reading comprehension has recently seen rapid progress, with <a href=https://en.wikipedia.org/wiki/Computer>systems</a> matching humans on the most popular datasets for the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. However, a large body of work has highlighted the brittleness of these <a href=https://en.wikipedia.org/wiki/System>systems</a>, showing that there is much work left to be done. We introduce a new reading comprehension benchmark, DROP, which requires Discrete Reasoning Over the content of Paragraphs. In this crowdsourced, adversarially-created, 55k-question benchmark, a system must resolve references in a question, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or sorting). These operations require a much more comprehensive understanding of the content of paragraphs, as they remove the paraphrase-and-entity-typing shortcuts available in prior datasets. We apply state-of-the-art methods from both the reading comprehension and semantic parsing literatures on this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and show that the best <a href=https://en.wikipedia.org/wiki/System>systems</a> only achieve 38.4 % <a href=https://en.wikipedia.org/wiki/F-number>F1</a> on our generalized accuracy metric, while expert human performance is 96 %. We additionally present a new model that combines reading comprehension methods with simple <a href=https://en.wikipedia.org/wiki/Numerical_analysis>numerical reasoning</a> to achieve 51 % <a href=https://en.wikipedia.org/wiki/F-number>F1</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-5001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-5001 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-5001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N19-5001.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/359555654 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-5001/>Deep Adversarial Learning for <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP</a><span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/w/william-yang-wang/>William Yang Wang</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a>
|
<a href=/people/j/jiwei-li/>Jiwei Li</a><br><a href=/volumes/N19-5/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-5001><div class="card-body p-3 small">Adversarial learning is a game-theoretic learning paradigm, which has achieved huge successes in the field of <a href=https://en.wikipedia.org/wiki/Computer_vision>Computer Vision</a> recently. Adversarial learning is also a general framework that enables a variety of learning models, including the popular Generative Adversarial Networks (GANs). Due to the discrete nature of language, designing adversarial learning models is still challenging for NLP problems. In this tutorial, we provide a gentle introduction to the foundation of deep adversarial learning, as well as some practical problem formulations and solutions in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. We describe recent advances in deep adversarial learning for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, with a special focus on generation, adversarial examples & rules, and <a href=https://en.wikipedia.org/wiki/Dialogue>dialogue</a>. We provide an overview of the research area, categorize different types of <a href=https://en.wikipedia.org/wiki/Adversarial_learning>adversarial learning models</a>, and discuss pros and cons, aiming at providing some practical perspectives on the future of <a href=https://en.wikipedia.org/wiki/Adversarial_learning>adversarial learning</a> for solving real-world NLP problems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1621.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1621 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1621 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1621" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1621/>Are Red Roses Red? Evaluating Consistency of Question-Answering Models</a></strong><br><a href=/people/m/marco-tulio-ribeiro/>Marco Tulio Ribeiro</a>
|
<a href=/people/c/carlos-guestrin/>Carlos Guestrin</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1621><div class="card-body p-3 small">Although current evaluation of <a href=https://en.wikipedia.org/wiki/Question_answering>question-answering systems</a> treats predictions in isolation, we need to consider the relationship between predictions to measure true understanding. A <a href=https://en.wikipedia.org/wiki/Model_(person)>model</a> should be penalized for answering no to Is the rose red? if it answers red to What color is the rose?. We propose a method to automatically extract such implications for instances from two QA datasets, VQA and SQuAD, which we then use to evaluate the consistency of models. Human evaluation shows these generated implications are well formed and valid. Consistency evaluation provides crucial insights into gaps in existing models, while retraining with implication-augmented data improves <a href=https://en.wikipedia.org/wiki/Consistency>consistency</a> on both synthetic and human-generated implications.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1233.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1233 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1233 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D18-1233.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1233/>Interpretation of Natural Language Rules in Conversational Machine Reading</a></strong><br><a href=/people/m/marzieh-saeidi/>Marzieh Saeidi</a>
|
<a href=/people/m/max-bartolo/>Max Bartolo</a>
|
<a href=/people/p/patrick-lewis/>Patrick Lewis</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a>
|
<a href=/people/t/tim-rocktaschel/>Tim Rocktäschel</a>
|
<a href=/people/m/mike-sheldon/>Mike Sheldon</a>
|
<a href=/people/g/guillaume-bouchard/>Guillaume Bouchard</a>
|
<a href=/people/s/sebastian-riedel/>Sebastian Riedel</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1233><div class="card-body p-3 small">Most work in <a href=https://en.wikipedia.org/wiki/Machine_reading>machine reading</a> focuses on question answering problems where the answer is directly expressed in the text to read. However, many real-world question answering problems require the reading of text not because it contains the literal answer, but because it contains a recipe to derive an answer together with the reader&#8217;s background knowledge. One example is the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> of interpreting regulations to answer Can I...? or Do I have to...? questions such as I am working in Canada. Do I have to carry on paying UK National Insurance? after reading a UK government website about this topic. This <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> requires both the interpretation of rules and the application of background knowledge. It is further complicated due to the fact that, in practice, most questions are underspecified, and a human assistant will regularly have to ask clarification questions such as How long have you been working abroad? when the answer can not be directly derived from the question and text. In this paper, we formalise this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> and develop a crowd-sourcing strategy to collect 37k <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task instances</a> based on real-world rules and crowd-generated questions and scenarios. We analyse the challenges of this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> and assess its difficulty by evaluating the performance of rule-based and machine-learning baselines. We observe promising results when no background knowledge is necessary, and substantial room for improvement whenever background knowledge is needed.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1079.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1079 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1079 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1079.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1079.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285801102 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1079" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1079/>Semantically Equivalent Adversarial Rules for Debugging NLP models<span class=acl-fixed-case>NLP</span> models</a></strong><br><a href=/people/m/marco-tulio-ribeiro/>Marco Tulio Ribeiro</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a>
|
<a href=/people/c/carlos-guestrin/>Carlos Guestrin</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1079><div class="card-body p-3 small">Complex machine learning models for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> are often brittle, making different predictions for input instances that are extremely similar semantically. To automatically detect this behavior for individual instances, we present semantically equivalent adversaries (SEAs) semantic-preserving perturbations that induce changes in the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s predictions. We generalize these <a href=https://en.wikipedia.org/wiki/Adversarial_system>adversaries</a> into semantically equivalent adversarial rules (SEARs) simple, universal replacement rules that induce <a href=https://en.wikipedia.org/wiki/Adversarial_system>adversaries</a> on many instances. We demonstrate the usefulness and flexibility of SEAs and SEARs by detecting bugs in black-box state-of-the-art models for three domains : machine comprehension, visual question-answering, and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>. Via user studies, we demonstrate that we generate high-quality local adversaries for more instances than humans, and that SEARs induce four times as many mistakes as the bugs discovered by human experts. SEARs are also actionable : retraining models using <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> significantly reduces bugs, while maintaining <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1284.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1284 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1284 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1284/>Entity Linking via Joint Encoding of Types, Descriptions, and Context</a></strong><br><a href=/people/n/nitish-gupta/>Nitish Gupta</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1284><div class="card-body p-3 small">For accurate <a href=https://en.wikipedia.org/wiki/Entity_linking>entity linking</a>, we need to capture various information aspects of an entity, such as its description in a <a href=https://en.wikipedia.org/wiki/Knowledge_base>KB</a>, contexts in which it is mentioned, and structured knowledge. Additionally, a linking system should work on texts from different domains without requiring domain-specific training data or hand-engineered features. In this work we present a neural, modular entity linking system that learns a unified dense representation for each entity using multiple sources of information, such as its description, contexts around its mentions, and its fine-grained types. We show that the resulting entity linking system is effective at combining these sources, and performs competitively, sometimes out-performing current state-of-the-art systems across datasets, without requiring any domain-specific training data or hand-engineered features. We also show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can effectively embed entities that are new to the KB, and is able to link its mentions accurately.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Sameer+Singh" title="Search for 'Sameer Singh' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/m/matt-gardner/ class=align-middle>Matt Gardner</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/e/eric-wallace/ class=align-middle>Eric Wallace</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/m/marco-tulio-ribeiro/ class=align-middle>Marco Tulio Ribeiro</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/c/carlos-guestrin/ class=align-middle>Carlos Guestrin</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/r/robert-l-logan-iv/ class=align-middle>Robert L. Logan IV</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/g/gabriel-stanovsky/ class=align-middle>Gabriel Stanovsky</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/n/nitish-gupta/ class=align-middle>Nitish Gupta</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/dan-roth/ class=align-middle>Dan Roth</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/dheeru-dua/ class=align-middle>Dheeru Dua</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yizhong-wang/ class=align-middle>Yizhong Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/andrew-mccallum/ class=align-middle>Andrew McCallum</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dan-bikel/ class=align-middle>Dan Bikel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/taylor-shin/ class=align-middle>Taylor Shin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yasaman-razeghi/ class=align-middle>Yasaman Razeghi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anthony-chen/ class=align-middle>Anthony Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tongshuang-wu/ class=align-middle>Tongshuang Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marzieh-saeidi/ class=align-middle>Marzieh Saeidi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/max-bartolo/ class=align-middle>Max Bartolo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/patrick-lewis/ class=align-middle>Patrick Lewis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tim-rocktaschel/ class=align-middle>Tim Rocktäschel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mike-sheldon/ class=align-middle>Mike Sheldon</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/guillaume-bouchard/ class=align-middle>Guillaume Bouchard</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sebastian-riedel/ class=align-middle>Sebastian Riedel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cicero-dos-santos/ class=align-middle>Cicero dos Santos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/patrick-ng/ class=align-middle>Patrick Ng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/ben-athiwaratkun/ class=align-middle>Ben Athiwaratkun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bing-xiang/ class=align-middle>Bing Xiang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kai-wei-chang/ class=align-middle>Kai-Wei Chang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/he-he/ class=align-middle>He He</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/robin-jia/ class=align-middle>Robin Jia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/matthew-e-peters/ class=align-middle>Matthew E. Peters</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mark-neumann/ class=align-middle>Mark Neumann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/robert-logan/ class=align-middle>Robert Logan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/roy-schwartz/ class=align-middle>Roy Schwartz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vidur-joshi/ class=align-middle>Vidur Joshi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/noah-a-smith/ class=align-middle>Noah A. Smith</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sujian-li/ class=align-middle>Sujian Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tony-zhao/ class=align-middle>Tony Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shi-feng/ class=align-middle>Shi Feng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pouya-pezeshkpour/ class=align-middle>Pouya Pezeshkpour</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sarthak-jain/ class=align-middle>Sarthak Jain</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/byron-c-wallace/ class=align-middle>Byron C. Wallace</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/junlin-wang/ class=align-middle>Junlin Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jens-tuyls/ class=align-middle>Jens Tuyls</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sanjay-subramanian/ class=align-middle>Sanjay Subramanian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lucy-lu-wang/ class=align-middle>Lucy Lu Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/ben-bogin/ class=align-middle>Ben Bogin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sachin-mehta/ class=align-middle>Sachin Mehta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/madeleine-van-zuylen/ class=align-middle>Madeleine van Zuylen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sravanthi-parasa/ class=align-middle>Sravanthi Parasa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hannaneh-hajishirzi/ class=align-middle>Hannaneh Hajishirzi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhouhang-xie/ class=align-middle>Zhouhang Xie</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jonathan-brophy/ class=align-middle>Jonathan Brophy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/adam-noack/ class=align-middle>Adam Noack</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wencong-you/ class=align-middle>Wencong You</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kalyani-asthana/ class=align-middle>Kalyani Asthana</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/carter-perkins/ class=align-middle>Carter Perkins</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sabrina-reis/ class=align-middle>Sabrina Reis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zayd-hammoudeh/ class=align-middle>Zayd Hammoudeh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/daniel-lowd/ class=align-middle>Daniel Lowd</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pradeep-dasigi/ class=align-middle>Pradeep Dasigi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/william-yang-wang/ class=align-middle>William Yang Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiwei-li/ class=align-middle>Jiwei Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">9</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/blackboxnlp/ class=align-middle>BlackboxNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>