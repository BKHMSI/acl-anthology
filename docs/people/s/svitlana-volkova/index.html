<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Svitlana Volkova - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Svitlana</span> <span class=font-weight-bold>Volkova</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dash-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dash-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dash-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.dash-1.13" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.dash-1.13/>CrossCheck : Rapid, Reproducible, and Interpretable Model Evaluation<span class=acl-fixed-case>C</span>ross<span class=acl-fixed-case>C</span>heck: Rapid, Reproducible, and Interpretable Model Evaluation</a></strong><br><a href=/people/d/dustin-arendt/>Dustin Arendt</a>
|
<a href=/people/z/zhuanyi-shaw/>Zhuanyi Shaw</a>
|
<a href=/people/p/prasha-shrestha/>Prasha Shrestha</a>
|
<a href=/people/e/ellyn-ayton/>Ellyn Ayton</a>
|
<a href=/people/m/maria-glenski/>Maria Glenski</a>
|
<a href=/people/s/svitlana-volkova/>Svitlana Volkova</a><br><a href=/volumes/2021.dash-1/ class=text-muted>Proceedings of the Second Workshop on Data Science with Human in the Loop: Language Advances</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dash-1--13><div class="card-body p-3 small">Evaluation beyond aggregate performance metrics, e.g. F1-score, is crucial to both establish an appropriate level of trust in <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning models</a> and identify avenues for future <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> improvements. In this paper we demonstrate CrossCheck, an interactive capability for rapid cross-model comparison and reproducible error analysis. We describe the tool, discuss design and implementation details, and present three NLP use cases named entity recognition, <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>, and clickbait detection that show the benefits of using the tool for model evaluation. CrossCheck enables users to make informed decisions when choosing between multiple models, identify when the models are correct and for which examples, investigate whether the models are making the same mistakes as humans, evaluate models&#8217; generalizability and highlight models&#8217; limitations, strengths and weaknesses. Furthermore, CrossCheck is implemented as a <a href=https://en.wikipedia.org/wiki/Jupyter>Jupyter widget</a>, which allows for rapid and convenient integration into existing model development workflows.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-main.210.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-main--210 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-main.210 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-main.210/>Evaluating Neural Model Robustness for Machine Comprehension</a></strong><br><a href=/people/w/winston-wu/>Winston Wu</a>
|
<a href=/people/d/dustin-arendt/>Dustin Arendt</a>
|
<a href=/people/s/svitlana-volkova/>Svitlana Volkova</a><br><a href=/volumes/2021.eacl-main/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-main--210><div class="card-body p-3 small">We evaluate neural model robustness to adversarial attacks using different types of linguistic unit perturbations character and word, and propose a new method for strategic sentence-level perturbations. We experiment with different amounts of perturbations to examine model confidence and misclassification rate, and contrast model performance with different embeddings BERT and ELMo on two benchmark datasets SQuAD and TriviaQA. We demonstrate how to improve <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performance during an <a href=https://en.wikipedia.org/wiki/Adversarial_system>adversarial attack</a> by using <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensembles</a>. Finally, we analyze factors that effect model behavior under adversarial attack, and develop a new <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to predict errors during attacks. Our novel findings reveal that (a) unlike BERT, models that use ELMo embeddings are more susceptible to adversarial attacks, (b) unlike word and paraphrase, character perturbations affect the model the most but are most easily compensated for by adversarial training, (c) word perturbations lead to more high-confidence misclassifications compared to sentence- and character-level perturbations, (d) the type of question and model answer length (the longer the answer the more likely it is to be incorrect) is the most predictive of model errors in adversarial setting, and (e) conclusions about model behavior are dataset-specific.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.socialnlp-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--socialnlp-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.socialnlp-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.socialnlp-1.6/>Evaluating Deception Detection Model Robustness To <a href=https://en.wikipedia.org/wiki/Variation_(linguistics)>Linguistic Variation</a></a></strong><br><a href=/people/m/maria-glenski/>Maria Glenski</a>
|
<a href=/people/e/ellyn-ayton/>Ellyn Ayton</a>
|
<a href=/people/r/robin-cosbey/>Robin Cosbey</a>
|
<a href=/people/d/dustin-arendt/>Dustin Arendt</a>
|
<a href=/people/s/svitlana-volkova/>Svitlana Volkova</a><br><a href=/volumes/2021.socialnlp-1/ class=text-muted>Proceedings of the Ninth International Workshop on Natural Language Processing for Social Media</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--socialnlp-1--6><div class="card-body p-3 small">With the increasing use of machine-learning driven algorithmic judgements, it is critical to develop <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that are robust to evolving or manipulated inputs. We propose an extensive analysis of <a href=https://en.wikipedia.org/wiki/Robust_statistics>model robustness</a> against <a href=https://en.wikipedia.org/wiki/Variation_(linguistics)>linguistic variation</a> in the setting of deceptive news detection, an important task in the context of <a href=https://en.wikipedia.org/wiki/Misinformation>misinformation spread online</a>. We consider two prediction tasks and compare three state-of-the-art embeddings to highlight consistent trends in <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performance, high confidence misclassifications, and high impact failures. By measuring the effectiveness of adversarial defense strategies and evaluating model susceptibility to adversarial attacks using character- and word-perturbed text, we find that character or mixed ensemble models are the most effective defenses and that character perturbation-based attack tactics are more successful.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpcss-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nlpcss-1.0/>Proceedings of the Fourth Workshop on Natural Language Processing and Computational Social Science</a></strong><br><a href=/people/d/david-bamman/>David Bamman</a>
|
<a href=/people/d/dirk-hovy/>Dirk Hovy</a>
|
<a href=/people/d/david-jurgens/>David Jurgens</a>
|
<a href=/people/b/brendan-o-connor/>Brendan O'Connor</a>
|
<a href=/people/s/svitlana-volkova/>Svitlana Volkova</a><br><a href=/volumes/2020.nlpcss-1/ class=text-muted>Proceedings of the Fourth Workshop on Natural Language Processing and Computational Social Science</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2100.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2100/>Proceedings of the Third Workshop on Natural Language Processing and Computational Social Science</a></strong><br><a href=/people/s/svitlana-volkova/>Svitlana Volkova</a>
|
<a href=/people/d/david-jurgens/>David Jurgens</a>
|
<a href=/people/d/dirk-hovy/>Dirk Hovy</a>
|
<a href=/people/d/david-bamman/>David Bamman</a>
|
<a href=/people/o/oren-tsur/>Oren Tsur</a><br><a href=/volumes/W19-21/ class=text-muted>Proceedings of the Third Workshop on Natural Language Processing and Computational Social Science</a></span></p><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2096.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-2096 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-2096 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-2096/>Predicting Foreign Language Usage from English-Only Social Media Posts<span class=acl-fixed-case>E</span>nglish-Only Social Media Posts</a></strong><br><a href=/people/s/svitlana-volkova/>Svitlana Volkova</a>
|
<a href=/people/s/stephen-ranshous/>Stephen Ranshous</a>
|
<a href=/people/l/lawrence-phillips/>Lawrence Phillips</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-2096><div class="card-body p-3 small">Social media is known for its multi-cultural and multilingual interactions, a natural product of which is <a href=https://en.wikipedia.org/wiki/Code_mixing>code-mixing</a>. Multilingual speakers mix languages they tweet to address a different audience, express certain feelings, or attract attention. This paper presents a large-scale analysis of 6 million tweets produced by 27 thousand multilingual users speaking 12 other languages besides <a href=https://en.wikipedia.org/wiki/English_language>English</a>. We rely on this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> to build <a href=https://en.wikipedia.org/wiki/Predictive_modelling>predictive models</a> to infer non-English languages that users speak exclusively from their <a href=https://en.wikipedia.org/wiki/Twitter>English tweets</a>. Unlike native language identification task, we rely on large amounts of informal social media communications rather than <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>ESL essays</a>. We contrast the predictive power of the state-of-the-art <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning models</a> trained on lexical, syntactic, and stylistic signals with <a href=https://en.wikipedia.org/wiki/Neural_network>neural network models</a> learned from word, character and byte representations extracted from <a href=https://en.wikipedia.org/wiki/Twitter>English only tweets</a>. We report that <a href=https://en.wikipedia.org/wiki/Content_(media)>content</a>, style and <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> are the most predictive of non-English languages that users speak on <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>. Neural network models learned from byte representations of user content combined with <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> yield the best performance. Finally, by analyzing cross-lingual transfer the influence of non-English languages on various levels of linguistic performance in English, we present novel findings on stylistic and syntactic variations across speakers of 12 languages in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-2029.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-2029 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-2029 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-2029/>Identifying and Understanding User Reactions to Deceptive and Trusted Social News Sources</a></strong><br><a href=/people/m/maria-glenski/>Maria Glenski</a>
|
<a href=/people/t/tim-weninger/>Tim Weninger</a>
|
<a href=/people/s/svitlana-volkova/>Svitlana Volkova</a><br><a href=/volumes/P18-2/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-2029><div class="card-body p-3 small">In the age of <a href=https://en.wikipedia.org/wiki/Social_news_website>social news</a>, it is important to understand the types of <a href=https://en.wikipedia.org/wiki/Reactionary>reactions</a> that are evoked from <a href=https://en.wikipedia.org/wiki/Source_(journalism)>news sources</a> with various levels of <a href=https://en.wikipedia.org/wiki/Credibility>credibility</a>. In the present work we seek to better understand how users react to trusted and deceptive news sources across two popular, and very different, <a href=https://en.wikipedia.org/wiki/Social_media>social media platforms</a>. To that end, (1) we develop a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to classify user reactions into one of nine types, such as answer, elaboration, and question, etc, and (2) we measure the speed and the type of reaction for trusted and deceptive news sources for 10.8 M <a href=https://en.wikipedia.org/wiki/Twitter>Twitter posts</a> and 6.2 M <a href=https://en.wikipedia.org/wiki/Reddit>Reddit comments</a>. We show that there are significant differences in the speed and the type of reactions between trusted and deceptive news sources on <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>, but far smaller differences on <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a>.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2073.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2073 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2073 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P17-2073/>Multilingual Connotation Frames : A Case Study on <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a> for Targeted Sentiment Analysis and Forecast</a></strong><br><a href=/people/h/hannah-rashkin/>Hannah Rashkin</a>
|
<a href=/people/e/eric-bell/>Eric Bell</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/s/svitlana-volkova/>Svitlana Volkova</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2073><div class="card-body p-3 small">People around the globe respond to major real world events through <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. To study targeted public sentiments across many languages and geographic locations, we introduce multilingual connotation frames : an extension from English connotation frames of Rashkin et al. (2016) with 10 additional <a href=https://en.wikipedia.org/wiki/Languages_of_Europe>European languages</a>, focusing on the implied sentiments among event participants engaged in a frame. As a case study, we present large scale analysis on targeted public sentiments toward salient events and <a href=https://en.wikipedia.org/wiki/Non-physical_entity>entities</a> using 1.2 million multilingual connotation frames extracted from <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2102.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2102 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2102 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-2102.Datasets.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-2102/>Separating Facts from Fiction : Linguistic Models to Classify Suspicious and Trusted News Posts on Twitter<span class=acl-fixed-case>T</span>witter</a></strong><br><a href=/people/s/svitlana-volkova/>Svitlana Volkova</a>
|
<a href=/people/k/kyle-shaffer/>Kyle Shaffer</a>
|
<a href=/people/j/jin-yea-jang/>Jin Yea Jang</a>
|
<a href=/people/n/nathan-hodas/>Nathan Hodas</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2102><div class="card-body p-3 small">Pew research polls report 62 percent of U.S. adults get news on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> (Gottfried and Shearer, 2016). In a December poll, 64 percent of U.S. adults said that made-up news has caused a great deal of confusion about the facts of current events (Barthel et al., 2016). Fabricated stories in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, ranging from <a href=https://en.wikipedia.org/wiki/Propaganda>deliberate propaganda</a> to <a href=https://en.wikipedia.org/wiki/Hoax>hoaxes</a> and <a href=https://en.wikipedia.org/wiki/Satire>satire</a>, contributes to this confusion in addition to having serious effects on global stability. In this work we build predictive models to classify 130 thousand news posts as suspicious or verified, and predict four sub-types of suspicious news satire, <a href=https://en.wikipedia.org/wiki/Hoax>hoaxes</a>, <a href=https://en.wikipedia.org/wiki/Clickbait>clickbait</a> and <a href=https://en.wikipedia.org/wiki/Propaganda>propaganda</a>. We show that <a href=https://en.wikipedia.org/wiki/Neural_network>neural network models</a> trained on tweet content and <a href=https://en.wikipedia.org/wiki/Social_network>social network interactions</a> outperform <a href=https://en.wikipedia.org/wiki/Lexical_analysis>lexical models</a>. Unlike previous work on deception detection, we find that adding syntax and grammar features to our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> does not improve performance. Incorporating linguistic features improves <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> results, however, social interaction features are most informative for finer-grained separation between four types of suspicious news posts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2624.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2624 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2624 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2624/>Intrinsic and Extrinsic Evaluation of Spatiotemporal Text Representations in Twitter Streams<span class=acl-fixed-case>T</span>witter Streams</a></strong><br><a href=/people/l/lawrence-phillips/>Lawrence Phillips</a>
|
<a href=/people/k/kyle-shaffer/>Kyle Shaffer</a>
|
<a href=/people/d/dustin-arendt/>Dustin Arendt</a>
|
<a href=/people/n/nathan-hodas/>Nathan Hodas</a>
|
<a href=/people/s/svitlana-volkova/>Svitlana Volkova</a><br><a href=/volumes/W17-26/ class=text-muted>Proceedings of the 2nd Workshop on Representation Learning for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2624><div class="card-body p-3 small">Language in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> is a dynamic system, constantly evolving and adapting, with words and concepts rapidly emerging, disappearing, and changing their meaning. These changes can be estimated using word representations in context, over time and across locations. A number of methods have been proposed to track these spatiotemporal changes but no general method exists to evaluate the quality of these representations. Previous work largely focused on qualitative evaluation, which we improve by proposing a set of <a href=https://en.wikipedia.org/wiki/Visualization_(graphics)>visualizations</a> that highlight changes in text representation over both space and time. We demonstrate usefulness of novel spatiotemporal representations to explore and characterize specific aspects of the <a href=https://en.wikipedia.org/wiki/Twitter>corpus of tweets</a> collected from European countries over a two-week period centered around the <a href=https://en.wikipedia.org/wiki/2016_Brussels_bombings>terrorist attacks</a> in Brussels in March 2016. In addition, we quantitatively evaluate spatiotemporal representations by feeding them into a downstream classification task event type prediction. Thus, our work is the first to provide both intrinsic (qualitative) and extrinsic (quantitative) evaluation of text representations for spatiotemporal trends.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2900.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2900/>Proceedings of the Second Workshop on <span class=acl-fixed-case>NLP</span> and Computational Social Science</a></strong><br><a href=/people/d/dirk-hovy/>Dirk Hovy</a>
|
<a href=/people/s/svitlana-volkova/>Svitlana Volkova</a>
|
<a href=/people/d/david-bamman/>David Bamman</a>
|
<a href=/people/d/david-jurgens/>David Jurgens</a>
|
<a href=/people/b/brendan-oconnor/>Brendan O’Connor</a>
|
<a href=/people/o/oren-tsur/>Oren Tsur</a>
|
<a href=/people/a/a-seza-dogruoz/>A. Seza Doğruöz</a><br><a href=/volumes/W17-29/ class=text-muted>Proceedings of the Second Workshop on NLP and Computational Social Science</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1317.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1317 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1317 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238236521 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1317/>Truth of Varying Shades : Analyzing Language in Fake News and Political Fact-Checking</a></strong><br><a href=/people/h/hannah-rashkin/>Hannah Rashkin</a>
|
<a href=/people/e/eunsol-choi/>Eunsol Choi</a>
|
<a href=/people/j/jin-yea-jang/>Jin Yea Jang</a>
|
<a href=/people/s/svitlana-volkova/>Svitlana Volkova</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1317><div class="card-body p-3 small">We present an analytic study on the language of news media in the context of <a href=https://en.wikipedia.org/wiki/Fact-checking>political fact-checking</a> and fake news detection. We compare the language of real news with that of <a href=https://en.wikipedia.org/wiki/Satire>satire</a>, <a href=https://en.wikipedia.org/wiki/Hoax>hoaxes</a>, and <a href=https://en.wikipedia.org/wiki/Propaganda>propaganda</a> to find linguistic characteristics of untrustworthy text. To probe the feasibility of automatic political fact-checking, we also present a <a href=https://en.wikipedia.org/wiki/Case_study>case study</a> based on <a href=https://en.wikipedia.org/wiki/PolitiFact>PolitiFact.com</a> using their factuality judgments on a 6-point scale. Experiments show that while media fact-checking remains to be an open research question, stylistic cues can help determine the truthfulness of text.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Svitlana+Volkova" title="Search for 'Svitlana Volkova' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/d/dustin-arendt/ class=align-middle>Dustin Arendt</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/m/maria-glenski/ class=align-middle>Maria Glenski</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/d/dirk-hovy/ class=align-middle>Dirk Hovy</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/d/david-bamman/ class=align-middle>David Bamman</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/d/david-jurgens/ class=align-middle>David Jurgens</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/e/ellyn-ayton/ class=align-middle>Ellyn Ayton</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hannah-rashkin/ class=align-middle>Hannah Rashkin</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yejin-choi/ class=align-middle>Yejin Choi</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/kyle-shaffer/ class=align-middle>Kyle Shaffer</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jin-yea-jang/ class=align-middle>Jin Yea Jang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/n/nathan-hodas/ class=align-middle>Nathan Hodas</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/lawrence-phillips/ class=align-middle>Lawrence Phillips</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/o/oren-tsur/ class=align-middle>Oren Tsur</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/zhuanyi-shaw/ class=align-middle>Zhuanyi Shaw</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/prasha-shrestha/ class=align-middle>Prasha Shrestha</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eric-bell/ class=align-middle>Eric Bell</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/winston-wu/ class=align-middle>Winston Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/robin-cosbey/ class=align-middle>Robin Cosbey</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/brendan-oconnor/ class=align-middle>Brendan O’Connor</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/a-seza-dogruoz/ class=align-middle>A. Seza Doğruöz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eunsol-choi/ class=align-middle>Eunsol Choi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/brendan-o-connor/ class=align-middle>Brendan O'Connor</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stephen-ranshous/ class=align-middle>Stephen Ranshous</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tim-weninger/ class=align-middle>Tim Weninger</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/dash/ class=align-middle>DaSH</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/socialnlp/ class=align-middle>SocialNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/nlpcss/ class=align-middle>NLP+CSS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>