<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Shafiq Joty - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Shafiq</span> <span class=font-weight-bold>Joty</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.453.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--453 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.453 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.453/>MulDA : A Multilingual Data Augmentation Framework for Low-Resource Cross-Lingual NER<span class=acl-fixed-case>M</span>ul<span class=acl-fixed-case>DA</span>: A Multilingual Data Augmentation Framework for Low-Resource Cross-Lingual <span class=acl-fixed-case>NER</span></a></strong><br><a href=/people/l/linlin-liu/>Linlin Liu</a>
|
<a href=/people/b/bosheng-ding/>Bosheng Ding</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/l/luo-si/>Luo Si</a>
|
<a href=/people/c/chunyan-miao/>Chunyan Miao</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--453><div class="card-body p-3 small">Named Entity Recognition (NER) for low-resource languages is a both practical and challenging research problem. This paper addresses zero-shot transfer for cross-lingual NER, especially when the amount of source-language training data is also limited. The paper first proposes a simple but effective labeled sequence translation method to translate source-language training data to target languages and avoids problems such as word order change and entity span determination. With the source-language data as well as the translated data, a generation-based multilingual data augmentation method is introduced to further increase diversity by generating synthetic labeled data in multiple languages. These augmented data enable the language model based NER models to generalize better with both the language-specific features from the target-language synthetic data and the language-independent features from multilingual synthetic data. An extensive set of experiments were conducted to demonstrate encouraging cross-lingual transfer performance of the new <a href=https://en.wikipedia.org/wiki/Research>research</a> on a wide variety of target languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.685.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--685 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.685 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.685" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.685/>CodeT5 : Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation<span class=acl-fixed-case>C</span>ode<span class=acl-fixed-case>T</span>5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation</a></strong><br><a href=/people/y/yue-wang/>Yue Wang</a>
|
<a href=/people/w/weishi-wang/>Weishi Wang</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/s/steven-c-h-hoi/>Steven C.H. Hoi</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--685><div class="card-body p-3 small">Pre-trained models for Natural Languages (NL) like BERT and GPT have been recently shown to transfer well to Programming Languages (PL) and largely benefit a broad set of code-related tasks. Despite their success, most current methods either rely on an encoder-only (or decoder-only) pre-training that is suboptimal for generation (resp. understanding) tasks or process the code snippet in the same way as NL, neglecting the special characteristics of PL such as token types. We present CodeT5, a unified pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers. Our model employs a unified framework to seamlessly support both code understanding and generation tasks and allows for <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a>. Besides, we propose a novel identifier-aware pre-training task that enables the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to distinguish which code tokens are identifiers and to recover them when they are masked. Furthermore, we propose to exploit the user-written code comments with a bimodal dual generation task for better NL-PL alignment. Comprehensive experiments show that CodeT5 significantly outperforms prior methods on understanding tasks such as code defect detection and clone detection, and generation tasks across various directions including PL-NL, NL-PL, and PL-PL. Further analysis reveals that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can better capture semantic information from code. Our code and pre-trained models are released at https://github.com/salesforce/CodeT5.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.57.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--57 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.57 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.57/>Improving Zero and Few-Shot Abstractive Summarization with Intermediate Fine-tuning and Data Augmentation</a></strong><br><a href=/people/a/alexander-richard-fabbri/>Alexander Fabbri</a>
|
<a href=/people/s/simeng-han/>Simeng Han</a>
|
<a href=/people/h/haoyuan-li/>Haoyuan Li</a>
|
<a href=/people/h/haoran-li/>Haoran Li</a>
|
<a href=/people/m/marjan-ghazvininejad/>Marjan Ghazvininejad</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/d/dragomir-radev/>Dragomir Radev</a>
|
<a href=/people/y/yashar-mehdad/>Yashar Mehdad</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--57><div class="card-body p-3 small">Models pretrained with self-supervised objectives on large text corpora achieve state-of-the-art performance on English text summarization tasks. However, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are typically fine-tuned on hundreds of thousands of data points, an infeasible requirement when applying <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> to new, niche domains. In this work, we introduce a novel and generalizable method, called WikiTransfer, for fine-tuning pretrained models for <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> in an unsupervised, dataset-specific manner. WikiTransfer fine-tunes pretrained models on pseudo-summaries, produced from generic Wikipedia data, which contain characteristics of the target dataset, such as the length and level of abstraction of the desired summaries. WikiTransfer models achieve state-of-the-art, zero-shot abstractive summarization performance on the CNN-DailyMail dataset and demonstrate the effectiveness of our approach on three additional diverse datasets. These models are more robust to noisy data and also achieve better or comparable few-shot performance using 10 and 100 training examples when compared to few-shot transfer from other summarization datasets. To further boost performance, we employ <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> via <a href=https://en.wikipedia.org/wiki/Round-trip_translation>round-trip translation</a> as well as introduce a regularization term for improved few-shot transfer. To understand the role of dataset aspects in transfer performance and the quality of the resulting output summaries, we further study the effect of the components of our unsupervised fine-tuning data and analyze few-shot performance using both automatic and human evaluation.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.177.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--177 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.177 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939290 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.177" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.177/>Pronoun-Targeted Fine-tuning for NMT with Hybrid Losses<span class=acl-fixed-case>NMT</span> with Hybrid Losses</a></strong><br><a href=/people/p/prathyusha-jwalapuram/>Prathyusha Jwalapuram</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/y/youlin-shen/>Youlin Shen</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--177><div class="card-body p-3 small">Popular Neural Machine Translation model training uses strategies like backtranslation to improve BLEU scores, requiring large amounts of additional data and training. We introduce a class of conditional generative-discriminative hybrid losses that we use to fine-tune a trained <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation model</a>. Through a combination of targeted fine-tuning objectives and intuitive re-use of the training data the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> has failed to adequately learn from, we improve the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> performance of both a sentence-level and a contextual model without using any additional data. We target the improvement of pronoun translations through our <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> and evaluate our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on a pronoun benchmark testset. Our sentence-level model shows a 0.5 BLEU improvement on both the WMT14 and the IWSLT13 De-En testsets, while our contextual model achieves the best results, improving from 31.81 to 32 BLEU on WMT14 De-En testset, and from 32.10 to 33.13 on the IWSLT13 De-En testset, with corresponding improvements in pronoun translation. We further show the generalizability of our method by reproducing the improvements on two additional language pairs, Fr-En and Cs-En.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.88.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--88 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.88 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928988 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.88" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.88/>Explicit Memory Tracker with Coarse-to-Fine Reasoning for Conversational Machine Reading</a></strong><br><a href=/people/y/yifan-gao/>Yifan Gao</a>
|
<a href=/people/c/chien-sheng-wu/>Chien-Sheng Wu</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/c/caiming-xiong/>Caiming Xiong</a>
|
<a href=/people/r/richard-socher/>Richard Socher</a>
|
<a href=/people/i/irwin-king/>Irwin King</a>
|
<a href=/people/m/michael-lyu/>Michael Lyu</a>
|
<a href=/people/s/steven-c-h-hoi/>Steven C.H. Hoi</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--88><div class="card-body p-3 small">The goal of conversational machine reading is to answer user questions given a knowledge base text which may require asking clarification questions. Existing approaches are limited in their decision making due to struggles in extracting question-related rules and reasoning about them. In this paper, we present a new framework of conversational machine reading that comprises a novel Explicit Memory Tracker (EMT) to track whether conditions listed in the rule text have already been satisfied to make a decision. Moreover, our framework generates clarification questions by adopting a coarse-to-fine reasoning strategy, utilizing sentence-level entailment scores to weight token-level distributions. On the ShARC benchmark (blind, held-out) testset, <a href=https://en.wikipedia.org/wiki/Emergency_medical_technician>EMT</a> achieves new state-of-the-art results of 74.6 % micro-averaged decision accuracy and 49.5 BLEU4. We also show that <a href=https://en.wikipedia.org/wiki/Emergency_medical_technician>EMT</a> is more interpretable by visualizing the entailment-oriented reasoning process as the conversation flows. Code and models are released at https://github.com/Yifan-Gao/explicit_memory_tracker.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.301.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--301 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.301 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928813 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.301/>Efficient Constituency Parsing by Pointing</a></strong><br><a href=/people/t/thanh-tung-nguyen/>Thanh-Tung Nguyen</a>
|
<a href=/people/x/xuan-phi-nguyen/>Xuan-Phi Nguyen</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/x/xiaoli-li/>Xiaoli Li</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--301><div class="card-body p-3 small">We propose a novel constituency parsing model that casts the parsing problem into a series of pointing tasks. Specifically, our model estimates the likelihood of a span being a legitimate tree constituent via the pointing score corresponding to the boundary words of the span. Our parsing model supports efficient <a href=https://en.wikipedia.org/wiki/Top-down_and_bottom-up_design>top-down decoding</a> and our learning objective is able to enforce structural consistency without resorting to the expensive CKY inference. The experiments on the standard English Penn Treebank parsing task show that our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> achieves 92.78 F1 without using pre-trained models, which is higher than all the existing methods with similar <a href=https://en.wikipedia.org/wiki/Time_complexity>time complexity</a>. Using pre-trained BERT, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves 95.48 <a href=https://en.wikipedia.org/wiki/F-number>F1</a>, which is competitive with the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> while being faster. Our approach also establishes new state-of-the-art in <a href=https://en.wikipedia.org/wiki/Basque_language>Basque</a> and <a href=https://en.wikipedia.org/wiki/Swedish_language>Swedish</a> in the SPMRL shared tasks on multilingual constituency parsing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.589.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--589 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.589 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928814 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.589/>Differentiable Window for Dynamic Local Attention</a></strong><br><a href=/people/t/thanh-tung-nguyen/>Thanh-Tung Nguyen</a>
|
<a href=/people/x/xuan-phi-nguyen/>Xuan-Phi Nguyen</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/x/xiaoli-li/>Xiaoli Li</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--589><div class="card-body p-3 small">We propose Differentiable Window, a new neural module and general purpose component for dynamic window selection. While universally applicable, we demonstrate a compelling use case of utilizing Differentiable Window to improve standard attention modules by enabling more focused attentions over the input regions. We propose two variants of Differentiable Window, and integrate them within the Transformer architecture in two novel ways. We evaluate our proposed approach on a myriad of NLP tasks, including <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, <a href=https://en.wikipedia.org/wiki/Agreement_(linguistics)>subject-verb agreement</a> and <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>. Our experimental results demonstrate consistent and sizable improvements across all <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cl-2.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--cl-2--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.cl-2.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.cl-2.2/>Unsupervised Word Translation with Adversarial Autoencoder</a></strong><br><a href=/people/m/muhammad-tasnim-mohiuddin/>Tasnim Mohiuddin</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a><br><a href=/volumes/2020.cl-2/ class=text-muted>Computational Linguistics, Volume 46, Issue 2 - June 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--cl-2--2><div class="card-body p-3 small">Crosslingual word embeddings learned from monolingual embeddings have a crucial role in many downstream tasks, ranging from <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> to <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>. Adversarial training has shown impressive success in learning crosslingual embeddings and the associated word translation task without any parallel data by mapping monolingual embeddings to a shared space. However, recent work has shown superior performance for non-adversarial methods in more challenging language pairs. In this article, we investigate adversarial autoencoder for unsupervised word translation and propose two novel extensions to it that yield more stable training and improved results. Our method includes regularization terms to enforce cycle consistency and input reconstruction, and puts the target encoders as an adversary against the corresponding discriminator. We use two types of <a href=https://en.wikipedia.org/wiki/Refinement_(computing)>refinement procedures</a> sequentially after obtaining the trained encoders and mappings from the adversarial training, namely, <a href=https://en.wikipedia.org/wiki/Refinement_(computing)>refinement</a> with Procrustes solution and <a href=https://en.wikipedia.org/wiki/Refinement_(computing)>refinement</a> with symmetric re-weighting. Extensive experimentations with high- and low-resource languages from two different data sets show that our method achieves better performance than existing adversarial and non-adversarial approaches and is also competitive with the <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised system</a>. Along with performing comprehensive ablation studies to understand the contribution of different components of our <a href=https://en.wikipedia.org/wiki/Adversarial_model>adversarial model</a>, we also conduct a thorough analysis of the refinement procedures to understand their effects.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sustainlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sustainlp-1.0/>Proceedings of SustaiNLP: Workshop on Simple and Efficient Natural Language Processing</a></strong><br><a href=/people/n/nafise-sadat-moosavi/>Nafise Sadat Moosavi</a>
|
<a href=/people/a/angela-fan/>Angela Fan</a>
|
<a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/g/goran-glavas/>Goran Glavaš</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/a/alex-wang/>Alex Wang</a>
|
<a href=/people/t/thomas-wolf/>Thomas Wolf</a><br><a href=/volumes/2020.sustainlp-1/ class=text-muted>Proceedings of SustaiNLP: Workshop on Simple and Efficient Natural Language Processing</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1231.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1231 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1231 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1231/>A Unified Neural Coherence Model</a></strong><br><a href=/people/h/han-cheol-moon/>Han Cheol Moon</a>
|
<a href=/people/m/muhammad-tasnim-mohiuddin/>Tasnim Mohiuddin</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/c/chi-xu/>Chi Xu</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1231><div class="card-body p-3 small">Recently, neural approaches to coherence modeling have achieved state-of-the-art results in several evaluation tasks. However, we show that most of these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> often fail on harder <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> with more realistic application scenarios. In particular, the existing models underperform on tasks that require the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to be sensitive to local contexts such as candidate ranking in <a href=https://en.wikipedia.org/wiki/Dialogue>conversational dialogue</a> and in <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. In this paper, we propose a unified coherence model that incorporates sentence grammar, inter-sentence coherence relations, and global coherence patterns into a common neural framework. With extensive experiments on local and global discrimination tasks, we demonstrate that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> by a good margin, and establish a new <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1294.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1294 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1294 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1294.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1294" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1294/>Evaluating Pronominal Anaphora in <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a> : An Evaluation Measure and a Test Suite</a></strong><br><a href=/people/p/prathyusha-jwalapuram/>Prathyusha Jwalapuram</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/i/irina-temnikova/>Irina Temnikova</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1294><div class="card-body p-3 small">The ongoing neural revolution in <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> has made it easier to model larger contexts beyond the sentence-level, which can potentially help resolve some discourse-level ambiguities such as pronominal anaphora, thus enabling better translations. Unfortunately, even when the resulting improvements are seen as substantial by humans, they remain virtually unnoticed by traditional automatic evaluation measures like <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>, as only a few words end up being affected. Thus, specialized <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation measures</a> are needed. With this aim in mind, we contribute an extensive, targeted dataset that can be used as a test suite for pronoun translation, covering multiple source languages and different pronoun errors drawn from real system translations, for <a href=https://en.wikipedia.org/wiki/English_language>English</a>. We further propose an evaluation measure to differentiate good and bad pronoun translations. We also conduct a <a href=https://en.wikipedia.org/wiki/User_study>user study</a> to report correlations with <a href=https://en.wikipedia.org/wiki/Judgement>human judgments</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1134.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1134 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1134 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-1134/>Adaptation of Hierarchical Structured Models for <a href=https://en.wikipedia.org/wiki/Speech_recognition>Speech Act Recognition</a> in Asynchronous Conversation</a></strong><br><a href=/people/m/muhammad-tasnim-mohiuddin/>Tasnim Mohiuddin</a>
|
<a href=/people/t/thanh-tung-nguyen/>Thanh-Tung Nguyen</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1134><div class="card-body p-3 small">We address the problem of speech act recognition (SAR) in asynchronous conversations (forums, emails). Unlike <a href=https://en.wikipedia.org/wiki/Synchronization>synchronous conversations</a> (e.g., meetings, phone), asynchronous domains lack large labeled datasets to train an effective SAR model. In this paper, we propose methods to effectively leverage abundant unlabeled conversational data and the available labeled data from synchronous domains. We carry out our research in three main steps. First, we introduce a neural architecture based on hierarchical LSTMs and conditional random fields (CRF) for SAR, and show that our method outperforms existing methods when trained on in-domain data only. Second, we improve our initial SAR models by <a href=https://en.wikipedia.org/wiki/Semi-supervised_learning>semi-supervised learning</a> in the form of pretrained word embeddings learned from a large unlabeled conversational corpus. Finally, we employ adversarial training to improve the results further by leveraging the labeled data from synchronous domains and by explicitly modeling the distributional shift in two domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1244.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1244 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1244 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1244/>Sentence-Level Evidence Embedding for Claim Verification with Hierarchical Attention Networks</a></strong><br><a href=/people/j/jing-ma/>Jing Ma</a>
|
<a href=/people/w/wei-gao/>Wei Gao</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/k/kam-fai-wong/>Kam-Fai Wong</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1244><div class="card-body p-3 small">Claim verification is generally a task of verifying the veracity of a given claim, which is critical to many downstream applications. It is cumbersome and inefficient for human fact-checkers to find consistent pieces of evidence, from which solid verdict could be inferred against the claim. In this paper, we propose a novel end-to-end hierarchical attention network focusing on learning to represent coherent evidence as well as their semantic relatedness with the claim. Our model consists of three main components : 1) A coherence-based attention layer embeds coherent evidence considering the claim and sentences from relevant articles ; 2) An entailment-based attention layer attends on sentences that can semantically infer the claim on top of the first attention ; and 3) An output layer predicts the verdict based on the embedded evidence. Experimental results on three public benchmark datasets show that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms a set of state-of-the-art baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1410.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1410 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1410 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1410.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385254497 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1410" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1410/>A Unified Linear-Time Framework for Sentence-Level Discourse Parsing</a></strong><br><a href=/people/x/xiang-lin/>Xiang Lin</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/p/prathyusha-jwalapuram/>Prathyusha Jwalapuram</a>
|
<a href=/people/m/m-saiful-bari/>M Saiful Bari</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1410><div class="card-body p-3 small">We propose an efficient neural framework for sentence-level discourse analysis in accordance with Rhetorical Structure Theory (RST). Our framework comprises a discourse segmenter to identify the elementary discourse units (EDU) in a text, and a discourse parser that constructs a discourse tree in a top-down fashion. Both the segmenter and the <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> are based on Pointer Networks and operate in <a href=https://en.wikipedia.org/wiki/Time_complexity>linear time</a>. Our segmenter yields an F1 score of 95.4 %, and our parser achieves an F1 score of 81.7 % on the aggregated labeled (relation) metric, surpassing previous approaches by a good margin and approaching human agreement on both tasks (98.3 and 83.0 F1).</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1452.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1452 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1452 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/306149753 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1452/>Joint Multitask Learning for Community Question Answering Using Task-Specific Embeddings</a></strong><br><a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/l/lluis-marquez/>Lluís Màrquez</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1452><div class="card-body p-3 small">We address jointly two important tasks for Question Answering in community forums : given a new question, (i) find related existing questions, and (ii) find relevant answers to this new question. We further use an auxiliary task to complement the previous two, i.e., (iii) find good answers with respect to the thread question in a question-comment thread. We use deep neural networks (DNNs) to learn meaningful task-specific embeddings, which we then incorporate into a conditional random field (CRF) model for the multitask setting, performing joint learning over a complex graph structure. While <a href=https://en.wikipedia.org/wiki/Deep_learning>DNNs</a> alone achieve competitive results when trained to produce the embeddings, the CRF, which makes use of the embeddings and the dependencies between the tasks, improves the results significantly and consistently across a variety of evaluation metrics, thus showing the complementarity of <a href=https://en.wikipedia.org/wiki/Deep_learning>DNNs</a> and <a href=https://en.wikipedia.org/wiki/Structured_learning>structured learning</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1052.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1052 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1052 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1052.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1052.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1052/>Coherence Modeling of Asynchronous Conversations : A Neural Entity Grid Approach</a></strong><br><a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/m/muhammad-tasnim-mohiuddin/>Muhammad Tasnim Mohiuddin</a>
|
<a href=/people/d/dat-tien-nguyen/>Dat Tien Nguyen</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1052><div class="card-body p-3 small">We propose a novel coherence model for <a href=https://en.wikipedia.org/wiki/Asynchronous_communication>written asynchronous conversations</a> (e.g., <a href=https://en.wikipedia.org/wiki/Internet_forum>forums</a>, emails), and show its applications in coherence assessment and thread reconstruction tasks. We conduct our research in two steps. First, we propose improvements to the recently proposed neural entity grid model by lexicalizing its entity transitions. Then, we extend the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to <a href=https://en.wikipedia.org/wiki/Asynchronous_communication>asynchronous conversations</a> by incorporating the underlying conversational structure in the <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity grid representation</a> and feature computation. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves state of the art results on standard coherence assessment tasks in monologue and conversations outperforming existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. We also demonstrate its effectiveness in reconstructing thread structures.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1099.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1099 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1099 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1099.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802247 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1099" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1099/>Domain Adaptation with Adversarial Training and Graph Embeddings</a></strong><br><a href=/people/f/firoj-alam/>Firoj Alam</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/m/muhammad-imran/>Muhammad Imran</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1099><div class="card-body p-3 small">The success of deep neural networks (DNNs) is heavily dependent on the availability of labeled data. However, obtaining <a href=https://en.wikipedia.org/wiki/Labeled_data>labeled data</a> is a big challenge in many real-world problems. In such scenarios, a DNN model can leverage labeled and unlabeled data from a related domain, but it has to deal with the shift in data distributions between the source and the target domains. In this paper, we study the problem of classifying social media posts during a crisis event (e.g., Earthquake). For that, we use labeled and unlabeled data from past similar events (e.g., Flood) and unlabeled data for the current event. We propose a novel model that performs adversarial learning based domain adaptation to deal with distribution drifts and graph based semi-supervised learning to leverage unlabeled data within a single unified deep learning framework. Our experiments with two real-world crisis datasets collected from <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> demonstrate significant improvements over several <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-1024/>Cross-language Learning with Adversarial Neural Networks</a></strong><br><a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/l/lluis-marquez/>Lluís Màrquez</a>
|
<a href=/people/i/israa-jaradat/>Israa Jaradat</a><br><a href=/volumes/K17-1/ class=text-muted>Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-1024><div class="card-body p-3 small">We address the problem of cross-language adaptation for question-question similarity reranking in community question answering, with the objective to port a system trained on one input language to another input language given labeled training data for the first language and only unlabeled data for the second language. In particular, we propose to use adversarial training of neural networks to learn high-level features that are discriminative for the main learning task, and at the same time are invariant across the input languages. The evaluation results show sizable improvements for our cross-language adversarial neural network (CLANN) model over a strong non-adversarial system.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1121.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1121 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1121 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/306164201 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P17-1121" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1121/>A Neural Local Coherence Model</a></strong><br><a href=/people/d/dat-tien-nguyen/>Dat Tien Nguyen</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1121><div class="card-body p-3 small">We propose a local coherence model based on a <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural network</a> that operates over the entity grid representation of a text. The model captures long range entity transitions along with entity-specific features without loosing <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a>, thanks to the power of <a href=https://en.wikipedia.org/wiki/Distributed_representation>distributed representation</a>. We present a pairwise ranking method to train the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in an end-to-end fashion on a task and learn task-specific high level features. Our evaluation on three different coherence assessment tasks demonstrates that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves state of the art results outperforming existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> by a good margin.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/J17-4001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-J17-4001 data-toggle=collapse aria-expanded=false aria-controls=abstract-J17-4001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/J17-4001/>Discourse Structure in Machine Translation Evaluation</a></strong><br><a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/f/francisco-guzman/>Francisco Guzmán</a>
|
<a href=/people/l/lluis-marquez/>Lluís Màrquez</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/J17-4/ class=text-muted>Computational Linguistics, Volume 43, Issue 4 - December 2017</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-J17-4001><div class="card-body p-3 small">In this article, we explore the potential of using sentence-level discourse structure for machine translation evaluation. We first design discourse-aware similarity measures, which use all-subtree kernels to compare discourse parse trees in accordance with the Rhetorical Structure Theory (RST). Then, we show that a simple <a href=https://en.wikipedia.org/wiki/Linear_combination>linear combination</a> with these measures can help improve various existing machine translation evaluation metrics regarding correlation with human judgments both at the segment level and at the system level. This suggests that discourse information is complementary to the information used by many of the existing evaluation metrics, and thus it could be taken into account when developing richer evaluation metrics, such as the WMT-14 winning combined metric DiscoTKparty. We also provide a detailed analysis of the relevance of various discourse elements and relations from the RST parse trees for machine translation evaluation. In particular, we show that (i) all aspects of the RST tree are relevant, (ii) <a href=https://en.wikipedia.org/wiki/Nuclearity>nuclearity</a> is more useful than relation type, and (iii) the similarity of the translation RST tree to the reference RST tree is positively correlated with translation quality.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Shafiq+Joty" title="Search for 'Shafiq Joty' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/p/preslav-nakov/ class=align-middle>Preslav Nakov</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/m/muhammad-tasnim-mohiuddin/ class=align-middle>Muhammad Tasnim Mohiuddin</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/p/prathyusha-jwalapuram/ class=align-middle>Prathyusha Jwalapuram</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/t/thanh-tung-nguyen/ class=align-middle>Thanh-Tung Nguyen</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/lluis-marquez/ class=align-middle>Lluís Màrquez</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/s/steven-c-h-hoi/ class=align-middle>Steven C.H. Hoi</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/x/xuan-phi-nguyen/ class=align-middle>Xuan-Phi Nguyen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/x/xiaoli-li/ class=align-middle>Xiaoli Li</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/dat-tien-nguyen/ class=align-middle>Dat Tien Nguyen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/linlin-liu/ class=align-middle>Linlin Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bosheng-ding/ class=align-middle>Bosheng Ding</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lidong-bing/ class=align-middle>Lidong Bing</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luo-si/ class=align-middle>Luo Si</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chunyan-miao/ class=align-middle>Chunyan Miao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/youlin-shen/ class=align-middle>Youlin Shen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yifan-gao/ class=align-middle>Yifan Gao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chien-sheng-wu/ class=align-middle>Chien-Sheng Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/caiming-xiong/ class=align-middle>Caiming Xiong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/richard-socher/ class=align-middle>Richard Socher</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/irwin-king/ class=align-middle>Irwin King</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-lyu/ class=align-middle>Michael Lyu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/israa-jaradat/ class=align-middle>Israa Jaradat</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/francisco-guzman/ class=align-middle>Francisco Guzmán</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yue-wang/ class=align-middle>Yue Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/weishi-wang/ class=align-middle>Weishi Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/han-cheol-moon/ class=align-middle>Han Cheol Moon</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chi-xu/ class=align-middle>Chi Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/irina-temnikova/ class=align-middle>Irina Temnikova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexander-richard-fabbri/ class=align-middle>Alexander Richard Fabbri</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/simeng-han/ class=align-middle>Simeng Han</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haoyuan-li/ class=align-middle>Haoyuan Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haoran-li/ class=align-middle>Haoran Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marjan-ghazvininejad/ class=align-middle>Marjan Ghazvininejad</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dragomir-radev/ class=align-middle>Dragomir Radev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yashar-mehdad/ class=align-middle>Yashar Mehdad</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/firoj-alam/ class=align-middle>Firoj Alam</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/muhammad-imran/ class=align-middle>Muhammad Imran</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jing-ma/ class=align-middle>Jing Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wei-gao/ class=align-middle>Wei Gao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kam-fai-wong/ class=align-middle>Kam-Fai Wong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiang-lin/ class=align-middle>Xiang Lin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/m-saiful-bari/ class=align-middle>M Saiful Bari</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nafise-sadat-moosavi/ class=align-middle>Nafise Sadat Moosavi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/angela-fan/ class=align-middle>Angela Fan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vered-shwartz/ class=align-middle>Vered Shwartz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/goran-glavas/ class=align-middle>Goran Glavaš</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alex-wang/ class=align-middle>Alex Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thomas-wolf/ class=align-middle>Thomas Wolf</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">9</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/cl/ class=align-middle>CL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/sustainlp/ class=align-middle>sustainlp</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>