<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Sujian Li - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Sujian</span> <span class=font-weight-bold>Li</span></h2><hr><div class=row><div class=col-lg-9><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ccl-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ccl-1.0/>Proceedings of the 19th Chinese National Conference on Computational Linguistics</a></strong><br><a href=/people/m/maosong-sun/>Maosong Sun (孙茂松)</a>
|
<a href=/people/s/sujian-li/>Sujian Li (李素建)</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang (张岳)</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu (刘洋)</a><br><a href=/volumes/2020.ccl-1/ class=text-muted>Proceedings of the 19th Chinese National Conference on Computational Linguistics</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ccl-1.82.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ccl-1--82 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ccl-1.82 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ccl-1.82/>Refining Data for <a href=https://en.wikipedia.org/wiki/Text-based_user_interface>Text Generation</a></a></strong><br><a href=/people/w/wenyu-guan/>Wenyu Guan</a>
|
<a href=/people/q/qianying-liu/>Qianying Liu</a>
|
<a href=/people/t/tianyi-li/>Tianyi Li</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a><br><a href=/volumes/2020.ccl-1/ class=text-muted>Proceedings of the 19th Chinese National Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ccl-1--82><div class="card-body p-3 small">Recent work on data-to-text generation has made progress under the neural encoder-decoder architectures. However, the data input size is often enormous, while not all data records are important for text generation and inappropriate input may bring noise into the final output. To solve this problem, we propose a two-step approach which first selects and orders the important data records and then generates text from the noise-reduced data. Here we propose a learning to rank model to rank the importance of each record which is supervised by a relation extractor. With the noise-reduced data as input, we implement a <a href=https://en.wikipedia.org/wiki/Text_generator>text generator</a> which sequentially models the input data records and emits a summary. Experiments on the ROTOWIRE dataset verifies the effectiveness of our proposed method in both performance and efficiency.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1534.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1534 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1534 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1534.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-1534/>Do NLP Models Know Numbers? Probing Numeracy in Embeddings<span class=acl-fixed-case>NLP</span> Models Know Numbers? Probing Numeracy in Embeddings</a></strong><br><a href=/people/e/eric-wallace/>Eric Wallace</a>
|
<a href=/people/y/yizhong-wang/>Yizhong Wang</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a>
|
<a href=/people/m/matt-gardner/>Matt Gardner</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1534><div class="card-body p-3 small">The ability to understand and work with numbers (numeracy) is critical for many complex reasoning tasks. Currently, most NLP models treat numbers in text in the same way as other tokensthey embed them as distributed vectors. Is this enough to capture <a href=https://en.wikipedia.org/wiki/Numeracy>numeracy</a>? We begin by investigating the numerical reasoning capabilities of a state-of-the-art <a href=https://en.wikipedia.org/wiki/Question_answering>question answering model</a> on the DROP dataset. We find this <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> excels on questions that require <a href=https://en.wikipedia.org/wiki/Numerical_analysis>numerical reasoning</a>, i.e., <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> already captures <a href=https://en.wikipedia.org/wiki/Numeracy>numeracy</a>. To understand how this capability emerges, we probe token embedding methods (e.g., BERT, GloVe) on synthetic list maximum, number decoding, and addition tasks. A surprising degree of <a href=https://en.wikipedia.org/wiki/Numeracy>numeracy</a> is naturally present in standard <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a>. For example, GloVe and <a href=https://en.wikipedia.org/wiki/Word2vec>word2vec</a> accurately encode <a href=https://en.wikipedia.org/wiki/Magnitude_(mathematics)>magnitude</a> for numbers up to 1,000. Furthermore, character-level embeddings are even more preciseELMo captures <a href=https://en.wikipedia.org/wiki/Numeracy>numeracy</a> the best for all pre-trained methodsbut BERT, which uses sub-word units, is less exact.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8102.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8102 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8102 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8102/>Incorporating Textual Evidence in Visual Storytelling</a></strong><br><a href=/people/t/tianyi-li/>Tianyi Li</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a><br><a href=/volumes/W19-81/ class=text-muted>Proceedings of the 1st Workshop on Discourse Structure in Neural NLG</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8102><div class="card-body p-3 small">Previous work on <a href=https://en.wikipedia.org/wiki/Visual_storytelling>visual storytelling</a> mainly focused on exploring image sequence as evidence for <a href=https://en.wikipedia.org/wiki/Storytelling>storytelling</a> and neglected textual evidence for guiding <a href=https://en.wikipedia.org/wiki/Storytelling>story generation</a>. Motivated by human storytelling process which recalls stories for familiar images, we exploit textual evidence from similar images to help generate coherent and meaningful stories. To pick the <a href=https://en.wikipedia.org/wiki/Digital_image>images</a> which may provide textual experience, we propose a two-step ranking method based on image object recognition techniques. To utilize textual information, we design an extended Seq2Seq model with two-channel encoder and attention. Experiments on the VIST dataset show that our method outperforms state-of-the-art baseline models without heavy engineering.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/U19-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-U19-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-U19-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/U19-1024/>An Improved Coarse-to-Fine Method for Solving Generation Tasks</a></strong><br><a href=/people/w/wenyv-guan/>Wenyv Guan</a>
|
<a href=/people/q/qianying-liu/>Qianying Liu</a>
|
<a href=/people/g/guangzhi-han/>Guangzhi Han</a>
|
<a href=/people/b/bin-wang/>Bin Wang</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a><br><a href=/volumes/U19-1/ class=text-muted>Proceedings of the The 17th Annual Workshop of the Australasian Language Technology Association</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-U19-1024><div class="card-body p-3 small">The coarse-to-fine (coarse2fine) methods have recently been widely used in the generation tasks. The methods first generate a rough sketch in the coarse stage and then use the sketch to get the final result in the fine stage. However, <a href=https://en.wikipedia.org/wiki/They_(2017_film)>they</a> usually lack the correction ability when getting a wrong sketch. To solve this problem, in this paper, we propose an improved coarse2fine model with a control mechanism, with which our method can control the influence of the sketch on the final results in the fine stage. Even if the sketch is wrong, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> still has the opportunity to get a correct result. We have experimented our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> on the tasks of <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> and math word problem solving. The results have shown the effectiveness of our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1226.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1226 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1226 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1226/>Enhancing Pre-Trained Language Representations with Rich Knowledge for Machine Reading Comprehension</a></strong><br><a href=/people/a/an-yang/>An Yang</a>
|
<a href=/people/q/quan-wang/>Quan Wang</a>
|
<a href=/people/j/jing-liu/>Jing Liu</a>
|
<a href=/people/k/kai-liu/>Kai Liu</a>
|
<a href=/people/y/yajuan-lyu/>Yajuan Lyu</a>
|
<a href=/people/h/hua-wu/>Hua Wu</a>
|
<a href=/people/q/qiaoqiao-she/>Qiaoqiao She</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1226><div class="card-body p-3 small">Machine reading comprehension (MRC) is a crucial and challenging task in <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP</a>. Recently, pre-trained language models (LMs), especially BERT, have achieved remarkable success, presenting new state-of-the-art results in <a href=https://en.wikipedia.org/wiki/Machine_learning>MRC</a>. In this work, we investigate the potential of leveraging external knowledge bases (KBs) to further improve BERT for <a href=https://en.wikipedia.org/wiki/Medical_record>MRC</a>. We introduce KT-NET, which employs an attention mechanism to adaptively select desired knowledge from KBs, and then fuses selected knowledge with BERT to enable context- and knowledge-aware predictions. We believe this would combine the merits of both deep LMs and curated KBs towards better MRC. Experimental results indicate that KT-NET offers significant and consistent improvements over BERT, outperforming competitive <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>baselines</a> on ReCoRD and SQuAD1.1 benchmarks. Notably, it ranks the 1st place on the ReCoRD leaderboard, and is also the best single <a href=https://en.wikipedia.org/wiki/Computer_model>model</a> on the SQuAD1.1 leaderboard at the time of submission (March 4th, 2019).</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1072.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1072 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1072 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1072/>Auto-Dialabel : Labeling Dialogue Data with <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>Unsupervised Learning</a></a></strong><br><a href=/people/c/chen-shi/>Chen Shi</a>
|
<a href=/people/q/qi-chen/>Qi Chen</a>
|
<a href=/people/l/lei-sha/>Lei Sha</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a>
|
<a href=/people/x/xu-sun/>Xu Sun</a>
|
<a href=/people/h/houfeng-wang/>Houfeng Wang</a>
|
<a href=/people/l/lintao-zhang/>Lintao Zhang</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1072><div class="card-body p-3 small">The lack of <a href=https://en.wikipedia.org/wiki/Data_(computing)>labeled data</a> is one of the main challenges when building a task-oriented dialogue system. Existing dialogue datasets usually rely on human labeling, which is expensive, limited in size, and in low coverage. In this paper, we instead propose our framework auto-dialabel to automatically cluster the dialogue intents and slots. In this framework, we collect a set of context features, leverage an <a href=https://en.wikipedia.org/wiki/Autoencoder>autoencoder</a> for feature assembly, and adapt a dynamic hierarchical clustering method for intent and slot labeling. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> can promote human labeling cost to a great extent, achieve good intent clustering accuracy (84.1 %), and provide reasonable and instructive slot labeling results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1116.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1116 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1116 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/306361340 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1116/>Toward Fast and Accurate Neural Discourse Segmentation</a></strong><br><a href=/people/y/yizhong-wang/>Yizhong Wang</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a>
|
<a href=/people/j/jingfeng-yang/>Jingfeng Yang</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1116><div class="card-body p-3 small">Discourse segmentation, which segments texts into Elementary Discourse Units, is a fundamental step in <a href=https://en.wikipedia.org/wiki/Discourse_analysis>discourse analysis</a>. Previous discourse segmenters rely on complicated hand-crafted features and are not practical in actual use. In this paper, we propose an end-to-end neural segmenter based on BiLSTM-CRF framework. To improve its <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, we address the problem of data insufficiency by transferring a word representation model that is trained on a large corpus. We also propose a restricted self-attention mechanism in order to capture useful information within a neighborhood. Experiments on the RST-DT corpus show that our model is significantly faster than previous methods, while achieving new state-of-the-art performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-2611.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-2611 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-2611 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-2611/>Adaptations of ROUGE and BLEU to Better Evaluate Machine Reading Comprehension Task<span class=acl-fixed-case>ROUGE</span> and <span class=acl-fixed-case>BLEU</span> to Better Evaluate Machine Reading Comprehension Task</a></strong><br><a href=/people/a/an-yang/>An Yang</a>
|
<a href=/people/k/kai-liu/>Kai Liu</a>
|
<a href=/people/j/jing-liu/>Jing Liu</a>
|
<a href=/people/y/yajuan-lyu/>Yajuan Lyu</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a><br><a href=/volumes/W18-26/ class=text-muted>Proceedings of the Workshop on Machine Reading for Question Answering</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-2611><div class="card-body p-3 small">Current evaluation metrics to <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> based machine reading comprehension (MRC) systems generally focus on the lexical overlap between candidate and reference answers, such as ROUGE and <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>. However, bias may appear when these <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> are used for specific question types, especially questions inquiring yes-no opinions and entity lists. In this paper, we make adaptations on the <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> to better correlate n-gram overlap with the <a href=https://en.wikipedia.org/wiki/Judgement>human judgment</a> for answers to these two question types. Statistical analysis proves the effectiveness of our <a href=https://en.wikipedia.org/wiki/Scientific_method>approach</a>. Our adaptations may provide positive guidance for the development of real-scene MRC systems.<tex-math>n</tex-math>-gram overlap with the human judgment for answers to these two question types. Statistical analysis proves the effectiveness of our approach. Our adaptations may provide positive guidance for the development of real-scene MRC systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1015.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1015 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1015 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1015.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285800584 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1015/>Retrieve, Rerank and Rewrite : Soft Template Based Neural Summarization</a></strong><br><a href=/people/z/ziqiang-cao/>Ziqiang Cao</a>
|
<a href=/people/w/wenjie-li/>Wenjie Li</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a>
|
<a href=/people/f/furu-wei/>Furu Wei</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1015><div class="card-body p-3 small">Most previous seq2seq summarization systems purely depend on the source text to generate summaries, which tends to work unstably. Inspired by the traditional template-based summarization approaches, this paper proposes to use existing summaries as soft templates to guide the seq2seq model. To this end, we use a popular IR platform to Retrieve proper summaries as candidate templates. Then, we extend the seq2seq framework to jointly conduct template Reranking and template-aware summary generation (Rewriting). Experiments show that, in terms of informativeness, our model significantly outperforms the state-of-the-art methods, and even soft templates themselves demonstrate high competitiveness. In addition, the import of high-quality external summaries improves the <a href=https://en.wikipedia.org/wiki/BIBO_stability>stability</a> and readability of generated summaries.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-2071.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-2071 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-2071 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-2071.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285804155 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-2071" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-2071/>SciDTB : Discourse Dependency TreeBank for Scientific Abstracts<span class=acl-fixed-case>S</span>ci<span class=acl-fixed-case>DTB</span>: Discourse Dependency <span class=acl-fixed-case>T</span>ree<span class=acl-fixed-case>B</span>ank for Scientific Abstracts</a></strong><br><a href=/people/a/an-yang/>An Yang</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a><br><a href=/volumes/P18-2/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-2071><div class="card-body p-3 small">Annotation corpus for <a href=https://en.wikipedia.org/wiki/Discourse_analysis>discourse relations</a> benefits NLP tasks such as <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> and <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>. In this paper, we present SciDTB, a domain-specific discourse treebank annotated on <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific articles</a>. Different from widely-used RST-DT and <a href=https://en.wikipedia.org/wiki/PDTB>PDTB</a>, SciDTB uses dependency trees to represent discourse structure, which is flexible and simplified to some extent but do not sacrifice structural integrity. We discuss the labeling framework, annotation workflow and some statistics about SciDTB. Furthermore, our <a href=https://en.wikipedia.org/wiki/Treebank>treebank</a> is made as a benchmark for evaluating discourse dependency parsers, on which we provide several baselines as fundamental work.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-1050.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-1050 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-1050 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-1050/>Tag-Enhanced Tree-Structured Neural Networks for Implicit Discourse Relation Classification</a></strong><br><a href=/people/y/yizhong-wang/>Yizhong Wang</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a>
|
<a href=/people/j/jingfeng-yang/>Jingfeng Yang</a>
|
<a href=/people/x/xu-sun/>Xu Sun</a>
|
<a href=/people/h/houfeng-wang/>Houfeng Wang</a><br><a href=/volumes/I17-1/ class=text-muted>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-1050><div class="card-body p-3 small">Identifying implicit discourse relations between text spans is a challenging task because it requires understanding the meaning of the text. To tackle this task, recent studies have tried several <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning methods</a> but few of them exploited the <a href=https://en.wikipedia.org/wiki/Syntax>syntactic information</a>. In this work, we explore the idea of incorporating syntactic parse tree into <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>. Specifically, we employ the Tree-LSTM model and Tree-GRU model, which is based on the <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>tree structure</a>, to encode the arguments in a relation. And we further leverage the constituent tags to control the semantic composition process in these tree-structured neural networks. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> achieves state-of-the-art performance on PDTB corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-1064.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-1064 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-1064 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-1064/>Cascading Multiway Attentions for Document-level Sentiment Classification</a></strong><br><a href=/people/d/dehong-ma/>Dehong Ma</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a>
|
<a href=/people/x/xiaodong-zhang/>Xiaodong Zhang</a>
|
<a href=/people/h/houfeng-wang/>Houfeng Wang</a>
|
<a href=/people/x/xu-sun/>Xu Sun</a><br><a href=/volumes/I17-1/ class=text-muted>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-1064><div class="card-body p-3 small">Document-level sentiment classification aims to assign the user reviews a sentiment polarity. Previous methods either just utilized the document content without consideration of user and product information, or did not comprehensively consider what roles the three kinds of information play in text modeling. In this paper, to reasonably use all the information, we present the idea that <a href=https://en.wikipedia.org/wiki/User_(computing)>user</a>, product and their combination can all influence the generation of attentions to words and sentences, when judging the <a href=https://en.wikipedia.org/wiki/Sentimentality>sentiment</a> of a document. With this idea, we propose a cascading multiway attention (CMA) model, where multiple ways of using user and product information are cascaded to influence the generation of attentions on the word and sentence layers. Then, sentences and documents are well modeled by multiple representation vectors, which provide rich information for sentiment classification. Experiments on IMDB and Yelp datasets demonstrate the effectiveness of our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2029.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2029 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2029 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234959057 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-2029/>A Two-Stage Parsing Method for Text-Level Discourse Analysis</a></strong><br><a href=/people/y/yizhong-wang/>Yizhong Wang</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a>
|
<a href=/people/h/houfeng-wang/>Houfeng Wang</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2029><div class="card-body p-3 small">Previous work introduced transition-based algorithms to form a unified architecture of parsing rhetorical structures (including span, nuclearity and relation), but did not achieve satisfactory performance. In this paper, we propose that transition-based model is more appropriate for parsing the naked discourse tree (i.e., identifying span and nuclearity) due to data sparsity. At the same time, we argue that relation labeling can benefit from naked tree structure and should be treated elaborately with consideration of three kinds of <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a> including within-sentence, across-sentence and across-paragraph relations. Thus, we design a pipelined two-stage parsing method for generating an RST tree from text. Experimental results show that our method achieves state-of-the-art performance, especially on span and nuclearity identification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2161.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2161 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2161 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2161/>PKU_ICL at SemEval-2017 Task 10 : Keyphrase Extraction with Model Ensemble and External Knowledge<span class=acl-fixed-case>PKU</span>_<span class=acl-fixed-case>ICL</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 10: Keyphrase Extraction with Model Ensemble and External Knowledge</a></strong><br><a href=/people/l/liang-wang/>Liang Wang</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2161><div class="card-body p-3 small">This paper presents a system that participated in SemEval 2017 Task 10 (subtask A and subtask B): Extracting Keyphrases and Relations from Scientific Publications (Augenstein et al., 2017). Our proposed approach utilizes external knowledge to enrich feature representation of candidate keyphrase, including <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, IEEE taxonomy and pre-trained word embeddings etc. Ensemble of unsupervised models, <a href=https://en.wikipedia.org/wiki/Random_forest>random forest</a> and linear models are used for candidate keyphrase ranking and keyphrase type classification. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves the 3rd place in subtask A and 4th place in subtask B.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1139.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1139 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1139 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1139/>Learning to Rank Semantic Coherence for Topic Segmentation</a></strong><br><a href=/people/l/liang-wang/>Liang Wang</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a>
|
<a href=/people/y/yajuan-lu/>Yajuan Lv</a>
|
<a href=/people/h/houfeng-wang/>Houfeng Wang</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1139><div class="card-body p-3 small">Topic segmentation plays an important role for discourse parsing and <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a>. Due to the absence of training data, previous work mainly adopts <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised methods</a> to rank semantic coherence between paragraphs for <a href=https://en.wikipedia.org/wiki/Topic_segmentation>topic segmentation</a>. In this paper, we present an intuitive and simple idea to automatically create a quasi training dataset, which includes a large amount of text pairs from the same or different documents with different semantic coherence. With the training corpus, we design a symmetric CNN neural network to model text pairs and rank the semantic coherence within the learning to rank framework. Experiments show that our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> is able to achieve competitive performance over strong baselines on several real-world datasets.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Sujian+Li" title="Search for 'Sujian Li' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/h/houfeng-wang/ class=align-middle>Houfeng Wang</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/y/yizhong-wang/ class=align-middle>Yizhong Wang</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/x/xu-sun/ class=align-middle>Xu Sun</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/an-yang/ class=align-middle>An Yang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/jingfeng-yang/ class=align-middle>Jingfeng Yang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/q/qianying-liu/ class=align-middle>Qianying Liu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/tianyi-li/ class=align-middle>Tianyi Li</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/liang-wang/ class=align-middle>Liang Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/kai-liu/ class=align-middle>Kai Liu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jing-liu/ class=align-middle>Jing Liu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yajuan-lyu/ class=align-middle>Yajuan Lyu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/dehong-ma/ class=align-middle>Dehong Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaodong-zhang/ class=align-middle>Xiaodong Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maosong-sun/ class=align-middle>Maosong Sun (孙茂松)</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yue-zhang/ class=align-middle>Yue Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yang-liu-ict/ class=align-middle>Yang Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wenyu-guan/ class=align-middle>Wenyu Guan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chen-shi/ class=align-middle>Chen Shi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qi-chen/ class=align-middle>Qi Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lei-sha/ class=align-middle>Lei Sha</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lintao-zhang/ class=align-middle>Lintao Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eric-wallace/ class=align-middle>Eric Wallace</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sameer-singh/ class=align-middle>Sameer Singh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/matt-gardner/ class=align-middle>Matt Gardner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yajuan-lu/ class=align-middle>Yajuan Lü</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wenyv-guan/ class=align-middle>Wenyv Guan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/guangzhi-han/ class=align-middle>Guangzhi Han</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bin-wang/ class=align-middle>Bin Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/ziqiang-cao/ class=align-middle>Ziqiang Cao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wenjie-li/ class=align-middle>Wenjie Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/furu-wei/ class=align-middle>Furu Wei</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/quan-wang/ class=align-middle>Quan Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hua-wu/ class=align-middle>Hua Wu (吴华)</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qiaoqiao-she/ class=align-middle>Qiaoqiao She</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ccl/ class=align-middle>CCL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/alta/ class=align-middle>ALTA</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>