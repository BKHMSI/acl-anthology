<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Sophia Ananiadou - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Sophia</span> <span class=font-weight-bold>Ananiadou</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-demos.28.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-demos--28 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-demos.28 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-demos.28/>Paladin : an annotation tool based on active and proactive learning</a></strong><br><a href=/people/m/minh-quoc-nghiem/>Minh-Quoc Nghiem</a>
|
<a href=/people/p/paul-baylis/>Paul Baylis</a>
|
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a><br><a href=/volumes/2021.eacl-demos/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-demos--28><div class="card-body p-3 small">In this paper, we present Paladin, an open-source web-based annotation tool for creating high-quality multi-label document-level datasets. By integrating <a href=https://en.wikipedia.org/wiki/Active_learning>active learning</a> and <a href=https://en.wikipedia.org/wiki/Proactive_learning>proactive learning</a> to the annotation task, <a href=https://en.wikipedia.org/wiki/Paladin>Paladin</a> makes the task less time-consuming and requiring less human effort. Although <a href=https://en.wikipedia.org/wiki/Paladin>Paladin</a> is designed for multi-label settings, the <a href=https://en.wikipedia.org/wiki/System>system</a> is flexible and can be adapted to other tasks in single-label settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.bionlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.bionlp-1.0/>Proceedings of the 20th Workshop on Biomedical Language Processing</a></strong><br><a href=/people/d/dina-demner-fushman/>Dina Demner-Fushman</a>
|
<a href=/people/k/k-bretonnel-cohen/>Kevin Bretonnel Cohen</a>
|
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a>
|
<a href=/people/j/junichi-tsujii/>Junichi Tsujii</a><br><a href=/volumes/2021.bionlp-1/ class=text-muted>Proceedings of the 20th Workshop on Biomedical Language Processing</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bionlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bionlp-1.0/>Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing</a></strong><br><a href=/people/d/dina-demner-fushman/>Dina Demner-Fushman</a>
|
<a href=/people/k/k-bretonnel-cohen/>Kevin Bretonnel Cohen</a>
|
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a>
|
<a href=/people/j/junichi-tsujii/>Junichi Tsujii</a><br><a href=/volumes/2020.bionlp-1/ class=text-muted>Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1381.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1381 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1381 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1381/>A Search-based Neural Model for Biomedical Nested and Overlapping Event Detection</a></strong><br><a href=/people/k/kurt-junshean-espinosa/>Kurt Junshean Espinosa</a>
|
<a href=/people/m/makoto-miwa/>Makoto Miwa</a>
|
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1381><div class="card-body p-3 small">We tackle the nested and overlapping event detection task and propose a novel search-based neural network (SBNN) structured prediction model that treats the task as a search problem on a relation graph of trigger-argument structures. Unlike existing structured prediction tasks such as dependency parsing, the task targets to detect DAG structures, which constitute <a href=https://en.wikipedia.org/wiki/Event_(computing)>events</a>, from the relation graph. We define actions to construct events and use all the beams in a <a href=https://en.wikipedia.org/wiki/Beam_search>beam search</a> to detect all event structures that may be overlapping and nested. The search process constructs <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>events</a> in a bottom-up manner while modelling the global properties for nested and overlapping structures simultaneously using <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>. We show that the model achieves performance comparable to the state-of-the-art model Turku Event Extraction System (TEES) on the BioNLP Cancer Genetics (CG) Shared Task 2013 without the use of any syntactic and hand-engineered features. Further analyses on the development set show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is more computationally efficient while yielding higher <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5000/>Proceedings of the 18th BioNLP Workshop and Shared Task</a></strong><br><a href=/people/d/dina-demner-fushman/>Dina Demner-Fushman</a>
|
<a href=/people/k/k-bretonnel-cohen/>Kevin Bretonnel Cohen</a>
|
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a>
|
<a href=/people/j/junichi-tsujii/>Junichi Tsujii</a><br><a href=/volumes/W19-50/ class=text-muted>Proceedings of the 18th BioNLP Workshop and Shared Task</a></span></p><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-2019.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-2019 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-2019 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-2019/>APLenty : annotation tool for creating high-quality datasets using active and proactive learning<span class=acl-fixed-case>APL</span>enty: annotation tool for creating high-quality datasets using active and proactive learning</a></strong><br><a href=/people/m/minh-quoc-nghiem/>Minh-Quoc Nghiem</a>
|
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a><br><a href=/volumes/D18-2/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-2019><div class="card-body p-3 small">In this paper, we present APLenty, an annotation tool for creating high-quality sequence labeling datasets using active and proactive learning. A major innovation of our tool is the integration of automatic annotation with <a href=https://en.wikipedia.org/wiki/Active_learning>active learning</a> and <a href=https://en.wikipedia.org/wiki/Proactive_learning>proactive learning</a>. This makes the task of creating labeled datasets easier, less time-consuming and requiring less human effort. APLenty is highly flexible and can be adapted to various other <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-2300.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-2300/>Proceedings of the <span class=acl-fixed-case>B</span>io<span class=acl-fixed-case>NLP</span> 2018 workshop</a></strong><br><a href=/people/d/dina-demner-fushman/>Dina Demner-Fushman</a>
|
<a href=/people/k/k-bretonnel-cohen/>Kevin Bretonnel Cohen</a>
|
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a>
|
<a href=/people/j/junichi-tsujii/>Junichi Tsujii</a><br><a href=/volumes/W18-23/ class=text-muted>Proceedings of the BioNLP 2018 workshop</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1131.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1131 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1131 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/277349441 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1131/>A Neural Layered Model for Nested Named Entity Recognition</a></strong><br><a href=/people/m/meizhi-ju/>Meizhi Ju</a>
|
<a href=/people/m/makoto-miwa/>Makoto Miwa</a>
|
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1131><div class="card-body p-3 small">Entity mentions embedded in longer entity mentions are referred to as nested entities. Most named entity recognition (NER) systems deal only with the flat entities and ignore the inner nested ones, which fails to capture finer-grained semantic information in underlying texts. To address this issue, we propose a novel neural model to identify nested entities by dynamically stacking flat NER layers. Each flat NER layer is based on the state-of-the-art flat NER model that captures sequential context representation with bidirectional Long Short-Term Memory (LSTM) layer and feeds it to the cascaded CRF layer. Our model merges the output of the LSTM layer in the current flat NER layer to build new representation for detected entities and subsequently feeds them into the next flat NER layer. This allows our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to extract outer entities by taking full advantage of information encoded in their corresponding inner entities, in an inside-to-outside way. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> dynamically stacks the flat NER layers until no outer entities are extracted. Extensive evaluation shows that our <a href=https://en.wikipedia.org/wiki/Dynamical_system>dynamic model</a> outperforms state-of-the-art feature-based systems on nested NER, achieving 74.7 % and 72.2 % on GENIA and ACE2005 datasets, respectively, in terms of <a href=https://en.wikipedia.org/wiki/F-score>F-score</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-2014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-2014 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-2014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-2014.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-2014" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-2014/>A Walk-based Model on <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>Entity Graphs</a> for Relation Extraction</a></strong><br><a href=/people/f/fenia-christopoulou/>Fenia Christopoulou</a>
|
<a href=/people/m/makoto-miwa/>Makoto Miwa</a>
|
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a><br><a href=/volumes/P18-2/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-2014><div class="card-body p-3 small">We present a novel graph-based neural network model for <a href=https://en.wikipedia.org/wiki/Relation_extraction>relation extraction</a>. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> treats multiple pairs in a sentence simultaneously and considers interactions among them. All the entities in a sentence are placed as <a href=https://en.wikipedia.org/wiki/Vertex_(graph_theory)>nodes</a> in a fully-connected graph structure. The <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>edges</a> are represented with <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>position-aware contexts</a> around the entity pairs. In order to consider different <a href=https://en.wikipedia.org/wiki/Path_(graph_theory)>relation paths</a> between two entities, we construct up to l-length walks between each pair. The resulting <a href=https://en.wikipedia.org/wiki/Walk_(graph_theory)>walks</a> are merged and iteratively used to update the edge representations into longer walks representations. We show that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves performance comparable to the state-of-the-art systems on the ACE 2005 dataset without using any external tools.<tex-math>l</tex-math>-length walks between each pair. The resulting walks are merged and iteratively used to update the edge representations into longer walks representations. We show that the model achieves performance comparable to the state-of-the-art systems on the ACE 2005 dataset without using any external tools.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2300.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2300/><span class=acl-fixed-case>B</span>io<span class=acl-fixed-case>NLP</span> 2017</a></strong><br><a href=/people/k/k-bretonnel-cohen/>Kevin Bretonnel Cohen</a>
|
<a href=/people/d/dina-demner-fushman/>Dina Demner-Fushman</a>
|
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a>
|
<a href=/people/j/junichi-tsujii/>Junichi Tsujii</a><br><a href=/volumes/W17-23/ class=text-muted>BioNLP 2017</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2314.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2314 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2314 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2314/>Proactive Learning for Named Entity Recognition</a></strong><br><a href=/people/m/maolin-li/>Maolin Li</a>
|
<a href=/people/n/nhung-nguyen/>Nhung Nguyen</a>
|
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a><br><a href=/volumes/W17-23/ class=text-muted>BioNLP 2017</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2314><div class="card-body p-3 small">The goal of <a href=https://en.wikipedia.org/wiki/Active_learning>active learning</a> is to minimise the cost of producing an <a href=https://en.wikipedia.org/wiki/Annotation>annotated dataset</a>, in which annotators are assumed to be perfect, i.e., they always choose the correct labels. However, in practice, annotators are not infallible, and they are likely to assign incorrect labels to some instances. Proactive learning is a generalisation of active learning that can model different kinds of <a href=https://en.wikipedia.org/wiki/Annotation>annotators</a>. Although <a href=https://en.wikipedia.org/wiki/Proactive_learning>proactive learning</a> has been applied to certain labelling tasks, such as text classification, there is little work on its application to named entity (NE) tagging. In this paper, we propose a proactive learning method for producing NE annotated corpora, using two annotators with different levels of expertise, and who charge different amounts based on their levels of experience. To optimise both cost and annotation quality, we also propose a mechanism to present multiple sentences to annotators at each iteration. Experimental results for several corpora show that our method facilitates the construction of high-quality NE labelled datasets at minimal cost.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-1093.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-1093 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-1093 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-1093/>Distributed Document and Phrase Co-embeddings for Descriptive Clustering</a></strong><br><a href=/people/m/motoki-sato/>Motoki Sato</a>
|
<a href=/people/a/austin-j-brockmeier/>Austin J. Brockmeier</a>
|
<a href=/people/g/georgios-kontonatsios/>Georgios Kontonatsios</a>
|
<a href=/people/t/tingting-mu/>Tingting Mu</a>
|
<a href=/people/j/john-y-goulermas/>John Y. Goulermas</a>
|
<a href=/people/j/junichi-tsujii/>Jun’ichi Tsujii</a>
|
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a><br><a href=/volumes/E17-1/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-1093><div class="card-body p-3 small">Descriptive document clustering aims to automatically discover groups of semantically related documents and to assign a meaningful label to characterise the content of each cluster. In this paper, we present a descriptive clustering approach that employs a distributed representation model, namely the paragraph vector model, to capture semantic similarities between documents and phrases. The proposed method uses a joint representation of phrases and documents (i.e., a co-embedding) to automatically select a <a href=https://en.wikipedia.org/wiki/Linguistic_description>descriptive phrase</a> that best represents each document cluster. We evaluate our method by comparing its performance to an existing state-of-the-art descriptive clustering method that also uses co-embedding but relies on a bag-of-words representation. Results obtained on benchmark datasets demonstrate that the paragraph vector-based method obtains superior performance over the existing approach in both identifying clusters and assigning appropriate descriptive labels to them.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Sophia+Ananiadou" title="Search for 'Sophia Ananiadou' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/j/junichi-tsujii/ class=align-middle>Jun’ichi Tsujii</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/d/dina-demner-fushman/ class=align-middle>Dina Demner-Fushman</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/k/k-bretonnel-cohen/ class=align-middle>K. Bretonnel Cohen</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/m/makoto-miwa/ class=align-middle>Makoto Miwa</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/minh-quoc-nghiem/ class=align-middle>Minh-Quoc Nghiem</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/p/paul-baylis/ class=align-middle>Paul Baylis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maolin-li/ class=align-middle>Maolin Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nhung-nguyen/ class=align-middle>Nhung Nguyen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kurt-junshean-espinosa/ class=align-middle>Kurt Junshean Espinosa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/meizhi-ju/ class=align-middle>Meizhi Ju</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/motoki-sato/ class=align-middle>Motoki Sato</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/austin-j-brockmeier/ class=align-middle>Austin J. Brockmeier</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/georgios-kontonatsios/ class=align-middle>Georgios Kontonatsios</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tingting-mu/ class=align-middle>Tingting Mu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/john-y-goulermas/ class=align-middle>John Y. Goulermas</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fenia-christopoulou/ class=align-middle>Fenia Christopoulou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/bionlp/ class=align-middle>BioNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>