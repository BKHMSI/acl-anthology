<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Ellie Pavlick - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Ellie</span> <span class=font-weight-bold>Pavlick</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naloma-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naloma-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naloma-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naloma-1.4/>Transferring Representations of Logical Connectives</a></strong><br><a href=/people/a/aaron-traylor/>Aaron Traylor</a>
|
<a href=/people/e/ellie-pavlick/>Ellie Pavlick</a>
|
<a href=/people/r/roman-feiman/>Roman Feiman</a><br><a href=/volumes/2021.naloma-1/ class=text-muted>Proceedings of the 1st and 2nd Workshops on Natural Logic Meets Machine Learning (NALOMA)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naloma-1--4><div class="card-body p-3 small">In modern natural language processing pipelines, it is common practice to pretrain a generative language model on a large corpus of text, and then to finetune the created representations by continuing to train them on a discriminative textual inference task. However, it is not immediately clear whether the <a href=https://en.wikipedia.org/wiki/Meaning_(linguistics)>logical meaning</a> necessary to model <a href=https://en.wikipedia.org/wiki/Logical_consequence>logical entailment</a> is captured by <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> in this <a href=https://en.wikipedia.org/wiki/Paradigm>paradigm</a>. We examine this pretrain-finetune recipe with language models trained on a synthetic propositional language entailment task, and present results on test sets probing models&#8217; knowledge of axioms of first order logic.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-short.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-short--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-short.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-short.21/>AND does not mean OR : Using Formal Languages to Study Language Models’ Representations<span class=acl-fixed-case>AND</span> does not mean <span class=acl-fixed-case>OR</span>: Using Formal Languages to Study Language Models’ Representations</a></strong><br><a href=/people/a/aaron-traylor/>Aaron Traylor</a>
|
<a href=/people/r/roman-feiman/>Roman Feiman</a>
|
<a href=/people/e/ellie-pavlick/>Ellie Pavlick</a><br><a href=/volumes/2021.acl-short/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-short--21><div class="card-body p-3 small">A current open question in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> is to what extent language models, which are trained with access only to the form of language, are able to capture the meaning of language. This question is challenging to answer in general, as there is no clear line between <a href=https://en.wikipedia.org/wiki/Meaning_(linguistics)>meaning</a> and <a href=https://en.wikipedia.org/wiki/Theory_of_forms>form</a>, but rather <a href=https://en.wikipedia.org/wiki/Meaning_(linguistics)>meaning</a> constrains <a href=https://en.wikipedia.org/wiki/Theory_of_forms>form</a> in consistent ways. The goal of this study is to offer insights into a narrower but critical subquestion : Under what conditions should we expect that <a href=https://en.wikipedia.org/wiki/Meaning_(linguistics)>meaning</a> and <a href=https://en.wikipedia.org/wiki/Theory_of_forms>form</a> covary sufficiently, such that a language model with access only to <a href=https://en.wikipedia.org/wiki/Theory_of_forms>form</a> might nonetheless succeed in emulating <a href=https://en.wikipedia.org/wiki/Meaning_(linguistics)>meaning</a>? Focusing on several formal languages (propositional logic and a set of programming languages), we generate training corpora using a variety of motivated constraints, and measure a distributional language model&#8217;s ability to differentiate logical symbols (AND, OR, and NOT). Our findings are largely negative : none of our simulated training corpora result in <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> which definitively differentiate meaningfully different symbols (e.g., AND vs. OR), suggesting a limitation to the types of semantic signals that current <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> are able to exploit.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.335.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--335 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.335 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939226 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.335/>Are Undocumented Workers the Same as Illegal Aliens? Disentangling Denotation and Connotation in Vector Spaces<span class=acl-fixed-case>D</span>isentangling Denotation and Connotation in Vector Spaces</a></strong><br><a href=/people/a/albert-webson/>Albert Webson</a>
|
<a href=/people/z/zhizhong-chen/>Zhizhong Chen</a>
|
<a href=/people/c/carsten-eickhoff/>Carsten Eickhoff</a>
|
<a href=/people/e/ellie-pavlick/>Ellie Pavlick</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--335><div class="card-body p-3 small">In <a href=https://en.wikipedia.org/wiki/Politics>politics</a>, <a href=https://en.wikipedia.org/wiki/Neologism>neologisms</a> are frequently invented for partisan objectives. For example, <a href=https://en.wikipedia.org/wiki/Illegal_immigration_to_the_United_States>undocumented workers</a> and illegal aliens refer to the same group of people (i.e., they have the same denotation), but they carry clearly different <a href=https://en.wikipedia.org/wiki/Connotation>connotations</a>. Examples like these have traditionally posed a challenge to reference-based semantic theories and led to increasing acceptance of alternative theories (e.g., Two-Factor Semantics) among philosophers and cognitive scientists. In <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, however, popular pretrained models encode both <a href=https://en.wikipedia.org/wiki/Denotation>denotation</a> and <a href=https://en.wikipedia.org/wiki/Connotation>connotation</a> as one entangled representation. In this study, we propose an adversarial nerual netowrk that decomposes a pretrained representation as independent denotation and connotation representations. For intrinsic interpretability, we show that words with the same denotation but different connotations (e.g., immigrants vs. aliens, estate tax vs. death tax) move closer to each other in denotation space while moving further apart in connotation space. For extrinsic application, we train an <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval system</a> with our disentangled representations and show that the denotation vectors improve the viewpoint diversity of document rankings.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1228.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1228 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1228 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1228.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-1228/>How well do NLI models capture verb veridicality?<span class=acl-fixed-case>NLI</span> models capture verb veridicality?</a></strong><br><a href=/people/a/alexis-ross/>Alexis Ross</a>
|
<a href=/people/e/ellie-pavlick/>Ellie Pavlick</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1228><div class="card-body p-3 small">In natural language inference (NLI), contexts are considered veridical if they allow us to infer that their underlying propositions make true claims about the real world. We investigate whether a state-of-the-art natural language inference model (BERT) learns to make correct inferences about <a href=https://en.wikipedia.org/wiki/Veridicality>veridicality</a> in verb-complement constructions. We introduce an NLI dataset for veridicality evaluation consisting of 1,500 sentence pairs, covering 137 unique verbs. We find that both human and model inferences generally follow theoretical patterns, but exhibit a systematic bias towards assuming that verbs are veridicala bias which is amplified in BERT. We further show that, encouragingly, BERT&#8217;s inferences are sensitive not only to the presence of individual verb types, but also to the syntactic role of the verb, the form of the <a href=https://en.wikipedia.org/wiki/Complement_clause>complement clause</a> (to- vs. that-complements), and <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>negation</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2918.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2918 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2918 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2918/>Using Grounded Word Representations to Study Theories of Lexical Concepts</a></strong><br><a href=/people/d/dylan-ebert/>Dylan Ebert</a>
|
<a href=/people/e/ellie-pavlick/>Ellie Pavlick</a><br><a href=/volumes/W19-29/ class=text-muted>Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2918><div class="card-body p-3 small">The fields of <a href=https://en.wikipedia.org/wiki/Cognitive_science>cognitive science</a> and <a href=https://en.wikipedia.org/wiki/Philosophy>philosophy</a> have proposed many different <a href=https://en.wikipedia.org/wiki/Theory>theories</a> for how humans represent concepts. Multiple such <a href=https://en.wikipedia.org/wiki/Theory>theories</a> are compatible with state-of-the-art NLP methods, and could in principle be operationalized using <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>. We focus on two particularly prominent theoriesClassical Theory and Prototype Theoryin the context of visually-grounded lexical representations. We compare when and how the behavior of <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> based on these theories differs in terms of <a href=https://en.wikipedia.org/wiki/Categorization>categorization</a> and <a href=https://en.wikipedia.org/wiki/Logical_consequence>entailment tasks</a>. Our preliminary results suggest that Classical-based representations perform better for <a href=https://en.wikipedia.org/wiki/Logical_consequence>entailment</a> and Prototype-based representations perform better for <a href=https://en.wikipedia.org/wiki/Categorization>categorization</a>. We discuss plans for additional experiments needed to confirm these initial observations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1334.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1334 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1334 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384776891 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1334" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1334/>Right for the Wrong Reasons : Diagnosing Syntactic Heuristics in Natural Language Inference</a></strong><br><a href=/people/t/tom-mccoy/>Tom McCoy</a>
|
<a href=/people/e/ellie-pavlick/>Ellie Pavlick</a>
|
<a href=/people/t/tal-linzen/>Tal Linzen</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1334><div class="card-body p-3 small">A <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning system</a> can score well on a given test set by relying on <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a> that are effective for frequent example types but break down in more challenging cases. We study this issue within natural language inference (NLI), the task of determining whether one sentence entails another. We hypothesize that statistical NLI models may adopt three fallible syntactic heuristics : the lexical overlap heuristic, the subsequence heuristic, and the constituent heuristic. To determine whether models have adopted these <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a>, we introduce a controlled evaluation set called HANS (Heuristic Analysis for NLI Systems), which contains many examples where the <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a> fail. We find that models trained on MNLI, including BERT, a state-of-the-art model, perform very poorly on <a href=https://en.wikipedia.org/wiki/HANS>HANS</a>, suggesting that they have indeed adopted these <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a>. We conclude that there is substantial room for improvement in NLI systems, and that the HANS dataset can motivate and measure progress in this area.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1452.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1452 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1452 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1452/>BERT Rediscovers the Classical NLP Pipeline<span class=acl-fixed-case>BERT</span> Rediscovers the Classical <span class=acl-fixed-case>NLP</span> Pipeline</a></strong><br><a href=/people/i/ian-tenney/>Ian Tenney</a>
|
<a href=/people/d/dipanjan-das/>Dipanjan Das</a>
|
<a href=/people/e/ellie-pavlick/>Ellie Pavlick</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1452><div class="card-body p-3 small">Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, BERT, and aim to quantify where linguistic information is captured within the <a href=https://en.wikipedia.org/wiki/Neural_network>network</a>. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence : POS tagging, <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a>, NER, semantic roles, then <a href=https://en.wikipedia.org/wiki/Coreference>coreference</a>. Qualitative analysis reveals that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can and often does adjust this <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline</a> dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1007 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/305194062 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1007/>Collecting Diverse Natural Language Inference Problems for Sentence Representation Evaluation</a></strong><br><a href=/people/a/adam-poliak/>Adam Poliak</a>
|
<a href=/people/a/aparajita-haldar/>Aparajita Haldar</a>
|
<a href=/people/r/rachel-rudinger/>Rachel Rudinger</a>
|
<a href=/people/j/j-edward-hu/>J. Edward Hu</a>
|
<a href=/people/e/ellie-pavlick/>Ellie Pavlick</a>
|
<a href=/people/a/aaron-steven-white/>Aaron Steven White</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1007><div class="card-body p-3 small">We present a large-scale collection of diverse natural language inference (NLI) datasets that help provide insight into how well a sentence representation captures distinct types of <a href=https://en.wikipedia.org/wiki/Reason>reasoning</a>. The collection results from recasting 13 existing datasets from 7 semantic phenomena into a common NLI structure, resulting in over half a million labeled context-hypothesis pairs in total. We refer to our <a href=https://en.wikipedia.org/wiki/Collection_(artwork)>collection</a> as the DNC : Diverse Natural Language Inference Collection. The DNC is available online at, and will grow over time as additional resources are recast and added from novel sources.<url>https://www.decomp.net</url>, and will grow over time as additional resources are recast and added from novel sources.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5441.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5441 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5441 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/305194062 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W18-5441/>Collecting Diverse Natural Language Inference Problems for Sentence Representation Evaluation</a></strong><br><a href=/people/a/adam-poliak/>Adam Poliak</a>
|
<a href=/people/a/aparajita-haldar/>Aparajita Haldar</a>
|
<a href=/people/r/rachel-rudinger/>Rachel Rudinger</a>
|
<a href=/people/j/j-edward-hu/>J. Edward Hu</a>
|
<a href=/people/e/ellie-pavlick/>Ellie Pavlick</a>
|
<a href=/people/a/aaron-steven-white/>Aaron Steven White</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a><br><a href=/volumes/W18-54/ class=text-muted>Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5441><div class="card-body p-3 small">We present a large scale collection of diverse natural language inference (NLI) datasets that help provide insight into how well a <a href=https://en.wikipedia.org/wiki/Sentence_processing>sentence representation</a> encoded by a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> captures distinct types of <a href=https://en.wikipedia.org/wiki/Reason>reasoning</a>. The collection results from recasting 13 existing datasets from 7 semantic phenomena into a common NLI structure, resulting in over half a million labeled context-hypothesis pairs in total. Our collection of diverse datasets is available at, and will grow over time as additional resources are recast and added from novel sources.<url>http://www.decomp.net/</url>, and will grow over time as additional resources are recast and added from novel sources.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1192.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1192 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1192 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-1192.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-1192.Datasets.tgz data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1192/>Identifying 1950s American Jazz Musicians : Fine-Grained IsA Extraction via Modifier Composition<span class=acl-fixed-case>A</span>merican Jazz Musicians: Fine-Grained <span class=acl-fixed-case>I</span>s<span class=acl-fixed-case>A</span> Extraction via Modifier Composition</a></strong><br><a href=/people/e/ellie-pavlick/>Ellie Pavlick</a>
|
<a href=/people/m/marius-pasca/>Marius Paşca</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1192><div class="card-body p-3 small">We present a <a href=https://en.wikipedia.org/wiki/Methodology>method</a> for populating <a href=https://en.wikipedia.org/wiki/Class_(set_theory)>fine-grained classes</a> (e.g., 1950s American jazz musicians) with <a href=https://en.wikipedia.org/wiki/Class_(set_theory)>instances</a> (e.g., Charles Mingus). While state-of-the-art methods tend to treat class labels as single lexical units, the proposed <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> considers each of the individual modifiers in the class label relative to the head. An evaluation on the task of reconstructing Wikipedia category pages demonstrates a 10 point increase in <a href=https://en.wikipedia.org/wiki/Analysis_of_covariance>AUC</a>, over a strong baseline relying on widely-used Hearst patterns.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Ellie+Pavlick" title="Search for 'Ellie Pavlick' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/a/aaron-traylor/ class=align-middle>Aaron Traylor</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/roman-feiman/ class=align-middle>Roman Feiman</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/adam-poliak/ class=align-middle>Adam Poliak</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/aparajita-haldar/ class=align-middle>Aparajita Haldar</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/rachel-rudinger/ class=align-middle>Rachel Rudinger</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/j/j-edward-hu/ class=align-middle>J. Edward Hu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/aaron-steven-white/ class=align-middle>Aaron Steven White</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/benjamin-van-durme/ class=align-middle>Benjamin Van Durme</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/albert-webson/ class=align-middle>Albert Webson</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhizhong-chen/ class=align-middle>Zhizhong Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/carsten-eickhoff/ class=align-middle>Carsten Eickhoff</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marius-pasca/ class=align-middle>Marius Pasca</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexis-ross/ class=align-middle>Alexis Ross</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dylan-ebert/ class=align-middle>Dylan Ebert</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tom-mccoy/ class=align-middle>Tom McCoy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tal-linzen/ class=align-middle>Tal Linzen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ian-tenney/ class=align-middle>Ian Tenney</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dipanjan-das/ class=align-middle>Dipanjan Das</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/naloma/ class=align-middle>NALOMA</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>