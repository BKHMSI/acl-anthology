<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Elham Mohammadi - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Elham</span> <span class=font-weight-bold>Mohammadi</span></h2><hr><div class=row><div class=col-lg-9><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-2023.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S19-2023 data-toggle=collapse aria-expanded=false aria-controls=abstract-S19-2023 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-2023/>CLaC Lab at SemEval-2019 Task 3 : Contextual Emotion Detection Using a Combination of Neural Networks and SVM<span class=acl-fixed-case>CL</span>a<span class=acl-fixed-case>C</span> Lab at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2019 Task 3: Contextual Emotion Detection Using a Combination of Neural Networks and <span class=acl-fixed-case>SVM</span></a></strong><br><a href=/people/e/elham-mohammadi/>Elham Mohammadi</a>
|
<a href=/people/h/hessam-amini/>Hessam Amini</a>
|
<a href=/people/l/leila-kosseim/>Leila Kosseim</a><br><a href=/volumes/S19-2/ class=text-muted>Proceedings of the 13th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S19-2023><div class="card-body p-3 small">This paper describes our system at SemEval 2019, Task 3 (EmoContext), which focused on the contextual detection of emotions in a dataset of 3-round dialogues. For our final system, we used a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> with pretrained ELMo word embeddings and POS tags as input, GRUs as hidden units, an attention mechanism to capture representations of the dialogues, and an SVM classifier which used the learned network representations to perform the task of multi-class classification. This system yielded a micro-averaged F1 score of 0.7072 for the three emotion classes, improving the baseline by approximately 12 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3004 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3004/>CLaC at CLPsych 2019 : Fusion of Neural Features and Predicted Class Probabilities for Suicide Risk Assessment Based on Online Posts<span class=acl-fixed-case>CL</span>a<span class=acl-fixed-case>C</span> at <span class=acl-fixed-case>CLP</span>sych 2019: Fusion of Neural Features and Predicted Class Probabilities for Suicide Risk Assessment Based on Online Posts</a></strong><br><a href=/people/e/elham-mohammadi/>Elham Mohammadi</a>
|
<a href=/people/h/hessam-amini/>Hessam Amini</a>
|
<a href=/people/l/leila-kosseim/>Leila Kosseim</a><br><a href=/volumes/W19-30/ class=text-muted>Proceedings of the Sixth Workshop on Computational Linguistics and Clinical Psychology</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3004><div class="card-body p-3 small">This paper summarizes our participation to the CLPsych 2019 shared task, under the name CLaC. The goal of the shared task was to detect and assess suicide risk based on a collection of online posts. For our participation, we used an <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble method</a> which utilizes 8 neural sub-models to extract neural features and predict class probabilities, which are then used by an SVM classifier. Our team ranked first in 2 out of the 3 <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> (tasks A and C).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1091.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1091 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1091 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1091/>Neural Feature Extraction for Contextual Emotion Detection</a></strong><br><a href=/people/e/elham-mohammadi/>Elham Mohammadi</a>
|
<a href=/people/h/hessam-amini/>Hessam Amini</a>
|
<a href=/people/l/leila-kosseim/>Leila Kosseim</a><br><a href=/volumes/R19-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1091><div class="card-body p-3 small">This paper describes a new approach for the task of contextual emotion detection. The approach is based on a neural feature extractor, composed of a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network</a> with an <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanism</a>, followed by a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a>, that can be neural or SVM-based. We evaluated the model with the dataset of the task 3 of SemEval 2019 (EmoContext), which includes short 3-turn conversations, tagged with 4 emotion classes. The best performing setup was achieved using ELMo word embeddings and POS tags as input, bidirectional GRU as hidden units, and an <a href=https://en.wikipedia.org/wiki/Symmetric_multiprocessing>SVM</a> as the final classifier. This configuration reached 69.93 % in terms of micro-average F1 score on the main 3 emotion classes, a score that outperformed the baseline system by 11.25 %.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5022.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5022 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5022 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-5022.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W17-5022/>Native Language Identification Using a Mixture of Character and Word N-grams</a></strong><br><a href=/people/e/elham-mohammadi/>Elham Mohammadi</a>
|
<a href=/people/h/hadi-veisi/>Hadi Veisi</a>
|
<a href=/people/h/hessam-amini/>Hessam Amini</a><br><a href=/volumes/W17-50/ class=text-muted>Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5022><div class="card-body p-3 small">Native language identification (NLI) is the task of determining an author&#8217;s native language, based on a piece of his / her writing in a second language. In recent years, NLI has received much attention due to its challenging nature and its applications in <a href=https://en.wikipedia.org/wiki/Language_pedagogy>language pedagogy</a> and <a href=https://en.wikipedia.org/wiki/Forensic_linguistics>forensic linguistics</a>. We participated in the NLI2017 shared task under the name UT-DSP. In our effort to implement a method for <a href=https://en.wikipedia.org/wiki/Native-language_identification>native language identification</a>, we made use of a fusion of character and word N-grams, and achieved an optimal <a href=https://en.wikipedia.org/wiki/F-number>F1-Score</a> of 77.64 %, using both essay and speech transcription datasets.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Elham+Mohammadi" title="Search for 'Elham Mohammadi' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/h/hessam-amini/ class=align-middle>Hessam Amini</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/l/leila-kosseim/ class=align-middle>Leila Kosseim</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/h/hadi-veisi/ class=align-middle>Hadi Veisi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ranlp/ class=align-middle>RANLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>