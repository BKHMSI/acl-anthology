<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Ekaterina Shutova - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Ekaterina</span> <span class=font-weight-bold>Shutova</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.409.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--409 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.409 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.409/>Meta-Learning with Variational Semantic Memory for Word Sense Disambiguation</a></strong><br><a href=/people/y/yingjun-du/>Yingjun Du</a>
|
<a href=/people/n/nithin-holla/>Nithin Holla</a>
|
<a href=/people/x/xiantong-zhen/>Xiantong Zhen</a>
|
<a href=/people/c/cees-snoek/>Cees Snoek</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--409><div class="card-body p-3 small">A critical challenge faced by supervised word sense disambiguation (WSD) is the lack of large annotated datasets with sufficient coverage of words in their diversity of senses. This inspired recent research on few-shot WSD using <a href=https://en.wikipedia.org/wiki/Meta-learning>meta-learning</a>. While such work has successfully applied <a href=https://en.wikipedia.org/wiki/Meta-learning>meta-learning</a> to learn new word senses from very few examples, its performance still lags behind its fully-supervised counterpart. Aiming to further close this gap, we propose a model of <a href=https://en.wikipedia.org/wiki/Semantic_memory>semantic memory</a> for WSD in a meta-learning setting. Semantic memory encapsulates prior experiences seen throughout the lifetime of the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>, which aids better <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a> in limited data settings. Our model is based on hierarchical variational inference and incorporates an adaptive memory update rule via a hypernetwork. We show our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> advances the state of the art in few-shot WSD, supports effective <a href=https://en.wikipedia.org/wiki/Machine_learning>learning</a> in extremely data scarce (e.g. one-shot) scenarios and produces meaning prototypes that capture similar senses of distinct words.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.111.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--111 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.111 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.111/>Stepmothers are mean and academics are pretentious : What do pretrained language models learn about you?</a></strong><br><a href=/people/r/rochelle-choenni/>Rochelle Choenni</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a>
|
<a href=/people/r/robert-van-rooij/>Robert van Rooij</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--111><div class="card-body p-3 small">In this paper, we investigate what types of <a href=https://en.wikipedia.org/wiki/Stereotypes_of_East_Asians_in_the_United_States>stereotypical information</a> are captured by pretrained language models. We present the first dataset comprising stereotypical attributes of a range of social groups and propose a method to elicit <a href=https://en.wikipedia.org/wiki/Stereotype>stereotypes</a> encoded by pretrained language models in an unsupervised fashion. Moreover, we link the emergent stereotypes to their manifestation as basic emotions as a means to study their emotional effects in a more generalized manner. To demonstrate how our methods can be used to analyze emotion and stereotype shifts due to linguistic experience, we use <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> on news sources as a case study. Our experiments expose how attitudes towards different social groups vary across models and how quickly emotions and stereotypes can shift at the fine-tuning stage.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.394.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--394 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.394 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929125 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.394/>Joint Modelling of Emotion and Abusive Language Detection</a></strong><br><a href=/people/s/santhosh-rajamanickam/>Santhosh Rajamanickam</a>
|
<a href=/people/p/pushkar-mishra/>Pushkar Mishra</a>
|
<a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--394><div class="card-body p-3 small">The rise of online communication platforms has been accompanied by some undesirable effects, such as the proliferation of aggressive and abusive behaviour online. Aiming to tackle this problem, the natural language processing (NLP) community has experimented with a range of techniques for abuse detection. While achieving substantial success, these methods have so far only focused on modelling the linguistic properties of the comments and the online communities of users, disregarding the emotional state of the users and how this might affect their language. The latter is, however, inextricably linked to <a href=https://en.wikipedia.org/wiki/Abusive_power_and_control>abusive behaviour</a>. In this paper, we present the first joint model of emotion and abusive language detection, experimenting in a multi-task learning framework that allows one task to inform the other. Our results demonstrate that incorporating <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>affective features</a> leads to significant improvements in abuse detection performance across datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.figlang-1.0/>Proceedings of the Second Workshop on Figurative Language Processing</a></strong><br><a href=/people/b/beata-beigman-klebanov/>Beata Beigman Klebanov</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a>
|
<a href=/people/p/patricia-lichtenstein/>Patricia Lichtenstein</a>
|
<a href=/people/s/smaranda-muresan/>Smaranda Muresan</a>
|
<a href=/people/c/chee-wee/>Chee Wee</a>
|
<a href=/people/a/anna-feldman/>Anna Feldman</a>
|
<a href=/people/d/debanjan-ghosh/>Debanjan Ghosh</a><br><a href=/volumes/2020.figlang-1/ class=text-muted>Proceedings of the Second Workshop on Figurative Language Processing</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.semeval-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.semeval-1.0/>Proceedings of the Fourteenth Workshop on Semantic Evaluation</a></strong><br><a href=/people/a/aurelie-herbelot/>Aurelie Herbelot</a>
|
<a href=/people/x/xiaodan-zhu/>Xiaodan Zhu</a>
|
<a href=/people/a/alexis-palmer/>Alexis Palmer</a>
|
<a href=/people/n/nathan-schneider/>Nathan Schneider</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a><br><a href=/volumes/2020.semeval-1/ class=text-muted>Proceedings of the Fourteenth Workshop on Semantic Evaluation</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1227.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1227 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1227 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1227/>Modelling the interplay of <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a> and <a href=https://en.wikipedia.org/wiki/Emotion>emotion</a> through <a href=https://en.wikipedia.org/wiki/Multitask_learning>multitask learning</a></a></strong><br><a href=/people/v/verna-dankers/>Verna Dankers</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/m/martha-lewis/>Martha Lewis</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1227><div class="card-body p-3 small">Metaphors allow us to convey <a href=https://en.wikipedia.org/wiki/Emotion>emotion</a> by connecting <a href=https://en.wikipedia.org/wiki/Experience>physical experiences</a> and <a href=https://en.wikipedia.org/wiki/Abstraction>abstract concepts</a>. The results of previous research in <a href=https://en.wikipedia.org/wiki/Linguistics>linguistics</a> and <a href=https://en.wikipedia.org/wiki/Psychology>psychology</a> suggest that metaphorical phrases tend to be more emotionally evocative than their literal counterparts. In this paper, we investigate the relationship between <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a> and <a href=https://en.wikipedia.org/wiki/Emotion>emotion</a> within a <a href=https://en.wikipedia.org/wiki/Software_framework>computational framework</a>, by proposing the first joint model of these <a href=https://en.wikipedia.org/wiki/Phenomenon>phenomena</a>. We experiment with several multitask learning architectures for this purpose, involving both hard and soft parameter sharing. Our results demonstrate that metaphor identification and emotion prediction mutually benefit from joint learning and our models advance the state of the art in both of these tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-1000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-1000/>Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*<span class=acl-fixed-case>SEM</span> 2019)</a></strong><br><a href=/people/r/rada-mihalcea/>Rada Mihalcea</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a>
|
<a href=/people/l/lun-wei-ku/>Lun-Wei Ku</a>
|
<a href=/people/k/kilian-evang/>Kilian Evang</a>
|
<a href=/people/s/soujanya-poria/>Soujanya Poria</a><br><a href=/volumes/S19-1/ class=text-muted>Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-1013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S19-1013 data-toggle=collapse aria-expanded=false aria-controls=abstract-S19-1013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-1013/>Deconstructing <a href=https://en.wikipedia.org/wiki/Multimodality>multimodality</a> : <a href=https://en.wikipedia.org/wiki/Visual_system>visual properties</a> and <a href=https://en.wikipedia.org/wiki/Context_(language_use)>visual context</a> in human semantic processing</a></strong><br><a href=/people/c/christopher-davis/>Christopher Davis</a>
|
<a href=/people/l/luana-bulat/>Luana Bulat</a>
|
<a href=/people/a/anita-lilla-vero/>Anita Lilla Vero</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a><br><a href=/volumes/S19-1/ class=text-muted>Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S19-1013><div class="card-body p-3 small">Multimodal semantic models that extend linguistic representations with additional perceptual input have proved successful in a range of natural language processing (NLP) tasks. Recent research has successfully used <a href=https://en.wikipedia.org/wiki/Artificial_neural_network>neural methods</a> to automatically create <a href=https://en.wikipedia.org/wiki/Mental_image>visual representations</a> for words. However, these works have extracted visual features from complete images, and have not examined how different kinds of visual information impact performance. In contrast, we construct multimodal models that differentiate between internal visual properties of the objects and their external visual context. We evaluate the models on the task of decoding brain activity associated with the meanings of nouns, demonstrating their advantage over those based on complete images.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-2000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-2000/>Proceedings of the 13th International Workshop on Semantic Evaluation</a></strong><br><a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a>
|
<a href=/people/a/aurelie-herbelot/>Aurelie Herbelot</a>
|
<a href=/people/x/xiaodan-zhu/>Xiaodan Zhu</a>
|
<a href=/people/m/marianna-apidianaki/>Marianna Apidianaki</a>
|
<a href=/people/s/saif-mohammad/>Saif M. Mohammad</a><br><a href=/volumes/S19-2/ class=text-muted>Proceedings of the 13th International Workshop on Semantic Evaluation</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1221.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1221 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1221 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/355811189 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-1221/>Abusive Language Detection with Graph Convolutional Networks<span class=acl-fixed-case>A</span>busive <span class=acl-fixed-case>L</span>anguage <span class=acl-fixed-case>D</span>etection with <span class=acl-fixed-case>G</span>raph <span class=acl-fixed-case>C</span>onvolutional <span class=acl-fixed-case>N</span>etworks</a></strong><br><a href=/people/p/pushkar-mishra/>Pushkar Mishra</a>
|
<a href=/people/m/marco-del-tredici/>Marco Del Tredici</a>
|
<a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1221><div class="card-body p-3 small">Abuse on the <a href=https://en.wikipedia.org/wiki/Internet>Internet</a> represents a significant societal problem of our time. Previous research on automated abusive language detection in <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> has shown that community-based profiling of users is a promising technique for this task. However, existing approaches only capture shallow properties of online communities by modeling followerfollowing relationships. In contrast, working with graph convolutional networks (GCNs), we present the first approach that captures not only the structure of online communities but also the linguistic behavior of the users within them. We show that such a heterogeneous graph-structured modeling of communities significantly advances the current state of the art in abusive language detection.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1000/>Proceedings of The 12th International Workshop on Semantic Evaluation</a></strong><br><a href=/people/m/marianna-apidianaki/>Marianna Apidianaki</a>
|
<a href=/people/s/saif-mohammad/>Saif M. Mohammad</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a>
|
<a href=/people/s/steven-bethard/>Steven Bethard</a>
|
<a href=/people/m/marine-carpuat/>Marine Carpuat</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-0900.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-0900/>Proceedings of the Workshop on Figurative Language Processing</a></strong><br><a href=/people/b/beata-beigman-klebanov/>Beata Beigman Klebanov</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a>
|
<a href=/people/p/patricia-lichtenstein/>Patricia Lichtenstein</a>
|
<a href=/people/s/smaranda-muresan/>Smaranda Muresan</a>
|
<a href=/people/c/chee-wee/>Chee Wee</a><br><a href=/volumes/W18-09/ class=text-muted>Proceedings of the Workshop on Figurative Language Processing</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-0907.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-0907 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-0907 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-0907/>A Report on the 2018 VUA Metaphor Detection Shared Task<span class=acl-fixed-case>VUA</span> Metaphor Detection Shared Task</a></strong><br><a href=/people/c/chee-wee-leong/>Chee Wee (Ben) Leong</a>
|
<a href=/people/b/beata-beigman-klebanov/>Beata Beigman Klebanov</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a><br><a href=/volumes/W18-09/ class=text-muted>Proceedings of the Workshop on Figurative Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-0907><div class="card-body p-3 small">As the community working on computational approaches to <a href=https://en.wikipedia.org/wiki/Figurative_language>figurative language</a> is growing and as methods and data become increasingly diverse, it is important to create widely shared empirical knowledge of the level of system performance in a range of contexts, thus facilitating progress in this area. One way of creating such shared knowledge is through benchmarking multiple systems on a common dataset. We report on the shared task on metaphor identification on the VU Amsterdam Metaphor Corpus conducted at the NAACL 2018 Workshop on Figurative Language Processing.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5033.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5033 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5033 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5033/>Modelling semantic acquisition in second language learning</a></strong><br><a href=/people/e/ekaterina-kochmar/>Ekaterina Kochmar</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a><br><a href=/volumes/W17-50/ class=text-muted>Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5033><div class="card-body p-3 small">Using methods of <a href=https://en.wikipedia.org/wiki/Statistical_inference>statistical analysis</a>, we investigate how semantic knowledge is acquired in <a href=https://en.wikipedia.org/wiki/English_language>English</a> as a second language and evaluate the pace of development across a number of predicate types and content word combinations, as well as across the levels of language proficiency and native languages. Our exploratory study helps identify the most problematic areas for <a href=https://en.wikipedia.org/wiki/Language_acquisition>language learners</a> with different backgrounds and at different stages of learning.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/J17-1003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-J17-1003 data-toggle=collapse aria-expanded=false aria-controls=abstract-J17-1003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/J17-1003/>Multilingual Metaphor Processing : Experiments with Semi-Supervised and Unsupervised Learning</a></strong><br><a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a>
|
<a href=/people/l/lin-sun/>Lin Sun</a>
|
<a href=/people/e/e-dario-gutierrez/>Elkin Darío Gutiérrez</a>
|
<a href=/people/p/patricia-lichtenstein/>Patricia Lichtenstein</a>
|
<a href=/people/s/srini-narayanan/>Srini Narayanan</a><br><a href=/volumes/J17-1/ class=text-muted>Computational Linguistics, Volume 43, Issue 1 - April 2017</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-J17-1003><div class="card-body p-3 small">Highly frequent in language and communication, <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a> represents a significant challenge for Natural Language Processing (NLP) applications. Computational work on <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a> has traditionally evolved around the use of hand-coded knowledge, making the <a href=https://en.wikipedia.org/wiki/System>systems</a> hard to scale. Recent years have witnessed a rise in <a href=https://en.wikipedia.org/wiki/Statistics>statistical approaches</a> to metaphor processing. However, these approaches often require extensive human annotation effort and are predominantly evaluated within a <a href=https://en.wikipedia.org/wiki/Domain_(biology)>limited domain</a>. In contrast, we experiment with weakly supervised and unsupervised techniqueswith little or no annotationto generalize higher-level mechanisms of metaphor from distributional properties of concepts. We investigate different levels and types of <a href=https://en.wikipedia.org/wiki/Supervisor>supervision</a> (learning from linguistic examples vs. learning from a given set of metaphorical mappings vs. learning without annotation) in flat and hierarchical, unconstrained and constrained clustering settings. Our aim is to identify the optimal type of <a href=https://en.wikipedia.org/wiki/Supervisor>supervision</a> for a <a href=https://en.wikipedia.org/wiki/Machine_learning>learning algorithm</a> that discovers patterns of metaphorical association from <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text</a>. In order to investigate the scalability and adaptability of our models, we applied them to data in three languages from different language groupsEnglish, Spanish, and Russianachieving state-of-the-art results with little supervision. Finally, we demonstrate that <a href=https://en.wikipedia.org/wiki/Statistics>statistical methods</a> can facilitate and scale up cross-linguistic research on <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-1018.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-1018 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-1018 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-1018/>Semantic Frames and Visual Scenes : Learning Semantic Role Inventories from Image and Video Descriptions</a></strong><br><a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a>
|
<a href=/people/a/andreas-wundsam/>Andreas Wundsam</a>
|
<a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a><br><a href=/volumes/S17-1/ class=text-muted>Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-1018><div class="card-body p-3 small">Frame-semantic parsing and semantic role labelling, that aim to automatically assign semantic roles to arguments of verbs in a sentence, have become an active strand of research in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. However, to date these methods have relied on a predefined inventory of semantic roles. In this paper, we present a method to automatically learn argument role inventories for verbs from large corpora of text, images and videos. We evaluate the method against manually constructed role inventories in <a href=https://en.wikipedia.org/wiki/FrameNet>FrameNet</a> and show that the <a href=https://en.wikipedia.org/wiki/Visual_model>visual model</a> outperforms the language-only model and operates with a high <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1113.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1113 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1113 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238235824 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1113/>Speaking, Seeing, Understanding : Correlating semantic models with conceptual representation in the brain</a></strong><br><a href=/people/l/luana-bulat/>Luana Bulat</a>
|
<a href=/people/s/stephen-clark/>Stephen Clark</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1113><div class="card-body p-3 small">Research in <a href=https://en.wikipedia.org/wiki/Computational_semantics>computational semantics</a> is increasingly guided by our understanding of human semantic processing. However, semantic models are typically studied in the context of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing system</a> performance. In this paper, we present a systematic evaluation and comparison of a range of widely-used, state-of-the-art semantic models in their ability to predict patterns of conceptual representation in the human brain. Our results provide new insights both for the design of computational semantic models and for further research in <a href=https://en.wikipedia.org/wiki/Cognitive_neuroscience>cognitive neuroscience</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1162.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1162 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1162 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238233405 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1162/>Grasping the Finer Point : A Supervised Similarity Network for Metaphor Detection</a></strong><br><a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/l/luana-bulat/>Luana Bulat</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1162><div class="card-body p-3 small">The ubiquity of <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a> in our everyday communication makes <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> an important problem for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a>. Yet, the majority of metaphor processing systems to date rely on hand-engineered features and there is still no consensus in the field as to which features are optimal for this task. In this paper, we present the first deep learning architecture designed to capture metaphorical composition. Our results demonstrate that <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> outperforms the existing <a href=https://en.wikipedia.org/wiki/Psychological_evaluation>approaches</a> in the metaphor identification task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-2084.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-2084 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-2084 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-2084/>Modelling metaphor with attribute-based semantics</a></strong><br><a href=/people/l/luana-bulat/>Luana Bulat</a>
|
<a href=/people/s/stephen-clark/>Stephen Clark</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a><br><a href=/volumes/E17-2/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-2084><div class="card-body p-3 small">One of the key problems in computational metaphor modelling is finding the optimal level of abstraction of semantic representations, such that these are able to capture and generalise metaphorical mechanisms. In this paper we present the first metaphor identification method that uses <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representations</a> constructed from <a href=https://en.wikipedia.org/wiki/Norm_(philosophy)>property norms</a>. Such <a href=https://en.wikipedia.org/wiki/Social_norm>norms</a> have been previously shown to provide a cognitively plausible representation of concepts in terms of <a href=https://en.wikipedia.org/wiki/Semantics>semantic properties</a>. Our results demonstrate that such property-based semantic representations provide a suitable model of cross-domain knowledge projection in metaphors, outperforming standard distributional models on a metaphor identification task.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Ekaterina+Shutova" title="Search for 'Ekaterina Shutova' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/l/luana-bulat/ class=align-middle>Luana Bulat</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/h/helen-yannakoudakis/ class=align-middle>Helen Yannakoudakis</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/p/patricia-lichtenstein/ class=align-middle>Patricia Lichtenstein</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/b/beata-beigman-klebanov/ class=align-middle>Beata Beigman Klebanov</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/jonathan-may/ class=align-middle>Jonathan May</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/p/pushkar-mishra/ class=align-middle>Pushkar Mishra</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/smaranda-muresan/ class=align-middle>Smaranda Muresan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/chee-wee/ class=align-middle>Chee Wee</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/aurelie-herbelot/ class=align-middle>Aurélie Herbelot</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/x/xiaodan-zhu/ class=align-middle>Xiaodan Zhu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/marek-rei/ class=align-middle>Marek Rei</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/stephen-clark/ class=align-middle>Stephen Clark</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/marianna-apidianaki/ class=align-middle>Marianna Apidianaki</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/saif-mohammad/ class=align-middle>Saif Mohammad</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yingjun-du/ class=align-middle>Yingjun Du</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nithin-holla/ class=align-middle>Nithin Holla</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiantong-zhen/ class=align-middle>Xiantong Zhen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cees-snoek/ class=align-middle>Cees Snoek</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/santhosh-rajamanickam/ class=align-middle>Santhosh Rajamanickam</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/ekaterina-kochmar/ class=align-middle>Ekaterina Kochmar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lin-sun/ class=align-middle>Lin Sun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/e-dario-gutierrez/ class=align-middle>E. Dario Gutierrez</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/srini-narayanan/ class=align-middle>Srini Narayanan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anna-feldman/ class=align-middle>Anna Feldman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/debanjan-ghosh/ class=align-middle>Debanjan Ghosh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rochelle-choenni/ class=align-middle>Rochelle Choenni</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/robert-van-rooij/ class=align-middle>Robert van Rooij</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexis-palmer/ class=align-middle>Alexis Palmer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nathan-schneider/ class=align-middle>Nathan Schneider</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/verna-dankers/ class=align-middle>Verna Dankers</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/martha-lewis/ class=align-middle>Martha Lewis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andreas-wundsam/ class=align-middle>Andreas Wundsam</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/douwe-kiela/ class=align-middle>Douwe Kiela</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rada-mihalcea/ class=align-middle>Rada Mihalcea</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lun-wei-ku/ class=align-middle>Lun-Wei Ku</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kilian-evang/ class=align-middle>Kilian Evang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/soujanya-poria/ class=align-middle>Soujanya Poria</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christopher-davis/ class=align-middle>Christopher Davis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anita-lilla-vero/ class=align-middle>Anita Lilla Verő</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/steven-bethard/ class=align-middle>Steven Bethard</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marine-carpuat/ class=align-middle>Marine Carpuat</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chee-wee-leong/ class=align-middle>Chee Wee Leong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marco-del-tredici/ class=align-middle>Marco Del Tredici</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/cl/ class=align-middle>CL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/figlang/ class=align-middle>Fig-Lang</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>