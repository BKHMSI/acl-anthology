<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Ellen Riloff - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Ellen</span> <span class=font-weight-bold>Riloff</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-main.206.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-main--206 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-main.206 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.eacl-main.206" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-main.206/>Exploiting Definitions for Frame Identification</a></strong><br><a href=/people/t/tianyu-jiang/>Tianyu Jiang</a>
|
<a href=/people/e/ellen-riloff/>Ellen Riloff</a><br><a href=/volumes/2021.eacl-main/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-main--206><div class="card-body p-3 small">Frame identification is one of the key challenges for frame-semantic parsing. The goal of this task is to determine which <a href=https://en.wikipedia.org/wiki/Film_frame>frame</a> best captures the meaning of a target word or phrase in a sentence. We present a new model for frame identification that uses a pre-trained transformer model to generate representations for frames and lexical units (senses) using their formal definitions in <a href=https://en.wikipedia.org/wiki/FrameNet>FrameNet</a>. Our <a href=https://en.wikipedia.org/wiki/Framing_(social_sciences)>frame identification model</a> assesses the suitability of a <a href=https://en.wikipedia.org/wiki/Framing_(social_sciences)>frame</a> for a target word in a sentence based on the semantic coherence of their meanings. We evaluate our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on three data sets and show that <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> consistently achieves better performance than previous <a href=https://en.wikipedia.org/wiki/System>systems</a>.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.41.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--41 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.41 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928672 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.41/>Exploring the Role of <a href=https://en.wikipedia.org/wiki/Context_(language_use)>Context</a> to Distinguish Rhetorical and Information-Seeking Questions</a></strong><br><a href=/people/y/yuan-zhuang/>Yuan Zhuang</a>
|
<a href=/people/e/ellen-riloff/>Ellen Riloff</a><br><a href=/volumes/2020.acl-srw/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--41><div class="card-body p-3 small">Social media posts often contain questions, but many of the questions are rhetorical and do not seek information. Our work studies the problem of distinguishing rhetorical and information-seeking questions on <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>. Most work has focused on <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> of the question itself, but we hypothesize that the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>prior context</a> plays a role too. This paper introduces a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> containing questions in tweets paired with their prior tweets to provide context. We create classification models to assess the difficulty of distinguishing rhetorical and information-seeking questions, and experiment with different properties of the prior context. Our results show that the prior tweet and topic features can improve performance on this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.20.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--20 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.20 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929717 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.20/>Recognizing Euphemisms and Dysphemisms Using <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a></a></strong><br><a href=/people/c/christian-felt/>Christian Felt</a>
|
<a href=/people/e/ellen-riloff/>Ellen Riloff</a><br><a href=/volumes/2020.figlang-1/ class=text-muted>Proceedings of the Second Workshop on Figurative Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--20><div class="card-body p-3 small">This paper presents the first research aimed at recognizing euphemistic and dysphemistic phrases with <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. Euphemisms soften references to topics that are sensitive, disagreeable, or taboo. Conversely, <a href=https://en.wikipedia.org/wiki/Dysphemism>dysphemisms</a> refer to sensitive topics in a harsh or rude way. For example, passed away and departed are <a href=https://en.wikipedia.org/wiki/Euphemism>euphemisms</a> for death, while croaked and six feet under are <a href=https://en.wikipedia.org/wiki/Dysphemism>dysphemisms</a> for death. Our work explores the use of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> to recognize euphemistic and dysphemistic language. First, we identify near-synonym phrases for three topics (firing, lying, and stealing) using a bootstrapping algorithm for semantic lexicon induction. Next, we classify phrases as <a href=https://en.wikipedia.org/wiki/Euphemism>euphemistic</a>, dysphemistic, or neutral using <a href=https://en.wikipedia.org/wiki/Lexical_analysis>lexical sentiment cues</a> and contextual sentiment analysis. We introduce a new gold standard data set and present our experimental results for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-1022.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S19-1022 data-toggle=collapse aria-expanded=false aria-controls=abstract-S19-1022 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-1022/>Improving Human Needs Categorization of Events with Semantic Classification</a></strong><br><a href=/people/h/haibo-ding/>Haibo Ding</a>
|
<a href=/people/e/ellen-riloff/>Ellen Riloff</a>
|
<a href=/people/z/zhe-feng/>Zhe Feng</a><br><a href=/volumes/S19-1/ class=text-muted>Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S19-1022><div class="card-body p-3 small">Human Needs categories have been used to characterize the reason why an <a href=https://en.wikipedia.org/wiki/Affect_(psychology)>affective event</a> is positive or negative. For example, I got the flu and I got fired are both negative (undesirable) events, but getting the flu is a Health problem while getting fired is a Financial problem. Previous work created learning models to assign <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>events</a> to Human Needs categories based on their words and contexts. In this paper, we introduce an intermediate step that assigns words to relevant semantic concepts. We create lightly supervised models that learn to label words with respect to 10 semantic concepts associated with Human Needs categories, and incorporate these labels as features for event categorization. Our results show that recognizing relevant semantic concepts improves both the <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a> and <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> of Human Needs categorization for <a href=https://en.wikipedia.org/wiki/Event_(philosophy)>events</a>.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1000/>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></strong><br><a href=/people/e/ellen-riloff/>Ellen Riloff</a>
|
<a href=/people/d/david-chiang/>David Chiang</a>
|
<a href=/people/j/julia-hockenmaier/>Julia Hockenmaier</a>
|
<a href=/people/j/junichi-tsujii/>Jun’ichi Tsujii</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6201.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6201 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6201 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6201/>Identifying Affective Events and the Reasons for their Polarity</a></strong><br><a href=/people/e/ellen-riloff/>Ellen Riloff</a><br><a href=/volumes/W18-62/ class=text-muted>Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6201><div class="card-body p-3 small">Many events have a positive or negative impact on our lives (e.g., I bought a house is typically good news, but My house burned down is bad news). Recognizing events that have affective polarity is essential for narrative text understanding, conversational dialogue, and applications such as <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> and sarcasm detection. We will discuss our recent work on identifying <a href=https://en.wikipedia.org/wiki/Affect_(psychology)>affective events</a> and categorizing them based on the underlying reasons for their <a href=https://en.wikipedia.org/wiki/Affect_(psychology)>affective polarity</a>. First, we will describe a weakly supervised learning method to induce a large set of <a href=https://en.wikipedia.org/wiki/Event_(philosophy)>affective events</a> from a <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpus</a> by optimizing for semantic consistency. Second, we will present models to classify affective events based on Human Need Categories, which often explain people&#8217;s motivations and desires. Our best results use a co-training model that consists of event expression and event context classifiers and exploits both labeled and unlabeled texts. We will conclude with a discussion of interesting directions for future work in this area.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1174.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1174 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1174 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277671591 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1174/>Human Needs Categorization of Affective Events Using Labeled and Unlabeled Data</a></strong><br><a href=/people/h/haibo-ding/>Haibo Ding</a>
|
<a href=/people/e/ellen-riloff/>Ellen Riloff</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1174><div class="card-body p-3 small">We often talk about events that impact us positively or negatively. For example I got a job is good news, but I lost my job is bad news. When we discuss an event, we not only understand its <a href=https://en.wikipedia.org/wiki/Affect_(psychology)>affective polarity</a> but also the reason why the event is beneficial or detrimental. For example, getting or losing a job has affective polarity primarily because it impacts us financially. Our work aims to categorize affective events based upon human need categories that often explain people&#8217;s motivations and desires : PHYSIOLOGICAL, HEALTH, LEISURE, SOCIAL, FINANCIAL, COGNITION, and FREEDOM. We create classification models based on event expressions as well as <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that use contexts surrounding event mentions. We also design a co-training model that learns from unlabeled data by simultaneously training event expression and event context classifiers in an iterative learning process. Our results show that <a href=https://en.wikipedia.org/wiki/Co-training>co-training</a> performs well, producing substantially better results than the individual <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1120.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1120 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1120 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285803482 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1120/>Learning Prototypical Goal Activities for Locations</a></strong><br><a href=/people/t/tianyu-jiang/>Tianyu Jiang</a>
|
<a href=/people/e/ellen-riloff/>Ellen Riloff</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1120><div class="card-body p-3 small">People go to different places to engage in activities that reflect their goals. For example, people go to restaurants to eat, libraries to study, and churches to pray. We refer to an activity that represents a common reason why people typically go to a location as a prototypical goal activity (goal-act). Our research aims to learn goal-acts for specific locations using a <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpus</a> and <a href=https://en.wikipedia.org/wiki/Semi-supervised_learning>semi-supervised learning</a>. First, we extract activities and locations that co-occur in goal-oriented syntactic patterns. Next, we create an activity profile matrix and apply a semi-supervised label propagation algorithm to iteratively revise the activity strengths for different locations using a small set of labeled data. We show that this approach outperforms several baseline methods when judged against goal-acts identified by human annotators.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Ellen+Riloff" title="Search for 'Ellen Riloff' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/t/tianyu-jiang/ class=align-middle>Tianyu Jiang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/haibo-ding/ class=align-middle>Haibo Ding</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yuan-zhuang/ class=align-middle>Yuan Zhuang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/david-chiang/ class=align-middle>David Chiang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/julia-hockenmaier/ class=align-middle>Julia Hockenmaier</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/j/junichi-tsujii/ class=align-middle>Jun’ichi Tsujii</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christian-felt/ class=align-middle>Christian Felt</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhe-feng/ class=align-middle>Zhe Feng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/figlang/ class=align-middle>Fig-Lang</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>