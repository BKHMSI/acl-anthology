<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Khyathi Chandu - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Khyathi</span> <span class=font-weight-bold>Chandu</span></h2><hr><div class=row><div class=col-lg-9><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1606.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1606 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1606 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1606/>Storyboarding of Recipes : Grounded Contextual Generation</a></strong><br><a href=/people/k/khyathi-chandu/>Khyathi Chandu</a>
|
<a href=/people/e/eric-nyberg/>Eric Nyberg</a>
|
<a href=/people/a/alan-w-black/>Alan W Black</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1606><div class="card-body p-3 small">Information need of humans is essentially multimodal in nature, enabling maximum exploitation of situated context. We introduce a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for sequential procedural (how-to) text generation from images in cooking domain. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> consists of 16,441 cooking recipes with 160,479 photos associated with different steps. We setup a baseline motivated by the best performing model in terms of human evaluation for the Visual Story Telling (ViST) task. In addition, we introduce two models to incorporate high level structure learnt by a Finite State Machine (FSM) in neural sequential generation process by : (1) Scaffolding Structure in Decoder (SSiD) (2) Scaffolding Structure in Loss (SSiL). Our best performing <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> (SSiL) achieves a <a href=https://en.wikipedia.org/wiki/METEOR>METEOR score</a> of 0.31, which is an improvement of 0.6 over the baseline model. We also conducted human evaluation of the generated grounded recipes, which reveal that 61 % found that our proposed (SSiL) model is better than the baseline model in terms of overall recipes. We also discuss analysis of the output highlighting key important NLP issues for prospective directions.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-2610.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-2610 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-2610 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-2610/>Comparative Analysis of Neural QA models on SQuAD<span class=acl-fixed-case>QA</span> models on <span class=acl-fixed-case>SQ</span>u<span class=acl-fixed-case>AD</span></a></strong><br><a href=/people/s/soumya-wadhwa/>Soumya Wadhwa</a>
|
<a href=/people/k/khyathi-chandu/>Khyathi Chandu</a>
|
<a href=/people/e/eric-nyberg/>Eric Nyberg</a><br><a href=/volumes/W18-26/ class=text-muted>Proceedings of the Workshop on Machine Reading for Question Answering</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-2610><div class="card-body p-3 small">The task of <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a> has gained prominence in the past few decades for testing the ability of machines to understand <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. Large datasets for <a href=https://en.wikipedia.org/wiki/Machine_reading>Machine Reading</a> have led to the development of neural models that cater to deeper language understanding compared to <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval tasks</a>. Different <a href=https://en.wikipedia.org/wiki/Component-based_software_engineering>components</a> in these neural architectures are intended to tackle different challenges. As a first step towards achieving generalization across multiple domains, we attempt to understand and compare the peculiarities of existing end-to-end neural models on the Stanford Question Answering Dataset (SQuAD) by performing quantitative as well as qualitative analysis of the results attained by each of them. We observed that prediction errors reflect certain model-specific biases, which we further discuss in this paper.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3204.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3204 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3204 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3204/>Code-Mixed Question Answering Challenge : Crowd-sourcing Data and Techniques</a></strong><br><a href=/people/k/khyathi-chandu/>Khyathi Chandu</a>
|
<a href=/people/e/ekaterina-loginova/>Ekaterina Loginova</a>
|
<a href=/people/v/vishal-gupta/>Vishal Gupta</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a>
|
<a href=/people/g/gunter-neumann/>GÃ¼nter Neumann</a>
|
<a href=/people/m/manoj-chinnakotla/>Manoj Chinnakotla</a>
|
<a href=/people/e/eric-nyberg/>Eric Nyberg</a>
|
<a href=/people/a/alan-w-black/>Alan W. Black</a><br><a href=/volumes/W18-32/ class=text-muted>Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3204><div class="card-body p-3 small">Code-Mixing (CM) is the phenomenon of alternating between two or more languages which is prevalent in bi- and multi-lingual communities. Most NLP applications today are still designed with the assumption of a single interaction language and are most likely to break given a CM utterance with multiple languages mixed at a morphological, phrase or sentence level. For example, popular commercial search engines do not yet fully understand the intents expressed in CM queries. As a first step towards fostering research which supports CM in NLP applications, we systematically crowd-sourced and curated an evaluation dataset for factoid question answering in three CM languages-Hinglish (Hindi+English), Tenglish (Telugu+English) and Tamlish (Tamil+English) which belong to two language families (Indo-Aryan and Dravidian). We share the details of our data collection process, techniques which were used to avoid inducing lexical bias amongst the crowd workers and other CM specific linguistic properties of the dataset. Our final dataset, which is available freely for research purposes, has 1,694 <a href=https://en.wikipedia.org/wiki/Hinglish>Hinglish</a>, 2,848 Tamlish and 1,391 Tenglish factoid questions and their answers. We discuss the <a href=https://en.wikipedia.org/wiki/List_of_art_media>techniques</a> used by the participants for the first edition of this ongoing challenge.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3211.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3211 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3211 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3211/>Language Informed Modeling of Code-Switched Text</a></strong><br><a href=/people/k/khyathi-chandu/>Khyathi Chandu</a>
|
<a href=/people/t/thomas-manzini/>Thomas Manzini</a>
|
<a href=/people/s/sumeet-singh/>Sumeet Singh</a>
|
<a href=/people/a/alan-w-black/>Alan W. Black</a><br><a href=/volumes/W18-32/ class=text-muted>Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3211><div class="card-body p-3 small">Code-switching (CS), the practice of alternating between two or more languages in conversations, is pervasive in most <a href=https://en.wikipedia.org/wiki/Multilingualism>multi-lingual communities</a>. CS texts have a complex interplay between languages and occur in informal contexts that make them harder to collect and construct NLP tools for. We approach this problem through Language Modeling (LM) on a new Hindi-English mixed corpus containing 59,189 unique sentences collected from <a href=https://en.wikipedia.org/wiki/Blog>blogging websites</a>. We implement and discuss different <a href=https://en.wikipedia.org/wiki/Language_model>Language Models</a> derived from a multi-layered LSTM architecture. We hypothesize that <a href=https://en.wikipedia.org/wiki/Code-switching>encoding language information</a> strengthens a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> by helping to learn code-switching points. We show that our highest performing <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> achieves a test perplexity of 19.52 on the <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>CS corpus</a> that we collected and processed. On this data we demonstrate that our performance is an improvement over AWD-LSTM LM (a recent state of the art on monolingual English).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3217.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3217 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3217 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3217/>Tackling Code-Switched NER : Participation of CMU<span class=acl-fixed-case>NER</span>: Participation of <span class=acl-fixed-case>CMU</span></a></strong><br><a href=/people/p/parvathy-geetha/>Parvathy Geetha</a>
|
<a href=/people/k/khyathi-chandu/>Khyathi Chandu</a>
|
<a href=/people/a/alan-w-black/>Alan W Black</a><br><a href=/volumes/W18-32/ class=text-muted>Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3217><div class="card-body p-3 small">Named Entity Recognition plays a major role in several downstream applications in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. Though this task has been heavily studied in formal monolingual texts and also <a href=https://en.wikipedia.org/wiki/Noisy_text>noisy texts</a> like Twitter data, it is still an emerging task in code-switched (CS) content on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. This paper describes our participation in the shared task of NER on code-switched data for Spanglish (Spanish + English) and Arabish (Arabic + English). In this paper we describe <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that intuitively developed from the <a href=https://en.wikipedia.org/wiki/Data>data</a> for the shared task Named Entity Recognition on Code-switched Data. Owing to the sparse and non-linear relationships between words in Twitter data, we explored neural architectures that are capable of non-linearities fairly well. In specific, we trained character level models and word level models based on Bidirectional LSTMs (Bi-LSTMs) to perform sequential tagging. We train multiple models to identify nominal mentions and subsequently use this information to predict the labels of named entity in a sequence. Our best <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is a character level model along with word level pre-trained multilingual embeddings that gave an <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> of 56.72 in <a href=https://en.wikipedia.org/wiki/Spanglish>Spanglish</a> and a word level model that gave an <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> of 65.02 in <a href=https://en.wikipedia.org/wiki/Arabic>Arabish</a> on the test data.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2307.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2307 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2307 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2307/>Tackling Biomedical Text Summarization : OAQA at BioASQ 5B<span class=acl-fixed-case>OAQA</span> at <span class=acl-fixed-case>B</span>io<span class=acl-fixed-case>ASQ</span> 5<span class=acl-fixed-case>B</span></a></strong><br><a href=/people/k/khyathi-chandu/>Khyathi Chandu</a>
|
<a href=/people/a/aakanksha-naik/>Aakanksha Naik</a>
|
<a href=/people/a/aditya-chandrasekar/>Aditya Chandrasekar</a>
|
<a href=/people/z/zi-yang/>Zi Yang</a>
|
<a href=/people/n/niloy-gupta/>Niloy Gupta</a>
|
<a href=/people/e/eric-nyberg/>Eric Nyberg</a><br><a href=/volumes/W17-23/ class=text-muted>BioNLP 2017</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2307><div class="card-body p-3 small">In this paper, we describe our participation in phase B of task 5b of the fifth edition of the annual BioASQ challenge, which includes answering factoid, list, yes-no and summary questions from biomedical data. We describe our techniques with an emphasis on ideal answer generation, where the goal is to produce a relevant, precise, non-redundant, query-oriented summary from multiple relevant documents. We make use of extractive summarization techniques to address this task and experiment with different biomedical ontologies and various algorithms including <a href=https://en.wikipedia.org/wiki/Agglomerative_clustering>agglomerative clustering</a>, Maximum Marginal Relevance (MMR) and sentence compression. We propose a novel word embedding based tf-idf similarity metric and a soft positional constraint which improve our system performance. We evaluate our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>techniques</a> on test batch 4 from the fourth edition of the challenge. Our best system achieves a ROUGE-2 score of 0.6534 and ROUGE-SU4 score of 0.6536.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Khyathi+Chandu" title="Search for 'Khyathi Chandu' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/e/eric-nyberg/ class=align-middle>Eric Nyberg</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/a/alan-w-black/ class=align-middle>Alan W. Black</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/a/aakanksha-naik/ class=align-middle>Aakanksha Naik</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aditya-chandrasekar/ class=align-middle>Aditya Chandrasekar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zi-yang/ class=align-middle>Zi Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/n/niloy-gupta/ class=align-middle>Niloy Gupta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/soumya-wadhwa/ class=align-middle>Soumya Wadhwa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/ekaterina-loginova/ class=align-middle>Ekaterina Loginova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vishal-gupta/ class=align-middle>Vishal Gupta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/josef-van-genabith/ class=align-middle>Josef van Genabith</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gunter-neumann/ class=align-middle>GÃ¼nter Neumann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/manoj-chinnakotla/ class=align-middle>Manoj Chinnakotla</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thomas-manzini/ class=align-middle>Thomas Manzini</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sumeet-singh/ class=align-middle>Sumeet Singh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/parvathy-geetha/ class=align-middle>Parvathy Geetha</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>