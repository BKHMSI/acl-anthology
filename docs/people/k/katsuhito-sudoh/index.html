<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Katsuhito Sudoh - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Katsuhito</span> <span class=font-weight-bold>Sudoh</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.sigdial-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--sigdial-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.sigdial-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href="https://www.youtube.com/watch?v=Y4OAaQzoIhA" data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.sigdial-1.9" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.sigdial-1.9/>ARTA : Collection and Classification of Ambiguous Requests and Thoughtful Actions<span class=acl-fixed-case>ARTA</span>: Collection and Classification of Ambiguous Requests and Thoughtful Actions</a></strong><br><a href=/people/s/shohei-tanaka/>Shohei Tanaka</a>
|
<a href=/people/k/koichiro-yoshino/>Koichiro Yoshino</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/s/satoshi-nakamura/>Satoshi Nakamura</a><br><a href=/volumes/2021.sigdial-1/ class=text-muted>Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--sigdial-1--9><div class="card-body p-3 small">Human-assisting systems such as dialogue systems must take thoughtful, appropriate actions not only for clear and unambiguous user requests, but also for ambiguous user requests, even if the users themselves are not aware of their potential requirements. To construct such a dialogue agent, we collected a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> and developed a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> that classifies ambiguous user requests into corresponding system actions. In order to collect a high-quality corpus, we asked workers to input antecedent user requests whose pre-defined actions could be regarded as thoughtful. Although multiple actions could be identified as thoughtful for a single <a href=https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol>user request</a>, annotating all combinations of <a href=https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol>user requests</a> and <a href=https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol>system actions</a> is impractical. For this reason, we fully annotated only the test data and left the annotation of the training data incomplete. In order to train the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification model</a> on such training data, we applied the positive / unlabeled (PU) learning method, which assumes that only a part of the data is labeled with positive examples. The experimental results show that the PU learning method achieved better performance than the general positive / negative (PN) learning method to classify thoughtful actions given an ambiguous user request.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wmt-1.120.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wmt-1--120 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wmt-1.120 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wmt-1.120/>Simultaneous Neural Machine Translation with Constituent Label Prediction</a></strong><br><a href=/people/y/yasumasa-kano/>Yasumasa Kano</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/s/satoshi-nakamura/>Satoshi Nakamura</a><br><a href=/volumes/2021.wmt-1/ class=text-muted>Proceedings of the Sixth Conference on Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wmt-1--120><div class="card-body p-3 small">Simultaneous translation is a task in which <a href=https://en.wikipedia.org/wiki/Translation>translation</a> begins before the speaker has finished speaking, so it is important to decide when to start the <a href=https://en.wikipedia.org/wiki/Translation>translation process</a>. However, deciding whether to read more input words or start to translate is difficult for language pairs with different word orders such as <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>. Motivated by the concept of pre-reordering, we propose a couple of simple decision rules using the label of the next constituent predicted by incremental constituent label prediction. In experiments on English-to-Japanese simultaneous translation, the proposed method outperformed <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> in the <a href=https://en.wikipedia.org/wiki/Latency_(engineering)>quality-latency trade-off</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wat-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wat-1.0/>Proceedings of the 8th Workshop on Asian Translation (WAT2021)</a></strong><br><a href=/people/t/toshiaki-nakazawa/>Toshiaki Nakazawa</a>
|
<a href=/people/h/hideki-nakayama/>Hideki Nakayama</a>
|
<a href=/people/i/isao-goto/>Isao Goto</a>
|
<a href=/people/h/hideya-mino/>Hideya Mino</a>
|
<a href=/people/c/chenchen-ding/>Chenchen Ding</a>
|
<a href=/people/r/raj-dabre/>Raj Dabre</a>
|
<a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/s/shohei-higashiyama/>Shohei Higashiyama</a>
|
<a href=/people/h/hiroshi-manabe/>Hiroshi Manabe</a>
|
<a href=/people/w/win-pa-pa/>Win Pa Pa</a>
|
<a href=/people/s/shantipriya-parida/>Shantipriya Parida</a>
|
<a href=/people/o/ondrej-bojar/>Ond≈ôej Bojar</a>
|
<a href=/people/c/chenhui-chu/>Chenhui Chu</a>
|
<a href=/people/a/akiko-eriguchi/>Akiko Eriguchi</a>
|
<a href=/people/k/kaori-abe/>Kaori Abe</a>
|
<a href=/people/y/yusuke-oda/>Yusuke Oda</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/s/sadao-kurohashi/>Sadao Kurohashi</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/2021.wat-1/ class=text-muted>Proceedings of the 8th Workshop on Asian Translation (WAT2021)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.iwslt-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--iwslt-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.iwslt-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.iwslt-1.1/>FINDINGS OF THE IWSLT 2021 EVALUATION CAMPAIGN<span class=acl-fixed-case>FINDINGS</span> <span class=acl-fixed-case>OF</span> <span class=acl-fixed-case>THE</span> <span class=acl-fixed-case>IWSLT</span> 2021 <span class=acl-fixed-case>EVALUATION</span> <span class=acl-fixed-case>CAMPAIGN</span></a></strong><br><a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/o/ondrej-bojar/>Ond≈ôej Bojar</a>
|
<a href=/people/j/jacob-bremerman/>Jacob Bremerman</a>
|
<a href=/people/r/roldano-cattoni/>Roldano Cattoni</a>
|
<a href=/people/m/maha-elbayad/>Maha Elbayad</a>
|
<a href=/people/m/marcello-federico/>Marcello Federico</a>
|
<a href=/people/x/xutai-ma/>Xutai Ma</a>
|
<a href=/people/s/satoshi-nakamura/>Satoshi Nakamura</a>
|
<a href=/people/m/matteo-negri/>Matteo Negri</a>
|
<a href=/people/j/jan-niehues/>Jan Niehues</a>
|
<a href=/people/j/juan-pino/>Juan Pino</a>
|
<a href=/people/e/elizabeth-salesky/>Elizabeth Salesky</a>
|
<a href=/people/s/sebastian-stuker/>Sebastian St√ºker</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/m/marco-turchi/>Marco Turchi</a>
|
<a href=/people/a/alex-waibel/>Alexander Waibel</a>
|
<a href=/people/c/changhan-wang/>Changhan Wang</a>
|
<a href=/people/m/matthew-wiesner/>Matthew Wiesner</a><br><a href=/volumes/2021.iwslt-1/ class=text-muted>Proceedings of the 18th International Conference on Spoken Language Translation (IWSLT 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--iwslt-1--1><div class="card-body p-3 small">The evaluation campaign of the International Conference on Spoken Language Translation (IWSLT 2021) featured this year four shared tasks : (i) Simultaneous speech translation, (ii) Offline speech translation, (iii) Multilingual speech translation, (iv) Low-resource speech translation. A total of 22 teams participated in at least one of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. This paper describes each shared task, data and evaluation metrics, and reports results of the received submissions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.iwslt-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--iwslt-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.iwslt-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.iwslt-1.3/>NAIST English-to-Japanese Simultaneous Translation System for IWSLT 2021 Simultaneous Text-to-text Task<span class=acl-fixed-case>NAIST</span> <span class=acl-fixed-case>E</span>nglish-to-<span class=acl-fixed-case>J</span>apanese Simultaneous Translation System for <span class=acl-fixed-case>IWSLT</span> 2021 Simultaneous Text-to-text Task</a></strong><br><a href=/people/r/ryo-fukuda/>Ryo Fukuda</a>
|
<a href=/people/y/yui-oka/>Yui Oka</a>
|
<a href=/people/y/yasumasa-kano/>Yasumasa Kano</a>
|
<a href=/people/y/yuki-yano/>Yuki Yano</a>
|
<a href=/people/y/yuka-ko/>Yuka Ko</a>
|
<a href=/people/h/hirotaka-tokuyama/>Hirotaka Tokuyama</a>
|
<a href=/people/k/kosuke-doi/>Kosuke Doi</a>
|
<a href=/people/s/sakriani-sakti/>Sakriani Sakti</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/s/satoshi-nakamura/>Satoshi Nakamura</a><br><a href=/volumes/2021.iwslt-1/ class=text-muted>Proceedings of the 18th International Conference on Spoken Language Translation (IWSLT 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--iwslt-1--3><div class="card-body p-3 small">This paper describes NAIST&#8217;s system for the English-to-Japanese Simultaneous Text-to-text Translation Task in IWSLT 2021 Evaluation Campaign. Our primary submission is based on wait-k neural machine translation with sequence-level knowledge distillation to encourage <a href=https://en.wikipedia.org/wiki/Literal_translation>literal translation</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.humeval-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--humeval-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.humeval-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.humeval-1.5.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href="https://www.youtube.com/watch?v=myG72lA2hpo" data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.humeval-1.5/>Is This Translation Error Critical? : Classification-Based Human and Automatic Machine Translation Evaluation Focusing on Critical Errors</a></strong><br><a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/k/kosuke-takahashi/>Kosuke Takahashi</a>
|
<a href=/people/s/satoshi-nakamura/>Satoshi Nakamura</a><br><a href=/volumes/2021.humeval-1/ class=text-muted>Proceedings of the Workshop on Human Evaluation of NLP Systems (HumEval)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--humeval-1--5><div class="card-body p-3 small">This paper discusses a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification-based approach</a> to machine translation evaluation, as opposed to a common <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression-based approach</a> in the WMT Metrics task. Recent <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> usually works well but sometimes makes critical errors due to just a few wrong word choices. Our classification-based approach focuses on such errors using several error type labels, for practical machine translation evaluation in an age of <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>. We made additional annotations on the WMT 2015-2017 Metrics datasets with fluency and adequacy labels to distinguish different types of translation errors from syntactic and semantic viewpoints. We present our human evaluation criteria for the corpus development and automatic evaluation experiments using the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>. The human evaluation corpus will be publicly available upon publication.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.319.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--319 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.319 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.319/>Incorporating Noisy Length Constraints into Transformer with Length-aware Positional Encodings</a></strong><br><a href=/people/y/yui-oka/>Yui Oka</a>
|
<a href=/people/k/katsuki-chousa/>Katsuki Chousa</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/s/satoshi-nakamura/>Satoshi Nakamura</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--319><div class="card-body p-3 small">Neural Machine Translation often suffers from an under-translation problem due to its limited modeling of output sequence lengths. In this work, we propose a novel approach to training a Transformer model using length constraints based on length-aware positional encoding (PE). Since length constraints with exact target sentence lengths degrade translation performance, we add random noise within a certain window size to the length constraints in the PE during the training. In the <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference step</a>, we predict the output lengths using input sequences and a BERT-based length prediction model. Experimental results in an ASPEC English-to-Japanese translation showed the proposed method produced translations with lengths close to the reference ones and outperformed a vanilla Transformer (especially in short sentences) by 3.22 points in <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>. The average translation results using our length prediction model were also better than another baseline method using input lengths for the length constraints. The proposed noise injection improved robustness for length prediction errors, especially within the window size.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wat-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.wat-1.0/>Proceedings of the 7th Workshop on Asian Translation</a></strong><br><a href=/people/t/toshiaki-nakazawa/>Toshiaki Nakazawa</a>
|
<a href=/people/h/hideki-nakayama/>Hideki Nakayama</a>
|
<a href=/people/c/chenchen-ding/>Chenchen Ding</a>
|
<a href=/people/r/raj-dabre/>Raj Dabre</a>
|
<a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/w/win-pa-pa/>Win Pa Pa</a>
|
<a href=/people/o/ondrej-bojar/>Ond≈ôej Bojar</a>
|
<a href=/people/s/shantipriya-parida/>Shantipriya Parida</a>
|
<a href=/people/i/isao-goto/>Isao Goto</a>
|
<a href=/people/h/hidaya-mino/>Hidaya Mino</a>
|
<a href=/people/h/hiroshi-manabe/>Hiroshi Manabe</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/s/sadao-kurohashi/>Sadao Kurohashi</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/2020.wat-1/ class=text-muted>Proceedings of the 7th Workshop on Asian Translation</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5600.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5600/>Proceedings of the 3rd Workshop on Neural Generation and Translation</a></strong><br><a href=/people/a/alexandra-birch/>Alexandra Birch</a>
|
<a href=/people/a/andrew-finch/>Andrew Finch</a>
|
<a href=/people/h/hiroaki-hayashi/>Hiroaki Hayashi</a>
|
<a href=/people/i/ioannis-konstas/>Ioannis Konstas</a>
|
<a href=/people/m/minh-thang-luong/>Thang Luong</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/y/yusuke-oda/>Yusuke Oda</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a><br><a href=/volumes/D19-56/ class=text-muted>Proceedings of the 3rd Workshop on Neural Generation and Translation</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-7200.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-7200/>Proceedings of The 8th Workshop on Patent and Scientific Literature Translation</a></strong><br><a href=/people/t/takehito-utsuro/>Takehito Utsuro</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/t/takashi-tsunakawa/>Takashi Tsunakawa</a><br><a href=/volumes/W19-72/ class=text-muted>Proceedings of The 8th Workshop on Patent and Scientific Literature Translation</a></span></p><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-2711.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-2711 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-2711 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-2711/>Multi-Source Neural Machine Translation with Missing Data</a></strong><br><a href=/people/y/yuta-nishimura/>Yuta Nishimura</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/s/satoshi-nakamura/>Satoshi Nakamura</a><br><a href=/volumes/W18-27/ class=text-muted>Proceedings of the 2nd Workshop on Neural Machine Translation and Generation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-2711><div class="card-body p-3 small">Multi-source translation is an <a href=https://en.wikipedia.org/wiki/Software_development_process>approach</a> to exploit multiple inputs (e.g. in two different languages) to increase <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>translation accuracy</a>. In this paper, we examine approaches for multi-source neural machine translation (NMT) using an incomplete multilingual corpus in which some translations are missing. In practice, many multilingual corpora are not complete due to the difficulty to provide translations in all of the relevant languages (for example, in <a href=https://en.wikipedia.org/wiki/TED_(conference)>TED talks</a>, most English talks only have subtitles for a small portion of the languages that TED supports). Existing studies on multi-source translation did not explicitly handle such situations. This study focuses on the use of incomplete multilingual corpora in multi-encoder NMT and mixture of NMT experts and examines a very simple implementation where missing source translations are replaced by a special symbol NULL. These methods allow us to use incomplete corpora both at training time and test time. In experiments with real incomplete multilingual corpora of TED Talks, the multi-source NMT with the NULL tokens achieved higher translation accuracies measured by <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a> than those by any one-to-one NMT systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2018--iwslt-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2018.iwslt-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><span class="align-middle mr-1" data-toggle=tooltip data-placement=bottom title="Best Student Paper"><i class="fas fa-award"></i></span></span>
<span class=d-block><strong><a class=align-middle href=/2018.iwslt-1.7/>Multi-Source Neural Machine Translation with Data Augmentation</a></strong><br><a href=/people/y/yuta-nishimura/>Yuta Nishimura</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/s/satoshi-nakamura/>Satoshi Nakamura</a><br><a href=/volumes/2018.iwslt-1/ class=text-muted>Proceedings of the 15th International Conference on Spoken Language Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2018--iwslt-1--7><div class="card-body p-3 small">Multi-source translation systems translate from multiple languages to a single target language. By using information from these multiple sources, these <a href=https://en.wikipedia.org/wiki/System>systems</a> achieve large gains in <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. To train these systems, it is necessary to have corpora with parallel text in multiple sources and the target language. However, these <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a> are rarely complete in practice due to the difficulty of providing human translations in all of the relevant languages. In this paper, we propose a data augmentation approach to fill such incomplete parts using multi-source neural machine translation (NMT). In our experiments, results varied over different language combinations but significant gains were observed when using a source language similar to the target language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2018--iwslt-1--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2018.iwslt-1.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2018.iwslt-1.27/>Multi-paraphrase Augmentation to Leverage Neural Caption Translation</a></strong><br><a href=/people/j/johanes-effendi/>Johanes Effendi</a>
|
<a href=/people/s/sakriani-sakti/>Sakriani Sakti</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/s/satoshi-nakamura/>Satoshi Nakamura</a><br><a href=/volumes/2018.iwslt-1/ class=text-muted>Proceedings of the 15th International Conference on Spoken Language Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2018--iwslt-1--27><div class="card-body p-3 small">Paraphrasing has been proven to improve translation quality in <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation (MT)</a> and has been widely studied alongside with the development of <a href=https://en.wikipedia.org/wiki/Statistical_machine_translation>statistical MT (SMT)</a>. In this paper, we investigate and utilize neural paraphrasing to improve <a href=https://en.wikipedia.org/wiki/Translation_(biology)>translation quality</a> in neural MT (NMT), which has not yet been much explored. Our first contribution is to propose a new way of creating a multi-paraphrase corpus through visual description. After that, we also proposed to construct neural paraphrase models which initiate expert models and utilize them to leverage NMT. Here, we diffuse the image information by using image-based paraphrasing without using the image itself. Our proposed image-based multi-paraphrase augmentation strategies showed improvement against a vanilla NMT baseline.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5712.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5712 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5712 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5712/>A Simple and Strong Baseline : NAIST-NICT Neural Machine Translation System for WAT2017 English-Japanese Translation Task<span class=acl-fixed-case>NAIST</span>-<span class=acl-fixed-case>NICT</span> Neural Machine Translation System for <span class=acl-fixed-case>WAT</span>2017 <span class=acl-fixed-case>E</span>nglish-<span class=acl-fixed-case>J</span>apanese Translation Task</a></strong><br><a href=/people/y/yusuke-oda/>Yusuke Oda</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/s/satoshi-nakamura/>Satoshi Nakamura</a>
|
<a href=/people/m/masao-utiyama/>Masao Utiyama</a>
|
<a href=/people/e/eiichiro-sumita/>Eiichiro Sumita</a><br><a href=/volumes/W17-57/ class=text-muted>Proceedings of the 4th Workshop on Asian Translation (WAT2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5712><div class="card-body p-3 small">This paper describes the details about the NAIST-NICT machine translation system for WAT2017 English-Japanese Scientific Paper Translation Task. The system consists of a language-independent tokenizer and an attentional encoder-decoder style neural machine translation model. According to the official results, our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves higher translation accuracy than any systems submitted previous campaigns despite simple <a href=https://en.wikipedia.org/wiki/Conceptual_model>model architecture</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2017.iwslt-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2017--iwslt-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2017.iwslt-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2017.iwslt-1.1/>Overview of the IWSLT 2017 Evaluation Campaign<span class=acl-fixed-case>IWSLT</span> 2017 Evaluation Campaign</a></strong><br><a href=/people/m/mauro-cettolo/>Mauro Cettolo</a>
|
<a href=/people/m/marcello-federico/>Marcello Federico</a>
|
<a href=/people/l/luisa-bentivogli/>Luisa Bentivogli</a>
|
<a href=/people/j/jan-niehues/>Jan Niehues</a>
|
<a href=/people/s/sebastian-stuker/>Sebastian St√ºker</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/k/koichiro-yoshino/>Koichiro Yoshino</a>
|
<a href=/people/c/christian-federmann/>Christian Federmann</a><br><a href=/volumes/2017.iwslt-1/ class=text-muted>Proceedings of the 14th International Conference on Spoken Language Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2017--iwslt-1--1><div class="card-body p-3 small">The IWSLT 2017 evaluation campaign has organised three tasks. The Multilingual task, which is about training <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation systems</a> handling many-to-many language directions, including so-called zero-shot directions. The Dialogue task, which calls for the integration of context information in <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, in order to resolve <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphoric references</a> that typically occur in human-human dialogue turns. And, finally, the Lecture task, which offers the challenge of automatically transcribing and translating real-life university lectures. Following the tradition of these reports, we will described all tasks in detail and present the results of all runs submitted by their participants.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Katsuhito+Sudoh" title="Search for 'Katsuhito Sudoh' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/s/satoshi-nakamura/ class=align-middle>Satoshi Nakamura</a>
<span class="badge badge-secondary align-middle ml-2">10</span></li><li class=list-group-item><a href=/people/y/yusuke-oda/ class=align-middle>Yusuke Oda</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/g/graham-neubig/ class=align-middle>Graham Neubig</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/o/ondrej-bojar/ class=align-middle>Ond≈ôej Bojar</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/k/koichiro-yoshino/ class=align-middle>Koichiro Yoshino</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/m/marcello-federico/ class=align-middle>Marcello Federico</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jan-niehues/ class=align-middle>Jan Niehues</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sebastian-stuker/ class=align-middle>Sebastian St√ºker</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yasumasa-kano/ class=align-middle>Yasumasa Kano</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/toshiaki-nakazawa/ class=align-middle>Toshiaki Nakazawa</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hideki-nakayama/ class=align-middle>Hideki Nakayama</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/i/isao-goto/ class=align-middle>Isao Goto</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/chenchen-ding/ class=align-middle>Chenchen Ding</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/raj-dabre/ class=align-middle>Raj Dabre</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/anoop-kunchukuttan/ class=align-middle>Anoop Kunchukuttan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hiroshi-manabe/ class=align-middle>Hiroshi Manabe</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/w/win-pa-pa/ class=align-middle>Win Pa Pa</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/shantipriya-parida/ class=align-middle>Shantipriya Parida</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sadao-kurohashi/ class=align-middle>Sadao Kurohashi</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/pushpak-bhattacharyya/ class=align-middle>Pushpak Bhattacharyya</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yui-oka/ class=align-middle>Yui Oka</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sakriani-sakti/ class=align-middle>Sakriani Sakti</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yuta-nishimura/ class=align-middle>Yuta Nishimura</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/shohei-tanaka/ class=align-middle>Shohei Tanaka</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/masao-utiyama/ class=align-middle>Masao Utiyama</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eiichiro-sumita/ class=align-middle>Eiichiro Sumita</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mauro-cettolo/ class=align-middle>Mauro Cettolo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luisa-bentivogli/ class=align-middle>Luisa Bentivogli</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christian-federmann/ class=align-middle>Christian Federmann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexandra-birch/ class=align-middle>Alexandra Birch</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrew-finch/ class=align-middle>Andrew Finch</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hiroaki-hayashi/ class=align-middle>Hiroaki Hayashi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ioannis-konstas/ class=align-middle>Ioannis Konstas</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/minh-thang-luong/ class=align-middle>Minh-Thang Luong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hideya-mino/ class=align-middle>Hideya Mino</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shohei-higashiyama/ class=align-middle>Shohei Higashiyama</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chenhui-chu/ class=align-middle>Chenhui Chu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/akiko-eriguchi/ class=align-middle>Akiko Eriguchi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kaori-abe/ class=align-middle>Kaori Abe</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/antonios-anastasopoulos/ class=align-middle>Antonios Anastasopoulos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jacob-bremerman/ class=align-middle>Jacob Bremerman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/roldano-cattoni/ class=align-middle>Roldano Cattoni</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maha-elbayad/ class=align-middle>Maha Elbayad</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xutai-ma/ class=align-middle>Xutai Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/matteo-negri/ class=align-middle>Matteo Negri</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/juan-pino/ class=align-middle>Juan Pino</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elizabeth-salesky/ class=align-middle>Elizabeth Salesky</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marco-turchi/ class=align-middle>Marco Turchi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alex-waibel/ class=align-middle>Alex Waibel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/changhan-wang/ class=align-middle>Changhan Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/matthew-wiesner/ class=align-middle>Matthew Wiesner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ryo-fukuda/ class=align-middle>Ryo Fukuda</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yuki-yano/ class=align-middle>Yuki Yano</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yuka-ko/ class=align-middle>Yuka Ko</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hirotaka-tokuyama/ class=align-middle>Hirotaka Tokuyama</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kosuke-doi/ class=align-middle>Kosuke Doi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/takehito-utsuro/ class=align-middle>Takehito Utsuro</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/takashi-tsunakawa/ class=align-middle>Takashi Tsunakawa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/katsuki-chousa/ class=align-middle>Katsuki Chousa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hidaya-mino/ class=align-middle>Hidaya Mino</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/johanes-effendi/ class=align-middle>Johanes Effendi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kosuke-takahashi/ class=align-middle>Kosuke Takahashi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/iwslt/ class=align-middle>IWSLT</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/wat/ class=align-middle>WAT</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/sigdial/ class=align-middle>SIGDIAL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/wmt/ class=align-middle>WMT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/humeval/ class=align-middle>HumEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ¬©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>