<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Kai-Wei Chang - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Kai-Wei</span> <span class=font-weight-bold>Chang</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-main.88.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-main--88 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-main.88 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.eacl-main.88" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-main.88/>Generating Syntactically Controlled Paraphrases without Using Annotated Parallel Pairs</a></strong><br><a href=/people/k/kuan-hao-huang/>Kuan-Hao Huang</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/2021.eacl-main/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-main--88><div class="card-body p-3 small">Paraphrase generation plays an essential role in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language process (NLP)</a>, and it has many downstream applications. However, training supervised paraphrase models requires many annotated paraphrase pairs, which are usually costly to obtain. On the other hand, the <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrases</a> generated by existing unsupervised approaches are usually syntactically similar to the source sentences and are limited in diversity. In this paper, we demonstrate that it is possible to generate syntactically various paraphrases without the need for annotated paraphrase pairs. We propose Syntactically controlled Paraphrase Generator (SynPG), an encoder-decoder based model that learns to disentangle the <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> and the <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> of a sentence from a collection of unannotated texts. The disentanglement enables SynPG to control the <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> of output paraphrases by manipulating the embedding in the syntactic space. Extensive experiments using automatic metrics and human evaluation show that SynPG performs better syntactic control than unsupervised baselines, while the quality of the generated paraphrases is competitive. We also demonstrate that the performance of SynPG is competitive or even better than supervised models when the unannotated data is large. Finally, we show that the syntactically controlled paraphrases generated by SynPG can be utilized for <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> to improve the robustness of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP models</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.121.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--121 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.121 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.121/>On the Transferability of Adversarial Attacks against Neural Text Classifier</a></strong><br><a href=/people/l/liping-yuan/>Liping Yuan</a>
|
<a href=/people/x/xiaoqing-zheng/>Xiaoqing Zheng</a>
|
<a href=/people/y/yi-zhou/>Yi Zhou</a>
|
<a href=/people/c/cho-jui-hsieh/>Cho-Jui Hsieh</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--121><div class="card-body p-3 small">Deep neural networks are vulnerable to adversarial attacks, where a small perturbation to an input alters the model prediction. In many cases, malicious inputs intentionally crafted for one <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> can fool another <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>. In this paper, we present the first study to systematically investigate the transferability of adversarial examples for text classification models and explore how various factors, including <a href=https://en.wikipedia.org/wiki/Network_architecture>network architecture</a>, <a href=https://en.wikipedia.org/wiki/Lexical_analysis>tokenization scheme</a>, <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a>, and model capacity, affect the transferability of adversarial examples. Based on these studies, we propose a <a href=https://en.wikipedia.org/wiki/Genetic_algorithm>genetic algorithm</a> to find an ensemble of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that can be used to induce adversarial examples to fool almost all existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Such adversarial examples reflect the defects of the learning process and the data bias in the training set. Finally, we derive word replacement rules that can be used for model diagnostics from these adversarial examples.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.162.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--162 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.162 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.162" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.162/>Broaden the Vision : Geo-Diverse Visual Commonsense Reasoning</a></strong><br><a href=/people/d/da-yin/>Da Yin</a>
|
<a href=/people/l/liunian-harold-li/>Liunian Harold Li</a>
|
<a href=/people/z/ziniu-hu/>Ziniu Hu</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--162><div class="card-body p-3 small">Commonsense is defined as the knowledge on which everyone agrees. However, certain types of <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a> are correlated with culture and geographic locations and they are only shared locally. For example, the scenes of wedding ceremonies vary across regions due to different customs influenced by historical and religious factors. Such regional characteristics, however, are generally omitted in prior work. In this paper, we construct a Geo-Diverse Visual Commonsense Reasoning dataset (GD-VCR) to test vision-and-language models&#8217; ability to understand cultural and geo-location-specific commonsense. In particular, we study two state-of-the-art Vision-and-Language models, VisualBERT and ViLBERT trained on <a href=https://en.wikipedia.org/wiki/Videocassette_recorder>VCR</a>, a standard benchmark with images primarily from Western regions. We then evaluate how well the trained <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> can generalize to answering the questions in GD-VCR. We find that the performance of both models for non-Western regions including <a href=https://en.wikipedia.org/wiki/East_Asia>East Asia</a>, <a href=https://en.wikipedia.org/wiki/South_Asia>South Asia</a>, and <a href=https://en.wikipedia.org/wiki/Africa>Africa</a> is significantly lower than that for <a href=https://en.wikipedia.org/wiki/Western_world>Western region</a>. We analyze the reasons behind the performance disparity and find that the performance gap is larger on QA pairs that : 1) are concerned with <a href=https://en.wikipedia.org/wiki/Culture>culture-related scenarios</a>, e.g., <a href=https://en.wikipedia.org/wiki/Wedding>weddings</a>, <a href=https://en.wikipedia.org/wiki/Religion>religious activities</a>, and <a href=https://en.wikipedia.org/wiki/Festival>festivals</a> ; 2) require high-level geo-diverse commonsense reasoning rather than low-order perception and recognition. Dataset and code are released at https://github.com/WadeYin9712/GD-VCR.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-tutorials.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-tutorials--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-tutorials.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-tutorials.5/>Robustness and Adversarial Examples in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a></a></strong><br><a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/h/he-he/>He He</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a><br><a href=/volumes/2021.emnlp-tutorials/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-tutorials--5><div class="card-body p-3 small">Recent studies show that many NLP systems are sensitive and vulnerable to a small perturbation of inputs and do not generalize well across different datasets. This lack of <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> derails the use of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP systems</a> in real-world applications. This tutorial aims at bringing awareness of practical concerns about NLP robustness. It targets NLP researchers and practitioners who are interested in building reliable NLP systems. In particular, we will review recent studies on analyzing the weakness of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP systems</a> when facing adversarial inputs and data with a <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distribution shift</a>. We will provide the audience with a holistic view of 1) how to use adversarial examples to examine the weakness of NLP models and facilitate <a href=https://en.wikipedia.org/wiki/Debugging>debugging</a> ; 2) how to enhance the <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> of existing NLP models and defense against adversarial inputs ; and 3) how the consideration of <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> affects the real-world NLP applications used in our daily lives. We will conclude the tutorial by outlining future research directions in this area.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.60.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--60 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.60 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.60/>Nice Try, Kiddo : Investigating Ad Hominems in Dialogue Responses</a></strong><br><a href=/people/e/emily-sheng/>Emily Sheng</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/p/prem-natarajan/>Prem Natarajan</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--60><div class="card-body p-3 small">Ad hominem attacks are those that target some feature of a person&#8217;s character instead of the position the person is maintaining. These attacks are harmful because they propagate implicit biases and diminish a person&#8217;s credibility. Since <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a> respond directly to <a href=https://en.wikipedia.org/wiki/Input_(computer_science)>user input</a>, it is important to study ad hominems in dialogue responses. To this end, we propose categories of ad hominems, compose an annotated dataset, and build a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> to analyze human and dialogue system responses to English Twitter posts. We specifically compare responses to Twitter topics about marginalized communities (# BlackLivesMatter, # MeToo) versus other topics (# Vegan, # WFH), because the abusive language of ad hominems could further amplify the skew of power away from marginalized populations. Furthermore, we propose a constrained decoding technique that uses salient n-gram similarity as a soft constraint for top-k sampling to reduce the amount of ad hominems generated. Our results indicate that 1) responses from both humans and DialoGPT contain more <a href=https://en.wikipedia.org/wiki/Ad_hominem>ad hominems</a> for discussions around marginalized communities, 2) different quantities of <a href=https://en.wikipedia.org/wiki/Ad_hominem>ad hominems</a> in the training data can influence the likelihood of generating <a href=https://en.wikipedia.org/wiki/Ad_hominem>ad hominems</a>, and 3) we can use constrained decoding techniques to reduce <a href=https://en.wikipedia.org/wiki/Ad_hominem>ad hominems</a> in generated dialogue responses.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.305.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--305 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.305 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.305" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.305/>Double Perturbation : On the Robustness of Robustness and Counterfactual Bias Evaluation</a></strong><br><a href=/people/c/chong-zhang/>Chong Zhang</a>
|
<a href=/people/j/jieyu-zhao/>Jieyu Zhao</a>
|
<a href=/people/h/huan-zhang/>Huan Zhang</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/c/cho-jui-hsieh/>Cho-Jui Hsieh</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--305><div class="card-body p-3 small">Robustness and counterfactual bias are usually evaluated on a test dataset. However, are these <a href=https://en.wikipedia.org/wiki/Evaluation>evaluations</a> robust? If the test dataset is perturbed slightly, will the evaluation results keep the same? In this paper, we propose a double perturbation framework to uncover model weaknesses beyond the test dataset. The framework first perturbs the test dataset to construct abundant natural sentences similar to the test data, and then diagnoses the prediction change regarding a single-word substitution. We apply this framework to study two perturbation-based approaches that are used to analyze models&#8217; robustness and counterfactual bias in <a href=https://en.wikipedia.org/wiki/English_language>English</a>. (1) For <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a>, we focus on synonym substitutions and identify vulnerable examples where prediction can be altered. Our proposed <a href=https://en.wikipedia.org/wiki/Cyberattack>attack</a> attains high success rates (96.0%-99.8 %) in finding vulnerable examples on both original and robustly trained <a href=https://en.wikipedia.org/wiki/Computer_simulation>CNNs</a> and Transformers. (2) For counterfactual bias, we focus on substituting demographic tokens (e.g., gender, race) and measure the shift of the expected prediction among constructed sentences. Our method is able to reveal the hidden model biases not directly shown in the test dataset. Our code is available at https://github.com/chong-z/nlp-second-order-attack.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.361.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--361 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.361 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.361/>Adapting <a href=https://en.wikipedia.org/wiki/Coreference_resolution>Coreference Resolution</a> for Processing Violent Death Narratives</a></strong><br><a href=/people/a/ankith-uppunda/>Ankith Uppunda</a>
|
<a href=/people/s/susan-cochran/>Susan Cochran</a>
|
<a href=/people/j/jacob-foster/>Jacob Foster</a>
|
<a href=/people/a/alina-arseniev-koehler/>Alina Arseniev-Koehler</a>
|
<a href=/people/v/vickie-mays/>Vickie Mays</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--361><div class="card-body p-3 small">Coreference resolution is an important compo-nent in analyzing <a href=https://en.wikipedia.org/wiki/Narrative>narrative text</a> from admin-istrative data (e.g., clinical or police sources).However, existing coreference models trainedon general language corpora suffer from poortransferability due to domain gaps, especiallywhen they are applied to gender-inclusive datawith lesbian, gay, bisexual, and transgender(LGBT) individuals. In this paper, we an-alyzed the challenges of coreference resolu-tion in an exemplary form of administrativetext written in English : violent death nar-ratives from the USA&#8217;s Centers for DiseaseControl&#8217;s (CDC) National Violent Death Re-porting System. We developed a set of dataaugmentation rules to improve model perfor-mance using a probabilistic data programmingframework. Experiments on narratives froman administrative database, as well as existinggender-inclusive coreference datasets, demon-strate the effectiveness of data augmentationin training coreference models that can betterhandle text data about LGBT individuals.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.402.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--402 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.402 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.402" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.402/>Evaluating the Values of Sources in <a href=https://en.wikipedia.org/wiki/Transfer_learning>Transfer Learning</a></a></strong><br><a href=/people/m/md-rizwan-parvez/>Md Rizwan Parvez</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--402><div class="card-body p-3 small">Transfer learning that adapts a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> trained on data-rich sources to low-resource targets has been widely applied in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a>. However, when training a transfer model over multiple sources, not every source is equally useful for the target. To better transfer a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>, it is essential to understand the values of the sources. In this paper, we develop, an efficient source valuation framework for quantifying the usefulness of the sources (e.g.,) in <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> based on the Shapley value method. Experiments and comprehensive analyses on both cross-domain and cross-lingual transfers demonstrate that our framework is not only effective in choosing useful transfer sources but also the source values match the intuitive source-target similarity.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.420.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--420 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.420 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.420.OptionalSupplementaryData.zip data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.naacl-main.420/>Unsupervised Vision-and-Language Pre-training Without Parallel Images and Captions</a></strong><br><a href=/people/l/liunian-harold-li/>Liunian Harold Li</a>
|
<a href=/people/h/haoxuan-you/>Haoxuan You</a>
|
<a href=/people/z/zhecan-wang/>Zhecan Wang</a>
|
<a href=/people/a/alireza-zareian/>Alireza Zareian</a>
|
<a href=/people/s/shih-fu-chang/>Shih-Fu Chang</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--420><div class="card-body p-3 small">Pre-trained contextual vision-and-language (V&L) models have achieved impressive performance on various <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmarks</a>. However, existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> require a large amount of parallel image-caption data for <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>pre-training</a>. Such <a href=https://en.wikipedia.org/wiki/Data>data</a> are costly to collect and require cumbersome curation. Inspired by unsupervised machine translation, we investigate if a strong V&L representation model can be learned through unsupervised pre-training without image-caption corpora. In particular, we propose to conduct mask-and-predict pre-training on text-only and image-only corpora and introduce the object tags detected by an object recognition model as anchor points to bridge two modalities. We find that such a simple approach achieves performance close to a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> pre-trained with <a href=https://en.wikipedia.org/wiki/Data_alignment>aligned data</a>, on four English V&L benchmarks. Our work challenges the widely held notion that aligned data is necessary for V&L pre-training, while significantly reducing the amount of supervision needed for V&L models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.trustnlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.trustnlp-1.0/>Proceedings of the First Workshop on Trustworthy Natural Language Processing</a></strong><br><a href=/people/y/yada-pruksachatkun/>Yada Pruksachatkun</a>
|
<a href=/people/a/anil-ramakrishna/>Anil Ramakrishna</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/s/satyapriya-krishna/>Satyapriya Krishna</a>
|
<a href=/people/j/jwala-dhamala/>Jwala Dhamala</a>
|
<a href=/people/t/tanaya-guha/>Tanaya Guha</a>
|
<a href=/people/x/xiang-ren/>Xiang Ren</a><br><a href=/volumes/2021.trustnlp-1/ class=text-muted>Proceedings of the First Workshop on Trustworthy Natural Language Processing</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.155.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--155 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.155 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939216 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.155" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.155/>LOGAN : Local Group Bias Detection by Clustering<span class=acl-fixed-case>LOGAN</span>: Local Group Bias Detection by Clustering</a></strong><br><a href=/people/j/jieyu-zhao/>Jieyu Zhao</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--155><div class="card-body p-3 small">Machine learning techniques have been widely used in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a>. However, as revealed by many recent studies, <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning models</a> often inherit and amplify the societal biases in data. Various metrics have been proposed to quantify biases in model predictions. In particular, several of them evaluate disparity in model performance between <a href=https://en.wikipedia.org/wiki/Protected_group>protected groups</a> and advantaged groups in the test corpus. However, we argue that evaluating bias at the corpus level is not enough for understanding how <a href=https://en.wikipedia.org/wiki/Bias>biases</a> are embedded in a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>. In fact, a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> with similar aggregated performance between different groups on the entire data may behave differently on instances in a <a href=https://en.wikipedia.org/wiki/Region>local region</a>. To analyze and detect such local bias, we propose LOGAN, a new bias detection technique based on <a href=https://en.wikipedia.org/wiki/Cluster_analysis>clustering</a>. Experiments on toxicity classification and object classification tasks show that LOGAN identifies bias in a local region and allows us to better analyze the biases in model predictions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.260.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--260 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.260 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928955 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.260/>Gender Bias in Multilingual Embeddings and Cross-Lingual Transfer</a></strong><br><a href=/people/j/jieyu-zhao/>Jieyu Zhao</a>
|
<a href=/people/s/subhabrata-mukherjee/>Subhabrata Mukherjee</a>
|
<a href=/people/s/saghar-hosseini/>Saghar Hosseini</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/a/ahmed-hassan-awadallah/>Ahmed Hassan Awadallah</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--260><div class="card-body p-3 small">Multilingual representations embed words from many languages into a single <a href=https://en.wikipedia.org/wiki/Semantic_space>semantic space</a> such that words with similar meanings are close to each other regardless of the language. These embeddings have been widely used in various settings, such as cross-lingual transfer, where a <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP) model</a> trained on one language is deployed to another language. While the cross-lingual transfer techniques are powerful, they carry <a href=https://en.wikipedia.org/wiki/Gender_bias>gender bias</a> from the source to target languages. In this paper, we study <a href=https://en.wikipedia.org/wiki/Gender_bias>gender bias</a> in multilingual embeddings and how it affects <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP applications</a>. We create a multilingual dataset for bias analysis and propose several ways for quantifying bias in multilingual representations from both the intrinsic and extrinsic perspectives. Experimental results show that the magnitude of bias in the multilingual representations changes differently when we align the embeddings to different target spaces and that the alignment direction can also have an influence on the bias in <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>. We further provide recommendations for using the multilingual word representations for <a href=https://en.wikipedia.org/wiki/Downstream_(networking)>downstream tasks</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.264.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--264 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.264 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928917 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.264" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.264/>Mitigating Gender Bias Amplification in Distribution by Posterior Regularization</a></strong><br><a href=/people/s/shengyu-jia/>Shengyu Jia</a>
|
<a href=/people/t/tao-meng/>Tao Meng</a>
|
<a href=/people/j/jieyu-zhao/>Jieyu Zhao</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--264><div class="card-body p-3 small">Advanced machine learning techniques have boosted the performance of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. Nevertheless, recent studies, e.g., (CITATION) show that these techniques inadvertently capture the societal bias hidden in the corpus and further amplify it. However, their analysis is conducted only on models&#8217; top predictions. In this paper, we investigate the gender bias amplification issue from the distribution perspective and demonstrate that the bias is amplified in the view of predicted probability distribution over labels. We further propose a bias mitigation approach based on posterior regularization. With little performance loss, our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> can almost remove the bias amplification in the distribution. Our study sheds the light on understanding the bias amplification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.265.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--265 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.265 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.265.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929244 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.265/>Towards Understanding Gender Bias in Relation Extraction</a></strong><br><a href=/people/a/andrew-gaut/>Andrew Gaut</a>
|
<a href=/people/t/tony-sun/>Tony Sun</a>
|
<a href=/people/s/shirlyn-tang/>Shirlyn Tang</a>
|
<a href=/people/y/yuxin-huang/>Yuxin Huang</a>
|
<a href=/people/j/jing-qian/>Jing Qian</a>
|
<a href=/people/m/mai-elsherief/>Mai ElSherief</a>
|
<a href=/people/j/jieyu-zhao/>Jieyu Zhao</a>
|
<a href=/people/d/diba-mirza/>Diba Mirza</a>
|
<a href=/people/e/elizabeth-belding/>Elizabeth Belding</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--265><div class="card-body p-3 small">Recent developments in Neural Relation Extraction (NRE) have made significant strides towards Automated Knowledge Base Construction. While much attention has been dedicated towards improvements in <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, there have been no attempts in the literature to evaluate <a href=https://en.wikipedia.org/wiki/Bias>social biases</a> exhibited in NRE systems. In this paper, we create WikiGenderBias, a distantly supervised dataset composed of over 45,000 sentences including a 10 % human annotated test set for the purpose of analyzing gender bias in relation extraction systems. We find that when extracting spouse-of and hypernym (i.e., occupation) relations, an NRE system performs differently when the gender of the target entity is different. However, such disparity does not appear when extracting relations such as <a href=https://en.wikipedia.org/wiki/Birth_date>birthDate</a> or <a href=https://en.wikipedia.org/wiki/Place_of_birth>birthPlace</a>. We also analyze how existing bias mitigation techniques, such as name anonymization, word embedding debiasing, and <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> affect the NRE system in terms of maintaining the test performance and reducing biases. Unfortunately, due to NRE models rely heavily on surface level cues, we find that existing bias mitigation approaches have a negative effect on NRE. Our analysis lays groundwork for future quantifying and mitigating bias in NRE.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.341.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--341 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.341 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928884 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.341" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.341/>SentiBERT : A Transferable Transformer-Based Architecture for Compositional Sentiment Semantics<span class=acl-fixed-case>S</span>enti<span class=acl-fixed-case>BERT</span>: A Transferable Transformer-Based Architecture for Compositional Sentiment Semantics</a></strong><br><a href=/people/d/da-yin/>Da Yin</a>
|
<a href=/people/t/tao-meng/>Tao Meng</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--341><div class="card-body p-3 small">We propose SentiBERT, a variant of <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> that effectively captures compositional sentiment semantics. The model incorporates contextualized representation with binary constituency parse tree to capture semantic composition. Comprehensive experiments demonstrate that SentiBERT achieves competitive performance on phrase-level sentiment classification. We further demonstrate that the sentiment composition learned from the phrase-level annotations on <a href=https://en.wikipedia.org/wiki/Standard_score>SST</a> can be transferred to other sentiment analysis tasks as well as related tasks, such as emotion classification tasks. Moreover, we conduct <a href=https://en.wikipedia.org/wiki/Ablation>ablation studies</a> and design visualization methods to understand SentiBERT. We show that SentiBERT is better than baseline approaches in capturing <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>negation</a> and the <a href=https://en.wikipedia.org/wiki/Contrast_(linguistics)>contrastive relation</a> and model the compositional sentiment semantics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.449.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--449 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.449 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929076 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.449" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.449/>A Transformer-based Approach for Source Code Summarization</a></strong><br><a href=/people/w/wasi-ahmad/>Wasi Ahmad</a>
|
<a href=/people/s/saikat-chakraborty/>Saikat Chakraborty</a>
|
<a href=/people/b/baishakhi-ray/>Baishakhi Ray</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--449><div class="card-body p-3 small">Generating a readable summary that describes the functionality of a program is known as source code summarization. In this task, learning code representation by modeling the pairwise relationship between code tokens to capture their long-range dependencies is crucial. To learn code representation for <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a>, we explore the Transformer model that uses a self-attention mechanism and has shown to be effective in capturing long-range dependencies. In this work, we show that despite the approach is simple, it outperforms the state-of-the-art techniques by a significant margin. We perform extensive analysis and ablation studies that reveal several important findings, e.g., the absolute encoding of source code tokens&#8217; position hinders, while relative encoding significantly improves the <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> performance. We have made our code publicly available to facilitate future research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.aacl-main.61.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--aacl-main--61 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.aacl-main.61 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.aacl-main.61" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.aacl-main.61/>Generating Sports News from Live Commentary : A Chinese Dataset for Sports Game Summarization<span class=acl-fixed-case>C</span>hinese Dataset for Sports Game Summarization</a></strong><br><a href=/people/k/kuan-hao-huang/>Kuan-Hao Huang</a>
|
<a href=/people/c/chen-li/>Chen Li</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/2020.aacl-main/ class=text-muted>Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--aacl-main--61><div class="card-body p-3 small">Sports game summarization focuses on generating news articles from <a href=https://en.wikipedia.org/wiki/Sports_commentator>live commentaries</a>. Unlike traditional summarization tasks, the source documents and the target summaries for sports game summarization tasks are written in quite different writing styles. In addition, live commentaries usually contain many <a href=https://en.wikipedia.org/wiki/Named_entity>named entities</a>, which makes summarizing sports games precisely very challenging. To deeply study this task, we present SportsSum, a Chinese sports game summarization dataset which contains 5,428 soccer games of live commentaries and the corresponding <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>. Additionally, we propose a two-step summarization model consisting of a selector and a rewriter for SportsSum. To evaluate the correctness of generated sports summaries, we design two novel score metrics : name matching score and event matching score. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performs better than other summarization baselines on ROUGE scores as well as the two designed scores.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.291.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--291 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.291 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.findings-emnlp.291" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.291/>Towards Controllable Biases in Language Generation<span class=acl-fixed-case>C</span>ontrollable <span class=acl-fixed-case>B</span>iases in <span class=acl-fixed-case>L</span>anguage <span class=acl-fixed-case>G</span>eneration</a></strong><br><a href=/people/e/emily-sheng/>Emily Sheng</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/p/prem-natarajan/>Prem Natarajan</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--291><div class="card-body p-3 small">We present a general approach towards controllable societal biases in natural language generation (NLG). Building upon the idea of adversarial triggers, we develop a method to induce societal biases in generated text when input prompts contain mentions of specific demographic groups. We then analyze two scenarios : 1) inducing negative biases for one demographic and positive biases for another demographic, and 2) equalizing biases between demographics. The former <a href=https://en.wikipedia.org/wiki/Scenario>scenario</a> enables us to detect the types of <a href=https://en.wikipedia.org/wiki/Bias>biases</a> present in the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. Specifically, we show the effectiveness of our approach at facilitating bias analysis by finding topics that correspond to demographic inequalities in generated text and comparing the relative effectiveness of inducing biases for different demographics. The second <a href=https://en.wikipedia.org/wiki/Scenario>scenario</a> is useful for mitigating biases in downstream applications such as dialogue generation. In our experiments, the mitigation technique proves to be effective at equalizing the amount of biases across demographics while simultaneously generating less negatively biased text overall.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1339.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1339 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1339 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1339.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1339" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1339/>The Woman Worked as a Babysitter : On Biases in Language Generation</a></strong><br><a href=/people/e/emily-sheng/>Emily Sheng</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/p/prem-natarajan/>Premkumar Natarajan</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1339><div class="card-body p-3 small">We present a systematic study of biases in natural language generation (NLG) by analyzing text generated from prompts that contain mentions of different demographic groups. In this work, we introduce the notion of the regard towards a demographic, use the varying levels of regard towards different demographics as a defining metric for bias in NLG, and analyze the extent to which sentiment scores are a relevant proxy metric for <a href=https://en.wikipedia.org/wiki/Opinion_poll>regard</a>. To this end, we collect strategically-generated text from <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> and manually annotate the text with both sentiment and regard scores. Additionally, we build an automatic regard classifier through <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>, so that we can analyze biases in unseen text. Together, these <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> reveal the extent of the biased nature of language model generations. Our analysis provides a study of biases in NLG, bias metrics and correlated human judgments, and empirical evidence on the usefulness of our annotated dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1531.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1531 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1531 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1531" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1531/>Examining Gender Bias in <a href=https://en.wikipedia.org/wiki/Language>Languages</a> with Grammatical Gender</a></strong><br><a href=/people/p/pei-zhou/>Pei Zhou</a>
|
<a href=/people/w/weijia-shi/>Weijia Shi</a>
|
<a href=/people/j/jieyu-zhao/>Jieyu Zhao</a>
|
<a href=/people/k/kuan-hao-huang/>Kuan-Hao Huang</a>
|
<a href=/people/m/muhao-chen/>Muhao Chen</a>
|
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1531><div class="card-body p-3 small">Recent studies have shown that <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> exhibit <a href=https://en.wikipedia.org/wiki/Gender_bias>gender bias</a> inherited from the training corpora. However, most studies to date have focused on quantifying and mitigating such <a href=https://en.wikipedia.org/wiki/Bias>bias</a> only in <a href=https://en.wikipedia.org/wiki/English_language>English</a>. These analyses can not be directly extended to <a href=https://en.wikipedia.org/wiki/Language>languages</a> that exhibit <a href=https://en.wikipedia.org/wiki/Agreement_(linguistics)>morphological agreement</a> on gender, such as <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a> and <a href=https://en.wikipedia.org/wiki/French_language>French</a>. In this paper, we propose new metrics for evaluating <a href=https://en.wikipedia.org/wiki/Gender_bias>gender bias</a> in <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> of these languages and further demonstrate evidence of <a href=https://en.wikipedia.org/wiki/Gender_bias>gender bias</a> in bilingual embeddings which align these languages with <a href=https://en.wikipedia.org/wiki/English_language>English</a>. Finally, we extend an existing approach to mitigate gender bias in <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a> of these <a href=https://en.wikipedia.org/wiki/Language>languages</a> under both monolingual and bilingual settings. Experiments on modified Word Embedding Association Test, word similarity, word translation, and word pair translation tasks show that the proposed approaches can effectively reduce the gender bias while preserving the utility of the original embeddings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-info align-middle mr-1" href=#abstract-D19-2004 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-2004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-2004/>Bias and Fairness in Natural Language Processing</a></strong><br><a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/v/vinodkumar-prabhakaran/>Vinodkumar Prabhakaran</a>
|
<a href=/people/v/vicente-ordonez/>Vicente Ordonez</a><br><a href=/volumes/D19-2/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): Tutorial Abstracts</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-2004><div class="card-body p-3 small">Recent advances in data-driven machine learning techniques (e.g., deep neural networks) have revolutionized many natural language processing applications. These approaches automatically learn how to make decisions based on the statistics and diagnostic information from large amounts of training data. Despite the remarkable accuracy of machine learning in various applications, learning algorithms run the risk of relying on societal biases encoded in the training data to make predictions. This often occurs even when gender and ethnicity information is not explicitly provided to the system because learning algorithms are able to discover implicit associations between individuals and their demographic information based on other variables such as names, titles, home addresses, etc. Therefore, machine learning algorithms risk potentially encouraging unfair and discriminatory decision making and raise serious privacy concerns. Without properly quantifying and reducing the reliance on such correlations, broad adoption of these models might have the undesirable effect of magnifying harmful stereotypes or implicit biases that rely on sensitive demographic attributes.\n\nIn this tutorial, we will review the history of bias and fairness studies in machine learning and language processing and present recent community effort in quantifying and mitigating bias in natural language processing models for a wide spectrum of tasks, including word embeddings, co-reference resolution, machine translation, and vision-and-language tasks. In particular, we will focus on the following topics:\n\n+ Definitions of fairness and bias.\n\n+ Data, algorithms, and models that propagate and even amplify social bias to NLP applications and metrics to quantify these biases.\n\n+ Algorithmic solutions; learning objective; design principles to prevent social bias in NLP systems and their potential drawbacks.\n\nThe tutorial will bring researchers and practitioners to be aware of this issue, and encourage the research community to propose innovative solutions to promote fairness in NLP.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1064.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1064 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1064 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/347396468 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-1064/>Gender Bias in Contextualized Word Embeddings</a></strong><br><a href=/people/j/jieyu-zhao/>Jieyu Zhao</a>
|
<a href=/people/t/tianlu-wang/>Tianlu Wang</a>
|
<a href=/people/m/mark-yatskar/>Mark Yatskar</a>
|
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a>
|
<a href=/people/v/vicente-ordonez/>Vicente Ordonez</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1064><div class="card-body p-3 small">In this paper, we quantify, analyze and mitigate <a href=https://en.wikipedia.org/wiki/Gender_bias>gender bias</a> exhibited in ELMo&#8217;s contextualized word vectors. First, we conduct several intrinsic analyses and find that (1) training data for ELMo contains significantly more male than female entities, (2) the trained ELMo embeddings systematically encode gender information and (3) ELMo unequally encodes gender information about male and female entities. Then, we show that a state-of-the-art coreference system that depends on ELMo inherits its bias and demonstrates significant bias on the WinoBias probing corpus. Finally, we explore two methods to mitigate such gender bias and show that the bias demonstrated on WinoBias can be eliminated.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1253.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1253 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1253 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N19-1253.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1253" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N19-1253/>On Difficulties of Cross-Lingual Transfer with Order Differences : A Case Study on Dependency Parsing</a></strong><br><a href=/people/w/wasi-ahmad/>Wasi Ahmad</a>
|
<a href=/people/z/zhisong-zhang/>Zhisong Zhang</a>
|
<a href=/people/x/xuezhe-ma/>Xuezhe Ma</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1253><div class="card-body p-3 small">Different languages might have different <a href=https://en.wikipedia.org/wiki/Part_of_speech>word orders</a>. In this paper, we investigate crosslingual transfer and posit that an orderagnostic model will perform better when transferring to distant foreign languages. To test our hypothesis, we train dependency parsers on an <a href=https://en.wikipedia.org/wiki/English_language>English corpus</a> and evaluate their transfer performance on 30 other languages. Specifically, we compare <a href=https://en.wikipedia.org/wiki/Encoder>encoders</a> and <a href=https://en.wikipedia.org/wiki/Code>decoders</a> based on <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>Recurrent Neural Networks (RNNs)</a> and modified self-attentive architectures. The former relies on sequential information while the latter is more flexible at modeling <a href=https://en.wikipedia.org/wiki/Word_order>word order</a>. Rigorous experiments and detailed analysis shows that RNN-based architectures transfer well to languages that are close to <a href=https://en.wikipedia.org/wiki/English_language>English</a>, while self-attentive models have better overall cross-lingual transferability and perform especially well on distant languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1402.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1402 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1402 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1402" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1402/>Few-Shot Representation Learning for Out-Of-Vocabulary Words</a></strong><br><a href=/people/z/ziniu-hu/>Ziniu Hu</a>
|
<a href=/people/t/ting-chen/>Ting Chen</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/y/yizhou-sun/>Yizhou Sun</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1402><div class="card-body p-3 small">Existing approaches for learning word embedding often assume there are sufficient occurrences for each word in the corpus, such that the representation of words can be accurately estimated from their contexts. However, in real-world scenarios, out-of-vocabulary (a.k.a. OOV) words that do not appear in training corpus emerge frequently. How to learn accurate representations of these words to augment a pre-trained embedding by only a few observations is a challenging research problem. In this paper, we formulate the learning of OOV embedding as a few-shot regression problem by fitting a representation function to predict an oracle embedding vector (defined as <a href=https://en.wikipedia.org/wiki/Embedding>embedding</a> trained with abundant observations) based on limited contexts. Specifically, we propose a novel hierarchical attention network-based embedding framework to serve as the neural regression function, in which the context information of a word is encoded and aggregated from K observations. Furthermore, we propose to use Model-Agnostic Meta-Learning (MAML) for adapting the learned model to the new <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> fast and robustly. Experiments show that the proposed approach significantly outperforms existing methods in constructing an accurate <a href=https://en.wikipedia.org/wiki/Embedding>embedding</a> for OOV words and improves downstream tasks when the <a href=https://en.wikipedia.org/wiki/Embedding>embedding</a> is utilized.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K19-1015.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K19-1015 data-toggle=collapse aria-expanded=false aria-controls=abstract-K19-1015 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K19-1015" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K19-1015/>Learning to Represent Bilingual Dictionaries</a></strong><br><a href=/people/m/muhao-chen/>Muhao Chen</a>
|
<a href=/people/y/yingtao-tian/>Yingtao Tian</a>
|
<a href=/people/h/haochen-chen/>Haochen Chen</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/s/steven-skiena/>Steven Skiena</a>
|
<a href=/people/c/carlo-zaniolo/>Carlo Zaniolo</a><br><a href=/volumes/K19-1/ class=text-muted>Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K19-1015><div class="card-body p-3 small">Bilingual word embeddings have been widely used to capture the correspondence of lexical semantics in different <a href=https://en.wikipedia.org/wiki/Language>human languages</a>. However, the cross-lingual correspondence between sentences and words is less studied, despite that this correspondence can significantly benefit many applications such as crosslingual semantic search and textual inference. To bridge this gap, we propose a neural embedding model that leverages <a href=https://en.wikipedia.org/wiki/Bilingual_dictionary>bilingual dictionaries</a>. The proposed model is trained to map the lexical definitions to the cross-lingual target words, for which we explore with different sentence encoding techniques. To enhance the learning process on limited resources, our model adopts several critical learning strategies, including multi-task learning on different bridges of languages, and joint learning of the dictionary model with a bilingual word embedding model. We conduct experiments on two new <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. In the cross-lingual reverse dictionary retrieval task, we demonstrate that our model is capable of comprehending bilingual concepts based on descriptions, and the proposed learning strategies are effective. In the bilingual paraphrase identification task, we show that our model effectively associates sentences in different languages via a shared embedding space, and outperforms existing approaches in identifying bilingual paraphrases.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-2003 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-2003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-2003.Datasets.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-2003/>Gender Bias in <a href=https://en.wikipedia.org/wiki/Coreference_resolution>Coreference Resolution</a> : Evaluation and Debiasing Methods</a></strong><br><a href=/people/j/jieyu-zhao/>Jieyu Zhao</a>
|
<a href=/people/t/tianlu-wang/>Tianlu Wang</a>
|
<a href=/people/m/mark-yatskar/>Mark Yatskar</a>
|
<a href=/people/v/vicente-ordonez/>Vicente Ordonez</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-2003><div class="card-body p-3 small">In this paper, we introduce a new <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmark</a> for co-reference resolution focused on <a href=https://en.wikipedia.org/wiki/Sexism>gender bias</a>, WinoBias. Our <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> contains Winograd-schema style sentences with entities corresponding to people referred by their occupation (e.g. the nurse, the doctor, the carpenter). We demonstrate that a rule-based, a feature-rich, and a neural coreference system all link gendered pronouns to pro-stereotypical entities with higher accuracy than anti-stereotypical entities, by an average difference of 21.1 in <a href=https://en.wikipedia.org/wiki/F1_score>F1 score</a>. Finally, we demonstrate a data-augmentation approach that, in combination with existing word-embedding debiasing techniques, removes the bias demonstrated by these systems in WinoBias without significantly affecting their performance on existing datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1221.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1221 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1221 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1221.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1221" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1221/>Building <a href=https://en.wikipedia.org/wiki/Language_model>Language Models</a> for Text with Named Entities</a></strong><br><a href=/people/m/md-rizwan-parvez/>Md Rizwan Parvez</a>
|
<a href=/people/s/saikat-chakraborty/>Saikat Chakraborty</a>
|
<a href=/people/b/baishakhi-ray/>Baishakhi Ray</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1221><div class="card-body p-3 small">Text in many domains involves a significant amount of <a href=https://en.wikipedia.org/wiki/Named_entity>named entities</a>. Predicting the entity names is often challenging for a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> as they appear less frequent on the training corpus. In this paper, we propose a novel and effective approach to building a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> which can learn the entity names by leveraging their entity type information. We also introduce two <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark datasets</a> based on recipes and <a href=https://en.wikipedia.org/wiki/Java_(programming_language)>Java programming codes</a>, on which we evaluate the proposed <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves 52.2 % better perplexity in recipe generation and 22.06 % on <a href=https://en.wikipedia.org/wiki/Code_generation_(compiler)>code generation</a> than state-of-the-art language models.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2009 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/I17-2009.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=I17-2009" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/I17-2009/>Counterfactual Language Model Adaptation for Suggesting Phrases</a></strong><br><a href=/people/k/kenneth-arnold/>Kenneth Arnold</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/a/adam-kalai/>Adam Kalai</a><br><a href=/volumes/I17-2/ class=text-muted>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2009><div class="card-body p-3 small">Mobile devices use <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> to suggest words and phrases for use in <a href=https://en.wikipedia.org/wiki/Computer_terminal>text entry</a>. Traditional <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> are based on contextual word frequency in a static corpus of text. However, certain types of phrases, when offered to writers as suggestions, may be systematically chosen more often than their frequency would predict. In this paper, we propose the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> of generating suggestions that writers accept, a related but distinct <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> to making accurate predictions. Although this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is fundamentally interactive, we propose a counterfactual setting that permits offline training and evaluation. We find that even a simple <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> can capture text characteristics that improve <a href=https://en.wikipedia.org/wiki/Acceptability>acceptability</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2613.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2613 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2613 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2613/>Beyond Bilingual : Multi-sense Word Embeddings using Multilingual Context</a></strong><br><a href=/people/s/shyam-upadhyay/>Shyam Upadhyay</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/m/matt-taddy/>Matt Taddy</a>
|
<a href=/people/a/adam-kalai/>Adam Kalai</a>
|
<a href=/people/j/james-zou/>James Zou</a><br><a href=/volumes/W17-26/ class=text-muted>Proceedings of the 2nd Workshop on Representation Learning for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2613><div class="card-body p-3 small">Word embeddings, which represent a word as a point in a <a href=https://en.wikipedia.org/wiki/Vector_space>vector space</a>, have become ubiquitous to several NLP tasks. A recent line of work uses bilingual (two languages) corpora to learn a different vector for each sense of a word, by exploiting crosslingual signals to aid sense identification. We present a multi-view Bayesian non-parametric algorithm which improves multi-sense wor d embeddings by (a) using multilingual (i.e., more than two languages) corpora to significantly improve sense embeddings beyond what one achieves with bilingual information, and (b) uses a principled approach to learn a variable number of senses per word, in a data-driven manner. Ours is the first approach with the ability to leverage multilingual corpora efficiently for multi-sense representation learning. Experiments show that multilingual training significantly improves performance over monolingual and bilingual training, by allowing us to combine different parallel corpora to leverage multilingual context. Multilingual training yields comparable performance to a state of the art <a href=https://en.wikipedia.org/wiki/Monolingualism>monolingual model</a> trained on five times more training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4300.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4300/>Proceedings of the 2nd Workshop on Structured Prediction for Natural Language Processing</a></strong><br><a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/m/ming-wei-chang/>Ming-Wei Chang</a>
|
<a href=/people/v/vivek-srikumar/>Vivek Srikumar</a>
|
<a href=/people/a/alexander-m-rush/>Alexander M. Rush</a><br><a href=/volumes/W17-43/ class=text-muted>Proceedings of the 2nd Workshop on Structured Prediction for Natural Language Processing</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1323.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1323 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1323 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D17-1323" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D17-1323/>Men Also Like Shopping : Reducing Gender Bias Amplification using Corpus-level Constraints</a></strong><br><a href=/people/j/jieyu-zhao/>Jieyu Zhao</a>
|
<a href=/people/t/tianlu-wang/>Tianlu Wang</a>
|
<a href=/people/m/mark-yatskar/>Mark Yatskar</a>
|
<a href=/people/v/vicente-ordonez/>Vicente Ordonez</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1323><div class="card-body p-3 small">Language is increasingly being used to de-fine rich visual recognition problems with supporting image collections sourced from the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>web</a>. Structured prediction models are used in these tasks to take advantage of correlations between co-occurring labels and visual input but risk inadvertently encoding social biases found in web corpora. In this work, we study <a href=https://en.wikipedia.org/wiki/Data>data</a> and <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> associated with multilabel object classification and visual semantic role labeling. We find that (a) <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> for these tasks contain significant <a href=https://en.wikipedia.org/wiki/Gender_bias>gender bias</a> and (b) <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on these <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> further amplify existing bias. For example, the activity cooking is over 33 % more likely to involve females than males in a training set, and a trained <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> further amplifies the disparity to 68 % at test time. We propose to inject corpus-level constraints for calibrating existing structured prediction models and design an <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> based on <a href=https://en.wikipedia.org/wiki/Lagrangian_and_Eulerian_specification_of_the_flow_field>Lagrangian relaxation</a> for collective inference. Our method results in almost no performance loss for the underlying recognition task but decreases the magnitude of bias amplification by 47.5 % and 40.5 % for multilabel classification and visual semantic role labeling, respectively</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Kai-Wei+Chang" title="Search for 'Kai-Wei Chang' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/j/jieyu-zhao/ class=align-middle>Jieyu Zhao</a>
<span class="badge badge-secondary align-middle ml-2">9</span></li><li class=list-group-item><a href=/people/n/nanyun-peng/ class=align-middle>Nanyun Peng</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/v/vicente-ordonez/ class=align-middle>Vicente Ordonez</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/k/kuan-hao-huang/ class=align-middle>Kuan-Hao Huang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/e/emily-sheng/ class=align-middle>Emily Sheng</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/p/prem-natarajan/ class=align-middle>Prem Natarajan</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/t/tianlu-wang/ class=align-middle>Tianlu Wang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/mark-yatskar/ class=align-middle>Mark Yatskar</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/adam-kalai/ class=align-middle>Adam Kalai</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/tao-meng/ class=align-middle>Tao Meng</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/da-yin/ class=align-middle>Da Yin</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/w/wasi-ahmad/ class=align-middle>Wasi Ahmad</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/saikat-chakraborty/ class=align-middle>Saikat Chakraborty</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/baishakhi-ray/ class=align-middle>Baishakhi Ray</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/cho-jui-hsieh/ class=align-middle>Cho-Jui Hsieh</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/liunian-harold-li/ class=align-middle>Liunian Harold Li</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/ziniu-hu/ class=align-middle>Ziniu Hu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/muhao-chen/ class=align-middle>Muhao Chen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/ryan-cotterell/ class=align-middle>Ryan Cotterell</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/md-rizwan-parvez/ class=align-middle>Md. Rizwan Parvez</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/kenneth-arnold/ class=align-middle>Kenneth Arnold</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/subhabrata-mukherjee/ class=align-middle>Subhabrata Mukherjee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/saghar-hosseini/ class=align-middle>Saghar Hosseini</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ahmed-hassan-awadallah/ class=align-middle>Ahmed Hassan Awadallah</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shengyu-jia/ class=align-middle>Shengyu Jia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrew-gaut/ class=align-middle>Andrew Gaut</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tony-sun/ class=align-middle>Tony Sun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shirlyn-tang/ class=align-middle>Shirlyn Tang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yuxin-huang/ class=align-middle>Yuxin Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jing-qian/ class=align-middle>Jing Qian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mai-elsherief/ class=align-middle>Mai ElSherief</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/diba-mirza/ class=align-middle>Diba Mirza</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elizabeth-belding/ class=align-middle>Elizabeth Belding</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/william-yang-wang/ class=align-middle>William Yang Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shyam-upadhyay/ class=align-middle>Shyam Upadhyay</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/matt-taddy/ class=align-middle>Matt Taddy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/james-zou/ class=align-middle>James Zou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/ming-wei-chang/ class=align-middle>Ming-Wei Chang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vivek-srikumar/ class=align-middle>Vivek Srikumar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexander-m-rush/ class=align-middle>Alexander M. Rush</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chen-li/ class=align-middle>Chen Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/liping-yuan/ class=align-middle>Liping Yuan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaoqing-zheng/ class=align-middle>Xiaoqing Zheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yi-zhou/ class=align-middle>Yi Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/he-he/ class=align-middle>He He</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/robin-jia/ class=align-middle>Robin Jia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sameer-singh/ class=align-middle>Sameer Singh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pei-zhou/ class=align-middle>Pei Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/weijia-shi/ class=align-middle>Weijia Shi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vinodkumar-prabhakaran/ class=align-middle>Vinodkumar Prabhakaran</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chong-zhang/ class=align-middle>Chong Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/huan-zhang/ class=align-middle>Huan Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ankith-uppunda/ class=align-middle>Ankith Uppunda</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/susan-cochran/ class=align-middle>Susan Cochran</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jacob-foster/ class=align-middle>Jacob Foster</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alina-arseniev-koehler/ class=align-middle>Alina Arseniev-Koehler</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vickie-mays/ class=align-middle>Vickie Mays</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haoxuan-you/ class=align-middle>Haoxuan You</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhecan-wang/ class=align-middle>Zhecan Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alireza-zareian/ class=align-middle>Alireza Zareian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shih-fu-chang/ class=align-middle>Shih-Fu Chang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhisong-zhang/ class=align-middle>Zhisong Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xuezhe-ma/ class=align-middle>Xuezhe Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eduard-hovy/ class=align-middle>Eduard Hovy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yada-pruksachatkun/ class=align-middle>Yada Pruksachatkun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anil-ramakrishna/ class=align-middle>Anil Ramakrishna</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/satyapriya-krishna/ class=align-middle>Satyapriya Krishna</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jwala-dhamala/ class=align-middle>Jwala Dhamala</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tanaya-guha/ class=align-middle>Tanaya Guha</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiang-ren/ class=align-middle>Xiang Ren</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/ting-chen/ class=align-middle>Ting Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yizhou-sun/ class=align-middle>Yizhou Sun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yingtao-tian/ class=align-middle>Yingtao Tian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haochen-chen/ class=align-middle>Haochen Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/steven-skiena/ class=align-middle>Steven Skiena</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/carlo-zaniolo/ class=align-middle>Carlo Zaniolo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/aacl/ class=align-middle>AACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/trustnlp/ class=align-middle>TrustNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright &nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>