<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Kathleen McKeown - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Kathleen</span> <span class=font-weight-bold>McKeown</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Kathy <span class=font-weight-normal>McKeown</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-main.235.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-main--235 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-main.235 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.eacl-main.235" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-main.235/>Entity-level Factual Consistency of Abstractive Text Summarization</a></strong><br><a href=/people/f/feng-nan/>Feng Nan</a>
|
<a href=/people/r/ramesh-nallapati/>Ramesh Nallapati</a>
|
<a href=/people/z/zhiguo-wang/>Zhiguo Wang</a>
|
<a href=/people/c/cicero-dos-santos/>Cicero Nogueira dos Santos</a>
|
<a href=/people/h/henghui-zhu/>Henghui Zhu</a>
|
<a href=/people/d/dejiao-zhang/>Dejiao Zhang</a>
|
<a href=/people/k/kathleen-mckeown/>Kathleen McKeown</a>
|
<a href=/people/b/bing-xiang/>Bing Xiang</a><br><a href=/volumes/2021.eacl-main/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-main--235><div class="card-body p-3 small">A key challenge for abstractive summarization is ensuring factual consistency of the generated summary with respect to the original document. For example, state-of-the-art <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on existing datasets exhibit entity hallucination, generating names of entities that are not present in the source document. We propose a set of new metrics to quantify the entity-level factual consistency of generated summaries and we show that the entity hallucination problem can be alleviated by simply filtering the training data. In addition, we propose a summary-worthy entity classification task to the training process as well as a joint entity and summary generation approach, which yield further improvements in entity level metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.230.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--230 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.230 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.230" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.230/>Emotion-Infused Models for Explainable Psychological Stress Detection</a></strong><br><a href=/people/e/elsbeth-turcan/>Elsbeth Turcan</a>
|
<a href=/people/s/smaranda-muresan/>Smaranda Muresan</a>
|
<a href=/people/k/kathleen-mckeown/>Kathleen McKeown</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--230><div class="card-body p-3 small">The problem of detecting psychological stress in online posts, and more broadly, of detecting people in distress or in need of help, is a sensitive application for which the ability to interpret models is vital. Here, we present work exploring the use of a semantically related task, <a href=https://en.wikipedia.org/wiki/Emotion_detection>emotion detection</a>, for equally competent but more explainable and human-like psychological stress detection as compared to a black-box model. In particular, we explore the use of <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a> as well as emotion-based language model fine-tuning. With our emotion-infused models, we see comparable results to state-of-the-art BERT. Our analysis of the words used for prediction show that our emotion-infused models mirror psychological components of stress.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.315.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--315 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.315 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.315/>Margin-aware Unsupervised Domain Adaptation for Cross-lingual Text Labeling</a></strong><br><a href=/people/d/dejiao-zhang/>Dejiao Zhang</a>
|
<a href=/people/r/ramesh-nallapati/>Ramesh Nallapati</a>
|
<a href=/people/h/henghui-zhu/>Henghui Zhu</a>
|
<a href=/people/f/feng-nan/>Feng Nan</a>
|
<a href=/people/c/cicero-dos-santos/>Cicero Nogueira dos Santos</a>
|
<a href=/people/k/kathleen-mckeown/>Kathleen McKeown</a>
|
<a href=/people/b/bing-xiang/>Bing Xiang</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--315><div class="card-body p-3 small">Unsupervised domain adaptation addresses the problem of leveraging labeled data in a source domain to learn a well-performing <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> in a target domain where labels are unavailable. In this paper, we improve upon a recent theoretical work (Zhang et al., 2019b) and adopt the Margin Disparity Discrepancy (MDD) unsupervised domain adaptation algorithm to solve the cross-lingual text labeling problems. Experiments on cross-lingual document classification and NER demonstrate the proposed domain adaptation approach advances the state-of-the-art results by a large margin. Specifically, we improve MDD by efficiently optimizing the margin loss on the source domain via Virtual Adversarial Training (VAT). This bridges the gap between theory and the <a href=https://en.wikipedia.org/wiki/Loss_function>loss function</a> used in the original work Zhang et al. (2019b), and thereby significantly boosts the performance. Our numerical results also indicate that VAT can remarkably improve the <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a> performance of both domains for various domain adaptation approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clssts-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.clssts-1.0/>Proceedings of the workshop on Cross-Language Search and Summarization of Text and Speech (CLSSTS2020)</a></strong><br><a href=/people/k/kathleen-mckeown/>Kathy McKeown</a>
|
<a href=/people/d/douglas-w-oard/>Douglas W. Oard</a>
|
<a href=/people/e/elizabeth/>Elizabeth</a>
|
<a href=/people/r/richard-schwartz/>Richard Schwartz</a><br><a href=/volumes/2020.clssts-1/ class=text-muted>Proceedings of the workshop on Cross-Language Search and Summarization of Text and Speech (CLSSTS2020)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wmt-1.141.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--wmt-1--141 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.wmt-1.141 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939650 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.wmt-1.141" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.wmt-1.141/>Incorporating Terminology Constraints in Automatic Post-Editing</a></strong><br><a href=/people/d/david-wan/>David Wan</a>
|
<a href=/people/c/chris-kedzie/>Chris Kedzie</a>
|
<a href=/people/f/faisal-ladhak/>Faisal Ladhak</a>
|
<a href=/people/m/marine-carpuat/>Marine Carpuat</a>
|
<a href=/people/k/kathleen-mckeown/>Kathleen McKeown</a><br><a href=/volumes/2020.wmt-1/ class=text-muted>Proceedings of the Fifth Conference on Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--wmt-1--141><div class="card-body p-3 small">Users of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation (MT)</a> may want to ensure the use of specific <a href=https://en.wikipedia.org/wiki/Terminology>lexical terminologies</a>. While there exist techniques for incorporating terminology constraints during <a href=https://en.wikipedia.org/wiki/Inference>inference</a> for MT, current APE approaches can not ensure that they will appear in the final translation. In this paper, we present both autoregressive and non-autoregressive models for lexically constrained APE, demonstrating that our approach enables preservation of 95 % of the terminologies and also improves translation quality on English-German benchmarks. Even when applied to lexically constrained MT output, our approach is able to improve preservation of the terminologies. However, we show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> do not learn to copy constraints systematically and suggest a simple data augmentation technique that leads to improved performance and <a href=https://en.wikipedia.org/wiki/Robust_statistics>robustness</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6213.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-6213 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-6213 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-6213.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-6213/>Dreaddit : A Reddit Dataset for <a href=https://en.wikipedia.org/wiki/Stress&#8211;strain_analysis>Stress Analysis</a> in <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a><span class=acl-fixed-case>D</span>readdit: A <span class=acl-fixed-case>R</span>eddit Dataset for Stress Analysis in Social Media</a></strong><br><a href=/people/e/elsbeth-turcan/>Elsbeth Turcan</a>
|
<a href=/people/k/kathleen-mckeown/>Kathy McKeown</a><br><a href=/volumes/D19-62/ class=text-muted>Proceedings of the Tenth International Workshop on Health Text Mining and Information Analysis (LOUHI 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-6213><div class="card-body p-3 small">Stress is a nigh-universal human experience, particularly in the <a href=https://en.wikipedia.org/wiki/Online_and_offline>online world</a>. While <a href=https://en.wikipedia.org/wiki/Stress_(biology)>stress</a> can be a motivator, too much <a href=https://en.wikipedia.org/wiki/Stress_(biology)>stress</a> is associated with many negative health outcomes, making its identification useful across a range of domains. However, existing computational research typically only studies <a href=https://en.wikipedia.org/wiki/Stress_(biology)>stress</a> in domains such as <a href=https://en.wikipedia.org/wiki/Speech>speech</a>, or in short genres such as <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>. We present Dreaddit, a new text corpus of lengthy multi-domain social media data for the identification of stress. Our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> consists of 190 K posts from five different categories of <a href=https://en.wikipedia.org/wiki/Reddit>Reddit communities</a> ; we additionally label 3.5 K total segments taken from 3 K posts using <a href=https://en.wikipedia.org/wiki/Amazon_Mechanical_Turk>Amazon Mechanical Turk</a>. We present preliminary supervised learning methods for identifying <a href=https://en.wikipedia.org/wiki/Stress_(biology)>stress</a>, both neural and traditional, and analyze the complexity and diversity of the data and characteristics of each category.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3002 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3002/>Identifying therapist conversational actions across diverse <a href=https://en.wikipedia.org/wiki/Psychotherapy>psychotherapeutic approaches</a></a></strong><br><a href=/people/f/fei-tzin-lee/>Fei-Tzin Lee</a>
|
<a href=/people/d/derrick-hull/>Derrick Hull</a>
|
<a href=/people/j/jacob-levine/>Jacob Levine</a>
|
<a href=/people/b/bonnie-ray/>Bonnie Ray</a>
|
<a href=/people/k/kathleen-mckeown/>Kathy McKeown</a><br><a href=/volumes/W19-30/ class=text-muted>Proceedings of the Sixth Workshop on Computational Linguistics and Clinical Psychology</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3002><div class="card-body p-3 small">While conversation in therapy sessions can vary widely in both topic and style, an understanding of the underlying techniques used by therapists can provide valuable insights into how therapists best help clients of different types. Dialogue act classification aims to identify the conversational action each speaker takes at each utterance, such as <a href=https://en.wikipedia.org/wiki/Sympathy>sympathizing</a>, <a href=https://en.wikipedia.org/wiki/Problem_solving>problem-solving</a> or assumption checking. We propose to apply dialogue act classification to therapy transcripts, using a therapy-specific labeling scheme, in order to gain a high-level understanding of the flow of conversation in therapy sessions. We present a novel annotation scheme that spans multiple <a href=https://en.wikipedia.org/wiki/Psychotherapy>psychotherapeutic approaches</a>, apply it to a large and diverse corpus of psychotherapy transcripts, and present and discuss <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> results obtained using both SVM and neural network-based models. The results indicate that identifying the structure and flow of therapeutic actions is an obtainable goal, opening up the opportunity in the future to provide therapeutic recommendations tailored to specific client situations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8672.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8672 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8672 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W19-8672.Supplementary_Attachment.pdf data-toggle=tooltip data-placement=top title="Supplementary attachment"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-8672" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-8672/>A Good Sample is Hard to Find : Noise Injection Sampling and Self-Training for Neural Language Generation Models</a></strong><br><a href=/people/c/chris-kedzie/>Chris Kedzie</a>
|
<a href=/people/k/kathleen-mckeown/>Kathleen McKeown</a><br><a href=/volumes/W19-86/ class=text-muted>Proceedings of the 12th International Conference on Natural Language Generation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8672><div class="card-body p-3 small">Deep neural networks (DNN) are quickly becoming the de facto standard modeling method for many natural language generation (NLG) tasks. In order for such <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> to truly be useful, they must be capable of correctly generating utterances for novel meaning representations (MRs) at test time. In practice, even sophisticated DNNs with various forms of semantic control frequently fail to generate utterances faithful to the input MR. In this paper, we propose an architecture agnostic self-training method to sample novel MR / text utterance pairs to augment the original training data. Remarkably, after training on the augmented data, even simple encoder-decoder models with greedy decoding are capable of generating semantically correct utterances that are as good as state-of-the-art outputs in both automatic and human evaluations of quality.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1174.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1174 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1174 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1174" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N19-1174/>Fixed That for You : Generating Contrastive Claims with Semantic Edits</a></strong><br><a href=/people/c/christopher-hidey/>Christopher Hidey</a>
|
<a href=/people/k/kathleen-mckeown/>Kathy McKeown</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1174><div class="card-body p-3 small">Understanding contrastive opinions is a key component of argument generation. Central to an argument is the claim, a statement that is in dispute. Generating a counter-argument then requires generating a response in contrast to the main claim of the original argument. To generate contrastive claims, we create a corpus of Reddit comment pairs self-labeled by posters using the acronym FTFY (fixed that for you). We then train neural models on these pairs to edit the original claim and produce a new claim with a different view. We demonstrate significant improvement over a sequence-to-sequence baseline in BLEU score and a human evaluation for <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a>, <a href=https://en.wikipedia.org/wiki/Coherence_(linguistics)>coherence</a>, and <a href=https://en.wikipedia.org/wiki/Contrast_(vision)>contrast</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1467.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1467 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1467 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1467/>Neural Network Alignment for Sentential Paraphrases</a></strong><br><a href=/people/j/jessica-ouyang/>Jessica Ouyang</a>
|
<a href=/people/k/kathleen-mckeown/>Kathy McKeown</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1467><div class="card-body p-3 small">We present a monolingual alignment system for long, sentence- or clause-level alignments, and demonstrate that systems designed for word- or short phrase-based alignment are ill-suited for these longer alignments. Our <a href=https://en.wikipedia.org/wiki/System>system</a> is capable of aligning semantically similar spans of arbitrary length. We achieve significantly higher <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a> on aligning phrases of four or more words and outperform state-of-the- art aligners on the long alignments in the MSR RTE corpus.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1005 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D18-1005.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/305204297 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1005" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1005/>Detecting Gang-Involved Escalation on <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a> Using Context</a></strong><br><a href=/people/s/serina-chang/>Serina Chang</a>
|
<a href=/people/r/ruiqi-zhong/>Ruiqi Zhong</a>
|
<a href=/people/e/ethan-adams/>Ethan Adams</a>
|
<a href=/people/f/fei-tzin-lee/>Fei-Tzin Lee</a>
|
<a href=/people/s/siddharth-varia/>Siddharth Varia</a>
|
<a href=/people/d/desmond-patton/>Desmond Patton</a>
|
<a href=/people/w/william-frey/>William Frey</a>
|
<a href=/people/c/chris-kedzie/>Chris Kedzie</a>
|
<a href=/people/k/kathleen-mckeown/>Kathy McKeown</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1005><div class="card-body p-3 small">Gang-involved youth in cities such as Chicago have increasingly turned to <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> to post about their experiences and intents online. In some situations, when they experience the loss of a loved one, their online expression of emotion may evolve into aggression towards rival gangs and ultimately into real-world violence. In this paper, we present a novel <a href=https://en.wikipedia.org/wiki/System>system</a> for detecting Aggression and Loss in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. Our system features the use of domain-specific resources automatically derived from a large unlabeled corpus, and contextual representations of the emotional and semantic content of the user&#8217;s recent tweets as well as their interactions with other users. Incorporating <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context</a> in our Convolutional Neural Network (CNN) leads to a significant improvement.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1208.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1208 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1208 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D18-1208.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/305886331 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1208" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1208/>Content Selection in Deep Learning Models of Summarization</a></strong><br><a href=/people/c/chris-kedzie/>Chris Kedzie</a>
|
<a href=/people/k/kathleen-mckeown/>Kathleen McKeown</a>
|
<a href=/people/h/hal-daume-iii/>Hal Daumé III</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1208><div class="card-body p-3 small">We carry out experiments with deep learning models of <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> across the domains of <a href=https://en.wikipedia.org/wiki/News>news</a>, personal stories, meetings, and <a href=https://en.wikipedia.org/wiki/Medicine>medical articles</a> in order to understand how content selection is performed. We find that many sophisticated <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> of state of the art extractive summarizers do not improve performance over simpler <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. These results suggest that it is easier to create a <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarizer</a> for a new domain than previous work suggests and bring into question the benefit of <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning models</a> for <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> for those domains that do have <a href=https://en.wikipedia.org/wiki/Big_data>massive datasets</a> (i.e., news). At the same time, they suggest important questions for new research in summarization ; namely, new forms of sentence representations or external knowledge sources are needed that are better suited to the sumarization task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5104.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5104 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5104 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5104/>Predictive Embeddings for Hate Speech Detection on Twitter<span class=acl-fixed-case>T</span>witter</a></strong><br><a href=/people/r/rohan-kshirsagar/>Rohan Kshirsagar</a>
|
<a href=/people/t/tyrus-cukuvac/>Tyrus Cukuvac</a>
|
<a href=/people/k/kathleen-mckeown/>Kathy McKeown</a>
|
<a href=/people/s/susan-mcgregor/>Susan McGregor</a><br><a href=/volumes/W18-51/ class=text-muted>Proceedings of the 2nd Workshop on Abusive Language Online (ALW2)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5104><div class="card-body p-3 small">We present a neural-network based approach to classifying online hate speech in general, as well as racist and sexist speech in particular. Using pre-trained word embeddings and max / mean pooling from simple, fully-connected transformations of these embeddings, we are able to predict the occurrence of hate speech on three commonly used publicly available datasets. Our models match or outperform state of the art F1 performance on all three datasets using significantly fewer parameters and minimal feature preprocessing compared to previous methods.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-1031.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-1031 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-1031 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-1031/>Domain-Adaptable Hybrid Generation of RDF Entity Descriptions<span class=acl-fixed-case>RDF</span> Entity Descriptions</a></strong><br><a href=/people/o/or-biran/>Or Biran</a>
|
<a href=/people/k/kathleen-mckeown/>Kathleen McKeown</a><br><a href=/volumes/I17-1/ class=text-muted>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-1031><div class="card-body p-3 small">RDF ontologies provide <a href=https://en.wikipedia.org/wiki/Structured_data>structured data</a> on entities in many domains and continue to grow in size and diversity. While they can be useful as a starting point for generating descriptions of entities, they often miss important information about an entity that can not be captured as simple relations. In addition, generic approaches to generation from <a href=https://en.wikipedia.org/wiki/Resource_Description_Framework>RDF</a> can not capture the unique style and content of specific domains. We describe a framework for hybrid generation of entity descriptions, which combines generation from <a href=https://en.wikipedia.org/wiki/Resource_Description_Framework>RDF data</a> with text extracted from a corpus, and extracts unique aspects of the domain from the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> to create domain-specific generation systems. We show that each component of our approach significantly increases the satisfaction of readers with the text across multiple applications and domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5102.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5102 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5102 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5102/>Analyzing the Semantic Types of Claims and Premises in an Online Persuasive Forum</a></strong><br><a href=/people/c/christopher-hidey/>Christopher Hidey</a>
|
<a href=/people/e/elena-musi/>Elena Musi</a>
|
<a href=/people/a/alyssa-hwang/>Alyssa Hwang</a>
|
<a href=/people/s/smaranda-muresan/>Smaranda Muresan</a>
|
<a href=/people/k/kathleen-mckeown/>Kathy McKeown</a><br><a href=/volumes/W17-51/ class=text-muted>Proceedings of the 4th Workshop on Argument Mining</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5102><div class="card-body p-3 small">Argumentative text has been analyzed both theoretically and computationally in terms of argumentative structure that consists of argument components (e.g., claims, premises) and their argumentative relations (e.g., support, attack). Less emphasis has been placed on analyzing the semantic types of <a href=https://en.wikipedia.org/wiki/Argument_(linguistics)>argument components</a>. We propose a two-tiered annotation scheme to label claims and premises and their semantic types in an online persuasive forum, Change My View, with the long-term goal of understanding what makes a message persuasive. Premises are annotated with the three types of persuasive modes : <a href=https://en.wikipedia.org/wiki/Ethos>ethos</a>, <a href=https://en.wikipedia.org/wiki/Logos>logos</a>, <a href=https://en.wikipedia.org/wiki/Pathos>pathos</a>, while claims are labeled as interpretation, evaluation, agreement, or disagreement, the latter two designed to account for the dialogical nature of our corpus. We aim to answer three questions : 1) can humans reliably annotate the semantic types of argument components? 2) are types of premises / claims positioned in recurrent orders? and 3) are certain types of claims and/or premises more likely to appear in persuasive messages than in non-persuasive messages?</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-1094.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-1094 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-1094 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-1094/>SMARTies : Sentiment Models for Arabic Target entities<span class=acl-fixed-case>SMART</span>ies: Sentiment Models for <span class=acl-fixed-case>A</span>rabic Target entities</a></strong><br><a href=/people/n/noura-farra/>Noura Farra</a>
|
<a href=/people/k/kathleen-mckeown/>Kathy McKeown</a><br><a href=/volumes/E17-1/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-1094><div class="card-body p-3 small">We consider entity-level sentiment analysis in <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a>, a morphologically rich language with increasing resources. We present a <a href=https://en.wikipedia.org/wiki/System>system</a> that is applied to complex posts written in response to Arabic newspaper articles. Our goal is to identify important entity targets within the post along with the polarity expressed about each target. We achieve significant improvements over multiple baselines, demonstrating that the use of specific morphological representations improves the performance of identifying both important targets and their sentiment, and that the use of distributional semantic clusters further boosts performances for these representations, especially when richer linguistic resources are not available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-2008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-2008 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-2008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-2008/>Crowd-Sourced Iterative Annotation for Narrative Summarization Corpora</a></strong><br><a href=/people/j/jessica-ouyang/>Jessica Ouyang</a>
|
<a href=/people/s/serina-chang/>Serina Chang</a>
|
<a href=/people/k/kathleen-mckeown/>Kathy McKeown</a><br><a href=/volumes/E17-2/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-2008><div class="card-body p-3 small">We present an iterative annotation process for producing aligned, parallel corpora of abstractive and extractive summaries for <a href=https://en.wikipedia.org/wiki/Narrative>narrative</a>. Our approach uses a combination of trained annotators and <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowd-sourcing</a>, allowing us to elicit human-generated summaries and alignments quickly and at low cost. We use <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowd-sourcing</a> to annotate aligned phrases with the text-to-text generation techniques needed to transform each phrase into the other. We apply this process to a corpus of 476 personal narratives, which we make available on the Web.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Kathleen+McKeown" title="Search for 'Kathleen McKeown' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/c/chris-kedzie/ class=align-middle>Chris Kedzie</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/f/feng-nan/ class=align-middle>Feng Nan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/ramesh-nallapati/ class=align-middle>Ramesh Nallapati</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/cicero-dos-santos/ class=align-middle>Cicero dos Santos</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/henghui-zhu/ class=align-middle>Henghui Zhu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/d/dejiao-zhang/ class=align-middle>Dejiao Zhang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/bing-xiang/ class=align-middle>Bing Xiang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/christopher-hidey/ class=align-middle>Christopher Hidey</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/smaranda-muresan/ class=align-middle>Smaranda Muresan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/serina-chang/ class=align-middle>Serina Chang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/f/fei-tzin-lee/ class=align-middle>Fei-Tzin Lee</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/elsbeth-turcan/ class=align-middle>Elsbeth Turcan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jessica-ouyang/ class=align-middle>Jessica Ouyang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/o/or-biran/ class=align-middle>Or Biran</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhiguo-wang/ class=align-middle>Zhiguo Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elena-musi/ class=align-middle>Elena Musi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alyssa-hwang/ class=align-middle>Alyssa Hwang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ruiqi-zhong/ class=align-middle>Ruiqi Zhong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/ethan-adams/ class=align-middle>Ethan Adams</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/siddharth-varia/ class=align-middle>Siddharth Varia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/desmond-patton/ class=align-middle>Desmond Patton</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/william-frey/ class=align-middle>William Frey</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hal-daume-iii/ class=align-middle>Hal Daumé III</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/douglas-w-oard/ class=align-middle>Douglas W. Oard</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elizabeth/ class=align-middle>Elizabeth</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/richard-schwartz/ class=align-middle>Richard Schwartz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rohan-kshirsagar/ class=align-middle>Rohan Kshirsagar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tyrus-cukuvac/ class=align-middle>Tyrus Cukuvac</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/susan-mcgregor/ class=align-middle>Susan McGregor</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/derrick-hull/ class=align-middle>Derrick Hull</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jacob-levine/ class=align-middle>Jacob Levine</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bonnie-ray/ class=align-middle>Bonnie Ray</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/david-wan/ class=align-middle>David Wan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/faisal-ladhak/ class=align-middle>Faisal Ladhak</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marine-carpuat/ class=align-middle>Marine Carpuat</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/noura-farra/ class=align-middle>Noura Farra</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/clssts/ class=align-middle>CLSSTS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wmt/ class=align-middle>WMT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>