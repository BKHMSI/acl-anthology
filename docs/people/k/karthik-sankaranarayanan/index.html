<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Karthik Sankaranarayanan - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Karthik</span> <span class=font-weight-bold>Sankaranarayanan</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.342.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--342 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.342 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.342" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.342/>Topic Transferable Table Question Answering</a></strong><br><a href=/people/s/saneem-chemmengath/>Saneem Chemmengath</a>
|
<a href=/people/v/vishwajeet-kumar/>Vishwajeet Kumar</a>
|
<a href=/people/s/samarth-bharadwaj/>Samarth Bharadwaj</a>
|
<a href=/people/j/jaydeep-sen/>Jaydeep Sen</a>
|
<a href=/people/m/mustafa-canim/>Mustafa Canim</a>
|
<a href=/people/s/soumen-chakrabarti/>Soumen Chakrabarti</a>
|
<a href=/people/a/alfio-gliozzo/>Alfio Gliozzo</a>
|
<a href=/people/k/karthik-sankaranarayanan/>Karthik Sankaranarayanan</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--342><div class="card-body p-3 small">Weakly-supervised table question-answering (TableQA) models have achieved state-of-art performance by using pre-trained BERT transformer to jointly encoding a question and a table to produce structured query for the question. However, in practical settings TableQA systems are deployed over table corpora having topic and word distributions quite distinct from BERT&#8217;s pretraining corpus. In this work we simulate the practical topic shift scenario by designing novel challenge benchmarks WikiSQL-TS and WikiTable-TS, consisting of train-dev-test splits in five distinct topic groups, based on the popular WikiSQL and WikiTable-Questions datasets. We empirically show that, despite pre-training on large open-domain text, performance of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> degrades significantly when they are evaluated on unseen topics. In response, we propose T3QA (Topic Transferable Table Question Answering) a pragmatic adaptation framework for TableQA comprising of : (1) topic-specific vocabulary injection into BERT, (2) a novel text-to-text transformer generator (such as T5, GPT2) based natural language question generation pipeline focused on generating topic-specific training data, and (3) a logical form re-ranker. We show that T3QA provides a reasonably good baseline for our topic shift benchmarks. We believe our topic split benchmarks will lead to robust TableQA solutions that are better suited for practical deployment</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.115.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--115 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.115 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.115/>Schema Aware Semantic Reasoning for Interpreting Natural Language Queries in Enterprise Settings</a></strong><br><a href=/people/j/jaydeep-sen/>Jaydeep Sen</a>
|
<a href=/people/t/tanaya-babtiwale/>Tanaya Babtiwale</a>
|
<a href=/people/k/kanishk-saxena/>Kanishk Saxena</a>
|
<a href=/people/y/yash-butala/>Yash Butala</a>
|
<a href=/people/s/sumit-bhatia/>Sumit Bhatia</a>
|
<a href=/people/k/karthik-sankaranarayanan/>Karthik Sankaranarayanan</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--115><div class="card-body p-3 small">Natural Language Query interfaces allow the end-users to access the desired information without the need to know any specialized query language, <a href=https://en.wikipedia.org/wiki/Computer_data_storage>data storage</a>, or schema details. Even with the recent advances in NLP research space, the state-of-the-art QA systems fall short of understanding implicit intents of real-world Business Intelligence (BI) queries in enterprise systems, since <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>Natural Language Understanding</a> still remains an AI-hard problem. We posit that deploying ontology reasoning over domain semantics can help in achieving better <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a> for <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA systems</a>. In this paper, we specifically focus on building a Schema Aware Semantic Reasoning Framework that translates natural language interpretation as a sequence of solvable tasks by an ontology reasoner. We apply our framework on top of an ontology based, state-of-the-art natural language question-answering system ATHENA, and experiment with 4 benchmarks focused on BI queries. Our experimental numbers empirically show that the Schema Aware Semantic Reasoning indeed helps in achieving significantly better results for handling BI queries with an average accuracy improvement of ~30 %</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1636.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1636 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1636 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1636/>A Modular Architecture for Unsupervised Sarcasm Generation</a></strong><br><a href=/people/a/abhijit-mishra/>Abhijit Mishra</a>
|
<a href=/people/t/tarun-tater/>Tarun Tater</a>
|
<a href=/people/k/karthik-sankaranarayanan/>Karthik Sankaranarayanan</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1636><div class="card-body p-3 small">In this paper, we propose a novel framework for sarcasm generation ; the system takes a literal negative opinion as input and translates it into a sarcastic version. Our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> does not require any <a href=https://en.wikipedia.org/wiki/Paired_data>paired data</a> for training. Sarcasm emanates from context-incongruity which becomes apparent as the sentence unfolds. Our framework introduces incongruity into the literal input version through modules that : (a) filter factual content from the input opinion, (b) retrieve incongruous phrases related to the filtered facts and (c) synthesize sarcastic text from the incongruous filtered and incongruous phrases. The framework employs reinforced neural sequence to sequence learning and information retrieval and is trained only using unlabeled non-sarcastic and sarcastic opinions. Since no labeled dataset exists for such a task, for evaluation, we manually prepare a benchmark dataset containing <a href=https://en.wikipedia.org/wiki/Literal_and_figurative_language>literal opinions</a> and their <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcastic paraphrases</a>. Qualitative and quantitative performance analyses on the data reveal our system&#8217;s superiority over baselines built using known unsupervised statistical and neural machine translation and style transfer techniques.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q19-1012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q19-1012 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q19-1012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q19-1012/>Complex Program Induction for Querying Knowledge Bases in the Absence of Gold Programs</a></strong><br><a href=/people/a/amrita-saha/>Amrita Saha</a>
|
<a href=/people/g/ghulam-ahmed-ansari/>Ghulam Ahmed Ansari</a>
|
<a href=/people/a/abhishek-laddha/>Abhishek Laddha</a>
|
<a href=/people/k/karthik-sankaranarayanan/>Karthik Sankaranarayanan</a>
|
<a href=/people/s/soumen-chakrabarti/>Soumen Chakrabarti</a><br><a href=/volumes/Q19-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 7</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q19-1012><div class="card-body p-3 small">Recent years have seen increasingly complex question-answering on knowledge bases (KBQA) involving logical, quantitative, and comparative reasoning over KB subgraphs. Neural Program Induction (NPI) is a pragmatic approach toward modularizing the <a href=https://en.wikipedia.org/wiki/Automated_reasoning>reasoning process</a> by translating a complex <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language query</a> into a multi-step executable program. While NPI has been commonly trained with the &#8216;&#8216;gold&#8217;&#8217; program or its sketch, for realistic KBQA applications such gold programs are expensive to obtain. There, practically only <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language queries</a> and the corresponding answers can be provided for training. The resulting combinatorial explosion in program space, along with extremely sparse rewards, makes <a href=https://en.wikipedia.org/wiki/Non-blocking_algorithm>NPI</a> for KBQA ambitious and challenging. We present Complex Imperative Program Induction from Terminal Rewards (CIPITR), an advanced neural programmer that mitigates reward sparsity with auxiliary rewards, and restricts the program space to semantically correct programs using high-level constraints, KB schema, and inferred answer type. CIPITR solves complex KBQA considerably more accurately than key-value memory networks and neural symbolic machines (NSM). For moderately complex queries requiring 2- to 5-step programs, CIPITR scores at least 3 higher F1 than the competing systems. On one of the hardest class of programs (comparative reasoning) with 510 steps, CIPITR outperforms NSM by a factor of 89 and memory networks by 9 times.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1139.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1139 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1139 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1139" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1139/>Generating Descriptions from Structured Data Using a Bifocal Attention Mechanism and Gated Orthogonalization</a></strong><br><a href=/people/p/preksha-nema/>Preksha Nema</a>
|
<a href=/people/s/shreyas-shetty/>Shreyas Shetty</a>
|
<a href=/people/p/parag-jain/>Parag Jain</a>
|
<a href=/people/a/anirban-laha/>Anirban Laha</a>
|
<a href=/people/k/karthik-sankaranarayanan/>Karthik Sankaranarayanan</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1139><div class="card-body p-3 small">In this work, we focus on the task of generating natural language descriptions from a structured table of facts containing fields (such as nationality, occupation, etc) and values (such as <a href=https://en.wikipedia.org/wiki/Indian_people>Indian</a>, <a href=https://en.wikipedia.org/wiki/Actor>actor</a>, director, etc). One simple choice is to treat the table as a sequence of fields and values and then use a standard seq2seq model for this task. However, such a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is too generic and does not exploit task specific characteristics. For example, while generating descriptions from a table, a human would attend to information at two levels : (i) the fields (macro level) and (ii) the values within the field (micro level). Further, a human would continue attending to a field for a few timesteps till all the information from that field has been rendered and then never return back to this field (because there is nothing left to say about it). To capture this behavior we use (i) a fused bifocal attention mechanism which exploits and combines this micro and macro level information and (ii) a gated orthogonalization mechanism which tries to ensure that a field is remembered for a few time steps and then forgotten. We experiment with a recently released dataset which contains fact tables about people and their corresponding one line biographical descriptions in English. In addition, we also introduce two similar <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> for <a href=https://en.wikipedia.org/wiki/French_language>French</a> and <a href=https://en.wikipedia.org/wiki/German_language>German</a>. Our experiments show that the proposed model gives 21 % relative improvement over a recently proposed state of the art method and 10 % relative improvement over basic seq2seq models.<url>https://github.com/PrekshaNema25/StructuredData_To_Descriptions</url>\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2098.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-2098 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-2098 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-2098/>A Mixed Hierarchical Attention Based Encoder-Decoder Approach for Standard Table Summarization</a></strong><br><a href=/people/p/parag-jain/>Parag Jain</a>
|
<a href=/people/a/anirban-laha/>Anirban Laha</a>
|
<a href=/people/k/karthik-sankaranarayanan/>Karthik Sankaranarayanan</a>
|
<a href=/people/p/preksha-nema/>Preksha Nema</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a>
|
<a href=/people/s/shreyas-shetty/>Shreyas Shetty</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-2098><div class="card-body p-3 small">Structured data summarization involves <a href=https://en.wikipedia.org/wiki/Natural-language_generation>generation of natural language summaries</a> from <a href=https://en.wikipedia.org/wiki/Structured_data>structured input data</a>. In this work, we consider summarizing structured data occurring in the form of tables as they are prevalent across a wide variety of domains. We formulate the standard table summarization problem, which deals with tables conforming to a single predefined schema. To this end, we propose a mixed hierarchical attention based encoder-decoder model which is able to leverage the structure in addition to the content of the tables. Our experiments on the publicly available weathergov dataset show around 18 BLEU (around 30 %) improvement over the current <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1156.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1156 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1156 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1156.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1156" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1156/>DuoRC : Towards Complex Language Understanding with Paraphrased Reading Comprehension<span class=acl-fixed-case>D</span>uo<span class=acl-fixed-case>RC</span>: Towards Complex Language Understanding with Paraphrased Reading Comprehension</a></strong><br><a href=/people/a/amrita-saha/>Amrita Saha</a>
|
<a href=/people/r/rahul-aralikatte/>Rahul Aralikatte</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a>
|
<a href=/people/k/karthik-sankaranarayanan/>Karthik Sankaranarayanan</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1156><div class="card-body p-3 small">We propose DuoRC, a novel dataset for Reading Comprehension (RC) that motivates several new challenges for neural approaches in <a href=https://en.wikipedia.org/wiki/Language_understanding>language understanding</a> beyond those offered by existing RC datasets. DuoRC contains 186,089 unique question-answer pairs created from a collection of 7680 pairs of movie plots where each pair in the <a href=https://en.wikipedia.org/wiki/Collection_(abstract_data_type)>collection</a> reflects two versions of the same movie-one from Wikipedia and the other from IMDb-written by two different authors. We asked crowdsourced workers to create questions from one version of the plot and a different set of workers to extract or synthesize answers from the other version. This unique characteristic of DuoRC where questions and answers are created from different versions of a document narrating the same underlying story, ensures by design, that there is very little lexical overlap between the questions created from one version and the segments containing the answer in the other version. Further, since the two versions have different levels of plot detail, narration style, <a href=https://en.wikipedia.org/wiki/Vocabulary>vocabulary</a>, etc., answering questions from the second version requires deeper <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>language understanding</a> and incorporating external background knowledge. Additionally, the narrative style of passages arising from movie plots (as opposed to typical descriptive passages in existing datasets) exhibits the need to perform complex reasoning over events across multiple sentences. Indeed, we observe that state-of-the-art neural RC models which have achieved near human performance on the SQuAD dataset, even when coupled with traditional NLP techniques to address the challenges presented in DuoRC exhibit very poor performance (F1 score of 37.42 % on DuoRC v / s 86 % on SQuAD dataset).</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Karthik+Sankaranarayanan" title="Search for 'Karthik Sankaranarayanan' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/m/mitesh-m-khapra/ class=align-middle>Mitesh M. Khapra</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/jaydeep-sen/ class=align-middle>Jaydeep Sen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/soumen-chakrabarti/ class=align-middle>Soumen Chakrabarti</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/amrita-saha/ class=align-middle>Amrita Saha</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/preksha-nema/ class=align-middle>Preksha Nema</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/s/shreyas-shetty/ class=align-middle>Shreyas Shetty</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/parag-jain/ class=align-middle>Parag Jain</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/anirban-laha/ class=align-middle>Anirban Laha</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/saneem-chemmengath/ class=align-middle>Saneem Chemmengath</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vishwajeet-kumar/ class=align-middle>Vishwajeet Kumar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/samarth-bharadwaj/ class=align-middle>Samarth Bharadwaj</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mustafa-canim/ class=align-middle>Mustafa Canim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alfio-gliozzo/ class=align-middle>Alfio Gliozzo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/abhijit-mishra/ class=align-middle>Abhijit Mishra</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tarun-tater/ class=align-middle>Tarun Tater</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/ghulam-ahmed-ansari/ class=align-middle>Ghulam Ahmed Ansari</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/abhishek-laddha/ class=align-middle>Abhishek Laddha</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tanaya-babtiwale/ class=align-middle>Tanaya Babtiwale</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kanishk-saxena/ class=align-middle>Kanishk Saxena</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yash-butala/ class=align-middle>Yash Butala</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sumit-bhatia/ class=align-middle>Sumit Bhatia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rahul-aralikatte/ class=align-middle>Rahul Aralikatte</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/tacl/ class=align-middle>TACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>