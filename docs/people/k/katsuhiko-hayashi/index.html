<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Katsuhiko Hayashi - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Katsuhiko</span> <span class=font-weight-bold>Hayashi</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.argmining-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--argmining-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.argmining-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.argmining-1.11/>Bayesian Argumentation-Scheme Networks : A Probabilistic Model of Argument Validity Facilitated by Argumentation Schemes<span class=acl-fixed-case>B</span>ayesian Argumentation-Scheme Networks: <span class=acl-fixed-case>A</span> Probabilistic Model of Argument Validity Facilitated by Argumentation Schemes</a></strong><br><a href=/people/t/takahiro-kondo/>Takahiro Kondo</a>
|
<a href=/people/k/koki-washio/>Koki Washio</a>
|
<a href=/people/k/katsuhiko-hayashi/>Katsuhiko Hayashi</a>
|
<a href=/people/y/yusuke-miyao/>Yusuke Miyao</a><br><a href=/volumes/2021.argmining-1/ class=text-muted>Proceedings of the 8th Workshop on Argument Mining</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--argmining-1--11><div class="card-body p-3 small">We propose a <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> for representing the reasoning structure of arguments using <a href=https://en.wikipedia.org/wiki/Bayesian_network>Bayesian networks</a> and <a href=https://en.wikipedia.org/wiki/First-order_logic>predicate logic</a> facilitated by <a href=https://en.wikipedia.org/wiki/Argumentation_theory>argumentation schemes</a>. We express the meaning of text segments using <a href=https://en.wikipedia.org/wiki/First-order_logic>predicate logic</a> and map the boolean values of <a href=https://en.wikipedia.org/wiki/First-order_logic>predicate logic expressions</a> to nodes in a <a href=https://en.wikipedia.org/wiki/Bayesian_network>Bayesian network</a>. The reasoning structure among text segments is described with a <a href=https://en.wikipedia.org/wiki/Directed_acyclic_graph>directed acyclic graph</a>. While our <a href=https://en.wikipedia.org/wiki/Formalism_(philosophy_of_mathematics)>formalism</a> is highly expressive and capable of describing the informal logic of human arguments, it is too open-ended to actually build a network for an argument. It is not at all obvious which segment of argumentative text should be considered as a node in a <a href=https://en.wikipedia.org/wiki/Bayesian_network>Bayesian network</a>, and how to decide the dependencies among nodes. To alleviate the difficulty, we provide abstract network fragments, called <a href=https://en.wikipedia.org/wiki/Idiom_(language_structure)>idioms</a>, which represent typical argument justification patterns derived from <a href=https://en.wikipedia.org/wiki/Argumentation_theory>argumentation schemes</a>. The network construction process is decomposed into idiom selection, idiom instantiation, and idiom combination. We define 17 <a href=https://en.wikipedia.org/wiki/Idiom_(language_structure)>idioms</a> in total by referring to <a href=https://en.wikipedia.org/wiki/Argumentation_theory>argumentation schemes</a> as well as analyzing actual arguments and fitting <a href=https://en.wikipedia.org/wiki/Idiom_(language_structure)>idioms</a> to them. We also create a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> consisting of pairs of an argumentative text and a corresponding <a href=https://en.wikipedia.org/wiki/Bayesian_network>Bayesian network</a>. Our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> contains about 2,400 pairs, which is large in the research area of <a href=https://en.wikipedia.org/wiki/Argumentation_theory>argumentation schemes</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1246.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1246 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1246 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1246/>A Non-commutative Bilinear Model for Answering Path Queries in Knowledge Graphs</a></strong><br><a href=/people/k/katsuhiko-hayashi/>Katsuhiko Hayashi</a>
|
<a href=/people/m/masashi-shimbo/>Masashi Shimbo</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1246><div class="card-body p-3 small">Bilinear diagonal models for knowledge graph embedding (KGE), such as DistMult and ComplEx, balance expressiveness and computational efficiency by representing relations as diagonal matrices. Although they perform well in predicting atomic relations, composite relations (relation paths) can not be modeled naturally by the product of relation matrices, as the product of diagonal matrices is commutative and hence invariant with the order of relations. In this paper, we propose a new bilinear KGE model, called BlockHolE, based on block circulant matrices. In BlockHolE, <a href=https://en.wikipedia.org/wiki/Matrix_(mathematics)>relation matrices</a> can be non-commutative, allowing composite relations to be modeled by <a href=https://en.wikipedia.org/wiki/Matrix_multiplication>matrix product</a>. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is parameterized in a way that covers a spectrum ranging from diagonal to full relation matrices. A fast computation technique can be developed on the basis of the duality of the Fourier transform of circulant matrices.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1047.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1047 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1047 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1047/>Neural Tensor Networks with Diagonal Slice Matrices</a></strong><br><a href=/people/t/takahiro-ishihara/>Takahiro Ishihara</a>
|
<a href=/people/k/katsuhiko-hayashi/>Katsuhiko Hayashi</a>
|
<a href=/people/h/hitoshi-manabe/>Hitoshi Manabe</a>
|
<a href=/people/m/masashi-shimbo/>Masashi Shimbo</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1047><div class="card-body p-3 small">Although neural tensor networks (NTNs) have been successful in many NLP tasks, they require a large number of parameters to be estimated, which often leads to <a href=https://en.wikipedia.org/wiki/Overfitting>overfitting</a> and a long training time. We address these issues by applying <a href=https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix>eigendecomposition</a> to each slice matrix of a <a href=https://en.wikipedia.org/wiki/Tensor>tensor</a> to reduce its number of paramters. First, we evaluate our proposed NTN models on knowledge graph completion. Second, we extend the models to recursive NTNs (RNTNs) and evaluate them on logical reasoning tasks. These experiments show that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> learn better and faster than the original (R)NTNs.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2002 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2002/>Supervised Attention for Sequence-to-Sequence Constituency Parsing</a></strong><br><a href=/people/h/hidetaka-kamigaito/>Hidetaka Kamigaito</a>
|
<a href=/people/k/katsuhiko-hayashi/>Katsuhiko Hayashi</a>
|
<a href=/people/t/tsutomu-hirao/>Tsutomu Hirao</a>
|
<a href=/people/h/hiroya-takamura/>Hiroya Takamura</a>
|
<a href=/people/m/manabu-okumura/>Manabu Okumura</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/I17-2/ class=text-muted>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2002><div class="card-body p-3 small">The sequence-to-sequence (Seq2Seq) model has been successfully applied to <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation (MT)</a>. Recently, MT performances were improved by incorporating supervised attention into the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. In this paper, we introduce supervised attention to constituency parsing that can be regarded as another translation task. Evaluation results on the PTB corpus showed that the bracketing F-measure was improved by supervised attention.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2088.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2088 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2088 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-2088.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-2088/>On the Equivalence of Holographic and Complex Embeddings for Link Prediction</a></strong><br><a href=/people/k/katsuhiko-hayashi/>Katsuhiko Hayashi</a>
|
<a href=/people/m/masashi-shimbo/>Masashi Shimbo</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2088><div class="card-body p-3 small">We show the equivalence of two state-of-the-art models for link prediction / knowledge graph completion : Nickel et al&#8217;s holographic embeddings and Trouillon et al.&#8217;s complex embeddings. We first consider a spectral version of the holographic embeddings, exploiting the <a href=https://en.wikipedia.org/wiki/Frequency_domain>frequency domain</a> in the <a href=https://en.wikipedia.org/wiki/Fourier_transform>Fourier transform</a> for efficient computation. The analysis of the resulting <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> reveals that it can be viewed as an instance of the complex embeddings with a certain constraint imposed on the initial vectors upon training. Conversely, any set of complex embeddings can be converted to a set of equivalent holographic embeddings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6308.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6308 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6308 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6308/>Hierarchical Word Structure-based Parsing : A Feasibility Study on UD-style Dependency Parsing in <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a><span class=acl-fixed-case>UD</span>-style Dependency Parsing in <span class=acl-fixed-case>J</span>apanese</a></strong><br><a href=/people/t/takaaki-tanaka/>Takaaki Tanaka</a>
|
<a href=/people/k/katsuhiko-hayashi/>Katsuhiko Hayashi</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/W17-63/ class=text-muted>Proceedings of the 15th International Conference on Parsing Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6308><div class="card-body p-3 small">In applying word-based dependency parsing such as Universal Dependencies (UD) to <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>, the uncertainty of <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a> emerges for defining a word unit of the dependencies. We introduce the following hierarchical word structures to dependency parsing in <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> : morphological units (a short unit word, SUW) and syntactic units (a long unit word, LUW). An SUW can be used to segment a sentence consistently, while it is too short to represent syntactic construction. An LUW is a unit including functional multiwords and LUW-based analysis facilitates the capturing of syntactic structure and makes <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a> results more precise than SUW-based analysis. This paper describes the results of a feasibility study on the ability and the effectiveness of parsing methods based on hierarchical word structure (LUW chunking+parsing) in comparison to single layer word structure (SUW parsing). We also show joint analysis of LUW-chunking and dependency parsing improves the performance of identifying predicate-argument structures, while there is not much difference between overall results of them. not much difference between overall results of them.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-2049.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-2049 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-2049 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-2049/>K-best Iterative Viterbi Parsing<span class=acl-fixed-case>V</span>iterbi Parsing</a></strong><br><a href=/people/k/katsuhiko-hayashi/>Katsuhiko Hayashi</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/E17-2/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-2049><div class="card-body p-3 small">This paper presents an efficient and optimal parsing algorithm for probabilistic context-free grammars (PCFGs). To achieve faster <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a>, our proposal employs a pruning technique to reduce unnecessary edges in the <a href=https://en.wikipedia.org/wiki/Feasible_region>search space</a>. The key is to conduct repetitively Viterbi inside and outside parsing, while gradually expanding the <a href=https://en.wikipedia.org/wiki/Feasible_region>search space</a> to efficiently compute <a href=https://en.wikipedia.org/wiki/Heuristic_(computer_science)>heuristic bounds</a> used for <a href=https://en.wikipedia.org/wiki/Parsing>pruning</a>. Our experimental results using the English Penn Treebank corpus show that the proposed <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> is faster than the standard CKY parsing algorithm. In addition, we also show how to extend this <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> to extract k-best Viterbi parse trees.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Katsuhiko+Hayashi" title="Search for 'Katsuhiko Hayashi' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/m/masaaki-nagata/ class=align-middle>Masaaki Nagata</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/m/masashi-shimbo/ class=align-middle>Masashi Shimbo</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/h/hidetaka-kamigaito/ class=align-middle>Hidetaka Kamigaito</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tsutomu-hirao/ class=align-middle>Tsutomu Hirao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hiroya-takamura/ class=align-middle>Hiroya Takamura</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/m/manabu-okumura/ class=align-middle>Manabu Okumura</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/takaaki-tanaka/ class=align-middle>Takaaki Tanaka</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/takahiro-kondo/ class=align-middle>Takahiro Kondo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/koki-washio/ class=align-middle>Koki Washio</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yusuke-miyao/ class=align-middle>Yusuke Miyao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/takahiro-ishihara/ class=align-middle>Takahiro Ishihara</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hitoshi-manabe/ class=align-middle>Hitoshi Manabe</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/argmining/ class=align-middle>ArgMining</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>