<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Jan Šnajder - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Jan</span> <span class=font-weight-bold>Šnajder</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Jan <span class=font-weight-normal>Snajder</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.socialnlp-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--socialnlp-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.socialnlp-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.socialnlp-1.12/>PANDORA Talks : Personality and Demographics on Reddit<span class=acl-fixed-case>PANDORA</span> Talks: Personality and Demographics on <span class=acl-fixed-case>R</span>eddit</a></strong><br><a href=/people/m/matej-gjurkovic/>Matej Gjurković</a>
|
<a href=/people/m/mladen-karan/>Mladen Karan</a>
|
<a href=/people/i/iva-vukojevic/>Iva Vukojević</a>
|
<a href=/people/m/mihaela-bosnjak/>Mihaela Bošnjak</a>
|
<a href=/people/j/jan-snajder/>Jan Snajder</a><br><a href=/volumes/2021.socialnlp-1/ class=text-muted>Proceedings of the Ninth International Workshop on Natural Language Processing for Social Media</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--socialnlp-1--12><div class="card-body p-3 small">Personality and demographics are important variables in <a href=https://en.wikipedia.org/wiki/Social_science>social sciences</a> and computational sociolinguistics. However, <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> with both <a href=https://en.wikipedia.org/wiki/Personality_type>personality and demographic labels</a> are scarce. To address this, we present <a href=https://en.wikipedia.org/wiki/PANDORA>PANDORA</a>, the first dataset of Reddit comments of 10k users partially labeled with three personality models and <a href=https://en.wikipedia.org/wiki/Demography>demographics</a> (age, gender, and location), including 1.6k users labeled with the well-established Big 5 personality model. We showcase the usefulness of this dataset on three experiments, where we leverage the more readily available data from other personality models to predict the Big 5 traits, analyze gender classification biases arising from psycho-demographic variables, and carry out a confirmatory and exploratory analysis based on psychological theories. Finally, we present benchmark prediction models for all <a href=https://en.wikipedia.org/wiki/Personality_type>personality and demographic variables</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3514.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3514 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3514 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3514/>Preemptive Toxic Language Detection in Wikipedia Comments Using Thread-Level Context<span class=acl-fixed-case>W</span>ikipedia Comments Using Thread-Level Context</a></strong><br><a href=/people/m/mladen-karan/>Mladen Karan</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a><br><a href=/volumes/W19-35/ class=text-muted>Proceedings of the Third Workshop on Abusive Language Online</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3514><div class="card-body p-3 small">We address the task of automatically detecting toxic content in <a href=https://en.wikipedia.org/wiki/User-generated_content>user generated texts</a>. We fo cus on exploring the potential for preemptive moderation, i.e., predicting whether a particular conversation thread will, in the future, incite a toxic comment. Moreover, we perform preliminary investigation of whether a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that jointly considers all comments in a <a href=https://en.wikipedia.org/wiki/Conversation_threading>conversation thread</a> outperforms a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that considers only individual comments. Using an existing <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of conversations among <a href=https://en.wikipedia.org/wiki/Wikipedia_community>Wikipedia contributors</a> as a starting point, we compile a new large-scale dataset for this task consisting of labeled comments and comments from their conversation threads.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3700.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3700/>Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing</a></strong><br><a href=/people/t/tomaz-erjavec/>Tomaž Erjavec</a>
|
<a href=/people/m/michal-marcinczuk/>Michał Marcińczuk</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/j/jakub-piskorski/>Jakub Piskorski</a>
|
<a href=/people/l/lidia-pivovarova/>Lidia Pivovarova</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a>
|
<a href=/people/j/josef-steinberger/>Josef Steinberger</a>
|
<a href=/people/r/roman-yangarber/>Roman Yangarber</a><br><a href=/volumes/W19-37/ class=text-muted>Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4405.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4405 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4405 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4405/>Analysing Rhetorical Structure as a Key Feature of Summary Coherence</a></strong><br><a href=/people/j/jan-snajder/>Jan Šnajder</a>
|
<a href=/people/t/tamara-sladoljev-agejev/>Tamara Sladoljev-Agejev</a>
|
<a href=/people/s/svjetlana-kolic-vehovec/>Svjetlana Kolić Vehovec</a><br><a href=/volumes/W19-44/ class=text-muted>Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4405><div class="card-body p-3 small">We present a model for automatic scoring of coherence based on comparing the rhetorical structure (RS) of college student summaries in L2 (English) against expert summaries. Coherence is conceptualised as a construct consisting of the rhetorical relation and its arguments. Comparison with expert-assigned scores shows that RS scores correlate with both <a href=https://en.wikipedia.org/wiki/Group_cohesiveness>cohesion</a> and <a href=https://en.wikipedia.org/wiki/Group_cohesiveness>coherence</a>. Furthermore, RS scores improve the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of a <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression model</a> for cohesion score prediction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5118.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5118 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5118 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5118/>Evaluating Automatic Term Extraction Methods on Individual Documents</a></strong><br><a href=/people/a/antonio-sajatovic/>Antonio Šajatović</a>
|
<a href=/people/m/maja-buljan/>Maja Buljan</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a>
|
<a href=/people/b/bojana-dalbelo-basic/>Bojana Dalbelo Bašić</a><br><a href=/volumes/W19-51/ class=text-muted>Proceedings of the Joint Workshop on Multiword Expressions and WordNet (MWE-WN 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5118><div class="card-body p-3 small">Automatic Term Extraction (ATE) extracts terminology from <a href=https://en.wikipedia.org/wiki/Domain-specific_language>domain-specific corpora</a>. ATE is used in many NLP tasks, including <a href=https://en.wikipedia.org/wiki/Computer-aided_translation>Computer Assisted Translation</a>, where it is typically applied to individual documents rather than the entire corpus. While corpus-level ATE has been extensively evaluated, it is not obvious how the results transfer to document-level ATE. To fill this gap, we evaluate 16 state-of-the-art ATE methods on full-length documents from three different domains, on both corpus and document levels. Unlike existing studies, our evaluation is more realistic as we take into account all gold terms. We show that no single method is best in corpus-level ATE, but C-Value and KeyConceptRelatendess surpass others in document-level ATE.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-1112.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-1112 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-1112 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-1112/>Reddit : A Gold Mine for Personality Prediction<span class=acl-fixed-case>R</span>eddit: A Gold Mine for Personality Prediction</a></strong><br><a href=/people/m/matej-gjurkovic/>Matej Gjurković</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a><br><a href=/volumes/W18-11/ class=text-muted>Proceedings of the Second Workshop on Computational Modeling of People’s Opinions, Personality, and Emotions in Social Media</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-1112><div class="card-body p-3 small">Automated personality prediction from <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> is gaining increasing attention in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> and social sciences communities. However, due to high labeling costs and privacy issues, the few publicly available datasets are of limited size and low <a href=https://en.wikipedia.org/wiki/Diversity_(business)>topic diversity</a>. We address this problem by introducing a large-scale dataset derived from <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a>, a source so far overlooked for personality prediction. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is labeled with <a href=https://en.wikipedia.org/wiki/Myers&#8211;Briggs_Type_Indicator>Myers-Briggs Type Indicators (MBTI)</a> and comes with a rich set of <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> for more than 9k users. We carry out a preliminary feature analysis, revealing marked differences between the MBTI dimensions and <a href=https://en.wikipedia.org/wiki/Zeros_and_poles>poles</a>. Furthermore, we use the dataset to train and evaluate benchmark personality prediction models, achieving macro F1-scores between 67 % and 82 % on the individual dimensions and 82 % accuracy for exact or one-off accurate type prediction. These results are encouraging and comparable with the reliability of standardized tests.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-4422.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-4422 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-4422 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-4422/>Combining Shallow and Deep Learning for Aggressive Text Detection</a></strong><br><a href=/people/v/viktor-golem/>Viktor Golem</a>
|
<a href=/people/m/mladen-karan/>Mladen Karan</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a><br><a href=/volumes/W18-44/ class=text-muted>Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-4422><div class="card-body p-3 small">We describe the participation of team TakeLab in the aggression detection shared task at the TRAC1 workshop for <a href=https://en.wikipedia.org/wiki/English_language>English</a>. Aggression manifests in a variety of ways. Unlike some forms of <a href=https://en.wikipedia.org/wiki/Aggression>aggression</a> that are impossible to prevent in day-to-day life, aggressive speech abounding on <a href=https://en.wikipedia.org/wiki/List_of_social_networking_websites>social networks</a> could in principle be prevented or at least reduced by simply disabling users that post aggressively worded messages. The first step in achieving this is to detect such <a href=https://en.wikipedia.org/wiki/Message>messages</a>. The task, however, is far from being trivial, as what is considered as aggressive speech can be quite subjective, and the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is further complicated by the noisy nature of <a href=https://en.wikipedia.org/wiki/User-generated_content>user-generated text</a> on <a href=https://en.wikipedia.org/wiki/List_of_social_networking_websites>social networks</a>. Our system learns to distinguish between <a href=https://en.wikipedia.org/wiki/Aggression>open aggression</a>, <a href=https://en.wikipedia.org/wiki/Non-aggression_principle>covert aggression</a>, and <a href=https://en.wikipedia.org/wiki/Non-aggression_principle>non-aggression</a> in social media texts. We tried different machine learning approaches, including traditional (shallow) machine learning models, <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning models</a>, and a combination of both. We achieved respectable results, ranking 4th and 8th out of 31 submissions on the Facebook and Twitter test sets, respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5117.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5117 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5117 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5117/>Cross-Domain Detection of Abusive Language Online</a></strong><br><a href=/people/m/mladen-karan/>Mladen Karan</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a><br><a href=/volumes/W18-51/ class=text-muted>Proceedings of the 2nd Workshop on Abusive Language Online (ALW2)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5117><div class="card-body p-3 small">We investigate to what extent the <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained to detect general abusive language generalize between different datasets labeled with different abusive language types. To this end, we compare the cross-domain performance of simple classification models on nine different <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, finding that the <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> fail to generalize to out-domain datasets and that having at least some in-domain data is important. We also show that using the frustratingly simple domain adaptation (Daume III, 2007) in most cases improves the results over in-domain training, especially when used to augment a smaller dataset with a larger one.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5427.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5427 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5427 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5427/>Iterative Recursive Attention Model for Interpretable Sequence Classification</a></strong><br><a href=/people/m/martin-tutek/>Martin Tutek</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a><br><a href=/volumes/W18-54/ class=text-muted>Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5427><div class="card-body p-3 small">Natural language processing has greatly benefited from the introduction of the attention mechanism. However, standard attention models are of limited interpretability for tasks that involve a series of <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference steps</a>. We describe an iterative recursive attention model, which constructs incremental representations of input data through reusing results of previously computed queries. We train our <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> on sentiment classification datasets and demonstrate its capacity to identify and combine different aspects of the input in an easily interpretable manner, while obtaining performance close to the state of the art.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6211.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6211 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6211 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6211/>Not Just Depressed : Bipolar Disorder Prediction on Reddit<span class=acl-fixed-case>R</span>eddit</a></strong><br><a href=/people/i/ivan-sekulic/>Ivan Sekulic</a>
|
<a href=/people/m/matej-gjurkovic/>Matej Gjurković</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a><br><a href=/volumes/W18-62/ class=text-muted>Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6211><div class="card-body p-3 small">Bipolar disorder, an illness characterized by <a href=https://en.wikipedia.org/wiki/Bipolar_disorder>manic and depressive episodes</a>, affects more than 60 million people worldwide. We present a preliminary study on bipolar disorder prediction from <a href=https://en.wikipedia.org/wiki/User-generated_content>user-generated text</a> on <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a>, which relies on users&#8217; self-reported labels. Our benchmark classifiers for bipolar disorder prediction outperform the baselines and reach <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and F1-scores of above 86 %. Feature analysis shows interesting differences in language use between users with <a href=https://en.wikipedia.org/wiki/Bipolar_disorder>bipolar disorders</a> and the <a href=https://en.wikipedia.org/wiki/Treatment_and_control_groups>control group</a>, including differences in the use of emotion-expressive words.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2031.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2031 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2031 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2031/>Using Analytic Scoring Rubrics in the Automatic Assessment of College-Level Summary Writing Tasks in L2<span class=acl-fixed-case>L</span>2</a></strong><br><a href=/people/t/tamara-sladoljev-agejev/>Tamara Sladoljev-Agejev</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a><br><a href=/volumes/I17-2/ class=text-muted>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2031><div class="card-body p-3 small">Assessing summaries is a demanding, yet useful task which provides valuable information on <a href=https://en.wikipedia.org/wiki/Linguistic_competence>language competence</a>, especially for <a href=https://en.wikipedia.org/wiki/Second-language_acquisition>second language learners</a>. We consider automated scoring of college-level summary writing task in English as a second language (EL2). We adopt the Reading-for-Understanding (RU) cognitive framework, extended with the Reading-to-Write (RW) element, and use analytic scoring with six rubrics covering content and writing quality. We show that <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression models</a> with reference-based and linguistic features considerably outperform the baselines across all the rubrics. Moreover, we find interesting correlations between summary features and analytic rubrics, revealing the links between the RU and RW constructs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-0810.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-0810 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-0810 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-0810/>Two Layers of Annotation for Representing Event Mentions in News Stories</a></strong><br><a href=/people/m/maria-pia-di-buono/>Maria Pia di Buono</a>
|
<a href=/people/m/martin-tutek/>Martin Tutek</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a>
|
<a href=/people/g/goran-glavas/>Goran Glavaš</a>
|
<a href=/people/b/bojana-dalbelo-basic/>Bojana Dalbelo Bašić</a>
|
<a href=/people/n/natasa-milic-frayling/>Nataša Milić-Frayling</a><br><a href=/volumes/W17-08/ class=text-muted>Proceedings of the 11th Linguistic Annotation Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-0810><div class="card-body p-3 small">In this paper, we describe our preliminary study on annotating event mention as a part of our research on high-precision news event extraction models. To this end, we propose a two-layer annotation scheme, designed to separately capture the functional and conceptual aspects of event mentions. We hypothesize that the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> of <a href=https://en.wikipedia.org/wiki/Computer_simulation>models</a> can be improved by modeling and extracting separately the different aspects of news events, and then combining the extracted information by leveraging the complementarities of the <a href=https://en.wikipedia.org/wiki/Computer_simulation>models</a>. In addition, we carry out a preliminary <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a> using the proposed scheme and analyze the <a href=https://en.wikipedia.org/wiki/Annotation>annotation quality</a> in terms of <a href=https://en.wikipedia.org/wiki/Inter-annotator_agreement>inter-annotator agreement</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1400.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1400/>Proceedings of the 6th Workshop on <span class=acl-fixed-case>B</span>alto-<span class=acl-fixed-case>S</span>lavic Natural Language Processing</a></strong><br><a href=/people/t/tomaz-erjavec/>Tomaž Erjavec</a>
|
<a href=/people/j/jakub-piskorski/>Jakub Piskorski</a>
|
<a href=/people/l/lidia-pivovarova/>Lidia Pivovarova</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a>
|
<a href=/people/j/josef-steinberger/>Josef Steinberger</a>
|
<a href=/people/r/roman-yangarber/>Roman Yangarber</a><br><a href=/volumes/W17-14/ class=text-muted>Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1403.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1403 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1403 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1403/>A Preliminary Study of Croatian Lexical Substitution<span class=acl-fixed-case>C</span>roatian Lexical Substitution</a></strong><br><a href=/people/d/domagoj-alagic/>Domagoj Alagić</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a><br><a href=/volumes/W17-14/ class=text-muted>Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1403><div class="card-body p-3 small">Lexical substitution is a task of determining a meaning-preserving replacement for a word in context. We report on a preliminary study of this task for the <a href=https://en.wikipedia.org/wiki/Croatian_language>Croatian language</a> on a small-scale lexical sample dataset, manually annotated using three different annotation schemes. We compare the <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a>, analyze the inter-annotator agreement, and observe a number of interesting language specific details in the obtained lexical substitutes. Furthermore, we apply a recently-proposed, dependency-based lexical substitution model to our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves a <a href=https://en.wikipedia.org/wiki/P-value>P@3 score</a> of 0.35, which indicates the difficulty of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1409.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1409 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1409 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1409/>Debunking Sentiment Lexicons : A Case of Domain-Specific Sentiment Classification for Croatian<span class=acl-fixed-case>C</span>roatian</a></strong><br><a href=/people/p/paula-gombar/>Paula Gombar</a>
|
<a href=/people/z/zoran-medic/>Zoran Medić</a>
|
<a href=/people/d/domagoj-alagic/>Domagoj Alagić</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a><br><a href=/volumes/W17-14/ class=text-muted>Proceedings of the 6th Workshop on Balto-Slavic Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1409><div class="card-body p-3 small">Sentiment lexicons are widely used as an intuitive and inexpensive way of tackling sentiment classification, often within a simple lexicon word-counting approach or as part of a supervised model. However, it is an open question whether these approaches can compete with <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised models</a> that use only word-representation features. We address this question in the context of domain-specific sentiment classification for <a href=https://en.wikipedia.org/wiki/Croatian_language>Croatian</a>. We experiment with the graph-based acquisition of sentiment lexicons, analyze their quality, and investigate how effectively they can be used in sentiment classification. Our results indicate that, even with as few as 500 labeled instances, a <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised model</a> substantially outperforms a word-counting model. We also observe that adding lexicon-based features does not significantly improve supervised sentiment classification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1727.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1727 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1727 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1727/>Combining <a href=https://en.wikipedia.org/wiki/Linguistic_feature>Linguistic Features</a> for the Detection of Croatian Multiword Expressions<span class=acl-fixed-case>C</span>roatian Multiword Expressions</a></strong><br><a href=/people/m/maja-buljan/>Maja Buljan</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a><br><a href=/volumes/W17-17/ class=text-muted>Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1727><div class="card-body p-3 small">As multiword expressions (MWEs) exhibit a range of <a href=https://en.wikipedia.org/wiki/Idiosyncrasy>idiosyncrasies</a>, their automatic detection warrants the use of many different features. Tsvetkov and Wintner (2014) proposed a Bayesian network model that combines linguistically motivated features and also models their interactions. In this paper, we extend their model with new <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> and apply it to <a href=https://en.wikipedia.org/wiki/Croatian_language>Croatian</a>, a <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphologically complex</a> and a relatively free word order language, achieving a satisfactory performance of 0.823 F1-score. Furthermore, by comparing against (semi)naive Bayes models, we demonstrate that manually modeling feature interactions is indeed important. We make our annotated dataset of Croatian MWEs freely available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4201.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4201 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4201 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4201/>Predicting News Values from <a href=https://en.wikipedia.org/wiki/Headline>Headline Text</a> and Emotions</a></strong><br><a href=/people/m/maria-pia-di-buono/>Maria Pia di Buono</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a>
|
<a href=/people/b/bojana-dalbelo-basic/>Bojana Dalbelo Bašić</a>
|
<a href=/people/g/goran-glavas/>Goran Glavaš</a>
|
<a href=/people/m/martin-tutek/>Martin Tutek</a>
|
<a href=/people/n/natasa-milic-frayling/>Natasa Milic-Frayling</a><br><a href=/volumes/W17-42/ class=text-muted>Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4201><div class="card-body p-3 small">We present a preliminary study on predicting news values from headline text and emotions. We perform a <a href=https://en.wikipedia.org/wiki/Multivariate_analysis>multivariate analysis</a> on a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> manually annotated with news values and emotions, discovering interesting correlations among them. We then train two competitive machine learning models an SVM and a CNN to predict news values from headline text and emotions as features. We find that, while both models yield a satisfactory performance, some news values are more difficult to detect than others, while some profit more from including emotion information.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q17-1032.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q17-1032 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q17-1032 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/277673914 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/Q17-1032/>Unsupervised Acquisition of Comprehensive Multiword Lexicons using Competition in an n-gram Lattice</a></strong><br><a href=/people/j/julian-brooke/>Julian Brooke</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a>
|
<a href=/people/t/timothy-baldwin/>Timothy Baldwin</a><br><a href=/volumes/Q17-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 5</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q17-1032><div class="card-body p-3 small">We present a new model for acquiring comprehensive multiword lexicons from large corpora based on competition among n-gram candidates. In contrast to the standard approach of simple ranking by association measure, in our model n-grams are arranged in a lattice structure based on subsumption and overlap relationships, with nodes inhibiting other nodes in their vicinity when they are selected as a lexical item. We show how the configuration of such a <a href=https://en.wikipedia.org/wiki/Lattice_(group)>lattice</a> can be optimized tractably, and demonstrate using annotations of sampled n-grams that our method consistently outperforms alternatives by at least 0.05 <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> across several corpora and languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-1014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-1014 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-1014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/S17-1014.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/S17-1014/>Does Free Word Order Hurt? Assessing the Practical Lexical Function Model for Croatian<span class=acl-fixed-case>C</span>roatian</a></strong><br><a href=/people/z/zoran-medic/>Zoran Medić</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a><br><a href=/volumes/S17-1/ class=text-muted>Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-1014><div class="card-body p-3 small">The Practical Lexical Function (PLF) model is a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> of computational distributional semantics that attempts to strike a balance between expressivity and learnability in predicting phrase meaning and shows competitive results. We investigate how well the PLF carries over to free word order languages, given that it builds on observations of predicate-argument combinations that are harder to recover in free word order languages. We evaluate variants of the PLF for <a href=https://en.wikipedia.org/wiki/Croatian_language>Croatian</a>, using a new lexical substitution dataset. We find that the PLF works about as well for <a href=https://en.wikipedia.org/wiki/Croatian_language>Croatian</a> as for <a href=https://en.wikipedia.org/wiki/English_language>English</a>, but demonstrate that its strength lies in modeling verbs, and that the free word order affects the less robust PLF variant.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2055.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2055 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2055 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2055/>TakeLab-QA at SemEval-2017 Task 3 : Classification Experiments for Answer Retrieval in Community QA<span class=acl-fixed-case>T</span>ake<span class=acl-fixed-case>L</span>ab-<span class=acl-fixed-case>QA</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 3: Classification Experiments for Answer Retrieval in Community <span class=acl-fixed-case>QA</span></a></strong><br><a href=/people/f/filip-saina/>Filip Šaina</a>
|
<a href=/people/t/toni-kukurin/>Toni Kukurin</a>
|
<a href=/people/l/lukrecija-puljic/>Lukrecija Puljić</a>
|
<a href=/people/m/mladen-karan/>Mladen Karan</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2055><div class="card-body p-3 small">In this paper we present the TakeLab-QA entry to SemEval 2017 task 3, which is a question-comment re-ranking problem. We present a classification based approach, including two supervised learning models Support Vector Machines (SVM) and Convolutional Neural Networks (CNN). We use <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> based on different semantic similarity models (e.g., Latent Dirichlet Allocation), as well as <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> based on several types of pre-trained word embeddings. Moreover, we also use some hand-crafted task-specific features. For <a href=https://en.wikipedia.org/wiki/Training>training</a>, our <a href=https://en.wikipedia.org/wiki/System>system</a> uses no external labeled data apart from that provided by the organizers. Our primary submission achieves a MAP-score of 81.14 and F1-score of 66.99 ranking us 10th on the SemEval 2017 task 3, subtask A.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2066.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2066 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2066 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2066/>TakeLab at SemEval-2017 Task 6 : # RankingHumorIn4Pages<span class=acl-fixed-case>T</span>ake<span class=acl-fixed-case>L</span>ab at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 6: #<span class=acl-fixed-case>R</span>anking<span class=acl-fixed-case>H</span>umor<span class=acl-fixed-case>I</span>n4<span class=acl-fixed-case>P</span>ages</a></strong><br><a href=/people/m/marin-kukovacec/>Marin Kukovačec</a>
|
<a href=/people/j/juraj-malenica/>Juraj Malenica</a>
|
<a href=/people/i/ivan-mrsic/>Ivan Mršić</a>
|
<a href=/people/a/antonio-sajatovic/>Antonio Šajatović</a>
|
<a href=/people/d/domagoj-alagic/>Domagoj Alagić</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2066><div class="card-body p-3 small">This paper describes our system for humor ranking in <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> within the SemEval 2017 Task 6 : # HashtagWars (6A and 6B). For both subtasks, we use an off-the-shelf gradient boosting model built on a rich set of features, handcrafted to provide the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> with the external knowledge needed to better predict the <a href=https://en.wikipedia.org/wiki/Humour>humor</a> in the text. The <a href=https://en.wikipedia.org/wiki/Feature_film>features</a> capture various cultural references and specific <a href=https://en.wikipedia.org/wiki/Culture_of_the_United_States>humor patterns</a>. Our system ranked 2nd (officially 7th) among 10 submissions on the Subtask A and 2nd among 9 submissions on the Subtask B.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2148.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2148 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2148 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2148/>TakeLab at SemEval-2017 Task 5 : Linear aggregation of word embeddings for fine-grained sentiment analysis of financial news<span class=acl-fixed-case>T</span>ake<span class=acl-fixed-case>L</span>ab at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 5: Linear aggregation of word embeddings for fine-grained sentiment analysis of financial news</a></strong><br><a href=/people/l/leon-rotim/>Leon Rotim</a>
|
<a href=/people/m/martin-tutek/>Martin Tutek</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2148><div class="card-body p-3 small">This paper describes our system for fine-grained sentiment scoring of news headlines submitted to SemEval 2017 task 5subtask 2. Our system uses a feature-light method that consists of a Support Vector Regression (SVR) with various kernels and <a href=https://en.wikipedia.org/wiki/Word_vector>word vectors</a> as <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>. Our best-performing submission scored 3rd on the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> out of 29 teams and 4th out of 45 submissions with a <a href=https://en.wikipedia.org/wiki/Trigonometric_functions>cosine score</a> of 0.733.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Jan+%C5%A0najder" title="Search for 'Jan Šnajder' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/m/mladen-karan/ class=align-middle>Mladen Karan</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/m/martin-tutek/ class=align-middle>Martin Tutek</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/m/matej-gjurkovic/ class=align-middle>Matej Gjurković</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/b/bojana-dalbelo-basic/ class=align-middle>Bojana Dalbelo Bašić</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/d/domagoj-alagic/ class=align-middle>Domagoj Alagić</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/t/tamara-sladoljev-agejev/ class=align-middle>Tamara Sladoljev-Agejev</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/maria-pia-di-buono/ class=align-middle>Maria Pia Di Buono</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/g/goran-glavas/ class=align-middle>Goran Glavaš</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/n/natasa-milic-frayling/ class=align-middle>Nataša Milić-Frayling</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/tomaz-erjavec/ class=align-middle>Tomaž Erjavec</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jakub-piskorski/ class=align-middle>Jakub Piskorski</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/lidia-pivovarova/ class=align-middle>Lidia Pivovarova</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/josef-steinberger/ class=align-middle>Josef Steinberger</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/roman-yangarber/ class=align-middle>Roman Yangarber</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/zoran-medic/ class=align-middle>Zoran Medić</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/maja-buljan/ class=align-middle>Maja Buljan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/antonio-sajatovic/ class=align-middle>Antonio Šajatović</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/i/iva-vukojevic/ class=align-middle>Iva Vukojević</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mihaela-bosnjak/ class=align-middle>Mihaela Bošnjak</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paula-gombar/ class=align-middle>Paula Gombar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/julian-brooke/ class=align-middle>Julian Brooke</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/timothy-baldwin/ class=align-middle>Timothy Baldwin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sebastian-pado/ class=align-middle>Sebastian Padó</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/filip-saina/ class=align-middle>Filip Šaina</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/toni-kukurin/ class=align-middle>Toni Kukurin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lukrecija-puljic/ class=align-middle>Lukrecija Puljić</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marin-kukovacec/ class=align-middle>Marin Kukovačec</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/juraj-malenica/ class=align-middle>Juraj Malenica</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ivan-mrsic/ class=align-middle>Ivan Mršić</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/leon-rotim/ class=align-middle>Leon Rotim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/viktor-golem/ class=align-middle>Viktor Golem</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ivan-sekulic/ class=align-middle>Ivan Sekulic</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michal-marcinczuk/ class=align-middle>Michał Marcińczuk</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/preslav-nakov/ class=align-middle>Preslav Nakov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/svjetlana-kolic-vehovec/ class=align-middle>Svjetlana Kolić Vehovec</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">15</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/socialnlp/ class=align-middle>SocialNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/tacl/ class=align-middle>TACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>