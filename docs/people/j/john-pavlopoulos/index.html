<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>John Pavlopoulos - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>John</span> <span class=font-weight-bold>Pavlopoulos</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-main.124.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-main--124 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-main.124 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.eacl-main.124.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.eacl-main.124" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-main.124/>Civil Rephrases Of Toxic Texts With Self-Supervised Transformers</a></strong><br><a href=/people/l/leo-laugier/>LÃ©o Laugier</a>
|
<a href=/people/j/john-pavlopoulos/>John Pavlopoulos</a>
|
<a href=/people/j/jeffrey-sorensen/>Jeffrey Sorensen</a>
|
<a href=/people/l/lucas-dixon/>Lucas Dixon</a><br><a href=/volumes/2021.eacl-main/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-main--124><div class="card-body p-3 small">Platforms that support online commentary, from <a href=https://en.wikipedia.org/wiki/List_of_social_networking_websites>social networks</a> to <a href=https://en.wikipedia.org/wiki/Online_newspaper>news sites</a>, are increasingly leveraging <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a> to assist their moderation efforts. But this process does not typically provide feedback to the author that would help them contribute according to the community guidelines. This is prohibitively time-consuming for <a href=https://en.wikipedia.org/wiki/Moderator_(Internet)>human moderators</a> to do, and <a href=https://en.wikipedia.org/wiki/Computational_model>computational approaches</a> are still nascent. This work focuses on <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that can help suggest rephrasings of toxic comments in a more civil manner. Inspired by recent progress in unpaired sequence-to-sequence tasks, a self-supervised learning model is introduced, called CAE-T5. CAE-T5 employs a pre-trained text-to-text transformer, which is fine tuned with a denoising and cyclic auto-encoder loss. Experimenting with the largest toxicity detection dataset to date (Civil Comments) our model generates sentences that are more fluent and better at preserving the initial content compared to earlier text style transfer systems which we compare with using several scoring systems and human evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.woah-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--woah-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.woah-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.woah-1.15/>Context Sensitivity Estimation in Toxicity Detection</a></strong><br><a href=/people/a/alexandros-xenos/>Alexandros Xenos</a>
|
<a href=/people/j/john-pavlopoulos/>John Pavlopoulos</a>
|
<a href=/people/i/ion-androutsopoulos/>Ion Androutsopoulos</a><br><a href=/volumes/2021.woah-1/ class=text-muted>Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--woah-1--15><div class="card-body p-3 small">User posts whose perceived toxicity depends on the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>conversational context</a> are rare in current toxicity detection datasets. Hence, toxicity detectors trained on current datasets will also disregard <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context</a>, making the detection of context-sensitive toxicity a lot harder when it occurs. We constructed and publicly release a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 10k posts with two kinds of toxicity labels per post, obtained from annotators who considered (i) both the current post and the previous one as context, or (ii) only the current post. We introduce a new task, context-sensitivity estimation, which aims to identify posts whose perceived toxicity changes if the context (previous post) is also considered. Using the new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, we show that <a href=https://en.wikipedia.org/wiki/System>systems</a> can be developed for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. Such systems could be used to enhance toxicity detection datasets with more context-dependent posts or to suggest when moderators should consider the parent posts, which may not always be necessary and may introduce additional costs.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-2102.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S19-2102 data-toggle=collapse aria-expanded=false aria-controls=abstract-S19-2102 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-2102/>ConvAI at SemEval-2019 Task 6 : Offensive Language Identification and Categorization with Perspective and BERT<span class=acl-fixed-case>C</span>onv<span class=acl-fixed-case>AI</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2019 Task 6: Offensive Language Identification and Categorization with Perspective and <span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/j/john-pavlopoulos/>John Pavlopoulos</a>
|
<a href=/people/n/nithum-thain/>Nithum Thain</a>
|
<a href=/people/l/lucas-dixon/>Lucas Dixon</a>
|
<a href=/people/i/ion-androutsopoulos/>Ion Androutsopoulos</a><br><a href=/volumes/S19-2/ class=text-muted>Proceedings of the 13th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S19-2102><div class="card-body p-3 small">This paper presents the application of two strong baseline systems for toxicity detection and evaluates their performance in identifying and categorizing offensive language in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. PERSPECTIVE is an <a href=https://en.wikipedia.org/wiki/Application_programming_interface>API</a>, that serves multiple <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning models</a> for the improvement of conversations online, as well as a toxicity detection system, trained on a wide variety of comments from platforms across the Internet. BERT is a recently popular language representation model, fine tuned per task and achieving state of the art performance in multiple NLP tasks. PERSPECTIVE performed better than BERT in detecting <a href=https://en.wikipedia.org/wiki/Toxicity>toxicity</a>, but BERT was much better in categorizing the offensive type. Both baselines were ranked surprisingly high in the SEMEVAL-2019 OFFENSEVAL competition, PERSPECTIVE in detecting an offensive post (12th) and BERT in categorizing it (11th). The main contribution of this paper is the assessment of two strong baselines for the identification (PERSPECTIVE) and the categorization (BERT) of offensive language with little or no additional training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-1803.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-1803 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-1803 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-1803" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-1803/>A Survey on Biomedical Image Captioning</a></strong><br><a href=/people/j/john-pavlopoulos/>John Pavlopoulos</a>
|
<a href=/people/v/vasiliki-kougia/>Vasiliki Kougia</a>
|
<a href=/people/i/ion-androutsopoulos/>Ion Androutsopoulos</a><br><a href=/volumes/W19-18/ class=text-muted>Proceedings of the Second Workshop on Shortcomings in Vision and Language</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-1803><div class="card-body p-3 small">Image captioning applied to biomedical images can assist and accelerate the diagnosis process followed by clinicians. This article is the first survey of biomedical image captioning, discussing <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation measures</a>, and <a href=https://en.wikipedia.org/wiki/Scientific_method>state of the art methods</a>. Additionally, we suggest two <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>, a weak and a stronger one ; the latter outperforms all current state of the art systems on one of the <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3004 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3004/>Deep Learning for User Comment Moderation</a></strong><br><a href=/people/j/john-pavlopoulos/>John Pavlopoulos</a>
|
<a href=/people/p/prodromos-malakasiotis/>Prodromos Malakasiotis</a>
|
<a href=/people/i/ion-androutsopoulos/>Ion Androutsopoulos</a><br><a href=/volumes/W17-30/ class=text-muted>Proceedings of the First Workshop on Abusive Language Online</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3004><div class="card-body p-3 small">Experimenting with a new dataset of 1.6 M user comments from a Greek news portal and existing datasets of EnglishWikipedia comments, we show that an <a href=https://en.wikipedia.org/wiki/Random-access_memory>RNN</a> outperforms the previous state of the art in <a href=https://en.wikipedia.org/wiki/Moderation_system>moderation</a>. A deep, classification-specific attention mechanism improves further the overall performance of the <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>RNN</a>. We also compare against a <a href=https://en.wikipedia.org/wiki/CNN>CNN</a> and a word-list baseline, considering both fully automatic and semi-automatic moderation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4209.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4209 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4209 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4209/>Improved Abusive Comment Moderation with User Embeddings</a></strong><br><a href=/people/j/john-pavlopoulos/>John Pavlopoulos</a>
|
<a href=/people/p/prodromos-malakasiotis/>Prodromos Malakasiotis</a>
|
<a href=/people/j/juli-bakagianni/>Juli Bakagianni</a>
|
<a href=/people/i/ion-androutsopoulos/>Ion Androutsopoulos</a><br><a href=/volumes/W17-42/ class=text-muted>Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4209><div class="card-body p-3 small">Experimenting with a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of approximately 1.6 M user comments from a Greek news sports portal, we explore how a state of the art RNN-based moderation method can be improved by adding <a href=https://en.wikipedia.org/wiki/Graph_embedding>user embeddings</a>, <a href=https://en.wikipedia.org/wiki/Graph_embedding>user type embeddings</a>, user biases, or <a href=https://en.wikipedia.org/wiki/Graph_embedding>user type biases</a>. We observe improvements in all cases, with user embeddings leading to the biggest performance gains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1117.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1117 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1117 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238232251 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1117/>Deeper Attention to Abusive User Content Moderation</a></strong><br><a href=/people/j/john-pavlopoulos/>John Pavlopoulos</a>
|
<a href=/people/p/prodromos-malakasiotis/>Prodromos Malakasiotis</a>
|
<a href=/people/i/ion-androutsopoulos/>Ion Androutsopoulos</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1117><div class="card-body p-3 small">Experimenting with a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 1.6 M user comments from a news portal and an existing <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 115 K Wikipedia talk page comments, we show that an RNN operating on word embeddings outpeforms the previous state of the art in moderation, which used <a href=https://en.wikipedia.org/wiki/Logistic_regression>logistic regression</a> or an MLP classifier with character or word n-grams. We also compare against a <a href=https://en.wikipedia.org/wiki/CNN>CNN</a> operating on <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>, and a word-list baseline. A novel, deep, classificationspecific attention mechanism improves the performance of the <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>RNN</a> further, and can also highlight suspicious words for free, without including highlighted words in the training data. We consider both fully automatic and semi-automatic moderation.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=John+Pavlopoulos" title="Search for 'John Pavlopoulos' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/i/ion-androutsopoulos/ class=align-middle>Ion Androutsopoulos</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/p/prodromos-malakasiotis/ class=align-middle>Prodromos Malakasiotis</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/lucas-dixon/ class=align-middle>Lucas Dixon</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/leo-laugier/ class=align-middle>LÃ©o Laugier</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jeffrey-sorensen/ class=align-middle>Jeffrey Sorensen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/j/juli-bakagianni/ class=align-middle>Juli Bakagianni</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexandros-xenos/ class=align-middle>Alexandros Xenos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nithum-thain/ class=align-middle>Nithum Thain</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vasiliki-kougia/ class=align-middle>Vasiliki Kougia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/woah/ class=align-middle>WOAH</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>