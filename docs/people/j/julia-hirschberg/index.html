<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Julia Hirschberg - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Julia</span> <span class=font-weight-bold>Hirschberg</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.364.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--364 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.364 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.364/>CHoRaL : Collecting Humor Reaction Labels from Millions of Social Media Users<span class=acl-fixed-case>CH</span>o<span class=acl-fixed-case>R</span>a<span class=acl-fixed-case>L</span>: Collecting Humor Reaction Labels from Millions of Social Media Users</a></strong><br><a href=/people/z/zixiaofan-yang/>Zixiaofan Yang</a>
|
<a href=/people/s/shayan-hooshmand/>Shayan Hooshmand</a>
|
<a href=/people/j/julia-hirschberg/>Julia Hirschberg</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--364><div class="card-body p-3 small">Humor detection has gained attention in recent years due to the desire to understand <a href=https://en.wikipedia.org/wiki/User-generated_content>user-generated content</a> with <a href=https://en.wikipedia.org/wiki/Literal_and_figurative_language>figurative language</a>. However, substantial individual and cultural differences in humor perception make it very difficult to collect a large-scale humor dataset with reliable humor labels. We propose CHoRaL, a <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> to generate perceived humor labels on Facebook posts, using the naturally available user reactions to these posts with no manual annotation needed. CHoRaL provides both binary labels and continuous scores of <a href=https://en.wikipedia.org/wiki/Humour>humor</a> and non-humor. We present the largest <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> to date with labeled humor on 785 K posts related to COVID-19. Additionally, we analyze the expression of COVID-related humor in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> by extracting lexico-semantic and affective features from the posts, and build humor detection models with performance similar to humans. CHoRaL enables the development of large-scale humor detection models on any topic and opens a new path to the study of <a href=https://en.wikipedia.org/wiki/Humour>humor</a> on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.clpsych-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--clpsych-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.clpsych-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.clpsych-1.14/>Automatic Detection and Prediction of Psychiatric Hospitalizations From Social Media Posts</a></strong><br><a href=/people/z/zheng-ping-jiang/>Zhengping Jiang</a>
|
<a href=/people/j/jonathan-zomick/>Jonathan Zomick</a>
|
<a href=/people/s/sarah-ita-levitan/>Sarah Ita Levitan</a>
|
<a href=/people/m/mark-serper/>Mark Serper</a>
|
<a href=/people/j/julia-hirschberg/>Julia Hirschberg</a><br><a href=/volumes/2021.clpsych-1/ class=text-muted>Proceedings of the Seventh Workshop on Computational Linguistics and Clinical Psychology: Improving Access</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--clpsych-1--14><div class="card-body p-3 small">We address the problem of predicting psychiatric hospitalizations using <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a> drawn from <a href=https://en.wikipedia.org/wiki/Social_media>social media posts</a>. We formulate this novel task and develop an approach to automatically extract time spans of self-reported psychiatric hospitalizations. Using this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, we build <a href=https://en.wikipedia.org/wiki/Predictive_modelling>predictive models</a> of psychiatric hospitalization, comparing <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature sets</a>, user vs. post classification, and comparing model performance using a varying time window of posts. Our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves an <a href=https://en.wikipedia.org/wiki/F-number>F1</a> of.718 using 7 days of posts. Our results suggest that this is a useful framework for collecting hospitalization data, and that social media data can be leveraged to predict acute psychiatric crises before they occur, potentially saving lives and improving outcomes for individuals with <a href=https://en.wikipedia.org/wiki/Mental_disorder>mental illness</a>.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.tacl-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--tacl-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.tacl-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.tacl-1.14/>Acoustic-Prosodic and Lexical Cues to Deception and Trust : Deciphering How People Detect Lies</a></strong><br><a href=/people/x/xi-leslie-chen/>Xi (Leslie) Chen</a>
|
<a href=/people/s/sarah-ita-levitan/>Sarah Ita Levitan</a>
|
<a href=/people/m/michelle-levine/>Michelle Levine</a>
|
<a href=/people/m/marko-mandic/>Marko Mandic</a>
|
<a href=/people/j/julia-hirschberg/>Julia Hirschberg</a><br><a href=/volumes/2020.tacl-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 8</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--tacl-1--14><div class="card-body p-3 small">Humans rarely perform better than chance at <a href=https://en.wikipedia.org/wiki/Lie_detection>lie detection</a>. To better understand human perception of deception, we created a game framework, LieCatcher, to collect ratings of perceived deception using a large corpus of deceptive and truthful interviews. We analyzed the acoustic-prosodic and linguistic characteristics of language trusted and mistrusted by raters and compared these to characteristics of actual truthful and deceptive language to understand how perception aligns with reality. With this data we built <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> to automatically distinguish <a href=https://en.wikipedia.org/wiki/Trust_(social_science)>trusted</a> from mistrusted speech, achieving an F1 of 66.1 %. We next evaluated whether the strategies raters said they used to discriminate between truthful and deceptive responses were in fact useful. Our results show that, although several prosodic and lexical features were consistently perceived as trustworthy, they were not reliable cues. Also, the <a href=https://en.wikipedia.org/wiki/Strategy>strategies</a> that judges reported using in deception detection were not helpful for the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. Our work sheds light on the nature of trusted language and provides insight into the challenging problem of human deception detection.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-1301.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-1301 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-1301 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-1301/>Using Hedge Detection to Improve Committed Belief Tagging</a></strong><br><a href=/people/m/morgan-ulinski/>Morgan Ulinski</a>
|
<a href=/people/s/seth-benjamin/>Seth Benjamin</a>
|
<a href=/people/j/julia-hirschberg/>Julia Hirschberg</a><br><a href=/volumes/W18-13/ class=text-muted>Proceedings of the Workshop on Computational Semantics beyond Events and Roles</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-1301><div class="card-body p-3 small">We describe a novel method for identifying hedge terms using a set of manually constructed rules. We present experiments adding hedge features to a committed belief system to improve <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a>. We compare performance of this system (a) without <a href=https://en.wikipedia.org/wiki/Hedge_(finance)>hedging features</a>, (b) with dictionary-based features, and (c) with rule-based features. We find that using hedge features improves performance of the committed belief system, particularly in identifying instances of non-committed belief and reported belief.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3200.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3200/>Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching</a></strong><br><a href=/people/g/gustavo-aguilar/>Gustavo Aguilar</a>
|
<a href=/people/f/fahad-alghamdi/>Fahad AlGhamdi</a>
|
<a href=/people/v/victor-soto/>Victor Soto</a>
|
<a href=/people/t/thamar-solorio/>Thamar Solorio</a>
|
<a href=/people/m/mona-diab/>Mona Diab</a>
|
<a href=/people/j/julia-hirschberg/>Julia Hirschberg</a><br><a href=/volumes/W18-32/ class=text-muted>Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3201.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3201 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3201 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3201/>Joint Part-of-Speech and Language ID Tagging for Code-Switched Data<span class=acl-fixed-case>ID</span> Tagging for Code-Switched Data</a></strong><br><a href=/people/v/victor-soto/>Victor Soto</a>
|
<a href=/people/j/julia-hirschberg/>Julia Hirschberg</a><br><a href=/volumes/W18-32/ class=text-muted>Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3201><div class="card-body p-3 small">Code-switching is the fluent alternation between two or more languages in conversation between bilinguals. Large populations of speakers code-switch during communication, but little effort has been made to develop tools for <a href=https://en.wikipedia.org/wiki/Code-switching>code-switching</a>, including <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech taggers</a>. In this paper, we propose an approach to POS tagging of code-switched English-Spanish data based on <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural networks</a>. We test our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on known monolingual benchmarks to demonstrate that our neural POS tagging model is on par with state-of-the-art methods. We next test our code-switched methods on the Miami Bangor corpus of English Spanish conversation, focusing on two types of experiments : <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>POS tagging</a> alone, for which we achieve 96.34 % accuracy, and joint part-of-speech and language ID tagging, which achieves similar <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>POS tagging accuracy</a> (96.39 %) and very high language ID accuracy (98.78 %). Finally, we show that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> outperform other state-of-the-art code-switched taggers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1176.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1176 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1176 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277672970 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1176/>Linguistic Cues to Deception and Perceived Deception in Interview Dialogues</a></strong><br><a href=/people/s/sarah-ita-levitan/>Sarah Ita Levitan</a>
|
<a href=/people/a/angel-maredia/>Angel Maredia</a>
|
<a href=/people/j/julia-hirschberg/>Julia Hirschberg</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1176><div class="card-body p-3 small">We explore deception detection in interview dialogues. We analyze a set of <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a> in both truthful and deceptive responses to interview questions. We also study the perception of deception, identifying characteristics of statements that are perceived as truthful or deceptive by interviewers. Our analysis show significant differences between truthful and deceptive question responses, as well as variations in deception patterns across gender and native language. This analysis motivated our selection of <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> for <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a> experiments aimed at classifying globally deceptive speech. Our best <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance is 72.74 % F1-Score (about 17 % better than human performance), which is achieved using a combination of <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a> and <a href=https://en.wikipedia.org/wiki/Phenotypic_trait>individual traits</a>.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-1013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-1013 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-1013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-1013/>Comparing Approaches for Automatic Question Identification</a></strong><br><a href=/people/a/angel-maredia/>Angel Maredia</a>
|
<a href=/people/k/kara-schechtman/>Kara Schechtman</a>
|
<a href=/people/s/sarah-ita-levitan/>Sarah Ita Levitan</a>
|
<a href=/people/j/julia-hirschberg/>Julia Hirschberg</a><br><a href=/volumes/S17-1/ class=text-muted>Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-1013><div class="card-body p-3 small">Collecting spontaneous speech corpora that are open-ended, yet topically constrained, is increasingly popular for research in spoken dialogue systems and speaker state, inter alia. Typically, these <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpora</a> are labeled by human annotators, either in the lab or through <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowd-sourcing</a> ; however, this is cumbersome and time-consuming for large corpora. We present four different approaches to automatically tagging a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> when general topics of the conversations are known. We develop these approaches on the Columbia X-Cultural Deception corpus and find <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> that significantly exceeds the <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baseline</a>. Finally, we conduct a cross-corpus evaluation by testing the best performing approach on the Columbia / SRI / Colorado corpus.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Julia+Hirschberg" title="Search for 'Julia Hirschberg' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/s/sarah-ita-levitan/ class=align-middle>Sarah Ita Levitan</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/a/angel-maredia/ class=align-middle>Angel Maredia</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/v/victor-soto/ class=align-middle>Victor Soto</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/zixiaofan-yang/ class=align-middle>Zixiaofan Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shayan-hooshmand/ class=align-middle>Shayan Hooshmand</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/k/kara-schechtman/ class=align-middle>Kara Schechtman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/morgan-ulinski/ class=align-middle>Morgan Ulinski</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/seth-benjamin/ class=align-middle>Seth Benjamin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gustavo-aguilar/ class=align-middle>Gustavo Aguilar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fahad-alghamdi/ class=align-middle>Fahad AlGhamdi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thamar-solorio/ class=align-middle>Thamar Solorio</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mona-diab/ class=align-middle>Mona Diab</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zheng-ping-jiang/ class=align-middle>Zheng Ping Jiang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jonathan-zomick/ class=align-middle>Jonathan Zomick</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mark-serper/ class=align-middle>Mark Serper</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xi-leslie-chen/ class=align-middle>Xi (Leslie) Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michelle-levine/ class=align-middle>Michelle Levine</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marko-mandic/ class=align-middle>Marko Mandic</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/clpsych/ class=align-middle>CLPsych</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/tacl/ class=align-middle>TACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>