<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>James Allen - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>James</span> <span class=font-weight-bold>Allen</span></h2><p class="font-weight-light text-muted">Rochester</p><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
James F. <span class=font-weight-normal>Allen</span></p><p class="font-weight-light text-muted"><span class=font-italic>Other people with similar names:</span>
<a href=/people/j/james-allan/>James Allan</a>
(UMass Amherst)</p><hr><div class=row><div class=col-lg-9><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/J18-1003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-J18-1003 data-toggle=collapse aria-expanded=false aria-controls=abstract-J18-1003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/J18-1003/>A Notion of Semantic Coherence for Underspecified Semantic Representation</a></strong><br><a href=/people/m/mehdi-manshadi/>Mehdi Manshadi</a>
|
<a href=/people/d/daniel-gildea/>Daniel Gildea</a>
|
<a href=/people/j/james-allen/>James F. Allen</a><br><a href=/volumes/J18-1/ class=text-muted>Computational Linguistics, Volume 44, Issue 1 - April 2018</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-J18-1003><div class="card-body p-3 small">The general problem of finding satisfying solutions to constraint-based underspecified representations of quantifier scope is NP-complete. Existing frameworks, including Dominance Graphs, <a href=https://en.wikipedia.org/wiki/Minimal_recursion_semantics>Minimal Recursion Semantics</a>, and Hole Semantics, have struggled to balance expressivity and tractability in order to cover real natural language sentences with efficient algorithms. We address this trade-off with a general principle of <a href=https://en.wikipedia.org/wiki/Coherence_(linguistics)>coherence</a>, which requires that every variable introduced in the <a href=https://en.wikipedia.org/wiki/Domain_of_discourse>domain of discourse</a> must contribute to the overall <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> of the sentence. We show that every underspecified representation meeting this criterion can be efficiently processed, and that our set of <a href=https://en.wikipedia.org/wiki/Representation_theory>representations</a> subsumes all previously identified tractable sets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5010 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5010/>A Situated Dialogue System for Learning Structural Concepts in Blocks World</a></strong><br><a href=/people/i/ian-perera/>Ian Perera</a>
|
<a href=/people/j/james-allen/>James Allen</a>
|
<a href=/people/c/choh-man-teng/>Choh Man Teng</a>
|
<a href=/people/l/lucian-galescu/>Lucian Galescu</a><br><a href=/volumes/W18-50/ class=text-muted>Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5010><div class="card-body p-3 small">We present a modular, end-to-end dialogue system for a situated agent to address a multimodal, natural language dialogue task in which the <a href=https://en.wikipedia.org/wiki/Intelligent_agent>agent</a> learns complex representations of block structure classes through assertions, demonstrations, and questioning. The concept to learn is provided to the user through a set of positive and negative visual examples, from which the user determines the underlying constraints to be provided to the <a href=https://en.wikipedia.org/wiki/System>system</a> in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language</a>. The <a href=https://en.wikipedia.org/wiki/System>system</a> in turn asks questions about demonstrated examples and simulates new examples to check its knowledge and verify the user&#8217;s description is complete. We find that this task is non-trivial for users and generates <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a> that is varied yet understood by our deep language understanding architecture.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5048.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5048 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5048 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5048/>Cogent : A Generic Dialogue System Shell Based on a Collaborative Problem Solving Model<span class=acl-fixed-case>C</span>ogent: A Generic Dialogue System Shell Based on a Collaborative Problem Solving Model</a></strong><br><a href=/people/l/lucian-galescu/>Lucian Galescu</a>
|
<a href=/people/c/choh-man-teng/>Choh Man Teng</a>
|
<a href=/people/j/james-allen/>James Allen</a>
|
<a href=/people/i/ian-perera/>Ian Perera</a><br><a href=/volumes/W18-50/ class=text-muted>Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5048><div class="card-body p-3 small">The bulk of current research in <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a> is focused on fairly simple task models, primarily state-based. Progress on developing <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a> for more complex tasks has been limited by the lack generic toolkits to build from. In this paper we report on our development from the ground up of a new dialogue model based on collaborative problem solving. We implemented the model in a dialogue system shell (Cogent) that al-lows developers to plug in problem-solving agents to create dialogue systems in new domains. The Cogent shell has now been used by several independent teams of researchers to develop dialogue systems in different domains, with varied lexicons and interaction style, each with their own problem-solving back-end. We believe this to be the first practical demonstration of the feasibility of a CPS-based dialogue system shell.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1084.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1084 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1084 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234956988 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1084/>Apples to Apples : Learning Semantics of Common Entities Through a Novel Comprehension Task</a></strong><br><a href=/people/o/omid-bakhshandeh/>Omid Bakhshandeh</a>
|
<a href=/people/j/james-allen/>James Allen</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1084><div class="card-body p-3 small">Understanding common entities and their attributes is a primary requirement for any <a href=https://en.wikipedia.org/wiki/System>system</a> that comprehends <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. In order to enable learning about common entities, we introduce a novel machine comprehension task, GuessTwo : given a short paragraph comparing different aspects of two real-world semantically-similar entities, a system should guess what those entities are. Accomplishing this task requires <a href=https://en.wikipedia.org/wiki/Deep_learning>deep language understanding</a> which enables <a href=https://en.wikipedia.org/wiki/Inference>inference</a>, connecting each comparison paragraph to different levels of knowledge about world entities and their attributes. So far we have crowdsourced a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of more than 14 K comparison paragraphs comparing entities from a variety of categories such as fruits and animals. We have designed two <a href=https://en.wikipedia.org/wiki/Scheme_(mathematics)>schemes</a> for evaluation : open-ended, and binary-choice prediction. For benchmarking further progress in the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, we have collected a set of paragraphs as the test set on which human can accomplish the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> with an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 94.2 % on open-ended prediction. We have implemented various <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> for tackling the task, ranging from semantic-driven to neural models. The semantic-driven approach outperforms the neural models, however, the results indicate that the task is very challenging across the models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-0906.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-0906 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-0906 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-0906/>LSDSem 2017 Shared Task : The Story Cloze Test<span class=acl-fixed-case>LSDS</span>em 2017 Shared Task: The Story Cloze Test</a></strong><br><a href=/people/n/nasrin-mostafazadeh/>Nasrin Mostafazadeh</a>
|
<a href=/people/m/michael-roth/>Michael Roth</a>
|
<a href=/people/a/annie-louis/>Annie Louis</a>
|
<a href=/people/n/nathanael-chambers/>Nathanael Chambers</a>
|
<a href=/people/j/james-allen/>James Allen</a><br><a href=/volumes/W17-09/ class=text-muted>Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-0906><div class="card-body p-3 small">The LSDSem&#8217;17 shared task is the Story Cloze Test, a new evaluation for story understanding and script learning. This test provides a <a href=https://en.wikipedia.org/wiki/System>system</a> with a four-sentence story and two possible endings, and the system must choose the correct ending to the story. Successful narrative understanding (getting closer to human performance of 100 %) requires systems to link various levels of <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> to <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a>. A total of eight systems participated in the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>shared task</a>, with a variety of <a href=https://en.wikipedia.org/wiki/Software_development_process>approaches</a> including.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1719.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1719 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1719 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1719/>Compositionality in Verb-Particle Constructions</a></strong><br><a href=/people/a/archna-bhatia/>Archna Bhatia</a>
|
<a href=/people/c/choh-man-teng/>Choh Man Teng</a>
|
<a href=/people/j/james-allen/>James Allen</a><br><a href=/volumes/W17-17/ class=text-muted>Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1719><div class="card-body p-3 small">We are developing a broad-coverage deep semantic lexicon for a system that parses sentences into a logical form expressed in a rich ontology that supports <a href=https://en.wikipedia.org/wiki/Reason>reasoning</a>. In this paper we look at verb-particle constructions (VPCs), and the extent to which they can be treated compositionally vs idiomatically. First we distinguish between the different types of VPCs based on their compositionality and then present a set of <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a> for classifying specific instances as compositional or not. We then identify a small set of general sense classes for <a href=https://en.wikipedia.org/wiki/Grammatical_particle>particles</a> when used compositionally and discuss the resulting lexical representations that are being added to the lexicon. By treating VPCs as compositional whenever possible, we attain broad coverage in a compact way, and also enable interpretations of novel VPC usages not explicitly present in the lexicon.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=James+Allen" title="Search for 'James Allen' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/c/choh-man-teng/ class=align-middle>Choh Man Teng</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/i/ian-perera/ class=align-middle>Ian Perera</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/lucian-galescu/ class=align-middle>Lucian Galescu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/o/omid-bakhshandeh/ class=align-middle>Omid Bakhshandeh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nasrin-mostafazadeh/ class=align-middle>Nasrin Mostafazadeh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/m/michael-roth/ class=align-middle>Michael Roth</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/annie-louis/ class=align-middle>Annie Louis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nathanael-chambers/ class=align-middle>Nathanael Chambers</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/archna-bhatia/ class=align-middle>Archna Bhatia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mehdi-manshadi/ class=align-middle>Mehdi Manshadi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/daniel-gildea/ class=align-middle>Daniel Gildea</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/cl/ class=align-middle>CL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>