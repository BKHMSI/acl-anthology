<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Josef van Genabith - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Josef</span> <span class=font-weight-bold>van Genabith</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.23/>Multi-Head Highly Parallelized LSTM Decoder for Neural Machine Translation<span class=acl-fixed-case>LSTM</span> Decoder for Neural Machine Translation</a></strong><br><a href=/people/h/hongfei-xu/>Hongfei Xu</a>
|
<a href=/people/q/qiuhui-liu/>Qiuhui Liu</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a>
|
<a href=/people/d/deyi-xiong/>Deyi Xiong</a>
|
<a href=/people/m/meng-zhang/>Meng Zhang</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--23><div class="card-body p-3 small">One of the reasons Transformer translation models are popular is that self-attention networks for <a href=https://en.wikipedia.org/wiki/Context_model>context modelling</a> can be easily parallelized at sequence level. However, the <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>computational complexity</a> of a self-attention network is O(n^2), increasing quadratically with sequence length. By contrast, the <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>complexity</a> of LSTM-based approaches is only O(n). In practice, however, LSTMs are much slower to train than self-attention networks as they can not be parallelized at sequence level : to model context, the current LSTM state relies on the full LSTM computation of the preceding state. This has to be computed n times for a sequence of length n. The <a href=https://en.wikipedia.org/wiki/Linear_map>linear transformations</a> involved in the LSTM gate and state computations are the major cost factors in this. To enable sequence-level parallelization of LSTMs, we approximate full LSTM context modelling by computing hidden states and gates with the current input and a simple bag-of-words representation of the preceding tokens context. This allows us to compute each input step efficiently in parallel, avoiding the formerly costly sequential linear transformations. We then connect the outputs of each parallel step with computationally cheap element-wise computations. We call this the Highly Parallelized LSTM. To further constrain the number of LSTM parameters, we compute several small HPLSTMs in parallel like multi-head attention in the Transformer. The experiments show that our MHPLSTM decoder achieves significant BLEU improvements, while being even slightly faster than the self-attention network in training, and much faster than the standard LSTM.<tex-math>O(n^2)</tex-math>, increasing quadratically with sequence length. By contrast, the complexity of LSTM-based approaches is only O(n). In practice, however, LSTMs are much slower to train than self-attention networks as they cannot be parallelized at sequence level: to model context, the current LSTM state relies on the full LSTM computation of the preceding state. This has to be computed n times for a sequence of length n. The linear transformations involved in the LSTM gate and state computations are the major cost factors in this. To enable sequence-level parallelization of LSTMs, we approximate full LSTM context modelling by computing hidden states and gates with the current input and a simple bag-of-words representation of the preceding tokens context. This allows us to compute each input step efficiently in parallel, avoiding the formerly costly sequential linear transformations. We then connect the outputs of each parallel step with computationally cheap element-wise computations. We call this the Highly Parallelized LSTM. To further constrain the number of LSTM parameters, we compute several small HPLSTMs in parallel like multi-head attention in the Transformer. The experiments show that our MHPLSTM decoder achieves significant BLEU improvements, while being even slightly faster than the self-attention network in training, and much faster than the standard LSTM.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.24.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--24 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.24 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.24/>A Bidirectional Transformer Based Alignment Model for Unsupervised Word Alignment</a></strong><br><a href=/people/j/jingyi-zhang/>Jingyi Zhang</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--24><div class="card-body p-3 small">Word alignment and <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> are two closely related <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. Neural translation models, such as RNN-based and Transformer models, employ a target-to-source attention mechanism which can provide rough word alignments, but with a rather low accuracy. High-quality <a href=https://en.wikipedia.org/wiki/Word_alignment>word alignment</a> can help <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a> in many different ways, such as missing word detection, annotation transfer and lexicon injection. Existing methods for learning <a href=https://en.wikipedia.org/wiki/Word_alignment>word alignment</a> include statistical word aligners (e.g. GIZA++) and recently neural word alignment models. This paper presents a bidirectional Transformer based alignment (BTBA) model for <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised learning</a> of the word alignment task. Our BTBA model predicts the current target word by attending the source context and both left-side and right-side target context to produce accurate target-to-source attention (alignment). We further fine-tune the target-to-source attention in the BTBA model to obtain better alignments using a full context based optimization method and self-supervised training. We test our method on three word alignment tasks and show that our method outperforms both previous neural word alignment approaches and the popular statistical word aligner GIZA++.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.527.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--527 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.527 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.527" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.527/>Mid-Air Hand Gestures for Post-Editing of Machine Translation</a></strong><br><a href=/people/r/rashad-albo-jamara/>Rashad Albo Jamara</a>
|
<a href=/people/n/nico-herbig/>Nico Herbig</a>
|
<a href=/people/a/antonio-kruger/>Antonio Krüger</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--527><div class="card-body p-3 small">To translate large volumes of text in a globally connected world, more and more translators are integrating <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation (MT)</a> and <a href=https://en.wikipedia.org/wiki/Post-editing>post-editing (PE)</a> into their translation workflows to generate publishable quality translations. While this process has been shown to save time and reduce errors, the task of <a href=https://en.wikipedia.org/wiki/Translation>translation</a> is changing from mostly text production from scratch to fixing errors within useful but partly incorrect MT output. This is affecting the interface design of <a href=https://en.wikipedia.org/wiki/Machine_translation>translation tools</a>, where better support for <a href=https://en.wikipedia.org/wiki/Text_editor>text editing tasks</a> is required. Here, we present the first study that investigates the usefulness of mid-air hand gestures in combination with the keyboard (GK) for text editing in PE of MT. Guided by a gesture elicitation study with 14 freelance translators, we develop a prototype supporting mid-air hand gestures for cursor placement, text selection, deletion, and reordering. These gestures combined with the <a href=https://en.wikipedia.org/wiki/Computer_keyboard>keyboard</a> facilitate all editing types required for PE. An evaluation of the <a href=https://en.wikipedia.org/wiki/Prototype>prototype</a> shows that the average editing duration of GK is only slightly slower than the standard mouse and keyboard (MK), even though participants are very familiar with the latter, and relative novices to the former. Furthermore, the <a href=https://en.wikipedia.org/wiki/Qualitative_research>qualitative analysis</a> shows positive attitudes towards <a href=https://en.wikipedia.org/wiki/List_of_gestures>hand gestures</a> for <a href=https://en.wikipedia.org/wiki/Physical_education>PE</a>, especially when manipulating <a href=https://en.wikipedia.org/wiki/Phrase>single words</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-short.46.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-short--46 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-short.46 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-short.46/>Modeling Task-Aware MIMO Cardinality for Efficient Multilingual Neural Machine Translation<span class=acl-fixed-case>MIMO</span> Cardinality for Efficient Multilingual Neural Machine Translation</a></strong><br><a href=/people/h/hongfei-xu/>Hongfei Xu</a>
|
<a href=/people/q/qiuhui-liu/>Qiuhui Liu</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a>
|
<a href=/people/d/deyi-xiong/>Deyi Xiong</a><br><a href=/volumes/2021.acl-short/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-short--46><div class="card-body p-3 small">Neural machine translation has achieved great success in <a href=https://en.wikipedia.org/wiki/Multilingualism>bilingual settings</a>, as well as in <a href=https://en.wikipedia.org/wiki/Multilingualism>multilingual settings</a>. With the increase of the number of languages, multilingual systems tend to underperform their bilingual counterparts. Model capacity has been found crucial for massively multilingual NMT to support language pairs with varying <a href=https://en.wikipedia.org/wiki/Linguistic_typology>typological characteristics</a>. Previous work increases the modeling capacity by deepening or widening the <a href=https://en.wikipedia.org/wiki/Transformer>Transformer</a>. However, modeling cardinality based on aggregating a set of transformations with the same <a href=https://en.wikipedia.org/wiki/Topological_space>topology</a> has been proven more effective than going deeper or wider when increasing <a href=https://en.wikipedia.org/wiki/Capacity_of_a_set>capacity</a>. In this paper, we propose to efficiently increase the capacity for multilingual NMT by increasing the <a href=https://en.wikipedia.org/wiki/Cardinality>cardinality</a>. Unlike previous work which feeds the same input to several transformations and merges their outputs into one, we present a Multi-Input-Multi-Output (MIMO) architecture that allows each transformation of the block to have its own input. We also present a task-aware attention mechanism to learn to selectively utilize individual transformations from a set of transformations for different translation directions. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> surpasses previous work and establishes a new <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> on the large scale OPUS-100 corpus while being 1.31 times as fast.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mmtlrl-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mmtlrl-1.0/>Proceedings of the First Workshop on Multimodal Machine Translation for Low Resource Languages (MMTLRL 2021)</a></strong><br><a href=/people/t/thoudam-doren-singh/>Thoudam Doren Singh</a>
|
<a href=/people/c/cristina-espana-i-bonet/>Cristina España i Bonet</a>
|
<a href=/people/s/sivaji-bandyopadhyay/>Sivaji Bandyopadhyay</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a><br><a href=/volumes/2021.mmtlrl-1/ class=text-muted>Proceedings of the First Workshop on Multimodal Machine Translation for Low Resource Languages (MMTLRL 2021)</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.38.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--38 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.38 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928681 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.38/>Lipschitz Constrained Parameter Initialization for Deep Transformers</a></strong><br><a href=/people/h/hongfei-xu/>Hongfei Xu</a>
|
<a href=/people/q/qiuhui-liu/>Qiuhui Liu</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a>
|
<a href=/people/d/deyi-xiong/>Deyi Xiong</a>
|
<a href=/people/j/jingyi-zhang/>Jingyi Zhang</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--38><div class="card-body p-3 small">The Transformer translation model employs residual connection and layer normalization to ease the optimization difficulties caused by its multi-layer encoder / decoder structure. Previous research shows that even with residual connection and layer normalization, deep Transformers still have difficulty in training, and particularly Transformer models with more than 12 encoder / decoder layers fail to converge. In this paper, we first empirically demonstrate that a simple modification made in the official implementation, which changes the computation order of residual connection and layer normalization, can significantly ease the optimization of deep Transformers. We then compare the subtle differences in computation order in considerable detail, and present a parameter initialization method that leverages the Lipschitz constraint on the initialization of Transformer parameters that effectively ensures training convergence. In contrast to findings in previous research we further demonstrate that with Lipschitz parameter initialization, deep Transformers with the original computation order can converge, and obtain significant BLEU improvements with up to 24 layers. In contrast to previous research which focuses on deep encoders, our approach additionally enables <a href=https://en.wikipedia.org/wiki/Transformers_(toy_line)>Transformers</a> to also benefit from deep decoders.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.37.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--37 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.37 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928587 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.37/>MMPE : A Multi-Modal Interface using Handwriting, Touch Reordering, and Speech Commands for Post-Editing Machine Translation<span class=acl-fixed-case>MMPE</span>: <span class=acl-fixed-case>A</span> <span class=acl-fixed-case>M</span>ulti-<span class=acl-fixed-case>M</span>odal <span class=acl-fixed-case>I</span>nterface using <span class=acl-fixed-case>H</span>andwriting, <span class=acl-fixed-case>T</span>ouch <span class=acl-fixed-case>R</span>eordering, and <span class=acl-fixed-case>S</span>peech <span class=acl-fixed-case>C</span>ommands for <span class=acl-fixed-case>P</span>ost-<span class=acl-fixed-case>E</span>diting <span class=acl-fixed-case>M</span>achine <span class=acl-fixed-case>T</span>ranslation</a></strong><br><a href=/people/n/nico-herbig/>Nico Herbig</a>
|
<a href=/people/s/santanu-pal/>Santanu Pal</a>
|
<a href=/people/t/tim-duwel/>Tim Düwel</a>
|
<a href=/people/k/kalliopi-meladaki/>Kalliopi Meladaki</a>
|
<a href=/people/m/mahsa-monshizadeh/>Mahsa Monshizadeh</a>
|
<a href=/people/v/vladislav-hnatovskiy/>Vladislav Hnatovskiy</a>
|
<a href=/people/a/antonio-kruger/>Antonio Krüger</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a><br><a href=/volumes/2020.acl-demos/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--37><div class="card-body p-3 small">The shift from traditional <a href=https://en.wikipedia.org/wiki/Translation>translation</a> to post-editing (PE) of machine-translated (MT) text can save time and reduce errors, but it also affects the design of <a href=https://en.wikipedia.org/wiki/Translation>translation interfaces</a>, as the task changes from mainly generating text to correcting errors within otherwise helpful translation proposals. Since this paradigm shift offers potential for modalities other than <a href=https://en.wikipedia.org/wiki/Computer_mouse>mouse</a> and <a href=https://en.wikipedia.org/wiki/Computer_keyboard>keyboard</a>, we present MMPE, the first prototype to combine traditional input modes with pen, touch, and speech modalities for PE of MT. Users can directly cross out or hand-write new text, drag and drop words for reordering, or use spoken commands to update the text in place. All text manipulations are logged in an easily interpretable format to simplify subsequent translation process research. The results of an evaluation with professional translators suggest that pen and touch interaction are suitable for deletion and reordering tasks, while speech and multi-modal combinations of select & speech are considered suitable for replacements and insertions. Overall, experiment participants were enthusiastic about the new modalities and saw them as useful extensions to mouse & keyboard, but not as a complete substitute.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.524.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--524 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.524 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.524/>The Transference Architecture for Automatic Post-Editing</a></strong><br><a href=/people/s/santanu-pal/>Santanu Pal</a>
|
<a href=/people/h/hongfei-xu/>Hongfei Xu</a>
|
<a href=/people/n/nico-herbig/>Nico Herbig</a>
|
<a href=/people/s/sudip-kumar-naskar/>Sudip Kumar Naskar</a>
|
<a href=/people/a/antonio-kruger/>Antonio Krüger</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--524><div class="card-body p-3 small">In automatic post-editing (APE) it makes sense to condition post-editing (pe) decisions on both the source (src) and the machine translated text (mt) as input. This has led to multi-encoder based neural APE approaches. A research challenge now is the search for architectures that best support the capture, preparation and provision of src and mt information and its integration with pe decisions. In this paper we present an efficient multi-encoder based APE model, called <a href=https://en.wikipedia.org/wiki/Transference>transference</a>. Unlike previous approaches, it (i) uses a transformer encoder block for src, (ii) followed by a decoder block, but without masking for self-attention on mt, which effectively acts as second encoder combining src mt, and (iii) feeds this representation into a final decoder block generating pe. Our model outperforms the best performing systems by 1 BLEU point on the WMT 2016, 2017, and 2018 EnglishGerman APE shared tasks (PBSMT and NMT). Furthermore, the results of our model on the WMT 2019 APE task using NMT data shows a comparable performance to the state-of-the-art system. The <a href=https://en.wikipedia.org/wiki/Time_complexity>inference time</a> of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is similar to the vanilla transformer-based NMT system although our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> deals with two separate encoders. We further investigate the importance of our newly introduced second encoder and find that a too small amount of <a href=https://en.wikipedia.org/wiki/Abstraction_layer>layers</a> does hurt the performance, while reducing the number of layers of the <a href=https://en.wikipedia.org/wiki/Code>decoder</a> does not matter much.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.532.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--532 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.532 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.532/>Understanding Translationese in Multi-view Embedding Spaces</a></strong><br><a href=/people/k/koel-dutta-chowdhury/>Koel Dutta Chowdhury</a>
|
<a href=/people/c/cristina-espana-bonet/>Cristina España-Bonet</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--532><div class="card-body p-3 small">Recent studies use a combination of lexical and syntactic features to show that footprints of the source language remain visible in translations, to the extent that it is possible to predict the original source language from the translation. In this paper, we focus on embedding-based semantic spaces, exploiting departures from isomorphism between spaces built from original target language and translations into this target language to predict relations between languages in an unsupervised way. We use different views of the data words, <a href=https://en.wikipedia.org/wiki/Part_of_speech>parts of speech</a>, semantic tags and synsets to track translationese. Our analysis shows that (i) semantic distances between original target language and translations into this target language can be detected using the notion of <a href=https://en.wikipedia.org/wiki/Isomorphism>isomorphism</a>, (ii) language family ties with characteristics similar to linguistically motivated phylogenetic trees can be inferred from the distances and (iii) with delexicalised embeddings exhibiting source-language interference most significantly, other levels of abstraction display the same tendency, indicating the lexicalised results to be not just due to possible topic differences between original and translated texts. To the best of our knowledge, this is the first time departures from isomorphism between embedding spaces are used to track <a href=https://en.wikipedia.org/wiki/Translation_(geometry)>translationese</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wmt-1.129.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--wmt-1--129 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.wmt-1.129 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939584 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.wmt-1.129/>UdS-DFKI@WMT20 : Unsupervised MT and Very Low Resource Supervised MT for German-Upper Sorbian<span class=acl-fixed-case>U</span>d<span class=acl-fixed-case>S</span>-<span class=acl-fixed-case>DFKI</span>@<span class=acl-fixed-case>WMT</span>20: Unsupervised <span class=acl-fixed-case>MT</span> and Very Low Resource Supervised <span class=acl-fixed-case>MT</span> for <span class=acl-fixed-case>G</span>erman-<span class=acl-fixed-case>U</span>pper <span class=acl-fixed-case>S</span>orbian</a></strong><br><a href=/people/s/sourav-dutta/>Sourav Dutta</a>
|
<a href=/people/j/jesujoba-alabi/>Jesujoba Alabi</a>
|
<a href=/people/s/saptarashmi-bandyopadhyay/>Saptarashmi Bandyopadhyay</a>
|
<a href=/people/d/dana-ruiter/>Dana Ruiter</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a><br><a href=/volumes/2020.wmt-1/ class=text-muted>Proceedings of the Fifth Conference on Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--wmt-1--129><div class="card-body p-3 small">This paper describes the UdS-DFKI submission to the shared task for unsupervised machine translation (MT) and very low-resource supervised MT between German (de) and Upper Sorbian (hsb) at the Fifth Conference of Machine Translation (WMT20). We submit <a href=https://en.wikipedia.org/wiki/System>systems</a> for both the supervised and unsupervised tracks. Apart from various experimental approaches like bitext mining, model pre-training, and iterative back-translation, we employ a factored machine translation approach on a small BPE vocabulary.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.407.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--407 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.407 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.407/>The European Language Technology Landscape in 2020 : Language-Centric and Human-Centric AI for Cross-Cultural Communication in Multilingual Europe<span class=acl-fixed-case>E</span>uropean Language Technology Landscape in 2020: Language-Centric and Human-Centric <span class=acl-fixed-case>AI</span> for Cross-Cultural Communication in Multilingual <span class=acl-fixed-case>E</span>urope</a></strong><br><a href=/people/g/georg-rehm/>Georg Rehm</a>
|
<a href=/people/k/katrin-marheinecke/>Katrin Marheinecke</a>
|
<a href=/people/s/stefanie-hegele/>Stefanie Hegele</a>
|
<a href=/people/s/stelios-piperidis/>Stelios Piperidis</a>
|
<a href=/people/k/kalina-bontcheva/>Kalina Bontcheva</a>
|
<a href=/people/j/jan-hajic/>Jan Hajič</a>
|
<a href=/people/k/khalid-choukri/>Khalid Choukri</a>
|
<a href=/people/a/andrejs-vasiljevs/>Andrejs Vasiļjevs</a>
|
<a href=/people/g/gerhard-backfried/>Gerhard Backfried</a>
|
<a href=/people/c/christoph-prinz/>Christoph Prinz</a>
|
<a href=/people/j/jose-manuel-gomez-perez/>José Manuel Gómez-Pérez</a>
|
<a href=/people/l/luc-meertens/>Luc Meertens</a>
|
<a href=/people/p/paul-lukowicz/>Paul Lukowicz</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a>
|
<a href=/people/a/andrea-losch/>Andrea Lösch</a>
|
<a href=/people/p/philipp-slusallek/>Philipp Slusallek</a>
|
<a href=/people/m/morten-irgens/>Morten Irgens</a>
|
<a href=/people/p/patrick-gatellier/>Patrick Gatellier</a>
|
<a href=/people/j/joachim-kohler/>Joachim Köhler</a>
|
<a href=/people/l/laure-le-bars/>Laure Le Bars</a>
|
<a href=/people/d/dimitra-anastasiou/>Dimitra Anastasiou</a>
|
<a href=/people/a/albina-auksoriute/>Albina Auksoriūtė</a>
|
<a href=/people/n/nuria-bel/>Núria Bel</a>
|
<a href=/people/a/antonio-branco/>António Branco</a>
|
<a href=/people/g/gerhard-budin/>Gerhard Budin</a>
|
<a href=/people/w/walter-daelemans/>Walter Daelemans</a>
|
<a href=/people/k/koenraad-de-smedt/>Koenraad De Smedt</a>
|
<a href=/people/r/radovan-garabik/>Radovan Garabík</a>
|
<a href=/people/m/maria-gavriilidou/>Maria Gavriilidou</a>
|
<a href=/people/d/dagmar-gromann/>Dagmar Gromann</a>
|
<a href=/people/s/svetla-koeva/>Svetla Koeva</a>
|
<a href=/people/s/simon-krek/>Simon Krek</a>
|
<a href=/people/c/cvetana-krstev/>Cvetana Krstev</a>
|
<a href=/people/k/krister-linden/>Krister Lindén</a>
|
<a href=/people/b/bernardo-magnini/>Bernardo Magnini</a>
|
<a href=/people/j/jan-odijk/>Jan Odijk</a>
|
<a href=/people/m/maciej-ogrodniczuk/>Maciej Ogrodniczuk</a>
|
<a href=/people/e/eirikur-rognvaldsson/>Eiríkur Rögnvaldsson</a>
|
<a href=/people/m/michael-rosner/>Mike Rosner</a>
|
<a href=/people/b/bolette-sandford-pedersen/>Bolette Pedersen</a>
|
<a href=/people/i/inguna-skadina/>Inguna Skadiņa</a>
|
<a href=/people/m/marko-tadic/>Marko Tadić</a>
|
<a href=/people/d/dan-tufis/>Dan Tufiș</a>
|
<a href=/people/t/tamas-varadi/>Tamás Váradi</a>
|
<a href=/people/k/kadri-vider/>Kadri Vider</a>
|
<a href=/people/a/andy-way/>Andy Way</a>
|
<a href=/people/f/francois-yvon/>François Yvon</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--407><div class="card-body p-3 small">Multilingualism is a cultural cornerstone of Europe and firmly anchored in the <a href=https://en.wikipedia.org/wiki/Treaties_of_the_European_Union>European treaties</a> including <a href=https://en.wikipedia.org/wiki/Linguistic_rights>full language equality</a>. However, <a href=https://en.wikipedia.org/wiki/Language_barrier>language barriers</a> impacting business, <a href=https://en.wikipedia.org/wiki/Cross-cultural_communication>cross-lingual and cross-cultural communication</a> are still omnipresent. Language Technologies (LTs) are a powerful means to break down these barriers. While the last decade has seen various initiatives that created a multitude of <a href=https://en.wikipedia.org/wiki/Software_development_process>approaches</a> and technologies tailored to Europe&#8217;s specific needs, there is still an immense level of fragmentation. At the same time, AI has become an increasingly important concept in the European Information and Communication Technology area. For a few years now, <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI</a> including many opportunities, synergies but also misconceptions has been overshadowing every other topic. We present an overview of the European LT landscape, describing funding programmes, activities, actions and challenges in the different countries with regard to LT, including the current state of play in industry and the LT market. We present a brief overview of the main LT-related activities on the EU level in the last ten years and develop strategic guidance with regard to four key dimensions.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6501.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-6501 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-6501 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6501/>Analysing Coreference in Transformer Outputs</a></strong><br><a href=/people/e/ekaterina-lapshinova-koltunski/>Ekaterina Lapshinova-Koltunski</a>
|
<a href=/people/c/cristina-espana-bonet/>Cristina España-Bonet</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a><br><a href=/volumes/D19-65/ class=text-muted>Proceedings of the Fourth Workshop on Discourse in Machine Translation (DiscoMT 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-6501><div class="card-body p-3 small">We analyse coreference phenomena in three neural machine translation systems trained with different data settings with or without access to explicit intra- and cross-sentential anaphoric information. We compare <a href=https://en.wikipedia.org/wiki/System>system</a> performance on two different <a href=https://en.wikipedia.org/wiki/Genre>genres</a> : <a href=https://en.wikipedia.org/wiki/News>news</a> and <a href=https://en.wikipedia.org/wiki/TED_(conference)>TED talks</a>. To do this, we manually annotate (the possibly incorrect) coreference chains in the MT outputs and evaluate the coreference chain translations. We define an error typology that aims to go further than pronoun translation adequacy and includes types such as incorrect word selection or missing words. The features of coreference chains in automatic translations are also compared to those of the source texts and <a href=https://en.wikipedia.org/wiki/Translation>human translations</a>. The analysis shows stronger potential translationese effects in machine translated outputs than in human translations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5417.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5417 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5417 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W19-5417.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W19-5417/>UdS Submission for the WMT 19 Automatic Post-Editing Task<span class=acl-fixed-case>U</span>d<span class=acl-fixed-case>S</span> Submission for the <span class=acl-fixed-case>WMT</span> 19 Automatic Post-Editing Task</a></strong><br><a href=/people/h/hongfei-xu/>Hongfei Xu</a>
|
<a href=/people/q/qiuhui-liu/>Qiuhui Liu</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a><br><a href=/volumes/W19-54/ class=text-muted>Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5417><div class="card-body p-3 small">In this paper, we describe our submission to the English-German APE shared task at WMT 2019. We utilize and adapt an NMT architecture originally developed for exploiting context information to <a href=https://en.wikipedia.org/wiki/Application_programming_interface>APE</a>, implement this in our own transformer model and explore joint training of the <a href=https://en.wikipedia.org/wiki/Application_programming_interface>APE task</a> with a de-noising encoder.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5430.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5430 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5430 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5430/>UDSDFKI Submission to the WMT2019 CzechPolish Similar Language Translation Shared Task<span class=acl-fixed-case>UDS</span>–<span class=acl-fixed-case>DFKI</span> Submission to the <span class=acl-fixed-case>WMT</span>2019 <span class=acl-fixed-case>C</span>zech–<span class=acl-fixed-case>P</span>olish Similar Language Translation Shared Task</a></strong><br><a href=/people/s/santanu-pal/>Santanu Pal</a>
|
<a href=/people/m/marcos-zampieri/>Marcos Zampieri</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a><br><a href=/volumes/W19-54/ class=text-muted>Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5430><div class="card-body p-3 small">In this paper we present the UDS-DFKI system submitted to the Similar Language Translation shared task at WMT 2019. The first edition of this shared task featured data from three pairs of similar languages : <a href=https://en.wikipedia.org/wiki/Czech_language>Czech</a> and <a href=https://en.wikipedia.org/wiki/Polish_language>Polish</a>, <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> and Nepali, and <a href=https://en.wikipedia.org/wiki/Portuguese_language>Portuguese</a> and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. Participants could choose to participate in any of these three tracks and submit system outputs in any translation direction. We report the results obtained by our <a href=https://en.wikipedia.org/wiki/System>system</a> in translating from <a href=https://en.wikipedia.org/wiki/Czech_language>Czech</a> to <a href=https://en.wikipedia.org/wiki/Polish_language>Polish</a> and comment on the impact of out-of-domain test data in the performance of our <a href=https://en.wikipedia.org/wiki/System>system</a>. UDS-DFKI achieved competitive performance ranking second among ten teams in <a href=https://en.wikipedia.org/wiki/Czech_language>Czech</a> to Polish translation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1178.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1178 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1178 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384515284 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1178" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1178/>Self-Supervised Neural Machine Translation</a></strong><br><a href=/people/d/dana-ruiter/>Dana Ruiter</a>
|
<a href=/people/c/cristina-espana-bonet/>Cristina España-Bonet</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1178><div class="card-body p-3 small">We present a simple new method where an emergent NMT system is used for simultaneously selecting training data and learning internal NMT representations. This is done in a self-supervised way without parallel data, in such a way that both tasks enhance each other during training. The method is language independent, introduces no additional hyper-parameters, and achieves BLEU scores of 29.21 (en2fr) and 27.36 (fr2en) on newstest2014 using English and French Wikipedia data for training.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3204.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3204 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3204 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3204/>Code-Mixed Question Answering Challenge : Crowd-sourcing Data and Techniques</a></strong><br><a href=/people/k/khyathi-chandu/>Khyathi Chandu</a>
|
<a href=/people/e/ekaterina-loginova/>Ekaterina Loginova</a>
|
<a href=/people/v/vishal-gupta/>Vishal Gupta</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a>
|
<a href=/people/g/gunter-neumann/>Günter Neumann</a>
|
<a href=/people/m/manoj-chinnakotla/>Manoj Chinnakotla</a>
|
<a href=/people/e/eric-nyberg/>Eric Nyberg</a>
|
<a href=/people/a/alan-w-black/>Alan W. Black</a><br><a href=/volumes/W18-32/ class=text-muted>Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3204><div class="card-body p-3 small">Code-Mixing (CM) is the phenomenon of alternating between two or more languages which is prevalent in bi- and multi-lingual communities. Most NLP applications today are still designed with the assumption of a single interaction language and are most likely to break given a CM utterance with multiple languages mixed at a morphological, phrase or sentence level. For example, popular commercial search engines do not yet fully understand the intents expressed in CM queries. As a first step towards fostering research which supports CM in NLP applications, we systematically crowd-sourced and curated an evaluation dataset for factoid question answering in three CM languages-Hinglish (Hindi+English), Tenglish (Telugu+English) and Tamlish (Tamil+English) which belong to two language families (Indo-Aryan and Dravidian). We share the details of our data collection process, techniques which were used to avoid inducing lexical bias amongst the crowd workers and other CM specific linguistic properties of the dataset. Our final dataset, which is available freely for research purposes, has 1,694 <a href=https://en.wikipedia.org/wiki/Hinglish>Hinglish</a>, 2,848 Tamlish and 1,391 Tenglish factoid questions and their answers. We discuss the <a href=https://en.wikipedia.org/wiki/List_of_art_media>techniques</a> used by the participants for the first edition of this ongoing challenge.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6468.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6468 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6468 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6468/>A Transformer-Based Multi-Source Automatic Post-Editing System</a></strong><br><a href=/people/s/santanu-pal/>Santanu Pal</a>
|
<a href=/people/n/nico-herbig/>Nico Herbig</a>
|
<a href=/people/a/antonio-kruger/>Antonio Krüger</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a><br><a href=/volumes/W18-64/ class=text-muted>Proceedings of the Third Conference on Machine Translation: Shared Task Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6468><div class="card-body p-3 small">This paper presents our EnglishGerman Automatic Post-Editing (APE) system submitted to the APE Task organized at WMT 2018 (Chatterjee et al., 2018). The proposed model is an extension of the transformer architecture : two separate self-attention-based encoders encode the machine translation output (mt) and the source (src), followed by a joint encoder that attends over a combination of these two encoded sequences (encsrc and encmt) for generating the post-edited sentence. We compare this multi-source architecture (i.e, <a href=https://en.wikipedia.org/wiki/Source_code>src</a>, mt pe) to a monolingual transformer (i.e., mt pe) model and an ensemble combining the multi-source src, mt pe and single-source mt pe models. For both the PBSMT and the NMT task, the <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble</a> yields the best results, followed by the multi-source model and last the single-source approach. Our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, the <a href=https://en.wikipedia.org/wiki/Ensemble_cast>ensemble</a>, achieves a BLEU score of 66.16 and 74.22 for the PBSMT and NMT task, respectively.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4410.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4410 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4410 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4410/>The Effect of <a href=https://en.wikipedia.org/wiki/Error_rate>Error Rate</a> in Artificially Generated Data for Automatic Preposition and Determiner Correction</a></strong><br><a href=/people/f/fraser-bowen/>Fraser Bowen</a>
|
<a href=/people/j/jon-dehdari/>Jon Dehdari</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a><br><a href=/volumes/W17-44/ class=text-muted>Proceedings of the 3rd Workshop on Noisy User-generated Text</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4410><div class="card-body p-3 small">In this research we investigate the impact of mismatches in the density and type of error between training and test data on a <a href=https://en.wikipedia.org/wiki/Nervous_system>neural system</a> correcting preposition and determiner errors. We use synthetically produced training data to control error density and type, and real error data for testing. Our results show it is possible to combine error types, although <a href=https://en.wikipedia.org/wiki/Preposition_and_postposition>prepositions</a> and <a href=https://en.wikipedia.org/wiki/Determiner>determiners</a> behave differently in terms of how much error should be artificially introduced into the training data in order to get the best results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5403.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5403 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5403 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-5403" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-5403/>Massively Multilingual Neural Grapheme-to-Phoneme Conversion</a></strong><br><a href=/people/b/ben-peters/>Ben Peters</a>
|
<a href=/people/j/jon-dehdari/>Jon Dehdari</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a><br><a href=/volumes/W17-54/ class=text-muted>Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5403><div class="card-body p-3 small">Grapheme-to-phoneme conversion (g2p) is necessary for text-to-speech and automatic speech recognition systems. Most g2p systems are monolingual : they require language-specific data or handcrafting of rules. Such systems are difficult to extend to low resource languages, for which data and handcrafted rules are not available. As an alternative, we present a neural sequence-to-sequence approach to g2p which is trained on spellingpronunciation pairs in hundreds of languages. The system shares a single encoder and decoder across all languages, allowing it to utilize the intrinsic similarities between different <a href=https://en.wikipedia.org/wiki/Writing_system>writing systems</a>. We show an 11 % improvement in phoneme error rate over an approach based on adapting high-resource monolingual g2p models to low-resource languages. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is also much more compact relative to previous <a href=https://en.wikipedia.org/wiki/Scientific_modelling>approaches</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2017.iwslt-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2017--iwslt-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2017.iwslt-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2017.iwslt-1.2/>Going beyond zero-shot MT : combining phonological, morphological and semantic factors. The UdS-DFKI System at IWSLT 2017<span class=acl-fixed-case>MT</span>: combining phonological, morphological and semantic factors. The <span class=acl-fixed-case>U</span>d<span class=acl-fixed-case>S</span>-<span class=acl-fixed-case>DFKI</span> System at <span class=acl-fixed-case>IWSLT</span> 2017</a></strong><br><a href=/people/c/cristina-espana-bonet/>Cristina España-Bonet</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a><br><a href=/volumes/2017.iwslt-1/ class=text-muted>Proceedings of the 14th International Conference on Spoken Language Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2017--iwslt-1--2><div class="card-body p-3 small">This paper describes the UdS-DFKI participation to the multilingual task of the IWSLT Evaluation 2017. Our approach is based on factored multilingual neural translation systems following the small data and zero-shot training conditions. Our systems are designed to fully exploit multilinguality by including factors that increase the number of common elements among languages such as phonetic coarse encodings and synsets, besides shallow part-of-speech tags, <a href=https://en.wikipedia.org/wiki/Word_stem>stems</a> and <a href=https://en.wikipedia.org/wiki/Lemma_(morphology)>lemmas</a>. Document level information is also considered by including the topic of every document. This approach improves a <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> without any additional factor for all the language pairs and even allows beyond-zero-shot translation. That is, the translation from unseen languages is possible thanks to the common elements especially <a href=https://en.wikipedia.org/wiki/Synonym>synsets</a> in our <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> among languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-1048.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-1048 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-1048 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-1048/>An Extensive Empirical Evaluation of Character-Based Morphological Tagging for 14 Languages</a></strong><br><a href=/people/g/georg-heigold/>Georg Heigold</a>
|
<a href=/people/g/gunter-neumann/>Guenter Neumann</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a><br><a href=/volumes/E17-1/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-1048><div class="card-body p-3 small">This paper investigates neural character-based morphological tagging for languages with complex morphology and large tag sets. Character-based approaches are attractive as they can handle rarely- and unseen words gracefully. We evaluate on 14 languages and observe consistent gains over a state-of-the-art morphological tagger across all languages except for <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/French_language>French</a>, where we match the state-of-the-art. We compare two architectures for computing character-based word vectors using <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent (RNN)</a> and <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional (CNN) nets</a>. We show that the CNN based approach performs slightly worse and less consistently than the RNN based approach. Small but systematic gains are observed when combining the two <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a> by <a href=https://en.wikipedia.org/wiki/Assembly_language>ensembling</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-3002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-3002 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-3002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-3002/>Common Round : Application of Language Technologies to Large-Scale Web Debates</a></strong><br><a href=/people/h/hans-uszkoreit/>Hans Uszkoreit</a>
|
<a href=/people/a/aleksandra-gabryszak/>Aleksandra Gabryszak</a>
|
<a href=/people/l/leonhard-hennig/>Leonhard Hennig</a>
|
<a href=/people/j/jorg-steffen/>Jörg Steffen</a>
|
<a href=/people/r/renlong-ai/>Renlong Ai</a>
|
<a href=/people/s/stephan-busemann/>Stephan Busemann</a>
|
<a href=/people/j/jon-dehdari/>Jon Dehdari</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a>
|
<a href=/people/g/georg-heigold/>Georg Heigold</a>
|
<a href=/people/n/nils-rethmeier/>Nils Rethmeier</a>
|
<a href=/people/r/raphael-rubino/>Raphael Rubino</a>
|
<a href=/people/s/sven-schmeier/>Sven Schmeier</a>
|
<a href=/people/p/philippe-thomas/>Philippe Thomas</a>
|
<a href=/people/h/he-wang/>He Wang</a>
|
<a href=/people/f/feiyu-xu/>Feiyu Xu</a><br><a href=/volumes/E17-3/ class=text-muted>Proceedings of the Software Demonstrations of the 15th Conference of the European Chapter of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-3002><div class="card-body p-3 small">Web debates play an important role in enabling broad participation of constituencies in social, political and economic decision-taking. However, it is challenging to organize, structure, and navigate a vast number of diverse argumentations and comments collected from many participants over a long time period. In this paper we demonstrate Common Round, a next generation platform for large-scale web debates, which provides functions for eliciting the semantic content and structures from the contributions of participants. In particular, Common Round applies <a href=https://en.wikipedia.org/wiki/Language_technology>language technologies</a> for the extraction of semantic essence from textual input, aggregation of the formulated opinions and arguments. The <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a> also provides a cross-lingual access to <a href=https://en.wikipedia.org/wiki/Debate>debates</a> using <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Josef+van+Genabith" title="Search for 'Josef van Genabith' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/h/hongfei-xu/ class=align-middle>Hongfei Xu</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/q/qiuhui-liu/ class=align-middle>Qiuhui Liu</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/n/nico-herbig/ class=align-middle>Nico Herbig</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/a/antonio-kruger/ class=align-middle>Antonio Krüger</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/s/santanu-pal/ class=align-middle>Santanu Pal</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/c/cristina-espana-bonet/ class=align-middle>Cristina España-Bonet</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/d/deyi-xiong/ class=align-middle>Deyi Xiong</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/jon-dehdari/ class=align-middle>Jon Dehdari</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/jingyi-zhang/ class=align-middle>Jingyi Zhang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/g/gunter-neumann/ class=align-middle>Günter Neumann</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/dana-ruiter/ class=align-middle>Dana Ruiter</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/g/georg-heigold/ class=align-middle>Georg Heigold</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/meng-zhang/ class=align-middle>Meng Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rashad-albo-jamara/ class=align-middle>Rashad Albo Jamara</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tim-duwel/ class=align-middle>Tim Düwel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kalliopi-meladaki/ class=align-middle>Kalliopi Meladaki</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mahsa-monshizadeh/ class=align-middle>Mahsa Monshizadeh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vladislav-hnatovskiy/ class=align-middle>Vladislav Hnatovskiy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fraser-bowen/ class=align-middle>Fraser Bowen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/ben-peters/ class=align-middle>Ben Peters</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/ekaterina-lapshinova-koltunski/ class=align-middle>Ekaterina Lapshinova-Koltunski</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/khyathi-chandu/ class=align-middle>Khyathi Chandu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/ekaterina-loginova/ class=align-middle>Ekaterina Loginova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vishal-gupta/ class=align-middle>Vishal Gupta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/manoj-chinnakotla/ class=align-middle>Manoj Chinnakotla</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eric-nyberg/ class=align-middle>Eric Nyberg</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alan-w-black/ class=align-middle>Alan W. Black</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marcos-zampieri/ class=align-middle>Marcos Zampieri</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sudip-kumar-naskar/ class=align-middle>Sudip Kumar Naskar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/koel-dutta-chowdhury/ class=align-middle>Koel Dutta Chowdhury</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thoudam-doren-singh/ class=align-middle>Thoudam Doren Singh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cristina-espana-i-bonet/ class=align-middle>Cristina España i Bonet</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sivaji-bandyopadhyay/ class=align-middle>Sivaji Bandyopadhyay</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sourav-dutta/ class=align-middle>Sourav Dutta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jesujoba-alabi/ class=align-middle>Jesujoba Alabi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/saptarashmi-bandyopadhyay/ class=align-middle>Saptarashmi Bandyopadhyay</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/georg-rehm/ class=align-middle>Georg Rehm</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/katrin-marheinecke/ class=align-middle>Katrin Marheinecke</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stefanie-hegele/ class=align-middle>Stefanie Hegele</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stelios-piperidis/ class=align-middle>Stelios Piperidis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kalina-bontcheva/ class=align-middle>Kalina Bontcheva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jan-hajic/ class=align-middle>Jan Hajic</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/khalid-choukri/ class=align-middle>Khalid Choukri</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrejs-vasiljevs/ class=align-middle>Andrejs Vasiļjevs</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gerhard-backfried/ class=align-middle>Gerhard Backfried</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christoph-prinz/ class=align-middle>Christoph Prinz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jose-manuel-gomez-perez/ class=align-middle>José Manuel Gómez-Pérez</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luc-meertens/ class=align-middle>Luc Meertens</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paul-lukowicz/ class=align-middle>Paul Lukowicz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrea-losch/ class=align-middle>Andrea Lösch</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/philipp-slusallek/ class=align-middle>Philipp Slusallek</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/morten-irgens/ class=align-middle>Morten Irgens</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/patrick-gatellier/ class=align-middle>Patrick Gatellier</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joachim-kohler/ class=align-middle>Joachim Köhler</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/laure-le-bars/ class=align-middle>Laure Le Bars</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dimitra-anastasiou/ class=align-middle>Dimitra Anastasiou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/albina-auksoriute/ class=align-middle>Albina Auksoriūtė</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nuria-bel/ class=align-middle>Núria Bel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/antonio-branco/ class=align-middle>António Branco</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gerhard-budin/ class=align-middle>Gerhard Budin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/walter-daelemans/ class=align-middle>Walter Daelemans</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/koenraad-de-smedt/ class=align-middle>Koenraad De Smedt</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/radovan-garabik/ class=align-middle>Radovan Garabík</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maria-gavriilidou/ class=align-middle>Maria Gavriilidou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dagmar-gromann/ class=align-middle>Dagmar Gromann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/svetla-koeva/ class=align-middle>Svetla Koeva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/simon-krek/ class=align-middle>Simon Krek</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cvetana-krstev/ class=align-middle>Cvetana Krstev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/krister-linden/ class=align-middle>Krister Lindén</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bernardo-magnini/ class=align-middle>Bernardo Magnini</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jan-odijk/ class=align-middle>Jan Odijk</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maciej-ogrodniczuk/ class=align-middle>Maciej Ogrodniczuk</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eirikur-rognvaldsson/ class=align-middle>Eirikur Rögnvaldsson</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-rosner/ class=align-middle>Michael Rosner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bolette-sandford-pedersen/ class=align-middle>Bolette Sandford Pedersen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/inguna-skadina/ class=align-middle>Inguna Skadiņa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marko-tadic/ class=align-middle>Marko Tadić</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dan-tufis/ class=align-middle>Dan Tufiş</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tamas-varadi/ class=align-middle>Tamás Váradi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kadri-vider/ class=align-middle>Kadri Vider</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andy-way/ class=align-middle>Andy Way</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/francois-yvon/ class=align-middle>François Yvon</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hans-uszkoreit/ class=align-middle>Hans Uszkoreit</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aleksandra-gabryszak/ class=align-middle>Aleksandra Gabryszak</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/leonhard-hennig/ class=align-middle>Leonhard Hennig</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jorg-steffen/ class=align-middle>Jörg Steffen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/renlong-ai/ class=align-middle>Renlong Ai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stephan-busemann/ class=align-middle>Stephan Busemann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nils-rethmeier/ class=align-middle>Nils Rethmeier</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/raphael-rubino/ class=align-middle>Raphael Rubino</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sven-schmeier/ class=align-middle>Sven Schmeier</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/philippe-thomas/ class=align-middle>Philippe Thomas</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/he-wang/ class=align-middle>He Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/feiyu-xu/ class=align-middle>Feiyu Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/iwslt/ class=align-middle>IWSLT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/mmtlrl/ class=align-middle>MMTLRL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wmt/ class=align-middle>WMT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>