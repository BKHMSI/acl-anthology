<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Jonathan May - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Jonathan</span> <span class=font-weight-bold>May</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.254.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--254 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.254 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.254" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.254/>CaSiNo : A Corpus of Campsite Negotiation Dialogues for Automatic Negotiation Systems<span class=acl-fixed-case>C</span>a<span class=acl-fixed-case>S</span>i<span class=acl-fixed-case>N</span>o: A Corpus of Campsite Negotiation Dialogues for Automatic Negotiation Systems</a></strong><br><a href=/people/k/kushal-chawla/>Kushal Chawla</a>
|
<a href=/people/j/jaysa-ramirez/>Jaysa Ramirez</a>
|
<a href=/people/r/rene-clever/>Rene Clever</a>
|
<a href=/people/g/gale-lucas/>Gale Lucas</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/j/jonathan-gratch/>Jonathan Gratch</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--254><div class="card-body p-3 small">Automated systems that negotiate with humans have broad applications in <a href=https://en.wikipedia.org/wiki/Pedagogy>pedagogy</a> and conversational AI. To advance the development of practical <a href=https://en.wikipedia.org/wiki/Negotiation>negotiation systems</a>, we present CaSiNo : a novel <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of over a thousand <a href=https://en.wikipedia.org/wiki/Negotiation>negotiation dialogues</a> in English. Participants take the role of campsite neighbors and negotiate for food, water, and firewood packages for their upcoming trip. Our design results in diverse and linguistically rich negotiations while maintaining a tractable, closed-domain environment. Inspired by the literature in human-human negotiations, we annotate <a href=https://en.wikipedia.org/wiki/Persuasion>persuasion strategies</a> and perform <a href=https://en.wikipedia.org/wiki/Correlation_and_dependence>correlation analysis</a> to understand how the dialogue behaviors are associated with the <a href=https://en.wikipedia.org/wiki/Negotiation>negotiation</a> performance. We further propose and evaluate a multi-task framework to recognize these <a href=https://en.wikipedia.org/wiki/Strategy>strategies</a> in a given utterance. We find that <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a> substantially improves the performance for all strategy labels, especially for the ones that are the most skewed. We release the dataset, annotations, and the code to propel future work in human-machine negotiations : https://github.com/kushalchawla/CaSiNo</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.283.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--283 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.283 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.283" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.283/>X-METRA-ADA : Cross-lingual Meta-Transfer learning Adaptation to <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>Natural Language Understanding</a> and Question Answering<span class=acl-fixed-case>X</span>-<span class=acl-fixed-case>METRA</span>-<span class=acl-fixed-case>ADA</span>: Cross-lingual Meta-Transfer learning Adaptation to Natural Language Understanding and Question Answering</a></strong><br><a href=/people/m/meryem-mhamdi/>Meryem Mâ€™hamdi</a>
|
<a href=/people/d/doo-soon-kim/>Doo Soon Kim</a>
|
<a href=/people/f/franck-dernoncourt/>Franck Dernoncourt</a>
|
<a href=/people/t/trung-bui/>Trung Bui</a>
|
<a href=/people/x/xiang-ren/>Xiang Ren</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--283><div class="card-body p-3 small">Multilingual models, such as M-BERT and XLM-R, have gained increasing popularity, due to their zero-shot cross-lingual transfer learning capabilities. However, their <a href=https://en.wikipedia.org/wiki/Generalization>generalization ability</a> is still inconsistent for <a href=https://en.wikipedia.org/wiki/Linguistic_typology>typologically diverse languages</a> and across different benchmarks. Recently, <a href=https://en.wikipedia.org/wiki/Meta-learning>meta-learning</a> has garnered attention as a promising technique for enhancing <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> under low-resource scenarios : particularly for cross-lingual transfer in Natural Language Understanding (NLU). In this work, we propose X-METRA-ADA, a cross-lingual MEta-TRAnsfer learning ADAptation approach for NLU. Our approach adapts MAML, an optimization-based meta-learning approach, to learn to adapt to new languages. We extensively evaluate our framework on two challenging cross-lingual NLU tasks : multilingual task-oriented dialog and typologically diverse question answering. We show that our approach outperforms naive fine-tuning, reaching competitive performance on both tasks for most languages. Our analysis reveals that X-METRA-ADA can leverage limited data for faster adaptation.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.50.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--50 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.50 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938669 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.50/>Connecting the Dots : Event Graph Schema Induction with Path Language Modeling</a></strong><br><a href=/people/m/manling-li/>Manling Li</a>
|
<a href=/people/q/qi-zeng/>Qi Zeng</a>
|
<a href=/people/y/ying-lin/>Ying Lin</a>
|
<a href=/people/k/kyunghyun-cho/>Kyunghyun Cho</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/n/nathanael-chambers/>Nathanael Chambers</a>
|
<a href=/people/c/clare-voss/>Clare Voss</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--50><div class="card-body p-3 small">Event schemas can guide our understanding and ability to make predictions with respect to what might happen next. We propose a new Event Graph Schema, where two event types are connected through multiple paths involving entities that fill important roles in a coherent story. We then introduce Path Language Model, an auto-regressive language model trained on event-event paths, and select salient and coherent paths to probabilistically construct these graph schemas. We design two evaluation metrics, instance coverage and instance coherence, to evaluate the quality of graph schema induction, by checking when coherent event instances are covered by the schema graph. Intrinsic evaluations show that our approach is highly effective at inducing salient and coherent schemas. Extrinsic evaluations show the induced schema repository provides significant improvement to downstream end-to-end Information Extraction over a state-of-the-art joint neural extraction model, when used as additional global features to unfold instance graphs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.semeval-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.semeval-1.0/>Proceedings of the Fourteenth Workshop on Semantic Evaluation</a></strong><br><a href=/people/a/aurelie-herbelot/>Aurelie Herbelot</a>
|
<a href=/people/x/xiaodan-zhu/>Xiaodan Zhu</a>
|
<a href=/people/a/alexis-palmer/>Alexis Palmer</a>
|
<a href=/people/n/nathan-schneider/>Nathan Schneider</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a><br><a href=/volumes/2020.semeval-1/ class=text-muted>Proceedings of the Fourteenth Workshop on Semantic Evaluation</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.352.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--352 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.352 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.findings-emnlp.352.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.findings-emnlp.352" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.352/>Finding the Optimal Vocabulary Size for <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a></a></strong><br><a href=/people/t/thamme-gowda/>Thamme Gowda</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--352><div class="card-body p-3 small">We cast neural machine translation (NMT) as a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification task</a> in an autoregressive setting and analyze the limitations of both <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> and autoregression components. Classifiers are known to perform better with balanced class distributions during training. Since the Zipfian nature of languages causes imbalanced classes, we explore its effect on NMT. We analyze the effect of various <a href=https://en.wikipedia.org/wiki/Vocabulary_size>vocabulary sizes</a> on <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NMT</a> performance on multiple languages with many data sizes, and reveal an explanation for why certain <a href=https://en.wikipedia.org/wiki/Vocabulary_size>vocabulary sizes</a> are better than others.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpcovid19-acl.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nlpcovid19-acl.0/>Proceedings of the 1st Workshop on <span class=acl-fixed-case>NLP</span> for <span class=acl-fixed-case>COVID-19</span> at <span class=acl-fixed-case>ACL</span> 2020</a></strong><br><a href=/people/k/karin-verspoor/>Karin Verspoor</a>
|
<a href=/people/k/k-bretonnel-cohen/>Kevin Bretonnel Cohen</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a>
|
<a href=/people/e/emilio-ferrara/>Emilio Ferrara</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/r/robert-munro/>Robert Munro</a>
|
<a href=/people/c/cecile-paris/>Cecile Paris</a>
|
<a href=/people/b/byron-c-wallace/>Byron Wallace</a><br><a href=/volumes/2020.nlpcovid19-acl/ class=text-muted>Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1030.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1030 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1030 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1030/>Cross-lingual Structure Transfer for Relation and Event Extraction</a></strong><br><a href=/people/a/ananya-subburathinam/>Ananya Subburathinam</a>
|
<a href=/people/d/di-lu/>Di Lu</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/s/shih-fu-chang/>Shih-Fu Chang</a>
|
<a href=/people/a/avirup-sil/>Avirup Sil</a>
|
<a href=/people/c/clare-voss/>Clare Voss</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1030><div class="card-body p-3 small">The identification of complex semantic structures such as <a href=https://en.wikipedia.org/wiki/Event_(philosophy)>events</a> and <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity relations</a>, already a challenging Information Extraction task, is doubly difficult from sources written in under-resourced and under-annotated languages. We investigate the suitability of cross-lingual structure transfer techniques for these <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. We exploit relation- and event-relevant language-universal features, leveraging both symbolic (including part-of-speech and dependency path) and distributional (including type representation and contextualized representation) information. By representing all entity mentions, event triggers, and contexts into this complex and structured multilingual common space, using graph convolutional networks, we can train a relation or event extractor from source language annotations and apply it to the target language. Extensive experiments on cross-lingual relation and event transfer among <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, and <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a> demonstrate that our approach achieves performance comparable to state-of-the-art <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised models</a> trained on up to 3,000 manually annotated mentions : up to 62.6 % F-score for Relation Extraction, and 63.1 % F-score for Event Argument Role Labeling. The event argument role labeling model transferred from <a href=https://en.wikipedia.org/wiki/English_language>English</a> to <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a> achieves similar performance as the model trained from <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>. We thus find that language-universal symbolic and distributional representations are complementary for cross-lingual structure transfer.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1672.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1672 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1672 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1672/>What Matters for Neural Cross-Lingual Named Entity Recognition : An Empirical Analysis</a></strong><br><a href=/people/x/xiaolei-huang/>Xiaolei Huang</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1672><div class="card-body p-3 small">Building named entity recognition (NER) models for languages that do not have much training data is a challenging task. While recent work has shown promising results on cross-lingual transfer from high-resource languages, it is unclear what knowledge is transferred. In this paper, we first propose a simple and efficient neural architecture for cross-lingual NER. Experiments show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves competitive performance with the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a>. We further explore how <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> works for cross-lingual NER on two transferable factors : sequential order and multilingual embedding. Our results shed light on future research for improving cross-lingual NER.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-2000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-2000/>Proceedings of the 13th International Workshop on Semantic Evaluation</a></strong><br><a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a>
|
<a href=/people/a/aurelie-herbelot/>Aurelie Herbelot</a>
|
<a href=/people/x/xiaodan-zhu/>Xiaodan Zhu</a>
|
<a href=/people/m/marianna-apidianaki/>Marianna Apidianaki</a>
|
<a href=/people/s/saif-mohammad/>Saif M. Mohammad</a><br><a href=/volumes/S19-2/ class=text-muted>Proceedings of the 13th International Workshop on Semantic Evaluation</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1252.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1252 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1252 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1252" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N19-1252/>A Grounded Unsupervised Universal Part-of-Speech Tagger for Low-Resource Languages</a></strong><br><a href=/people/r/ronald-cardenas/>Ronald Cardenas</a>
|
<a href=/people/y/ying-lin/>Ying Lin</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1252><div class="card-body p-3 small">Unsupervised part of speech (POS) tagging is often framed as a clustering problem, but practical taggers need to ground their clusters as well. Grounding generally requires reference labeled data, a luxury a low-resource language might not have. In this work, we describe an approach for low-resource unsupervised POS tagging that yields fully grounded output and requires no labeled training data. We find the classic <a href=https://en.wikipedia.org/wiki/Scientific_method>method</a> of Brown et al. (1992) clusters well in our use case and employ a decipherment-based approach to grounding. This approach presumes a sequence of cluster IDs is a &#8216;ciphertext&#8217; and seeks a POS tag-to-cluster ID mapping that will reveal the POS sequence. We show intrinsically that, despite the difficulty of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, we obtain reasonable performance across a variety of languages. We also show extrinsically that incorporating our <a href=https://en.wikipedia.org/wiki/POS_tagger>POS tagger</a> into a name tagger leads to state-of-the-art tagging performance in <a href=https://en.wikipedia.org/wiki/Sinhala_language>Sinhalese</a> and <a href=https://en.wikipedia.org/wiki/Kinyarwanda>Kinyarwanda</a>, two languages with nearly no labeled POS data available. We further demonstrate our tagger&#8217;s utility by incorporating it into a true &#8216;zero-resource&#8217; variant of the MALOPA (Ammar et al., 2016) dependency parser model that removes the current reliance on multilingual resources and gold POS tags for new languages. Experiments show that including our <a href=https://en.wikipedia.org/wiki/Tagger>tagger</a> makes up much of the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> lost when gold POS tags are unavailable.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-3004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-3004 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-3004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-3004/>SARAL : A Low-Resource Cross-Lingual Domain-Focused Information Retrieval System for Effective Rapid Document Triage<span class=acl-fixed-case>SARAL</span>: A Low-Resource Cross-Lingual Domain-Focused Information Retrieval System for Effective Rapid Document Triage</a></strong><br><a href=/people/e/elizabeth-boschee/>Elizabeth Boschee</a>
|
<a href=/people/j/joel-barry/>Joel Barry</a>
|
<a href=/people/j/jayadev-billa/>Jayadev Billa</a>
|
<a href=/people/m/marjorie-freedman/>Marjorie Freedman</a>
|
<a href=/people/t/thamme-gowda/>Thamme Gowda</a>
|
<a href=/people/c/constantine-lignos/>Constantine Lignos</a>
|
<a href=/people/c/chester-palen-michel/>Chester Palen-Michel</a>
|
<a href=/people/m/michael-pust/>Michael Pust</a>
|
<a href=/people/b/banriskhem-kayang-khonglah/>Banriskhem Kayang Khonglah</a>
|
<a href=/people/s/srikanth-madikeri/>Srikanth Madikeri</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/s/scott-miller/>Scott Miller</a><br><a href=/volumes/P19-3/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-3004><div class="card-body p-3 small">With the increasing democratization of <a href=https://en.wikipedia.org/wiki/Electronic_media>electronic media</a>, vast information resources are available in less-frequently-taught languages such as <a href=https://en.wikipedia.org/wiki/Swahili_language>Swahili</a> or <a href=https://en.wikipedia.org/wiki/Somali_language>Somali</a>. That information, which may be crucially important and not available elsewhere, can be difficult for monolingual English speakers to effectively access. In this paper we present an end-to-end cross-lingual information retrieval (CLIR) and summarization system for low-resource languages that 1) enables English speakers to search foreign language repositories of text and audio using English queries, 2) summarizes the retrieved documents in English with respect to a particular information need, and 3) provides complete transcriptions and translations as needed. The SARAL system achieved the top end-to-end performance in the most recent IARPA MATERIAL CLIR+summarization evaluations. Our demonstration system provides end-to-end open query retrieval and summarization capability, and presents the original source text or audio, <a href=https://en.wikipedia.org/wiki/Transcription_(linguistics)>speech transcription</a>, and <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, for two low resource languages.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1000/>Proceedings of The 12th International Workshop on Semantic Evaluation</a></strong><br><a href=/people/m/marianna-apidianaki/>Marianna Apidianaki</a>
|
<a href=/people/s/saif-mohammad/>Saif M. Mohammad</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a>
|
<a href=/people/s/steven-bethard/>Steven Bethard</a>
|
<a href=/people/m/marine-carpuat/>Marine Carpuat</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-1505.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-1505 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-1505 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-1505/>Towards Controllable Story Generation</a></strong><br><a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/m/marjan-ghazvininejad/>Marjan Ghazvininejad</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/k/kevin-knight/>Kevin Knight</a><br><a href=/volumes/W18-15/ class=text-muted>Proceedings of the First Workshop on Storytelling</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-1505><div class="card-body p-3 small">We present a general <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> of analyzing existing story corpora to generate controllable and creative new stories. The proposed <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> needs little manual annotation to achieve controllable story generation. It creates a new interface for humans to interact with computers to generate personalized stories. We apply the framework to build recurrent neural network (RNN)-based generation models to control story ending valence and <a href=https://en.wikipedia.org/wiki/Plot_(narrative)>storyline</a>. Experiments show that our methods successfully achieve the control and enhance the coherence of stories through introducing <a href=https://en.wikipedia.org/wiki/Plot_(narrative)>storylines</a>. with additional control factors, the generation model gets lower perplexity, and yields more coherent stories that are faithful to the control factors according to human evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-5009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-5009 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-5009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-5009/>ELISA-EDL : A Cross-lingual Entity Extraction, Linking and Localization System<span class=acl-fixed-case>ELISA</span>-<span class=acl-fixed-case>EDL</span>: A Cross-lingual Entity Extraction, Linking and Localization System</a></strong><br><a href=/people/b/boliang-zhang/>Boliang Zhang</a>
|
<a href=/people/y/ying-lin/>Ying Lin</a>
|
<a href=/people/x/xiaoman-pan/>Xiaoman Pan</a>
|
<a href=/people/d/di-lu/>Di Lu</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/k/kevin-knight/>Kevin Knight</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a><br><a href=/volumes/N18-5/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-5009><div class="card-body p-3 small">We demonstrate ELISA-EDL, a state-of-the-art re-trainable system to extract entity mentions from low-resource languages, link them to external English knowledge bases, and visualize locations related to disaster topics on a world heatmap. We make all of our data sets, resources and system training and testing APIs publicly available for research purpose.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1178.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1178 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1178 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P17-1178/>Cross-lingual Name Tagging and Linking for 282 Languages</a></strong><br><a href=/people/x/xiaoman-pan/>Xiaoman Pan</a>
|
<a href=/people/b/boliang-zhang/>Boliang Zhang</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/j/joel-nothman/>Joel Nothman</a>
|
<a href=/people/k/kevin-knight/>Kevin Knight</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1178><div class="card-body p-3 small">The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework for 282 languages that exist in <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>. Given a document in any of these languages, our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> is able to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of new KB mining methods : generating silver-standard annotations by transferring annotations from English to other languages through cross-lingual links and KB properties, refining annotations through self-training and topic selection, deriving language-specific morphology features from anchor links, and mining word translation pairs from cross-lingual links. Both name tagging and linking results for 282 languages are promising on Wikipedia data and on-Wikipedia data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2090.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2090 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2090 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2090/>SemEval-2017 Task 9 : Abstract Meaning Representation Parsing and Generation<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 9: <span class=acl-fixed-case>A</span>bstract <span class=acl-fixed-case>M</span>eaning <span class=acl-fixed-case>R</span>epresentation Parsing and Generation</a></strong><br><a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/j/jay-priyadarshi/>Jay Priyadarshi</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2090><div class="card-body p-3 small">In this report we summarize the results of the 2017 AMR SemEval shared task. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> consisted of two separate yet related <a href=https://en.wikipedia.org/wiki/Task_(project_management)>subtasks</a>. In the parsing subtask, participants were asked to produce Abstract Meaning Representation (AMR) (Banarescu et al., 2013) graphs for a set of English sentences in the biomedical domain. In the generation subtask, participants were asked to generate <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>English sentences</a> given AMR graphs in the <a href=https://en.wikipedia.org/wiki/Internet_forum>news / forum domain</a>. A total of five sites participated in the parsing subtask, and four participated in the generation subtask. Along with a description of the task and the participants&#8217; systems, we show various score ablations and some sample outputs.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Jonathan+May" title="Search for 'Jonathan May' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/h/heng-ji/ class=align-middle>Heng Ji</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/y/ying-lin/ class=align-middle>Ying Lin</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/k/kevin-knight/ class=align-middle>Kevin Knight</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/e/ekaterina-shutova/ class=align-middle>Ekaterina Shutova</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/c/clare-voss/ class=align-middle>Clare Voss</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/x/xiaoman-pan/ class=align-middle>Xiaoman Pan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/boliang-zhang/ class=align-middle>Boliang Zhang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/aurelie-herbelot/ class=align-middle>AurÃ©lie Herbelot</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/x/xiaodan-zhu/ class=align-middle>Xiaodan Zhu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/di-lu/ class=align-middle>Di Lu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/n/nanyun-peng/ class=align-middle>Nanyun Peng</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/marianna-apidianaki/ class=align-middle>Marianna Apidianaki</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/saif-mohammad/ class=align-middle>Saif Mohammad</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/thamme-gowda/ class=align-middle>Thamme Gowda</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/manling-li/ class=align-middle>Manling Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qi-zeng/ class=align-middle>Qi Zeng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kyunghyun-cho/ class=align-middle>Kyunghyun Cho</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nathanael-chambers/ class=align-middle>Nathanael Chambers</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joel-nothman/ class=align-middle>Joel Nothman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexis-palmer/ class=align-middle>Alexis Palmer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nathan-schneider/ class=align-middle>Nathan Schneider</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ananya-subburathinam/ class=align-middle>Ananya Subburathinam</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shih-fu-chang/ class=align-middle>Shih-Fu Chang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/avirup-sil/ class=align-middle>Avirup Sil</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaolei-huang/ class=align-middle>Xiaolei Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jay-priyadarshi/ class=align-middle>Jay Priyadarshi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kushal-chawla/ class=align-middle>Kushal Chawla</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jaysa-ramirez/ class=align-middle>Jaysa Ramirez</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rene-clever/ class=align-middle>Rene Clever</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gale-lucas/ class=align-middle>Gale Lucas</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jonathan-gratch/ class=align-middle>Jonathan Gratch</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/meryem-mhamdi/ class=align-middle>Meryem Mâ€™hamdi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/doo-soon-kim/ class=align-middle>Doo Soon Kim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/franck-dernoncourt/ class=align-middle>Franck Dernoncourt</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/trung-bui/ class=align-middle>Trung Bui</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiang-ren/ class=align-middle>Xiang Ren</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/steven-bethard/ class=align-middle>Steven Bethard</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marine-carpuat/ class=align-middle>Marine Carpuat</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marjan-ghazvininejad/ class=align-middle>Marjan Ghazvininejad</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ronald-cardenas/ class=align-middle>Ronald Cardenas</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/karin-verspoor/ class=align-middle>Karin Verspoor</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/k-bretonnel-cohen/ class=align-middle>K. Bretonnel Cohen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mark-dredze/ class=align-middle>Mark Dredze</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/emilio-ferrara/ class=align-middle>Emilio Ferrara</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/robert-munro/ class=align-middle>Robert Munro</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cecile-paris/ class=align-middle>Cecile Paris</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/byron-c-wallace/ class=align-middle>Byron C. Wallace</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elizabeth-boschee/ class=align-middle>Elizabeth Boschee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joel-barry/ class=align-middle>Joel Barry</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jayadev-billa/ class=align-middle>Jayadev Billa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marjorie-freedman/ class=align-middle>Marjorie Freedman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/constantine-lignos/ class=align-middle>Constantine Lignos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chester-palen-michel/ class=align-middle>Chester Palen-Michel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-pust/ class=align-middle>Michael Pust</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/banriskhem-kayang-khonglah/ class=align-middle>Banriskhem Kayang Khonglah</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/srikanth-madikeri/ class=align-middle>Srikanth Madikeri</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/scott-miller/ class=align-middle>Scott Miller</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/nlpcovid19/ class=align-middle>NLP-COVID19</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>