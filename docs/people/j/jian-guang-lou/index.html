<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Jian-Guang Lou - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Jian-Guang</span> <span class=font-weight-bold>Lou</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.78.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--78 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.78 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2022.acl-long.78.software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.acl-long.78" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.78/>HiTab A Hierarchical Table Dataset for <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a> and Natural Language Generation<span class=acl-fixed-case>H</span>i<span class=acl-fixed-case>T</span>ab: A Hierarchical Table Dataset for Question Answering and Natural Language Generation</a></strong><br><a href=/people/z/zhoujun-cheng/>Zhoujun Cheng</a>
|
<a href=/people/h/haoyu-dong/>Haoyu Dong</a>
|
<a href=/people/z/zhiruo-wang/>Zhiruo Wang</a>
|
<a href=/people/r/ran-jia/>Ran Jia</a>
|
<a href=/people/j/jiaqi-guo/>Jiaqi Guo</a>
|
<a href=/people/y/yan-gao/>Yan Gao</a>
|
<a href=/people/s/shi-han/>Shi Han</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/d/dongmei-zhang/>Dongmei Zhang</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--78><div class="card-body p-3 small">Tables are often created with hierarchies but existing works on table reasoning mainly focus on flat tables and neglect hierarchical tables Hierarchical tables challenge numerical reasoning by complex hierarchical indexing as well as implicit relationships of calculation and semantics We present a new dataset HiTab to study question answering QA and natural language generation NLG over hierarchical tables HiTab is a cross domain dataset constructed from a wealth of statistical reports and Wikipedia pages and has unique characteristics nearly all tables are hierarchical and QA pairs are not proposed by annotators from scratch but are revised from real and meaningful sentences authored by analysts to reveal complex numerical reasoning in statistical reports we provide fine grained annotations of quantity and entity alignment Experiments suggest that this HiTab presents a strong challenge for existing baselines and a valuable benchmark for future research Targeting hierarchical structure we devise a hierarchy aware logical form for symbolic reasoning over tables which shows high effectiveness Targeting table reasoning we leverage entity and quantity alignment to explore partially supervised training in QA and conditional generation in NLG and largely reduce spurious predictions in QA and produce better descriptions in NLG</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.142.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--142 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.142 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.acl-long.142" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.142/>Towards Robustness of Text-to-<span class=acl-fixed-case>SQL</span> Models Against Natural and Realistic Adversarial Table Perturbation</a></strong><br><a href=/people/x/xinyu-pi/>Xinyu Pi</a>
|
<a href=/people/b/bing-wang/>Bing Wang</a>
|
<a href=/people/y/yan-gao/>Yan Gao</a>
|
<a href=/people/j/jiaqi-guo/>Jiaqi Guo</a>
|
<a href=/people/z/zhoujun-li/>Zhoujun Li</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--142><div class="card-body p-3 small">The robustness of Text-to-SQL parsers against adversarial perturbations plays a crucial role in delivering highly reliable applications. Previous studies along this line primarily focused on perturbations in the natural language question side, neglecting the variability of tables. Motivated by this, we propose the Adversarial Table Perturbation (ATP) as a new attacking paradigm to measure robustness of Text-to-SQL models. Following this proposition, we curate ADVETA, the first robustness evaluation benchmark featuring natural and realistic ATPs. All tested state-of-the-art models experience dramatic performance drops on ADVETA, revealing significant room of improvement. To defense against ATP, we build a systematic adversarial training example generation framework tailored for better contextualization of tabular data. Experiments show that our approach brings models best robustness improvement against ATP, while also substantially boost model robustness against NL-side perturbations. We will release ADVETA and code to facilitate future research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.191.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--191 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.191 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2022.acl-long.191.software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.acl-long.191" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.191/><span class=acl-fixed-case>GL</span>-<span class=acl-fixed-case>CL</span>e<span class=acl-fixed-case>F</span>: A Global–Local Contrastive Learning Framework for Cross-lingual Spoken Language Understanding</a></strong><br><a href=/people/l/libo-qin/>Libo Qin</a>
|
<a href=/people/q/qiguang-chen/>Qiguang Chen</a>
|
<a href=/people/t/tianbao-xie/>Tianbao Xie</a>
|
<a href=/people/q/qixin-li/>Qixin Li</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/m/min-yen-kan/>Min-Yen Kan</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--191><div class="card-body p-3 small">Due to high data demands of current methods, attention to zero-shot cross-lingual spoken language understanding (SLU) has grown, as such approaches greatly reduce human annotation effort. However, existing models solely rely on shared parameters, which can only perform implicit alignment across languages. We present Global-Local Contrastive Learning Framework (GL-CLeF) to address this shortcoming. Specifically, we employ contrastive learning, leveraging bilingual dictionaries to construct multilingual views of the same utterance, then encourage their representations to be more similar than negative example pairs, which achieves to explicitly align representations of similar sentences across languages. In addition, a key step in GL-CLeF is a proposed Local and Global component, which achieves a fine-grained cross-lingual transfer (i.e., sentence-level Local intent transfer, token-level Local slot transfer, and semantic-level Global transfer across intent and slot). Experiments on MultiATIS++ show that GL-CLeF achieves the best performance and successfully pulls representations of similar sentences across languages closer.</div></div><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.39.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--39 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.39 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-demo.39" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.39/>ReTraCk : A Flexible and Efficient Framework for Knowledge Base Question Answering<span class=acl-fixed-case>R</span>e<span class=acl-fixed-case>T</span>ra<span class=acl-fixed-case>C</span>k: A Flexible and Efficient Framework for Knowledge Base Question Answering</a></strong><br><a href=/people/s/shuang-chen/>Shuang Chen</a>
|
<a href=/people/q/qian-liu/>Qian Liu</a>
|
<a href=/people/z/zhiwei-yu/>Zhiwei Yu</a>
|
<a href=/people/c/chin-yew-lin/>Chin-Yew Lin</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/f/feng-jiang/>Feng Jiang</a><br><a href=/volumes/2021.acl-demo/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--39><div class="card-body p-3 small">We present Retriever-Transducer-Checker (ReTraCk), a neural semantic parsing framework for large scale knowledge base question answering (KBQA). ReTraCk is designed as a <a href=https://en.wikipedia.org/wiki/Modular_programming>modular framework</a> to maintain high flexibility. It includes a retriever to retrieve relevant KB items efficiently, a transducer to generate <a href=https://en.wikipedia.org/wiki/Logical_form>logical form</a> with syntax correctness guarantees and a checker to improve transduction procedure. ReTraCk is ranked at top1 overall performance on the GrailQA leaderboard and obtains highly competitive performance on the typical WebQuestionsSP benchmark. Our <a href=https://en.wikipedia.org/wiki/System>system</a> can interact with users timely, demonstrating the efficiency of the proposed <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a>.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.118.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--118 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.118 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938878 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.118" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.118/>Benchmarking Meaning Representations in Neural Semantic Parsing</a></strong><br><a href=/people/j/jiaqi-guo/>Jiaqi Guo</a>
|
<a href=/people/q/qian-liu/>Qian Liu</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/z/zhenwen-li/>Zhenwen Li</a>
|
<a href=/people/x/xueqing-liu/>Xueqing Liu</a>
|
<a href=/people/t/tao-xie/>Tao Xie</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--118><div class="card-body p-3 small">Meaning representation is an important component of <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a>. Although researchers have designed a lot of meaning representations, recent work focuses on only a few of <a href=https://en.wikipedia.org/wiki/List_of_Latin_phrases_(M)>them</a>. Thus, the impact of meaning representation on <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> is less understood. Furthermore, existing work&#8217;s performance is often not comprehensively evaluated due to the lack of readily-available execution engines. Upon identifying these gaps, we propose, a new unified benchmark on meaning representations, by integrating existing semantic parsing datasets, completing the missing logical forms, and implementing the missing execution engines. The resulting unified benchmark contains the complete enumeration of <a href=https://en.wikipedia.org/wiki/Logical_form>logical forms</a> and <a href=https://en.wikipedia.org/wiki/Execution_(computing)>execution engines</a> over three datasets four meaning representations. A thorough experimental study on Unimer reveals that neural semantic parsing approaches exhibit notably different performance when they are trained to generate different meaning representations. Also, program alias and <a href=https://en.wikipedia.org/wiki/Formal_grammar>grammar rules</a> heavily impact the performance of different <a href=https://en.wikipedia.org/wiki/Semantics>meaning representations</a>. Our <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark</a>, execution engines and implementation can be found on : https://github.com/JasperGuo/Unimer.<tex-math>\\times</tex-math> four meaning representations. A thorough experimental study on Unimer reveals that neural semantic parsing approaches exhibit notably different performance when they are trained to generate different meaning representations. Also, program alias and grammar rules heavily impact the performance of different meaning representations. Our benchmark, execution engines and implementation can be found on: https://github.com/JasperGuo/Unimer.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.561.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--561 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.561 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939001 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.561/>What Do You Mean by That? A Parser-Independent Interactive Approach for Enhancing Text-to-SQL<span class=acl-fixed-case>SQL</span></a></strong><br><a href=/people/y/yuntao-li/>Yuntao Li</a>
|
<a href=/people/b/bei-chen/>Bei Chen</a>
|
<a href=/people/q/qian-liu/>Qian Liu</a>
|
<a href=/people/y/yan-gao/>Yan Gao</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/y/yan-zhang/>Yan Zhang</a>
|
<a href=/people/d/dongmei-zhang/>Dongmei Zhang</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--561><div class="card-body p-3 small">In Natural Language Interfaces to Databases systems, the text-to-SQL technique allows users to query databases by using natural language questions. Though significant progress in this area has been made recently, most <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a> may fall short when they are deployed in real systems. One main reason stems from the difficulty of fully understanding the users&#8217; natural language questions. In this paper, we include human in the loop and present a novel parser-independent interactive approach (PIIA) that interacts with users using multi-choice questions and can easily work with arbitrary parsers. Experiments were conducted on two cross-domain datasets, the WikiSQL and the more complex Spider, with five state-of-the-art <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a>. These demonstrated that PIIA is capable of enhancing the text-to-SQL performance with limited interaction turns by using both simulation and human evaluation.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1535.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1535 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1535 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1535" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1535/>A Split-and-Recombine Approach for Follow-up Query Analysis</a></strong><br><a href=/people/q/qian-liu/>Qian Liu</a>
|
<a href=/people/b/bei-chen/>Bei Chen</a>
|
<a href=/people/h/haoyan-liu/>Haoyan Liu</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/l/lei-fang/>Lei Fang</a>
|
<a href=/people/b/bin-zhou/>Bin Zhou</a>
|
<a href=/people/d/dongmei-zhang/>Dongmei Zhang</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1535><div class="card-body p-3 small">Context-dependent semantic parsing has proven to be an important yet challenging <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. To leverage the advances in context-independent semantic parsing, we propose to perform follow-up query analysis, aiming to restate context-dependent natural language queries with <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual information</a>. To accomplish the task, we propose STAR, a novel approach with a well-designed two-phase process. It is parser-independent and able to handle multifarious follow-up scenarios in different domains. Experiments on the FollowUp dataset show that STAR outperforms the state-of-the-art baseline by a large margin of nearly 8 %. The superiority on <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a> results verifies the feasibility of follow-up query analysis. We also explore the extensibility of STAR on the SQA dataset, which is very promising.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1444.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1444 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1444 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1444.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1444" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1444/>Towards Complex Text-to-SQL in Cross-Domain Database with Intermediate Representation<span class=acl-fixed-case>SQL</span> in Cross-Domain Database with Intermediate Representation</a></strong><br><a href=/people/j/jiaqi-guo/>Jiaqi Guo</a>
|
<a href=/people/z/zecheng-zhan/>Zecheng Zhan</a>
|
<a href=/people/y/yan-gao/>Yan Gao</a>
|
<a href=/people/y/yan-xiao/>Yan Xiao</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/d/dongmei-zhang/>Dongmei Zhang</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1444><div class="card-body p-3 small">We present a neural approach called IRNet for complex and cross-domain Text-to-SQL. IRNet aims to address two challenges : 1) the mismatch between intents expressed in natural language (NL) and the implementation details in <a href=https://en.wikipedia.org/wiki/SQL>SQL</a> ; 2) the challenge in predicting columns caused by the large number of out-of-domain words. Instead of end-to-end synthesizing a <a href=https://en.wikipedia.org/wiki/SQL>SQL query</a>, IRNet decomposes the synthesis process into three phases. In the first phase, IRNet performs a schema linking over a question and a <a href=https://en.wikipedia.org/wiki/Database_schema>database schema</a>. Then, IRNet adopts a grammar-based neural model to synthesize a SemQL query which is an intermediate representation that we design to bridge <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NL</a> and <a href=https://en.wikipedia.org/wiki/SQL>SQL</a>. Finally, IRNet deterministically infers a <a href=https://en.wikipedia.org/wiki/SQL>SQL query</a> from the synthesized SemQL query with <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain knowledge</a>. On the challenging Text-to-SQL benchmark Spider, IRNet achieves 46.7 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, obtaining 19.5 % absolute improvement over previous <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>state-of-the-art approaches</a>. At the time of writing, IRNet achieves the first position on the Spider leaderboard.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1189.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1189 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1189 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1189/>SemRegex : A Semantics-Based Approach for Generating <a href=https://en.wikipedia.org/wiki/Regular_expression>Regular Expressions</a> from Natural Language Specifications<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>R</span>egex: A Semantics-Based Approach for Generating Regular Expressions from Natural Language Specifications</a></strong><br><a href=/people/z/zexuan-zhong/>Zexuan Zhong</a>
|
<a href=/people/j/jiaqi-guo/>Jiaqi Guo</a>
|
<a href=/people/w/wei-yang/>Wei Yang</a>
|
<a href=/people/j/jian-peng/>Jian Peng</a>
|
<a href=/people/t/tao-xie/>Tao Xie</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/d/dongmei-zhang/>Dongmei Zhang</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1189><div class="card-body p-3 small">Recent research proposes syntax-based approaches to address the problem of <a href=https://en.wikipedia.org/wiki/Computer_programming>generating programs</a> from <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language specifications</a>. These approaches typically train a sequence-to-sequence learning model using a syntax-based objective : <a href=https://en.wikipedia.org/wiki/Maximum_likelihood_estimation>maximum likelihood estimation (MLE)</a>. Such syntax-based approaches do not effectively address the goal of generating semantically correct programs, because these approaches fail to handle Program Aliasing, i.e., semantically equivalent programs may have many syntactically different forms. To address this issue, in this paper, we propose a semantics-based approach named SemRegex. SemRegex provides solutions for a subtask of the program-synthesis problem : generating <a href=https://en.wikipedia.org/wiki/Regular_expression>regular expressions</a> from <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. Different from the existing syntax-based approaches, SemRegex trains the model by maximizing the expected semantic correctness of the generated <a href=https://en.wikipedia.org/wiki/Regular_expression>regular expressions</a>. The semantic correctness is measured using the DFA-equivalence oracle, random test cases, and distinguishing test cases. The experiments on three public datasets demonstrate the superiority of SemRegex over the existing state-of-the-art approaches.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Jian-Guang+Lou" title="Search for 'Jian-Guang Lou' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/j/jiaqi-guo/ class=align-middle>Jiaqi Guo</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/d/dongmei-zhang/ class=align-middle>Dongmei Zhang</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/q/qian-liu/ class=align-middle>Qian Liu</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/y/yan-gao/ class=align-middle>Yan Gao</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/t/ting-liu/ class=align-middle>Ting Liu</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/t/tao-xie/ class=align-middle>Tao Xie</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/bei-chen/ class=align-middle>Bei Chen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/shuang-chen/ class=align-middle>Shuang Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhiwei-yu/ class=align-middle>Zhiwei Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chin-yew-lin/ class=align-middle>Chin-Yew Lin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/feng-jiang/ class=align-middle>Feng Jiang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhenwen-li/ class=align-middle>Zhenwen Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xueqing-liu/ class=align-middle>Xueqing Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yuntao-li/ class=align-middle>Yuntao Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yan-zhang/ class=align-middle>Yan Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhoujun-cheng/ class=align-middle>Zhoujun Cheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haoyu-dong/ class=align-middle>Haoyu Dong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhiruo-wang/ class=align-middle>Zhiruo Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ran-jia/ class=align-middle>Ran Jia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shi-han/ class=align-middle>Shi Han</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xinyu-pi/ class=align-middle>Xinyu Pi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bing-wang/ class=align-middle>Bing Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhoujun-li/ class=align-middle>Zhoujun Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/libo-qin/ class=align-middle>Libo Qin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qiguang-chen/ class=align-middle>Qiguang Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tianbao-xie/ class=align-middle>Tianbao Xie</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qixin-li/ class=align-middle>Qixin Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wanxiang-che/ class=align-middle>Wanxiang Che (车万翔)</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/min-yen-kan/ class=align-middle>Min-Yen Kan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zexuan-zhong/ class=align-middle>Zexuan Zhong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wei-yang/ class=align-middle>Wei Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jian-peng/ class=align-middle>Jian Peng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haoyan-liu/ class=align-middle>Haoyan Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lei-fang/ class=align-middle>Lei Fang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bin-zhou/ class=align-middle>Bin Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zecheng-zhan/ class=align-middle>Zecheng Zhan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yan-xiao/ class=align-middle>Yan Xiao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">4</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>