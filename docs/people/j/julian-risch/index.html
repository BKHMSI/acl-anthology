<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Julian Risch - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Julian</span> <span class=font-weight-bold>Risch</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mrqa-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mrqa-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mrqa-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mrqa-1.15/>Semantic Answer Similarity for Evaluating Question Answering Models</a></strong><br><a href=/people/j/julian-risch/>Julian Risch</a>
|
<a href=/people/t/timo-moller/>Timo Möller</a>
|
<a href=/people/j/julian-gutsch/>Julian Gutsch</a>
|
<a href=/people/m/malte-pietsch/>Malte Pietsch</a><br><a href=/volumes/2021.mrqa-1/ class=text-muted>Proceedings of the 3rd Workshop on Machine Reading for Question Answering</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mrqa-1--15><div class="card-body p-3 small">The evaluation of question answering models compares <a href=https://en.wikipedia.org/wiki/Ground_truth>ground-truth annotations</a> with <a href=https://en.wikipedia.org/wiki/Prediction>model predictions</a>. However, as of today, this comparison is mostly lexical-based and therefore misses out on answers that have no lexical overlap but are still semantically similar, thus treating correct answers as false. This underestimation of the true performance of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> hinders user acceptance in applications and complicates a fair comparison of different <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Therefore, there is a need for an evaluation metric that is based on <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> instead of pure <a href=https://en.wikipedia.org/wiki/String_similarity>string similarity</a>. In this short paper, we present SAS, a cross-encoder-based metric for the estimation of semantic answer similarity, and compare it to seven existing <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a>. To this end, we create an English and a German three-way annotated evaluation dataset containing pairs of answers along with human judgment of their <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic similarity</a>, which we release along with an implementation of the SAS metric and the experiments. We find that semantic similarity metrics based on recent transformer models correlate much better with human judgment than traditional lexical similarity metrics on our two newly created datasets and one dataset from related work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.germeval-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.germeval-1.0/>Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments</a></strong><br><a href=/people/j/julian-risch/>Julian Risch</a>
|
<a href=/people/a/anke-stoll/>Anke Stoll</a>
|
<a href=/people/l/lena-wilms/>Lena Wilms</a>
|
<a href=/people/m/michael-wiegand/>Michael Wiegand</a><br><a href=/volumes/2021.germeval-1/ class=text-muted>Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.trac-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--trac-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.trac-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.trac-1.9" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.trac-1.9/>Bagging BERT Models for Robust Aggression Identification<span class=acl-fixed-case>BERT</span> Models for Robust Aggression Identification</a></strong><br><a href=/people/j/julian-risch/>Julian Risch</a>
|
<a href=/people/r/ralf-krestel/>Ralf Krestel</a><br><a href=/volumes/2020.trac-1/ class=text-muted>Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--trac-1--9><div class="card-body p-3 small">Modern transformer-based models with hundreds of millions of parameters, such as BERT, achieve impressive results at text classification tasks. This also holds for aggression identification and offensive language detection, where deep learning approaches consistently outperform less complex models, such as <a href=https://en.wikipedia.org/wiki/Decision_tree_learning>decision trees</a>. While the complex models fit training data well (low bias), they also come with an unwanted high variance. Especially when fine-tuning them on small datasets, the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance varies significantly for slightly different training data. To overcome the high variance and provide more robust predictions, we propose an ensemble of multiple fine-tuned BERT models based on bootstrap aggregating (bagging). In this paper, we describe such an ensemble system and present our submission to the shared tasks on aggression identification 2020 (team name : Julian). Our submission is the best-performing <a href=https://en.wikipedia.org/wiki/System>system</a> for five out of six subtasks. For example, we achieve a weighted F1-score of 80.3 % for task A on the test dataset of English social media posts. In our experiments, we compare different model configurations and vary the number of models used in the <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble</a>. We find that the F1-score drastically increases when ensembling up to 15 models, but the returns diminish for more models.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-4418.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-4418 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-4418 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-4418" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-4418/>Aggression Identification Using <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Learning</a> and Data Augmentation</a></strong><br><a href=/people/j/julian-risch/>Julian Risch</a>
|
<a href=/people/r/ralf-krestel/>Ralf Krestel</a><br><a href=/volumes/W18-44/ class=text-muted>Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-4418><div class="card-body p-3 small">Social media platforms allow users to share and discuss their opinions online. However, a minority of user posts is aggressive, thereby hinders respectful discussion, and at an extreme level is liable to prosecution. The automatic identification of such harmful posts is important, because <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> can support the costly manual moderation of online discussions. Further, the <a href=https://en.wikipedia.org/wiki/Automation>automation</a> allows unprecedented analyses of discussion datasets that contain millions of posts. This system description paper presents our submission to the First Shared Task on Aggression Identification. We propose to augment the provided <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> to increase the number of labeled comments from 15,000 to 60,000. Thereby, we introduce <a href=https://en.wikipedia.org/wiki/Variety_(linguistics)>linguistic variety</a> into the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. As a consequence of the larger amount of training data, we are able to train a special <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural net</a>, which generalizes especially well to unseen data. To further boost the performance, we combine this <a href=https://en.wikipedia.org/wiki/Artificial_neural_network>neural net</a> with three logistic regression classifiers trained on character and word n-grams, and hand-picked syntactic features. This <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble</a> is more robust than the individual single models. Our team named Julian achieves an F1-score of 60 % on both English datasets, 63 % on the Hindi Facebook dataset, and 38 % on the Hindi Twitter dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-4420.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-4420 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-4420 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-4420/>Delete or not Delete? Semi-Automatic Comment Moderation for the Newsroom</a></strong><br><a href=/people/j/julian-risch/>Julian Risch</a>
|
<a href=/people/r/ralf-krestel/>Ralf Krestel</a><br><a href=/volumes/W18-44/ class=text-muted>Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-4420><div class="card-body p-3 small">Comment sections of online news providers have enabled millions to share and discuss their opinions on news topics. Today, moderators ensure respectful and informative discussions by deleting not only insults, <a href=https://en.wikipedia.org/wiki/Defamation>defamation</a>, and hate speech, but also unverifiable facts. This process has to be transparent and comprehensive in order to keep the community engaged. Further, news providers have to make sure to not give the impression of <a href=https://en.wikipedia.org/wiki/Censorship>censorship</a> or dissemination of fake news. Yet <a href=https://en.wikipedia.org/wiki/Moderation_system>manual moderation</a> is very expensive and becomes more and more unfeasible with the increasing amount of comments. Hence, we propose a semi-automatic, holistic approach, which includes comment features but also their context, such as information about users and articles. For evaluation, we present experiments on a novel <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of 3 million news comments annotated by a team of professional moderators.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5105.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5105 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5105 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5105/>Challenges for Toxic Comment Classification : An In-Depth Error Analysis</a></strong><br><a href=/people/b/betty-van-aken/>Betty van Aken</a>
|
<a href=/people/j/julian-risch/>Julian Risch</a>
|
<a href=/people/r/ralf-krestel/>Ralf Krestel</a>
|
<a href=/people/a/alexander-loser/>Alexander Löser</a><br><a href=/volumes/W18-51/ class=text-muted>Proceedings of the 2nd Workshop on Abusive Language Online (ALW2)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5105><div class="card-body p-3 small">Toxic comment classification has become an active research field with many recently proposed approaches. However, while these approaches address some of the task&#8217;s challenges others still remain unsolved and directions for further research are needed. To this end, we compare different deep learning and shallow approaches on a new, large comment dataset and propose an <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble</a> that outperforms all individual models. Further, we validate our findings on a second <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. The results of the <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble</a> enable us to perform an extensive error analysis, which reveals open challenges for state-of-the-art methods and directions towards pending future research. These challenges include missing paradigmatic context and inconsistent dataset labels.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Julian+Risch" title="Search for 'Julian Risch' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/r/ralf-krestel/ class=align-middle>Ralf Krestel</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/t/timo-moller/ class=align-middle>Timo Möller</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/julian-gutsch/ class=align-middle>Julian Gutsch</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/malte-pietsch/ class=align-middle>Malte Pietsch</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anke-stoll/ class=align-middle>Anke Stoll</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/l/lena-wilms/ class=align-middle>Lena Wilms</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-wiegand/ class=align-middle>Michael Wiegand</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/betty-van-aken/ class=align-middle>Betty van Aken</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexander-loser/ class=align-middle>Alexander Löser</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/mrqa/ class=align-middle>MRQA</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/germeval/ class=align-middle>GermEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/trac/ class=align-middle>TRAC</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>