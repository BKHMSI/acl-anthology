<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Jonathan K. Kummerfeld - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Jonathan K.</span> <span class=font-weight-bold>Kummerfeld</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-short.44.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-short--44 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-short.44 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.acl-short.44.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.acl-short.44/>Quantifying and Avoiding Unfair Qualification Labour in Crowdsourcing</a></strong><br><a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a><br><a href=/volumes/2021.acl-short/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-short--44><div class="card-body p-3 small">Extensive work has argued in favour of paying crowd workers a wage that is at least equivalent to the U.S. federal minimum wage. Meanwhile, research on collecting high quality annotations suggests using a qualification that requires workers to have previously completed a certain number of tasks. If most requesters who pay fairly require workers to have completed a large number of tasks already then workers need to complete a substantial amount of poorly paid work before they can earn a fair wage. Through analysis of worker discussions and guidance for researchers, we estimate that workers spend approximately 2.25 months of full time effort on poorly paid tasks in order to get the <a href=https://en.wikipedia.org/wiki/Professional_certification>qualifications</a> needed for better paid tasks. We discuss alternatives to this qualification and conduct a study of the correlation between <a href=https://en.wikipedia.org/wiki/Professional_certification>qualifications</a> and work quality on two NLP tasks. We find that it is possible to reduce the burden on workers while still collecting <a href=https://en.wikipedia.org/wiki/Data_quality>high quality data</a>.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.334.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--334 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.334 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939153 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.334" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.334/>Compositional Demographic Word Embeddings</a></strong><br><a href=/people/c/charles-welch/>Charles Welch</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/v/veronica-perez-rosas/>Verónica Pérez-Rosas</a>
|
<a href=/people/r/rada-mihalcea/>Rada Mihalcea</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--334><div class="card-body p-3 small">Word embeddings are usually derived from corpora containing text from many individuals, thus leading to general purpose representations rather than individually personalized representations. While personalized embeddings can be useful to improve <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> performance and other language processing tasks, they can only be computed for people with a large amount of <a href=https://en.wikipedia.org/wiki/Panel_data>longitudinal data</a>, which is not the case for new users. We propose a new form of personalized word embeddings that use demographic-specific word representations derived compositionally from full or partial demographic information for a user (i.e., gender, age, location, religion). We show that the resulting demographic-aware word representations outperform generic word representations on two tasks for <a href=https://en.wikipedia.org/wiki/English_language>English</a> : <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a> and word associations. We further explore the trade-off between the number of available attributes and their relative effectiveness and discuss the ethical implications of using them.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.650.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--650 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.650 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.650.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938895 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.650/>Iterative Feature Mining for Constraint-Based Data Collection to Increase Data Diversity and Model Robustness</a></strong><br><a href=/people/s/stefan-larson/>Stefan Larson</a>
|
<a href=/people/a/anthony-zheng/>Anthony Zheng</a>
|
<a href=/people/a/anish-mahendran/>Anish Mahendran</a>
|
<a href=/people/r/rishi-tekriwal/>Rishi Tekriwal</a>
|
<a href=/people/a/adrian-cheung/>Adrian Cheung</a>
|
<a href=/people/e/eric-guldan/>Eric Guldan</a>
|
<a href=/people/k/kevin-leach/>Kevin Leach</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--650><div class="card-body p-3 small">Diverse data is crucial for training robust models, but crowdsourced text often lacks diversity as workers tend to write simple variations from prompts. We propose a general approach for guiding workers to write more diverse text by iteratively constraining their writing. We show how prior workflows are special cases of our approach, and present a way to apply the approach to dialog tasks such as intent classification and slot-filling. Using our <a href=https://en.wikipedia.org/wiki/Methodology>method</a>, we create more challenging versions of test sets from prior dialog datasets and find dramatic performance drops for standard <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Finally, we show that our approach is complementary to recent work on improving <a href=https://en.wikipedia.org/wiki/Data>data diversity</a>, and training on <a href=https://en.wikipedia.org/wiki/Data>data</a> collected with our approach leads to more robust models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.38.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--38 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.38 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.findings-emnlp.38.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.findings-emnlp.38" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.38/>A Novel Workflow for Accurately and Efficiently Crowdsourcing Predicate Senses and Argument Labels</a></strong><br><a href=/people/y/youxuan-jiang/>Youxuan Jiang</a>
|
<a href=/people/h/huaiyu-zhu/>Huaiyu Zhu</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/y/yunyao-li/>Yunyao Li</a>
|
<a href=/people/w/walter-lasecki/>Walter Lasecki</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--38><div class="card-body p-3 small">Resources for Semantic Role Labeling (SRL) are typically annotated by experts at great expense. Prior attempts to develop <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing methods</a> have either had low <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> or required substantial <a href=https://en.wikipedia.org/wiki/Annotation>expert annotation</a>. We propose a new multi-stage crowd workflow that substantially reduces expert involvement without sacrificing <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. In particular, we introduce a unique filter stage based on the key observation that crowd workers are able to almost perfectly filter out incorrect options for labels. Our three-stage workflow produces annotations with 95 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> for predicate labels and 93 % for argument labels, which is comparable to expert agreement. Compared to prior work on <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a> for SRL, we decrease expert effort by 4x, from 56 % to 14 % of cases. Our approach enables more scalable annotation of SRL, and could enable annotation of NLP tasks that have previously been considered too complex to effectively crowdsource.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1131.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1131 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1131 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1131.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1131" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1131/>An Evaluation Dataset for Intent Classification and Out-of-Scope Prediction</a></strong><br><a href=/people/s/stefan-larson/>Stefan Larson</a>
|
<a href=/people/a/anish-mahendran/>Anish Mahendran</a>
|
<a href=/people/j/joseph-j-peper/>Joseph J. Peper</a>
|
<a href=/people/c/christopher-clarke/>Christopher Clarke</a>
|
<a href=/people/a/andrew-lee/>Andrew Lee</a>
|
<a href=/people/p/parker-hill/>Parker Hill</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/k/kevin-leach/>Kevin Leach</a>
|
<a href=/people/m/michael-a-laurenzano/>Michael A. Laurenzano</a>
|
<a href=/people/l/lingjia-tang/>Lingjia Tang</a>
|
<a href=/people/j/jason-mars/>Jason Mars</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1131><div class="card-body p-3 small">Task-oriented dialog systems need to know when a query falls outside their range of supported intents, but current text classification corpora only define label sets that cover every example. We introduce a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> that includes queries that are out-of-scopei.e., queries that do not fall into any of the system&#8217;s supported intents. This poses a new challenge because models can not assume that every query at inference time belongs to a system-supported intent class. Our dataset also covers 150 intent classes over 10 domains, capturing the breadth that a production task-oriented agent must handle. We evaluate a range of benchmark classifiers on our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> along with several different out-of-scope identification schemes. We find that while the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> perform well on in-scope intent classification, they struggle to identify out-of-scope queries. Our dataset and evaluation fill an important gap in the field, offering a way of more rigorously and realistically benchmarking text classification in task-driven dialog systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4107.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4107 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4107 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4107/>DSTC7 Task 1 : Noetic End-to-End Response Selection<span class=acl-fixed-case>DSTC</span>7 Task 1: Noetic End-to-End Response Selection</a></strong><br><a href=/people/c/chulaka-gunasekara/>Chulaka Gunasekara</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/l/lazaros-polymenakos/>Lazaros Polymenakos</a>
|
<a href=/people/w/walter-lasecki/>Walter Lasecki</a><br><a href=/volumes/W19-41/ class=text-muted>Proceedings of the First Workshop on NLP for Conversational AI</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4107><div class="card-body p-3 small">Goal-oriented dialogue in complex domains is an extremely challenging problem and there are relatively few datasets. This <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> provided two new resources that presented different challenges : one was focused but small, while the other was large but diverse. We also considered several new variations on the next utterance selection problem : (1) increasing the number of candidates, (2) including paraphrases, and (3) not including a correct option in the candidate set. Twenty teams participated, developing a range of neural network models, including some that successfully incorporated external data to boost performance. Both <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> have been publicly released, enabling future work to build on these results, working towards robust goal-oriented dialogue systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1051.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1051 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1051 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-1051/>Outlier Detection for Improved Data Quality and Diversity in Dialog Systems</a></strong><br><a href=/people/s/stefan-larson/>Stefan Larson</a>
|
<a href=/people/a/anish-mahendran/>Anish Mahendran</a>
|
<a href=/people/a/andrew-lee/>Andrew Lee</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/p/parker-hill/>Parker Hill</a>
|
<a href=/people/m/michael-a-laurenzano/>Michael A. Laurenzano</a>
|
<a href=/people/j/johann-hauswald/>Johann Hauswald</a>
|
<a href=/people/l/lingjia-tang/>Lingjia Tang</a>
|
<a href=/people/j/jason-mars/>Jason Mars</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1051><div class="card-body p-3 small">In a <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpus of data</a>, <a href=https://en.wikipedia.org/wiki/Outlier>outliers</a> are either errors : mistakes in the data that are counterproductive, or are unique : informative samples that improve <a href=https://en.wikipedia.org/wiki/Robust_statistics>model robustness</a>. Identifying outliers can lead to better datasets by (1) removing noise in datasets and (2) guiding collection of additional data to fill gaps. However, the problem of detecting both outlier types has received relatively little attention in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, particularly for dialog systems. We introduce a simple and effective technique for detecting both erroneous and unique samples in a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus of short texts</a> using neural sentence embeddings combined with distance-based outlier detection. We also present a novel data collection pipeline built atop our detection technique to automatically and iteratively mine unique data samples while discarding erroneous samples. Experiments show that our outlier detection technique is effective at finding errors while our data collection pipeline yields highly diverse corpora that in turn produce more robust intent classification and slot-filling models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1374.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1374 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1374 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1374.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1374.Software.tgz data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1374" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1374/>A Large-Scale Corpus for Conversation Disentanglement</a></strong><br><a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/s/sai-r-gouravajhala/>Sai R. Gouravajhala</a>
|
<a href=/people/j/joseph-j-peper/>Joseph J. Peper</a>
|
<a href=/people/v/vignesh-athreya/>Vignesh Athreya</a>
|
<a href=/people/c/chulaka-gunasekara/>Chulaka Gunasekara</a>
|
<a href=/people/j/jatin-ganhotra/>Jatin Ganhotra</a>
|
<a href=/people/s/siva-sankalp-patel/>Siva Sankalp Patel</a>
|
<a href=/people/l/lazaros-c-polymenakos/>Lazaros C Polymenakos</a>
|
<a href=/people/w/walter-lasecki/>Walter Lasecki</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1374><div class="card-body p-3 small">Disentangling conversations mixed together in a single stream of messages is a difficult task, made harder by the lack of large manually annotated datasets. We created a new dataset of 77,563 messages manually annotated with reply-structure graphs that both disentangle conversations and define internal conversation structure. Our <a href=https://en.wikipedia.org/wiki/Data>data</a> is 16 times larger than all previously released datasets combined, the first to include adjudication of annotation disagreements, and the first to include <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context</a>. We use our data to re-examine prior work, in particular, finding that 89 % of conversations in a widely used dialogue corpus are either missing messages or contain extra messages. Our manually-annotated data presents an opportunity to develop robust data-driven methods for conversation disentanglement, which will help advance dialogue research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-3002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-3002 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-3002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-3002.Note.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-3002" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-3002/>SLATE : A Super-Lightweight Annotation Tool for Experts<span class=acl-fixed-case>SLATE</span>: A Super-Lightweight Annotation Tool for Experts</a></strong><br><a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a><br><a href=/volumes/P19-3/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-3002><div class="card-body p-3 small">Many annotation tools have been developed, covering a wide variety of tasks and providing features like user management, pre-processing, and automatic labeling. However, all of these tools use <a href=https://en.wikipedia.org/wiki/Graphical_user_interface>Graphical User Interfaces</a>, and often require substantial effort to install and configure. This paper presents a new annotation tool that is designed to fill the niche of a lightweight interface for users with a terminal-based workflow. SLATE supports annotation at different scales (spans of characters, tokens, and lines, or a document) and of different types (free text, labels, and links), with easily customisable keybindings, and unicode support. In a user study comparing with other tools it was consistently the easiest to install and use. SLATE fills a need not met by existing systems, and has already been used to annotate two corpora, one of which involved over 250 hours of annotation effort.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2099.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-2099 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-2099 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-2099.Datasets.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-2099/>Effective <a href=https://en.wikipedia.org/wiki/Crowdsourcing>Crowdsourcing</a> for a New Type of Summarization Task</a></strong><br><a href=/people/y/youxuan-jiang/>Youxuan Jiang</a>
|
<a href=/people/c/catherine-finegan-dollak/>Catherine Finegan-Dollak</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/w/walter-lasecki/>Walter Lasecki</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-2099><div class="card-body p-3 small">Most <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> research focuses on summarizing the entire given text, but in practice readers are often interested in only one aspect of the document or conversation. We propose targeted summarization as an umbrella category for summarization tasks that intentionally consider only parts of the input data. This covers query-based summarization, update summarization, and a new task we propose where the goal is to summarize a particular aspect of a document. However, collecting data for this new task is hard because directly asking annotators (e.g., crowd workers) to write summaries leads to data with low accuracy when there are a large number of facts to include. We introduce a novel crowdsourcing workflow, Pin-Refine, that allows us to collect high-quality summaries for our task, a necessary step for the development of automatic systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-3005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-3005 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-3005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277631102 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-3005/>Data Collection for Dialogue System : A Startup Perspective</a></strong><br><a href=/people/y/yiping-kang/>Yiping Kang</a>
|
<a href=/people/y/yunqi-zhang/>Yunqi Zhang</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/l/lingjia-tang/>Lingjia Tang</a>
|
<a href=/people/j/jason-mars/>Jason Mars</a><br><a href=/volumes/N18-3/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-3005><div class="card-body p-3 small">Industrial dialogue systems such as Apple Siri and Google Now rely on large scale diverse and robust training data to enable their sophisticated conversation capability. Crowdsourcing provides a scalable and inexpensive way of <a href=https://en.wikipedia.org/wiki/Data_collection>data collection</a> but collecting high quality data efficiently requires thoughtful orchestration of the crowdsourcing jobs. Prior study of this topic have focused on tasks only in the academia settings with limited scope or only provide intrinsic dataset analysis, lacking indication on how it affects the trained <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> performance. In this paper, we present a study of <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing methods</a> for a user intent classification task in our deployed <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue system</a>. Our <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> requires <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> of 47 possible user intents and contains many intent pairs with subtle differences. We consider different crowdsourcing job types and job prompts and analyze quantitatively the quality of the collected data and the downstream model performance on a test set of real user queries from production logs. Our observation provides insights into designing efficient crowdsourcing jobs and provide recommendations for future dialogue system data collection process.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1033.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1033 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1033 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1033.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1033" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1033/>Improving Text-to-SQL Evaluation Methodology<span class=acl-fixed-case>SQL</span> Evaluation Methodology</a></strong><br><a href=/people/c/catherine-finegan-dollak/>Catherine Finegan-Dollak</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/l/li-zhang/>Li Zhang</a>
|
<a href=/people/k/karthik-ramanathan/>Karthik Ramanathan</a>
|
<a href=/people/s/sesh-sadasivam/>Sesh Sadasivam</a>
|
<a href=/people/r/rui-zhang/>Rui Zhang</a>
|
<a href=/people/d/dragomir-radev/>Dragomir Radev</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1033><div class="card-body p-3 small">To be informative, an evaluation must measure how well systems generalize to realistic unseen data. We identify limitations of and propose improvements to current evaluations of text-to-SQL systems. First, we compare human-generated and automatically generated questions, characterizing properties of queries necessary for real-world applications. To facilitate evaluation on multiple datasets, we release standardized and improved versions of seven existing <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> and one new text-to-SQL dataset. Second, we show that the current division of data into training and test sets measures robustness to variations in the way questions are asked, but only partially tests how well systems generalize to new queries ; therefore, we propose a complementary dataset split for evaluation of future work. Finally, we demonstrate how the common practice of anonymizing variables during <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a> removes an important challenge of the task. Our observations highlight key difficulties, and our <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> enables effective measurement of future development.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2017.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2017 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2017 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-2017.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-2017.Datasets.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234958413 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-2017/>Understanding Task Design Trade-offs in Crowdsourced Paraphrase Collection</a></strong><br><a href=/people/y/youxuan-jiang/>Youxuan Jiang</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/w/walter-lasecki/>Walter S. Lasecki</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2017><div class="card-body p-3 small">Linguistically diverse datasets are critical for training and evaluating robust <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning systems</a>, but <a href=https://en.wikipedia.org/wiki/Data_collection>data collection</a> is a costly process that often requires experts. Crowdsourcing the process of <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a> is an effective means of expanding <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language datasets</a>, but there has been limited analysis of the trade-offs that arise when designing tasks. In this paper, we present the first systematic study of the key factors in crowdsourcing paraphrase collection. We consider variations in <a href=https://en.wikipedia.org/wiki/Instruction_set_architecture>instructions</a>, <a href=https://en.wikipedia.org/wiki/Incentive>incentives</a>, <a href=https://en.wikipedia.org/wiki/Data_domain>data domains</a>, and <a href=https://en.wikipedia.org/wiki/Workflow>workflows</a>. We manually analyzed paraphrases for correctness, <a href=https://en.wikipedia.org/wiki/Grammaticality>grammaticality</a>, and <a href=https://en.wikipedia.org/wiki/Linguistic_diversity>linguistic diversity</a>. Our observations provide new insight into the trade-offs between <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and diversity in crowd responses that arise as a result of <a href=https://en.wikipedia.org/wiki/Design_of_experiments>task design</a>, providing guidance for future paraphrase generation procedures.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1275.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1275 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1275 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D17-1275.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D17-1275" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D17-1275/>Identifying Products in Online Cybercrime Marketplaces : A Dataset for Fine-grained Domain Adaptation</a></strong><br><a href=/people/g/greg-durrett/>Greg Durrett</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a>
|
<a href=/people/r/rebecca-portnoff/>Rebecca Portnoff</a>
|
<a href=/people/s/sadia-afroz/>Sadia Afroz</a>
|
<a href=/people/d/damon-mccoy/>Damon McCoy</a>
|
<a href=/people/k/kirill-levchenko/>Kirill Levchenko</a>
|
<a href=/people/v/vern-paxson/>Vern Paxson</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1275><div class="card-body p-3 small">One weakness of machine-learned NLP models is that they typically perform poorly on out-of-domain data. In this work, we study the task of identifying products being bought and sold in online cybercrime forums, which exhibits particularly challenging cross-domain effects. We formulate a task that represents a hybrid of slot-filling information extraction and <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a> and annotate <a href=https://en.wikipedia.org/wiki/Data>data</a> from four different forums. Each of these <a href=https://en.wikipedia.org/wiki/Internet_forum>forums</a> constitutes its own fine-grained domain in that the <a href=https://en.wikipedia.org/wiki/Internet_forum>forums</a> cover different market sectors with different properties, even though all forums are in the broad domain of <a href=https://en.wikipedia.org/wiki/Cybercrime>cybercrime</a>. We characterize these domain differences in the context of a <a href=https://en.wikipedia.org/wiki/Machine_learning>learning-based system</a> : <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised models</a> see decreased accuracy when applied to new forums, and standard techniques for <a href=https://en.wikipedia.org/wiki/Semi-supervised_learning>semi-supervised learning</a> and <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> have limited effectiveness on this data, which suggests the need to improve these techniques. We release a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 1,938 annotated posts from across the four forums.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Jonathan+K.+Kummerfeld" title="Search for 'Jonathan K. Kummerfeld' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/w/walter-lasecki/ class=align-middle>Walter Lasecki</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/s/stefan-larson/ class=align-middle>Stefan Larson</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/anish-mahendran/ class=align-middle>Anish Mahendran</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/y/youxuan-jiang/ class=align-middle>Youxuan Jiang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/lingjia-tang/ class=align-middle>Lingjia Tang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/j/jason-mars/ class=align-middle>Jason Mars</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/k/kevin-leach/ class=align-middle>Kevin Leach</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/joseph-j-peper/ class=align-middle>Joseph J. Peper</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/andrew-lee/ class=align-middle>Andrew Lee</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/parker-hill/ class=align-middle>Parker Hill</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/michael-a-laurenzano/ class=align-middle>Michael A. Laurenzano</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/chulaka-gunasekara/ class=align-middle>Chulaka Gunasekara</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/catherine-finegan-dollak/ class=align-middle>Catherine Finegan-Dollak</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/charles-welch/ class=align-middle>Charles Welch</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/veronica-perez-rosas/ class=align-middle>Verónica Pérez-Rosas</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rada-mihalcea/ class=align-middle>Rada Mihalcea</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anthony-zheng/ class=align-middle>Anthony Zheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rishi-tekriwal/ class=align-middle>Rishi Tekriwal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/adrian-cheung/ class=align-middle>Adrian Cheung</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eric-guldan/ class=align-middle>Eric Guldan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christopher-clarke/ class=align-middle>Christopher Clarke</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/greg-durrett/ class=align-middle>Greg Durrett</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/taylor-berg-kirkpatrick/ class=align-middle>Taylor Berg-Kirkpatrick</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rebecca-portnoff/ class=align-middle>Rebecca Portnoff</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sadia-afroz/ class=align-middle>Sadia Afroz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/damon-mccoy/ class=align-middle>Damon McCoy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kirill-levchenko/ class=align-middle>Kirill Levchenko</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vern-paxson/ class=align-middle>Vern Paxson</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/huaiyu-zhu/ class=align-middle>Huaiyu Zhu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yunyao-li/ class=align-middle>Yunyao Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lazaros-polymenakos/ class=align-middle>Lazaros Polymenakos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/johann-hauswald/ class=align-middle>Johann Hauswald</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yiping-kang/ class=align-middle>Yiping Kang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yunqi-zhang/ class=align-middle>Yunqi Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/li-zhang/ class=align-middle>Li Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/karthik-ramanathan/ class=align-middle>Karthik Ramanathan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sesh-sadasivam/ class=align-middle>Sesh Sadasivam</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rui-zhang/ class=align-middle>Rui Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dragomir-radev/ class=align-middle>Dragomir Radev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sai-r-gouravajhala/ class=align-middle>Sai R. Gouravajhala</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vignesh-athreya/ class=align-middle>Vignesh Athreya</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jatin-ganhotra/ class=align-middle>Jatin Ganhotra</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/siva-sankalp-patel/ class=align-middle>Siva Sankalp Patel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lazaros-c-polymenakos/ class=align-middle>Lazaros C Polymenakos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>