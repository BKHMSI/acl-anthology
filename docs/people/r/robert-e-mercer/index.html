<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Robert E. Mercer - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Robert E.</span> <span class=font-weight-bold>Mercer</span></h2><p class="font-weight-light text-muted">Univ. of Western Ontario</p><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Robert <span class=font-weight-normal>Mercer</span></p><p class="font-weight-light text-muted"><span class=font-italic>Other people with similar names:</span>
<a href=/people/r/robert-l-mercer/>Robert L. Mercer</a>
(IBM)</p><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.210.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--210 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.210 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.acl-long.210" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.210/><span class=acl-fixed-case>K</span>en<span class=acl-fixed-case>M</span>e<span class=acl-fixed-case>SH</span>: Knowledge-enhanced End-to-end Biomedical Text Labelling</a></strong><br><a href=/people/x/xindi-wang/>Xindi Wang</a>
|
<a href=/people/r/robert-e-mercer/>Robert Mercer</a>
|
<a href=/people/f/frank-rudzicz/>Frank Rudzicz</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--210><div class="card-body p-3 small">Currently, Medical Subject Headings (MeSH) are manually assigned to every biomedical article published and subsequently recorded in the PubMed database to facilitate retrieving relevant information. With the rapid growth of the PubMed database, large-scale biomedical document indexing becomes increasingly important. MeSH indexing is a challenging task for machine learning, as it needs to assign multiple labels to each article from an extremely large hierachically organized collection. To address this challenge, we propose KenMeSH, an end-to-end model that combines new text features and a dynamic knowledge-enhanced mask attention that integrates document features with MeSH label hierarchy and journal correlation features to index MeSH terms. Experimental results show the proposed method achieves state-of-the-art performance on a number of measures.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.380.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--380 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.380 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.380/>A Lexicon-Based Approach for Detecting Hedges in Informal Text</a></strong><br><a href=/people/j/jumayel-islam/>Jumayel Islam</a>
|
<a href=/people/l/lu-xiao/>Lu Xiao</a>
|
<a href=/people/r/robert-e-mercer/>Robert E. Mercer</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--380><div class="card-body p-3 small">Hedging is a commonly used strategy in conversational management to show the speaker&#8217;s lack of commitment to what they communicate, which may signal problems between the speakers. Our project is interested in examining the presence of hedging words and phrases in identifying the tension between an interviewer and interviewee during a survivor interview. While there have been studies on hedging detection in the natural language processing literature, all existing work has focused on <a href=https://en.wikipedia.org/wiki/Structured_text>structured texts</a> and formal communications. Our project thus investigated a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of eight <a href=https://en.wikipedia.org/wiki/Unstructured_interview>unstructured conversational interviews</a> about the <a href=https://en.wikipedia.org/wiki/Rwandan_genocide>Rwanda Genocide</a> and identified <a href=https://en.wikipedia.org/wiki/Hedge>hedging patterns</a> in the interviewees&#8217; responses. Our work produced three manually constructed lists of hedge words, booster words, and hedging phrases. Leveraging these <a href=https://en.wikipedia.org/wiki/Lexicon>lexicons</a>, we developed a rule-based algorithm that detects sentence-level hedges in informal conversations such as survivor interviews. Our work also produced a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 3000 sentences having the categories Hedge and Non-hedge annotated by three researchers. With experiments on this annotated dataset, we verify the efficacy of our proposed <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a>. Our work contributes to the further development of tools that identify <a href=https://en.wikipedia.org/wiki/Hedge_(finance)>hedges</a> from informal conversations and discussions.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1137.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1137 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1137 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-1137/>Multi-Channel Convolutional Neural Network for Twitter Emotion and Sentiment Recognition<span class=acl-fixed-case>T</span>witter Emotion and Sentiment Recognition</a></strong><br><a href=/people/j/jumayel-islam/>Jumayel Islam</a>
|
<a href=/people/r/robert-e-mercer/>Robert E. Mercer</a>
|
<a href=/people/l/lu-xiao/>Lu Xiao</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1137><div class="card-body p-3 small">The advent of micro-blogging sites has paved the way for researchers to collect and analyze huge volumes of data in recent years. Twitter, being one of the leading social networking sites worldwide, provides a great opportunity to its users for expressing their states of mind via short messages which are called <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>. The urgency of identifying emotions and sentiments conveyed through <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> has led to several research works. It provides a great way to understand <a href=https://en.wikipedia.org/wiki/Human_psychology>human psychology</a> and impose a challenge to researchers to analyze their content easily. In this paper, we propose a novel use of a multi-channel convolutional neural architecture which can effectively use different emotion and sentiment indicators such as <a href=https://en.wikipedia.org/wiki/Hashtag>hashtags</a>, <a href=https://en.wikipedia.org/wiki/Emoticon>emoticons</a> and <a href=https://en.wikipedia.org/wiki/Emoji>emojis</a> that are present in the <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> and improve the performance of emotion and sentiment identification. We also investigate the incorporation of different lexical features in the <a href=https://en.wikipedia.org/wiki/Neural_network>neural network model</a> and its effect on the emotion and sentiment identification task. We analyze our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on some standard datasets and compare its effectiveness with existing techniques.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1030.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1030 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1030 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384000960 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1030/>You Only Need Attention to Traverse Trees</a></strong><br><a href=/people/m/mahtab-ahmed/>Mahtab Ahmed</a>
|
<a href=/people/m/muhammad-rifayat-samee/>Muhammad Rifayat Samee</a>
|
<a href=/people/r/robert-e-mercer/>Robert E. Mercer</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1030><div class="card-body p-3 small">In recent NLP research, a topic of interest is universal sentence encoding, sentence representations that can be used in any <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised task</a>. At the word sequence level, fully attention-based models suffer from two problems : a quadratic increase in memory consumption with respect to the <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence length</a> and an inability to capture and use <a href=https://en.wikipedia.org/wiki/Syntax>syntactic information</a>. Recursive neural nets can extract very good <a href=https://en.wikipedia.org/wiki/Syntax>syntactic information</a> by traversing a <a href=https://en.wikipedia.org/wiki/Tree_(graph_theory)>tree structure</a>. To this end, we propose Tree Transformer, a model that captures phrase level syntax for constituency trees as well as word-level dependencies for dependency trees by doing recursive traversal only with <a href=https://en.wikipedia.org/wiki/Attention>attention</a>. Evaluation of this model on four tasks gets noteworthy results compared to the standard transformer and LSTM-based models as well as tree-structured LSTMs. Ablation studies to find whether positional information is inherently encoded in the <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>trees</a> and which type of <a href=https://en.wikipedia.org/wiki/Attention>attention</a> is suitable for doing the recursive traversal are provided.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Robert+E.+Mercer" title="Search for 'Robert E. Mercer' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/j/jumayel-islam/ class=align-middle>Jumayel Islam</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/lu-xiao/ class=align-middle>Lu Xiao</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/x/xindi-wang/ class=align-middle>Xindi Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/frank-rudzicz/ class=align-middle>Frank Rudzicz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mahtab-ahmed/ class=align-middle>Mahtab Ahmed</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/m/muhammad-rifayat-samee/ class=align-middle>Muhammad Rifayat Samee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>