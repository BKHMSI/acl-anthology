<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Ranit Aharonov - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Ranit</span> <span class=font-weight-bold>Aharonov</span></h2><hr><div class=row><div class=col-lg-9><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.633.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--633 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.633 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928964 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.633/>Out of the Echo Chamber : Detecting Countering Debate Speeches<span class=acl-fixed-case>D</span>etecting Countering Debate Speeches</a></strong><br><a href=/people/m/matan-orbach/>Matan Orbach</a>
|
<a href=/people/y/yonatan-bilu/>Yonatan Bilu</a>
|
<a href=/people/a/assaf-toledo/>Assaf Toledo</a>
|
<a href=/people/d/dan-lahav/>Dan Lahav</a>
|
<a href=/people/m/michal-jacovi/>Michal Jacovi</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--633><div class="card-body p-3 small">An educated and informed consumption of media content has become a challenge in modern times. With the shift from traditional news outlets to <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> and similar venues, a major concern is that readers are becoming encapsulated in echo chambers and may fall prey to fake news and disinformation, lacking easy access to dissenting views. We suggest a novel task aiming to alleviate some of these concerns that of detecting articles that most effectively counter the arguments and not just the stance made in a given text. We study this <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> in the context of <a href=https://en.wikipedia.org/wiki/Public_speaking>debate speeches</a>. Given such a <a href=https://en.wikipedia.org/wiki/Public_speaking>speech</a>, we aim to identify, from among a set of <a href=https://en.wikipedia.org/wiki/Public_speaking>speeches</a> on the same topic and with an opposing stance, the ones that directly counter it. We provide a large dataset of 3,685 such speeches (in English), annotated for this relation, which hopefully would be of general interest to the NLP community. We explore several <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> addressing this task, and while some are successful, all fall short of expert human performance, suggesting room for further research. All data collected during this work is freely available for research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.aacl-main.46.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--aacl-main--46 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.aacl-main.46 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.aacl-main.46/>A Survey of the State of Explainable AI for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a><span class=acl-fixed-case>AI</span> for Natural Language Processing</a></strong><br><a href=/people/m/marina-danilevsky/>Marina Danilevsky</a>
|
<a href=/people/k/kun-qian/>Kun Qian</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/y/yannis-katsis/>Yannis Katsis</a>
|
<a href=/people/b/ban-kawas/>Ban Kawas</a>
|
<a href=/people/p/prithviraj-sen/>Prithviraj Sen</a><br><a href=/volumes/2020.aacl-main/ class=text-muted>Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--aacl-main--46><div class="card-body p-3 small">Recent years have seen important advances in the quality of state-of-the-art models, but this has come at the expense of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> becoming less interpretable. This survey presents an overview of the current state of Explainable AI (XAI), considered within the domain of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing (NLP)</a>. We discuss the main categorization of explanations, as well as the various ways explanations can be arrived at and visualized. We detail the operations and explainability techniques currently available for generating explanations for NLP model predictions, to serve as a resource for model developers in the community. Finally, we point out the current gaps and encourage directions for future work in this important research area.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.243.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--243 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.243 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.findings-emnlp.243.OptionalSupplementaryMaterial.txt data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.243/>Unsupervised Expressive Rules Provide Explainability and Assist Human Experts Grasping New Domains</a></strong><br><a href=/people/e/eyal-shnarch/>Eyal Shnarch</a>
|
<a href=/people/l/leshem-choshen/>Leshem Choshen</a>
|
<a href=/people/g/guy-moshkowich/>Guy Moshkowich</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--243><div class="card-body p-3 small">Approaching new data can be quite deterrent ; you do not know how your categories of interest are realized in it, commonly, there is no labeled data at hand, and the performance of domain adaptation methods is unsatisfactory. Aiming to assist domain experts in their first steps into a new task over a new corpus, we present an unsupervised approach to reveal complex rules which cluster the unexplored corpus by its prominent categories (or facets). These <a href=https://en.wikipedia.org/wiki/Rule_of_inference>rules</a> are human-readable, thus providing an important ingredient which has become in short supply lately-explainability. Each <a href=https://en.wikipedia.org/wiki/Rule_of_inference>rule</a> provides an explanation for the commonality of all the texts it clusters together. The experts can then identify which <a href=https://en.wikipedia.org/wiki/Rule_of_inference>rules</a> best capture texts of their categories of interest, and utilize them to deepen their understanding of these categories. These rules can also bootstrap the process of data labeling by pointing at a subset of the corpus which is enriched with texts demonstrating the target categories. We present an extensive evaluation of the usefulness of these rules in identifying target categories, as well as a user study which assesses their interpretability.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1564.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1564 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1564 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1564.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-1564/>Automatic Argument Quality Assessment-New Datasets and Methods</a></strong><br><a href=/people/a/assaf-toledo/>Assaf Toledo</a>
|
<a href=/people/s/shai-gretz/>Shai Gretz</a>
|
<a href=/people/e/edo-cohen-karlik/>Edo Cohen-Karlik</a>
|
<a href=/people/r/roni-friedman/>Roni Friedman</a>
|
<a href=/people/e/elad-venezian/>Elad Venezian</a>
|
<a href=/people/d/dan-lahav/>Dan Lahav</a>
|
<a href=/people/m/michal-jacovi/>Michal Jacovi</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1564><div class="card-body p-3 small">We explore the task of automatic assessment of argument quality. To that end, we actively collected 6.3k arguments, more than a factor of five compared to previously examined data. Each argument was explicitly and carefully annotated for its quality. In addition, 14k pairs of arguments were annotated independently, identifying the higher quality argument in each pair. In spite of the inherent subjective nature of the task, both <a href=https://en.wikipedia.org/wiki/Annotation>annotation schemes</a> led to surprisingly consistent results. We release the labeled datasets to the community. Furthermore, we suggest <a href=https://en.wikipedia.org/wiki/Artificial_neural_network>neural methods</a> based on a recently released <a href=https://en.wikipedia.org/wiki/Language_model>language model</a>, for argument ranking as well as for argument-pair classification. In the former <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, our results are comparable to <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> ; in the latter <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> our results significantly outperform earlier <a href=https://en.wikipedia.org/wiki/Methodology>methods</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5905.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5905 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5905 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-5905.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-5905/>Crowd-sourcing annotation of complex NLU tasks : A case study of argumentative content annotation<span class=acl-fixed-case>NLU</span> tasks: A case study of argumentative content annotation</a></strong><br><a href=/people/t/tamar-lavee/>Tamar Lavee</a>
|
<a href=/people/l/lili-kotlerman/>Lili Kotlerman</a>
|
<a href=/people/m/matan-orbach/>Matan Orbach</a>
|
<a href=/people/y/yonatan-bilu/>Yonatan Bilu</a>
|
<a href=/people/m/michal-jacovi/>Michal Jacovi</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/D19-59/ class=text-muted>Proceedings of the First Workshop on Aggregating and Analysing Crowdsourced Annotations for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5905><div class="card-body p-3 small">Recent advancements in <a href=https://en.wikipedia.org/wiki/Machine_reading>machine reading</a> and listening comprehension involve the annotation of long texts. Such <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a> are typically time consuming, making crowd-annotations an attractive solution, yet their complexity often makes such a <a href=https://en.wikipedia.org/wiki/Solution>solution</a> unfeasible. In particular, a major concern is that crowd annotators may be tempted to skim through long texts, and answer questions without reading thoroughly. We present a case study of adapting this type of <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> to the crowd. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is to identify claims in a several minute long debate speech. We show that sentence-by-sentence annotation does not scale and that labeling only a subset of sentences is insufficient. Instead, we propose a scheme for effectively performing the full, complex task with crowd annotators, allowing the collection of large scale annotated datasets. We believe that the encountered challenges and pitfalls, as well as lessons learned, are relevant in general when collecting data for large scale natural language understanding (NLU) tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4507.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4507 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4507 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4507/>Towards Effective Rebuttal : <a href=https://en.wikipedia.org/wiki/Listening_comprehension>Listening Comprehension</a> Using Corpus-Wide Claim Mining</a></strong><br><a href=/people/t/tamar-lavee/>Tamar Lavee</a>
|
<a href=/people/m/matan-orbach/>Matan Orbach</a>
|
<a href=/people/l/lili-kotlerman/>Lili Kotlerman</a>
|
<a href=/people/y/yoav-kantor/>Yoav Kantor</a>
|
<a href=/people/s/shai-gretz/>Shai Gretz</a>
|
<a href=/people/l/lena-dankin/>Lena Dankin</a>
|
<a href=/people/m/michal-jacovi/>Michal Jacovi</a>
|
<a href=/people/y/yonatan-bilu/>Yonatan Bilu</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/W19-45/ class=text-muted>Proceedings of the 6th Workshop on Argument Mining</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4507><div class="card-body p-3 small">Engaging in a live debate requires, among other things, the ability to effectively rebut arguments claimed by your opponent. In particular, this requires identifying these arguments. Here, we suggest doing so by automatically mining claims from a corpus of news articles containing billions of sentences, and searching for them in a given speech. This raises the question of whether such claims indeed correspond to those made in spoken speeches. To this end, we collected a large dataset of 400 speeches in English discussing 200 controversial topics, mined claims for each topic, and asked annotators to identify the mined claims mentioned in each speech. Results show that in the vast majority of speeches debaters indeed make use of such claims. In addition, we present several <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> for the automatic detection of mined claims in <a href=https://en.wikipedia.org/wiki/Public_speaking>speeches</a>, forming the basis for future work. All collected data is freely available for research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1093.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1093 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1093 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384469154 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1093/>Are You Convinced? Choosing the More Convincing Evidence with a Siamese Network<span class=acl-fixed-case>S</span>iamese Network</a></strong><br><a href=/people/m/martin-gleize/>Martin Gleize</a>
|
<a href=/people/e/eyal-shnarch/>Eyal Shnarch</a>
|
<a href=/people/l/leshem-choshen/>Leshem Choshen</a>
|
<a href=/people/l/lena-dankin/>Lena Dankin</a>
|
<a href=/people/g/guy-moshkowich/>Guy Moshkowich</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1093><div class="card-body p-3 small">With the advancement in argument detection, we suggest to pay more attention to the challenging task of identifying the more convincing arguments. Machines capable of responding and interacting with humans in helpful ways have become ubiquitous. We now expect them to discuss with us the more delicate questions in our world, and they should do so armed with effective arguments. But what makes an argument more persuasive? What will convince you? In this paper, we present a new <a href=https://en.wikipedia.org/wiki/Data_set>data set</a>, IBM-EviConv, of pairs of evidence labeled for convincingness, designed to be more challenging than existing alternatives. We also propose a Siamese neural network architecture shown to outperform several baselines on both a prior convincingness data set and our own. Finally, we provide insights into our experimental results and the various kinds of argumentative value our method is capable of detecting.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1094.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1094 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1094 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384469239 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1094/>From Surrogacy to Adoption ; From <a href=https://en.wikipedia.org/wiki/Bitcoin>Bitcoin</a> to <a href=https://en.wikipedia.org/wiki/Cryptocurrency>Cryptocurrency</a> : Debate Topic Expansion</a></strong><br><a href=/people/r/roy-bar-haim/>Roy Bar-Haim</a>
|
<a href=/people/d/dalia-krieger/>Dalia Krieger</a>
|
<a href=/people/o/orith-toledo-ronen/>Orith Toledo-Ronen</a>
|
<a href=/people/l/lilach-edelstein/>Lilach Edelstein</a>
|
<a href=/people/y/yonatan-bilu/>Yonatan Bilu</a>
|
<a href=/people/a/alon-halfon/>Alon Halfon</a>
|
<a href=/people/y/yoav-katz/>Yoav Katz</a>
|
<a href=/people/a/amir-menczel/>Amir Menczel</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1094><div class="card-body p-3 small">When debating a controversial topic, it is often desirable to expand the boundaries of discussion. For example, we may consider the pros and cons of possible alternatives to the debate topic, make generalizations, or give specific examples. We introduce the task of Debate Topic Expansion-finding such related topics for a given debate topic, along with a novel annotated dataset for the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. We focus on relations between Wikipedia concepts, and show that they differ from well-studied lexical-semantic relations such as <a href=https://en.wikipedia.org/wiki/Hypernymy>hypernyms</a>, <a href=https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy>hyponyms</a> and <a href=https://en.wikipedia.org/wiki/Opposite_(semantics)>antonyms</a>. We present <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> for finding both consistent and contrastive expansions and demonstrate their effectiveness empirically. We suggest that debate topic expansion may have various use cases in argumentation mining.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5200.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5200/>Proceedings of the 5th Workshop on Argument Mining</a></strong><br><a href=/people/n/noam-slonim/>Noam Slonim</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a><br><a href=/volumes/W18-52/ class=text-muted>Proceedings of the 5th Workshop on Argument Mining</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-2095.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-2095 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-2095 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-2095.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-2095/>Will it Blend? Blending Weak and Strong Labeled Data in a <a href=https://en.wikipedia.org/wiki/Neural_network>Neural Network</a> for Argumentation Mining</a></strong><br><a href=/people/e/eyal-shnarch/>Eyal Shnarch</a>
|
<a href=/people/c/carlos-alzate/>Carlos Alzate</a>
|
<a href=/people/l/lena-dankin/>Lena Dankin</a>
|
<a href=/people/m/martin-gleize/>Martin Gleize</a>
|
<a href=/people/y/yufang-hou/>Yufang Hou</a>
|
<a href=/people/l/leshem-choshen/>Leshem Choshen</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/P18-2/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-2095><div class="card-body p-3 small">The process of obtaining high quality <a href=https://en.wikipedia.org/wiki/Labeled_data>labeled data</a> for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding tasks</a> is often slow, error-prone, complicated and expensive. With the vast usage of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>, this issue becomes more notorious since these networks require a large amount of labeled data to produce satisfactory results. We propose a <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> to blend high quality but scarce strong labeled data with noisy but abundant weak labeled data during the training of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>. Experiments in the context of topic-dependent evidence detection with two forms of weak labeled data show the advantages of the blending scheme. In addition, we provide a manually annotated data set for the task of topic-dependent evidence detection. We believe that blending weak and strong labeled data is a general notion that may be applicable to many language understanding tasks, and can especially assist researchers who wish to train a <a href=https://en.wikipedia.org/wiki/Computer_network>network</a> but have a small amount of high quality <a href=https://en.wikipedia.org/wiki/Labeled_data>labeled data</a> for their task of interest.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5110.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5110 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5110 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-5110.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W17-5110/>Unsupervised corpuswide claim detection</a></strong><br><a href=/people/r/ran-levy/>Ran Levy</a>
|
<a href=/people/s/shai-gretz/>Shai Gretz</a>
|
<a href=/people/b/benjamin-sznajder/>Benjamin Sznajder</a>
|
<a href=/people/s/shay-hummel/>Shay Hummel</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/W17-51/ class=text-muted>Proceedings of the 4th Workshop on Argument Mining</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5110><div class="card-body p-3 small">Automatic claim detection is a fundamental argument mining task that aims to automatically mine claims regarding a topic of consideration. Previous works on mining argumentative content have assumed that a set of relevant documents is given in advance. Here, we present a first corpus wide claim detection framework, that can be directly applied to massive corpora. Using simple and intuitive empirical observations, we derive a claim sentence query by which we are able to directly retrieve sentences in which the <a href=https://en.wikipedia.org/wiki/Prior_probability>prior probability</a> to include topic-relevant claims is greatly enhanced. Next, we employ simple <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a> to rank the sentences, leading to an unsupervised corpuswide claim detection system, with precision that outperforms previously reported results on the task of claim detection given relevant documents and labeled data.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Ranit+Aharonov" title="Search for 'Ranit Aharonov' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/n/noam-slonim/ class=align-middle>Noam Slonim</a>
<span class="badge badge-secondary align-middle ml-2">10</span></li><li class=list-group-item><a href=/people/y/yonatan-bilu/ class=align-middle>Yonatan Bilu</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/m/michal-jacovi/ class=align-middle>Michal Jacovi</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/m/matan-orbach/ class=align-middle>Matan Orbach</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/shai-gretz/ class=align-middle>Shai Gretz</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/e/eyal-shnarch/ class=align-middle>Eyal Shnarch</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/leshem-choshen/ class=align-middle>Leshem Choshen</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/lena-dankin/ class=align-middle>Lena Dankin</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/assaf-toledo/ class=align-middle>Assaf Toledo</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/dan-lahav/ class=align-middle>Dan Lahav</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/tamar-lavee/ class=align-middle>Tamar Lavee</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/lili-kotlerman/ class=align-middle>Lili Kotlerman</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/g/guy-moshkowich/ class=align-middle>Guy Moshkowich</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/martin-gleize/ class=align-middle>Martin Gleize</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/ran-levy/ class=align-middle>Ran Levy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/benjamin-sznajder/ class=align-middle>Benjamin Sznajder</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shay-hummel/ class=align-middle>Shay Hummel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marina-danilevsky/ class=align-middle>Marina Danilevsky</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kun-qian/ class=align-middle>Kun Qian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yannis-katsis/ class=align-middle>Yannis Katsis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/ban-kawas/ class=align-middle>Ban Kawas</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/prithviraj-sen/ class=align-middle>Prithviraj Sen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/edo-cohen-karlik/ class=align-middle>Edo Cohen-Karlik</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/roni-friedman/ class=align-middle>Roni Friedman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elad-venezian/ class=align-middle>Elad Venezian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yoav-kantor/ class=align-middle>Yoav Kantor</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/carlos-alzate/ class=align-middle>Carlos Alzate</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yufang-hou/ class=align-middle>Yufang Hou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/roy-bar-haim/ class=align-middle>Roy Bar-Haim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dalia-krieger/ class=align-middle>Dalia Krieger</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/orith-toledo-ronen/ class=align-middle>Orith Toledo-Ronen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lilach-edelstein/ class=align-middle>Lilach Edelstein</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alon-halfon/ class=align-middle>Alon Halfon</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yoav-katz/ class=align-middle>Yoav Katz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/amir-menczel/ class=align-middle>Amir Menczel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/aacl/ class=align-middle>AACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>