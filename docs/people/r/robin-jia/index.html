<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Robin Jia - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Robin</span> <span class=font-weight-bold>Jia</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mrqa-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mrqa-1.0/>Proceedings of the 3rd Workshop on Machine Reading for Question Answering</a></strong><br><a href=/people/a/adam-fisch/>Adam Fisch</a>
|
<a href=/people/a/alon-talmor/>Alon Talmor</a>
|
<a href=/people/d/danqi-chen/>Danqi Chen</a>
|
<a href=/people/e/eunsol-choi/>Eunsol Choi</a>
|
<a href=/people/m/minjoon-seo/>Minjoon Seo</a>
|
<a href=/people/p/patrick-lewis/>Patrick Lewis</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/s/sewon-min/>Sewon Min</a><br><a href=/volumes/2021.mrqa-1/ class=text-muted>Proceedings of the 3rd Workshop on Machine Reading for Question Answering</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.230.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--230 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.230 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.230/>Masked Language Modeling and the Distributional Hypothesis : Order Word Matters Pre-training for Little</a></strong><br><a href=/people/k/koustuv-sinha/>Koustuv Sinha</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/d/dieuwke-hupkes/>Dieuwke Hupkes</a>
|
<a href=/people/j/joelle-pineau/>Joelle Pineau</a>
|
<a href=/people/a/adina-williams/>Adina Williams</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--230><div class="card-body p-3 small">A possible explanation for the impressive performance of masked language model (MLM) pre-training is that such models have learned to represent the syntactic structures prevalent in classical NLP pipelines. In this paper, we propose a different explanation : MLMs succeed on downstream tasks almost entirely due to their ability to model higher-order word co-occurrence statistics. To demonstrate this, we pre-train MLMs on sentences with randomly shuffled word order, and show that these models still achieve high <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> after fine-tuning on many downstream tasksincluding tasks specifically designed to be challenging for models that ignore <a href=https://en.wikipedia.org/wiki/Word_order>word order</a>. Our models perform surprisingly well according to some parametric syntactic probes, indicating possible deficiencies in how we test representations for syntactic information. Overall, our results show that purely distributional information largely explains the success of pre-training, and underscore the importance of curating challenging evaluation datasets that require deeper linguistic knowledge.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.696.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--696 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.696 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.696/>Improving Question Answering Model Robustness with Synthetic Adversarial Data Generation</a></strong><br><a href=/people/m/max-bartolo/>Max Bartolo</a>
|
<a href=/people/t/tristan-thrush/>Tristan Thrush</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/s/sebastian-riedel/>Sebastian Riedel</a>
|
<a href=/people/p/pontus-stenetorp/>Pontus Stenetorp</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--696><div class="card-body p-3 small">Despite recent progress, state-of-the-art question answering models remain vulnerable to a variety of <a href=https://en.wikipedia.org/wiki/Adversarial_system>adversarial attacks</a>. While dynamic adversarial data collection, in which a human annotator tries to write examples that fool a model-in-the-loop, can improve model robustness, this process is expensive which limits the scale of the collected data. In this work, we are the first to use synthetic adversarial data generation to make <a href=https://en.wikipedia.org/wiki/Question_answering>question answering models</a> more robust to <a href=https://en.wikipedia.org/wiki/Adversarial_system>human adversaries</a>. We develop a data generation pipeline that selects source passages, identifies candidate answers, generates questions, then finally filters or re-labels them to improve <a href=https://en.wikipedia.org/wiki/Quality_(business)>quality</a>. Using this approach, we amplify a smaller human-written adversarial dataset to a much larger set of synthetic question-answer pairs. By incorporating our synthetic data, we improve the state-of-the-art on the AdversarialQA dataset by 3.7F1 and improve model generalisation on nine of the twelve MRQA datasets. We further conduct a novel human-in-the-loop evaluation and show that our models are considerably more robust to new human-written adversarial examples : crowdworkers can fool our <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> only 8.8 % of the time on average, compared to 17.6 % for a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> trained without synthetic data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-tutorials.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-tutorials--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-tutorials.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-tutorials.5/>Robustness and Adversarial Examples in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a></a></strong><br><a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/h/he-he/>He He</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a><br><a href=/volumes/2021.emnlp-tutorials/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-tutorials--5><div class="card-body p-3 small">Recent studies show that many NLP systems are sensitive and vulnerable to a small perturbation of inputs and do not generalize well across different datasets. This lack of <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> derails the use of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP systems</a> in real-world applications. This tutorial aims at bringing awareness of practical concerns about NLP robustness. It targets NLP researchers and practitioners who are interested in building reliable NLP systems. In particular, we will review recent studies on analyzing the weakness of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP systems</a> when facing adversarial inputs and data with a <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distribution shift</a>. We will provide the audience with a holistic view of 1) how to use adversarial examples to examine the weakness of NLP models and facilitate <a href=https://en.wikipedia.org/wiki/Debugging>debugging</a> ; 2) how to enhance the <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> of existing NLP models and defense against adversarial inputs ; and 3) how the consideration of <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> affects the real-world NLP applications used in our daily lives. We will conclude the tutorial by outlining future research directions in this area.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.324.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--324 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.324 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.324/>Dynabench : Rethinking Benchmarking in NLP<span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/m/max-bartolo/>Max Bartolo</a>
|
<a href=/people/y/yixin-nie/>Yixin Nie</a>
|
<a href=/people/d/divyansh-kaushik/>Divyansh Kaushik</a>
|
<a href=/people/a/atticus-geiger/>Atticus Geiger</a>
|
<a href=/people/z/zhengxuan-wu/>Zhengxuan Wu</a>
|
<a href=/people/b/bertie-vidgen/>Bertie Vidgen</a>
|
<a href=/people/g/grusha-prasad/>Grusha Prasad</a>
|
<a href=/people/a/amanpreet-singh/>Amanpreet Singh</a>
|
<a href=/people/p/pratik-ringshia/>Pratik Ringshia</a>
|
<a href=/people/z/zhiyi-ma/>Zhiyi Ma</a>
|
<a href=/people/t/tristan-thrush/>Tristan Thrush</a>
|
<a href=/people/s/sebastian-riedel/>Sebastian Riedel</a>
|
<a href=/people/z/zeerak-waseem/>Zeerak Waseem</a>
|
<a href=/people/p/pontus-stenetorp/>Pontus Stenetorp</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a>
|
<a href=/people/c/christopher-potts/>Christopher Potts</a>
|
<a href=/people/a/adina-williams/>Adina Williams</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--324><div class="card-body p-3 small">We introduce Dynabench, an open-source platform for dynamic dataset creation and model benchmarking. Dynabench runs in a web browser and supports human-and-model-in-the-loop dataset creation : annotators seek to create examples that a target model will misclassify, but that another person will not. In this paper, we argue that Dynabench addresses a critical need in our community : contemporary models quickly achieve outstanding performance on benchmark tasks but nonetheless fail on simple challenge examples and falter in real-world scenarios. With Dynabench, dataset creation, model development, and model assessment can directly inform each other, leading to more robust and informative benchmarks. We report on four initial NLP tasks, illustrating these concepts and highlighting the promise of the <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a>, and address potential objections to dynamic benchmarking as a new standard for the field.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.503.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--503 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.503 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929409 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.503" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.503/>Selective Question Answering under Domain Shift</a></strong><br><a href=/people/a/amita-kamath/>Amita Kamath</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/p/percy-liang/>Percy Liang</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--503><div class="card-body p-3 small">To avoid giving wrong answers, question answering (QA) models need to know when to abstain from answering. Moreover, users often ask questions that diverge from the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>&#8217;s training data, making errors more likely and thus abstention more critical. In this work, we propose the setting of selective question answering under domain shift, in which a QA model is tested on a mixture of in-domain and out-of-domain data, and must answer (i.e., not abstain on) as many questions as possible while maintaining high accuracy. Abstention policies based solely on the model&#8217;s softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a <a href=https://en.wikipedia.org/wiki/Calibration>calibrator</a> to identify inputs on which the <a href=https://en.wikipedia.org/wiki/Quantitative_analysis_(finance)>QA model</a> errs, and abstain when it predicts an error is likely. Crucially, the calibrator benefits from observing the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s behavior on out-of-domain data, even if from a different domain than the test data. We combine this method with a SQuAD-trained QA model and evaluate on mixtures of SQuAD and five other QA datasets. Our method answers 56 % of questions while maintaining 80 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> ; in contrast, directly using the model&#8217;s probabilities only answers 48 % at 80 % accuracy.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.305.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--305 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.305 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.findings-emnlp.305" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.305/>On the Importance of Adaptive Data Collection for Extremely Imbalanced Pairwise Tasks<span class=acl-fixed-case>O</span>n the <span class=acl-fixed-case>I</span>mportance of <span class=acl-fixed-case>A</span>daptive <span class=acl-fixed-case>D</span>ata <span class=acl-fixed-case>C</span>ollection for <span class=acl-fixed-case>E</span>xtremely <span class=acl-fixed-case>I</span>mbalanced <span class=acl-fixed-case>P</span>airwise <span class=acl-fixed-case>T</span>asks</a></strong><br><a href=/people/s/stephen-mussmann/>Stephen Mussmann</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/p/percy-liang/>Percy Liang</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--305><div class="card-body p-3 small">Many pairwise classification tasks, such as <a href=https://en.wikipedia.org/wiki/Paraphrase_detection>paraphrase detection</a> and <a href=https://en.wikipedia.org/wiki/Open-domain_question_answering>open-domain question answering</a>, naturally have extreme label imbalance (e.g., 99.99 % of examples are negatives). In contrast, many recent <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> heuristically choose examples to ensure label balance. We show that these heuristics lead to trained <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that generalize poorly : State-of-the art <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> trained on <a href=https://en.wikipedia.org/wiki/QQP>QQP</a> and WikiQA each have only 2.4 % average precision when evaluated on realistically imbalanced test data. We instead collect training data with <a href=https://en.wikipedia.org/wiki/Active_learning_(machine_learning)>active learning</a>, using a BERT-based embedding model to efficiently retrieve uncertain points from a very large pool of unlabeled utterance pairs. By creating balanced training data with more informative negative examples, <a href=https://en.wikipedia.org/wiki/Active_learning>active learning</a> greatly improves <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>average precision</a> to 32.5 % on <a href=https://en.wikipedia.org/wiki/QQP>QQP</a> and 20.1 % on WikiQA.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1423.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1423 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1423 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1423.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1423" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1423/>Certified Robustness to Adversarial Word Substitutions</a></strong><br><a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/a/aditi-raghunathan/>Aditi Raghunathan</a>
|
<a href=/people/k/kerem-goksel/>Kerem Göksel</a>
|
<a href=/people/p/percy-liang/>Percy Liang</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1423><div class="card-body p-3 small">State-of-the-art <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP models</a> can often be fooled by adversaries that apply seemingly innocuous label-preserving transformations (e.g., <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrasing</a>) to input text. The number of possible <a href=https://en.wikipedia.org/wiki/Transformation_(function)>transformations</a> scales exponentially with text length, so <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> can not cover all <a href=https://en.wikipedia.org/wiki/Transformation_(function)>transformations</a> of an input. This paper considers one exponentially large family of label-preserving transformations, in which every word in the input can be replaced with a similar word. We train the first <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that are provably robust to all word substitutions in this family. Our training procedure uses Interval Bound Propagation (IBP) to minimize an upper bound on the worst-case loss that any combination of word substitutions can induce. To evaluate models&#8217; robustness to these transformations, we measure <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on adversarially chosen word substitutions applied to test examples. Our IBP-trained models attain 75 % adversarial accuracy on both <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> on <a href=https://en.wikipedia.org/wiki/IMDB>IMDB</a> and natural language inference on SNLI ; in comparison, on <a href=https://en.wikipedia.org/wiki/IMDB>IMDB</a>, models trained normally and ones trained with data augmentation achieve adversarial accuracy of only 12 % and 41 %, respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5800.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5800/>Proceedings of the 2nd Workshop on Machine Reading for Question Answering</a></strong><br><a href=/people/a/adam-fisch/>Adam Fisch</a>
|
<a href=/people/a/alon-talmor/>Alon Talmor</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/m/minjoon-seo/>Minjoon Seo</a>
|
<a href=/people/e/eunsol-choi/>Eunsol Choi</a>
|
<a href=/people/d/danqi-chen/>Danqi Chen</a><br><a href=/volumes/D19-58/ class=text-muted>Proceedings of the 2nd Workshop on Machine Reading for Question Answering</a></span></p><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-2600.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-2600/>Proceedings of the Workshop on Machine Reading for Question Answering</a></strong><br><a href=/people/e/eunsol-choi/>Eunsol Choi</a>
|
<a href=/people/m/minjoon-seo/>Minjoon Seo</a>
|
<a href=/people/d/danqi-chen/>Danqi Chen</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/j/jonathan-berant/>Jonathan Berant</a><br><a href=/volumes/W18-26/ class=text-muted>Proceedings of the Workshop on Machine Reading for Question Answering</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1169.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1169 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1169 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1169.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277673818 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1169" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1169/>Delete, Retrieve, Generate : a Simple Approach to Sentiment and Style Transfer</a></strong><br><a href=/people/j/juncen-li/>Juncen Li</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/h/he-he/>He He</a>
|
<a href=/people/p/percy-liang/>Percy Liang</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1169><div class="card-body p-3 small">We consider the task of text attribute transfer : transforming a sentence to alter a specific attribute (e.g., sentiment) while preserving its <a href=https://en.wikipedia.org/wiki/Content_(media)>attribute-independent content</a> (e.g., screen is just the right size to screen is too small). Our training data includes only sentences labeled with their attribute (e.g., positive and negative), but not pairs of sentences that only differ in the attributes, so we must learn to disentangle <a href=https://en.wikipedia.org/wiki/Attribute_(computing)>attributes</a> from attribute-independent content in an unsupervised way. Previous work using <a href=https://en.wikipedia.org/wiki/Adversarial_system>adversarial methods</a> has struggled to produce high-quality outputs. In this paper, we propose simpler <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> motivated by the observation that <a href=https://en.wikipedia.org/wiki/Attribute_(computing)>text attributes</a> are often marked by distinctive phrases (e.g., too small). Our strongest method extracts content words by deleting phrases associated with the sentence&#8217;s original attribute value, retrieves new phrases associated with the target attribute, and uses a neural model to fluently combine these into a final output. Based on human evaluation, our best method generates grammatical and appropriate responses on 22 % more inputs than the best previous system, averaged over three attribute transfer datasets : altering sentiment of reviews on <a href=https://en.wikipedia.org/wiki/Yelp>Yelp</a>, altering sentiment of reviews on <a href=https://en.wikipedia.org/wiki/Amazon_(company)>Amazon</a>, and altering image captions to be more romantic or humorous.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1215.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1215 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1215 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238231419 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D17-1215" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1215/>Adversarial Examples for Evaluating Reading Comprehension Systems</a></strong><br><a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/p/percy-liang/>Percy Liang</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1215><div class="card-body p-3 small">Standard accuracy metrics indicate that <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension systems</a> are making rapid progress, but the extent to which these <a href=https://en.wikipedia.org/wiki/System>systems</a> truly understand <a href=https://en.wikipedia.org/wiki/Language>language</a> remains unclear. To reward systems with real language understanding abilities, we propose an adversarial evaluation scheme for the Stanford Question Answering Dataset (SQuAD). Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences, which are automatically generated to distract computer systems without changing the correct answer or misleading humans. In this adversarial setting, the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of sixteen published <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> drops from an average of 75 % F1 score to 36 % ; when the adversary is allowed to add ungrammatical sequences of words, average accuracy on four models decreases further to 7 %. We hope our insights will motivate the development of new <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that understand language more precisely.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Robin+Jia" title="Search for 'Robin Jia' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/p/percy-liang/ class=align-middle>Percy Liang</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/d/danqi-chen/ class=align-middle>Danqi Chen</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/e/eunsol-choi/ class=align-middle>Eunsol Choi</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/minjoon-seo/ class=align-middle>Minjoon Seo</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/d/douwe-kiela/ class=align-middle>Douwe Kiela</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/a/adam-fisch/ class=align-middle>Adam Fisch</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/alon-talmor/ class=align-middle>Alon Talmor</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/adina-williams/ class=align-middle>Adina Williams</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/max-bartolo/ class=align-middle>Max Bartolo</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/tristan-thrush/ class=align-middle>Tristan Thrush</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sebastian-riedel/ class=align-middle>Sebastian Riedel</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/pontus-stenetorp/ class=align-middle>Pontus Stenetorp</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/he-he/ class=align-middle>He He</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/patrick-lewis/ class=align-middle>Patrick Lewis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sewon-min/ class=align-middle>Sewon Min</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/amita-kamath/ class=align-middle>Amita Kamath</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/koustuv-sinha/ class=align-middle>Koustuv Sinha</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dieuwke-hupkes/ class=align-middle>Dieuwke Hupkes</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joelle-pineau/ class=align-middle>Joelle Pineau</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kai-wei-chang/ class=align-middle>Kai-Wei Chang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sameer-singh/ class=align-middle>Sameer Singh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aditi-raghunathan/ class=align-middle>Aditi Raghunathan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kerem-goksel/ class=align-middle>Kerem Göksel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yixin-nie/ class=align-middle>Yixin Nie</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/divyansh-kaushik/ class=align-middle>Divyansh Kaushik</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/atticus-geiger/ class=align-middle>Atticus Geiger</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhengxuan-wu/ class=align-middle>Zhengxuan Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bertie-vidgen/ class=align-middle>Bertie Vidgen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/grusha-prasad/ class=align-middle>Grusha Prasad</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/amanpreet-singh/ class=align-middle>Amanpreet Singh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pratik-ringshia/ class=align-middle>Pratik Ringshia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhiyi-ma/ class=align-middle>Zhiyi Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zeerak-waseem/ class=align-middle>Zeerak Waseem</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mohit-bansal/ class=align-middle>Mohit Bansal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christopher-potts/ class=align-middle>Christopher Potts</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stephen-mussmann/ class=align-middle>Stephen Mussmann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jonathan-berant/ class=align-middle>Jonathan Berant</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/juncen-li/ class=align-middle>Juncen Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/mrqa/ class=align-middle>MRQA</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>