<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Ramón Fernandez Astudillo - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Ramón</span> <span class=font-weight-bold>Fernandez Astudillo</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Ramon <span class=font-weight-normal>F. Astudillo</span>,
Ramón <span class=font-weight-normal>Astudillo</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.289.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--289 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.289 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.289" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.289/>Structural Guidance for Transformer Language Models</a></strong><br><a href=/people/p/peng-qian/>Peng Qian</a>
|
<a href=/people/t/tahira-naseem/>Tahira Naseem</a>
|
<a href=/people/r/roger-levy/>Roger Levy</a>
|
<a href=/people/r/ramon-fernandez-astudillo/>Ramón Fernandez Astudillo</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--289><div class="card-body p-3 small">Transformer-based language models pre-trained on large amounts of text data have proven remarkably successful in learning generic transferable linguistic representations. Here we study whether structural guidance leads to more human-like systematic linguistic generalization in Transformer language models without resorting to pre-training on very large amounts of data. We explore two general ideas. The Generative Parsing idea jointly models the incremental parse and word sequence as part of the same sequence modeling task. The Structural Scaffold idea guides the language model&#8217;s representation via additional structure loss that separately predicts the incremental constituency parse. We train the proposed models along with a vanilla Transformer language model baseline on a 14 million-token and a 46 million-token subset of the BLLIP dataset, and evaluate models&#8217; syntactic generalization performances on SG Test Suites and sized BLiMP. Experiment results across two benchmarks suggest converging evidence that generative structural supervisions can induce more robust and humanlike linguistic generalization in Transformer language models without the need for data intensive pre-training.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.167.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--167 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.167 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929147 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.167" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.167/>GPT-too : A Language-Model-First Approach for AMR-to-Text Generation<span class=acl-fixed-case>GPT</span>-too: A Language-Model-First Approach for <span class=acl-fixed-case>AMR</span>-to-Text Generation</a></strong><br><a href=/people/m/manuel-mager/>Manuel Mager</a>
|
<a href=/people/r/ramon-fernandez-astudillo/>Ramón Fernandez Astudillo</a>
|
<a href=/people/t/tahira-naseem/>Tahira Naseem</a>
|
<a href=/people/m/md-arafat-sultan/>Md Arafat Sultan</a>
|
<a href=/people/y/young-suk-lee/>Young-Suk Lee</a>
|
<a href=/people/r/radu-florian/>Radu Florian</a>
|
<a href=/people/s/salim-roukos/>Salim Roukos</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--167><div class="card-body p-3 small">Abstract Meaning Representations (AMRs) are broad-coverage sentence-level semantic graphs. Existing approaches to generating text from AMR have focused on training sequence-to-sequence or graph-to-sequence models on AMR annotated data only. In this paper, we propose an alternative approach that combines a strong pre-trained language model with cycle consistency-based re-scoring. Despite the simplicity of the approach, our experimental results show these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> outperform all previous techniques on the English LDC2017T10 dataset, including the recent use of transformer architectures. In addition to the standard evaluation metrics, we provide human evaluation experiments that further substantiate the strength of our approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.500.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--500 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.500 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929093 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.500/>On the Importance of Diversity in Question Generation for QA<span class=acl-fixed-case>QA</span></a></strong><br><a href=/people/m/md-arafat-sultan/>Md Arafat Sultan</a>
|
<a href=/people/s/shubham-chandel/>Shubham Chandel</a>
|
<a href=/people/r/ramon-fernandez-astudillo/>Ramón Fernandez Astudillo</a>
|
<a href=/people/v/vittorio-castelli/>Vittorio Castelli</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--500><div class="card-body p-3 small">Automatic question generation (QG) has shown promise as a source of <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>synthetic training data</a> for question answering (QA). In this paper we ask : Is textual diversity in QG beneficial for downstream QA? Using top-p nucleus sampling to derive samples from a transformer-based question generator, we show that diversity-promoting QG indeed provides better QA training than likelihood maximization approaches such as <a href=https://en.wikipedia.org/wiki/Beam_search>beam search</a>. We also show that standard QG evaluation metrics such as <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>, ROUGE and <a href=https://en.wikipedia.org/wiki/METEOR>METEOR</a> are inversely correlated with diversity, and propose a diversity-aware intrinsic measure of overall QG quality that correlates well with extrinsic evaluation on <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA</a>.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-2100.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-2100/>Proceedings of the <span class=acl-fixed-case>AMTA</span> 2018 Workshop on Translation Quality Estimation and Automatic Post-Editing</a></strong><br><a href=/people/r/ramon-fernandez-astudillo/>Ramón Astudillo</a>
|
<a href=/people/j/joao-graca/>João Graça</a>
|
<a href=/people/a/andre-f-t-martins/>André Martins</a><br><a href=/volumes/W18-21/ class=text-muted>Proceedings of the AMTA 2018 Workshop on Translation Quality Estimation and Automatic Post-Editing</a></span></p><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5048.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5048 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5048 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5048/>Fusion of Simple Models for Native Language Identification</a></strong><br><a href=/people/f/fabio-kepler/>Fabio Kepler</a>
|
<a href=/people/r/ramon-fernandez-astudillo/>Ramon F. Astudillo</a>
|
<a href=/people/a/alberto-abad/>Alberto Abad</a><br><a href=/volumes/W17-50/ class=text-muted>Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5048><div class="card-body p-3 small">In this paper we describe the approaches we explored for the 2017 Native Language Identification shared task. We focused on simple word and sub-word units avoiding heavy use of hand-crafted features. Following recent trends, we explored linear and neural networks models to attempt to compensate for the lack of rich feature use. Initial efforts yielded <a href=https://en.wikipedia.org/wiki/F-number>f1-scores</a> of 82.39 % and 83.77 % in the development and test sets of the <a href=https://en.wikipedia.org/wiki/Fusion_power>fusion track</a>, and were officially submitted to the task as team L2F. After the task was closed, we carried on further experiments and relied on a late fusion strategy for combining our simple proposed approaches with modifications of the baselines provided by the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. As expected, the i-vectors based sub-system dominates the performance of the system combinations, and results in the major contributor to our achieved scores. Our best combined <a href=https://en.wikipedia.org/wiki/System>system</a> achieves 90.1 % and 90.2 % <a href=https://en.wikipedia.org/wiki/F-number>f1-score</a> in the development and test sets of the <a href=https://en.wikipedia.org/wiki/Fusion_energy>fusion track</a>, respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q17-1015.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q17-1015 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q17-1015 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234955039 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/Q17-1015/>Pushing the Limits of Translation Quality Estimation</a></strong><br><a href=/people/a/andre-f-t-martins/>André F. T. Martins</a>
|
<a href=/people/m/marcin-junczys-dowmunt/>Marcin Junczys-Dowmunt</a>
|
<a href=/people/f/fabio-kepler/>Fabio N. Kepler</a>
|
<a href=/people/r/ramon-fernandez-astudillo/>Ramón Astudillo</a>
|
<a href=/people/c/chris-hokamp/>Chris Hokamp</a>
|
<a href=/people/r/roman-grundkiewicz/>Roman Grundkiewicz</a><br><a href=/volumes/Q17-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 5</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q17-1015><div class="card-body p-3 small">Translation quality estimation is a task of growing importance in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, due to its potential to reduce post-editing human effort in disruptive ways. However, this potential is currently limited by the relatively low <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of existing <a href=https://en.wikipedia.org/wiki/System>systems</a>. In this paper, we achieve remarkable improvements by exploiting synergies between the related tasks of word-level quality estimation and automatic post-editing. First, we stack a new, carefully engineered, neural model into a rich feature-based word-level quality estimation system. Then, we use the output of an automatic post-editing system as an extra feature, obtaining striking results on WMT16 : a word-level FMULT1 score of 57.47 % (an absolute gain of +7.95 % over the current state of the art), and a <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>Pearson correlation score</a> of 65.56 % for sentence-level HTER prediction (an absolute gain of +13.36 %).</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Ram%C3%B3n+Fernandez+Astudillo" title="Search for 'Ramón Fernandez Astudillo' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/t/tahira-naseem/ class=align-middle>Tahira Naseem</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/md-arafat-sultan/ class=align-middle>Md Arafat Sultan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/f/fabio-kepler/ class=align-middle>Fabio Kepler</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/andre-f-t-martins/ class=align-middle>André F. T. Martins</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/peng-qian/ class=align-middle>Peng Qian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/r/roger-levy/ class=align-middle>Roger Levy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/manuel-mager/ class=align-middle>Manuel Mager</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/young-suk-lee/ class=align-middle>Young-Suk Lee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/radu-florian/ class=align-middle>Radu Florian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/salim-roukos/ class=align-middle>Salim Roukos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shubham-chandel/ class=align-middle>Shubham Chandel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vittorio-castelli/ class=align-middle>Vittorio Castelli</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alberto-abad/ class=align-middle>Alberto Abad</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marcin-junczys-dowmunt/ class=align-middle>Marcin Junczys-Dowmunt</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chris-hokamp/ class=align-middle>Chris Hokamp</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/roman-grundkiewicz/ class=align-middle>Roman Grundkiewicz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joao-graca/ class=align-middle>João Graça</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/tacl/ class=align-middle>TACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>