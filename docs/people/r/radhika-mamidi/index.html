<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Radhika Mamidi - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Radhika</span> <span class=font-weight-bold>Mamidi</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ltedi-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ltedi-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ltedi-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.ltedi-1.21.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.ltedi-1.21/>Autobots@LT-EDI-EACL2021 : One World, One Family : Hope Speech Detection with BERT Transformer Model<span class=acl-fixed-case>LT</span>-<span class=acl-fixed-case>EDI</span>-<span class=acl-fixed-case>EACL</span>2021: One World, One Family: Hope Speech Detection with <span class=acl-fixed-case>BERT</span> Transformer Model</a></strong><br><a href=/people/s/sunil-gundapu/>Sunil Gundapu</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a><br><a href=/volumes/2021.ltedi-1/ class=text-muted>Proceedings of the First Workshop on Language Technology for Equality, Diversity and Inclusion</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ltedi-1--21><div class="card-body p-3 small">The rapid rise of <a href=https://en.wikipedia.org/wiki/List_of_social_networking_websites>online social networks</a> like <a href=https://en.wikipedia.org/wiki/YouTube>YouTube</a>, <a href=https://en.wikipedia.org/wiki/Facebook>Facebook</a>, <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> allows people to express their views more widely online. However, at the same time, it can lead to an increase in <a href=https://en.wikipedia.org/wiki/Conflict_(process)>conflict</a> and hatred among consumers in the form of <a href=https://en.wikipedia.org/wiki/Freedom_of_speech>freedom of speech</a>. Therefore, it is essential to take a positive strengthening method to research on encouraging, positive, helping, and supportive social media content. In this paper, we describe a Transformer-based BERT model for Hope speech detection for equality, diversity, and inclusion, submitted for LT-EDI-2021 Task 2. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves a weighted averaged f1-score of 0.93 on the test set.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ranlp-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ranlp-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ranlp-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ranlp-1.13/>TEASER : Towards Efficient Aspect-based SEntiment Analysis and Recognition<span class=acl-fixed-case>TEASER</span>: Towards Efficient Aspect-based <span class=acl-fixed-case>SE</span>ntiment Analysis and Recognition</a></strong><br><a href=/people/v/vaibhav-bajaj/>Vaibhav Bajaj</a>
|
<a href=/people/k/kartikey-pant/>Kartikey Pant</a>
|
<a href=/people/i/ishan-upadhyay/>Ishan Upadhyay</a>
|
<a href=/people/s/srinath-nair/>Srinath Nair</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a><br><a href=/volumes/2021.ranlp-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ranlp-1--13><div class="card-body p-3 small">Sentiment analysis aims to detect the overall sentiment, i.e., the polarity of a sentence, paragraph, or text span, without considering the entities mentioned and their aspects. Aspect-based sentiment analysis aims to extract the aspects of the given target entities and their respective sentiments. Prior works formulate this as a sequence tagging problem or solve this task using a span-based extract-then-classify framework where first all the opinion targets are extracted from the sentence, and then with the help of span representations, the targets are classified as positive, negative, or neutral. The sequence tagging problem suffers from issues like sentiment inconsistency and colossal search space. Whereas, Span-based extract-then-classify framework suffers from issues such as half-word coverage and overlapping spans. To overcome this, we propose a similar span-based extract-then-classify framework with a novel and improved heuristic. Experiments on the three benchmark datasets (Restaurant14, Laptop14, Restaurant15) show our model consistently outperforms the current state-of-the-art. Moreover, we also present a novel supervised movie reviews dataset (Movie20) and a pseudo-labeled movie reviews dataset (moviesLarge) made explicitly for this task and report the results on the novel Movie20 dataset as well.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ranlp-1.42.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ranlp-1--42 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ranlp-1.42 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ranlp-1.42/>A Pre-trained Transformer and CNN Model with Joint Language ID and Part-of-Speech Tagging for Code-Mixed Social-Media Text<span class=acl-fixed-case>CNN</span> Model with Joint Language <span class=acl-fixed-case>ID</span> and Part-of-Speech Tagging for Code-Mixed Social-Media Text</a></strong><br><a href=/people/s/suman-dowlagar/>Suman Dowlagar</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a><br><a href=/volumes/2021.ranlp-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ranlp-1--42><div class="card-body p-3 small">Code-mixing (CM) is a frequently observed phenomenon that uses multiple languages in an utterance or sentence. There are no strict grammatical constraints observed in <a href=https://en.wikipedia.org/wiki/Code-mixing>code-mixing</a>, and it consists of non-standard variations of spelling. The linguistic complexity resulting from the above factors made the <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational analysis</a> of the code-mixed language a challenging task. Language identification (LI) and part of speech (POS) tagging are the fundamental steps that help analyze the structure of the code-mixed text. Often, the LI and POS tagging tasks are interdependent in the code-mixing scenario. We project the problem of dealing with <a href=https://en.wikipedia.org/wiki/Multilingualism>multilingualism</a> and <a href=https://en.wikipedia.org/wiki/Grammar>grammatical structure</a> while analyzing the code-mixed sentence as a joint learning task. In this paper, we jointly train and optimize <a href=https://en.wikipedia.org/wiki/Language_recognition>language detection</a> and <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part of speech tagging models</a> in the code-mixed scenario. We used a Transformer with convolutional neural network architecture. We train a joint learning method by combining POS tagging and LI models on code-mixed social media text obtained from the ICON shared task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ranlp-1.86.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ranlp-1--86 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ranlp-1.86 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ranlp-1.86/>Sentiment Analysis in Code-Mixed Telugu-English Text with Unsupervised Data Normalization<span class=acl-fixed-case>T</span>elugu-<span class=acl-fixed-case>E</span>nglish Text with Unsupervised Data Normalization</a></strong><br><a href=/people/s/siva-subrahamanyam-varma-kusampudi/>Siva Subrahamanyam Varma Kusampudi</a>
|
<a href=/people/p/preetham-sathineni/>Preetham Sathineni</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a><br><a href=/volumes/2021.ranlp-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ranlp-1--86><div class="card-body p-3 small">In a multilingual society, people communicate in more than one language, leading to Code-Mixed data. Sentimental analysis on Code-Mixed Telugu-English Text (CMTET) poses unique challenges. The unstructured nature of the Code-Mixed Data is due to the <a href=https://en.wikipedia.org/wiki/Informal_language>informal language</a>, <a href=https://en.wikipedia.org/wiki/Transliteration>informal transliterations</a>, and spelling errors. In this paper, we introduce an annotated dataset for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a> in CMTET. Also, we report an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 80.22 % on this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> using novel <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised data normalization</a> with a Multilayer Perceptron (MLP) model. This proposed data normalization technique can be extended to any NLP task involving CMTET. Further, we report an increase of 2.53 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> due to this data normalization approach in our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ranlp-1.173.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ranlp-1--173 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ranlp-1.173 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ranlp-1.173/>Towards Sentiment Analysis of Tobacco Productsâ€™ Usage in <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a></a></strong><br><a href=/people/v/venkata-himakar-yanamandra/>Venkata Himakar Yanamandra</a>
|
<a href=/people/k/kartikey-pant/>Kartikey Pant</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a><br><a href=/volumes/2021.ranlp-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ranlp-1--173><div class="card-body p-3 small">Contemporary tobacco-related studies are mostly concerned with a single <a href=https://en.wikipedia.org/wiki/Social_media>social media platform</a> while missing out on a broader audience. Moreover, they are heavily reliant on labeled datasets, which are expensive to make. In this work, we explore sentiment and product identification on tobacco-related text from two <a href=https://en.wikipedia.org/wiki/Social_media>social media platforms</a>. We release SentiSmoke-Twitter and SentiSmoke-Reddit datasets, along with a comprehensive annotation schema for identifying tobacco products&#8217; sentiment. We then perform benchmarking text classification experiments using state-of-the-art models, including BERT, RoBERTa, and DistilBERT. Our experiments show <a href=https://en.wikipedia.org/wiki/F-number>F1 scores</a> as high as 0.72 for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment identification</a> in the Twitter dataset, 0.46 for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment identification</a>, and 0.57 for product identification using <a href=https://en.wikipedia.org/wiki/Semi-supervised_learning>semi-supervised learning</a> for <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dialdoc-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dialdoc-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dialdoc-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.dialdoc-1.4/>Automatic Learning Assistant in Telugu<span class=acl-fixed-case>T</span>elugu</a></strong><br><a href=/people/m/meghana-bommadi/>Meghana Bommadi</a>
|
<a href=/people/s/shreya-terupally/>Shreya Terupally</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a><br><a href=/volumes/2021.dialdoc-1/ class=text-muted>Proceedings of the 1st Workshop on Document-grounded Dialogue and Conversational Question Answering (DialDoc 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dialdoc-1--4><div class="card-body p-3 small">This paper presents a learning assistant that tests one&#8217;s knowledge and gives feedback that helps a person learn at a faster pace. A learning assistant (based on automated question generation) has extensive uses in <a href=https://en.wikipedia.org/wiki/Education>education</a>, information websites, <a href=https://en.wikipedia.org/wiki/Self-assessment>self-assessment</a>, FAQs, testing ML agents, <a href=https://en.wikipedia.org/wiki/Research>research</a>, etc. Multiple researchers, and companies have worked on <a href=https://en.wikipedia.org/wiki/Virtual_Assistance>Virtual Assistance</a>, but majorly in <a href=https://en.wikipedia.org/wiki/English_language>English</a>. We built our learning assistant for <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu language</a> to help with teaching in the mother tongue, which is the most efficient way of learning. Our <a href=https://en.wikipedia.org/wiki/System>system</a> is built primarily based on Question Generation in <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a>. Many experiments were conducted on Question Generation in <a href=https://en.wikipedia.org/wiki/English_language>English</a> in multiple ways. We have built the first hybrid machine learning and rule-based solution in <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a>, which proves efficient for <a href=https://en.wikipedia.org/wiki/Short_story>short stories</a> or short passages in children&#8217;s books. Our work covers the fundamental question forms with question types : <a href=https://en.wikipedia.org/wiki/Adjective>adjective</a>, yes / no, <a href=https://en.wikipedia.org/wiki/Adverb>adverb</a>, <a href=https://en.wikipedia.org/wiki/Verb>verb</a>, when, where, whose, quotative, and quantitative (how many / how much). We constructed rules for question generation using Part of Speech (POS) tags and Universal Dependency (UD) tags along with linguistic information of the surrounding relevant context of the word. We used keyword matching, multilingual sentence embedding to evaluate the answer. Our system is primarily built on question generation in <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a>, and is also capable of evaluating the user&#8217;s answers to the generated questions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.173.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--173 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.173 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.173/>IIITH at SemEval-2021 Task 7 : Leveraging transformer-based humourous and offensive text detection architectures using lexical and hurtlex features and task adaptive pretraining<span class=acl-fixed-case>IIITH</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 7: Leveraging transformer-based humourous and offensive text detection architectures using lexical and hurtlex features and task adaptive pretraining</a></strong><br><a href=/people/t/tathagata-raha/>Tathagata Raha</a>
|
<a href=/people/i/ishan-sanjeev-upadhyay/>Ishan Sanjeev Upadhyay</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a>
|
<a href=/people/v/vasudeva-varma/>Vasudeva Varma</a><br><a href=/volumes/2021.semeval-1/ class=text-muted>Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--173><div class="card-body p-3 small">This paper describes our approach (IIITH) for SemEval-2021 Task 5 : HaHackathon : Detecting and Rating Humor and Offense. Our results focus on two major objectives : (i) Effect of task adaptive pretraining on the performance of transformer based models (ii) How does lexical and hurtlex features help in quantifying humour and offense. In this paper, we provide a detailed description of our approach along with comparisions mentioned above.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.codi-main.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--codi-main--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.codi-main.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.codi-main.2/>Developing Conversational Data and Detection of Conversational Humor in <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a><span class=acl-fixed-case>T</span>elugu</a></strong><br><a href=/people/v/vaishnavi-pamulapati/>Vaishnavi Pamulapati</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a><br><a href=/volumes/2021.codi-main/ class=text-muted>Proceedings of the 2nd Workshop on Computational Approaches to Discourse</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--codi-main--2><div class="card-body p-3 small">In the field of humor research, there has been a recent surge of interest in the sub-domain of Conversational Humor (CH). This study has two main objectives. (a) develop a conversational (humorous and non-humorous) dataset in <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a>. (b) detect <a href=https://en.wikipedia.org/wiki/Methylene_bridge>CH</a> in the compiled <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. In this paper, the challenges faced while collecting the data and experiments carried out are elucidated. Transfer learning and non-transfer learning techniques are implemented by utilizing pre-trained models such as FastText word embeddings, BERT language models and Text GCN, which learns the word and document embeddings simultaneously of the corpus given. State-of-the-art results are observed with a 99.3 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and a 98.5 % f1 score achieved by <a href=https://en.wikipedia.org/wiki/BERT>BERT</a>.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.eamt-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--eamt-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.eamt-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.eamt-1.9/>Leveraging Multilingual Resources for Language Invariant Sentiment Analysis</a></strong><br><a href=/people/a/allen-antony/>Allen Antony</a>
|
<a href=/people/a/arghya-bhattacharya/>Arghya Bhattacharya</a>
|
<a href=/people/j/jaipal-goud/>Jaipal Goud</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a><br><a href=/volumes/2020.eamt-1/ class=text-muted>Proceedings of the 22nd Annual Conference of the European Association for Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--eamt-1--9><div class="card-body p-3 small">Sentiment analysis is a widely researched NLP problem with state-of-the-art solutions capable of attaining human-like accuracies for various languages. However, these methods rely heavily on large amounts of labeled data or sentiment weighted language-specific lexical resources that are unavailable for low-resource languages. Our work attempts to tackle this data scarcity issue by introducing a neural architecture for language invariant sentiment analysis capable of leveraging various monolingual datasets for training without any kind of cross-lingual supervision. The proposed architecture attempts to learn language agnostic sentiment features via adversarial training on multiple resource-rich languages which can then be leveraged for inferring sentiment information at a sentence level on a low resource language. Our model outperforms the current state-of-the-art methods on the Multilingual Amazon Review Text Classification dataset [ REF ] and achieves significant performance gains over prior work on the low resource Sentiraama corpus [ REF ]. A detailed analysis of our research highlights the ability of our <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> to perform significantly well in the presence of minimal amounts of training data for low resource languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.figlang-1.15/>Detecting Sarcasm in Conversation Context Using Transformer-Based Models<span class=acl-fixed-case>D</span>etecting <span class=acl-fixed-case>S</span>arcasm in <span class=acl-fixed-case>C</span>onversation <span class=acl-fixed-case>C</span>ontext <span class=acl-fixed-case>U</span>sing <span class=acl-fixed-case>T</span>ransformer-<span class=acl-fixed-case>B</span>ased <span class=acl-fixed-case>M</span>odels</a></strong><br><a href=/people/a/adithya-avvaru/>Adithya Avvaru</a>
|
<a href=/people/s/sanath-vobilisetty/>Sanath Vobilisetty</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a><br><a href=/volumes/2020.figlang-1/ class=text-muted>Proceedings of the Second Workshop on Figurative Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--15><div class="card-body p-3 small">Sarcasm detection, regarded as one of the sub-problems of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, is a very typical task because the introduction of sarcastic words can flip the sentiment of the sentence itself. To date, many research works revolve around detecting <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> in one single sentence and there is very limited research to detect <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> resulting from multiple sentences. Current models used Long Short Term Memory (LSTM) variants with or without <a href=https://en.wikipedia.org/wiki/Attention>attention</a> to detect <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> in conversations. We showed that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> using state-of-the-art Bidirectional Encoder Representations from Transformers (BERT), to capture syntactic and semantic information across conversation sentences, performed better than the current <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Based on the data analysis, we estimated that the number of sentences in the conversation that can contribute to the <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> and the results agrees to this estimation. We also perform a comparative study of our different versions of BERT-based model with other variants of LSTM model and XLNet (both using the estimated number of conversation sentences) and find out that BERT-based models outperformed them.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.617.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--617 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.617 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.617/>Dataset Creation and Evaluation of Aspect Based Sentiment Analysis in <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a>, a Low Resource Language<span class=acl-fixed-case>T</span>elugu, a Low Resource Language</a></strong><br><a href=/people/y/yashwanth-reddy-regatte/>Yashwanth Reddy Regatte</a>
|
<a href=/people/r/rama-rohit-reddy-gangula/>Rama Rohit Reddy Gangula</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--617><div class="card-body p-3 small">In recent years, <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> has gained popularity as it is essential to moderate and analyse the information across the internet. It has various applications like <a href=https://en.wikipedia.org/wiki/Opinion_mining>opinion mining</a>, <a href=https://en.wikipedia.org/wiki/Social_media_monitoring>social media monitoring</a>, and <a href=https://en.wikipedia.org/wiki/Market_research>market research</a>. Aspect Based Sentiment Analysis (ABSA) is an area of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> which deals with sentiment at a finer level. ABSA classifies sentiment with respect to each aspect to gain greater insights into the sentiment expressed. Significant contributions have been made in ABSA, but this progress is limited only to a few languages with adequate resources. Telugu lags behind in this area of research despite being one of the most spoken languages in India and an enormous amount of data being created each day. In this paper, we create a reliable <a href=https://en.wikipedia.org/wiki/Resource>resource</a> for aspect based sentiment analysis in <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a>. The data is annotated for three tasks namely Aspect Term Extraction, Aspect Polarity Classification and Aspect Categorisation. Further, we develop <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> for the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> using <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning methods</a> demonstrating the reliability and usefulness of the <a href=https://en.wikipedia.org/wiki/Resource>resource</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.socialnlp-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--socialnlp-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.socialnlp-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929901 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.socialnlp-1.1/>Enhancing Bias Detection in <a href=https://en.wikipedia.org/wiki/Political_journalism>Political News</a> Using Pragmatic Presupposition</a></strong><br><a href=/people/l/lalitha-kameswari/>Lalitha Kameswari</a>
|
<a href=/people/d/dama-sravani/>Dama Sravani</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a><br><a href=/volumes/2020.socialnlp-1/ class=text-muted>Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--socialnlp-1--1><div class="card-body p-3 small">Usage of presuppositions in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> and news discourse can be a powerful way to influence the readers as they usually tend to not examine the truth value of the hidden or indirectly expressed information. Fairclough and Wodak (1997) discuss <a href=https://en.wikipedia.org/wiki/Presupposition>presupposition</a> at a discourse level where some implicit claims are taken for granted in the explicit meaning of a text or utterance. From the Gricean perspective, the presuppositions of a sentence determine the class of contexts in which the sentence could be felicitously uttered. This paper aims to correlate the type of knowledge presupposed in a news article to the bias present in it. We propose a set of guidelines to identify various kinds of presuppositions in news articles and present a dataset consisting of 1050 articles which are annotated for <a href=https://en.wikipedia.org/wiki/Bias>bias</a> (positive, negative or neutral) and the magnitude of <a href=https://en.wikipedia.org/wiki/Presupposition>presupposition</a>. We introduce a supervised classification approach for detecting bias in <a href=https://en.wikipedia.org/wiki/Political_journalism>political news</a> which significantly outperforms the existing systems.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.icon-1.28.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--icon-1--28 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.icon-1.28 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2019.icon-1.28.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2019.icon-1.28/>Samajh-Boojh : A Reading Comprehension system in Hindi<span class=acl-fixed-case>H</span>indi</a></strong><br><a href=/people/s/shalaka-vaidya/>Shalaka Vaidya</a>
|
<a href=/people/h/hiranmai-sri-adibhatla/>Hiranmai Sri Adibhatla</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a><br><a href=/volumes/2019.icon-1/ class=text-muted>Proceedings of the 16th International Conference on Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--icon-1--28><div class="card-body p-3 small">This paper presents a novel approach designed to answer questions on a reading comprehension passage. It is an end-to-end system which first focuses on comprehending the given passage wherein it converts <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured passage</a> into a <a href=https://en.wikipedia.org/wiki/Structured_data>structured data</a> and later proceeds to answer the questions related to the passage using solely the aforementioned <a href=https://en.wikipedia.org/wiki/Structured_data>structured data</a>. To the best of our knowledge, the proposed <a href=https://en.wikipedia.org/wiki/Design>design</a> is first of its kind which accounts for entire process of comprehending the passage and then answering the questions associated with the passage. The comprehension stage converts the passage into a Discourse Collection that comprises of the relation shared amongst logical sentences in given passage along with the key characteristics of each sentence. This <a href=https://en.wikipedia.org/wiki/Design>design</a> has its applications in academic domain, query comprehension in speech systems among others.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4809.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4809 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4809 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4809/>Detecting Political Bias in <a href=https://en.wikipedia.org/wiki/Article_(publishing)>News Articles</a> Using Headline Attention</a></strong><br><a href=/people/r/rama-rohit-reddy-gangula/>Rama Rohit Reddy Gangula</a>
|
<a href=/people/s/suma-reddy-duggenpudi/>Suma Reddy Duggenpudi</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a><br><a href=/volumes/W19-48/ class=text-muted>Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4809><div class="card-body p-3 small">Language is a powerful tool which can be used to state the facts as well as express our views and perceptions. Most of the times, we find a subtle bias towards or against someone or something. When it comes to <a href=https://en.wikipedia.org/wiki/Politics>politics</a>, media houses and journalists are known to create bias by shrewd means such as misinterpreting reality and distorting viewpoints towards some parties. This misinterpretation on a large scale can lead to the production of <a href=https://en.wikipedia.org/wiki/News_bias>biased news</a> and <a href=https://en.wikipedia.org/wiki/Conspiracy_theory>conspiracy theories</a>. Automating bias detection in newspaper articles could be a good challenge for research in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. We proposed a headline attention network for this bias detection. Our model has two distinctive characteristics : (i) it has a structure that mirrors a person&#8217;s way of reading a news article (ii) it has attention mechanism applied on the article based on its headline, enabling it to attend to more critical content to predict bias. As the required datasets were not available, we created a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> comprising of 1329 <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a> collected from various <a href=https://en.wikipedia.org/wiki/List_of_newspapers_in_India>Telugu newspapers</a> and marked them for bias towards a particular political party. The experiments conducted on it demonstrated that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms various baseline methods by a substantial margin.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-3014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-3014 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-3014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-3014/>BCSAT : A Benchmark Corpus for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a> in <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a> Using Word-level Annotations<span class=acl-fixed-case>BCSAT</span> : A Benchmark Corpus for Sentiment Analysis in <span class=acl-fixed-case>T</span>elugu Using Word-level Annotations</a></strong><br><a href=/people/s/sreekavitha-parupalli/>Sreekavitha Parupalli</a>
|
<a href=/people/v/vijjini-anvesh-rao/>Vijjini Anvesh Rao</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a><br><a href=/volumes/P18-3/ class=text-muted>Proceedings of ACL 2018, Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-3014><div class="card-body p-3 small">The presented work aims at generating a systematically annotated corpus that can support the enhancement of sentiment analysis tasks in <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a> using word-level sentiment annotations. From OntoSenseNet, we extracted 11,000 <a href=https://en.wikipedia.org/wiki/Adjective>adjectives</a>, 253 <a href=https://en.wikipedia.org/wiki/Adverb>adverbs</a>, 8483 verbs and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment annotation</a> is being done by language experts. We discuss the <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> followed for the polarity annotations and validate the developed <a href=https://en.wikipedia.org/wiki/Resource>resource</a>. This work aims at developing a benchmark corpus, as an extension to SentiWordNet, and baseline accuracy for a model where lexeme annotations are applied for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment predictions</a>. The fundamental aim of this paper is to validate and study the possibility of utilizing <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning algorithms</a>, <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>word-level sentiment annotations</a> in the task of automated sentiment identification. Furthermore, <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> is improved by annotating the bi-grams extracted from the target corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-3021.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-3021 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-3021 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-3021/>Automatic Spelling Correction for Resource-Scarce Languages using <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Learning</a></a></strong><br><a href=/people/p/pravallika-etoori/>Pravallika Etoori</a>
|
<a href=/people/m/manoj-chinnakotla/>Manoj Chinnakotla</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a><br><a href=/volumes/P18-3/ class=text-muted>Proceedings of ACL 2018, Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-3021><div class="card-body p-3 small">Spelling correction is a well-known task in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing (NLP)</a>. Automatic spelling correction is important for many NLP applications like <a href=https://en.wikipedia.org/wiki/Web_search_engine>web search engines</a>, <a href=https://en.wikipedia.org/wiki/Automatic_summarization>text summarization</a>, <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> etc. Most approaches use parallel data of noisy and correct word mappings from different sources as training data for automatic spelling correction. Indic languages are resource-scarce and do not have such parallel data due to low volume of queries and non-existence of such prior implementations. In this paper, we show how to build an automatic spelling corrector for resource-scarce languages. We propose a sequence-to-sequence deep learning model which trains <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end</a>. We perform experiments on synthetic datasets created for <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indic languages</a>, <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> and <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a>, by incorporating the spelling mistakes committed at character level. A comparative evaluation shows that our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is competitive with the existing <a href=https://en.wikipedia.org/wiki/Spell_checker>spell checking and correction techniques</a> for <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indic languages</a>.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2902.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2902 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2902 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-2902" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-2902/>When does a compliment become sexist? Analysis and classification of ambivalent sexism using twitter data</a></strong><br><a href=/people/a/akshita-jha/>Akshita Jha</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a><br><a href=/volumes/W17-29/ class=text-muted>Proceedings of the Second Workshop on NLP and Computational Social Science</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2902><div class="card-body p-3 small">Sexism is prevalent in today&#8217;s society, both offline and online, and poses a credible threat to <a href=https://en.wikipedia.org/wiki/Social_equality>social equality</a> with respect to gender. According to ambivalent sexism theory (Glick and Fiske, 1996), it comes in two forms : Hostile and Benevolent. While <a href=https://en.wikipedia.org/wiki/Hostile_sexism>hostile sexism</a> is characterized by an explicitly negative attitude, <a href=https://en.wikipedia.org/wiki/Benevolent_sexism>benevolent sexism</a> is more subtle. Previous works on computationally detecting sexism present online are restricted to identifying the hostile form. Our objective is to investigate the less pronounced form of <a href=https://en.wikipedia.org/wiki/Sexism>sexism</a> demonstrated online. We achieve this by creating and analyzing a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> that exhibit <a href=https://en.wikipedia.org/wiki/Benevolent_sexism>benevolent sexism</a>. By using Support Vector Machines (SVM), sequence-to-sequence models and FastText classifier, we classify tweets into &#8216;Hostile&#8217;, &#8216;Benevolent&#8217; or &#8216;Others&#8217; class depending on the kind of sexism they exhibit. We have been able to achieve an <a href=https://en.wikipedia.org/wiki/F-score>F1-score</a> of 87.22 % using FastText classifier. Our work helps analyze and understand the much prevalent ambivalent sexism in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5219.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5219 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5219 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5219/>Building a SentiWordNet for Odia<span class=acl-fixed-case>S</span>enti<span class=acl-fixed-case>W</span>ord<span class=acl-fixed-case>N</span>et for <span class=acl-fixed-case>O</span>dia</a></strong><br><a href=/people/g/gaurav-mohanty/>Gaurav Mohanty</a>
|
<a href=/people/a/abishek-kannan/>Abishek Kannan</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a><br><a href=/volumes/W17-52/ class=text-muted>Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5219><div class="card-body p-3 small">As a discipline of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a>, <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a> is used to extract and analyze <a href=https://en.wikipedia.org/wiki/Subjectivity>subjective information</a> present in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language data</a>. The task of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a> has acquired wide commercial uses including social media monitoring tasks, survey responses, review systems, etc. Languages like <a href=https://en.wikipedia.org/wiki/English_language>English</a> have several resources which aid in the task of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a>. SentiWordNet and Subjectivity WordList are examples of such tools and resources. With more data being available in native vernacular, language-specific SentiWordNet(s) have become essential. For resource poor languages, creating such SentiWordNet(s) is a difficult task to achieve. One solution is to use available resources in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and translate the final source lexicon to target lexicon via <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. Machine translation systems for the English-Odia language pair have not yet been developed. In this paper, we discuss a method to create a SentiWordNet for <a href=https://en.wikipedia.org/wiki/Odia_language>Odia</a>, which is resource-poor, by only using resources which are currently available for <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indian languages</a>. The lexicon created, would serve as a tool for Sentiment Analysis related task specific to Odia data.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Radhika+Mamidi" title="Search for 'Radhika Mamidi' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/k/kartikey-pant/ class=align-middle>Kartikey Pant</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/rama-rohit-reddy-gangula/ class=align-middle>Rama Rohit Reddy Gangula</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/allen-antony/ class=align-middle>Allen Antony</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/arghya-bhattacharya/ class=align-middle>Arghya Bhattacharya</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jaipal-goud/ class=align-middle>Jaipal Goud</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/s/sunil-gundapu/ class=align-middle>Sunil Gundapu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vaibhav-bajaj/ class=align-middle>Vaibhav Bajaj</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ishan-upadhyay/ class=align-middle>Ishan Upadhyay</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/srinath-nair/ class=align-middle>Srinath Nair</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/suman-dowlagar/ class=align-middle>Suman Dowlagar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/siva-subrahamanyam-varma-kusampudi/ class=align-middle>Siva Subrahamanyam Varma Kusampudi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/preetham-sathineni/ class=align-middle>Preetham Sathineni</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/venkata-himakar-yanamandra/ class=align-middle>Venkata Himakar Yanamandra</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shalaka-vaidya/ class=align-middle>Shalaka Vaidya</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hiranmai-sri-adibhatla/ class=align-middle>Hiranmai Sri Adibhatla</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/akshita-jha/ class=align-middle>Akshita Jha</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gaurav-mohanty/ class=align-middle>Gaurav Mohanty</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/abishek-kannan/ class=align-middle>Abishek Kannan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/adithya-avvaru/ class=align-middle>Adithya Avvaru</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sanath-vobilisetty/ class=align-middle>Sanath Vobilisetty</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/meghana-bommadi/ class=align-middle>Meghana Bommadi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shreya-terupally/ class=align-middle>Shreya Terupally</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/suma-reddy-duggenpudi/ class=align-middle>Suma Reddy Duggenpudi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yashwanth-reddy-regatte/ class=align-middle>Yashwanth Reddy Regatte</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tathagata-raha/ class=align-middle>Tathagata Raha</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ishan-sanjeev-upadhyay/ class=align-middle>Ishan Sanjeev Upadhyay</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vasudeva-varma/ class=align-middle>Vasudeva Varma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lalitha-kameswari/ class=align-middle>Lalitha Kameswari</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dama-sravani/ class=align-middle>Dama Sravani</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sreekavitha-parupalli/ class=align-middle>Sreekavitha Parupalli</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vijjini-anvesh-rao/ class=align-middle>Vijjini Anvesh Rao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pravallika-etoori/ class=align-middle>Pravallika Etoori</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/manoj-chinnakotla/ class=align-middle>Manoj Chinnakotla</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vaishnavi-pamulapati/ class=align-middle>Vaishnavi Pamulapati</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ranlp/ class=align-middle>RANLP</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/eamt/ class=align-middle>EAMT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ltedi/ class=align-middle>LTEDI</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/icon/ class=align-middle>ICON</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/figlang/ class=align-middle>Fig-Lang</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/dialdoc/ class=align-middle>dialdoc</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/socialnlp/ class=align-middle>SocialNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/codi/ class=align-middle>CODI</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>