<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Daniel Duckworth - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Daniel</span> <span class=font-weight-bold>Duckworth</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.humeval-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--humeval-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.humeval-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href="https://www.youtube.com/watch?v=P0SWVm30MFM" data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.humeval-1.3/>Trading Off Diversity and Quality in Natural Language Generation</a></strong><br><a href=/people/h/hugh-zhang/>Hugh Zhang</a>
|
<a href=/people/d/daniel-duckworth/>Daniel Duckworth</a>
|
<a href=/people/d/daphne-ippolito/>Daphne Ippolito</a>
|
<a href=/people/a/arvind-neelakantan/>Arvind Neelakantan</a><br><a href=/volumes/2021.humeval-1/ class=text-muted>Proceedings of the Workshop on Human Evaluation of NLP Systems (HumEval)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--humeval-1--3><div class="card-body p-3 small">For open-ended language generation tasks such as <a href=https://en.wikipedia.org/wiki/Storytelling>storytelling</a> or <a href=https://en.wikipedia.org/wiki/Dialogue>dialogue</a>, choosing the right decoding algorithm is vital for controlling the tradeoff between generation quality and diversity. However, there presently exists no consensus on which <a href=https://en.wikipedia.org/wiki/Decoding_methods>decoding procedure</a> is best or even the criteria by which to compare them. In this paper, we cast <a href=https://en.wikipedia.org/wiki/Decoding_methods>decoding</a> as a tradeoff between response quality and diversity, and we perform the first large-scale evaluation of <a href=https://en.wikipedia.org/wiki/Decoding_methods>decoding methods</a> along the entire quality-diversity spectrum. Our experiments confirm the existence of the likelihood trap : the counter-intuitive observation that high likelihood sequences are often surprisingly low quality. We also find that when diversity is a priority, all methods perform similarly, but when quality is viewed as more important, nucleus sampling (Holtzman et al., 2019) outperforms all other evaluated decoding algorithms.<i>quality</i> and <i>diversity</i>. However, there presently exists no consensus on which decoding procedure is best or even the criteria by which to compare them. In this paper, we cast decoding as a tradeoff between response quality and diversity, and we perform the first large-scale evaluation of decoding methods along the entire quality-diversity spectrum. Our experiments confirm the existence of the likelihood trap: the counter-intuitive observation that high likelihood sequences are often surprisingly low quality. We also find that when diversity is a priority, all methods perform similarly, but when quality is viewed as more important, nucleus sampling (Holtzman et al., 2019) outperforms all other evaluated decoding algorithms.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.164.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--164 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.164 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928914 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.164" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.164/>Automatic Detection of Generated Text is Easiest when Humans are Fooled</a></strong><br><a href=/people/d/daphne-ippolito/>Daphne Ippolito</a>
|
<a href=/people/d/daniel-duckworth/>Daniel Duckworth</a>
|
<a href=/people/c/chris-callison-burch/>Chris Callison-Burch</a>
|
<a href=/people/d/douglas-eck/>Douglas Eck</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--164><div class="card-body p-3 small">Recent advancements in neural language modelling make it possible to rapidly generate vast amounts of human-sounding text. The capabilities of <a href=https://en.wikipedia.org/wiki/Human>humans</a> and <a href=https://en.wikipedia.org/wiki/Discriminator>automatic discriminators</a> to detect machine-generated text have been a large source of research interest, but humans and machines rely on different cues to make their decisions. Here, we perform careful benchmarking and analysis of three popular sampling-based decoding strategiestop-_k _, nucleus sampling, and untruncated random samplingand show that improvements in decoding methods have primarily optimized for fooling humans. This comes at the expense of introducing <a href=https://en.wikipedia.org/wiki/Statistical_significance>statistical abnormalities</a> that make <a href=https://en.wikipedia.org/wiki/Detection>detection</a> easy for <a href=https://en.wikipedia.org/wiki/Automation>automatic systems</a>. We also show that though both human and automatic detector performance improve with longer excerpt length, even multi-sentence excerpts can fool expert human raters over 30 % of the time. Our findings reveal the importance of using both human and automatic detectors to assess the humanness of text generation systems.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1459.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1459 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1459 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1459/>Taskmaster-1 : Toward a Realistic and Diverse Dialog Dataset</a></strong><br><a href=/people/b/bill-byrne/>Bill Byrne</a>
|
<a href=/people/k/karthik-krishnamoorthi/>Karthik Krishnamoorthi</a>
|
<a href=/people/c/chinnadhurai-sankar/>Chinnadhurai Sankar</a>
|
<a href=/people/a/arvind-neelakantan/>Arvind Neelakantan</a>
|
<a href=/people/b/ben-goodrich/>Ben Goodrich</a>
|
<a href=/people/d/daniel-duckworth/>Daniel Duckworth</a>
|
<a href=/people/s/semih-yavuz/>Semih Yavuz</a>
|
<a href=/people/a/amit-dubey/>Amit Dubey</a>
|
<a href=/people/k/kyu-young-kim/>Kyu-Young Kim</a>
|
<a href=/people/a/andy-cedilnik/>Andy Cedilnik</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1459><div class="card-body p-3 small">A significant barrier to progress in data-driven approaches to building dialog systems is the lack of high quality, goal-oriented conversational data. To help satisfy this elementary requirement, we introduce the initial release of the Taskmaster-1 dataset which includes 13,215 task-based dialogs comprising six domains. Two <a href=https://en.wikipedia.org/wiki/Procedure_(term)>procedures</a> were used to create this <a href=https://en.wikipedia.org/wiki/Collection_(abstract_data_type)>collection</a>, each with unique advantages. The first involves a two-person, spoken Wizard of Oz (WOz) approach in which trained agents and crowdsourced workers interact to complete the task while the second is self-dialog in which crowdsourced workers write the entire dialog themselves. We do not restrict the workers to detailed scripts or to a small knowledge base and hence we observe that our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> contains more realistic and diverse conversations in comparison to existing datasets. We offer several baseline models including state of the art neural seq2seq architectures with benchmark performance as well as qualitative human evaluations. Dialogs are labeled with <a href=https://en.wikipedia.org/wiki/Application_programming_interface>API calls</a> and arguments, a simple and cost effective approach which avoids the requirement of complex annotation schema. The layer of abstraction between the dialog model and the service provider API allows for a given <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to interact with multiple services that provide similar functionally. Finally, the dataset will evoke interest in <a href=https://en.wikipedia.org/wiki/Writing>written vs. spoken language</a>, <a href=https://en.wikipedia.org/wiki/Discourse_analysis>discourse patterns</a>, <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error handling</a> and other <a href=https://en.wikipedia.org/wiki/Linguistic_description>linguistic phenomena</a> related to dialog system research, development and design.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1324.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1324 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1324 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1324/>The Importance of Generation Order in Language Modeling</a></strong><br><a href=/people/n/nicolas-ford/>Nicolas Ford</a>
|
<a href=/people/d/daniel-duckworth/>Daniel Duckworth</a>
|
<a href=/people/m/mohammad-norouzi/>Mohammad Norouzi</a>
|
<a href=/people/g/george-dahl/>George Dahl</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1324><div class="card-body p-3 small">Neural language models are a critical component of state-of-the-art systems for <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a>, <a href=https://en.wikipedia.org/wiki/Transcription_(linguistics)>audio transcription</a>, and other tasks. These language models are almost universally autoregressive in nature, generating sentences one token at a time from left to right. This paper studies the influence of token generation order on model quality via a novel two-pass language model that produces partially-filled sentence templates and then fills in missing tokens. We compare various <a href=https://en.wikipedia.org/wiki/Strategy_(game_theory)>strategies</a> for structuring these two passes and observe a surprisingly large variation in model quality. We find the most effective <a href=https://en.wikipedia.org/wiki/Strategy>strategy</a> generates <a href=https://en.wikipedia.org/wiki/Function_word>function words</a> in the first pass followed by <a href=https://en.wikipedia.org/wiki/Content_word>content words</a> in the second. We believe these experimental results justify a more extensive investigation of the generation order for neural language models.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Daniel+Duckworth" title="Search for 'Daniel Duckworth' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/d/daphne-ippolito/ class=align-middle>Daphne Ippolito</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/arvind-neelakantan/ class=align-middle>Arvind Neelakantan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/chris-callison-burch/ class=align-middle>Chris Callison-Burch</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/douglas-eck/ class=align-middle>Douglas Eck</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nicolas-ford/ class=align-middle>Nicolas Ford</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/m/mohammad-norouzi/ class=align-middle>Mohammad Norouzi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/george-dahl/ class=align-middle>George Dahl</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bill-byrne/ class=align-middle>Bill Byrne</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/karthik-krishnamoorthi/ class=align-middle>Karthik Krishnamoorthi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chinnadhurai-sankar/ class=align-middle>Chinnadhurai Sankar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/ben-goodrich/ class=align-middle>Ben Goodrich</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/semih-yavuz/ class=align-middle>Semih Yavuz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/amit-dubey/ class=align-middle>Amit Dubey</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kyu-young-kim/ class=align-middle>Kyu-Young Kim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andy-cedilnik/ class=align-middle>Andy Cedilnik</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hugh-zhang/ class=align-middle>Hugh Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/humeval/ class=align-middle>HumEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>