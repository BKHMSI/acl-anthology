<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Dusan Varis - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Dusan</span> <span class=font-weight-bold>Varis</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Dušan <span class=font-weight-normal>Variš</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-demos.26.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-demos--26 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-demos.26 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-demos.26/>European Language Grid : A Joint Platform for the European Language Technology Community<span class=acl-fixed-case>E</span>uropean Language Grid: A Joint Platform for the <span class=acl-fixed-case>E</span>uropean Language Technology Community</a></strong><br><a href=/people/g/georg-rehm/>Georg Rehm</a>
|
<a href=/people/s/stelios-piperidis/>Stelios Piperidis</a>
|
<a href=/people/k/kalina-bontcheva/>Kalina Bontcheva</a>
|
<a href=/people/j/jan-hajic/>Jan Hajic</a>
|
<a href=/people/v/victoria-arranz/>Victoria Arranz</a>
|
<a href=/people/a/andrejs-vasiljevs/>Andrejs Vasiļjevs</a>
|
<a href=/people/g/gerhard-backfried/>Gerhard Backfried</a>
|
<a href=/people/j/jose-manuel-gomez-perez/>Jose Manuel Gomez-Perez</a>
|
<a href=/people/u/ulrich-germann/>Ulrich Germann</a>
|
<a href=/people/r/remi-calizzano/>Rémi Calizzano</a>
|
<a href=/people/n/nils-feldhus/>Nils Feldhus</a>
|
<a href=/people/s/stefanie-hegele/>Stefanie Hegele</a>
|
<a href=/people/f/florian-kintzel/>Florian Kintzel</a>
|
<a href=/people/k/katrin-marheinecke/>Katrin Marheinecke</a>
|
<a href=/people/j/julian-moreno-schneider/>Julian Moreno-Schneider</a>
|
<a href=/people/d/dimitrios-galanis/>Dimitris Galanis</a>
|
<a href=/people/p/penny-labropoulou/>Penny Labropoulou</a>
|
<a href=/people/m/miltos-deligiannis/>Miltos Deligiannis</a>
|
<a href=/people/k/katerina-gkirtzou/>Katerina Gkirtzou</a>
|
<a href=/people/a/athanasia-kolovou/>Athanasia Kolovou</a>
|
<a href=/people/d/dimitris-gkoumas/>Dimitris Gkoumas</a>
|
<a href=/people/l/leon-voukoutis/>Leon Voukoutis</a>
|
<a href=/people/i/ian-roberts/>Ian Roberts</a>
|
<a href=/people/j/jana-hamrlova/>Jana Hamrlova</a>
|
<a href=/people/d/dusan-varis/>Dusan Varis</a>
|
<a href=/people/l/lukas-kacena/>Lukas Kacena</a>
|
<a href=/people/k/khalid-choukri/>Khalid Choukri</a>
|
<a href=/people/v/valerie-mapelli/>Valérie Mapelli</a>
|
<a href=/people/m/mickael-rigault/>Mickaël Rigault</a>
|
<a href=/people/j/julija-melnika/>Julija Melnika</a>
|
<a href=/people/m/miro-janosik/>Miro Janosik</a>
|
<a href=/people/k/katja-prinz/>Katja Prinz</a>
|
<a href=/people/a/andres-garcia-silva/>Andres Garcia-Silva</a>
|
<a href=/people/c/cristian-berrio/>Cristian Berrio</a>
|
<a href=/people/o/ondrej-klejch/>Ondrej Klejch</a>
|
<a href=/people/s/steve-renals/>Steve Renals</a><br><a href=/volumes/2021.eacl-demos/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-demos--26><div class="card-body p-3 small">Europe is a <a href=https://en.wikipedia.org/wiki/Multilingualism>multilingual society</a>, in which dozens of languages are spoken. The only option to enable and to benefit from <a href=https://en.wikipedia.org/wiki/Multilingualism>multilingualism</a> is through <a href=https://en.wikipedia.org/wiki/Language_technology>Language Technologies (LT)</a>, i.e., <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a> and <a href=https://en.wikipedia.org/wiki/Speech_technology>Speech Technologies</a>. We describe the European Language Grid (ELG), which is targeted to evolve into the primary platform and marketplace for LT in Europe by providing one umbrella platform for the European LT landscape, including research and industry, enabling all stakeholders to upload, share and distribute their services, products and resources. At the end of our EU project, which will establish a legal entity in 2022, the ELG will provide access to approx. 1300 services for all European languages as well as thousands of data sets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.650.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--650 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.650 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.650/>Sequence Length is a Domain : Length-based Overfitting in Transformer Models</a></strong><br><a href=/people/d/dusan-varis/>Dusan Varis</a>
|
<a href=/people/o/ondrej-bojar/>Ondřej Bojar</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--650><div class="card-body p-3 small">Transformer-based sequence-to-sequence architectures, while achieving state-of-the-art results on a large number of NLP tasks, can still suffer from <a href=https://en.wikipedia.org/wiki/Overfitting>overfitting</a> during training. In practice, this is usually countered either by applying <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization methods</a> (e.g. dropout, L2-regularization) or by providing huge amounts of <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data</a>. Additionally, Transformer and other architectures are known to struggle when generating very long sequences. For example, in <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, the neural-based systems perform worse on very long sequences when compared to the preceding phrase-based translation approaches (Koehn and Knowles, 2017). We present results which suggest that the issue might also be in the mismatch between the length distributions of the training and validation data combined with the aforementioned tendency of the neural networks to overfit to the training data. We demonstrate on a simple string editing tasks and a machine translation task that the Transformer model performance drops significantly when facing sequences of length diverging from the length distribution in the training data. Additionally, we show that the observed drop in performance is due to the hypothesis length corresponding to the lengths seen by the model during training rather than the length of the input sequence.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wmt-1.82.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wmt-1--82 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wmt-1.82 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wmt-1.82/>CUNI Systems for WMT21 : Terminology Translation Shared Task<span class=acl-fixed-case>CUNI</span> Systems for <span class=acl-fixed-case>WMT</span>21: Terminology Translation Shared Task</a></strong><br><a href=/people/j/josef-jon/>Josef Jon</a>
|
<a href=/people/m/michal-novak/>Michal Novák</a>
|
<a href=/people/j/joao-paulo-aires/>João Paulo Aires</a>
|
<a href=/people/d/dusan-varis/>Dusan Varis</a>
|
<a href=/people/o/ondrej-bojar/>Ondřej Bojar</a><br><a href=/volumes/2021.wmt-1/ class=text-muted>Proceedings of the Sixth Conference on Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wmt-1--82><div class="card-body p-3 small">This paper describes Charles University sub-mission for Terminology translation Shared Task at WMT21. The objective of this task is to design a <a href=https://en.wikipedia.org/wiki/System>system</a> which translates certain terms based on a provided <a href=https://en.wikipedia.org/wiki/Terminology_database>terminology database</a>, while preserving high overall translation quality. We competed in English-French language pair. Our approach is based on providing the desired translations alongside the input sentence and training the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> to use these provided terms. We lemmatize the terms both during the <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a> and inference, to allow the model to learn how to produce correct surface forms of the words, when they differ from the forms provided in the <a href=https://en.wikipedia.org/wiki/Terminology_database>terminology database</a>. Our submission ranked second in Exact Match metric which evaluates the ability of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to produce desired terms in the translation.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-2017.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-2017 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-2017 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-2017/>Unsupervised Pretraining for <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> Using Elastic Weight Consolidation</a></strong><br><a href=/people/d/dusan-varis/>Dušan Variš</a>
|
<a href=/people/o/ondrej-bojar/>Ondřej Bojar</a><br><a href=/volumes/P19-2/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-2017><div class="card-body p-3 small">This work presents our ongoing research of unsupervised pretraining in neural machine translation (NMT). In our method, we initialize the weights of the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> and <a href=https://en.wikipedia.org/wiki/Code>decoder</a> with two language models that are trained with monolingual data and then fine-tune the model on parallel data using Elastic Weight Consolidation (EWC) to avoid forgetting of the original language modeling task. We compare the <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization</a> by EWC with the previous work that focuses on <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization</a> by language modeling objectives. The positive result is that using EWC with the <a href=https://en.wikipedia.org/wiki/Codec>decoder</a> achieves BLEU scores similar to the previous work. However, the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> converges 2-3 times faster and does not require the original unlabeled training data during the fine-tuning stage. In contrast, the <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization</a> using EWC is less effective if the original and new tasks are not closely related. We show that initializing the bidirectional NMT encoder with a left-to-right language model and forcing the model to remember the original left-to-right language modeling task limits the learning capacity of the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> for the whole bidirectional context.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6441.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6441 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6441 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6441/>CUNI System for the WMT18 Multimodal Translation Task<span class=acl-fixed-case>CUNI</span> System for the <span class=acl-fixed-case>WMT</span>18 Multimodal Translation Task</a></strong><br><a href=/people/j/jindrich-helcl/>Jindřich Helcl</a>
|
<a href=/people/j/jindrich-libovicky/>Jindřich Libovický</a>
|
<a href=/people/d/dusan-varis/>Dušan Variš</a><br><a href=/volumes/W18-64/ class=text-muted>Proceedings of the Third Conference on Machine Translation: Shared Task Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6441><div class="card-body p-3 small">We present our submission to the WMT18 Multimodal Translation Task. The main feature of our submission is applying a self-attentive network instead of a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network</a>. We evaluate two methods of incorporating the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>visual features</a> in the <a href=https://en.wikipedia.org/wiki/Computer_simulation>model</a> : first, we include the image representation as another input to the network ; second, we train the <a href=https://en.wikipedia.org/wiki/Computer_simulation>model</a> to predict the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>visual features</a> and use it as an auxiliary objective. For our submission, we acquired both textual and multimodal additional data. Both of the proposed methods yield significant improvements over <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent networks</a> and self-attentive textual baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2018--iwslt-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2018.iwslt-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2018.iwslt-1.21/>CUNI Basque-to-English Submission in IWSLT18<span class=acl-fixed-case>CUNI</span> <span class=acl-fixed-case>B</span>asque-to-<span class=acl-fixed-case>E</span>nglish Submission in <span class=acl-fixed-case>IWSLT</span>18</a></strong><br><a href=/people/t/tom-kocmi/>Tom Kocmi</a>
|
<a href=/people/d/dusan-varis/>Dušan Variš</a>
|
<a href=/people/o/ondrej-bojar/>Ondřej Bojar</a><br><a href=/volumes/2018.iwslt-1/ class=text-muted>Proceedings of the 15th International Conference on Spoken Language Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2018--iwslt-1--21><div class="card-body p-3 small">We present our submission to the IWSLT18 Low Resource task focused on the translation from Basque-to-English. Our submission is based on the current state-of-the-art self-attentive neural network architecture, Transformer. We further improve this strong <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baseline</a> by exploiting available <a href=https://en.wikipedia.org/wiki/Monolingualism>monolingual data</a> using the back-translation technique. We also present further improvements gained by a <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>, a technique that trains a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> using a high-resource language pair (Czech-English) and then fine-tunes the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> using the target low-resource language pair (Basque-English).</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5715.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5715 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5715 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5715/>CUNI NMT System for WAT 2017 Translation Tasks<span class=acl-fixed-case>CUNI</span> <span class=acl-fixed-case>NMT</span> System for <span class=acl-fixed-case>WAT</span> 2017 Translation Tasks</a></strong><br><a href=/people/t/tom-kocmi/>Tom Kocmi</a>
|
<a href=/people/d/dusan-varis/>Dušan Variš</a>
|
<a href=/people/o/ondrej-bojar/>Ondřej Bojar</a><br><a href=/volumes/W17-57/ class=text-muted>Proceedings of the 4th Workshop on Asian Translation (WAT2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5715><div class="card-body p-3 small">The paper presents this year&#8217;s CUNI submissions to the WAT 2017 Translation Task focusing on the Japanese-English translation, namely Scientific papers subtask, Patents subtask and Newswire subtask. We compare two neural network architectures, the standard sequence-to-sequence with attention (Seq2Seq) and an architecture using convolutional sentence encoder (FBConv2Seq), both implemented in the NMT framework Neural Monkey that we currently participate in developing. We also compare various types of preprocessing of the source <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>Japanese sentences</a> and their impact on the overall results. Furthermore, we include the results of our experiments with out-of-domain data obtained by combining the corpora provided for each subtask.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Dusan+Varis" title="Search for 'Dusan Varis' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/o/ondrej-bojar/ class=align-middle>Ondřej Bojar</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/t/tom-kocmi/ class=align-middle>Tom Kocmi</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/g/georg-rehm/ class=align-middle>Georg Rehm</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stelios-piperidis/ class=align-middle>Stelios Piperidis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kalina-bontcheva/ class=align-middle>Kalina Bontcheva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/j/jan-hajic/ class=align-middle>Jan Hajic</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/victoria-arranz/ class=align-middle>Victoria Arranz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrejs-vasiljevs/ class=align-middle>Andrejs Vasiļjevs</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gerhard-backfried/ class=align-middle>Gerhard Backfried</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jose-manuel-gomez-perez/ class=align-middle>José Manuel Gómez-Pérez</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/u/ulrich-germann/ class=align-middle>Ulrich Germann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/remi-calizzano/ class=align-middle>Rémi Calizzano</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nils-feldhus/ class=align-middle>Nils Feldhus</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stefanie-hegele/ class=align-middle>Stefanie Hegele</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/florian-kintzel/ class=align-middle>Florian Kintzel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/katrin-marheinecke/ class=align-middle>Katrin Marheinecke</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/julian-moreno-schneider/ class=align-middle>Julian Moreno Schneider</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dimitrios-galanis/ class=align-middle>Dimitrios Galanis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/penny-labropoulou/ class=align-middle>Penny Labropoulou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/miltos-deligiannis/ class=align-middle>Miltos Deligiannis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/katerina-gkirtzou/ class=align-middle>Katerina Gkirtzou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/athanasia-kolovou/ class=align-middle>Athanasia Kolovou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dimitris-gkoumas/ class=align-middle>Dimitris Gkoumas</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/leon-voukoutis/ class=align-middle>Leon Voukoutis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ian-roberts/ class=align-middle>Ian Roberts</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jana-hamrlova/ class=align-middle>Jana Hamrlova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lukas-kacena/ class=align-middle>Lukas Kacena</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/khalid-choukri/ class=align-middle>Khalid Choukri</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/valerie-mapelli/ class=align-middle>Valérie Mapelli</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mickael-rigault/ class=align-middle>Mickaël Rigault</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/julija-melnika/ class=align-middle>Julija Melnika</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/miro-janosik/ class=align-middle>Miro Janosik</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/katja-prinz/ class=align-middle>Katja Prinz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andres-garcia-silva/ class=align-middle>Andres Garcia-Silva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cristian-berrio/ class=align-middle>Cristian Berrio</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/ondrej-klejch/ class=align-middle>Ondrej Klejch</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/steve-renals/ class=align-middle>Steve Renals</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/josef-jon/ class=align-middle>Josef Jon</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michal-novak/ class=align-middle>Michal Novák</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joao-paulo-aires/ class=align-middle>João Paulo Aires</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jindrich-helcl/ class=align-middle>Jindřich Helcl</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jindrich-libovicky/ class=align-middle>Jindřich Libovický</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wmt/ class=align-middle>WMT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/iwslt/ class=align-middle>IWSLT</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>