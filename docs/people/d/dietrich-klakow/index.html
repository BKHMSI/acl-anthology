<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Dietrich Klakow - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Dietrich</span> <span class=font-weight-bold>Klakow</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-srw.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-srw--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-srw.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-srw.3/>Do we read what we hear? Modeling orthographic influences on <a href=https://en.wikipedia.org/wiki/Spoken_word_recognition>spoken word recognition</a></a></strong><br><a href=/people/n/nicole-macher/>Nicole Macher</a>
|
<a href=/people/b/badr-m-abdullah/>Badr M. Abdullah</a>
|
<a href=/people/h/harm-brouwer/>Harm Brouwer</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a><br><a href=/volumes/2021.eacl-srw/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-srw--3><div class="card-body p-3 small">Theories and models of <a href=https://en.wikipedia.org/wiki/Spoken_word_recognition>spoken word recognition</a> aim to explain the process of accessing lexical knowledge given an acoustic realization of a word form. There is consensus that <a href=https://en.wikipedia.org/wiki/Phonology>phonological and semantic information</a> is crucial for this <a href=https://en.wikipedia.org/wiki/Process_(philosophy)>process</a>. However, there is accumulating evidence that orthographic information could also have an impact on auditory word recognition. This paper presents two <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> of <a href=https://en.wikipedia.org/wiki/Spoken_word_recognition>spoken word recognition</a> that instantiate different hypotheses regarding the influence of <a href=https://en.wikipedia.org/wiki/Orthography>orthography</a> on this process. We show that these models reproduce human-like behavior in different ways and provide testable hypotheses for future research on the source of orthographic effects in spoken word recognition.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.lantern-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.lantern-1.0/>Proceedings of the Third Workshop on Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN)</a></strong><br><a href=/people/m/marius-mosbach/>Marius Mosbach</a>
|
<a href=/people/m/michael-a-hedderich/>Michael A. Hedderich</a>
|
<a href=/people/s/sandro-pezzelle/>Sandro Pezzelle</a>
|
<a href=/people/a/aditya-mogadala/>Aditya Mogadala</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a>
|
<a href=/people/m/marie-francine-moens/>Marie-Francine Moens</a>
|
<a href=/people/z/zeynep-akata/>Zeynep Akata</a><br><a href=/volumes/2021.lantern-1/ class=text-muted>Proceedings of the Third Workshop on Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.689.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--689 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.689 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.689" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.689/>To Share or not to Share : Predicting Sets of Sources for Model Transfer Learning<span class=acl-fixed-case>P</span>redicting Sets of Sources for Model Transfer Learning</a></strong><br><a href=/people/l/lukas-lange/>Lukas Lange</a>
|
<a href=/people/j/jannik-strotgen/>Jannik Strötgen</a>
|
<a href=/people/h/heike-adel/>Heike Adel</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--689><div class="card-body p-3 small">In low-resource settings, model transfer can help to overcome a lack of labeled data for many tasks and domains. However, predicting useful transfer sources is a challenging problem, as even the most similar sources might lead to unexpected negative transfer results. Thus, ranking methods based on task and text similarity as suggested in prior work may not be sufficient to identify promising sources. To tackle this problem, we propose a new approach to automatically determine which and how many sources should be exploited. For this, we study the effects of model transfer on <a href=https://en.wikipedia.org/wiki/Sequence_labeling>sequence labeling</a> across various domains and tasks and show that our methods based on model similarity and support vector machines are able to predict promising sources, resulting in performance increases of up to 24 F1 points.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.isa-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--isa-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.isa-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.isa-1.5/>Discourse-based Argument Segmentation and Annotation</a></strong><br><a href=/people/e/ekaterina-saveleva/>Ekaterina Saveleva</a>
|
<a href=/people/v/volha-petukhova/>Volha Petukhova</a>
|
<a href=/people/m/marius-mosbach/>Marius Mosbach</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a><br><a href=/volumes/2021.isa-1/ class=text-muted>Proceedings of the 17th Joint ACL - ISO Workshop on Interoperable Semantic Annotation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--isa-1--5><div class="card-body p-3 small">The paper presents a discourse-based approach to the analysis of argumentative texts departing from the assumption that the coherence of a text should capture argumentation structure as well and, therefore, existing discourse analysis tools can be successfully applied for argument segmentation and annotation tasks. We tested the widely used Penn Discourse Tree Bank full parser (Lin et al., 2010) and the state-of-the-art neural network NeuralEDUSeg (Wang et al., 2018) and XLNet (Yang et al., 2019) models on the two-stage discourse segmentation and discourse relation recognition. The two-stage approach outperformed the PDTB parser by broad margin, i.e. the best achieved F1 scores of 21.2 % for PDTB parser vs 66.37 % for NeuralEDUSeg and XLNet models. Neural network models were fine-tuned and evaluated on the argumentative corpus showing a promising <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 60.22 %. The complete <a href=https://en.wikipedia.org/wiki/Argument_(linguistics)>argument structures</a> were reconstructed for further argumentation mining tasks. The reference Dagstuhl argumentative corpus containing 2,222 elementary discourse unit pairs annotated with the top-level and fine-grained PDTB relations will be released to the research community.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.641.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--641 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.641 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929190 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.641/>Neural Data-to-Text Generation via Jointly Learning the Segmentation and Correspondence</a></strong><br><a href=/people/x/xiaoyu-shen/>Xiaoyu Shen</a>
|
<a href=/people/e/ernie-chang/>Ernie Chang</a>
|
<a href=/people/h/hui-su/>Hui Su</a>
|
<a href=/people/c/cheng-niu/>Cheng Niu</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--641><div class="card-body p-3 small">The neural attention model has achieved great success in data-to-text generation tasks. Though usually excelling at producing fluent text, it suffers from the problem of information missing, <a href=https://en.wikipedia.org/wiki/Repetition_(rhetorical_device)>repetition</a> and <a href=https://en.wikipedia.org/wiki/Hallucination>hallucination</a>. Due to the black-box nature of the neural attention architecture, avoiding these problems in a systematic way is non-trivial. To address this concern, we propose to explicitly segment target text into fragment units and align them with their data correspondences. The segmentation and correspondence are jointly learned as <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a> without any human annotations. We further impose a soft statistical constraint to regularize the segmental granularity. The resulting architecture maintains the same <a href=https://en.wikipedia.org/wiki/Expressive_power_(computer_science)>expressive power</a> as neural attention models, while being able to generate fully interpretable outputs with several times less <a href=https://en.wikipedia.org/wiki/Computational_cost>computational cost</a>. On both E2E and WebNLG benchmarks, we show the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> consistently outperforms its neural attention counterparts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.insights-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--insights-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.insights-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940795 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.insights-1.8/>Label Propagation-Based Semi-Supervised Learning for Hate Speech Classification</a></strong><br><a href=/people/a/ashwin-geet-dsa/>Ashwin Geet D’Sa</a>
|
<a href=/people/i/irina-illina/>Irina Illina</a>
|
<a href=/people/d/dominique-fohr/>Dominique Fohr</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a>
|
<a href=/people/d/dana-ruiter/>Dana Ruiter</a><br><a href=/volumes/2020.insights-1/ class=text-muted>Proceedings of the First Workshop on Insights from Negative Results in NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--insights-1--8><div class="card-body p-3 small">Research on hate speech classification has received increased attention. In real-life scenarios, a small amount of labeled hate speech data is available to train a reliable <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a>. Semi-supervised learning takes advantage of a small amount of <a href=https://en.wikipedia.org/wiki/Labeled_data>labeled data</a> and a large amount of <a href=https://en.wikipedia.org/wiki/Labeled_data>unlabeled data</a>. In this paper, label propagation-based semi-supervised learning is explored for the task of hate speech classification. The quality of labeling the unlabeled set depends on the input representations. In this work, we show that pre-trained representations are label agnostic, and when used with label propagation yield poor results. Neural network-based fine-tuning can be adopted to learn task-specific representations using a small amount of <a href=https://en.wikipedia.org/wiki/Labeled_data>labeled data</a>. We show that fully fine-tuned representations may not always be the best representations for the label propagation and intermediate representations may perform better in a <a href=https://en.wikipedia.org/wiki/Semi-supervised_learning>semi-supervised setup</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.blackboxnlp-1.29.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--blackboxnlp-1--29 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.blackboxnlp-1.29 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.blackboxnlp-1.29/>Defining Explanation in an AI Context<span class=acl-fixed-case>AI</span> Context</a></strong><br><a href=/people/t/tejaswani-verma/>Tejaswani Verma</a>
|
<a href=/people/c/christoph-lingenfelder/>Christoph Lingenfelder</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a><br><a href=/volumes/2020.blackboxnlp-1/ class=text-muted>Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--blackboxnlp-1--29><div class="card-body p-3 small">With the increase in the use of <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI systems</a>, a need for explanation systems arises. Building an <a href=https://en.wikipedia.org/wiki/Explanation>explanation system</a> requires a definition of <a href=https://en.wikipedia.org/wiki/Explanation>explanation</a>. However, the natural language term explanation is difficult to define formally as it includes multiple perspectives from different domains such as <a href=https://en.wikipedia.org/wiki/Psychology>psychology</a>, <a href=https://en.wikipedia.org/wiki/Philosophy>philosophy</a>, and <a href=https://en.wikipedia.org/wiki/Cognitive_science>cognitive sciences</a>. We study multiple perspectives and aspects of explainability of recommendations or predictions made by <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI systems</a>, and provide a generic definition of <a href=https://en.wikipedia.org/wiki/Explanation>explanation</a>. The proposed <a href=https://en.wikipedia.org/wiki/Definition>definition</a> is ambitious and challenging to apply. With the intention to bridge the gap between theory and application, we also propose a possible architecture of an automated explanation system based on our definition of explanation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lantern-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lantern-1.0/>Proceedings of the Second Workshop on Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN)</a></strong><br><a href=/people/a/aditya-mogadala/>Aditya Mogadala</a>
|
<a href=/people/s/sandro-pezzelle/>Sandro Pezzelle</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a>
|
<a href=/people/m/marie-francine-moens/>Marie-Francine Moens</a>
|
<a href=/people/z/zeynep-akata/>Zeynep Akata</a><br><a href=/volumes/2020.lantern-1/ class=text-muted>Proceedings of the Second Workshop on Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN)</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1362.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1362 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1362 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1362" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1362/>Feature-Dependent Confusion Matrices for Low-Resource NER Labeling with Noisy Labels<span class=acl-fixed-case>NER</span> Labeling with Noisy Labels</a></strong><br><a href=/people/l/lukas-lange/>Lukas Lange</a>
|
<a href=/people/m/michael-a-hedderich/>Michael A. Hedderich</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1362><div class="card-body p-3 small">In low-resource settings, the performance of supervised labeling models can be improved with automatically annotated or distantly supervised data, which is cheap to create but often noisy. Previous works have shown that significant improvements can be reached by injecting information about the confusion between clean and noisy labels in this additional training data into the classifier training. However, for noise estimation, these approaches either do not take the input <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> (in our case word embeddings) into account, or they need to learn the noise modeling from scratch which can be difficult in a low-resource setting. We propose to cluster the training data using the input <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> and then compute different <a href=https://en.wikipedia.org/wiki/Confusion_matrix>confusion matrices</a> for each <a href=https://en.wikipedia.org/wiki/Cluster_analysis>cluster</a>. To the best of our knowledge, our approach is the first to leverage feature-dependent noise modeling with pre-initialized confusion matrices. We evaluate on low-resource named entity recognition settings in several languages, showing that our methods improve upon other confusion-matrix based methods by up to 9 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1390.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1390 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1390 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1390.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-1390/>Improving Latent Alignment in Text Summarization by Generalizing the Pointer Generator</a></strong><br><a href=/people/x/xiaoyu-shen/>Xiaoyu Shen</a>
|
<a href=/people/y/yang-zhao/>Yang Zhao</a>
|
<a href=/people/h/hui-su/>Hui Su</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1390><div class="card-body p-3 small">Pointer Generators have been the de facto standard for modern summarization systems. However, this architecture faces two major drawbacks : Firstly, the <a href=https://en.wikipedia.org/wiki/Pointer_(computer_programming)>pointer</a> is limited to copying the exact words while ignoring possible <a href=https://en.wikipedia.org/wiki/Inflection_point>inflections</a> or <a href=https://en.wikipedia.org/wiki/Abstraction_(computer_science)>abstractions</a>, which restricts its power of capturing richer latent alignment. Secondly, the copy mechanism results in a strong bias towards extractive generations, where most sentences are produced by simply copying from the source text. In this paper, we address these problems by allowing the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to edit pointed tokens instead of always hard copying them. The editing is performed by transforming the pointed word vector into a target space with a learned <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>relation embedding</a>. On three large-scale summarization dataset, we show the model is able to (1) capture more latent alignment relations than exact word matches, (2) improve word alignment accuracy, allowing for better model interpretation and controlling, (3) generate higher-quality summaries validated by both qualitative and quantitative evaluations and (4) bring more abstraction to the generated summaries.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6400.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6400/>Proceedings of the Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN)</a></strong><br><a href=/people/a/aditya-mogadala/>Aditya Mogadala</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a>
|
<a href=/people/s/sandro-pezzelle/>Sandro Pezzelle</a>
|
<a href=/people/m/marie-francine-moens/>Marie-Francine Moens</a><br><a href=/volumes/D19-64/ class=text-muted>Proceedings of the Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-0421.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-0421 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-0421 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-0421" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-0421/>Using Multi-Sense Vector Embeddings for Reverse Dictionaries</a></strong><br><a href=/people/m/michael-a-hedderich/>Michael A. Hedderich</a>
|
<a href=/people/a/andrew-yates/>Andrew Yates</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a>
|
<a href=/people/g/gerard-de-melo/>Gerard de Melo</a><br><a href=/volumes/W19-04/ class=text-muted>Proceedings of the 13th International Conference on Computational Semantics - Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-0421><div class="card-body p-3 small">Popular word embedding methods such as <a href=https://en.wikipedia.org/wiki/Word2vec>word2vec</a> and GloVe assign a single vector representation to each word, even if a word has multiple distinct meanings. Multi-sense embeddings instead provide different vectors for each sense of a word. However, they typically can not serve as a drop-in replacement for conventional single-sense embeddings, because the correct sense vector needs to be selected for each word. In this work, we study the effect of multi-sense embeddings on the task of <a href=https://en.wikipedia.org/wiki/Reverse_dictionary>reverse dictionaries</a>. We propose a <a href=https://en.wikipedia.org/wiki/Scientific_technique>technique</a> to easily integrate them into an existing <a href=https://en.wikipedia.org/wiki/Neural_network>neural network architecture</a> using an <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanism</a>. Our experiments demonstrate that large improvements can be obtained when employing multi-sense embeddings both in the input sequence as well as for the target representation. An analysis of the sense distributions and of the learned attention is provided as well.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1094.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1094 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1094 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1094/>incom.py-A Toolbox for Calculating Linguistic Distances and Asymmetries between Related Languages</a></strong><br><a href=/people/m/marius-mosbach/>Marius Mosbach</a>
|
<a href=/people/i/irina-stenger/>Irina Stenger</a>
|
<a href=/people/t/tania-avgustinova/>Tania Avgustinova</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a><br><a href=/volumes/R19-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1094><div class="card-body p-3 small">Languages may be differently distant from each other and their <a href=https://en.wikipedia.org/wiki/Mutual_intelligibility>mutual intelligibility</a> may be asymmetric. In this paper we introduce incom.py, a toolbox for calculating <a href=https://en.wikipedia.org/wiki/Linguistic_distance>linguistic distances</a> and asymmetries between related languages. incom.py allows linguist experts to quickly and easily perform <a href=https://en.wikipedia.org/wiki/Statistics>statistical analyses</a> and compare those with experimental results. We demonstrate the efficacy of incom.py in an incomprehension experiment on two <a href=https://en.wikipedia.org/wiki/Slavic_languages>Slavic languages</a> : <a href=https://en.wikipedia.org/wiki/Bulgarian_language>Bulgarian</a> and <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a>. Using incom.py we were able to validate three methods to measure linguistic distances and asymmetries : <a href=https://en.wikipedia.org/wiki/Levenshtein_distance>Levenshtein distance</a>, word adaptation surprisal, and <a href=https://en.wikipedia.org/wiki/Conditional_entropy>conditional entropy</a> as predictors of success in a reading intercomprehension experiment.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5425.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5425 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5425 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5425/>Closing Brackets with Recurrent Neural Networks</a></strong><br><a href=/people/n/natalia-skachkova/>Natalia Skachkova</a>
|
<a href=/people/t/thomas-alexander-trost/>Thomas Trost</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a><br><a href=/volumes/W18-54/ class=text-muted>Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5425><div class="card-body p-3 small">Many natural and formal languages contain words or symbols that require a matching counterpart for making an expression well-formed. The combination of opening and closing brackets is a typical example of such a construction. Due to their commonness, the ability to follow such <a href=https://en.wikipedia.org/wiki/Rule_of_inference>rules</a> is important for <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>. Currently, recurrent neural networks (RNNs) are extensively used for this <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>. We investigate whether they are capable of learning the rules of opening and closing brackets by applying them to synthetic Dyck languages that consist of different types of <a href=https://en.wikipedia.org/wiki/Bracket>brackets</a>. We provide an analysis of the statistical properties of these languages as a baseline and show strengths and limits of Elman-RNNs, GRUs and LSTMs in experiments on random samples of these languages. In terms of perplexity and prediction accuracy, the RNNs get close to the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>theoretical baseline</a> in most cases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6546.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6546 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6546 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6546/>Toward Bayesian Synchronous Tree Substitution Grammars for Sentence Planning<span class=acl-fixed-case>B</span>ayesian Synchronous Tree Substitution Grammars for Sentence Planning</a></strong><br><a href=/people/d/david-m-howcroft/>David M. Howcroft</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a>
|
<a href=/people/v/vera-demberg/>Vera Demberg</a><br><a href=/volumes/W18-65/ class=text-muted>Proceedings of the 11th International Conference on Natural Language Generation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6546><div class="card-body p-3 small">Developing conventional natural language generation systems requires extensive attention from human experts in order to craft complex sets of sentence planning rules. We propose a Bayesian nonparametric approach to learn sentence planning rules by inducing synchronous tree substitution grammars for pairs of text plans and morphosyntactically-specified dependency trees. Our system is able to learn rules which can be used to generate novel texts after training on small datasets.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2404.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2404 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2404 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2404/>Parameter Free Hierarchical Graph-Based Clustering for Analyzing Continuous Word Embeddings</a></strong><br><a href=/people/t/thomas-alexander-trost/>Thomas Alexander Trost</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a><br><a href=/volumes/W17-24/ class=text-muted>Proceedings of TextGraphs-11: the Workshop on Graph-based Methods for Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2404><div class="card-body p-3 small">Word embeddings are high-dimensional vector representations of words and are thus difficult to interpret. In order to deal with this, we introduce an unsupervised parameter free method for creating a hierarchical graphical clustering of the full ensemble of word vectors and show that this structure is a geometrically meaningful representation of the original relations between the words. This newly obtained representation can be used for better understanding and thus improving the <a href=https://en.wikipedia.org/wiki/Embedding>embedding algorithm</a> and exhibits <a href=https://en.wikipedia.org/wiki/Semantics>semantic meaning</a>, so it can also be utilized in a variety of language processing tasks like <a href=https://en.wikipedia.org/wiki/Categorization>categorization</a> or <a href=https://en.wikipedia.org/wiki/Similarity_measure>measuring similarity</a>.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Dietrich+Klakow" title="Search for 'Dietrich Klakow' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/m/marius-mosbach/ class=align-middle>Marius Mosbach</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/michael-a-hedderich/ class=align-middle>Michael A. Hedderich</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/sandro-pezzelle/ class=align-middle>Sandro Pezzelle</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/aditya-mogadala/ class=align-middle>Aditya Mogadala</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/marie-francine-moens/ class=align-middle>Marie Francine Moens</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/x/xiaoyu-shen/ class=align-middle>Xiaoyu Shen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hui-su/ class=align-middle>Hui Su</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/thomas-alexander-trost/ class=align-middle>Thomas Alexander Trost</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/zeynep-akata/ class=align-middle>Zeynep Akata</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/lukas-lange/ class=align-middle>Lukas Lange</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/ernie-chang/ class=align-middle>Ernie Chang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cheng-niu/ class=align-middle>Cheng Niu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nicole-macher/ class=align-middle>Nicole Macher</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/badr-m-abdullah/ class=align-middle>Badr M. Abdullah</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/harm-brouwer/ class=align-middle>Harm Brouwer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jannik-strotgen/ class=align-middle>Jannik Strötgen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/heike-adel/ class=align-middle>Heike Adel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yang-zhao/ class=align-middle>Yang Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/ekaterina-saveleva/ class=align-middle>Ekaterina Saveleva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/volha-petukhova/ class=align-middle>Volha Petukhova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/natalia-skachkova/ class=align-middle>Natalia Skachkova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/david-m-howcroft/ class=align-middle>David M. Howcroft</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vera-demberg/ class=align-middle>Vera Demberg</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrew-yates/ class=align-middle>Andrew Yates</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gerard-de-melo/ class=align-middle>Gerard de Melo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ashwin-geet-dsa/ class=align-middle>Ashwin Geet D’Sa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/irina-illina/ class=align-middle>Irina Illina</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dominique-fohr/ class=align-middle>Dominique Fohr</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dana-ruiter/ class=align-middle>Dana Ruiter</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tejaswani-verma/ class=align-middle>Tejaswani Verma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christoph-lingenfelder/ class=align-middle>Christoph Lingenfelder</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/irina-stenger/ class=align-middle>Irina Stenger</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tania-avgustinova/ class=align-middle>Tania Avgustinova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/lantern/ class=align-middle>LANTERN</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/isa/ class=align-middle>ISA</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/insights/ class=align-middle>insights</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/blackboxnlp/ class=align-middle>BlackboxNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ranlp/ class=align-middle>RANLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>