<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Dongmei Zhang - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Dongmei</span> <span class=font-weight-bold>Zhang</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.78.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--78 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.78 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2022.acl-long.78.software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.acl-long.78" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.78/>HiTab A Hierarchical Table Dataset for <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a> and Natural Language Generation<span class=acl-fixed-case>H</span>i<span class=acl-fixed-case>T</span>ab: A Hierarchical Table Dataset for Question Answering and Natural Language Generation</a></strong><br><a href=/people/z/zhoujun-cheng/>Zhoujun Cheng</a>
|
<a href=/people/h/haoyu-dong/>Haoyu Dong</a>
|
<a href=/people/z/zhiruo-wang/>Zhiruo Wang</a>
|
<a href=/people/r/ran-jia/>Ran Jia</a>
|
<a href=/people/j/jiaqi-guo/>Jiaqi Guo</a>
|
<a href=/people/y/yan-gao/>Yan Gao</a>
|
<a href=/people/s/shi-han/>Shi Han</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/d/dongmei-zhang/>Dongmei Zhang</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--78><div class="card-body p-3 small">Tables are often created with hierarchies but existing works on table reasoning mainly focus on flat tables and neglect hierarchical tables Hierarchical tables challenge numerical reasoning by complex hierarchical indexing as well as implicit relationships of calculation and semantics We present a new dataset HiTab to study question answering QA and natural language generation NLG over hierarchical tables HiTab is a cross domain dataset constructed from a wealth of statistical reports and Wikipedia pages and has unique characteristics nearly all tables are hierarchical and QA pairs are not proposed by annotators from scratch but are revised from real and meaningful sentences authored by analysts to reveal complex numerical reasoning in statistical reports we provide fine grained annotations of quantity and entity alignment Experiments suggest that this HiTab presents a strong challenge for existing baselines and a valuable benchmark for future research Targeting hierarchical structure we devise a hierarchy aware logical form for symbolic reasoning over tables which shows high effectiveness Targeting table reasoning we leverage entity and quantity alignment to explore partially supervised training in QA and conditional generation in NLG and largely reduce spurious predictions in QA and produce better descriptions in NLG</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.82.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--82 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.82 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2022.acl-long.82.software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.acl-long.82" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.82/><span class=acl-fixed-case>FORTAP</span>: Using Formulas for Numerical-Reasoning-Aware Table Pretraining</a></strong><br><a href=/people/z/zhoujun-cheng/>Zhoujun Cheng</a>
|
<a href=/people/h/haoyu-dong/>Haoyu Dong</a>
|
<a href=/people/r/ran-jia/>Ran Jia</a>
|
<a href=/people/p/pengfei-wu/>Pengfei Wu</a>
|
<a href=/people/s/shi-han/>Shi Han</a>
|
<a href=/people/f/fan-cheng/>Fan Cheng</a>
|
<a href=/people/d/dongmei-zhang/>Dongmei Zhang</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--82><div class="card-body p-3 small">Tables store rich numerical data, but numerical reasoning over tables is still a challenge. In this paper, we find that the spreadsheet formula, a commonly used language to perform computations on numerical values in spreadsheets, is a valuable supervision for numerical reasoning in tables. Considering large amounts of spreadsheets available on the web, we propose FORTAP, the first exploration to leverage spreadsheet formulas for table pretraining. Two novel self-supervised pretraining objectives are derived from formulas, numerical reference prediction (NRP) and numerical calculation prediction (NCP). While our proposed objectives are generic for encoders, to better capture spreadsheet table layouts and structures, FORTAP is built upon TUTA, the first transformer-based method for spreadsheet table pretraining with tree attention. FORTAP outperforms state-of-the-art methods by large margins on three representative datasets of formula prediction, question answering, and cell type classification, showing the great potential of leveraging formulas for table pretraining.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.181.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--181 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.181 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.181/>Accelerating Code Search with Deep Hashing and Code Classification</a></strong><br><a href=/people/w/wenchao-gu/>Wenchao Gu</a>
|
<a href=/people/y/yanlin-wang/>Yanlin Wang</a>
|
<a href=/people/l/lun-du/>Lun Du</a>
|
<a href=/people/h/hongyu-zhang/>Hongyu Zhang</a>
|
<a href=/people/s/shi-han/>Shi Han</a>
|
<a href=/people/d/dongmei-zhang/>Dongmei Zhang</a>
|
<a href=/people/m/michael-lyu/>Michael Lyu</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--181><div class="card-body p-3 small">Code search is to search reusable code snippets from <a href=https://en.wikipedia.org/wiki/Text_corpus>source code corpus</a> based on natural languages queries Deep learning based methods on code search have shown promising results However previous <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> focus on retrieval accuracy but lacked attention to the efficiency of the retrieval process We propose a novel method CoSHC to accelerate code search with deep hashing and code classification aiming to perform efficient code search without sacrificing too much accuracy To evaluate the effectiveness of CoSHC we apply our method \n on five code search models Extensive experimental results indicate that compared with previous code search baselines CoSHC can save more than of retrieval time meanwhile preserving at least of retrieval accuracy</div></div><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.332.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--332 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.332 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.332" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.332/>CAST : Enhancing Code Summarization with Hierarchical Splitting and Reconstruction of Abstract Syntax Trees<span class=acl-fixed-case>CAST</span>: Enhancing Code Summarization with Hierarchical Splitting and Reconstruction of Abstract Syntax Trees</a></strong><br><a href=/people/e/ensheng-shi/>Ensheng Shi</a>
|
<a href=/people/y/yanlin-wang/>Yanlin Wang</a>
|
<a href=/people/l/lun-du/>Lun Du</a>
|
<a href=/people/h/hongyu-zhang/>Hongyu Zhang</a>
|
<a href=/people/s/shi-han/>Shi Han</a>
|
<a href=/people/d/dongmei-zhang/>Dongmei Zhang</a>
|
<a href=/people/h/hongbin-sun/>Hongbin Sun</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--332><div class="card-body p-3 small">Code summarization aims to generate concise natural language descriptions of source code, which can help improve program comprehension and maintenance. Recent studies show that syntactic and structural information extracted from abstract syntax trees (ASTs) is conducive to summary generation. However, existing approaches fail to fully capture the rich information in ASTs because of the large size / depth of ASTs. In this paper, we propose a novel model CAST that hierarchically splits and reconstructs ASTs. First, we hierarchically split a large <a href=https://en.wikipedia.org/wiki/Abstract_syntax_tree>AST</a> into a set of <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>subtrees</a> and utilize a <a href=https://en.wikipedia.org/wiki/Recursive_neural_network>recursive neural network</a> to encode the <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>subtrees</a>. Then, we aggregate the embeddings of subtrees by reconstructing the split ASTs to get the representation of the complete AST. Finally, AST representation, together with source code embedding obtained by a vanilla code token encoder, is used for <a href=https://en.wikipedia.org/wiki/Automatic_programming>code summarization</a>. Extensive experiments, including the ablation study and the human evaluation, on benchmarks have demonstrated the power of CAST. To facilitate reproducibility, our code and data are available at https://github.com/DeepSoftwareAnalytics/CAST.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.561.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--561 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.561 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939001 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.561/>What Do You Mean by That? A Parser-Independent Interactive Approach for Enhancing Text-to-SQL<span class=acl-fixed-case>SQL</span></a></strong><br><a href=/people/y/yuntao-li/>Yuntao Li</a>
|
<a href=/people/b/bei-chen/>Bei Chen</a>
|
<a href=/people/q/qian-liu/>Qian Liu</a>
|
<a href=/people/y/yan-gao/>Yan Gao</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/y/yan-zhang/>Yan Zhang</a>
|
<a href=/people/d/dongmei-zhang/>Dongmei Zhang</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--561><div class="card-body p-3 small">In Natural Language Interfaces to Databases systems, the text-to-SQL technique allows users to query databases by using natural language questions. Though significant progress in this area has been made recently, most <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a> may fall short when they are deployed in real systems. One main reason stems from the difficulty of fully understanding the users&#8217; natural language questions. In this paper, we include human in the loop and present a novel parser-independent interactive approach (PIIA) that interacts with users using multi-choice questions and can easily work with arbitrary parsers. Experiments were conducted on two cross-domain datasets, the WikiSQL and the more complex Spider, with five state-of-the-art <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a>. These demonstrated that PIIA is capable of enhancing the text-to-SQL performance with limited interaction turns by using both simulation and human evaluation.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1535.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1535 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1535 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1535" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1535/>A Split-and-Recombine Approach for Follow-up Query Analysis</a></strong><br><a href=/people/q/qian-liu/>Qian Liu</a>
|
<a href=/people/b/bei-chen/>Bei Chen</a>
|
<a href=/people/h/haoyan-liu/>Haoyan Liu</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/l/lei-fang/>Lei Fang</a>
|
<a href=/people/b/bin-zhou/>Bin Zhou</a>
|
<a href=/people/d/dongmei-zhang/>Dongmei Zhang</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1535><div class="card-body p-3 small">Context-dependent semantic parsing has proven to be an important yet challenging <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. To leverage the advances in context-independent semantic parsing, we propose to perform follow-up query analysis, aiming to restate context-dependent natural language queries with <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual information</a>. To accomplish the task, we propose STAR, a novel approach with a well-designed two-phase process. It is parser-independent and able to handle multifarious follow-up scenarios in different domains. Experiments on the FollowUp dataset show that STAR outperforms the state-of-the-art baseline by a large margin of nearly 8 %. The superiority on <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a> results verifies the feasibility of follow-up query analysis. We also explore the extensibility of STAR on the SQA dataset, which is very promising.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1444.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1444 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1444 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1444.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1444" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1444/>Towards Complex Text-to-SQL in Cross-Domain Database with Intermediate Representation<span class=acl-fixed-case>SQL</span> in Cross-Domain Database with Intermediate Representation</a></strong><br><a href=/people/j/jiaqi-guo/>Jiaqi Guo</a>
|
<a href=/people/z/zecheng-zhan/>Zecheng Zhan</a>
|
<a href=/people/y/yan-gao/>Yan Gao</a>
|
<a href=/people/y/yan-xiao/>Yan Xiao</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/d/dongmei-zhang/>Dongmei Zhang</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1444><div class="card-body p-3 small">We present a neural approach called IRNet for complex and cross-domain Text-to-SQL. IRNet aims to address two challenges : 1) the mismatch between intents expressed in natural language (NL) and the implementation details in <a href=https://en.wikipedia.org/wiki/SQL>SQL</a> ; 2) the challenge in predicting columns caused by the large number of out-of-domain words. Instead of end-to-end synthesizing a <a href=https://en.wikipedia.org/wiki/SQL>SQL query</a>, IRNet decomposes the synthesis process into three phases. In the first phase, IRNet performs a schema linking over a question and a <a href=https://en.wikipedia.org/wiki/Database_schema>database schema</a>. Then, IRNet adopts a grammar-based neural model to synthesize a SemQL query which is an intermediate representation that we design to bridge <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NL</a> and <a href=https://en.wikipedia.org/wiki/SQL>SQL</a>. Finally, IRNet deterministically infers a <a href=https://en.wikipedia.org/wiki/SQL>SQL query</a> from the synthesized SemQL query with <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain knowledge</a>. On the challenging Text-to-SQL benchmark Spider, IRNet achieves 46.7 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, obtaining 19.5 % absolute improvement over previous <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>state-of-the-art approaches</a>. At the time of writing, IRNet achieves the first position on the Spider leaderboard.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1189.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1189 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1189 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1189/>SemRegex : A Semantics-Based Approach for Generating <a href=https://en.wikipedia.org/wiki/Regular_expression>Regular Expressions</a> from Natural Language Specifications<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>R</span>egex: A Semantics-Based Approach for Generating Regular Expressions from Natural Language Specifications</a></strong><br><a href=/people/z/zexuan-zhong/>Zexuan Zhong</a>
|
<a href=/people/j/jiaqi-guo/>Jiaqi Guo</a>
|
<a href=/people/w/wei-yang/>Wei Yang</a>
|
<a href=/people/j/jian-peng/>Jian Peng</a>
|
<a href=/people/t/tao-xie/>Tao Xie</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/d/dongmei-zhang/>Dongmei Zhang</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1189><div class="card-body p-3 small">Recent research proposes syntax-based approaches to address the problem of <a href=https://en.wikipedia.org/wiki/Computer_programming>generating programs</a> from <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language specifications</a>. These approaches typically train a sequence-to-sequence learning model using a syntax-based objective : <a href=https://en.wikipedia.org/wiki/Maximum_likelihood_estimation>maximum likelihood estimation (MLE)</a>. Such syntax-based approaches do not effectively address the goal of generating semantically correct programs, because these approaches fail to handle Program Aliasing, i.e., semantically equivalent programs may have many syntactically different forms. To address this issue, in this paper, we propose a semantics-based approach named SemRegex. SemRegex provides solutions for a subtask of the program-synthesis problem : generating <a href=https://en.wikipedia.org/wiki/Regular_expression>regular expressions</a> from <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. Different from the existing syntax-based approaches, SemRegex trains the model by maximizing the expected semantic correctness of the generated <a href=https://en.wikipedia.org/wiki/Regular_expression>regular expressions</a>. The semantic correctness is measured using the DFA-equivalence oracle, random test cases, and distinguishing test cases. The experiments on three public datasets demonstrate the superiority of SemRegex over the existing state-of-the-art approaches.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Dongmei+Zhang" title="Search for 'Dongmei Zhang' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/j/jian-guang-lou/ class=align-middle>Jian-Guang Lou</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/s/shi-han/ class=align-middle>Shi Han</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/y/yan-gao/ class=align-middle>Yan Gao</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/jiaqi-guo/ class=align-middle>Jiaqi Guo</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/b/bei-chen/ class=align-middle>Bei Chen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/q/qian-liu/ class=align-middle>Qian Liu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/zhoujun-cheng/ class=align-middle>Zhoujun Cheng</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/haoyu-dong/ class=align-middle>Haoyu Dong</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/ran-jia/ class=align-middle>Ran Jia</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yanlin-wang/ class=align-middle>Yanlin Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/lun-du/ class=align-middle>Lun Du</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hongyu-zhang/ class=align-middle>Hongyu Zhang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/ting-liu/ class=align-middle>Ting Liu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yuntao-li/ class=align-middle>Yuntao Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yan-zhang/ class=align-middle>Yan Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhiruo-wang/ class=align-middle>Zhiruo Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pengfei-wu/ class=align-middle>Pengfei Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fan-cheng/ class=align-middle>Fan Cheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wenchao-gu/ class=align-middle>Wenchao Gu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-lyu/ class=align-middle>Michael Lyu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zexuan-zhong/ class=align-middle>Zexuan Zhong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wei-yang/ class=align-middle>Wei Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jian-peng/ class=align-middle>Jian Peng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tao-xie/ class=align-middle>Tao Xie</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/ensheng-shi/ class=align-middle>Ensheng Shi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hongbin-sun/ class=align-middle>Hongbin Sun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haoyan-liu/ class=align-middle>Haoyan Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lei-fang/ class=align-middle>Lei Fang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bin-zhou/ class=align-middle>Bin Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zecheng-zhan/ class=align-middle>Zecheng Zhan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yan-xiao/ class=align-middle>Yan Xiao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>