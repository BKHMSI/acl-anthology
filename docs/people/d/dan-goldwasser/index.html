<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Dan Goldwasser - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Dan</span> <span class=font-weight-bold>Goldwasser</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.internlp-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--internlp-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.internlp-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.internlp-1.7/>Tackling Fake News Detection by Interactively Learning Representations using Graph Neural Networks</a></strong><br><a href=/people/n/nikhil-mehta/>Nikhil Mehta</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a><br><a href=/volumes/2021.internlp-1/ class=text-muted>Proceedings of the First Workshop on Interactive Learning for Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--internlp-1--7><div class="card-body p-3 small">Easy access, variety of content, and fast widespread interactions are some of the reasons that have made <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> increasingly popular in today&#8217;s society. However, this has also enabled the widespread propagation of fake news, text that is published with an intent to spread <a href=https://en.wikipedia.org/wiki/Misinformation>misinformation</a> and sway beliefs. Detecting fake news is important to prevent <a href=https://en.wikipedia.org/wiki/Misinformation>misinformation</a> and maintain a healthy society. While prior works have tackled this problem by building <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised learning systems</a>, automatedly modeling the social media landscape that enables the spread of <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a> is challenging. On the contrary, having humans fact check all news is not scalable. Thus, in this paper, we propose to approach this problem interactively, where human insight can be continually combined with an automated system, enabling better social media representation quality. Our experiments show performance improvements in this setting.<i>interactively</i>, where human insight can be continually combined with an automated system, enabling better social media representation quality. Our experiments show performance improvements in this setting.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.391.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--391 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.391 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.391" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.391/>Modeling Human Mental States with an Entity-based Narrative Graph</a></strong><br><a href=/people/i/i-ta-lee/>I-Ta Lee</a>
|
<a href=/people/m/maria-leonor-pacheco/>Maria Leonor Pacheco</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--391><div class="card-body p-3 small">Understanding <a href=https://en.wikipedia.org/wiki/Narrative>narrative text</a> requires capturing characters&#8217; motivations, goals, and <a href=https://en.wikipedia.org/wiki/Mental_state>mental states</a>. This paper proposes an Entity-based Narrative Graph (ENG) to model the internal- states of characters in a story. We explicitly model entities, their interactions and the context in which they appear, and learn rich representations for them. We experiment with different task-adaptive pre-training objectives, in-domain training, and symbolic inference to capture dependencies between different decisions in the output space. We evaluate our model on two narrative understanding tasks : predicting character mental states, and desire fulfillment, and conduct a <a href=https://en.wikipedia.org/wiki/Qualitative_property>qualitative analysis</a>.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwpt-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwpt-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929672 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.5/>Semi-supervised Parsing with a Variational Autoencoding Parser</a></strong><br><a href=/people/x/xiao-zhang/>Xiao Zhang</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a><br><a href=/volumes/2020.iwpt-1/ class=text-muted>Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwpt-1--5><div class="card-body p-3 small">We propose an end-to-end variational autoencoding parsing (VAP) model for semi-supervised graph-based projective dependency parsing. It encodes the input using <a href=https://en.wikipedia.org/wiki/Latent_variable_model>continuous latent variables</a> in a sequential manner by <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural networks (DNN)</a> that can utilize the contextual information, and reconstruct the input using a <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a>. The VAP model admits a unified structure with different <a href=https://en.wikipedia.org/wiki/Loss_function>loss functions</a> for labeled and unlabeled data with shared parameters. We conducted experiments on the WSJ data sets, showing the proposed model can use the unlabeled data to increase the performance on a limited amount of labeled data, on a par with a recently proposed semi-supervised parser with faster inference.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.620.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--620 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.620 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.620.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939379 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.620" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.620/>Weakly Supervised Learning of Nuanced Frames for Analyzing Polarization in <a href=https://en.wikipedia.org/wiki/News_media>News Media</a></a></strong><br><a href=/people/s/shamik-roy/>Shamik Roy</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--620><div class="card-body p-3 small">In this paper, we suggest a minimally supervised approach for identifying nuanced frames in news article coverage of politically divisive topics. We suggest to break the broad policy frames suggested by Boydstun et al., 2014 into fine-grained subframes which can capture differences in <a href=https://en.wikipedia.org/wiki/Ideology>political ideology</a> in a better way. We evaluate the suggested subframes and their embedding, learned using minimal supervision, over three topics, namely, <a href=https://en.wikipedia.org/wiki/Immigration>immigration</a>, <a href=https://en.wikipedia.org/wiki/Gun_politics_in_the_United_States>gun-control</a>, and <a href=https://en.wikipedia.org/wiki/Abortion>abortion</a>. We demonstrate the ability of the subframes to capture <a href=https://en.wikipedia.org/wiki/Ideology>ideological differences</a> and analyze <a href=https://en.wikipedia.org/wiki/Discourse_analysis>political discourse</a> in <a href=https://en.wikipedia.org/wiki/News_media>news media</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.35.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--35 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.35 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.35/>Predicting Stance Change Using Modular Architectures</a></strong><br><a href=/people/a/aldo-porco/>Aldo Porco</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--35><div class="card-body p-3 small">The ability to change a person&#8217;s mind on a given issue depends both on the arguments they are presented with and on their underlying perspectives and biases on that issue. Predicting stance changes require characterizing both aspects and the interaction between them, especially in realistic settings in which <a href=https://en.wikipedia.org/wiki/Stance_(martial_arts)>stance changes</a> are very rare. In this paper, we suggest a modular learning approach, which decomposes the task into multiple modules, focusing on different aspects of the interaction between users, their beliefs, and the arguments they are exposed to. Our experiments show that our modular approach archives significantly better results compared to the end-to-end approach using BERT over the same inputs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigdial-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sigdial-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sigdial-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sigdial-1.10/>Identifying Collaborative Conversations using Latent Discourse Behaviors</a></strong><br><a href=/people/a/ayush-jain/>Ayush Jain</a>
|
<a href=/people/m/maria-leonor-pacheco/>Maria Leonor Pacheco</a>
|
<a href=/people/s/steven-lancette/>Steven Lancette</a>
|
<a href=/people/m/mahak-goindani/>Mahak Goindani</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a><br><a href=/volumes/2020.sigdial-1/ class=text-muted>Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sigdial-1--10><div class="card-body p-3 small">In this work, we study collaborative online conversations. Such <a href=https://en.wikipedia.org/wiki/Conversation>conversations</a> are rich in content, constructive and motivated by a shared goal. Automatically identifying such conversations requires modeling complex discourse behaviors, which characterize the flow of information, <a href=https://en.wikipedia.org/wiki/Sentimentality>sentiment</a> and <a href=https://en.wikipedia.org/wiki/Community_structure>community structure</a> within discussions. To help capture these <a href=https://en.wikipedia.org/wiki/Behavior>behaviors</a>, we define a hybrid relational model in which relevant discourse behaviors are formulated as discrete latent variables and scored using <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>. These <a href=https://en.wikipedia.org/wiki/Variable_(mathematics)>variables</a> provide the information needed for predicting the overall collaborative characterization of the entire conversational thread. We show that adding <a href=https://en.wikipedia.org/wiki/Inductive_bias>inductive bias</a> in the form of <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a> results in performance improvement, while providing a natural way to explain the decision.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2112.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2112 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2112 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2112/>Modeling Behavioral Aspects of Social Media Discourse for Moral Classification</a></strong><br><a href=/people/k/kristen-johnson/>Kristen Johnson</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a><br><a href=/volumes/W19-21/ class=text-muted>Proceedings of the Third Workshop on Natural Language Processing and Computational Social Science</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2112><div class="card-body p-3 small">Political discourse on <a href=https://en.wikipedia.org/wiki/Microblogging>social media microblogs</a>, specifically <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>, has become an undeniable part of mainstream U.S. politics. Given the length constraint of tweets, politicians must carefully word their statements to ensure their message is understood by their intended audience. This constraint often eliminates the context of the tweet, making automatic analysis of social media political discourse a difficult task. To overcome this challenge, we propose simultaneous modeling of high-level abstractions of political language, such as political slogans and framing strategies, with <a href=https://en.wikipedia.org/wiki/Abstraction>abstractions</a> of how politicians behave on <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>. These behavioral abstractions can be further leveraged as forms of <a href=https://en.wikipedia.org/wiki/Supervisor>supervision</a> in order to increase prediction accuracy, while reducing the burden of <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a>. In this work, we use Probabilistic Soft Logic (PSL) to build <a href=https://en.wikipedia.org/wiki/Relational_model>relational models</a> to capture the similarities in language and behavior that obfuscate political messages on <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>. When combined, these descriptors reveal the moral foundations underlying the discourse of U.S. politicians online, across differing governing administrations, showing how <a href=https://en.wikipedia.org/wiki/List_of_political_parties_in_the_United_States>party talking points</a> remain cohesive or change over time.<i>across</i> differing governing administrations, showing how party talking points remain cohesive or change over time.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1055.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1055 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1055 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1055.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1055" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1055/>Sentiment Tagging with Partial Labels using Modular Architectures</a></strong><br><a href=/people/x/xiao-zhang/>Xiao Zhang</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1055><div class="card-body p-3 small">Many NLP learning tasks can be decomposed into several distinct sub-tasks, each associated with a partial label. In this paper we focus on a popular class of learning problems, sequence prediction applied to several sentiment analysis tasks, and suggest a modular learning approach in which different sub-tasks are learned using separate functional modules, combined to perform the final task while sharing information. Our experiments show this approach helps constrain the <a href=https://en.wikipedia.org/wiki/Learning>learning process</a> and can alleviate some of the supervision efforts.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1316.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1316 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1316 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=C18-1316" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/C18-1316/>Structured Representation Learning for Online Debate Stance Prediction</a></strong><br><a href=/people/c/chang-li/>Chang Li</a>
|
<a href=/people/a/aldo-porco/>Aldo Porco</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1316><div class="card-body p-3 small">Online debates can help provide valuable information about various perspectives on a wide range of issues. However, understanding the stances expressed in these <a href=https://en.wikipedia.org/wiki/Debate>debates</a> is a highly challenging task, which requires modeling both textual content and users&#8217; conversational interactions. Current approaches take a collective classification approach, which ignores the relationships between different debate topics. In this work, we suggest to view this task as a representation learning problem, and embed the text and authors jointly based on their interactions. We evaluate our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> over the Internet Argumentation Corpus, and compare different approaches for structural information embedding. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can achieve significantly better results compared to previous competitive models.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1069.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1069 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1069 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234955861 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1069/>Leveraging Behavioral and Social Information for Weakly Supervised Collective Classification of Political Discourse on Twitter<span class=acl-fixed-case>T</span>witter</a></strong><br><a href=/people/k/kristen-johnson/>Kristen Johnson</a>
|
<a href=/people/d/di-jin/>Di Jin</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1069><div class="card-body p-3 small">Framing is a political strategy in which politicians carefully word their statements in order to control public perception of issues. Previous works exploring <a href=https://en.wikipedia.org/wiki/Political_framing>political framing</a> typically analyze frame usage in longer texts, such as <a href=https://en.wikipedia.org/wiki/Public_speaking>congressional speeches</a>. We present a collection of weakly supervised models which harness collective classification to predict the frames used in <a href=https://en.wikipedia.org/wiki/Discourse_analysis>political discourse</a> on the <a href=https://en.wikipedia.org/wiki/Microblogging>microblogging platform</a>, <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>. Our global probabilistic models show that by combining both lexical features of <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> and network-based behavioral features of <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>, we are able to increase the average, <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised F1 score</a> by 21.52 points over a lexical baseline alone.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2913.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2913 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2913 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2913/>Ideological Phrase Indicators for Classification of Political Discourse Framing on Twitter<span class=acl-fixed-case>T</span>witter</a></strong><br><a href=/people/k/kristen-johnson/>Kristen Johnson</a>
|
<a href=/people/i/i-ta-lee/>I-Ta Lee</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a><br><a href=/volumes/W17-29/ class=text-muted>Proceedings of the Second Workshop on NLP and Computational Social Science</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2913><div class="card-body p-3 small">Politicians carefully word their statements in order to influence how others view an issue, a <a href=https://en.wikipedia.org/wiki/Political_strategy>political strategy</a> called <a href=https://en.wikipedia.org/wiki/Framing_(social_sciences)>framing</a>. Simultaneously, these <a href=https://en.wikipedia.org/wiki/Framing_(social_sciences)>frames</a> may also reveal the beliefs or positions on an issue of the politician. Simple language features such as <a href=https://en.wikipedia.org/wiki/Unigram>unigrams</a>, <a href=https://en.wikipedia.org/wiki/Bigram>bigrams</a>, and <a href=https://en.wikipedia.org/wiki/Trigram>trigrams</a> are important indicators for identifying the general frame of a text, for both longer congressional speeches and shorter tweets of politicians. However, <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> may contain multiple <a href=https://en.wikipedia.org/wiki/Unigram>unigrams</a> across different frames which limits the effectiveness of this approach. In this paper, we present a joint model which uses both linguistic features of tweets and ideological phrase indicators extracted from a state-of-the-art embedding-based model to predict the general frame of political tweets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2029.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2029 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2029 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2029/>PurdueNLP at SemEval-2017 Task 1 : Predicting Semantic Textual Similarity with Paraphrase and Event Embeddings<span class=acl-fixed-case>P</span>urdue<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 1: Predicting Semantic Textual Similarity with Paraphrase and Event Embeddings</a></strong><br><a href=/people/i/i-ta-lee/>I-Ta Lee</a>
|
<a href=/people/m/mahak-goindani/>Mahak Goindani</a>
|
<a href=/people/c/chang-li/>Chang Li</a>
|
<a href=/people/d/di-jin/>Di Jin</a>
|
<a href=/people/k/kristen-johnson/>Kristen Marie Johnson</a>
|
<a href=/people/x/xiao-zhang/>Xiao Zhang</a>
|
<a href=/people/m/maria-leonor-pacheco/>Maria Leonor Pacheco</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2029><div class="card-body p-3 small">This paper describes our proposed solution for SemEval 2017 Task 1 : <a href=https://en.wikipedia.org/wiki/Semantic_similarity>Semantic Textual Similarity</a> (Daniel Cer and Specia, 2017). The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> aims at measuring the degree of equivalence between sentences given in English. Performance is evaluated by computing <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>Pearson Correlation scores</a> between the predicted scores and <a href=https://en.wikipedia.org/wiki/Judgement>human judgements</a>. Our proposed <a href=https://en.wikipedia.org/wiki/System>system</a> consists of two <a href=https://en.wikipedia.org/wiki/System>subsystems</a> and one <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression model</a> for predicting STS scores. The two subsystems are designed to learn Paraphrase and Event Embeddings that can take the consideration of paraphrasing characteristics and <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence structures</a> into our <a href=https://en.wikipedia.org/wiki/System>system</a>. The <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression model</a> associates these <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> to make the final predictions. The experimental result shows that our <a href=https://en.wikipedia.org/wiki/Tensor_(intrinsic_definition)>system</a> acquires 0.8 of <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>Pearson Correlation Scores</a> in this task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1179.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1179 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1179 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D17-1179" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D17-1179/>Semi-supervised Structured Prediction with Neural CRF Autoencoder<span class=acl-fixed-case>CRF</span> Autoencoder</a></strong><br><a href=/people/x/xiao-zhang/>Xiao Zhang</a>
|
<a href=/people/y/yong-jiang/>Yong Jiang</a>
|
<a href=/people/h/hao-peng/>Hao Peng</a>
|
<a href=/people/k/kewei-tu/>Kewei Tu</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1179><div class="card-body p-3 small">In this paper we propose an end-to-end neural CRF autoencoder (NCRF-AE) model for semi-supervised learning of sequential structured prediction problems. Our NCRF-AE consists of two parts : an encoder which is a CRF model enhanced by <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural networks</a>, and a decoder which is a <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> trying to reconstruct the input. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> has a unified structure with different <a href=https://en.wikipedia.org/wiki/Loss_function>loss functions</a> for labeled and unlabeled data with shared parameters. We developed a variation of the EM algorithm for optimizing both the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> and the <a href=https://en.wikipedia.org/wiki/Codec>decoder</a> simultaneously by decoupling their parameters. Our Experimental results over the Part-of-Speech (POS) tagging task on eight different languages, show that our model can outperform competitive systems in both supervised and semi-supervised scenarios.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Dan+Goldwasser" title="Search for 'Dan Goldwasser' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/x/xiao-zhang/ class=align-middle>Xiao Zhang</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/k/kristen-johnson/ class=align-middle>Kristen Johnson</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/i/i-ta-lee/ class=align-middle>I-Ta Lee</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/maria-leonor-pacheco/ class=align-middle>María Leonor Pacheco</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/c/chang-li/ class=align-middle>Chang Li</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/a/aldo-porco/ class=align-middle>Aldo Porco</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/di-jin/ class=align-middle>Di Jin</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mahak-goindani/ class=align-middle>Mahak Goindani</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/shamik-roy/ class=align-middle>Shamik Roy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yong-jiang/ class=align-middle>Yong Jiang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hao-peng/ class=align-middle>Hao Peng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kewei-tu/ class=align-middle>Kewei Tu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nikhil-mehta/ class=align-middle>Nikhil Mehta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ayush-jain/ class=align-middle>Ayush Jain</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/steven-lancette/ class=align-middle>Steven Lancette</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/iwpt/ class=align-middle>IWPT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/internlp/ class=align-middle>InterNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/sigdial/ class=align-middle>SIGDIAL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>