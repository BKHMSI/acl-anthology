<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Daniel Beck - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Daniel</span> <span class=font-weight-bold>Beck</span></h2><hr><div class=row><div class=col-lg-9><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-tutorials.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-tutorials.0/>Proceedings of the 28th International Conference on Computational Linguistics: Tutorial Abstracts</a></strong><br><a href=/people/l/lucia-specia/>Lucia Specia</a>
|
<a href=/people/d/daniel-beck/>Daniel Beck</a><br><a href=/volumes/2020.coling-tutorials/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics: Tutorial Abstracts</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.alta-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.alta-1.0/>Proceedings of the The 18th Annual Workshop of the Australasian Language Technology Association</a></strong><br><a href=/people/m/maria-kim/>Maria Kim</a>
|
<a href=/people/d/daniel-beck/>Daniel Beck</a>
|
<a href=/people/m/meladel-mistica/>Meladel Mistica</a><br><a href=/volumes/2020.alta-1/ class=text-muted>Proceedings of the The 18th Annual Workshop of the Australasian Language Technology Association</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.alta-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--alta-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.alta-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.alta-1.12/>Information Extraction from Legal Documents : A Study in the Context of Common Law Court Judgements</a></strong><br><a href=/people/m/meladel-mistica/>Meladel Mistica</a>
|
<a href=/people/g/geordie-z-zhang/>Geordie Z. Zhang</a>
|
<a href=/people/h/hui-chia/>Hui Chia</a>
|
<a href=/people/k/kabir-manandhar-shrestha/>Kabir Manandhar Shrestha</a>
|
<a href=/people/r/rohit-kumar-gupta/>Rohit Kumar Gupta</a>
|
<a href=/people/s/saket-khandelwal/>Saket Khandelwal</a>
|
<a href=/people/j/jeannie-paterson/>Jeannie Paterson</a>
|
<a href=/people/t/timothy-baldwin/>Timothy Baldwin</a>
|
<a href=/people/d/daniel-beck/>Daniel Beck</a><br><a href=/volumes/2020.alta-1/ class=text-muted>Proceedings of the The 18th Annual Workshop of the Australasian Language Technology Association</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--alta-1--12><div class="card-body p-3 small">&#8216;Common Law&#8217; judicial systems follow the doctrine of precedent, which means the legal principles articulated in court judgements are binding in subsequent cases in lower courts. For this reason, lawyers must search prior judgements for the <a href=https://en.wikipedia.org/wiki/Legal_doctrine>legal principles</a> that are relevant to their case. The difficulty for those within the <a href=https://en.wikipedia.org/wiki/Legal_profession>legal profession</a> is that the information that they are looking for may be contained within a few paragraphs or sentences, but those few paragraphs may be buried within a hundred-page document. In this study, we create a schema based on the relevant information that legal professionals seek within judgements and perform text classification based on it, with the aim of not only assisting lawyers in researching cases, but eventually enabling large-scale analysis of legal judgements to find trends in court outcomes over time.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5304.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5304 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5304 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-5304.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-5304/>Neural Speech Translation using <a href=https://en.wikipedia.org/wiki/Lattice_model_(physics)>Lattice Transformations</a> and Graph Networks</a></strong><br><a href=/people/d/daniel-beck/>Daniel Beck</a>
|
<a href=/people/t/trevor-cohn/>Trevor Cohn</a>
|
<a href=/people/g/gholamreza-haffari/>Gholamreza Haffari</a><br><a href=/volumes/D19-53/ class=text-muted>Proceedings of the Thirteenth Workshop on Graph-Based Methods for Natural Language Processing (TextGraphs-13)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5304><div class="card-body p-3 small">Speech translation systems usually follow a pipeline approach, using word lattices as an <a href=https://en.wikipedia.org/wiki/Intermediate_representation>intermediate representation</a>. However, previous work assume access to the original <a href=https://en.wikipedia.org/wiki/Transcription_(linguistics)>transcriptions</a> used to train the ASR system, which can limit applicability in real scenarios. In this work we propose an approach for <a href=https://en.wikipedia.org/wiki/Speech_translation>speech translation</a> through lattice transformations and neural models based on <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph networks</a>. Experimental results show that our approach reaches competitive performance without relying on <a href=https://en.wikipedia.org/wiki/Transcription_(biology)>transcriptions</a>, while also being orders of magnitude faster than previous work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5525.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5525 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5525 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5525/>Modelling Uncertainty in Collaborative Document Quality Assessment</a></strong><br><a href=/people/a/aili-shen/>Aili Shen</a>
|
<a href=/people/d/daniel-beck/>Daniel Beck</a>
|
<a href=/people/b/bahar-salehi/>Bahar Salehi</a>
|
<a href=/people/j/jianzhong-qi/>Jianzhong Qi</a>
|
<a href=/people/t/timothy-baldwin/>Timothy Baldwin</a><br><a href=/volumes/D19-55/ class=text-muted>Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5525><div class="card-body p-3 small">In the context of document quality assessment, previous work has mainly focused on predicting the quality of a document relative to a putative gold standard, without paying attention to the subjectivity of this task. To imitate people&#8217;s disagreement over inherently subjective tasks such as rating the quality of a Wikipedia article, a document quality assessment system should provide not only a prediction of the article quality but also the uncertainty over its predictions. This motivates us to measure the uncertainty in document quality predictions, in addition to making the label prediction. Experimental results show that both Gaussian processes (GPs) and random forests (RFs) can yield competitive results in predicting the quality of Wikipedia articles, while providing an estimate of uncertainty when there is inconsistency in the quality labels from the Wikipedia contributors. We additionally evaluate our methods in the context of a semi-automated document quality class assignment decision-making process, where there is asymmetric risk associated with overestimates and underestimates of document quality. Our experiments suggest that GPs provide more reliable estimates in this context.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6405.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-6405 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-6405 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6405/>On the Role of Scene Graphs in Image Captioning</a></strong><br><a href=/people/d/dalin-wang/>Dalin Wang</a>
|
<a href=/people/d/daniel-beck/>Daniel Beck</a>
|
<a href=/people/t/trevor-cohn/>Trevor Cohn</a><br><a href=/volumes/D19-64/ class=text-muted>Proceedings of the Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-6405><div class="card-body p-3 small">Scene graphs represent semantic information in images, which can help <a href=https://en.wikipedia.org/wiki/Image>image captioning system</a> to produce more descriptive outputs versus using only the <a href=https://en.wikipedia.org/wiki/Image>image</a> as context. Recent captioning approaches rely on ad-hoc approaches to obtain <a href=https://en.wikipedia.org/wiki/Graph_of_a_function>graphs</a> for <a href=https://en.wikipedia.org/wiki/Image>images</a>. However, those <a href=https://en.wikipedia.org/wiki/Graph_of_a_function>graphs</a> introduce <a href=https://en.wikipedia.org/wiki/Noise_(electronics)>noise</a> and it is unclear the effect of <a href=https://en.wikipedia.org/wiki/Parsing>parser errors</a> on captioning accuracy. In this work, we investigate to what extent <a href=https://en.wikipedia.org/wiki/Scene_graph>scene graphs</a> can help image captioning. Our results show that a state-of-the-art scene graph parser can boost performance almost as much as the ground truth graphs, showing that the bottleneck currently resides more on the captioning models than on the performance of the scene graph parser.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2012 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/I17-2012.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/I17-2012/>Learning Kernels over Strings using <a href=https://en.wikipedia.org/wiki/Gaussian_function>Gaussian Processes</a><span class=acl-fixed-case>G</span>aussian Processes</a></strong><br><a href=/people/d/daniel-beck/>Daniel Beck</a>
|
<a href=/people/t/trevor-cohn/>Trevor Cohn</a><br><a href=/volumes/I17-2/ class=text-muted>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2012><div class="card-body p-3 small">Non-contiguous word sequences are widely known to be important in <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>modelling natural language</a>. However they not explicitly encoded in <a href=https://en.wikipedia.org/wiki/Universal_Coded_Character_Set>common text representations</a>. In this work we propose a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> for <a href=https://en.wikipedia.org/wiki/Text_processing>text processing</a> using <a href=https://en.wikipedia.org/wiki/String_kernel>string kernels</a>, capable of flexibly representing non-contiguous sequences. Specifically, we derive a vectorised version of the string kernel algorithm and their <a href=https://en.wikipedia.org/wiki/Gradient>gradients</a>, allowing efficient <a href=https://en.wikipedia.org/wiki/Hyperparameter_optimization>hyperparameter optimisation</a> as part of a Gaussian Process framework. Experiments on synthetic data and text regression for emotion analysis show the promise of this technique.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Daniel+Beck" title="Search for 'Daniel Beck' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/t/trevor-cohn/ class=align-middle>Trevor Cohn</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/t/timothy-baldwin/ class=align-middle>Timothy Baldwin</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/meladel-mistica/ class=align-middle>Meladel Mistica</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/g/gholamreza-haffari/ class=align-middle>Gholamreza Haffari</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aili-shen/ class=align-middle>Aili Shen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/b/bahar-salehi/ class=align-middle>Bahar Salehi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jianzhong-qi/ class=align-middle>Jianzhong Qi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dalin-wang/ class=align-middle>Dalin Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lucia-specia/ class=align-middle>Lucia Specia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maria-kim/ class=align-middle>Maria Kim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/geordie-z-zhang/ class=align-middle>Geordie Z. Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hui-chia/ class=align-middle>Hui Chia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kabir-manandhar-shrestha/ class=align-middle>Kabir Manandhar Shrestha</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rohit-kumar-gupta/ class=align-middle>Rohit Kumar Gupta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/saket-khandelwal/ class=align-middle>Saket Khandelwal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jeannie-paterson/ class=align-middle>Jeannie Paterson</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/alta/ class=align-middle>ALTA</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>