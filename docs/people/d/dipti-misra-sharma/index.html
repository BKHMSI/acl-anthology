<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Dipti Misra Sharma - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Dipti Misra</span> <span class=font-weight-bold>Sharma</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Dipti <span class=font-weight-normal>Sharma</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ranlp-1.83.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ranlp-1--83 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ranlp-1.83 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ranlp-1.83/>Multilingual Multi-Domain NMT for <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indian Languages</a><span class=acl-fixed-case>NMT</span> for <span class=acl-fixed-case>I</span>ndian Languages</a></strong><br><a href=/people/s/sourav-kumar/>Sourav Kumar</a>
|
<a href=/people/s/salil-aggarwal/>Salil Aggarwal</a>
|
<a href=/people/d/dipti-misra-sharma/>Dipti Sharma</a><br><a href=/volumes/2021.ranlp-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ranlp-1--83><div class="card-body p-3 small">India is known as the land of many tongues and dialects. Neural machine translation (NMT) is the current state-of-the-art approach for machine translation (MT) but performs better only with large datasets which Indian languages usually lack, making this approach infeasible. So, in this paper, we address the problem of data scarcity by efficiently training multilingual and multilingual multi domain NMT systems involving languages of the . We are proposing the technique for using the joint domain and language tags in a multilingual setup. We draw three major conclusions from our experiments : (i) Training a multilingual system via exploiting <a href=https://en.wikipedia.org/wiki/Lexical_similarity>lexical similarity</a> based on <a href=https://en.wikipedia.org/wiki/Language_family>language family</a> helps in achieving an overall average improvement of. over bilingual baselines, (ii) Technique of incorporating domain information into the language tokens helps multilingual multi-domain system in getting a significant average improvement of over the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>, (iii) Multistage fine-tuning further helps in getting an improvement of -. for the language pair of interest.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.sigmorphon-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--sigmorphon-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.sigmorphon-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.sigmorphon-1.7" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.sigmorphon-1.7/>Sample-efficient Linguistic Generalizations through <a href=https://en.wikipedia.org/wiki/Program_synthesis>Program Synthesis</a> : Experiments with Phonology Problems</a></strong><br><a href=/people/s/saujas-vaduguru/>Saujas Vaduguru</a>
|
<a href=/people/a/aalok-sathe/>Aalok Sathe</a>
|
<a href=/people/m/monojit-choudhury/>Monojit Choudhury</a>
|
<a href=/people/d/dipti-misra-sharma/>Dipti Sharma</a><br><a href=/volumes/2021.sigmorphon-1/ class=text-muted>Proceedings of the 18th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--sigmorphon-1--7><div class="card-body p-3 small">Neural models excel at extracting statistical patterns from large amounts of data, but struggle to learn <a href=https://en.wikipedia.org/wiki/Pattern>patterns</a> or reason about <a href=https://en.wikipedia.org/wiki/Language>language</a> from only a few examples. In this paper, we ask : Can we learn explicit <a href=https://en.wikipedia.org/wiki/Rule_of_inference>rules</a> that generalize well from only a few examples? We explore this question using <a href=https://en.wikipedia.org/wiki/Program_synthesis>program synthesis</a>. We develop a synthesis model to learn <a href=https://en.wikipedia.org/wiki/Phonology>phonology rules</a> as <a href=https://en.wikipedia.org/wiki/Computer_program>programs</a> in a <a href=https://en.wikipedia.org/wiki/Domain-specific_language>domain-specific language</a>. We test the ability of our models to generalize from few training examples using our new dataset of problems from the <a href=https://en.wikipedia.org/wiki/International_Linguistic_Olympiad>Linguistics Olympiad</a>, a challenging set of tasks that require strong linguistic reasoning ability. In addition to being highly sample-efficient, our approach generates <a href=https://en.wikipedia.org/wiki/Human-readable_medium>human-readable programs</a>, and allows control over the generalizability of the learnt programs.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-srw.22.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-srw.22.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928675 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.22/>Efficient <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> for Low-Resource Languages via Exploiting Related Languages</a></strong><br><a href=/people/v/vikrant-goyal/>Vikrant Goyal</a>
|
<a href=/people/s/sourav-kumar/>Sourav Kumar</a>
|
<a href=/people/d/dipti-misra-sharma/>Dipti Misra Sharma</a><br><a href=/volumes/2020.acl-srw/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--22><div class="card-body p-3 small">A large percentage of the world&#8217;s population speaks a language of the Indian subcontinent, comprising languages from both Indo-Aryan (e.g. Hindi, Punjabi, <a href=https://en.wikipedia.org/wiki/Gujarati_language>Gujarati</a>, etc.) and Dravidian (e.g. Tamil, <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a>, <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a>, etc.) families. A universal characteristic of <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indian languages</a> is their <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>complex morphology</a>, which, when combined with the general lack of sufficient quantities of high-quality parallel data, can make developing <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation (MT) systems</a> for these languages difficult. Neural Machine Translation (NMT) is a rapidly advancing MT paradigm and has shown promising results for many language pairs, especially in large training data scenarios. Since the condition of large parallel corpora is not met for Indian-English language pairs, we present our efforts towards building efficient NMT systems between <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indian languages</a> (specifically Indo-Aryan languages) and English via efficiently exploiting parallel data from the related languages. We propose a technique called Unified Transliteration and Subword Segmentation to leverage language similarity while exploiting parallel data from related language pairs. We also propose a Multilingual Transfer Learning technique to leverage parallel data from multiple related languages to assist <a href=https://en.wikipedia.org/wiki/Translation>translation</a> for low resource language pair of interest. Our experiments demonstrate an overall average improvement of 5 BLEU points over the standard Transformer-based NMT baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.38.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--38 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.38 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-srw.38.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928632 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.38/>Checkpoint Reranking : An Approach to Select Better Hypothesis for Neural Machine Translation Systems</a></strong><br><a href=/people/v/vinay-pandramish/>Vinay Pandramish</a>
|
<a href=/people/d/dipti-misra-sharma/>Dipti Misra Sharma</a><br><a href=/volumes/2020.acl-srw/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--38><div class="card-body p-3 small">In this paper, we propose a method of <a href=https://en.wikipedia.org/wiki/Ranking>re-ranking</a> the outputs of Neural Machine Translation (NMT) systems. After the decoding process, we select a few last iteration outputs in the training process as the N-best list. After training a Neural Machine Translation (NMT) baseline system, it has been observed that these iteration outputs have an oracle score higher than <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> up to 1.01 BLEU points compared to the last iteration of the trained system. We come up with a ranking mechanism by solely focusing on the decoder&#8217;s ability to generate distinct tokens and without the usage of any <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> or data. With this <a href=https://en.wikipedia.org/wiki/Methodology>method</a>, we achieved a translation improvement up to +0.16 BLEU points over baseline. We also evaluate our approach by applying the coverage penalty to the training process. In cases of moderate coverage penalty, the oracle scores are higher than the final iteration up to +0.99 BLEU points, and our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> gives an improvement up to +0.17 BLEU points. With excessive penalty, there is a decrease in translation quality compared to the baseline system. Still, an increase in <a href=https://en.wikipedia.org/wiki/Oracle_machine>oracle scores</a> up to +1.30 is observed with the re-ranking algorithm giving an improvement up to +0.15 BLEU points is found in case of excessive penalty. The proposed re-ranking method is a generic one and can be extended to other language pairs as well.<tex-math>N</tex-math>-best list. After training a Neural Machine Translation (NMT) baseline system, it has been observed that these iteration outputs have an oracle score higher than baseline up to 1.01 BLEU points compared to the last iteration of the trained system.We come up with a ranking mechanism by solely focusing on the decoder&#8217;s ability to generate distinct tokens and without the usage of any language model or data. With this method, we achieved a translation improvement up to +0.16 BLEU points over baseline.We also evaluate our approach by applying the coverage penalty to the training process.In cases of moderate coverage penalty, the oracle scores are higher than the final iteration up to +0.99 BLEU points, and our algorithm gives an improvement up to +0.17 BLEU points.With excessive penalty, there is a decrease in translation quality compared to the baseline system. Still, an increase in oracle scores up to +1.30 is observed with the re-ranking algorithm giving an improvement up to +0.15 BLEU points is found in case of excessive penalty.The proposed re-ranking method is a generic one and can be extended to other language pairs as well.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.icon-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.icon-1.0/>Proceedings of the 16th International Conference on Natural Language Processing</a></strong><br><a href=/people/d/dipti-misra-sharma/>Dipti Misra Sharma</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharya</a><br><a href=/volumes/2019.icon-1/ class=text-muted>Proceedings of the 16th International Conference on Natural Language Processing</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.icon-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--icon-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.icon-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.icon-1.15/>Dataset for Aspect Detection on Mobile reviews in Hindi<span class=acl-fixed-case>H</span>indi</a></strong><br><a href=/people/p/pruthwik-mishra/>Pruthwik Mishra</a>
|
<a href=/people/a/ayush-joshi/>Ayush Joshi</a>
|
<a href=/people/d/dipti-misra-sharma/>Dipti Sharma</a><br><a href=/volumes/2019.icon-1/ class=text-muted>Proceedings of the 16th International Conference on Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--icon-1--15><div class="card-body p-3 small">In recent years <a href=https://en.wikipedia.org/wiki/Opinion_mining>Opinion Mining</a> has become one of the very interesting fields of <a href=https://en.wikipedia.org/wiki/Language_processing>Language Processing</a>. To extract the gist of a sentence in a shorter and efficient manner is what <a href=https://en.wikipedia.org/wiki/Opinion_mining>opinion mining</a> provides. In this paper we focus on detecting aspects for a particular <a href=https://en.wikipedia.org/wiki/Domain_(mathematical_analysis)>domain</a>. While relevant research work has been done in aspect detection in resource rich languages like <a href=https://en.wikipedia.org/wiki/English_language>English</a>, we are trying to do the same in a relatively resource poor Hindi language. Here we present a corpus of mobile reviews which are labelled with carefully curated aspects. The motivation behind Aspect detection is to get information on a finer level about the data. In this paper we identify all aspects related to the gadget which are present on the reviews given online on various websites. We also propose <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baseline models</a> to detect <a href=https://en.wikipedia.org/wiki/Grammatical_aspect>aspects</a> in <a href=https://en.wikipedia.org/wiki/Hindi>Hindi text</a> after conducting various experiments.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.icon-1.18.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--icon-1--18 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.icon-1.18 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.icon-1.18/>Towards Handling Verb Phrase Ellipsis in English-Hindi Machine Translation<span class=acl-fixed-case>E</span>nglish-<span class=acl-fixed-case>H</span>indi Machine Translation</a></strong><br><a href=/people/n/niyati-bafna/>Niyati Bafna</a>
|
<a href=/people/d/dipti-misra-sharma/>Dipti Sharma</a><br><a href=/volumes/2019.icon-1/ class=text-muted>Proceedings of the 16th International Conference on Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--icon-1--18><div class="card-body p-3 small">English-Hindi machine translation systems have difficulty interpreting verb phrase ellipsis (VPE) in <a href=https://en.wikipedia.org/wiki/English_language>English</a>, and commit errors in translating sentences with VPE. We present a solution and theoretical backing for the treatment of English VPE, with the specific scope of enabling English-Hindi MT, based on an understanding of the syntactical phenomenon of verb-stranding verb phrase ellipsis in Hindi (VVPE). We implement a rule-based system to perform the following sub-tasks : 1) Verb ellipsis identification in the English source sentence, 2) Elided verb phrase head identification 3) Identification of verb segment which needs to be induced at the site of <a href=https://en.wikipedia.org/wiki/Ellipsis_(linguistics)>ellipsis</a> 4) Modify input sentence ; i.e. resolving <a href=https://en.wikipedia.org/wiki/Verb&#8211;object&#8211;subject>VPE</a> and inducing the required <a href=https://en.wikipedia.org/wiki/Verb&#8211;object&#8211;subject>verb segment</a>. This <a href=https://en.wikipedia.org/wiki/System>system</a> obtains 94.83 percent <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> and 83.04 percent <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a> on subtask (1), tested on 3900 sentences from the BNC corpus. This is competitive with state-of-the-art results. We measure <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of subtasks (2) and (3) together, and obtain a 91 percent <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on 200 sentences taken from the WSJ corpus. Finally, in order to indicate the relevance of ellipsis handling to MT, we carried out a manual analysis of the English-Hindi MT outputs of 100 sentences after passing it through our system. We set up a basic metric (1-5) for this evaluation, where 5 indicates drastic improvement, and obtained an average of 3.55. As far as we know, this is the first attempt to target ellipsis resolution in the context of improving English-Hindi machine translation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.icon-1.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--icon-1--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.icon-1.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.icon-1.22/>Kunji : A Resource Management System for Higher Productivity in Computer Aided Translation Tools</a></strong><br><a href=/people/p/priyank-gupta/>Priyank Gupta</a>
|
<a href=/people/m/manish-shrivastava/>Manish Shrivastava</a>
|
<a href=/people/d/dipti-misra-sharma/>Dipti Misra Sharma</a>
|
<a href=/people/r/rashid-ahmad/>Rashid Ahmad</a><br><a href=/volumes/2019.icon-1/ class=text-muted>Proceedings of the 16th International Conference on Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--icon-1--22><div class="card-body p-3 small">Complex NLP applications, such as machine translation systems, utilize various kinds of resources namely lexical, multiword, domain dictionaries, maps and rules etc. Similarly, translators working on Computer Aided Translation workbenches, also require help from various kinds of resources-glossaries, <a href=https://en.wikipedia.org/wiki/Terminology>terminologies</a>, <a href=https://en.wikipedia.org/wiki/Concordance_(publishing)>concordances</a> and <a href=https://en.wikipedia.org/wiki/Translation_memory>translation memory</a> in the workbenches in order to increase their productivity. Additionally, translators have to look away from the workbenches for linguistic resources like Named Entities, Multiwords, lexical and lexeme dictionaries in order to get help, as the available resources like concordances, terminologies and glossaries are often not enough. In this paper we present <a href=https://en.wikipedia.org/wiki/Kunji>Kunji</a>, a <a href=https://en.wikipedia.org/wiki/Resource_management_(computing)>resource management system</a> for translation workbenches and MT modules. This <a href=https://en.wikipedia.org/wiki/System>system</a> can be easily integrated in translation workbenches and can also be used as a management tool for resources for MT systems. The described <a href=https://en.wikipedia.org/wiki/Resource_management_(computing)>resource management system</a> has been integrated in a translation workbench Transzaar. We also study the impact of providing this <a href=https://en.wikipedia.org/wiki/Resource_management>resource management system</a> along with linguistic resources on the productivity of translators for English-Hindi language pair. When the linguistic resources like <a href=https://en.wikipedia.org/wiki/Lexeme>lexeme</a>, NER and MWE dictionaries were made available to translators in addition to their regular translation memories, <a href=https://en.wikipedia.org/wiki/Concordance_(publishing)>concordances</a> and <a href=https://en.wikipedia.org/wiki/Terminology>terminologies</a>, their productivity increased by 15.61 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5216.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5216 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5216 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5216/>LTRC-MT Simple & Effective Hindi-English Neural Machine Translation Systems at WAT 2019<span class=acl-fixed-case>LTRC</span>-<span class=acl-fixed-case>MT</span> Simple & Effective <span class=acl-fixed-case>H</span>indi-<span class=acl-fixed-case>E</span>nglish Neural Machine Translation Systems at <span class=acl-fixed-case>WAT</span> 2019</a></strong><br><a href=/people/v/vikrant-goyal/>Vikrant Goyal</a>
|
<a href=/people/d/dipti-misra-sharma/>Dipti Misra Sharma</a><br><a href=/volumes/D19-52/ class=text-muted>Proceedings of the 6th Workshop on Asian Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5216><div class="card-body p-3 small">This paper describes the Neural Machine Translation systems of IIIT-Hyderabad (LTRC-MT) for WAT 2019 Hindi-English shared task. We experimented with both Recurrent Neural Networks & Transformer architectures. We also show the results of our experiments of training NMT models using additional data via backtranslation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4020.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4020 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4020 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4020/>A Dataset for Semantic Role Labelling of Hindi-English Code-Mixed Tweets<span class=acl-fixed-case>H</span>indi-<span class=acl-fixed-case>E</span>nglish Code-Mixed Tweets</a></strong><br><a href=/people/r/riya-pal/>Riya Pal</a>
|
<a href=/people/d/dipti-misra-sharma/>Dipti Sharma</a><br><a href=/volumes/W19-40/ class=text-muted>Proceedings of the 13th Linguistic Annotation Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4020><div class="card-body p-3 small">We present a <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> of 1460 Hindi-English code-mixed tweets consisting of 20,949 tokens labelled with Proposition Bank labels marking their semantic roles. We created verb frames for complex predicates present in the corpus and formulated mappings from Paninian dependency labels to Proposition Bank labels. With the help of these mappings and the dependency tree, we propose a baseline rule based system for <a href=https://en.wikipedia.org/wiki/Semantic_Role_Labelling>Semantic Role Labelling</a> of Hindi-English code-mixed data. We obtain an accuracy of 96.74 % for Argument Identification and are able to further classify 73.93 % of the labels correctly. While there is relevant ongoing research on Semantic Role Labelling and on building tools for code-mixed social media data, this is the first attempt at labelling semantic roles in code-mixed data, to the best of our knowledge.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5316.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5316 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5316 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5316/>The IIIT-H Gujarati-English Machine Translation System for WMT19<span class=acl-fixed-case>IIIT</span>-<span class=acl-fixed-case>H</span> <span class=acl-fixed-case>G</span>ujarati-<span class=acl-fixed-case>E</span>nglish Machine Translation System for <span class=acl-fixed-case>WMT</span>19</a></strong><br><a href=/people/v/vikrant-goyal/>Vikrant Goyal</a>
|
<a href=/people/d/dipti-misra-sharma/>Dipti Misra Sharma</a><br><a href=/volumes/W19-53/ class=text-muted>Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5316><div class="card-body p-3 small">This paper describes the Neural Machine Translation system of IIIT-Hyderabad for the GujaratiEnglish news translation shared task of WMT19. Our <a href=https://en.wikipedia.org/wiki/System>system</a> is basedon encoder-decoder framework with <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanism</a>. We experimented with Multilingual Neural MT models. Our experiments show that Multilingual Neural Machine Translation leveraging parallel data from related language pairs helps in significant BLEU improvements upto 11.5, for low resource language pairs like Gujarati-English</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-3017.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-3017 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-3017 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-3017/>Deep Neural Network based system for solving Arithmetic Word problems</a></strong><br><a href=/people/p/purvanshi-mehta/>Purvanshi Mehta</a>
|
<a href=/people/p/pruthwik-mishra/>Pruthwik Mishra</a>
|
<a href=/people/v/vinayak-athavale/>Vinayak Athavale</a>
|
<a href=/people/m/manish-shrivastava/>Manish Shrivastava</a>
|
<a href=/people/d/dipti-misra-sharma/>Dipti Sharma</a><br><a href=/volumes/I17-3/ class=text-muted>Proceedings of the IJCNLP 2017, System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-3017><div class="card-body p-3 small">This paper presents DILTON a <a href=https://en.wikipedia.org/wiki/System>system</a> which solves simple arithmetic word problems. DILTON uses a Deep Neural based model to solve math word problems. DILTON divides the question into two parts-worldstate and query. The worldstate and the query are processed separately in two different <a href=https://en.wikipedia.org/wiki/Network_analysis_(electrical_circuits)>networks</a> and finally, the <a href=https://en.wikipedia.org/wiki/Network_analysis_(electrical_circuits)>networks</a> are merged to predict the final operation. We report the first deep learning approach for the prediction of operation between two numbers. DILTON learns to predict operations with 88.81 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> in a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus of primary school questions</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6309.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6309 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6309 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6309/>Leveraging Newswire Treebanks for Parsing Conversational Data with Argument Scrambling</a></strong><br><a href=/people/r/riyaz-ahmad-bhat/>Riyaz A. Bhat</a>
|
<a href=/people/i/irshad-bhat/>Irshad Bhat</a>
|
<a href=/people/d/dipti-misra-sharma/>Dipti Sharma</a><br><a href=/volumes/W17-63/ class=text-muted>Proceedings of the 15th International Conference on Parsing Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6309><div class="card-body p-3 small">We investigate the problem of parsing conversational data of morphologically-rich languages such as <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> where argument scrambling occurs frequently. We evaluate a state-of-the-art non-linear transition-based parsing system on a new dataset containing 506 dependency trees for sentences from Bollywood (Hindi) movie scripts and Twitter posts of Hindi monolingual speakers. We show that a <a href=https://en.wikipedia.org/wiki/Dependency_grammar>dependency parser</a> trained on a newswire treebank is strongly biased towards the <a href=https://en.wikipedia.org/wiki/Canonical_form>canonical structures</a> and degrades when applied to conversational data. Inspired by <a href=https://en.wikipedia.org/wiki/Transformational_grammar>Transformational Generative Grammar</a> (Chomsky, 1965), we mitigate the <a href=https://en.wikipedia.org/wiki/Sampling_bias>sampling bias</a> by generating all theoretically possible alternative word orders of a clause from the existing (kernel) structures in the <a href=https://en.wikipedia.org/wiki/Treebank>treebank</a>. Training our <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> on canonical and transformed structures improves performance on conversational data by around 9 % LAS over the baseline newswire parser.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-2052.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-2052 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-2052 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-2052/>Joining Hands : Exploiting Monolingual Treebanks for Parsing of Code-mixing Data</a></strong><br><a href=/people/i/irshad-bhat/>Irshad Bhat</a>
|
<a href=/people/r/riyaz-ahmad-bhat/>Riyaz A. Bhat</a>
|
<a href=/people/m/manish-shrivastava/>Manish Shrivastava</a>
|
<a href=/people/d/dipti-misra-sharma/>Dipti Sharma</a><br><a href=/volumes/E17-2/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-2052><div class="card-body p-3 small">In this paper, we propose efficient and less resource-intensive strategies for parsing of code-mixed data. These strategies are not constrained by in-domain annotations, rather they leverage pre-existing monolingual annotated resources for training. We show that these <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> can produce significantly better results as compared to an <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>informed baseline</a>. Due to lack of an evaluation set for code-mixed structures, we also present a data set of 450 Hindi and English code-mixed tweets of Hindi multilingual speakers for evaluation.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Dipti+Misra+Sharma" title="Search for 'Dipti Misra Sharma' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/m/manish-shrivastava/ class=align-middle>Manish Shrivastava</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/v/vikrant-goyal/ class=align-middle>Vikrant Goyal</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/sourav-kumar/ class=align-middle>Sourav Kumar</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/pruthwik-mishra/ class=align-middle>Pruthwik Mishra</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/riyaz-ahmad-bhat/ class=align-middle>Riyaz Ahmad Bhat</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/i/irshad-bhat/ class=align-middle>Irshad Bhat</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/salil-aggarwal/ class=align-middle>Salil Aggarwal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/purvanshi-mehta/ class=align-middle>Purvanshi Mehta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vinayak-athavale/ class=align-middle>Vinayak Athavale</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vinay-pandramish/ class=align-middle>Vinay Pandramish</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pushpak-bhattacharyya/ class=align-middle>Pushpak Bhattacharyya</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ayush-joshi/ class=align-middle>Ayush Joshi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/niyati-bafna/ class=align-middle>Niyati Bafna</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/priyank-gupta/ class=align-middle>Priyank Gupta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rashid-ahmad/ class=align-middle>Rashid Ahmad</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/saujas-vaduguru/ class=align-middle>Saujas Vaduguru</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aalok-sathe/ class=align-middle>Aalok Sathe</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/monojit-choudhury/ class=align-middle>Monojit Choudhury</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/riya-pal/ class=align-middle>Riya Pal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/icon/ class=align-middle>ICON</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ranlp/ class=align-middle>RANLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/sigmorphon/ class=align-middle>SIGMORPHON</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>