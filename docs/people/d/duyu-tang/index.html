<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Duyu Tang - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Duyu</span> <span class=font-weight-bold>Tang</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.findings-acl.127.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--findings-acl--127 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.findings-acl.127 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2022.findings-acl.127.software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.findings-acl.127" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.findings-acl.127/>Logic-Driven Context Extension and Data Augmentation for Logical Reasoning of Text</a></strong><br><a href=/people/s/siyuan-wang/>Siyuan Wang</a>
|
<a href=/people/w/wanjun-zhong/>Wanjun Zhong</a>
|
<a href=/people/d/duyu-tang/>Duyu Tang</a>
|
<a href=/people/z/zhongyu-wei/>Zhongyu Wei</a>
|
<a href=/people/z/zhihao-fan/>Zhihao Fan</a>
|
<a href=/people/d/daxin-jiang/>Daxin Jiang</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a><br><a href=/volumes/2022.findings-acl/ class=text-muted>Findings of the Association for Computational Linguistics: ACL 2022</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--findings-acl--127><div class="card-body p-3 small">Logical reasoning of text requires identifying critical logical structures in the text and performing inference over them. Existing methods for logical reasoning mainly focus on contextual semantics of text while struggling to explicitly model the logical inference process. In this paper, we not only put forward a logic-driven context extension framework but also propose a logic-driven data augmentation algorithm. The former follows a three-step reasoning paradigm, and each step is respectively to extract logical expressions as elementary reasoning units, symbolically infer the implicit expressions following equivalence laws and extend the context to validate the options. The latter augments literally similar but logically different instances and incorporates contrastive learning to better capture logical information, especially logical negative and conditional relationships. We conduct experiments on two benchmark datasets, ReClor and LogiQA. The results show that our method achieves state-of-the-art performance on both datasets, and even surpasses human performance on the ReClor dataset.</div></div><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.62.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--62 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.62 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.62" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.62/>Compare to The Knowledge : Graph Neural Fake News Detection with External Knowledge</a></strong><br><a href=/people/l/linmei-hu/>Linmei Hu</a>
|
<a href=/people/t/tianchi-yang/>Tianchi Yang</a>
|
<a href=/people/l/luhao-zhang/>Luhao Zhang</a>
|
<a href=/people/w/wanjun-zhong/>Wanjun Zhong</a>
|
<a href=/people/d/duyu-tang/>Duyu Tang</a>
|
<a href=/people/c/chuan-shi/>Chuan Shi</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--62><div class="card-body p-3 small">Nowadays, fake news detection, which aims to verify whether a news document is trusted or fake, has become urgent and important. Most existing methods rely heavily on linguistic and semantic features from the news content, and fail to effectively exploit external knowledge which could help determine whether the news document is trusted. In this paper, we propose a novel end-to-end graph neural model called CompareNet, which compares the news to the knowledge base (KB) through entities for fake news detection. Considering that <a href=https://en.wikipedia.org/wiki/Fake_news>fake news detection</a> is correlated with topics, we also incorporate <a href=https://en.wikipedia.org/wiki/Topic_and_comment>topics</a> to enrich the news representation. Specifically, we first construct a directed heterogeneous document graph for each news incorporating topics and <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entities</a>. Based on the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a>, we develop a heterogeneous graph attention network for learning the topic-enriched news representation as well as the contextual entity representations that encode the semantics of the news content. The contextual entity representations are then compared to the corresponding KB-based entity representations through a carefully designed entity comparison network, to capture the consistency between the news content and KB. Finally, the topic-enriched news representation combining the <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity comparison features</a> is fed into a fake news classifier. Experimental results on two benchmark datasets demonstrate that <a href=https://en.wikipedia.org/wiki/CompareNet>CompareNet</a> significantly outperforms state-of-the-art methods.<i>directed heterogeneous document graph</i> for each news incorporating topics and entities. Based on the graph, we develop a <i>heterogeneous graph attention network</i> for learning the topic-enriched news representation as well as the contextual entity representations that encode the semantics of the news content. The contextual entity representations are then compared to the corresponding KB-based entity representations through a carefully designed <i>entity comparison network</i>, to capture the consistency between the news content and KB. Finally, the topic-enriched news representation combining the entity comparison features is fed into a fake news classifier. Experimental results on two benchmark datasets demonstrate that CompareNet significantly outperforms state-of-the-art methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.442.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--442 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.442 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.442" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.442/>CoSQA : 20,000 + Web Queries for Code Search and Question Answering<span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>SQA</span>: 20,000+ Web Queries for Code Search and Question Answering</a></strong><br><a href=/people/j/junjie-huang/>Junjie Huang</a>
|
<a href=/people/d/duyu-tang/>Duyu Tang</a>
|
<a href=/people/l/linjun-shou/>Linjun Shou</a>
|
<a href=/people/m/ming-gong/>Ming Gong</a>
|
<a href=/people/k/ke-xu/>Ke Xu</a>
|
<a href=/people/d/daxin-jiang/>Daxin Jiang</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--442><div class="card-body p-3 small">Finding codes given <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language query</a> is beneficial to the productivity of software developers. Future progress towards better <a href=https://en.wikipedia.org/wiki/Semantic_matching>semantic matching</a> between query and code requires richer supervised training resources. To remedy this, we introduce CoSQA dataset. It includes 20,604 labels for pairs of <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language queries</a> and codes, each annotated by at least 3 human annotators. We further introduce a contrastive learning method dubbed CoCLR to enhance text-code matching, which works as a data augmenter to bring more artificially generated training instances. We show that, evaluated on CodeXGLUE with the same CodeBERT model, training on CoSQA improves the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of code question answering by 5.1 % and incorporating CoCLR brings a further improvement of 10.5 %.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.193.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--193 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.193 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938858 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.193/>Neural Deepfake Detection with Factual Structure of Text</a></strong><br><a href=/people/w/wanjun-zhong/>Wanjun Zhong</a>
|
<a href=/people/d/duyu-tang/>Duyu Tang</a>
|
<a href=/people/z/zenan-xu/>Zenan Xu</a>
|
<a href=/people/r/ruize-wang/>Ruize Wang</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a>
|
<a href=/people/j/jiahai-wang/>Jiahai Wang</a>
|
<a href=/people/j/jian-yin/>Jian Yin</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--193><div class="card-body p-3 small">Deepfake detection, the task of automatically discriminating machine-generated text, is increasingly critical with recent advances in natural language generative models. Existing approaches to deepfake detection typically represent documents with coarse-grained representations. However, they struggle to capture factual structures of documents, which is a discriminative factor between machine-generated and human-written text according to our statistical analysis. To address this, we propose a graph-based model that utilizes the factual structure of a document for deepfake detection of text. Our approach represents the factual structure of a given document as an <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity graph</a>, which is further utilized to learn <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence representations</a> with a graph neural network. Sentence representations are then composed to a document representation for making predictions, where consistent relations between neighboring sentences are sequentially modeled. Results of experiments on two public deepfake datasets show that our approach significantly improves strong base models built with RoBERTa. Model analysis further indicates that our model can distinguish the difference in the factual structure between machine-generated text and <a href=https://en.wikipedia.org/wiki/Written_language>human-written text</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.549.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--549 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.549 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928866 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.549/>Reasoning Over Semantic-Level Graph for Fact Checking</a></strong><br><a href=/people/w/wanjun-zhong/>Wanjun Zhong</a>
|
<a href=/people/j/jingjing-xu/>Jingjing Xu</a>
|
<a href=/people/d/duyu-tang/>Duyu Tang</a>
|
<a href=/people/z/zenan-xu/>Zenan Xu</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a>
|
<a href=/people/j/jiahai-wang/>Jiahai Wang</a>
|
<a href=/people/j/jian-yin/>Jian Yin</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--549><div class="card-body p-3 small">Fact checking is a challenging task because verifying the truthfulness of a claim requires reasoning about multiple retrievable evidence. In this work, we present a <a href=https://en.wikipedia.org/wiki/Methodology>method</a> suitable for reasoning about the semantic-level structure of evidence. Unlike most previous works, which typically represent evidence sentences with either string concatenation or fusing the features of isolated evidence sentences, our approach operates on rich semantic structures of evidence obtained by semantic role labeling. We propose two mechanisms to exploit the structure of evidence while leveraging the advances of pre-trained models like BERT, GPT or XLNet. Specifically, using XLNet as the backbone, we first utilize the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> to re-define the relative distances of words, with the intuition that semantically related words should have short distances. Then, we adopt graph convolutional network and graph attention network to propagate and aggregate information from neighboring nodes on the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a>. We evaluate our system on FEVER, a benchmark dataset for <a href=https://en.wikipedia.org/wiki/Fact-checking>fact checking</a>, and find that rich structural information is helpful and both our graph-based mechanisms improve the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. Our model is the state-of-the-art system in terms of both official evaluation metrics, namely claim verification accuracy and FEVER score.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1248.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1248 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1248 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1248.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1248" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1248/>Multi-Task Learning for Conversational Question Answering over a Large-Scale Knowledge Base</a></strong><br><a href=/people/t/tao-shen/>Tao Shen</a>
|
<a href=/people/x/xiubo-geng/>Xiubo Geng</a>
|
<a href=/people/t/tao-qin/>Tao Qin</a>
|
<a href=/people/d/daya-guo/>Daya Guo</a>
|
<a href=/people/d/duyu-tang/>Duyu Tang</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/g/guodong-long/>Guodong Long</a>
|
<a href=/people/d/daxin-jiang/>Daxin Jiang</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1248><div class="card-body p-3 small">We consider the problem of conversational question answering over a large-scale knowledge base. To handle huge entity vocabulary of a large-scale knowledge base, recent neural semantic parsing based approaches usually decompose the task into several subtasks and then solve them sequentially, which leads to following issues : 1) errors in earlier subtasks will be propagated and negatively affect downstream ones ; and 2) each subtask can not naturally share supervision signals with others. To tackle these issues, we propose an innovative multi-task learning framework where a pointer-equipped semantic parsing model is designed to resolve coreference in conversations, and naturally empower joint learning with a novel type-aware entity detection model. The proposed <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> thus enables shared supervisions and alleviates the effect of <a href=https://en.wikipedia.org/wiki/Error_propagation>error propagation</a>. Experiments on a large-scale conversational question answering dataset containing 1.6 M question answering pairs over 12.8 M entities show that the proposed <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> improves overall F1 score from 67 % to 79 % compared with previous state-of-the-art work.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1188.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1188 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1188 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1188/>Question Generation from SQL Queries Improves Neural Semantic Parsing<span class=acl-fixed-case>SQL</span> Queries Improves Neural Semantic Parsing</a></strong><br><a href=/people/d/daya-guo/>Daya Guo</a>
|
<a href=/people/y/yibo-sun/>Yibo Sun</a>
|
<a href=/people/d/duyu-tang/>Duyu Tang</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/j/jian-yin/>Jian Yin</a>
|
<a href=/people/h/hong-chi/>Hong Chi</a>
|
<a href=/people/j/james-cao/>James Cao</a>
|
<a href=/people/p/peng-chen/>Peng Chen</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1188><div class="card-body p-3 small">In this paper, we study how to learn a <a href=https://en.wikipedia.org/wiki/Semantic_parser>semantic parser</a> of state-of-the-art <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> with less supervised training data. We conduct our study on WikiSQL, the largest hand-annotated semantic parsing dataset to date. First, we demonstrate that question generation is an effective method that empowers us to learn a state-of-the-art neural network based semantic parser with thirty percent of the supervised training data. Second, we show that applying question generation to the full supervised training data further improves the state-of-the-art model. In addition, we observe that there is a logarithmic relationship between the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of a <a href=https://en.wikipedia.org/wiki/Semantic_parser>semantic parser</a> and the amount of training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1141.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1141 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1141 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1141/>Learning to Collaborate for Question Answering and Asking</a></strong><br><a href=/people/d/duyu-tang/>Duyu Tang</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/z/zhao-yan/>Zhao Yan</a>
|
<a href=/people/z/zhirui-zhang/>Zhirui Zhang</a>
|
<a href=/people/y/yibo-sun/>Yibo Sun</a>
|
<a href=/people/s/shujie-liu/>Shujie Liu</a>
|
<a href=/people/y/yuanhua-lv/>Yuanhua Lv</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1141><div class="card-body p-3 small">Question answering (QA) and question generation (QG) are closely related <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> that could improve each other ; however, the connection of these two <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> is not well explored in literature. In this paper, we give a systematic study that seeks to leverage the connection to improve both QA and QG. We present a training algorithm that generalizes both Generative Adversarial Network (GAN) and Generative Domain-Adaptive Nets (GDAN) under the question answering scenario. The two key ideas are improving the QG model with QA through incorporating additional QA-specific signal as the <a href=https://en.wikipedia.org/wiki/Loss_function>loss function</a>, and improving the QA model with QG through adding artificially generated training instances. We conduct experiments on both document based and knowledge based question answering tasks. We have two main findings. Firstly, the performance of a QG model (e.g in terms of BLEU score) could be easily improved by a QA model via policy gradient. Secondly, directly applying GAN that regards all the generated questions as negative instances could not improve the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of the QA model. Learning when to regard generated questions as positive instances could bring performance boost.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1034.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1034 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1034 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-1034/>Semantic Parsing with Syntax- and Table-Aware SQL Generation<span class=acl-fixed-case>SQL</span> Generation</a></strong><br><a href=/people/y/yibo-sun/>Yibo Sun</a>
|
<a href=/people/d/duyu-tang/>Duyu Tang</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/j/jianshu-ji/>Jianshu Ji</a>
|
<a href=/people/g/guihong-cao/>Guihong Cao</a>
|
<a href=/people/x/xiaocheng-feng/>Xiaocheng Feng</a>
|
<a href=/people/b/bing-qin/>Bing Qin</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1034><div class="card-body p-3 small">We present a <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> to map <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language questions</a> into <a href=https://en.wikipedia.org/wiki/SQL>SQL queries</a>. Existing neural network based approaches typically generate a SQL query word-by-word, however, a large portion of the generated results is incorrect or not executable due to the mismatch between question words and table contents. Our approach addresses this problem by considering the <a href=https://en.wikipedia.org/wiki/Table_(database)>structure of table</a> and the <a href=https://en.wikipedia.org/wiki/SQL>syntax of SQL language</a>. The quality of the generated SQL query is significantly improved through (1) learning to replicate content from column names, cells or SQL keywords ; and (2) improving the generation of WHERE clause by leveraging the column-cell relation. Experiments are conducted on WikiSQL, a recently released dataset with the largest question- SQL pairs. Our <a href=https://en.wikipedia.org/wiki/Scientific_method>approach</a> significantly improves the state-of-the-art <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>execution accuracy</a> from 69.0 % to 74.4 %.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1090.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1090 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1090 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1090/>Question Generation for Question Answering</a></strong><br><a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/d/duyu-tang/>Duyu Tang</a>
|
<a href=/people/p/peng-chen/>Peng Chen</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1090><div class="card-body p-3 small">This paper presents how to generate questions from given passages using <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>, where large scale QA pairs are automatically crawled and processed from Community-QA website, and used as training data. The contribution of the paper is 2-fold : First, two types of question generation approaches are proposed, one is a retrieval-based method using convolution neural network (CNN), the other is a generation-based method using recurrent neural network (RNN) ; Second, we show how to leverage the generated questions to improve existing question answering systems. We evaluate our question generation method for the answer sentence selection task on three benchmark datasets, including SQuAD, MS MARCO, and WikiQA. Experimental results show that, by using generated questions as an extra signal, significant <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA</a> improvement can be achieved.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Duyu+Tang" title="Search for 'Duyu Tang' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/n/nan-duan/ class=align-middle>Nan Duan</a>
<span class="badge badge-secondary align-middle ml-2">10</span></li><li class=list-group-item><a href=/people/m/ming-zhou/ class=align-middle>Ming Zhou</a>
<span class="badge badge-secondary align-middle ml-2">9</span></li><li class=list-group-item><a href=/people/w/wanjun-zhong/ class=align-middle>Wanjun Zhong</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/d/daxin-jiang/ class=align-middle>Daxin Jiang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/jian-yin/ class=align-middle>Jian Yin</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/y/yibo-sun/ class=align-middle>Yibo Sun</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/z/zenan-xu/ class=align-middle>Zenan Xu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jiahai-wang/ class=align-middle>Jiahai Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/daya-guo/ class=align-middle>Daya Guo</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/peng-chen/ class=align-middle>Peng Chen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/linmei-hu/ class=align-middle>Linmei Hu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tianchi-yang/ class=align-middle>Tianchi Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luhao-zhang/ class=align-middle>Luhao Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chuan-shi/ class=align-middle>Chuan Shi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/junjie-huang/ class=align-middle>Junjie Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/linjun-shou/ class=align-middle>Linjun Shou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/ming-gong/ class=align-middle>Ming Gong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/ke-xu/ class=align-middle>Ke Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ruize-wang/ class=align-middle>Ruize Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jingjing-xu/ class=align-middle>Jingjing Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hong-chi/ class=align-middle>Hong Chi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/james-cao/ class=align-middle>James Cao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tao-shen/ class=align-middle>Tao Shen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiubo-geng/ class=align-middle>Xiubo Geng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tao-qin/ class=align-middle>Tao Qin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/guodong-long/ class=align-middle>Guodong Long</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/siyuan-wang/ class=align-middle>Siyuan Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhongyu-wei/ class=align-middle>Zhongyu Wei</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhihao-fan/ class=align-middle>Zhihao Fan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhao-yan/ class=align-middle>Zhao Yan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhirui-zhang/ class=align-middle>Zhirui Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shujie-liu/ class=align-middle>Shujie Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yuanhua-lv/ class=align-middle>Yuanhua Lv</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jianshu-ji/ class=align-middle>Jianshu Ji</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/guihong-cao/ class=align-middle>Guihong Cao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaocheng-feng/ class=align-middle>Xiaocheng Feng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bing-qin/ class=align-middle>Bing Qin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/ting-liu/ class=align-middle>Ting Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>