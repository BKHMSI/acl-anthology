<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Denis Peskov - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Denis</span> <span class=font-weight-bold>Peskov</span></h2><hr><div class=row><div class=col-lg-9><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.353.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--353 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.353 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928719 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.353/>It Takes Two to Lie : One to Lie, and One to Listen</a></strong><br><a href=/people/d/denis-peskov/>Denis Peskov</a>
|
<a href=/people/b/benny-cheng/>Benny Cheng</a>
|
<a href=/people/a/ahmed-elgohary/>Ahmed Elgohary</a>
|
<a href=/people/j/joe-barrow/>Joe Barrow</a>
|
<a href=/people/c/cristian-danescu-niculescu-mizil/>Cristian Danescu-Niculescu-Mizil</a>
|
<a href=/people/j/jordan-boyd-graber/>Jordan Boyd-Graber</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--353><div class="card-body p-3 small">Trust is implicit in many online text conversationsstriking up new friendships, or asking for tech support. But <a href=https://en.wikipedia.org/wiki/Trust_(social_science)>trust</a> can be betrayed through <a href=https://en.wikipedia.org/wiki/Deception>deception</a>. We study the language and dynamics of <a href=https://en.wikipedia.org/wiki/Deception>deception</a> in the negotiation-based game Diplomacy, where seven players compete for world domination by forging and breaking alliances with each other. Our study with players from the Diplomacy community gathers 17,289 messages annotated by the sender for their intended truthfulness and by the receiver for their perceived truthfulness. Unlike existing datasets, this captures <a href=https://en.wikipedia.org/wiki/Deception>deception</a> in long-lasting relationships, where the interlocutors strategically combine truth with lies to advance objectives. A <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that uses power dynamics and conversational contexts can predict when a lie occurs nearly as well as human players.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.417.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--417 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.417 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.417/>ContraCAT : Contrastive Coreference Analytical Templates for <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a><span class=acl-fixed-case>C</span>ontra<span class=acl-fixed-case>CAT</span>: Contrastive Coreference Analytical Templates for Machine Translation</a></strong><br><a href=/people/d/dario-stojanovski/>Dario Stojanovski</a>
|
<a href=/people/b/benno-krojer/>Benno Krojer</a>
|
<a href=/people/d/denis-peskov/>Denis Peskov</a>
|
<a href=/people/a/alexander-fraser/>Alexander Fraser</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--417><div class="card-body p-3 small">Recent high scores on pronoun translation using context-aware neural machine translation have suggested that current approaches work well. ContraPro is a notable example of a contrastive challenge set for EnglishGerman pronoun translation. The high scores achieved by transformer models may suggest that they are able to effectively model the complicated set of <a href=https://en.wikipedia.org/wiki/Statistical_inference>inferences</a> required to carry out pronoun translation. This entails the ability to determine which entities could be referred to, identify which entity a source-language pronoun refers to (if any), and access the target-language grammatical gender for that entity. We first show through a series of targeted adversarial attacks that in fact current approaches are not able to model all of this information well. Inserting small amounts of <a href=https://en.wikipedia.org/wiki/Distraction>distracting information</a> is enough to strongly reduce scores, which should not be the case. We then create a new template test set ContraCAT, designed to individually assess the ability to handle the specific steps necessary for successful pronoun translation. Our analyses show that current approaches to context-aware NMT rely on a set of <a href=https://en.wikipedia.org/wiki/Heuristics_in_judgment_and_decision-making>surface heuristics</a>, which break down when translations require real reasoning. We also propose an approach for augmenting the training data, with some improvements.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1460.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1460 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1460 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1460.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-1460/>Multi-Domain Goal-Oriented Dialogues (MultiDoGO): Strategies toward Curating and Annotating Large Scale Dialogue Data<span class=acl-fixed-case>M</span>ulti<span class=acl-fixed-case>D</span>o<span class=acl-fixed-case>GO</span>): Strategies toward Curating and Annotating Large Scale Dialogue Data</a></strong><br><a href=/people/d/denis-peskov/>Denis Peskov</a>
|
<a href=/people/n/nancy-clarke/>Nancy Clarke</a>
|
<a href=/people/j/jason-krone/>Jason Krone</a>
|
<a href=/people/b/brigi-fodor/>Brigi Fodor</a>
|
<a href=/people/y/yi-zhang/>Yi Zhang</a>
|
<a href=/people/a/adel-youssef/>Adel Youssef</a>
|
<a href=/people/m/mona-diab/>Mona Diab</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1460><div class="card-body p-3 small">The need for high-quality, large-scale, goal-oriented dialogue datasets continues to grow as <a href=https://en.wikipedia.org/wiki/Virtual_assistant>virtual assistants</a> become increasingly wide-spread. However, publicly available datasets useful for this area are limited either in their size, <a href=https://en.wikipedia.org/wiki/Linguistic_diversity>linguistic diversity</a>, domain coverage, or <a href=https://en.wikipedia.org/wiki/Granularity>annotation granularity</a>. In this paper, we present <a href=https://en.wikipedia.org/wiki/Strategy>strategies</a> toward curating and annotating large scale goal oriented dialogue data. We introduce the MultiDoGO dataset to overcome these limitations. With a total of over 81 K dialogues harvested across six domains, MultiDoGO is over 8 times the size of MultiWOZ, the other largest comparable dialogue dataset currently available to the public. Over 54 K of these harvested conversations are annotated for intent classes and slot labels. We adopt a Wizard-of-Oz approach wherein a crowd-sourced worker (the customer) is paired with a trained annotator (the agent). The data curation process was controlled via biases to ensure a diversity in dialogue flows following variable dialogue policies. We provide distinct class label tags for agents vs. customer utterances, along with applicable slot labels. We also compare and contrast our <a href=https://en.wikipedia.org/wiki/Strategy>strategies</a> on annotation granularity, i.e. turn vs. sentence level. Furthermore, we compare and contrast annotations curated by leveraging professional annotators vs the crowd. We believe our strategies for eliciting and annotating such a dialogue dataset scales across modalities and domains and potentially languages in the future. To demonstrate the efficacy of our devised strategies we establish neural baselines for <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> on the agent and customer utterances as well as slot labeling for each domain.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1489.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1489 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1489 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1489/>Comparing and Developing Tools to Measure the Readability of Domain-Specific Texts</a></strong><br><a href=/people/e/elissa-redmiles/>Elissa Redmiles</a>
|
<a href=/people/l/lisa-maszkiewicz/>Lisa Maszkiewicz</a>
|
<a href=/people/e/emily-hwang/>Emily Hwang</a>
|
<a href=/people/d/dhruv-kuchhal/>Dhruv Kuchhal</a>
|
<a href=/people/e/everest-liu/>Everest Liu</a>
|
<a href=/people/m/miraida-morales/>Miraida Morales</a>
|
<a href=/people/d/denis-peskov/>Denis Peskov</a>
|
<a href=/people/s/sudha-rao/>Sudha Rao</a>
|
<a href=/people/r/rock-stevens/>Rock Stevens</a>
|
<a href=/people/k/kristina-gligoric/>Kristina Gligorić</a>
|
<a href=/people/s/sean-kross/>Sean Kross</a>
|
<a href=/people/m/michelle-mazurek/>Michelle Mazurek</a>
|
<a href=/people/h/hal-daume-iii/>Hal Daumé III</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1489><div class="card-body p-3 small">The <a href=https://en.wikipedia.org/wiki/Readability>readability</a> of a digital text can influence people&#8217;s ability to learn new things about a range topics from <a href=https://en.wikipedia.org/wiki/Web_resource>digital resources</a> (e.g., <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, <a href=https://en.wikipedia.org/wiki/WebMD>WebMD</a>). Readability also impacts <a href=https://en.wikipedia.org/wiki/Search_engine_results_page>search rankings</a>, and is used to evaluate the performance of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP systems</a>. Despite this, we lack a thorough understanding of how to validly measure <a href=https://en.wikipedia.org/wiki/Readability>readability</a> at scale, especially for domain-specific texts. In this work, we present a comparison of the <a href=https://en.wikipedia.org/wiki/Validity_(statistics)>validity</a> of well-known readability measures and introduce a novel approach, Smart Cloze, which is designed to address shortcomings of existing measures. We compare these approaches across four different corpora : crowdworker-generated stories, Wikipedia articles, security and privacy advice, and health information. On these corpora, we evaluate the convergent and content validity of each measure, and detail tradeoffs in score precision, domain-specificity, and participant burden. These results provide a foundation for more accurate readability measurements and better evaluation of new <a href=https://en.wikipedia.org/wiki/Natural-language_processing>natural-language-processing systems</a> and tools.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2026.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2026 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2026 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2026/>UMDeep at SemEval-2017 Task 1 : End-to-End Shared Weight LSTM Model for Semantic Textual Similarity<span class=acl-fixed-case>UMD</span>eep at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 1: End-to-End Shared Weight <span class=acl-fixed-case>LSTM</span> Model for Semantic Textual Similarity</a></strong><br><a href=/people/j/joe-barrow/>Joe Barrow</a>
|
<a href=/people/d/denis-peskov/>Denis Peskov</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2026><div class="card-body p-3 small">We describe a modified shared-LSTM network for the Semantic Textual Similarity (STS) task at SemEval-2017. The <a href=https://en.wikipedia.org/wiki/Computer_network>network</a> builds on previously explored Siamese network architectures. We treat max sentence length as an additional <a href=https://en.wikipedia.org/wiki/Hyperparameter>hyperparameter</a> to be tuned (beyond learning rate, <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization</a>, and dropout). Our results demonstrate that hand-tuning max sentence training length significantly improves final <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. After optimizing <a href=https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)>hyperparameters</a>, we train the <a href=https://en.wikipedia.org/wiki/Computer_network>network</a> on the multilingual semantic similarity task using pre-translated sentences. We achieved a <a href=https://en.wikipedia.org/wiki/Correlation_and_dependence>correlation</a> of 0.4792 for all the subtasks. We achieved the fourth highest team correlation for Task 4b, which was our best relative placement.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Denis+Peskov" title="Search for 'Denis Peskov' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/j/joe-barrow/ class=align-middle>Joe Barrow</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/benny-cheng/ class=align-middle>Benny Cheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ahmed-elgohary/ class=align-middle>Ahmed Elgohary</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cristian-danescu-niculescu-mizil/ class=align-middle>Cristian Danescu-Niculescu-Mizil</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jordan-boyd-graber/ class=align-middle>Jordan Boyd-Graber</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/n/nancy-clarke/ class=align-middle>Nancy Clarke</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jason-krone/ class=align-middle>Jason Krone</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/brigi-fodor/ class=align-middle>Brigi Fodor</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yi-zhang/ class=align-middle>Yi Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/adel-youssef/ class=align-middle>Adel Youssef</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mona-diab/ class=align-middle>Mona Diab</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elissa-redmiles/ class=align-middle>Elissa Redmiles</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lisa-maszkiewicz/ class=align-middle>Lisa Maszkiewicz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/emily-hwang/ class=align-middle>Emily Hwang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dhruv-kuchhal/ class=align-middle>Dhruv Kuchhal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/everest-liu/ class=align-middle>Everest Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/miraida-morales/ class=align-middle>Miraida Morales</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sudha-rao/ class=align-middle>Sudha Rao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rock-stevens/ class=align-middle>Rock Stevens</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kristina-gligoric/ class=align-middle>Kristina Gligorić</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sean-kross/ class=align-middle>Sean Kross</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michelle-mazurek/ class=align-middle>Michelle Mazurek</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hal-daume-iii/ class=align-middle>Hal Daumé III</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dario-stojanovski/ class=align-middle>Dario Stojanovski</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/benno-krojer/ class=align-middle>Benno Krojer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexander-fraser/ class=align-middle>Alexander Fraser</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>