<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Douwe Kiela - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Douwe</span> <span class=font-weight-bold>Kiela</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.517.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--517 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.517 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.517" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.517/>On the Efficacy of Adversarial Data Collection for <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a> : Results from a Large-Scale Randomized Study</a></strong><br><a href=/people/d/divyansh-kaushik/>Divyansh Kaushik</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/z/zachary-c-lipton/>Zachary C. Lipton</a>
|
<a href=/people/w/wen-tau-yih/>Wen-tau Yih</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--517><div class="card-body p-3 small">In adversarial data collection (ADC), a human workforce interacts with a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in real time, attempting to produce examples that elicit incorrect predictions. Researchers hope that <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> trained on these more challenging <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> will rely less on superficial patterns, and thus be less brittle. However, despite ADC&#8217;s intuitive appeal, it remains unclear when training on adversarial datasets produces more robust models. In this paper, we conduct a large-scale controlled study focused on <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>, assigning workers at random to compose questions either (i) adversarially (with a model in the loop) ; or (ii) in the standard fashion (without a model). Across a variety of <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> and datasets, we find that <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on adversarial data usually perform better on other adversarial datasets but worse on a diverse collection of out-of-domain evaluation sets. Finally, we provide a qualitative analysis of adversarial (vs standard) data, identifying key differences and offering guidance for future research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.230.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--230 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.230 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.230/>Masked Language Modeling and the Distributional Hypothesis : Order Word Matters Pre-training for Little</a></strong><br><a href=/people/k/koustuv-sinha/>Koustuv Sinha</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/d/dieuwke-hupkes/>Dieuwke Hupkes</a>
|
<a href=/people/j/joelle-pineau/>Joelle Pineau</a>
|
<a href=/people/a/adina-williams/>Adina Williams</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--230><div class="card-body p-3 small">A possible explanation for the impressive performance of masked language model (MLM) pre-training is that such models have learned to represent the syntactic structures prevalent in classical NLP pipelines. In this paper, we propose a different explanation : MLMs succeed on downstream tasks almost entirely due to their ability to model higher-order word co-occurrence statistics. To demonstrate this, we pre-train MLMs on sentences with randomly shuffled word order, and show that these models still achieve high <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> after fine-tuning on many downstream tasksincluding tasks specifically designed to be challenging for models that ignore <a href=https://en.wikipedia.org/wiki/Word_order>word order</a>. Our models perform surprisingly well according to some parametric syntactic probes, indicating possible deficiencies in how we test representations for syntactic information. Overall, our results show that purely distributional information largely explains the success of pre-training, and underscore the importance of curating challenging evaluation datasets that require deeper linguistic knowledge.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.464.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--464 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.464 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.464" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.464/>Gradient-based Adversarial Attacks against Text Transformers</a></strong><br><a href=/people/c/chuan-guo/>Chuan Guo</a>
|
<a href=/people/a/alexandre-sablayrolles/>Alexandre Sablayrolles</a>
|
<a href=/people/h/herve-jegou/>Hervé Jégou</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--464><div class="card-body p-3 small">We propose the first general-purpose gradient-based adversarial attack against transformer models. Instead of searching for a single adversarial example, we search for a distribution of adversarial examples parameterized by a continuous-valued matrix, hence enabling gradient-based optimization. We empirically demonstrate that our white-box attack attains state-of-the-art attack performance on a variety of natural language tasks, outperforming prior work in terms of adversarial success rate with matching imperceptibility as per automated and human evaluation. Furthermore, we show that a powerful black-box transfer attack, enabled by sampling from the adversarial distribution, matches or exceeds existing methods, while only requiring hard-label outputs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.696.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--696 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.696 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.696/>Improving Question Answering Model Robustness with Synthetic Adversarial Data Generation</a></strong><br><a href=/people/m/max-bartolo/>Max Bartolo</a>
|
<a href=/people/t/tristan-thrush/>Tristan Thrush</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/s/sebastian-riedel/>Sebastian Riedel</a>
|
<a href=/people/p/pontus-stenetorp/>Pontus Stenetorp</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--696><div class="card-body p-3 small">Despite recent progress, state-of-the-art question answering models remain vulnerable to a variety of <a href=https://en.wikipedia.org/wiki/Adversarial_system>adversarial attacks</a>. While dynamic adversarial data collection, in which a human annotator tries to write examples that fool a model-in-the-loop, can improve model robustness, this process is expensive which limits the scale of the collected data. In this work, we are the first to use synthetic adversarial data generation to make <a href=https://en.wikipedia.org/wiki/Question_answering>question answering models</a> more robust to <a href=https://en.wikipedia.org/wiki/Adversarial_system>human adversaries</a>. We develop a data generation pipeline that selects source passages, identifies candidate answers, generates questions, then finally filters or re-labels them to improve <a href=https://en.wikipedia.org/wiki/Quality_(business)>quality</a>. Using this approach, we amplify a smaller human-written adversarial dataset to a much larger set of synthetic question-answer pairs. By incorporating our synthetic data, we improve the state-of-the-art on the AdversarialQA dataset by 3.7F1 and improve model generalisation on nine of the twelve MRQA datasets. We further conduct a novel human-in-the-loop evaluation and show that our models are considerably more robust to new human-written adversarial examples : crowdworkers can fool our <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> only 8.8 % of the time on average, compared to 17.6 % for a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> trained without synthetic data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.woah-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.woah-1.0/>Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021)</a></strong><br><a href=/people/a/aida-mostafazadeh-davani/>Aida Mostafazadeh Davani</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/m/mathias-lambert/>Mathias Lambert</a>
|
<a href=/people/b/bertie-vidgen/>Bertie Vidgen</a>
|
<a href=/people/v/vinodkumar-prabhakaran/>Vinodkumar Prabhakaran</a>
|
<a href=/people/z/zeerak-waseem/>Zeerak Waseem</a><br><a href=/volumes/2021.woah-1/ class=text-muted>Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.324.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--324 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.324 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.324/>Dynabench : Rethinking Benchmarking in NLP<span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/m/max-bartolo/>Max Bartolo</a>
|
<a href=/people/y/yixin-nie/>Yixin Nie</a>
|
<a href=/people/d/divyansh-kaushik/>Divyansh Kaushik</a>
|
<a href=/people/a/atticus-geiger/>Atticus Geiger</a>
|
<a href=/people/z/zhengxuan-wu/>Zhengxuan Wu</a>
|
<a href=/people/b/bertie-vidgen/>Bertie Vidgen</a>
|
<a href=/people/g/grusha-prasad/>Grusha Prasad</a>
|
<a href=/people/a/amanpreet-singh/>Amanpreet Singh</a>
|
<a href=/people/p/pratik-ringshia/>Pratik Ringshia</a>
|
<a href=/people/z/zhiyi-ma/>Zhiyi Ma</a>
|
<a href=/people/t/tristan-thrush/>Tristan Thrush</a>
|
<a href=/people/s/sebastian-riedel/>Sebastian Riedel</a>
|
<a href=/people/z/zeerak-waseem/>Zeerak Waseem</a>
|
<a href=/people/p/pontus-stenetorp/>Pontus Stenetorp</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a>
|
<a href=/people/c/christopher-potts/>Christopher Potts</a>
|
<a href=/people/a/adina-williams/>Adina Williams</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--324><div class="card-body p-3 small">We introduce Dynabench, an open-source platform for dynamic dataset creation and model benchmarking. Dynabench runs in a web browser and supports human-and-model-in-the-loop dataset creation : annotators seek to create examples that a target model will misclassify, but that another person will not. In this paper, we argue that Dynabench addresses a critical need in our community : contemporary models quickly achieve outstanding performance on benchmark tasks but nonetheless fail on simple challenge examples and falter in real-world scenarios. With Dynabench, dataset creation, model development, and model assessment can directly inform each other, leading to more robust and informative benchmarks. We report on four initial NLP tasks, illustrating these concepts and highlighting the promise of the <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a>, and address potential objections to dynamic benchmarking as a new standard for the field.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.aacl-demo.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.aacl-demo.0/>Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing: System Demonstrations</a></strong><br><a href=/people/d/derek-wong/>Derek Wong</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a><br><a href=/volumes/2020.aacl-demo/ class=text-muted>Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing: System Demonstrations</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1062.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1062 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1062 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1062.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-1062/>Learning to Speak and Act in a Fantasy Text Adventure Game</a></strong><br><a href=/people/j/jack-urbanek/>Jack Urbanek</a>
|
<a href=/people/a/angela-fan/>Angela Fan</a>
|
<a href=/people/s/siddharth-karamcheti/>Siddharth Karamcheti</a>
|
<a href=/people/s/saachi-jain/>Saachi Jain</a>
|
<a href=/people/s/samuel-humeau/>Samuel Humeau</a>
|
<a href=/people/e/emily-dinan/>Emily Dinan</a>
|
<a href=/people/t/tim-rocktaschel/>Tim Rocktäschel</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/a/arthur-szlam/>Arthur Szlam</a>
|
<a href=/people/j/jason-weston/>Jason Weston</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1062><div class="card-body p-3 small">We introduce a large-scale crowdsourced text adventure game as a research platform for studying grounded dialogue. In it, agents can perceive, emote, and act whilst conducting dialogue with other agents. Models and humans can both act as characters within the <a href=https://en.wikipedia.org/wiki/Game>game</a>. We describe the results of training state-of-the-art generative and retrieval models in this setting. We show that in addition to using past dialogue, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are able to effectively use the state of the underlying world to condition their predictions. In particular, we show that grounding on the details of the local environment, including location descriptions, and the objects (and their affordances) and characters (and their previous actions) present within it allows better predictions of agent behavior and <a href=https://en.wikipedia.org/wiki/Dialogue>dialogue</a>. We analyze the ingredients necessary for successful grounding in this <a href=https://en.wikipedia.org/wiki/Setting_(narrative)>setting</a>, and how each of these factors relate to agents that can talk and act successfully.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6409.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-6409 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-6409 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6409/>Seeded self-play for <a href=https://en.wikipedia.org/wiki/Language_acquisition>language learning</a></a></strong><br><a href=/people/a/abhinav-gupta/>Abhinav Gupta</a>
|
<a href=/people/r/ryan-lowe/>Ryan Lowe</a>
|
<a href=/people/j/jakob-foerster/>Jakob Foerster</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/j/joelle-pineau/>Joelle Pineau</a><br><a href=/volumes/D19-64/ class=text-muted>Proceedings of the Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-6409><div class="card-body p-3 small">How can we teach <a href=https://en.wikipedia.org/wiki/Intelligent_agent>artificial agents</a> to use <a href=https://en.wikipedia.org/wiki/Human_language>human language</a> flexibly to solve problems in real-world environments? We have an example of this in nature : human babies eventually learn to use <a href=https://en.wikipedia.org/wiki/Human_language>human language</a> to solve problems, and they are taught with an adult human-in-the-loop. Unfortunately, current <a href=https://en.wikipedia.org/wiki/List_of_machine_learning_methods>machine learning methods</a> (e.g. from deep reinforcement learning) are too data inefficient to learn <a href=https://en.wikipedia.org/wiki/Language>language</a> in this way. An outstanding goal is finding an <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> with a suitable &#8216;language learning prior&#8217; that allows it to learn human language, while minimizing the number of on-policy human interactions. In this paper, we propose to learn such a prior in simulation using an approach we call, Learning to Learn to Communicate (L2C). Specifically, in L2C we train a meta-learning agent in simulation to interact with populations of pre-trained agents, each with their own distinct communication protocol. Once the meta-learning agent is able to quickly adapt to each population of agents, it can be deployed in new <a href=https://en.wikipedia.org/wiki/Population>populations</a>, including populations speaking human language. Our key insight is that such populations can be obtained via self-play, after pre-training agents with imitation learning on a small amount of off-policy human language data. We call this latter technique Seeded Self-Play (S2P). Our preliminary experiments show that agents trained with L2C and S2P need fewer on-policy samples to learn a compositional language in a <a href=https://en.wikipedia.org/wiki/Lewis_signaling_game>Lewis signaling game</a>.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1176.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1176 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1176 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1176" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D18-1176/>Dynamic Meta-Embeddings for Improved Sentence Representations</a></strong><br><a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/c/changhan-wang/>Changhan Wang</a>
|
<a href=/people/k/kyunghyun-cho/>Kyunghyun Cho</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1176><div class="card-body p-3 small">While one of the first steps in many NLP systems is selecting what pre-trained word embeddings to use, we argue that such a step is better left for <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> to figure out by themselves. To that end, we introduce dynamic meta-embeddings, a simple yet effective method for the supervised learning of embedding ensembles, which leads to state-of-the-art performance within the same model class on a variety of tasks. We subsequently show how the technique can be used to shed new light on the usage of <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP systems</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3221.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3221 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3221 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3221/>Code-Switched Named Entity Recognition with Embedding Attention</a></strong><br><a href=/people/c/changhan-wang/>Changhan Wang</a>
|
<a href=/people/k/kyunghyun-cho/>Kyunghyun Cho</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a><br><a href=/volumes/W18-32/ class=text-muted>Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3221><div class="card-body p-3 small">We describe our work for the CALCS 2018 shared task on <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a> on code-switched data. Our system ranked first place for MS Arabic-Egyptian named entity recognition and third place for English-Spanish.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1205.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1205 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1205 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1205.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805443 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1205" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1205/>Personalizing Dialogue Agents : I have a dog, do you have pets too?<span class=acl-fixed-case>I</span> have a dog, do you have pets too?</a></strong><br><a href=/people/s/saizheng-zhang/>Saizheng Zhang</a>
|
<a href=/people/e/emily-dinan/>Emily Dinan</a>
|
<a href=/people/j/jack-urbanek/>Jack Urbanek</a>
|
<a href=/people/a/arthur-szlam/>Arthur Szlam</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/j/jason-weston/>Jason Weston</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1205><div class="card-body p-3 small">Chit-chat models are known to have several problems : they lack <a href=https://en.wikipedia.org/wiki/Sensitivity_and_specificity>specificity</a>, do not display a consistent personality and are often not very captivating. In this work we present the task of making <a href=https://en.wikipedia.org/wiki/Chit-chat>chit-chat</a> more engaging by conditioning on profile information. We collect data and train models to (i)condition on their given profile information ; and (ii) information about the person they are talking to, resulting in improved dialogues, as measured by next utterance prediction. Since (ii) is initially unknown our model is trained to engage its partner with personal topics, and we show the resulting dialogue can be used to predict profile information about the interlocutors.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-2057.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-2057 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-2057 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-2057.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285803929 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-2057" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-2057/>Hearst Patterns Revisited : Automatic Hypernym Detection from Large Text Corpora</a></strong><br><a href=/people/s/stephen-roller/>Stephen Roller</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/m/maximilian-nickel/>Maximilian Nickel</a><br><a href=/volumes/P18-2/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-2057><div class="card-body p-3 small">Methods for unsupervised hypernym detection may broadly be categorized according to two paradigms : pattern-based and distributional methods. In this paper, we study the performance of both approaches on several hypernymy tasks and find that simple pattern-based methods consistently outperform <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distributional methods</a> on common benchmark datasets. Our results show that pattern-based models provide important contextual constraints which are not yet captured in <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distributional methods</a>.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1016 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-1016.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234952320 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1016/>Automatically Generating Rhythmic Verse with <a href=https://en.wikipedia.org/wiki/Neural_network>Neural Networks</a></a></strong><br><a href=/people/j/jack-hopkins/>Jack Hopkins</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1016><div class="card-body p-3 small">We propose two novel <a href=https://en.wikipedia.org/wiki/Methodology>methodologies</a> for the automatic generation of rhythmic poetry in a variety of forms. The first approach uses a neural language model trained on a <a href=https://en.wikipedia.org/wiki/Phonetic_transcription>phonetic encoding</a> to learn an implicit representation of both the form and content of English poetry. This model can effectively learn common poetic devices such as <a href=https://en.wikipedia.org/wiki/Rhyme>rhyme</a>, <a href=https://en.wikipedia.org/wiki/Rhythm>rhythm</a> and <a href=https://en.wikipedia.org/wiki/Alliteration>alliteration</a>. The second approach considers poetry generation as a <a href=https://en.wikipedia.org/wiki/Constraint_satisfaction_problem>constraint satisfaction problem</a> where a generative neural language model is tasked with learning a representation of content, and a discriminative weighted finite state machine constrains it on the basis of form. By manipulating the constraints of the latter <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>, we can generate coherent poetry with arbitrary forms and themes. A large-scale extrinsic evaluation demonstrated that participants consider machine-generated poems to be written by humans 54 % of the time. In addition, participants rated a machine-generated poem to be the best amongst all evaluated.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q17-1002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q17-1002 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q17-1002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234954554 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/Q17-1002/>Visually Grounded and Textual Semantic Models Differentially Decode Brain Activity Associated with Concrete and Abstract Nouns</a></strong><br><a href=/people/a/andrew-j-anderson/>Andrew J. Anderson</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/s/stephen-clark/>Stephen Clark</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a><br><a href=/volumes/Q17-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 5</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q17-1002><div class="card-body p-3 small">Important advances have recently been made using computational semantic models to decode brain activity patterns associated with <a href=https://en.wikipedia.org/wiki/Concept>concepts</a> ; however, this work has almost exclusively focused on concrete nouns. How well these <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> extend to decoding <a href=https://en.wikipedia.org/wiki/Noun>abstract nouns</a> is largely unknown. We address this question by applying state-of-the-art computational models to decode functional Magnetic Resonance Imaging (fMRI) activity patterns, elicited by participants reading and imagining a diverse set of both concrete and abstract nouns. One of the <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> we use is linguistic, exploiting the recent word2vec skipgram approach trained on <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>. The <a href=https://en.wikipedia.org/wiki/Second>second</a> is visually grounded, using <a href=https://en.wikipedia.org/wiki/Deep_learning>deep convolutional neural networks</a> trained on <a href=https://en.wikipedia.org/wiki/Google_Images>Google Images</a>. Dual coding theory considers concrete concepts to be encoded in the brain both linguistically and visually, and abstract concepts only linguistically. Splitting the fMRI data according to human concreteness ratings, we indeed observe that both models significantly decode the most concrete nouns ; however, accuracy is significantly greater using the text-based models for the most abstract nouns. More generally this confirms that current <a href=https://en.wikipedia.org/wiki/Computational_model>computational models</a> are sufficiently advanced to assist in investigating the representational structure of <a href=https://en.wikipedia.org/wiki/Concept>abstract concepts</a> in the brain.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/J17-4004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-J17-4004 data-toggle=collapse aria-expanded=false aria-controls=abstract-J17-4004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/J17-4004/>HyperLex : A Large-Scale Evaluation of Graded Lexical Entailment<span class=acl-fixed-case>H</span>yper<span class=acl-fixed-case>L</span>ex: A Large-Scale Evaluation of Graded Lexical Entailment</a></strong><br><a href=/people/i/ivan-vulic/>Ivan Vulić</a>
|
<a href=/people/d/daniela-gerz/>Daniela Gerz</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/f/felix-hill/>Felix Hill</a>
|
<a href=/people/a/anna-korhonen/>Anna Korhonen</a><br><a href=/volumes/J17-4/ class=text-muted>Computational Linguistics, Volume 43, Issue 4 - December 2017</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-J17-4004><div class="card-body p-3 small">We introduce HyperLexa data set and evaluation resource that quantifies the extent of the semantic category membership, that is, type-of relation, also known as <a href=https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy>hyponymyhypernymy</a> or lexical entailment (LE) relation between 2,616 concept pairs. Cognitive psychology research has established that typicality and category / class membership are computed in <a href=https://en.wikipedia.org/wiki/Semantic_memory>human semantic memory</a> as a gradual rather than <a href=https://en.wikipedia.org/wiki/Binary_relation>binary relation</a>. Nevertheless, most <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP research</a> and existing large-scale inventories of concept category membership (WordNet, <a href=https://en.wikipedia.org/wiki/DBPedia>DBPedia</a>, etc.) treat category membership and LE as binary. To address this, we asked hundreds of <a href=https://en.wikipedia.org/wiki/First_language>native English speakers</a> to indicate typicality and strength of <a href=https://en.wikipedia.org/wiki/Categorization>category membership</a> between a diverse range of concept pairs on a <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing platform</a>. Our results confirm that category membership and LE are indeed more gradual than <a href=https://en.wikipedia.org/wiki/Binary_relation>binary</a>. We then compare these human judgments with the predictions of automatic systems, which reveals a huge gap between human performance and state-of-the-art LE, distributional and representation learning models, and substantial differences between the models themselves. We discuss a pathway for improving semantic models to overcome this discrepancy, and indicate future application areas for improved graded LE systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1070.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1070 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1070 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238236002 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D17-1070" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1070/>Supervised Learning of Universal Sentence Representations from Natural Language Inference Data</a></strong><br><a href=/people/a/alexis-conneau/>Alexis Conneau</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/h/holger-schwenk/>Holger Schwenk</a>
|
<a href=/people/l/loic-barrault/>Loïc Barrault</a>
|
<a href=/people/a/antoine-bordes/>Antoine Bordes</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1070><div class="card-body p-3 small">Many modern NLP systems rely on <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>, previously trained in an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised manner</a> on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised data</a> of the Stanford Natural Language Inference datasets can consistently outperform <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised methods</a> like SkipThought vectors on a wide range of transfer tasks. Much like how <a href=https://en.wikipedia.org/wiki/Computer_vision>computer vision</a> uses <a href=https://en.wikipedia.org/wiki/ImageNet>ImageNet</a> to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> to other NLP tasks. Our <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> is publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1162.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1162 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1162 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238233405 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1162/>Grasping the Finer Point : A Supervised Similarity Network for Metaphor Detection</a></strong><br><a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/l/luana-bulat/>Luana Bulat</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1162><div class="card-body p-3 small">The ubiquity of <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a> in our everyday communication makes <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> an important problem for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a>. Yet, the majority of metaphor processing systems to date rely on hand-engineered features and there is still no consensus in the field as to which features are optimal for this task. In this paper, we present the first deep learning architecture designed to capture metaphorical composition. Our results demonstrate that <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> outperforms the existing <a href=https://en.wikipedia.org/wiki/Psychological_evaluation>approaches</a> in the metaphor identification task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-2012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-2012 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-2012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-2012/>Learning to Negate Adjectives with Bilinear Models</a></strong><br><a href=/people/l/laura-rimell/>Laura Rimell</a>
|
<a href=/people/a/amandla-mabona/>Amandla Mabona</a>
|
<a href=/people/l/luana-bulat/>Luana Bulat</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a><br><a href=/volumes/E17-2/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-2012><div class="card-body p-3 small">We learn a <a href=https://en.wikipedia.org/wiki/Map_(mathematics)>mapping</a> that negates <a href=https://en.wikipedia.org/wiki/Adjective>adjectives</a> by predicting an adjective&#8217;s antonym in an arbitrary word embedding model. We show that both <a href=https://en.wikipedia.org/wiki/Linear_model>linear models</a> and <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> improve on this task when they have access to a vector representing the <a href=https://en.wikipedia.org/wiki/Semantic_domain>semantic domain</a> of the input word, e.g. a centroid of temperature words when predicting the antonym of &#8216;cold&#8217;. We introduce a continuous class-conditional bilinear neural network which is able to negate <a href=https://en.wikipedia.org/wiki/Adjective>adjectives</a> with high <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a>.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Douwe+Kiela" title="Search for 'Douwe Kiela' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/r/robin-jia/ class=align-middle>Robin Jia</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/d/divyansh-kaushik/ class=align-middle>Divyansh Kaushik</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/changhan-wang/ class=align-middle>Changhan Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/kyunghyun-cho/ class=align-middle>Kyunghyun Cho</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/joelle-pineau/ class=align-middle>Joelle Pineau</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/a/adina-williams/ class=align-middle>Adina Williams</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/max-bartolo/ class=align-middle>Max Bartolo</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/tristan-thrush/ class=align-middle>Tristan Thrush</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sebastian-riedel/ class=align-middle>Sebastian Riedel</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/pontus-stenetorp/ class=align-middle>Pontus Stenetorp</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jack-urbanek/ class=align-middle>Jack Urbanek</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/emily-dinan/ class=align-middle>Emily Dinan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/arthur-szlam/ class=align-middle>Arthur Szlam</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jason-weston/ class=align-middle>Jason Weston</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/bertie-vidgen/ class=align-middle>Bertie Vidgen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/zeerak-waseem/ class=align-middle>Zeerak Waseem</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/luana-bulat/ class=align-middle>Luana Bulat</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/zachary-c-lipton/ class=align-middle>Zachary C. Lipton</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wen-tau-yih/ class=align-middle>Wen-tau Yih</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jack-hopkins/ class=align-middle>Jack Hopkins</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/derek-wong/ class=align-middle>Derek Wong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrew-j-anderson/ class=align-middle>Andrew J. Anderson</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stephen-clark/ class=align-middle>Stephen Clark</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/massimo-poesio/ class=align-middle>Massimo Poesio</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ivan-vulic/ class=align-middle>Ivan Vulić</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/daniela-gerz/ class=align-middle>Daniela Gerz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/felix-hill/ class=align-middle>Felix Hill</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anna-korhonen/ class=align-middle>Anna Korhonen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/koustuv-sinha/ class=align-middle>Koustuv Sinha</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dieuwke-hupkes/ class=align-middle>Dieuwke Hupkes</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chuan-guo/ class=align-middle>Chuan Guo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexandre-sablayrolles/ class=align-middle>Alexandre Sablayrolles</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/herve-jegou/ class=align-middle>Hervé Jégou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/angela-fan/ class=align-middle>Angela Fan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/siddharth-karamcheti/ class=align-middle>Siddharth Karamcheti</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/saachi-jain/ class=align-middle>Saachi Jain</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/samuel-humeau/ class=align-middle>Samuel Humeau</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tim-rocktaschel/ class=align-middle>Tim Rocktäschel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/abhinav-gupta/ class=align-middle>Abhinav Gupta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ryan-lowe/ class=align-middle>Ryan Lowe</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jakob-foerster/ class=align-middle>Jakob Foerster</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aida-mostafazadeh-davani/ class=align-middle>Aida Mostafazadeh Davani</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mathias-lambert/ class=align-middle>Mathias Lambert</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vinodkumar-prabhakaran/ class=align-middle>Vinodkumar Prabhakaran</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexis-conneau/ class=align-middle>Alexis Conneau</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/holger-schwenk/ class=align-middle>Holger Schwenk</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/loic-barrault/ class=align-middle>Loïc Barrault</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/antoine-bordes/ class=align-middle>Antoine Bordes</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marek-rei/ class=align-middle>Marek Rei</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/ekaterina-shutova/ class=align-middle>Ekaterina Shutova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yixin-nie/ class=align-middle>Yixin Nie</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/atticus-geiger/ class=align-middle>Atticus Geiger</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhengxuan-wu/ class=align-middle>Zhengxuan Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/grusha-prasad/ class=align-middle>Grusha Prasad</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/amanpreet-singh/ class=align-middle>Amanpreet Singh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pratik-ringshia/ class=align-middle>Pratik Ringshia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhiyi-ma/ class=align-middle>Zhiyi Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mohit-bansal/ class=align-middle>Mohit Bansal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christopher-potts/ class=align-middle>Christopher Potts</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/laura-rimell/ class=align-middle>Laura Rimell</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/amandla-mabona/ class=align-middle>Amandla Mabona</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/saizheng-zhang/ class=align-middle>Saizheng Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stephen-roller/ class=align-middle>Stephen Roller</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maximilian-nickel/ class=align-middle>Maximilian Nickel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/aacl/ class=align-middle>AACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/tacl/ class=align-middle>TACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/cl/ class=align-middle>CL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/woah/ class=align-middle>WOAH</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>