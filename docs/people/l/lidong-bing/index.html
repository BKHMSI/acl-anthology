<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Lidong Bing - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Lidong</span> <span class=font-weight-bold>Bing</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.162.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--162 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.162 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2022.acl-long.162.software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.acl-long.162" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.162/><span class=acl-fixed-case>IAM</span>: A Comprehensive and Large-Scale Dataset for Integrated Argument Mining Tasks</a></strong><br><a href=/people/l/liying-cheng/>Liying Cheng</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/r/ruidan-he/>Ruidan He</a>
|
<a href=/people/q/qian-yu/>Qian Yu</a>
|
<a href=/people/y/yan-zhang/>Yan Zhang</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--162><div class="card-body p-3 small">Traditionally, a debate usually requires a manual preparation process, including reading plenty of articles, selecting the claims, identifying the stances of the claims, seeking the evidence for the claims, etc. As the AI debate attracts more attention these years, it is worth exploring the methods to automate the tedious process involved in the debating system. In this work, we introduce a comprehensive and large dataset named IAM, which can be applied to a series of argument mining tasks, including claim extraction, stance classification, evidence extraction, etc. Our dataset is collected from over 1k articles related to 123 topics. Near 70k sentences in the dataset are fully annotated based on their argument properties (e.g., claims, stances, evidence, etc.). We further propose two new integrated argument mining tasks associated with the debate preparation process: (1) claim extraction with stance classification (CESC) and (2) claim-evidence pair extraction (CEPE). We adopt a pipeline approach and an end-to-end method for each integrated task separately. Promising experimental results are reported to show the values and challenges of our proposed tasks, and motivate future research on argument mining.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.findings-acl.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--findings-acl--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.findings-acl.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.findings-acl.5" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.findings-acl.5/><span class=acl-fixed-case>R</span>elation<span class=acl-fixed-case>P</span>rompt: Leveraging Prompts to Generate Synthetic Data for Zero-Shot Relation Triplet Extraction</a></strong><br><a href=/people/y/yew-ken-chia/>Yew Ken Chia</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/s/soujanya-poria/>Soujanya Poria</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/2022.findings-acl/ class=text-muted>Findings of the Association for Computational Linguistics: ACL 2022</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--findings-acl--5><div class="card-body p-3 small">Despite the importance of relation extraction in building and representing knowledge, less research is focused on generalizing to unseen relations types. We introduce the task setting of Zero-Shot Relation Triplet Extraction (ZeroRTE) to encourage further research in low-resource relation extraction methods. Given an input sentence, each extracted triplet consists of the head entity, relation label, and tail entity where the relation label is not seen at the training stage. To solve ZeroRTE, we propose to synthesize relation examples by prompting language models to generate structured texts. Concretely, we unify language model prompts and structured text approaches to design a structured prompt template for generating synthetic relation samples when conditioning on relation label prompts (RelationPrompt). To overcome the limitation for extracting multiple relation triplets in a sentence, we design a novel Triplet Search Decoding method. Experiments on FewRel and Wiki-ZSL datasets show the efficacy of RelationPrompt for the ZeroRTE task and zero-shot relation classification. Our code and data are available at github.com/declare-lab/RelationPrompt.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.findings-acl.132.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--findings-acl--132 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.findings-acl.132 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2022.findings-acl.132.software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.findings-acl.132" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.findings-acl.132/>Document-Level Relation Extraction with Adaptive Focal Loss and Knowledge Distillation</a></strong><br><a href=/people/q/qingyu-tan/>Qingyu Tan</a>
|
<a href=/people/r/ruidan-he/>Ruidan He</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/h/hwee-tou-ng/>Hwee Tou Ng</a><br><a href=/volumes/2022.findings-acl/ class=text-muted>Findings of the Association for Computational Linguistics: ACL 2022</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--findings-acl--132><div class="card-body p-3 small">Document-level Relation Extraction (DocRE) is a more challenging task compared to its sentence-level counterpart. It aims to extract relations from multiple sentences at once. In this paper, we propose a semi-supervised framework for DocRE with three novel components. Firstly, we use an axial attention module for learning the interdependency among entity-pairs, which improves the performance on two-hop relations. Secondly, we propose an adaptive focal loss to tackle the class imbalance problem of DocRE. Lastly, we use knowledge distillation to overcome the differences between human annotated data and distantly supervised data. We conducted experiments on two DocRE datasets. Our model consistently outperforms strong baselines and its performance exceeds the previous SOTA by 1.36 F1 and 1.46 Ign_F1 score on the DocRED leaderboard.</div></div><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.172.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--172 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.172 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.172/>On the Effectiveness of Adapter-based Tuning for Pretrained Language Model Adaptation</a></strong><br><a href=/people/r/ruidan-he/>Ruidan He</a>
|
<a href=/people/l/linlin-liu/>Linlin Liu</a>
|
<a href=/people/h/hai-ye/>Hai Ye</a>
|
<a href=/people/q/qingyu-tan/>Qingyu Tan</a>
|
<a href=/people/b/bosheng-ding/>Bosheng Ding</a>
|
<a href=/people/l/liying-cheng/>Liying Cheng</a>
|
<a href=/people/j/jiawei-low/>Jiawei Low</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--172><div class="card-body p-3 small">Adapter-based tuning has recently arisen as an alternative to <a href=https://en.wikipedia.org/wiki/Musical_tuning>fine-tuning</a>. It works by adding light-weight adapter modules to a pretrained language model (PrLM) and only updating the parameters of adapter modules when learning on a downstream task. As such, it adds only a few trainable parameters per new <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>, allowing a high degree of parameter sharing. Prior studies have shown that adapter-based tuning often achieves comparable results to <a href=https://en.wikipedia.org/wiki/Musical_tuning>fine-tuning</a>. However, existing work only focuses on the parameter-efficient aspect of adapter-based tuning while lacking further investigation on its effectiveness. In this paper, we study the latter. We first show that adapter-based tuning better mitigates forgetting issues than <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> since it yields representations with less deviation from those generated by the initial PrLM. We then empirically compare the two tuning methods on several downstream NLP tasks and settings. We demonstrate that 1) adapter-based tuning outperforms <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> on low-resource and cross-lingual tasks ; 2) it is more robust to <a href=https://en.wikipedia.org/wiki/Overfitting>overfitting</a> and less sensitive to changes in learning rates.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.453.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--453 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.453 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.453/>MulDA : A Multilingual Data Augmentation Framework for Low-Resource Cross-Lingual NER<span class=acl-fixed-case>M</span>ul<span class=acl-fixed-case>DA</span>: A Multilingual Data Augmentation Framework for Low-Resource Cross-Lingual <span class=acl-fixed-case>NER</span></a></strong><br><a href=/people/l/linlin-liu/>Linlin Liu</a>
|
<a href=/people/b/bosheng-ding/>Bosheng Ding</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/l/luo-si/>Luo Si</a>
|
<a href=/people/c/chunyan-miao/>Chunyan Miao</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--453><div class="card-body p-3 small">Named Entity Recognition (NER) for low-resource languages is a both practical and challenging research problem. This paper addresses zero-shot transfer for cross-lingual NER, especially when the amount of source-language training data is also limited. The paper first proposes a simple but effective labeled sequence translation method to translate source-language training data to target languages and avoids problems such as word order change and entity span determination. With the source-language data as well as the translated data, a generation-based multilingual data augmentation method is introduced to further increase diversity by generating synthetic labeled data in multiple languages. These augmented data enable the language model based NER models to generalize better with both the language-specific features from the target-language synthetic data and the language-independent features from multilingual synthetic data. An extensive set of experiments were conducted to demonstrate encouraging cross-lingual transfer performance of the new <a href=https://en.wikipedia.org/wiki/Research>research</a> on a wide variety of target languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.496.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--496 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.496 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.496" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.496/>Argument Pair Extraction via Attention-guided Multi-Layer Multi-Cross Encoding</a></strong><br><a href=/people/l/liying-cheng/>Liying Cheng</a>
|
<a href=/people/t/tianyu-wu/>Tianyu Wu</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--496><div class="card-body p-3 small">Argument pair extraction (APE) is a research task for extracting arguments from two passages and identifying potential argument pairs. Prior research work treats this task as a sequence labeling problem and a binary classification problem on two passages that are directly concatenated together, which has a limitation of not fully utilizing the unique characteristics and inherent relations of two different passages. This paper proposes a novel attention-guided multi-layer multi-cross encoding scheme to address the challenges. The new model processes two passages with two individual sequence encoders and updates their <a href=https://en.wikipedia.org/wiki/Representation_theory>representations</a> using each other&#8217;s representations through <a href=https://en.wikipedia.org/wiki/Attention>attention</a>. In addition, the pair prediction part is formulated as a table-filling problem by updating the representations of two sequences&#8217; Cartesian product. Furthermore, an auxiliary attention loss is introduced to guide each argument to align to its paired argument. An extensive set of experiments show that the new <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> significantly improves the APE performance over several alternatives.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.90.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--90 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.90 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938972 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.90" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.90/>ENT-DESC : Entity Description Generation by Exploring Knowledge Graph<span class=acl-fixed-case>ENT</span>-<span class=acl-fixed-case>DESC</span>: Entity Description Generation by Exploring Knowledge Graph</a></strong><br><a href=/people/l/liying-cheng/>Liying Cheng</a>
|
<a href=/people/d/dekun-wu/>Dekun Wu</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/y/yan-zhang/>Yan Zhang</a>
|
<a href=/people/z/zhanming-jie/>Zhanming Jie</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--90><div class="card-body p-3 small">Previous works on knowledge-to-text generation take as input a few <a href=https://en.wikipedia.org/wiki/Resource_Description_Framework>RDF triples</a> or key-value pairs conveying the knowledge of some entities to generate a <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language description</a>. Existing datasets, such as WIKIBIO, WebNLG, and <a href=https://en.wikipedia.org/wiki/E2E>E2E</a>, basically have a good alignment between an input triple / pair set and its output text. However, in practice, the input knowledge could be more than enough, since the output description may only cover the most significant knowledge. In this paper, we introduce a large-scale and challenging dataset to facilitate the study of such a practical scenario in KG-to-text. Our dataset involves retrieving abundant knowledge of various types of main entities from a large knowledge graph (KG), which makes the current graph-to-sequence models severely suffer from the problems of <a href=https://en.wikipedia.org/wiki/Information_loss>information loss</a> and parameter explosion while generating the descriptions. We address these challenges by proposing a multi-graph structure that is able to represent the original <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph information</a> more comprehensively. Furthermore, we also incorporate aggregation methods that learn to extract the rich graph information. Extensive experiments demonstrate the effectiveness of our model architecture.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.183.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--183 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.183 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.183.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939300 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.183" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.183/>Position-Aware Tagging for Aspect Sentiment Triplet Extraction</a></strong><br><a href=/people/l/lu-xu/>Lu Xu</a>
|
<a href=/people/h/hao-li/>Hao Li</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--183><div class="card-body p-3 small">Aspect Sentiment Triplet Extraction (ASTE) is the task of extracting the triplets of target entities, their associated sentiment, and opinion spans explaining the reason for the sentiment. Existing research efforts mostly solve this problem using pipeline approaches, which break the triplet extraction process into several stages. Our observation is that the three elements within a triplet are highly related to each other, and this motivates us to build a joint model to extract such triplets using a sequence tagging approach. However, how to effectively design a tagging approach to extract the triplets that can capture the rich interactions among the elements is a challenging research question. In this work, we propose the first <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end model</a> with a novel position-aware tagging scheme that is capable of jointly extracting the <a href=https://en.wikipedia.org/wiki/Multiple_birth>triplets</a>. Our experimental results on several existing datasets show that jointly capturing elements in the triplet using our approach leads to improved performance over the existing approaches. We also conducted extensive experiments to investigate the model effectiveness and robustness.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.569.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--569 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.569 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939058 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.569" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.569/>APE : Argument Pair Extraction from Peer Review and Rebuttal via <a href=https://en.wikipedia.org/wiki/Multi-task_learning>Multi-task Learning</a><span class=acl-fixed-case>APE</span>: Argument Pair Extraction from Peer Review and Rebuttal via Multi-task Learning</a></strong><br><a href=/people/l/liying-cheng/>Liying Cheng</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/q/qian-yu/>Qian Yu</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--569><div class="card-body p-3 small">Peer review and rebuttal, with rich interactions and argumentative discussions in between, are naturally a good resource to mine arguments. However, few works study both of <a href=https://en.wikipedia.org/wiki/List_of_Latin_phrases_(I)>them</a> simultaneously. In this paper, we introduce a new argument pair extraction (APE) task on peer review and rebuttal in order to study the contents, the structure and the connections between them. We prepare a challenging <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> that contains 4,764 fully annotated review-rebuttal passage pairs from an open review platform to facilitate the study of this task. To automatically detect argumentative propositions and extract argument pairs from this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, we cast it as the combination of a sequence labeling task and a text relation classification task. Thus, we propose a multitask learning framework based on hierarchical LSTM networks. Extensive experiments and analysis demonstrate the effectiveness of our multi-task framework, and also show the challenges of the new <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> as well as motivate future research directions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.738.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--738 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.738 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939283 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.738" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.738/>Partially-Aligned Data-to-Text Generation with Distant Supervision</a></strong><br><a href=/people/z/zihao-fu/>Zihao Fu</a>
|
<a href=/people/b/bei-shi/>Bei Shi</a>
|
<a href=/people/w/wai-lam/>Wai Lam</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/z/zhiyuan-liu/>Zhiyuan Liu</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--738><div class="card-body p-3 small">The Data-to-Text task aims to generate <a href=https://en.wikipedia.org/wiki/Human-readable_medium>human-readable text</a> for describing some given structured data enabling more interpretability. However, the typical generation task is confined to a few particular domains since it requires well-aligned data which is difficult and expensive to obtain. Using partially-aligned data is an alternative way of solving the dataset scarcity problem. This kind of <a href=https://en.wikipedia.org/wiki/Data>data</a> is much easier to obtain since <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> can be produced automatically. However, using this kind of <a href=https://en.wikipedia.org/wiki/Data>data</a> induces the over-generation problem posing difficulties for existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, which tends to add unrelated excerpts during the generation procedure. In order to effectively utilize automatically annotated partially-aligned datasets, we extend the traditional generation task to a refined task called Partially-Aligned Data-to-Text Generation (PADTG) which is more practical since it utilizes automatically annotated data for training and thus considerably expands the application domains. To tackle this new <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, we propose a novel distant supervision generation framework. It firstly estimates the input data&#8217;s supportiveness for each target word with an <a href=https://en.wikipedia.org/wiki/Estimator>estimator</a> and then applies a supportiveness adaptor and a rebalanced beam search to harness the over-generation problem in the training and generation phases respectively. We also contribute a partially-aligned dataset (The data and source code of this paper can be obtained from https://github.com/fuzihaofzh/distant_supervision_nlg) by sampling sentences from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a> and automatically extracting corresponding KB triples for each sentence from <a href=https://en.wikipedia.org/wiki/Wikidata>Wikidata</a>. The experimental results show that our <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> outperforms all baseline models as well as verify the feasibility of utilizing partially-aligned data.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1019.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1019 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1019 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1019/>Using Customer Service Dialogues for Satisfaction Analysis with Context-Assisted Multiple Instance Learning</a></strong><br><a href=/people/k/kaisong-song/>Kaisong Song</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/w/wei-gao/>Wei Gao</a>
|
<a href=/people/j/jun-lin/>Jun Lin</a>
|
<a href=/people/l/lujun-zhao/>Lujun Zhao</a>
|
<a href=/people/j/jiancheng-wang/>Jiancheng Wang</a>
|
<a href=/people/c/changlong-sun/>Changlong Sun</a>
|
<a href=/people/x/xiaozhong-liu/>Xiaozhong Liu</a>
|
<a href=/people/q/qiong-zhang/>Qiong Zhang</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1019><div class="card-body p-3 small">Customers ask questions and customer service staffs answer their questions, which is the basic <a href=https://en.wikipedia.org/wiki/Service_model>service model</a> via multi-turn customer service (CS) dialogues on <a href=https://en.wikipedia.org/wiki/E-commerce>E-commerce platforms</a>. Existing studies fail to provide comprehensive service satisfaction analysis, namely satisfaction polarity classification (e.g., well satisfied, met and unsatisfied) and sentimental utterance identification (e.g., positive, neutral and negative). In this paper, we conduct a pilot study on the task of service satisfaction analysis (SSA) based on multi-turn CS dialogues. We propose an extensible Context-Assisted Multiple Instance Learning (CAMIL) model to predict the <a href=https://en.wikipedia.org/wiki/Sentimentality>sentiments</a> of all the customer utterances and then aggregate those <a href=https://en.wikipedia.org/wiki/Sentimentality>sentiments</a> into service satisfaction polarity. After that, we propose a novel Context Clue Matching Mechanism (CCMM) to enhance the representations of all customer utterances with their matched context clues, i.e., sentiment and reasoning clues. We construct two CS dialogue datasets from a top E-commerce platform. Extensive experimental results are presented and contrasted against a few previous <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> to demonstrate the efficacy of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1024.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-1024/>Tackling Long-Tailed Relations and Uncommon Entities in Knowledge Graph Completion</a></strong><br><a href=/people/z/zihao-wang/>Zihao Wang</a>
|
<a href=/people/k/kwunping-lai/>Kwunping Lai</a>
|
<a href=/people/p/piji-li/>Piji Li</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/w/wai-lam/>Wai Lam</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1024><div class="card-body p-3 small">For large-scale knowledge graphs (KGs), recent research has been focusing on the large proportion of infrequent relations which have been ignored by previous studies. For example few-shot learning paradigm for <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a> has been investigated. In this work, we further advocate that handling uncommon entities is inevitable when dealing with infrequent relations. Therefore, we propose a meta-learning framework that aims at handling infrequent relations with few-shot learning and uncommon entities by using textual descriptions. We design a novel <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to better extract key information from textual descriptions. Besides, we also develop a novel <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> in our <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> to enhance the performance by generating extra triplets during the training stage. Experiments are conducted on two datasets from real-world KGs, and the results show that our framework outperforms previous methods when dealing with infrequent relations and their accompanying uncommon entities.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1199.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1199 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1199 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1199.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-1199/>Who Is Speaking to Whom? Learning to Identify Utterance Addressee in Multi-Party Conversations</a></strong><br><a href=/people/r/ran-le/>Ran Le</a>
|
<a href=/people/w/wenpeng-hu/>Wenpeng Hu</a>
|
<a href=/people/m/mingyue-shang/>Mingyue Shang</a>
|
<a href=/people/z/zhenjun-you/>Zhenjun You</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/d/dongyan-zhao/>Dongyan Zhao</a>
|
<a href=/people/r/rui-yan/>Rui Yan</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1199><div class="card-body p-3 small">Previous research on dialogue systems generally focuses on the conversation between two participants, yet multi-party conversations which involve more than two participants within one session bring up a more complicated but realistic scenario. In real multi- party conversations, we can observe who is speaking, but the addressee information is not always explicit. In this paper, we aim to tackle the challenge of identifying all the miss- ing addressees in a conversation session. To this end, we introduce a novel who-to-whom (W2W) model which models users and utterances in the session jointly in an interactive way. We conduct experiments on the benchmark Ubuntu Multi-Party Conversation Corpus and the experimental results demonstrate that our model outperforms baselines with consistent improvements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1466.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1466 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1466 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1466.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1466" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1466/>Transferable End-to-End Aspect-based Sentiment Analysis with Selective Adversarial Learning</a></strong><br><a href=/people/z/zheng-li/>Zheng Li</a>
|
<a href=/people/x/xin-li/>Xin Li</a>
|
<a href=/people/y/ying-wei/>Ying Wei</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/y/yu-zhang/>Yu Zhang</a>
|
<a href=/people/q/qiang-yang/>Qiang Yang</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1466><div class="card-body p-3 small">Joint extraction of aspects and sentiments can be effectively formulated as a sequence labeling problem. However, such formulation hinders the effectiveness of <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised methods</a> due to the lack of annotated sequence data in many domains. To address this issue, we firstly explore an unsupervised domain adaptation setting for this <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>. Prior work can only use common syntactic relations between <a href=https://en.wikipedia.org/wiki/Grammatical_aspect>aspect</a> and opinion words to bridge the domain gaps, which highly relies on external linguistic resources. To resolve it, we propose a novel Selective Adversarial Learning (SAL) method to align the inferred correlation vectors that automatically capture their latent relations. The SAL method can dynamically learn an alignment weight for each word such that more important words can possess higher alignment weights to achieve fine-grained (word-level) adaptation. Empirically, extensive experiments demonstrate the effectiveness of the proposed SAL method.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1499.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1499 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1499 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1499/>Semi-supervised Text Style Transfer : Cross Projection in Latent Space</a></strong><br><a href=/people/m/mingyue-shang/>Mingyue Shang</a>
|
<a href=/people/p/piji-li/>Piji Li</a>
|
<a href=/people/z/zhenxin-fu/>Zhenxin Fu</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/d/dongyan-zhao/>Dongyan Zhao</a>
|
<a href=/people/s/shuming-shi/>Shuming Shi</a>
|
<a href=/people/r/rui-yan/>Rui Yan</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1499><div class="card-body p-3 small">Text style transfer task requires the model to transfer a sentence of one style to another style while retaining its original content meaning, which is a challenging problem that has long suffered from the shortage of parallel data. In this paper, we first propose a semi-supervised text style transfer model that combines the small-scale parallel data with the large-scale nonparallel data. With these two types of training data, we introduce a <a href=https://en.wikipedia.org/wiki/Projection_(linear_algebra)>projection function</a> between the latent space of different styles and design two <a href=https://en.wikipedia.org/wiki/Constraint_(mathematics)>constraints</a> to train it. We also introduce two other simple but effective <a href=https://en.wikipedia.org/wiki/Semi-supervised_learning>semi-supervised methods</a> to compare with. To evaluate the performance of the proposed methods, we build and release a novel style transfer dataset that alters sentences between the style of ancient Chinese poem and the modern Chinese.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1563.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1563 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1563 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1563/>A Knowledge Regularized Hierarchical Approach for Emotion Cause Analysis</a></strong><br><a href=/people/c/chuang-fan/>Chuang Fan</a>
|
<a href=/people/h/hongyu-yan/>Hongyu Yan</a>
|
<a href=/people/j/jiachen-du/>Jiachen Du</a>
|
<a href=/people/l/lin-gui/>Lin Gui</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/m/min-yang/>Min Yang</a>
|
<a href=/people/r/ruifeng-xu/>Ruifeng Xu</a>
|
<a href=/people/r/ruibin-mao/>Ruibin Mao</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1563><div class="card-body p-3 small">Emotion cause analysis, which aims to identify the reasons behind emotions, is a key topic in <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>. A variety of neural network models have been proposed recently, however, these previous models mostly focus on the learning architecture with local textual information, ignoring the discourse and prior knowledge, which play crucial roles in human text comprehension. In this paper, we propose a new method to extract emotion cause with a hierarchical neural model and knowledge-based regularizations, which aims to incorporate discourse context information and restrain the parameters by sentiment lexicon and <a href=https://en.wikipedia.org/wiki/Common_knowledge>common knowledge</a>. The experimental results demonstrate that our proposed method achieves the state-of-the-art performance on two public datasets in different languages (Chinese and English), outperforming a number of competitive baselines by at least 2.08 % in <a href=https://en.wikipedia.org/wiki/F-measure>F-measure</a>.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1069.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1069 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1069 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/306360792 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1069/>Hybrid Neural Attention for Agreement / Disagreement Inference in Online Debates</a></strong><br><a href=/people/d/di-chen/>Di Chen</a>
|
<a href=/people/j/jiachen-du/>Jiachen Du</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/r/ruifeng-xu/>Ruifeng Xu</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1069><div class="card-body p-3 small">Inferring the agreement / disagreement relation in <a href=https://en.wikipedia.org/wiki/Debate>debates</a>, especially in online debates, is one of the fundamental tasks in argumentation mining. The expressions of agreement / disagreement usually rely on argumentative expressions in text as well as interactions between participants in debates. Previous works usually lack the capability of jointly modeling these two factors. To alleviate this problem, this paper proposes a hybrid neural attention model which combines self and cross attention mechanism to locate salient part from textual context and interaction between users. Experimental results on three (dis)agreement inference datasets show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms the state-of-the-art models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1322.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1322 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1322 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1322/>Estimating Marginal Probabilities of n-grams for Recurrent Neural Language Models</a></strong><br><a href=/people/t/thanapon-noraset/>Thanapon Noraset</a>
|
<a href=/people/d/doug-downey/>Doug Downey</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1322><div class="card-body p-3 small">Recurrent neural network language models (RNNLMs) are the current standard-bearer for statistical language modeling. However, RNNLMs only estimate probabilities for complete sequences of text, whereas some applications require context-independent phrase probabilities instead. In this paper, we study how to compute an RNNLM&#8217;s em marginal probability : the probability that the model assigns to a short sequence of text when the preceding context is not known. We introduce a simple method of altering the RNNLM training to make the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> more accurate at marginal estimation. Our experiments demonstrate that the technique is effective compared to baselines including the traditional RNNLM probability and an importance sampling approach. Finally, we show how we can use the marginal estimation to improve an RNNLM by training the <a href=https://en.wikipedia.org/wiki/Marginal_distribution>marginals</a> to match n-gram probabilities from a larger corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1420.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1420 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1420 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1420" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D18-1420/>QuaSE : Sequence Editing under Quantifiable Guidance<span class=acl-fixed-case>Q</span>ua<span class=acl-fixed-case>SE</span>: Sequence Editing under Quantifiable Guidance</a></strong><br><a href=/people/y/yi-liao/>Yi Liao</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/p/piji-li/>Piji Li</a>
|
<a href=/people/s/shuming-shi/>Shuming Shi</a>
|
<a href=/people/w/wai-lam/>Wai Lam</a>
|
<a href=/people/t/tong-zhang/>Tong Zhang</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1420><div class="card-body p-3 small">We propose the task of Quantifiable Sequence Editing (QuaSE): editing an input sequence to generate an output sequence that satisfies a given numerical outcome value measuring a certain property of the sequence, with the requirement of keeping the main content of the input sequence. For example, an input sequence could be a word sequence, such as review sentence and <a href=https://en.wikipedia.org/wiki/Advertising>advertisement text</a>. For a review sentence, the outcome could be the review rating ; for an <a href=https://en.wikipedia.org/wiki/Advertising>advertisement</a>, the outcome could be the <a href=https://en.wikipedia.org/wiki/Click-through_rate>click-through rate</a>. The major challenge in performing QuaSE is how to perceive the outcome-related wordings, and only edit them to change the outcome. In this paper, the proposed framework contains two latent factors, namely, outcome factor and content factor, disentangled from the input sentence to allow convenient editing to change the outcome and keep the content. Our framework explores the pseudo-parallel sentences by modeling their content similarity and outcome differences to enable a better disentanglement of the latent factors, which allows generating an output to better satisfy the desired outcome and keep the content. The dual reconstruction structure further enhances the capability of generating expected output by exploiting the couplings of latent factors of pseudo-parallel sentences. For evaluation, we prepared a dataset of Yelp review sentences with the ratings as outcome. Extensive experimental results are reported and discussed to elaborate the peculiarities of our <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1087.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1087 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1087 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1087.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285801308 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1087" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1087/>Transformation Networks for Target-Oriented Sentiment Classification</a></strong><br><a href=/people/x/xin-li/>Xin Li</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/w/wai-lam/>Wai Lam</a>
|
<a href=/people/b/bei-shi/>Bei Shi</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1087><div class="card-body p-3 small">Target-oriented sentiment classification aims at classifying sentiment polarities over individual opinion targets in a sentence. RNN with <a href=https://en.wikipedia.org/wiki/Attention>attention</a> seems a good fit for the characteristics of this <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>, and indeed it achieves the state-of-the-art performance. After re-examining the drawbacks of attention mechanism and the obstacles that block CNN to perform well in this classification task, we propose a new model that achieves new state-of-the-art results on a few benchmarks. Instead of <a href=https://en.wikipedia.org/wiki/Attention>attention</a>, our model employs a CNN layer to extract salient features from the transformed word representations originated from a bi-directional RNN layer. Between the two layers, we propose a component which first generates target-specific representations of words in the sentence, and then incorporates a mechanism for preserving the original contextual information from the RNN layer.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1232.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1232 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1232 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1232.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1232/>Learning Domain-Sensitive and Sentiment-Aware Word Embeddings</a></strong><br><a href=/people/b/bei-shi/>Bei Shi</a>
|
<a href=/people/z/zihao-fu/>Zihao Fu</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/w/wai-lam/>Wai Lam</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1232><div class="card-body p-3 small">Word embeddings have been widely used in sentiment classification because of their efficacy for semantic representations of words. Given reviews from different domains, some existing methods for <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> exploit <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment information</a>, but they can not produce domain-sensitive embeddings. On the other hand, some other existing methods can generate domain-sensitive word embeddings, but they can not distinguish words with similar contexts but opposite sentiment polarity. We propose a new method for learning domain-sensitive and sentiment-aware embeddings that simultaneously capture the information of sentiment semantics and domain sensitivity of individual words. Our method can automatically determine and produce domain-common embeddings and domain-specific embeddings. The differentiation of domain-common and domain-specific words enables the advantage of data augmentation of common semantics from multiple domains and capture the varied semantics of specific words from different domains at the same time. Experimental results show that our model provides an effective way to learn domain-sensitive and sentiment-aware word embeddings which benefit sentiment classification at both sentence level and lexicon term level.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1047.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1047 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1047 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D17-1047.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D17-1047" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D17-1047/>Recurrent Attention Network on Memory for Aspect Sentiment Analysis</a></strong><br><a href=/people/p/peng-chen/>Peng Chen</a>
|
<a href=/people/z/zhongqian-sun/>Zhongqian Sun</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/w/wei-yang/>Wei Yang</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1047><div class="card-body p-3 small">We propose a novel framework based on <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> to identify the sentiment of opinion targets in a comment / review. Our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> adopts multiple-attention mechanism to capture <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment features</a> separated by a long distance, so that it is more robust against irrelevant information. The results of multiple attentions are non-linearly combined with a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network</a>, which strengthens the expressive power of our model for handling more complications. The weighted-memory mechanism not only helps us avoid the labor-intensive feature engineering work, but also provides a tailor-made memory for different opinion targets of a sentence. We examine the merit of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on four <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> : two are from SemEval2014, i.e. reviews of restaurants and laptops ; a twitter dataset, for testing its performance on social media data ; and a Chinese news comment dataset, for testing its language sensitivity. The experimental results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> consistently outperforms the state-of-the-art methods on different types of data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1221.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1221 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1221 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1221/>Cascaded Attention based Unsupervised Information Distillation for Compressive Summarization</a></strong><br><a href=/people/p/piji-li/>Piji Li</a>
|
<a href=/people/w/wai-lam/>Wai Lam</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/w/weiwei-guo/>Weiwei Guo</a>
|
<a href=/people/h/hang-li/>Hang Li</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1221><div class="card-body p-3 small">When people recall and digest what they have read for writing summaries, the important content is more likely to attract their attention. Inspired by this observation, we propose a cascaded attention based unsupervised model to estimate the <a href=https://en.wikipedia.org/wiki/Salience_(neuroscience)>salience information</a> from the text for compressive multi-document summarization. The attention weights are learned automatically by an unsupervised data reconstruction framework which can capture the sentence salience. By adding sparsity constraints on the number of output vectors, we can generate condensed information which can be treated as word salience. Fine-grained and coarse-grained sentence compression strategies are incorporated to produce compressive summaries. Experiments on some benchmark data sets show that our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> achieves better results than the state-of-the-art methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1222.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1222 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1222 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1222/>Deep Recurrent Generative Decoder for Abstractive Text Summarization</a></strong><br><a href=/people/p/piji-li/>Piji Li</a>
|
<a href=/people/w/wai-lam/>Wai Lam</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/z/zihao-wang/>Zihao Wang</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1222><div class="card-body p-3 small">We propose a new framework for abstractive text summarization based on a sequence-to-sequence oriented encoder-decoder model equipped with a deep recurrent generative decoder (DRGN). Latent structure information implied in the target summaries is learned based on a recurrent latent random model for improving the summarization quality. Neural variational inference is employed to address the intractable posterior inference for the recurrent latent variables. Abstractive summaries are generated based on both the generative latent variables and the discriminative deterministic states. Extensive experiments on some benchmark datasets in different languages show that DRGN achieves improvements over the state-of-the-art methods.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Lidong+Bing" title="Search for 'Lidong Bing' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/l/luo-si/ class=align-middle>Luo Si</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/w/wai-lam/ class=align-middle>Wai Lam</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/l/liying-cheng/ class=align-middle>Liying Cheng</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/p/piji-li/ class=align-middle>Piji Li</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/r/ruidan-he/ class=align-middle>Ruidan He</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/w/wei-lu/ class=align-middle>Wei Lu</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/b/bei-shi/ class=align-middle>Bei Shi</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/linlin-liu/ class=align-middle>Linlin Liu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/q/qingyu-tan/ class=align-middle>Qingyu Tan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/bosheng-ding/ class=align-middle>Bosheng Ding</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yan-zhang/ class=align-middle>Yan Zhang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/q/qian-yu/ class=align-middle>Qian Yu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/zihao-fu/ class=align-middle>Zihao Fu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jiachen-du/ class=align-middle>Jiachen Du</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/ruifeng-xu/ class=align-middle>Ruifeng Xu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/shuming-shi/ class=align-middle>Shuming Shi</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/zihao-wang/ class=align-middle>Zihao Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mingyue-shang/ class=align-middle>Mingyue Shang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/dongyan-zhao/ class=align-middle>Dongyan Zhao</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/rui-yan/ class=align-middle>Rui Yan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/x/xin-li/ class=align-middle>Xin Li</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hai-ye/ class=align-middle>Hai Ye</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiawei-low/ class=align-middle>Jiawei Low</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shafiq-joty/ class=align-middle>Shafiq Joty</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chunyan-miao/ class=align-middle>Chunyan Miao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tianyu-wu/ class=align-middle>Tianyu Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dekun-wu/ class=align-middle>Dekun Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhanming-jie/ class=align-middle>Zhanming Jie</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lu-xu/ class=align-middle>Lu Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hao-li/ class=align-middle>Hao Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhiyuan-liu/ class=align-middle>Zhiyuan Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/di-chen/ class=align-middle>Di Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thanapon-noraset/ class=align-middle>Thanapon Noraset</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/doug-downey/ class=align-middle>Doug Downey</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yi-liao/ class=align-middle>Yi Liao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tong-zhang/ class=align-middle>Tong Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kaisong-song/ class=align-middle>Kaisong Song</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wei-gao/ class=align-middle>Wei Gao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jun-lin/ class=align-middle>Jun Lin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lujun-zhao/ class=align-middle>Lujun Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiancheng-wang/ class=align-middle>Jiancheng Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/changlong-sun/ class=align-middle>Changlong Sun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaozhong-liu/ class=align-middle>Xiaozhong Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qiong-zhang/ class=align-middle>Qiong Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kwunping-lai/ class=align-middle>Kwunping Lai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ran-le/ class=align-middle>Ran Le</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wenpeng-hu/ class=align-middle>Wenpeng Hu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhenjun-you/ class=align-middle>Zhenjun You</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zheng-li/ class=align-middle>Zheng Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/ying-wei/ class=align-middle>Ying Wei</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yu-zhang/ class=align-middle>Yu Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qiang-yang/ class=align-middle>Qiang Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhenxin-fu/ class=align-middle>Zhenxin Fu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chuang-fan/ class=align-middle>Chuang Fan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hongyu-yan/ class=align-middle>Hongyu Yan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lin-gui/ class=align-middle>Lin Gui</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/min-yang/ class=align-middle>Min Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ruibin-mao/ class=align-middle>Ruibin Mao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yew-ken-chia/ class=align-middle>Yew Ken Chia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/soujanya-poria/ class=align-middle>Soujanya Poria</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hwee-tou-ng/ class=align-middle>Hwee Tou Ng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/peng-chen/ class=align-middle>Peng Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhongqian-sun/ class=align-middle>Zhongqian Sun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wei-yang/ class=align-middle>Wei Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/weiwei-guo/ class=align-middle>Weiwei Guo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hang-li/ class=align-middle>Hang Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">16</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">2</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright &nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>