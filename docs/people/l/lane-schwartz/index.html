<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Lane Schwartz - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Lane</span> <span class=font-weight-bold>Schwartz</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cl-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cl-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cl-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.cl-1.7/>Depth-Bounded Statistical PCFG Induction as a Model of Human Grammar Acquisition<span class=acl-fixed-case>PCFG</span> Induction as a Model of Human Grammar Acquisition</a></strong><br><a href=/people/l/lifeng-jin/>Lifeng Jin</a>
|
<a href=/people/l/lane-schwartz/>Lane Schwartz</a>
|
<a href=/people/f/finale-doshi-velez/>Finale Doshi-Velez</a>
|
<a href=/people/t/timothy-miller/>Timothy Miller</a>
|
<a href=/people/w/william-schuler/>William Schuler</a><br><a href=/volumes/2021.cl-1/ class=text-muted>Computational Linguistics, Volume 47, Issue 1 - March 2021</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cl-1--7><div class="card-body p-3 small">Abstract This article describes a simple PCFG induction model with a fixed category domain that predicts a large majority of attested constituent boundaries, and predicts labels consistent with nearly half of attested constituent labels on a standard evaluation data set of child-directed speech. The article then explores the idea that the difference between simple grammars exhibited by child learners and fully <a href=https://en.wikipedia.org/wiki/Recursive_grammar>recursive grammars</a> exhibited by adult learners may be an effect of increasing working memory capacity, where the shallow grammars are constrained images of the <a href=https://en.wikipedia.org/wiki/Recursive_grammar>recursive grammars</a>. An implementation of these memory bounds as limits on <a href=https://en.wikipedia.org/wiki/Center_embedding>center embedding</a> in a depth-specific transform of a <a href=https://en.wikipedia.org/wiki/Recursive_grammar>recursive grammar</a> yields a significant improvement over an equivalent but unbounded baseline, suggesting that this arrangement may indeed confer a learning advantage.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wmt-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wmt-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wmt-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wmt-1.11/>Illinois Japanese English News Translation for WMT 2021<span class=acl-fixed-case>I</span>llinois <span class=acl-fixed-case>J</span>apanese <span class=tex-math>↔</span> <span class=acl-fixed-case>E</span>nglish <span class=acl-fixed-case>N</span>ews <span class=acl-fixed-case>T</span>ranslation for <span class=acl-fixed-case>WMT</span> 2021</a></strong><br><a href=/people/g/giang-le/>Giang Le</a>
|
<a href=/people/s/shinka-mori/>Shinka Mori</a>
|
<a href=/people/l/lane-schwartz/>Lane Schwartz</a><br><a href=/volumes/2021.wmt-1/ class=text-muted>Proceedings of the Sixth Conference on Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wmt-1--11><div class="card-body p-3 small">This system paper describes an end-to-end NMT pipeline for the Japanese English news translation task as submitted to WMT 2021, where we explore the efficacy of techniques such as tokenizing with language-independent and language-dependent tokenizers, normalizing by orthographic conversion, creating a politeness-and-formality-aware model by implementing a tagger, back-translation, model ensembling, and n-best reranking. We use parallel corpora provided by WMT 2021 organizers for training, and development and test data from WMT 2020 for evaluation of different experiment models. The preprocessed corpora are trained with a Transformer neural network model. We found that combining various techniques described herein, such as language-independent BPE tokenization, incorporating politeness and formality tags, model ensembling, n-best reranking, and back-translation produced the best translation models relative to other experiment systems.<tex-math>\\leftrightarrow</tex-math> English news translation task as submitted to WMT 2021, where we explore the efficacy of techniques such as tokenizing with language-independent and language-dependent tokenizers, normalizing by orthographic conversion, creating a politeness-and-formality-aware model by implementing a tagger, back-translation, model ensembling, and n-best reranking. We use parallel corpora provided by WMT 2021 organizers for training, and development and test data from WMT 2020 for evaluation of different experiment models. The preprocessed corpora are trained with a Transformer neural network model. We found that combining various techniques described herein, such as language-independent BPE tokenization, incorporating politeness and formality tags, model ensembling, n-best reranking, and back-translation produced the best translation models relative to other experiment systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.americasnlp-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--americasnlp-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.americasnlp-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.americasnlp-1.14/>Expanding Universal Dependencies for <a href=https://en.wikipedia.org/wiki/Polysynthetic_language>Polysynthetic Languages</a> : A Case of St. Lawrence Island Yupik<span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependencies for Polysynthetic Languages: A Case of <span class=acl-fixed-case>S</span>t. <span class=acl-fixed-case>L</span>awrence <span class=acl-fixed-case>I</span>sland <span class=acl-fixed-case>Y</span>upik</a></strong><br><a href=/people/h/hyunji-hayley-park/>Hyunji Hayley Park</a>
|
<a href=/people/l/lane-schwartz/>Lane Schwartz</a>
|
<a href=/people/f/francis-tyers/>Francis Tyers</a><br><a href=/volumes/2021.americasnlp-1/ class=text-muted>Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--americasnlp-1--14><div class="card-body p-3 small">This paper describes the development of the first Universal Dependencies (UD) treebank for St. Lawrence Island Yupik, an <a href=https://en.wikipedia.org/wiki/Endangered_language>endangered language</a> spoken in the <a href=https://en.wikipedia.org/wiki/Beringia>Bering Strait region</a>. While the UD guidelines provided a general framework for our annotations, language-specific decisions were made necessary by the rich morphology of the <a href=https://en.wikipedia.org/wiki/Polysynthetic_language>polysynthetic language</a>. Most notably, we annotated a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> at the <a href=https://en.wikipedia.org/wiki/Morpheme>morpheme level</a> as well as the <a href=https://en.wikipedia.org/wiki/Word>word level</a>. The morpheme level annotation was conducted using an existing <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphological analyzer</a> and manual disambiguation. By comparing the two resulting annotation schemes, we argue that morpheme-level annotation is essential for polysynthetic languages like St. Lawrence Island Yupik. Word-level annotation results in degenerate trees for some Yupik sentences and often fails to capture syntactic relations that can be manifested at the morpheme level. Dependency parsing experiments provide further support for morpheme-level annotation. Implications for UD annotation of other <a href=https://en.wikipedia.org/wiki/Polysynthetic_language>polysynthetic languages</a> are discussed.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-6000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-6000/>Proceedings of the 3rd Workshop on the Use of Computational Methods in the Study of Endangered Languages Volume 1 (Papers)</a></strong><br><a href=/people/a/antti-arppe/>Antti Arppe</a>
|
<a href=/people/j/jeff-good/>Jeff Good</a>
|
<a href=/people/m/mans-hulden/>Mans Hulden</a>
|
<a href=/people/j/jordan-lachler/>Jordan Lachler</a>
|
<a href=/people/a/alexis-palmer/>Alexis Palmer</a>
|
<a href=/people/l/lane-schwartz/>Lane Schwartz</a>
|
<a href=/people/m/miikka-silfverberg/>Miikka Silfverberg</a><br><a href=/volumes/W19-60/ class=text-muted>Proceedings of the 3rd Workshop on the Use of Computational Methods in the Study of Endangered Languages Volume 1 (Papers)</a></span></p><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1292.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1292 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1292 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1292" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D18-1292/>Depth-bounding is effective : Improvements and evaluation of unsupervised PCFG induction<span class=acl-fixed-case>PCFG</span> induction</a></strong><br><a href=/people/l/lifeng-jin/>Lifeng Jin</a>
|
<a href=/people/f/finale-doshi-velez/>Finale Doshi-Velez</a>
|
<a href=/people/t/timothy-miller/>Timothy Miller</a>
|
<a href=/people/w/william-schuler/>William Schuler</a>
|
<a href=/people/l/lane-schwartz/>Lane Schwartz</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1292><div class="card-body p-3 small">There have been several recent attempts to improve the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of grammar induction systems by bounding the recursive complexity of the <a href=https://en.wikipedia.org/wiki/Mathematical_induction>induction model</a>. Modern depth-bounded grammar inducers have been shown to be more accurate than early unbounded PCFG inducers, but this technique has never been compared against unbounded induction within the same system, in part because most previous depth-bounding models are built around sequence models, the complexity of which grows exponentially with the maximum allowed depth. The present work instead applies depth bounds within a chart-based Bayesian PCFG inducer, where <a href=https://en.wikipedia.org/wiki/Upper_and_lower_bounds>bounding</a> can be switched on and off, and then samples trees with or without <a href=https://en.wikipedia.org/wiki/Upper_and_lower_bounds>bounding</a>. Results show that depth-bounding is indeed significantly effective in limiting the <a href=https://en.wikipedia.org/wiki/Feasible_region>search space</a> of the inducer and thereby increasing accuracy of resulting parsing model, independent of the contribution of modern Bayesian induction techniques. Moreover, parsing results on <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a> and <a href=https://en.wikipedia.org/wiki/German_language>German</a> show that this bounded model is able to produce parse trees more accurately than or competitively with state-of-the-art constituency grammar induction models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1016 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/277673890 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1016" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1016/>Unsupervised Grammar Induction with Depth-bounded PCFG<span class=acl-fixed-case>PCFG</span></a></strong><br><a href=/people/l/lifeng-jin/>Lifeng Jin</a>
|
<a href=/people/f/finale-doshi-velez/>Finale Doshi-Velez</a>
|
<a href=/people/t/timothy-miller/>Timothy Miller</a>
|
<a href=/people/w/william-schuler/>William Schuler</a>
|
<a href=/people/l/lane-schwartz/>Lane Schwartz</a><br><a href=/volumes/Q18-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 6</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1016><div class="card-body p-3 small">There has been recent interest in applying cognitively- or empirically-motivated bounds on recursion depth to limit the search space of grammar induction models (Ponvert et al., 2011 ; Noji and Johnson, 2016 ; Shain et al., 2016). This work extends this depth-bounding approach to probabilistic context-free grammar induction (DB-PCFG), which has a smaller parameter space than hierarchical sequence models, and therefore more fully exploits the space reductions of depth-bounding. Results for this model on <a href=https://en.wikipedia.org/wiki/Grammar>grammar acquisition</a> from transcribed child-directed speech and newswire text exceed or are competitive with those of other models when evaluated on parse accuracy. Moreover, <a href=https://en.wikipedia.org/wiki/Grammar>grammars</a> acquired from this <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> demonstrate a consistent use of category labels, something which has not been demonstrated by other acquisition models.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-0100.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-0100/>Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages</a></strong><br><a href=/people/a/antti-arppe/>Antti Arppe</a>
|
<a href=/people/j/jeff-good/>Jeff Good</a>
|
<a href=/people/m/mans-hulden/>Mans Hulden</a>
|
<a href=/people/j/jordan-lachler/>Jordan Lachler</a>
|
<a href=/people/a/alexis-palmer/>Alexis Palmer</a>
|
<a href=/people/l/lane-schwartz/>Lane Schwartz</a><br><a href=/volumes/W17-01/ class=text-muted>Proceedings of the 2nd Workshop on the Use of Computational Methods in the Study of Endangered Languages</a></span></p></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Lane+Schwartz" title="Search for 'Lane Schwartz' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/l/lifeng-jin/ class=align-middle>Lifeng Jin</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/f/finale-doshi-velez/ class=align-middle>Finale Doshi-Velez</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/t/timothy-miller/ class=align-middle>Timothy Miller</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/w/william-schuler/ class=align-middle>William Schuler</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/antti-arppe/ class=align-middle>Antti Arppe</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/j/jeff-good/ class=align-middle>Jeff Good</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mans-hulden/ class=align-middle>Mans Hulden</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jordan-lachler/ class=align-middle>Jordan Lachler</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/alexis-palmer/ class=align-middle>Alexis Palmer</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/g/giang-le/ class=align-middle>Giang Le</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shinka-mori/ class=align-middle>Shinka Mori</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hyunji-hayley-park/ class=align-middle>Hyunji Hayley Park</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/francis-tyers/ class=align-middle>Francis Tyers</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/miikka-silfverberg/ class=align-middle>Miikka Silfverberg</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/cl/ class=align-middle>CL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/tacl/ class=align-middle>TACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wmt/ class=align-middle>WMT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/americasnlp/ class=align-middle>AmericasNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>