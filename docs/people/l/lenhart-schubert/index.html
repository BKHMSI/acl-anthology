<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Lenhart Schubert - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Lenhart</span> <span class=font-weight-bold>Schubert</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naloma-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naloma-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naloma-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naloma-1.5/>Monotonic Inference for Underspecified Episodic Logic</a></strong><br><a href=/people/g/gene-kim/>Gene Kim</a>
|
<a href=/people/m/mandar-juvekar/>Mandar Juvekar</a>
|
<a href=/people/l/lenhart-schubert/>Lenhart Schubert</a><br><a href=/volumes/2021.naloma-1/ class=text-muted>Proceedings of the 1st and 2nd Workshops on Natural Logic Meets Machine Learning (NALOMA)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naloma-1--5><div class="card-body p-3 small">We present a method of making natural logic inferences from Unscoped Logical Form of Episodic Logic. We establish a correspondence between inference rules of scope resolved Episodic Logic and the natural logic treatment by Snchez Valencia (1991a), and hence demonstrate the ability to handle foundational natural logic inferences from prior literature as well as more general nested monotonicity inferences.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.reinact-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--reinact-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.reinact-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.reinact-1.8/>Generating Justifications in a Spatial Question-Answering Dialogue System for a Blocks World</a></strong><br><a href=/people/g/georgiy-platonov/>Georgiy Platonov</a>
|
<a href=/people/b/benjamin-kane/>Benjamin Kane</a>
|
<a href=/people/l/lenhart-schubert/>Lenhart Schubert</a><br><a href=/volumes/2021.reinact-1/ class=text-muted>Proceedings of the Reasoning and Interaction Conference (ReInAct 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--reinact-1--8><div class="card-body p-3 small">As <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI</a> reaches wider adoption, designing <a href=https://en.wikipedia.org/wiki/System>systems</a> that are explainable and interpretable becomes a critical necessity. In particular, when it comes to <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a>, their reasoning must be transparent and must comply with <a href=https://en.wikipedia.org/wiki/Intuition>human intuitions</a> in order for them to be integrated seamlessly into day-to-day collaborative human-machine activities. Here, we describe our ongoing work on a (general purpose) dialogue system equipped with a spatial specialist with explanatory capabilities. We applied this <a href=https://en.wikipedia.org/wiki/System>system</a> to a particular task of characterizing spatial configurations of blocks in a simple physical Blocks World (BW) domain using natural locative expressions, as well as generating justifications for the proposed spatial descriptions by indicating the factors that the <a href=https://en.wikipedia.org/wiki/System>system</a> used to arrive at a particular conclusion.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.splurobonlp-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--splurobonlp-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.splurobonlp-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.splurobonlp-1.4/>Modeling Semantics and Pragmatics of Spatial Prepositions via Hierarchical Common-Sense Primitives</a></strong><br><a href=/people/g/georgiy-platonov/>Georgiy Platonov</a>
|
<a href=/people/y/yifei-yang/>Yifei Yang</a>
|
<a href=/people/h/haoyu-wu/>Haoyu Wu</a>
|
<a href=/people/j/jonathan-waxman/>Jonathan Waxman</a>
|
<a href=/people/m/marcus-hill/>Marcus Hill</a>
|
<a href=/people/l/lenhart-schubert/>Lenhart Schubert</a><br><a href=/volumes/2021.splurobonlp-1/ class=text-muted>Proceedings of Second International Combined Workshop on Spatial Language Understanding and Grounded Communication for Robotics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--splurobonlp-1--4><div class="card-body p-3 small">Understanding spatial expressions and using them appropriately is necessary for seamless and natural human-machine interaction. However, capturing the <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> and appropriate usage of spatial prepositions is notoriously difficult, because of their vagueness and <a href=https://en.wikipedia.org/wiki/Polysemy>polysemy</a>. Although modern data-driven approaches are good at capturing statistical regularities in the usage, they usually require substantial sample sizes, often do not generalize well to unseen instances and, most importantly, their structure is essentially opaque to analysis, which makes diagnosing problems and understanding their reasoning process difficult. In this work, we discuss our attempt at modeling spatial senses of prepositions in <a href=https://en.wikipedia.org/wiki/English_language>English</a> using a combination of rule-based and statistical learning approaches. Each preposition model is implemented as a <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>tree</a> where each node computes certain intuitive relations associated with the preposition, with the root computing the final value of the <a href=https://en.wikipedia.org/wiki/Preposition_and_postposition>prepositional relation</a> itself. The <a href=https://en.wikipedia.org/wiki/3D_modeling>models</a> operate on a set of artificial 3D room world environments, designed in <a href=https://en.wikipedia.org/wiki/Blender_(software)>Blender</a>, taking the scene itself as an input. We also discuss our annotation framework used to collect <a href=https://en.wikipedia.org/wiki/Judgement>human judgments</a> employed in the model training. Both our <a href=https://en.wikipedia.org/wiki/Factor_analysis>factored models</a> and black-box baseline models perform quite well, but the <a href=https://en.wikipedia.org/wiki/Factor_analysis>factored models</a> will enable reasoned explanations of spatial relation judgements.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-0402.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-0402 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-0402 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-0402/>A Type-coherent, Expressive Representation as an Initial Step to <a href=https://en.wikipedia.org/wiki/Language_understanding>Language Understanding</a></a></strong><br><a href=/people/g/gene-louis-kim/>Gene Louis Kim</a>
|
<a href=/people/l/lenhart-schubert/>Lenhart Schubert</a><br><a href=/volumes/W19-04/ class=text-muted>Proceedings of the 13th International Conference on Computational Semantics - Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-0402><div class="card-body p-3 small">A growing interest in tasks involving <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>language understanding</a> by the NLP community has led to the need for effective <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> and <a href=https://en.wikipedia.org/wiki/Inference>inference</a>. Modern NLP systems use semantic representations that do not quite fulfill the nuanced needs for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>language understanding</a> : adequately modeling <a href=https://en.wikipedia.org/wiki/Semantics>language semantics</a>, enabling general inferences, and being accurately recoverable. This document describes underspecified logical forms (ULF) for Episodic Logic (EL), which is an initial form for a semantic representation that balances these needs. ULFs fully resolve the semantic type structure while leaving issues such as quantifier scope, <a href=https://en.wikipedia.org/wiki/Word_sense>word sense</a>, and <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphora</a> unresolved ; they provide a starting point for further resolution into EL, and enable certain structural inferences without further resolution. This document also presents preliminary results of creating a hand-annotated corpus of ULFs for the purpose of training a precise ULF parser, showing a three-person pairwise interannotator agreement of 0.88 on confident annotations. We hypothesize that a divide-and-conquer approach to <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> starting with derivation of ULFs will lead to <a href=https://en.wikipedia.org/wiki/Semantic_analysis_(linguistics)>semantic analyses</a> that do justice to subtle aspects of <a href=https://en.wikipedia.org/wiki/Meaning_(linguistics)>linguistic meaning</a>, and will enable construction of more accurate semantic parsers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-1102.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-1102 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-1102 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-1102/>Towards Natural Language Story Understanding with Rich Logical Schemas</a></strong><br><a href=/people/l/lane-lawley/>Lane Lawley</a>
|
<a href=/people/g/gene-louis-kim/>Gene Louis Kim</a>
|
<a href=/people/l/lenhart-schubert/>Lenhart Schubert</a><br><a href=/volumes/W19-11/ class=text-muted>Proceedings of the Sixth Workshop on Natural Language and Computer Science</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-1102><div class="card-body p-3 small">Generating commonsense&#8217;&#8217; knowledge for intelligent understanding and reasoning is a difficult, long-standing problem, whose scale challenges the capacity of any approach driven primarily by human input. Furthermore, approaches based on mining statistically repetitive patterns fail to produce the rich representations humans acquire, and fall far short of human efficiency in inducing knowledge from text. The idea of our approach to this problem is to provide a learning system with a <a href=https://en.wikipedia.org/wiki/Head_start_(positioning)>head start</a> consisting of a semantic parser, some basic ontological knowledge, and most importantly, a small set of very general schemas about the kinds of patterns of events (often purposive, causal, or socially conventional) that even a one- or two-year-old could reasonably be presumed to possess. We match these initial <a href=https://en.wikipedia.org/wiki/Schema_(psychology)>schemas</a> to simple children&#8217;s stories, obtaining concrete instances, and combining and abstracting these into new candidate <a href=https://en.wikipedia.org/wiki/Schema_(psychology)>schemas</a>. Both the initial and generated schemas are specified using a rich, expressive <a href=https://en.wikipedia.org/wiki/Logical_form>logical form</a>. While modern approaches to schema reasoning often only use slot-and-filler structures, this <a href=https://en.wikipedia.org/wiki/Logical_form>logical form</a> allows us to specify complex relations and constraints over the slots. Though formal, the <a href=https://en.wikipedia.org/wiki/Representation_(systemics)>representations</a> are language-like, and as such readily relatable to NL text. The <a href=https://en.wikipedia.org/wiki/Agency_(philosophy)>agents</a>, <a href=https://en.wikipedia.org/wiki/Object_(philosophy)>objects</a>, and other roles in the schemas are represented by typed variables, and the <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>event variables</a> can be related through partial temporal ordering and causal relations. To match natural language stories with existing <a href=https://en.wikipedia.org/wiki/Schema_(psychology)>schemas</a>, we first parse the stories into an underspecified variant of the <a href=https://en.wikipedia.org/wiki/Logical_form>logical form</a> used by the <a href=https://en.wikipedia.org/wiki/Schema_(psychology)>schemas</a>, which is suitable for most concrete stories.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3306.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3306 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3306 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3306/>Generating Discourse Inferences from Unscoped Episodic Logical Formulas</a></strong><br><a href=/people/g/gene-kim/>Gene Kim</a>
|
<a href=/people/b/benjamin-kane/>Benjamin Kane</a>
|
<a href=/people/v/viet-duong/>Viet Duong</a>
|
<a href=/people/m/muskaan-mendiratta/>Muskaan Mendiratta</a>
|
<a href=/people/g/graeme-mcguire/>Graeme McGuire</a>
|
<a href=/people/s/sophie-sackstein/>Sophie Sackstein</a>
|
<a href=/people/g/georgiy-platonov/>Georgiy Platonov</a>
|
<a href=/people/l/lenhart-schubert/>Lenhart Schubert</a><br><a href=/volumes/W19-33/ class=text-muted>Proceedings of the First International Workshop on Designing Meaning Representations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3306><div class="card-body p-3 small">Abstract Unscoped episodic logical form (ULF) is a semantic representation capturing the predicate-argument structure of English within the episodic logic formalism in relation to the syntactic structure, while leaving scope, <a href=https://en.wikipedia.org/wiki/Word_sense>word sense</a>, and <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphora</a> unresolved. We describe how ULF can be used to generate natural language inferences that are grounded in the semantic and syntactic structure through a small set of rules defined over interpretable predicates and transformations on ULFs. The semantic restrictions placed by ULF semantic types enables us to ensure that the inferred structures are semantically coherent while the nearness to <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> enables accurate mapping to <a href=https://en.wikipedia.org/wiki/English_language>English</a>. We demonstrate these <a href=https://en.wikipedia.org/wiki/Statistical_inference>inferences</a> on four classes of conversationally-oriented inferences in a <a href=https://en.wikipedia.org/wiki/Multivariate_analysis_of_variance>mixed genre dataset</a> with 68.5 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> from human judgments.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1802.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1802 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1802 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1802/>Intension, <a href=https://en.wikipedia.org/wiki/Attitude_(psychology)>Attitude</a>, and <a href=https://en.wikipedia.org/wiki/Tense&#8211;aspect&#8211;mood>Tense Annotation</a> in a High-Fidelity Semantic Representation</a></strong><br><a href=/people/g/gene-kim/>Gene Kim</a>
|
<a href=/people/l/lenhart-schubert/>Lenhart Schubert</a><br><a href=/volumes/W17-18/ class=text-muted>Proceedings of the Workshop Computational Semantics Beyond Events and Roles</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1802><div class="card-body p-3 small">This paper describes current efforts in developing an annotation schema and guidelines for sentences in Episodic Logic (EL). We focus on important distinctions for representing <a href=https://en.wikipedia.org/wiki/Modal_logic>modality</a>, <a href=https://en.wikipedia.org/wiki/Attitude_(psychology)>attitudes</a>, and <a href=https://en.wikipedia.org/wiki/Grammatical_tense>tense</a> and present an annotation schema that makes these distinctions. EL has proved competitive with other logical formulations in speed and inference-enablement, while expressing a wider array of natural language phenomena including intensional modification of predicates and sentences, propositional attitudes, and <a href=https://en.wikipedia.org/wiki/Grammatical_tense>tense</a> and <a href=https://en.wikipedia.org/wiki/Grammatical_aspect>aspect</a>.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Lenhart+Schubert" title="Search for 'Lenhart Schubert' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/g/gene-kim/ class=align-middle>Gene Kim</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/g/georgiy-platonov/ class=align-middle>Georgiy Platonov</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/b/benjamin-kane/ class=align-middle>Benjamin Kane</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/g/gene-louis-kim/ class=align-middle>Gene Louis Kim</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mandar-juvekar/ class=align-middle>Mandar Juvekar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/y/yifei-yang/ class=align-middle>Yifei Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haoyu-wu/ class=align-middle>Haoyu Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jonathan-waxman/ class=align-middle>Jonathan Waxman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marcus-hill/ class=align-middle>Marcus Hill</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lane-lawley/ class=align-middle>Lane Lawley</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/viet-duong/ class=align-middle>Viet Duong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/muskaan-mendiratta/ class=align-middle>Muskaan Mendiratta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/graeme-mcguire/ class=align-middle>Graeme McGuire</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sophie-sackstein/ class=align-middle>Sophie Sackstein</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/naloma/ class=align-middle>NALOMA</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/reinact/ class=align-middle>ReInAct</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/splurobonlp/ class=align-middle>splurobonlp</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>