<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Laurent Besacier - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Laurent</span> <span class=font-weight-bold>Besacier</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.gebnlp-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--gebnlp-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.gebnlp-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.gebnlp-1.10/>Investigating the Impact of <a href=https://en.wikipedia.org/wiki/Gender_representation>Gender Representation</a> in ASR Training Data : a Case Study on Librispeech<span class=acl-fixed-case>ASR</span> Training Data: a Case Study on Librispeech</a></strong><br><a href=/people/m/mahault-garnerin/>Mahault Garnerin</a>
|
<a href=/people/s/solange-rossato/>Solange Rossato</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a><br><a href=/volumes/2021.gebnlp-1/ class=text-muted>Proceedings of the 3rd Workshop on Gender Bias in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--gebnlp-1--10><div class="card-body p-3 small">In this paper we question the impact of <a href=https://en.wikipedia.org/wiki/Gender_representation>gender representation</a> in training data on the performance of an end-to-end ASR system. We create an experiment based on the Librispeech corpus and build 3 different training corpora varying only the proportion of data produced by each gender category. We observe that if our system is overall robust to the gender balance or imbalance in training data, it is nonetheless dependant of the adequacy between the individuals present in the training and testing sets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.42.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--42 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.42 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.42/>Controlling Prosody in End-to-End TTS : A Case Study on Contrastive Focus Generation<span class=acl-fixed-case>TTS</span>: A Case Study on Contrastive Focus Generation</a></strong><br><a href=/people/s/siddique-latif/>Siddique Latif</a>
|
<a href=/people/i/inyoung-kim/>Inyoung Kim</a>
|
<a href=/people/i/ioan-calapodescu/>Ioan Calapodescu</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a><br><a href=/volumes/2021.conll-1/ class=text-muted>Proceedings of the 25th Conference on Computational Natural Language Learning</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--42><div class="card-body p-3 small">While End-2-End Text-to-Speech (TTS) has made significant progresses over the past few years, these systems still lack intuitive user controls over <a href=https://en.wikipedia.org/wiki/Prosody_(linguistics)>prosody</a>. For instance, generating <a href=https://en.wikipedia.org/wiki/Speech>speech</a> with fine-grained prosody control (prosodic prominence, contextually appropriate emotions) is still an open challenge. In this paper, we investigate whether we can control <a href=https://en.wikipedia.org/wiki/Prosody_(linguistics)>prosody</a> directly from the input text, in order to code information related to contrastive focus which emphasizes a specific word that is contrary to the presuppositions of the interlocutor. We build and share a specific <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for this purpose and show that it allows to train a TTS system were this fine-grained prosodic feature can be correctly conveyed using control tokens. Our evaluation compares synthetic and natural utterances and shows that prosodic patterns of contrastive focus (variations of Fo, Intensity and Duration) can be learnt accurately. Such a milestone is important to allow, for example, <a href=https://en.wikipedia.org/wiki/Smart_speaker>smart speakers</a> to be programmatically controlled in terms of output prosody.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.0/>Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)</a></strong><br><a href=/people/d/dorothee-beermann/>Dorothee Beermann</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a>
|
<a href=/people/s/sakriani-sakti/>Sakriani Sakti</a>
|
<a href=/people/c/claudia-soria/>Claudia Soria</a><br><a href=/volumes/2020.sltu-1/ class=text-muted>Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.314.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--314 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.314 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.coling-main.314" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.314/>Dual-decoder Transformer for Joint Automatic Speech Recognition and Multilingual Speech Translation</a></strong><br><a href=/people/h/hang-le/>Hang Le</a>
|
<a href=/people/j/juan-pino/>Juan Pino</a>
|
<a href=/people/c/changhan-wang/>Changhan Wang</a>
|
<a href=/people/j/jiatao-gu/>Jiatao Gu</a>
|
<a href=/people/d/didier-schwab/>Didier Schwab</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--314><div class="card-body p-3 small">We introduce dual-decoder Transformer, a new model architecture that jointly performs automatic speech recognition (ASR) and multilingual speech translation (ST). Our models are based on the original Transformer architecture (Vaswani et al., 2017) but consist of two decoders, each responsible for one task (ASR or ST). Our major contribution lies in how these <a href=https://en.wikipedia.org/wiki/Code>decoders</a> interact with each other : one decoder can attend to different information sources from the other via a dual-attention mechanism. We propose two variants of these architectures corresponding to two different levels of dependencies between the <a href=https://en.wikipedia.org/wiki/Code>decoders</a>, called the parallel and cross dual-decoder Transformers, respectively. Extensive experiments on the MuST-C dataset show that our models outperform the previously-reported highest <a href=https://en.wikipedia.org/wiki/Translation>translation</a> performance in the multilingual settings, and outperform as well bilingual one-to-one results. Furthermore, our parallel models demonstrate no trade-off between ASR and ST compared to the vanilla multi-task architecture. Our code and pre-trained models are available at https://github.com/formiel/speech-translation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.302.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--302 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.302 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.lrec-1.302" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.302/>FlauBERT : Unsupervised Language Model Pre-training for <a href=https://en.wikipedia.org/wiki/French_language>French</a><span class=acl-fixed-case>F</span>lau<span class=acl-fixed-case>BERT</span>: Unsupervised Language Model Pre-training for <span class=acl-fixed-case>F</span>rench</a></strong><br><a href=/people/h/hang-le/>Hang Le</a>
|
<a href=/people/l/loic-vial/>Loïc Vial</a>
|
<a href=/people/j/jibril-frej/>Jibril Frej</a>
|
<a href=/people/v/vincent-segonne/>Vincent Segonne</a>
|
<a href=/people/m/maximin-coavoux/>Maximin Coavoux</a>
|
<a href=/people/b/benjamin-lecouteux/>Benjamin Lecouteux</a>
|
<a href=/people/a/alexandre-allauzen/>Alexandre Allauzen</a>
|
<a href=/people/b/benoit-crabbe/>Benoit Crabbé</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a>
|
<a href=/people/d/didier-schwab/>Didier Schwab</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--302><div class="card-body p-3 small">Language models have become a key step to achieve state-of-the art results in many different Natural Language Processing (NLP) tasks. Leveraging the huge amount of unlabeled texts nowadays available, they provide an efficient way to pre-train continuous word representations that can be fine-tuned for a downstream task, along with their <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextualization</a> at the sentence level. This has been widely demonstrated for <a href=https://en.wikipedia.org/wiki/English_language>English</a> using contextualized representations (Dai and Le, 2015 ; Peters et al., 2018 ; Howard and Ruder, 2018 ; Radford et al., 2018 ; Devlin et al., 2019 ; Yang et al., 2019b). In this paper, we introduce and share FlauBERT, a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> learned on a very large and heterogeneous French corpus. Models of different sizes are trained using the new CNRS (French National Centre for Scientific Research) Jean Zay supercomputer. We apply our French language models to diverse NLP tasks (text classification, paraphrasing, natural language inference, parsing, word sense disambiguation) and show that most of the time they outperform other pre-training approaches. Different versions of FlauBERT as well as a unified evaluation protocol for the downstream tasks, called FLUE (French Language Understanding Evaluation), are shared to the research community for further reproducible experiments in French NLP.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.813.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--813 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.813 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.813/>Gender Representation in Open Source Speech Resources</a></strong><br><a href=/people/m/mahault-garnerin/>Mahault Garnerin</a>
|
<a href=/people/s/solange-rossato/>Solange Rossato</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--813><div class="card-body p-3 small">With the rise of <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>artificial intelligence (AI)</a> and the growing use of <a href=https://en.wikipedia.org/wiki/Deep_learning>deep-learning architectures</a>, the question of ethics, <a href=https://en.wikipedia.org/wiki/Transparency_(behavior)>transparency</a> and fairness of <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI systems</a> has become a central concern within the research community. We address transparency and fairness in spoken language systems by proposing a study about gender representation in speech resources available through the Open Speech and Language Resource platform. We show that finding gender information in open source corpora is not straightforward and that gender balance depends on other corpus characteristics (elicited / non elicited speech, low / high resource language, speech task targeted). The paper ends with recommendations about metadata and gender information for researchers in order to assure better transparency of the <a href=https://en.wikipedia.org/wiki/Speech_processing>speech systems</a> built using such <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5631.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5631 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5631 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5631/>Naver Labs Europe’s Systems for the Document-Level Generation and Translation Task at WNGT 2019<span class=acl-fixed-case>E</span>urope’s Systems for the Document-Level Generation and Translation Task at <span class=acl-fixed-case>WNGT</span> 2019</a></strong><br><a href=/people/f/fahimeh-saleh/>Fahimeh Saleh</a>
|
<a href=/people/a/alexandre-berard/>Alexandre Berard</a>
|
<a href=/people/i/ioan-calapodescu/>Ioan Calapodescu</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a><br><a href=/volumes/D19-56/ class=text-muted>Proceedings of the 3rd Workshop on Neural Generation and Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5631><div class="card-body p-3 small">Recently, neural models led to significant improvements in both <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation (MT)</a> and <a href=https://en.wikipedia.org/wiki/Natural-language_generation>natural language generation tasks (NLG)</a>. However, generation of long descriptive summaries conditioned on <a href=https://en.wikipedia.org/wiki/Structured_data>structured data</a> remains an open challenge. Likewise, <a href=https://en.wikipedia.org/wiki/Metadata>MT</a> that goes beyond <a href=https://en.wikipedia.org/wiki/Metadata>sentence-level context</a> is still an open issue (e.g., document-level MT or <a href=https://en.wikipedia.org/wiki/Metadata>MT</a> with metadata). To address these challenges, we propose to leverage data from both tasks and do <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> between MT, NLG, and MT with source-side metadata (MT+NLG). First, we train document-based MT systems with large amounts of <a href=https://en.wikipedia.org/wiki/Parallel_computing>parallel data</a>. Then, we adapt these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> to pure NLG and MT+NLG tasks by <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> with smaller amounts of domain-specific data. This end-to-end NLG approach, without data selection and planning, outperforms the previous state of the art on the Rotowire NLG task. We participated to the Document Generation and Translation task at WNGT 2019, and ranked first in all tracks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.11/>The LIG system for the English-Czech Text Translation Task of IWSLT 2019<span class=acl-fixed-case>LIG</span> system for the <span class=acl-fixed-case>E</span>nglish-<span class=acl-fixed-case>C</span>zech Text Translation Task of <span class=acl-fixed-case>IWSLT</span> 2019</a></strong><br><a href=/people/l/loic-vial/>Loïc Vial</a>
|
<a href=/people/b/benjamin-lecouteux/>Benjamin Lecouteux</a>
|
<a href=/people/d/didier-schwab/>Didier Schwab</a>
|
<a href=/people/h/hang-le/>Hang Le</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a><br><a href=/volumes/2019.iwslt-1/ class=text-muted>Proceedings of the 16th International Conference on Spoken Language Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--11><div class="card-body p-3 small">In this paper, we present our submission for the English to Czech Text Translation Task of IWSLT 2019. Our system aims to study how pre-trained language models, used as input embeddings, can improve a specialized machine translation system trained on few data. Therefore, we implemented a Transformer-based encoder-decoder neural system which is able to use the output of a pre-trained language model as input embeddings, and we compared its performance under three configurations : 1) without any pre-trained language model (constrained), 2) using a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> trained on the monolingual parts of the allowed English-Czech data (constrained), and 3) using a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> trained on a large quantity of external monolingual data (unconstrained). We used BERT as external pre-trained language model (configuration 3), and BERT architecture for training our own <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> (configuration 2). Regarding the training data, we trained our MT system on a small quantity of parallel text : one set only consists of the provided MuST-C corpus, and the other set consists of the MuST-C corpus and the News Commentary corpus from WMT. We observed that using the external pre-trained BERT improves the scores of our <a href=https://en.wikipedia.org/wiki/System>system</a> by +0.8 to +1.5 of BLEU on our development set, and +0.97 to +1.94 of BLEU on the test set. However, using our own <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> trained only on the allowed parallel data seems to improve the <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> performances only when the system is trained on the smallest dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K19-1032.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K19-1032 data-toggle=collapse aria-expanded=false aria-controls=abstract-K19-1032 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/K19-1032.Supplementary_Material.pdf data-toggle=tooltip data-placement=top title="Supplementary material"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/K19-1032/>Word Recognition, Competition, and Activation in a Model of Visually Grounded Speech</a></strong><br><a href=/people/w/william-n-havard/>William N. Havard</a>
|
<a href=/people/j/jean-pierre-chevrot/>Jean-Pierre Chevrot</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a><br><a href=/volumes/K19-1/ class=text-muted>Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K19-1032><div class="card-body p-3 small">In this paper, we study how word-like units are represented and activated in a recurrent neural model of visually grounded speech. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> used in our experiments is trained to project an <a href=https://en.wikipedia.org/wiki/Image>image</a> and its spoken description in a common representation space. We show that a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent model</a> trained on spoken sentences implicitly segments its input into word-like units and reliably maps them to their correct visual referents. We introduce a methodology originating from <a href=https://en.wikipedia.org/wiki/Linguistics>linguistics</a> to analyse the representation learned by neural networks the gating paradigm and show that the correct representation of a word is only activated if the <a href=https://en.wikipedia.org/wiki/Neural_network>network</a> has access to first phoneme of the target word, suggesting that the <a href=https://en.wikipedia.org/wiki/Neural_network>network</a> does not rely on a global acoustic pattern. Furthermore, we find out that not all speech frames (MFCC vectors in our case) play an equal role in the final encoded representation of a given word, but that some frames have a crucial effect on it. Finally we suggest that word representation could be activated through a process of lexical competition.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5804.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5804 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5804 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5804/>Adaptor Grammars for the Linguist : <a href=https://en.wikipedia.org/wiki/Word_segmentation>Word Segmentation</a> Experiments for Very Low-Resource Languages<span class=acl-fixed-case>A</span>daptor <span class=acl-fixed-case>G</span>rammars for the Linguist: Word Segmentation Experiments for Very Low-Resource Languages</a></strong><br><a href=/people/p/pierre-godard/>Pierre Godard</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a>
|
<a href=/people/f/francois-yvon/>François Yvon</a>
|
<a href=/people/m/martine-adda-decker/>Martine Adda-Decker</a>
|
<a href=/people/g/gilles-adda/>Gilles Adda</a>
|
<a href=/people/h/helene-bonneau-maynard/>Hélène Maynard</a>
|
<a href=/people/a/annie-rialland/>Annie Rialland</a><br><a href=/volumes/W18-58/ class=text-muted>Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5804><div class="card-body p-3 small">Computational Language Documentation attempts to make the most recent research in speech and language technologies available to linguists working on <a href=https://en.wikipedia.org/wiki/Language_preservation>language preservation</a> and documentation. In this paper, we pursue two main goals along these lines. The first is to improve upon a strong baseline for the unsupervised word discovery task on two very low-resource Bantu languages, taking advantage of the expertise of linguists on these particular languages. The second consists in exploring the Adaptor Grammar framework as a decision and prediction tool for linguists studying a new language. We experiment 162 grammar configurations for each language and show that using Adaptor Grammars for <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a> enables us to test hypotheses about a language. Specializing a generic grammar with language specific knowledge leads to great improvements for the word discovery task, ultimately achieving a leap of about 30 % token F-score from the results of a strong baseline.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2502.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2502 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2502 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-2502.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-2502" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-2502/>Deep Investigation of Cross-Language Plagiarism Detection Methods</a></strong><br><a href=/people/j/jeremy-ferrero/>Jérémy Ferrero</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a>
|
<a href=/people/d/didier-schwab/>Didier Schwab</a>
|
<a href=/people/f/frederic-agnes/>Frédéric Agnès</a><br><a href=/volumes/W17-25/ class=text-muted>Proceedings of the 10th Workshop on Building and Using Comparable Corpora</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2502><div class="card-body p-3 small">This paper is a deep investigation of cross-language plagiarism detection methods on a new recently introduced <a href=https://en.wikipedia.org/wiki/Open_data>open dataset</a>, which contains parallel and comparable collections of documents with multiple characteristics (different genres, languages and sizes of texts). We investigate cross-language plagiarism detection methods for 6 language pairs on 2 granularities of text units in order to draw robust conclusions on the best methods while deeply analyzing correlations across document styles and languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4608.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4608 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4608 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4608/>Amharic-English Speech Translation in Tourism Domain<span class=acl-fixed-case>A</span>mharic-<span class=acl-fixed-case>E</span>nglish Speech Translation in Tourism Domain</a></strong><br><a href=/people/m/michael-melese/>Michael Melese</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a>
|
<a href=/people/m/million-meshesha/>Million Meshesha</a><br><a href=/volumes/W17-46/ class=text-muted>Proceedings of the Workshop on Speech-Centric Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4608><div class="card-body p-3 small">This paper describes speech translation from Amharic-to-English, particularly Automatic Speech Recognition (ASR) with post-editing feature and Amharic-English Statistical Machine Translation (SMT). ASR experiment is conducted using morpheme language model (LM) and phoneme acoustic model(AM). Likewise, SMT conducted using word and morpheme as unit. Morpheme based translation shows a 6.29 BLEU score at a 76.4 % of recognition accuracy while word based translation shows a 12.83 BLEU score using 77.4 % word recognition accuracy. Further, after post-edit on Amharic ASR using <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpus based n-gram</a>, the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>word recognition accuracy</a> increased by 1.42 %. Since post-edit approach reduces <a href=https://en.wikipedia.org/wiki/Propagation_of_uncertainty>error propagation</a>, the word based translation accuracy improved by 0.25 (1.95 %) BLEU score. We are now working towards further improving propagated errors through different <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> at each unit of speech translation cascading component.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2012 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/S17-2012.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/S17-2012/>CompiLIG at SemEval-2017 Task 1 : Cross-Language Plagiarism Detection Methods for <a href=https://en.wikipedia.org/wiki/Semantic_similarity>Semantic Textual Similarity</a><span class=acl-fixed-case>C</span>ompi<span class=acl-fixed-case>LIG</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 1: Cross-Language Plagiarism Detection Methods for Semantic Textual Similarity</a></strong><br><a href=/people/j/jeremy-ferrero/>Jérémy Ferrero</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a>
|
<a href=/people/d/didier-schwab/>Didier Schwab</a>
|
<a href=/people/f/frederic-agnes/>Frédéric Agnès</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2012><div class="card-body p-3 small">We present our submitted <a href=https://en.wikipedia.org/wiki/System>systems</a> for Semantic Textual Similarity (STS) Track 4 at SemEval-2017. Given a pair of Spanish-English sentences, each <a href=https://en.wikipedia.org/wiki/System>system</a> must estimate their <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic similarity</a> by a score between 0 and 5. In our submission, we use syntax-based, dictionary-based, context-based, and MT-based methods. We also combine these <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> in unsupervised and supervised way. Our best run ranked 1st on track 4a with a correlation of 83.02 % with human annotations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-2066.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-2066 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-2066 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/E17-2066.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/E17-2066/>Using Word Embedding for Cross-Language Plagiarism Detection</a></strong><br><a href=/people/j/jeremy-ferrero/>Jérémy Ferrero</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a>
|
<a href=/people/d/didier-schwab/>Didier Schwab</a>
|
<a href=/people/f/frederic-agnes/>Frédéric Agnès</a><br><a href=/volumes/E17-2/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-2066><div class="card-body p-3 small">This paper proposes to use distributed representation of words (word embeddings) in cross-language textual similarity detection. The main contributions of this paper are the following : (a) we introduce new cross-language similarity detection methods based on distributed representation of words ; (b) we combine the different methods proposed to verify their complementarity and finally obtain an overall F1 score of 89.15 % for English-French similarity detection at chunk level (88.5 % at sentence level) on a very challenging corpus.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Laurent+Besacier" title="Search for 'Laurent Besacier' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/d/didier-schwab/ class=align-middle>Didier Schwab</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/j/jeremy-ferrero/ class=align-middle>Jérémy Ferrero</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/f/frederic-agnes/ class=align-middle>Frédéric Agnès</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/h/hang-le/ class=align-middle>Hang Le</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/mahault-garnerin/ class=align-middle>Mahault Garnerin</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/s/solange-rossato/ class=align-middle>Solange Rossato</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/i/ioan-calapodescu/ class=align-middle>Ioan Calapodescu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/loic-vial/ class=align-middle>Loïc Vial</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/benjamin-lecouteux/ class=align-middle>Benjamin Lecouteux</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/siddique-latif/ class=align-middle>Siddique Latif</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/inyoung-kim/ class=align-middle>Inyoung Kim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-melese/ class=align-middle>Michael Melese</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/million-meshesha/ class=align-middle>Million Meshesha</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fahimeh-saleh/ class=align-middle>Fahimeh Saleh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexandre-berard/ class=align-middle>Alexandre Berard</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dorothee-beermann/ class=align-middle>Dorothee Beermann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sakriani-sakti/ class=align-middle>Sakriani Sakti</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/claudia-soria/ class=align-middle>Claudia Soria</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pierre-godard/ class=align-middle>Pierre Godard</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/francois-yvon/ class=align-middle>François Yvon</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/martine-adda-decker/ class=align-middle>Martine Adda-Decker</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gilles-adda/ class=align-middle>Gilles Adda</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/helene-bonneau-maynard/ class=align-middle>Hélène Bonneau-Maynard</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/annie-rialland/ class=align-middle>Annie Rialland</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/juan-pino/ class=align-middle>Juan Pino</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/changhan-wang/ class=align-middle>Changhan Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiatao-gu/ class=align-middle>Jiatao Gu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jibril-frej/ class=align-middle>Jibril Frej</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vincent-segonne/ class=align-middle>Vincent Segonne</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maximin-coavoux/ class=align-middle>Maximin Coavoux</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexandre-allauzen/ class=align-middle>Alexandre Allauzen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/benoit-crabbe/ class=align-middle>Benoit Crabbé</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/william-n-havard/ class=align-middle>William N. Havard</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jean-pierre-chevrot/ class=align-middle>Jean-Pierre Chevrot</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/gebnlp/ class=align-middle>GeBNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/sltu/ class=align-middle>SLTU</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/iwslt/ class=align-middle>IWSLT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>