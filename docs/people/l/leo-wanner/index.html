<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Leo Wanner - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Leo</span> <span class=font-weight-bold>Wanner</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.118.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--118 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.118 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.118/>How much pretraining data do <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> need to learn syntax?</a></strong><br><a href=/people/l/laura-perez-mayos/>Laura Pérez-Mayos</a>
|
<a href=/people/m/miguel-ballesteros/>Miguel Ballesteros</a>
|
<a href=/people/l/leo-wanner/>Leo Wanner</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--118><div class="card-body p-3 small">Transformers-based pretrained language models achieve outstanding results in many well-known NLU benchmarks. However, while pretraining methods are very convenient, they are expensive in terms of time and resources. This calls for a study of the impact of pretraining data size on the knowledge of the <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a>. We explore this impact on the syntactic capabilities of RoBERTa, using <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on incremental sizes of raw text data. First, we use syntactic structural probes to determine whether models pretrained on more data encode a higher amount of syntactic information. Second, we perform a targeted syntactic evaluation to analyze the impact of pretraining data size on the syntactic generalization performance of the models. Third, we compare the performance of the different models on three downstream applications : <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a>, dependency parsing and paraphrase identification. We complement our study with an analysis of the cost-benefit trade-off of training such <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Our experiments show that while models pretrained on more data encode more syntactic knowledge and perform better on downstream applications, they do not always offer a better performance across the different syntactic phenomena and come at a higher financial and environmental cost.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.woah-1.19.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--woah-1--19 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.woah-1.19 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.woah-1.19" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.woah-1.19/>Targets and Aspects in <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a> Hate Speech</a></strong><br><a href=/people/a/alexander-shvets/>Alexander Shvets</a>
|
<a href=/people/p/paula-fortuna/>Paula Fortuna</a>
|
<a href=/people/j/juan-soler/>Juan Soler</a>
|
<a href=/people/l/leo-wanner/>Leo Wanner</a><br><a href=/volumes/2021.woah-1/ class=text-muted>Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--woah-1--19><div class="card-body p-3 small">Mainstream research on <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a> focused so far predominantly on the task of classifying mainly social media posts with respect to predefined typologies of rather coarse-grained hate speech categories. This may be sufficient if the goal is to detect and delete abusive language posts. However, removal is not always possible due to the legislation of a country. Also, there is evidence that <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a> can not be successfully combated by merely removing <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech posts</a> ; they should be countered by <a href=https://en.wikipedia.org/wiki/Education>education</a> and counter-narratives. For this purpose, we need to identify (i) who is the target in a given hate speech post, and (ii) what aspects (or characteristics) of the target are attributed to the target in the post. As the first approximation, we propose to adapt a generic state-of-the-art concept extraction model to the hate speech domain. The outcome of the experiments is promising and can serve as inspiration for further work on the task</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.mwe-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--mwe-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.mwe-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.mwe-1.1" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.mwe-1.1/>CollFrEn : Rich Bilingual EnglishFrench Collocation Resource<span class=acl-fixed-case>C</span>oll<span class=acl-fixed-case>F</span>r<span class=acl-fixed-case>E</span>n: Rich Bilingual <span class=acl-fixed-case>E</span>nglish–<span class=acl-fixed-case>F</span>rench Collocation Resource</a></strong><br><a href=/people/b/beatriz-fisas/>Beatriz Fisas</a>
|
<a href=/people/l/luis-espinosa-anke/>Luis Espinosa Anke</a>
|
<a href=/people/j/joan-codina-filba/>Joan Codina-Filbá</a>
|
<a href=/people/l/leo-wanner/>Leo Wanner</a><br><a href=/volumes/2020.mwe-1/ class=text-muted>Proceedings of the Joint Workshop on Multiword Expressions and Electronic Lexicons</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--mwe-1--1><div class="card-body p-3 small">Collocations in the sense of idiosyncratic lexical co-occurrences of two syntactically bound words traditionally pose a challenge to language learners and many Natural Language Processing (NLP) applications alike. Reliable ground truth (i.e., ideally manually compiled) resources are thus of high value. We present a manually compiled bilingual EnglishFrench collocation resource with 7,480 collocations in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and 6,733 in <a href=https://en.wikipedia.org/wiki/French_language>French</a>. Each <a href=https://en.wikipedia.org/wiki/Collocation>collocation</a> is enriched with information that facilitates its downstream exploitation in NLP tasks such as <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, <a href=https://en.wikipedia.org/wiki/Word-sense_disambiguation>word sense disambiguation</a>, <a href=https://en.wikipedia.org/wiki/Natural-language_generation>natural language generation</a>, relation classification, and so forth. Our proposed enrichment covers : the semantic category of the collocation (its lexical function), its vector space representation (for each individual word as well as their joint collocation embedding), a subcategorization pattern of both its elements, as well as their corresponding BabelNet i d, and finally, indices of their occurrences in large scale reference corpora.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.msr-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.msr-1.0/>Proceedings of the Third Workshop on Multilingual Surface Realisation</a></strong><br><a href=/people/a/anja-belz/>Anya Belz</a>
|
<a href=/people/b/bernd-bohnet/>Bernd Bohnet</a>
|
<a href=/people/t/thiago-castro-ferreira/>Thiago Castro Ferreira</a>
|
<a href=/people/y/yvette-graham/>Yvette Graham</a>
|
<a href=/people/s/simon-mille/>Simon Mille</a>
|
<a href=/people/l/leo-wanner/>Leo Wanner</a><br><a href=/volumes/2020.msr-1/ class=text-muted>Proceedings of the Third Workshop on Multilingual Surface Realisation</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.msr-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--msr-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.msr-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.msr-1.1" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.msr-1.1/>The Third Multilingual Surface Realisation Shared Task (SR’20): Overview and Evaluation Results<span class=acl-fixed-case>SR</span>’20): Overview and Evaluation Results</a></strong><br><a href=/people/s/simon-mille/>Simon Mille</a>
|
<a href=/people/a/anja-belz/>Anya Belz</a>
|
<a href=/people/b/bernd-bohnet/>Bernd Bohnet</a>
|
<a href=/people/t/thiago-castro-ferreira/>Thiago Castro Ferreira</a>
|
<a href=/people/y/yvette-graham/>Yvette Graham</a>
|
<a href=/people/l/leo-wanner/>Leo Wanner</a><br><a href=/volumes/2020.msr-1/ class=text-muted>Proceedings of the Third Workshop on Multilingual Surface Realisation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--msr-1--1><div class="card-body p-3 small">This paper presents results from the Third Shared Task on Multilingual Surface Realisation (SR&#8217;20) which was organised as part of the COLING&#8217;20 Workshop on Multilingual Surface Realisation. As in SR&#8217;18 and SR&#8217;19, the shared task comprised two tracks : (1) a Shallow Track where the inputs were full UD structures with word order information removed and tokens lemmatised ; and (2) a Deep Track where additionally, functional words and morphological information were removed. Moreover, each <a href=https://en.wikipedia.org/wiki/Track_(navigation)>track</a> had two subtracks : (a) restricted-resource, where only the data provided or approved as part of a track could be used for training models, and (b) open-resource, where any data could be used. The Shallow Track was offered in 11 languages, whereas the Deep Track in 3 ones. Systems were evaluated using both automatic metrics and direct assessment by human evaluators in terms of <a href=https://en.wikipedia.org/wiki/Readability>Readability</a> and Meaning Similarity to reference outputs. We present the evaluation results, along with descriptions of the SR&#8217;19 tracks, data and evaluation methods, as well as brief summaries of the participating systems. For full descriptions of the participating systems, please see the separate system reports elsewhere in this volume.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6300.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6300/>Proceedings of the 2nd Workshop on Multilingual Surface Realisation (MSR 2019)</a></strong><br><a href=/people/s/simon-mille/>Simon Mille</a>
|
<a href=/people/a/anja-belz/>Anja Belz</a>
|
<a href=/people/b/bernd-bohnet/>Bernd Bohnet</a>
|
<a href=/people/y/yvette-graham/>Yvette Graham</a>
|
<a href=/people/l/leo-wanner/>Leo Wanner</a><br><a href=/volumes/D19-63/ class=text-muted>Proceedings of the 2nd Workshop on Multilingual Surface Realisation (MSR 2019)</a></span></p><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3600.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3600/>Proceedings of the First Workshop on Multilingual Surface Realisation</a></strong><br><a href=/people/s/simon-mille/>Simon Mille</a>
|
<a href=/people/a/anja-belz/>Anja Belz</a>
|
<a href=/people/b/bernd-bohnet/>Bernd Bohnet</a>
|
<a href=/people/e/emily-pitler/>Emily Pitler</a>
|
<a href=/people/l/leo-wanner/>Leo Wanner</a><br><a href=/volumes/W18-36/ class=text-muted>Proceedings of the First Workshop on Multilingual Surface Realisation</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6527.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6527 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6527 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6527/>Underspecified Universal Dependency Structures as Inputs for Multilingual Surface Realisation<span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependency Structures as Inputs for Multilingual Surface Realisation</a></strong><br><a href=/people/s/simon-mille/>Simon Mille</a>
|
<a href=/people/a/anja-belz/>Anja Belz</a>
|
<a href=/people/b/bernd-bohnet/>Bernd Bohnet</a>
|
<a href=/people/l/leo-wanner/>Leo Wanner</a><br><a href=/volumes/W18-65/ class=text-muted>Proceedings of the 11th International Conference on Natural Language Generation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6527><div class="card-body p-3 small">In this paper, we present the <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> used in the Shallow and Deep Tracks of the First Multilingual Surface Realisation Shared Task (SR&#8217;18). For the Shallow Track, data in ten languages has been released : <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a>, <a href=https://en.wikipedia.org/wiki/Czech_language>Czech</a>, <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a>, <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Finnish_language>Finnish</a>, <a href=https://en.wikipedia.org/wiki/French_language>French</a>, <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a>, <a href=https://en.wikipedia.org/wiki/Portuguese_language>Portuguese</a>, <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a> and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. For the Deep Track, data in three languages is made available : <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/French_language>French</a> and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. We describe in detail how the <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> were derived from the Universal Dependencies V2.0, and report on an evaluation of the Deep Track input quality. In addition, we examine the motivation for, and likely usefulness of, deriving NLG inputs from annotations in resources originally developed for Natural Language Understanding (NLU), and assess whether the resulting inputs supply enough information of the right kind for the final stage in the NLG process.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2506.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2506 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2506 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-2506.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W17-2506/>Automatic Extraction of Parallel Speech Corpora from Dubbed Movies</a></strong><br><a href=/people/a/alp-oktem/>Alp Öktem</a>
|
<a href=/people/m/mireia-farrus/>Mireia Farrús</a>
|
<a href=/people/l/leo-wanner/>Leo Wanner</a><br><a href=/volumes/W17-25/ class=text-muted>Proceedings of the 10th Workshop on Building and Using Comparable Corpora</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2506><div class="card-body p-3 small">This paper presents a methodology to extract parallel speech corpora based on any language pair from dubbed movies, together with an application framework in which some corresponding prosodic parameters are extracted. The obtained <a href=https://en.wikipedia.org/wiki/Parallel_text>parallel corpora</a> are especially suitable for speech-to-speech translation applications when a <a href=https://en.wikipedia.org/wiki/Prosody_(linguistics)>prosody transfer</a> between source and target languages is desired.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3539.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3539 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3539 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3539/>A demo of FORGe : the Pompeu Fabra Open Rule-based Generator<span class=acl-fixed-case>FORG</span>e: the <span class=acl-fixed-case>P</span>ompeu <span class=acl-fixed-case>F</span>abra Open Rule-based Generator</a></strong><br><a href=/people/s/simon-mille/>Simon Mille</a>
|
<a href=/people/l/leo-wanner/>Leo Wanner</a><br><a href=/volumes/W17-35/ class=text-muted>Proceedings of the 10th International Conference on Natural Language Generation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3539><div class="card-body p-3 small">This demo paper presents the multilingual deep sentence generator developed by the TALN group at Universitat Pompeu Fabra, implemented as a series of rule-based graph-transducers for the syntacticization of the input graphs, the resolution of morphological agreements, and the linearization of the trees.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2158.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2158 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2158 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2158/>FORGe at SemEval-2017 Task 9 : Deep sentence generation based on a sequence of graph transducers<span class=acl-fixed-case>FORG</span>e at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 9: Deep sentence generation based on a sequence of graph transducers</a></strong><br><a href=/people/s/simon-mille/>Simon Mille</a>
|
<a href=/people/r/roberto-carlini/>Roberto Carlini</a>
|
<a href=/people/a/alicia-burga/>Alicia Burga</a>
|
<a href=/people/l/leo-wanner/>Leo Wanner</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2158><div class="card-body p-3 small">We present the contribution of Universitat Pompeu Fabra&#8217;s NLP group to the SemEval Task 9.2 (AMR-to-English Generation). The proposed generation pipeline comprises : (i) a series of rule-based graph-transducers for the syntacticization of the input graphs and the resolution of morphological agreements, and (ii) an off-the-shelf statistical linearization component.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-2108.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-2108 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-2108 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-2108/>On the Relevance of Syntactic and Discourse Features for Author Profiling and Identification</a></strong><br><a href=/people/j/juan-soler-company/>Juan Soler-Company</a>
|
<a href=/people/l/leo-wanner/>Leo Wanner</a><br><a href=/volumes/E17-2/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-2108><div class="card-body p-3 small">The majority of approaches to <a href=https://en.wikipedia.org/wiki/Author_profiling>author profiling</a> and author identification focus mainly on <a href=https://en.wikipedia.org/wiki/Lexicon>lexical features</a>, i.e., on the content of a text. We argue that syntactic and discourse features play a significantly more prominent role than they were given in the past. We show that they achieve state-of-the-art performance in author and gender identification on a <a href=https://en.wikipedia.org/wiki/Text_corpus>literary corpus</a> while keeping the feature set small : the used feature set is composed of only 188 features and still outperforms the winner of the PAN 2014 shared task on author verification in the <a href=https://en.wikipedia.org/wiki/Literary_genre>literary genre</a>.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Leo+Wanner" title="Search for 'Leo Wanner' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/s/simon-mille/ class=align-middle>Simon Mille</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/a/anja-belz/ class=align-middle>Anja Belz</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/b/bernd-bohnet/ class=align-middle>Bernd Bohnet</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/y/yvette-graham/ class=align-middle>Yvette Graham</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/t/thiago-castro-ferreira/ class=align-middle>Thiago Castro Ferreira</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/b/beatriz-fisas/ class=align-middle>Beatriz Fisas</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luis-espinosa-anke/ class=align-middle>Luis Espinosa Anke</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joan-codina-filba/ class=align-middle>Joan Codina-Filbá</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alp-oktem/ class=align-middle>Alp Öktem</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mireia-farrus/ class=align-middle>Mireia Farrús</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/laura-perez-mayos/ class=align-middle>Laura Pérez-Mayos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/miguel-ballesteros/ class=align-middle>Miguel Ballesteros</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexander-shvets/ class=align-middle>Alexander Shvets</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paula-fortuna/ class=align-middle>Paula Fortuna</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/juan-soler/ class=align-middle>Juan Soler</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/roberto-carlini/ class=align-middle>Roberto Carlini</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alicia-burga/ class=align-middle>Alicia Burga</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/emily-pitler/ class=align-middle>Emily Pitler</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/juan-soler-company/ class=align-middle>Juan Soler-Company</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/msr/ class=align-middle>MSR</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/mwe/ class=align-middle>MWE</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/woah/ class=align-middle>WOAH</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>