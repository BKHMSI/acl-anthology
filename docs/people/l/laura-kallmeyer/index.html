<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Laura Kallmeyer - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Laura</span> <span class=font-weight-bold>Kallmeyer</span></h2><hr><div class=row><div class=col-lg-9><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.readi-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--readi-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.readi-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.readi-1.12/>A multi-lingual and cross-domain analysis of features for <a href=https://en.wikipedia.org/wiki/Text_simplification>text simplification</a></a></strong><br><a href=/people/r/regina-stodden/>Regina Stodden</a>
|
<a href=/people/l/laura-kallmeyer/>Laura Kallmeyer</a><br><a href=/volumes/2020.readi-1/ class=text-muted>Proceedings of the 1st Workshop on Tools and Resources to Empower People with REAding DIfficulties (READI)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--readi-1--12><div class="card-body p-3 small">In <a href=https://en.wikipedia.org/wiki/Text_simplification>text simplification</a> and readability research, several features have been proposed to estimate or simplify a complex text, e.g., readability scores, <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence length</a>, or proportion of POS tags. These <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> are however mainly developed for <a href=https://en.wikipedia.org/wiki/English_language>English</a>. In this paper, we investigate their relevance for <a href=https://en.wikipedia.org/wiki/Czech_language>Czech</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a>, English, Spanish, and Italian text simplification corpora. Our multi-lingual and multi-domain corpus analysis shows that the relevance of different <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> for text simplification is different per corpora, language, and domain. For example, the relevance of the lexical complexity is different across all languages, the BLEU score across all domains, and 14 <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> within the web domain corpora. Overall, the negative statistical tests regarding the other <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> across and within domains and languages lead to the assumption that text simplification models may be transferable between different domains or different languages.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-0407.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-0407 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-0407 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-0407/>Towards a Compositional Analysis of German Light Verb Constructions (LVCs) Combining Lexicalized Tree Adjoining Grammar (LTAG) with Frame Semantics<span class=acl-fixed-case>G</span>erman Light Verb Constructions (<span class=acl-fixed-case>LVC</span>s) Combining <span class=acl-fixed-case>L</span>exicalized <span class=acl-fixed-case>T</span>ree <span class=acl-fixed-case>A</span>djoining <span class=acl-fixed-case>G</span>rammar (<span class=acl-fixed-case>LTAG</span>) with Frame Semantics</a></strong><br><a href=/people/j/jens-fleischhauer/>Jens Fleischhauer</a>
|
<a href=/people/t/thomas-gamerschlag/>Thomas Gamerschlag</a>
|
<a href=/people/l/laura-kallmeyer/>Laura Kallmeyer</a>
|
<a href=/people/s/simon-petitjean/>Simon Petitjean</a><br><a href=/volumes/W19-04/ class=text-muted>Proceedings of the 13th International Conference on Computational Semantics - Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-0407><div class="card-body p-3 small">Complex predicates formed of a semantically &#8216;light&#8217; verbal head and a noun or verb which contributes the major part of the meaning are frequently referred to as &#8216;light verb constructions&#8217; (LVCs). In the paper, we present a case study of LVCs with the German posture verb stehen &#8216;stand&#8217;. In our account, we model the syntactic as well as semantic composition of such LVCs by combining Lexicalized Tree Adjoining Grammar (LTAG) with <a href=https://en.wikipedia.org/wiki/Frame_(artificial_intelligence)>frames</a>. Starting from the analysis of the literal uses of posture verbs, we show how the meaning components of the literal uses are systematically exploited in the interpretation of stehen-LVCs. The paper constitutes an important step towards a compositional and computational analysis of LVCs. We show that LTAG allows us to separate constructional from lexical meaning components and that frames enable elegant generalizations over event types and related constraints.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-1043.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-1043 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-1043 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-1043/>Learning from Relatives : Unified Dialectal Arabic Segmentation<span class=acl-fixed-case>A</span>rabic Segmentation</a></strong><br><a href=/people/y/younes-samih/>Younes Samih</a>
|
<a href=/people/m/mohamed-eldesouki/>Mohamed Eldesouki</a>
|
<a href=/people/m/mohammed-attia/>Mohammed Attia</a>
|
<a href=/people/k/kareem-darwish/>Kareem Darwish</a>
|
<a href=/people/a/ahmed-abdelali/>Ahmed Abdelali</a>
|
<a href=/people/h/hamdy-mubarak/>Hamdy Mubarak</a>
|
<a href=/people/l/laura-kallmeyer/>Laura Kallmeyer</a><br><a href=/volumes/K17-1/ class=text-muted>Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-1043><div class="card-body p-3 small">Arabic dialects do not just share a common koin, but there are shared pan-dialectal linguistic phenomena that allow <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational models</a> for <a href=https://en.wikipedia.org/wiki/Dialect>dialects</a> to learn from each other. In this paper we build a unified segmentation model where the training data for different dialects are combined and a single <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> is trained. The model yields higher accuracies than dialect-specific models, eliminating the need for dialect identification before segmentation. We also measure the degree of <a href=https://en.wikipedia.org/wiki/Coefficient_of_relationship>relatedness</a> between four major <a href=https://en.wikipedia.org/wiki/Varieties_of_Arabic>Arabic dialects</a> by testing how a segmentation model trained on one dialect performs on the other dialects. We found that linguistic relatedness is contingent with <a href=https://en.wikipedia.org/wiki/Proxemics>geographical proximity</a>. In our experiments we use SVM-based ranking and bi-LSTM-CRF sequence labeling.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1306.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1306 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1306 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1306/>A Neural Architecture for Dialectal Arabic Segmentation<span class=acl-fixed-case>A</span>rabic Segmentation</a></strong><br><a href=/people/y/younes-samih/>Younes Samih</a>
|
<a href=/people/m/mohammed-attia/>Mohammed Attia</a>
|
<a href=/people/m/mohamed-eldesouki/>Mohamed Eldesouki</a>
|
<a href=/people/a/ahmed-abdelali/>Ahmed Abdelali</a>
|
<a href=/people/h/hamdy-mubarak/>Hamdy Mubarak</a>
|
<a href=/people/l/laura-kallmeyer/>Laura Kallmeyer</a>
|
<a href=/people/k/kareem-darwish/>Kareem Darwish</a><br><a href=/volumes/W17-13/ class=text-muted>Proceedings of the Third Arabic Natural Language Processing Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1306><div class="card-body p-3 small">The automated processing of <a href=https://en.wikipedia.org/wiki/Arabic_dialects>Arabic Dialects</a> is challenging due to the lack of spelling standards and to the scarcity of annotated data and resources in general. Segmentation of words into its constituent parts is an important processing building block. In this paper, we show how a segmenter can be trained using only 350 annotated tweets using <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> without any <a href=https://en.wikipedia.org/wiki/Normalization_(statistics)>normalization</a> or use of lexical features or lexical resources. We deal with segmentation as a sequence labeling problem at the <a href=https://en.wikipedia.org/wiki/Character_(computing)>character level</a>. We show experimentally that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can rival state-of-the-art methods that rely on additional resources.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2039.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2039 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2039 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2039/>HHU at SemEval-2017 Task 2 : Fast Hash-Based Embeddings for Semantic Word Similarity Assessment<span class=acl-fixed-case>HHU</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 2: Fast Hash-Based Embeddings for Semantic Word Similarity Assessment</a></strong><br><a href=/people/b/behrang-qasemizadeh/>Behrang QasemiZadeh</a>
|
<a href=/people/l/laura-kallmeyer/>Laura Kallmeyer</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2039><div class="card-body p-3 small">This paper describes the HHU system that participated in Task 2 of SemEval 2017, Multilingual and Cross-lingual Semantic Word Similarity. We introduce our unsupervised embedding learning technique and describe how it was employed and configured to address the problems of monolingual and multilingual word similarity measurement. This paper reports from empirical evaluations on the <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmark</a> provided by the task&#8217;s organizers.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Laura+Kallmeyer" title="Search for 'Laura Kallmeyer' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/y/younes-samih/ class=align-middle>Younes Samih</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mohamed-eldesouki/ class=align-middle>Mohamed Eldesouki</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mohammed-attia/ class=align-middle>Mohammed Attia</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/kareem-darwish/ class=align-middle>Kareem Darwish</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/ahmed-abdelali/ class=align-middle>Ahmed Abdelali</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/h/hamdy-mubarak/ class=align-middle>Hamdy Mubarak</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/behrang-qasemizadeh/ class=align-middle>Behrang QasemiZadeh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jens-fleischhauer/ class=align-middle>Jens Fleischhauer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thomas-gamerschlag/ class=align-middle>Thomas Gamerschlag</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/simon-petitjean/ class=align-middle>Simon Petitjean</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/regina-stodden/ class=align-middle>Regina Stodden</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/readi/ class=align-middle>READI</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>