<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Le Sun - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Le</span> <span class=font-weight-bold>Sun</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.395.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--395 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.395 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.acl-long.395" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.395/>Unified Structure Generation for Universal Information Extraction</a></strong><br><a href=/people/y/yaojie-lu/>Yaojie Lu</a>
|
<a href=/people/q/qing-liu/>Qing Liu</a>
|
<a href=/people/d/dai-dai/>Dai Dai</a>
|
<a href=/people/x/xinyan-xiao/>Xinyan Xiao</a>
|
<a href=/people/h/hongyu-lin/>Hongyu Lin</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a>
|
<a href=/people/l/le-sun/>Le Sun</a>
|
<a href=/people/h/hua-wu/>Hua Wu</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--395><div class="card-body p-3 small">Information extraction suffers from its varying targets heterogeneous structures and demand specific schemas In this paper we propose a unified text to structure generation framework namely UIE which can universally model different IE tasks adaptively generate targeted structures and collaboratively learn general IE abilities from different knowledge sources Specifically UIE uniformly encodes different extraction structures via a structured extraction language adaptively generates target extractions via a schema based prompt mechanism structural schema instructor and captures the common IE abilities via a large scale pretrained text to structure model Experiments show that UIE achieved the state of the art performance on IE tasks datasets and on all supervised low resource and few shot settings for a wide range of entity relation event and sentiment extraction tasks and their unification These results verified the effectiveness universality and transferability of <a href=https://en.wikipedia.org/wiki/UIE>UIE</a></div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.397.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--397 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.397 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.acl-long.397" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.397/>Pre-training to Match for Unified Low-shot Relation Extraction</a></strong><br><a href=/people/f/fangchao-liu/>Fangchao Liu</a>
|
<a href=/people/h/hongyu-lin/>Hongyu Lin</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a>
|
<a href=/people/b/boxi-cao/>Boxi Cao</a>
|
<a href=/people/l/le-sun/>Le Sun</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--397><div class="card-body p-3 small">Low-shot relation extraction (RE) aims to recognize novel relations with very few or even no samples, which is critical in real scenario application. Few-shot and zero-shot RE are two representative low-shot RE tasks, which seem to be with similar target but require totally different underlying abilities. In this paper, we propose Multi-Choice Matching Networks to unify low-shot relation extraction. To fill in the gap between zero-shot and few-shot RE, we propose the triplet-paraphrase meta-training, which leverages triplet paraphrase to pre-train zero-shot label matching ability and uses meta-learning paradigm to learn few-shot instance summarizing ability. Experimental results on three different low-shot RE tasks show that the proposed method outperforms strong baselines by a large margin, and achieve the best performance on few-shot RE leaderboard.</div></div><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.60.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--60 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.60 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.60" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.60/>From Discourse to Narrative : Knowledge Projection for Event Relation Extraction</a></strong><br><a href=/people/j/jialong-tang/>Jialong Tang</a>
|
<a href=/people/h/hongyu-lin/>Hongyu Lin</a>
|
<a href=/people/m/meng-liao/>Meng Liao</a>
|
<a href=/people/y/yaojie-lu/>Yaojie Lu</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a>
|
<a href=/people/l/le-sun/>Le Sun</a>
|
<a href=/people/w/weijian-xie/>Weijian Xie</a>
|
<a href=/people/j/jin-xu/>Jin Xu</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--60><div class="card-body p-3 small">Current event-centric knowledge graphs highly rely on explicit connectives to mine relations between events. Unfortunately, due to the sparsity of connectives, these methods severely undermine the coverage of EventKGs. The lack of high-quality labelled corpora further exacerbates that problem. In this paper, we propose a knowledge projection paradigm for event relation extraction : projecting discourse knowledge to narratives by exploiting the commonalities between them. Specifically, we propose Multi-tier Knowledge Projection Network (MKPNet), which can leverage multi-tier discourse knowledge effectively for event relation extraction. In this way, the labelled data requirement is significantly reduced, and implicit event relations can be effectively extracted. Intrinsic experimental results show that MKPNet achieves the new state-of-the-art performance and extrinsic experimental results verify the value of the extracted event relations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.217.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--217 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.217 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.217" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.217/>Text2Event : Controllable Sequence-to-Structure Generation for End-to-end Event Extraction<span class=acl-fixed-case>T</span>ext2<span class=acl-fixed-case>E</span>vent: Controllable Sequence-to-Structure Generation for End-to-end Event Extraction</a></strong><br><a href=/people/y/yaojie-lu/>Yaojie Lu</a>
|
<a href=/people/h/hongyu-lin/>Hongyu Lin</a>
|
<a href=/people/j/jin-xu/>Jin Xu</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a>
|
<a href=/people/j/jialong-tang/>Jialong Tang</a>
|
<a href=/people/a/annan-li/>Annan Li</a>
|
<a href=/people/l/le-sun/>Le Sun</a>
|
<a href=/people/m/meng-liao/>Meng Liao</a>
|
<a href=/people/s/shaoyi-chen/>Shaoyi Chen</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--217><div class="card-body p-3 small">Event extraction is challenging due to the complex structure of event records and the semantic gap between text and event. Traditional methods usually extract event records by decomposing the complex structure prediction task into multiple subtasks. In this paper, we propose Text2Event, a sequence-to-structure generation paradigm that can directly extract <a href=https://en.wikipedia.org/wiki/Event_(computing)>events</a> from the text in an end-to-end manner. Specifically, we design a sequence-to-structure network for unified event extraction, a constrained decoding algorithm for event knowledge injection during inference, and a curriculum learning algorithm for efficient model learning. Experimental results show that, by uniformly modeling all tasks in a single model and universally predicting different labels, our method can achieve competitive performance using only record-level annotations in both <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised learning</a> and transfer learning settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.397.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--397 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.397 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.397/>From <a href=https://en.wikipedia.org/wiki/Paraphrase>Paraphrasing</a> to Semantic Parsing : Unsupervised Semantic Parsing via Synchronous Semantic Decoding</a></strong><br><a href=/people/s/shan-wu/>Shan Wu</a>
|
<a href=/people/b/bo-chen/>Bo Chen</a>
|
<a href=/people/c/chunlei-xin/>Chunlei Xin</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a>
|
<a href=/people/l/le-sun/>Le Sun</a>
|
<a href=/people/w/weipeng-zhang/>Weipeng Zhang</a>
|
<a href=/people/j/jiansong-chen/>Jiansong Chen</a>
|
<a href=/people/f/fan-yang/>Fan Yang</a>
|
<a href=/people/x/xunliang-cai/>Xunliang Cai</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--397><div class="card-body p-3 small">Semantic parsing is challenging due to the structure gap and the <a href=https://en.wikipedia.org/wiki/Semantic_gap>semantic gap</a> between utterances and logical forms. In this paper, we propose an unsupervised semantic parsing method-Synchronous Semantic Decoding (SSD), which can simultaneously resolve the <a href=https://en.wikipedia.org/wiki/Semantic_gap>semantic gap</a> and the structure gap by jointly leveraging paraphrasing and grammar-constrained decoding. Specifically, we reformulate <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> as a constrained paraphrasing problem : given an utterance, our model synchronously generates its canonical utterancel and meaning representation. During synchronously decoding : the utterance paraphrasing is constrained by the structure of the logical form, therefore the canonical utterance can be paraphrased controlledly ; the semantic decoding is guided by the semantics of the canonical utterance, therefore its <a href=https://en.wikipedia.org/wiki/Logical_form>logical form</a> can be generated unsupervisedly. Experimental results show that SSD is a promising approach and can achieve state-of-the-art unsupervised semantic parsing performance on multiple datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.637.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--637 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.637 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.637" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.637/>Honey or Poison? Solving the Trigger Curse in Few-shot Event Detection via Causal Intervention</a></strong><br><a href=/people/j/jiawei-chen/>Jiawei Chen</a>
|
<a href=/people/h/hongyu-lin/>Hongyu Lin</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a>
|
<a href=/people/l/le-sun/>Le Sun</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--637><div class="card-body p-3 small">Event detection has long been troubled by the trigger curse : overfitting the trigger will harm the generalization ability while underfitting it will hurt the <a href=https://en.wikipedia.org/wiki/Detection>detection</a> performance. This <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> is even more severe in few-shot scenario. In this paper, we identify and solve the trigger curse problem in few-shot event detection (FSED) from a causal view. By formulating FSED with a structural causal model (SCM), we found that the trigger is a confounder of the context and the result, which makes previous FSED methods much easier to overfit triggers. To resolve this problem, we propose to intervene on the context via backdoor adjustment during <a href=https://en.wikipedia.org/wiki/Training>training</a>. Experiments show that our method significantly improves the FSED on both ACE05 and MAVEN datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.762.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--762 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.762 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.762" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.762/>Progressive Adversarial Learning for Bootstrapping : A Case Study on Entity Set Expansion</a></strong><br><a href=/people/l/lingyong-yan/>Lingyong Yan</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a>
|
<a href=/people/l/le-sun/>Le Sun</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--762><div class="card-body p-3 small">Bootstrapping has become the mainstream method for entity set expansion. Conventional bootstrapping methods mostly define the expansion boundary using seed-based distance metrics, which heavily depend on the quality of selected seeds and are hard to be adjusted due to the extremely sparse supervision. In this paper, we propose BootstrapGAN, a new learning method for <a href=https://en.wikipedia.org/wiki/Bootstrapping_(statistics)>bootstrapping</a> which jointly models the <a href=https://en.wikipedia.org/wiki/Bootstrapping_(statistics)>bootstrapping process</a> and the boundary learning process in a GAN framework. Specifically, the expansion boundaries of different bootstrapping iterations are learned via different discriminator networks ; the bootstrapping network is the generator to generate new positive entities, and the discriminator networks identify the expansion boundaries by trying to distinguish the generated entities from known positive entities. By iteratively performing the above <a href=https://en.wikipedia.org/wiki/Adversarial_learning>adversarial learning</a>, the generator and the discriminators can reinforce each other and be progressively refined along the whole bootstrapping process. Experiments show that BootstrapGAN achieves the new state-of-the-art entity set expansion performance.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.69.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--69 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.69 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.findings-emnlp.69.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.findings-emnlp.69" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.69/>Syntactic and Semantic-driven Learning for Open Information Extraction</a></strong><br><a href=/people/j/jialong-tang/>Jialong Tang</a>
|
<a href=/people/y/yaojie-lu/>Yaojie Lu</a>
|
<a href=/people/h/hongyu-lin/>Hongyu Lin</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a>
|
<a href=/people/l/le-sun/>Le Sun</a>
|
<a href=/people/x/xinyan-xiao/>Xinyan Xiao</a>
|
<a href=/people/h/hua-wu/>Hua Wu</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--69><div class="card-body p-3 small">One of the biggest bottlenecks in building accurate, high coverage neural open IE systems is the need for large labelled corpora. The diversity of <a href=https://en.wikipedia.org/wiki/Open_domain>open domain corpora</a> and the variety of <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language expressions</a> further exacerbate this problem. In this paper, we propose a syntactic and semantic-driven learning approach, which can learn neural open IE models without any human-labelled data by leveraging syntactic and semantic knowledge as noisier, higher-level supervision. Specifically, we first employ syntactic patterns as data labelling functions and pretrain a base model using the generated labels. Then we propose a syntactic and semantic-driven reinforcement learning algorithm, which can effectively generalize the base model to open situations with high <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. Experimental results show that our approach significantly outperforms the supervised counterparts, and can even achieve competitive performance to supervised state-of-the-art (SoA) model.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1028.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1028 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1028 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1028/>Learning to Bootstrap for Entity Set Expansion</a></strong><br><a href=/people/l/lingyong-yan/>Lingyong Yan</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a>
|
<a href=/people/l/le-sun/>Le Sun</a>
|
<a href=/people/b/ben-he/>Ben He</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1028><div class="card-body p-3 small">Bootstrapping for Entity Set Expansion (ESE) aims at iteratively acquiring new instances of a specific target category. Traditional bootstrapping methods often suffer from two problems : 1) delayed feedback, i.e., the pattern evaluation relies on both its direct extraction quality and extraction quality in later iterations. 2) sparse supervision, i.e., only few seed entities are used as the <a href=https://en.wikipedia.org/wiki/Supervisor>supervision</a>. To address the above two problems, we propose a novel bootstrapping method combining the Monte Carlo Tree Search (MCTS) algorithm with a deep similarity network, which can efficiently estimate delayed feedback for pattern evaluation and adaptively score entities given sparse supervision signals. Experimental results confirm the effectiveness of the proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1646.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1646 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1646 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1646/>Gazetteer-Enhanced Attentive Neural Networks for Named Entity Recognition</a></strong><br><a href=/people/h/hongyu-lin/>Hongyu Lin</a>
|
<a href=/people/y/yaojie-lu/>Yaojie Lu</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a>
|
<a href=/people/l/le-sun/>Le Sun</a>
|
<a href=/people/b/bin-dong/>Bin Dong</a>
|
<a href=/people/s/shanshan-jiang/>Shanshan Jiang</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1646><div class="card-body p-3 small">Current region-based NER models only rely on fully-annotated training data to learn effective region encoder, which often face the training data bottleneck. To alleviate this problem, this paper proposes Gazetteer-Enhanced Attentive Neural Networks, which can enhance region-based NER by learning name knowledge of entity mentions from easily-obtainable gazetteers, rather than only from fully-annotated data. Specially, we first propose an attentive neural network (ANN), which explicitly models the mention-context association and therefore is convenient for integrating externally-learned knowledge. Then we design an auxiliary gazetteer network, which can effectively encode name regularity of mentions only using <a href=https://en.wikipedia.org/wiki/Gazetteer>gazetteers</a>. Finally, the learned gazetteer network is incorporated into ANN for better <a href=https://en.wikipedia.org/wiki/Network_topology>NER</a>. Experiments show that our ANN can achieve the state-of-the-art performance on ACE2005 named entity recognition benchmark. Besides, incorporating gazetteer network can further improve the performance and significantly reduce the requirement of training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-3012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-3012 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-3012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-3012/>EUSP : An Easy-to-Use Semantic Parsing PlatForm<span class=acl-fixed-case>EUSP</span>: An Easy-to-Use Semantic Parsing <span class=acl-fixed-case>P</span>lat<span class=acl-fixed-case>F</span>orm</a></strong><br><a href=/people/b/bo-an/>Bo An</a>
|
<a href=/people/c/chen-bo/>Chen Bo</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a>
|
<a href=/people/l/le-sun/>Le Sun</a><br><a href=/volumes/D19-3/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-3012><div class="card-body p-3 small">Semantic parsing aims to map <a href=https://en.wikipedia.org/wiki/Utterance>natural language utterances</a> into structured meaning representations. We present a modular platform, EUSP (Easy-to-Use Semantic Parsing PlatForm), that facilitates developers to build semantic parser from scratch. Instead of requiring a large amount of training data or complex grammar knowledge, in our platform developers can build grammar-based semantic parser or neural-based semantic parser through configure files which specify the modules and components that compose semantic parsing system. A high quality grammar-based semantic parsing system only requires domain lexicons rather than costly training data for a <a href=https://en.wikipedia.org/wiki/Semantic_parser>semantic parser</a>. Furthermore, we provide a browser-based method to generate the semantic parsing system to minimize the difficulty of development. Experimental results show that the neural-based semantic parser system achieves competitive performance on semantic parsing task, and grammar-based semantic parsers significantly improve the performance of a business search engine.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1053.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1053 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1053 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1053" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1053/>Progressive Self-Supervised Attention Learning for Aspect-Level Sentiment Analysis</a></strong><br><a href=/people/j/jialong-tang/>Jialong Tang</a>
|
<a href=/people/z/ziyao-lu/>Ziyao Lu</a>
|
<a href=/people/j/jinsong-su/>Jinsong Su</a>
|
<a href=/people/y/yubin-ge/>Yubin Ge</a>
|
<a href=/people/l/linfeng-song/>Linfeng Song</a>
|
<a href=/people/l/le-sun/>Le Sun</a>
|
<a href=/people/j/jiebo-luo/>Jiebo Luo</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1053><div class="card-body p-3 small">In aspect-level sentiment classification (ASC), it is prevalent to equip dominant neural models with attention mechanisms, for the sake of acquiring the importance of each context word on the given aspect. However, such a <a href=https://en.wikipedia.org/wiki/Mechanism_(sociology)>mechanism</a> tends to excessively focus on a few frequent words with sentiment polarities, while ignoring infrequent ones. In this paper, we propose a progressive self-supervised attention learning approach for neural ASC models, which automatically mines useful attention supervision information from a training corpus to refine attention mechanisms. Specifically, we iteratively conduct <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment predictions</a> on all training instances. Particularly, at each iteration, the context word with the maximum attention weight is extracted as the one with active / misleading influence on the correct / incorrect prediction of every instance, and then the word itself is masked for subsequent iterations. Finally, we augment the conventional training objective with a regularization term, which enables ASC models to continue equally focusing on the extracted active context words while decreasing weights of those misleading ones. Experimental results on multiple datasets show that our proposed approach yields better attention mechanisms, leading to substantial improvements over the two state-of-the-art neural ASC models. Source code and trained models are available at https://github.com/DeepLearnXMU/PSSAttention.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1511.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1511 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1511 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1511" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1511/>Sequence-to-Nuggets : Nested Entity Mention Detection via Anchor-Region Networks</a></strong><br><a href=/people/h/hongyu-lin/>Hongyu Lin</a>
|
<a href=/people/y/yaojie-lu/>Yaojie Lu</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a>
|
<a href=/people/l/le-sun/>Le Sun</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1511><div class="card-body p-3 small">Sequential labeling-based NER approaches restrict each word belonging to at most one entity mention, which will face a serious problem when recognizing nested entity mentions. In this paper, we propose to resolve this problem by modeling and leveraging the head-driven phrase structures of <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity mentions</a>, i.e., although a mention can nest other mentions, they will not share the same <a href=https://en.wikipedia.org/wiki/Headword>head word</a>. Specifically, we propose Anchor-Region Networks (ARNs), a sequence-to-nuggets architecture for nested mention detection. ARNs first identify anchor words (i.e., possible head words) of all mentions, and then recognize the mention boundaries for each anchor word by exploiting regular phrase structures. Furthermore, we also design Bag Loss, an <a href=https://en.wikipedia.org/wiki/Loss_function>objective function</a> which can train ARNs in an end-to-end manner without using any anchor word annotation. Experiments show that ARNs achieve the state-of-the-art performance on three standard nested entity mention detection benchmarks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1521.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1521 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1521 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1521" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1521/>Cost-sensitive Regularization for Label Confusion-aware Event Detection</a></strong><br><a href=/people/h/hongyu-lin/>Hongyu Lin</a>
|
<a href=/people/y/yaojie-lu/>Yaojie Lu</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a>
|
<a href=/people/l/le-sun/>Le Sun</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1521><div class="card-body p-3 small">In supervised event detection, most of the mislabeling occurs between a small number of confusing type pairs, including trigger-NIL pairs and sibling sub-types of the same coarse type. To address this label confusion problem, this paper proposes cost-sensitive regularization, which can force the training procedure to concentrate more on optimizing confusing type pairs. Specifically, we introduce a cost-weighted term into the training loss, which penalizes more on mislabeling between confusing label pairs. Furthermore, we also propose two <a href=https://en.wikipedia.org/wiki/Estimator>estimators</a> which can effectively measure such label confusion based on instance-level or population-level statistics. Experiments on TAC-KBP 2017 datasets demonstrate that the proposed method can significantly improve the performances of different <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> in both English and Chinese event detection.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1076.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1076 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1076 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-1076/>Semi-Supervised Lexicon Learning for Wide-Coverage Semantic Parsing</a></strong><br><a href=/people/b/bo-chen/>Bo Chen</a>
|
<a href=/people/b/bo-an/>Bo An</a>
|
<a href=/people/l/le-sun/>Le Sun</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1076><div class="card-body p-3 small">Semantic parsers critically rely on accurate and high-coverage lexicons. However, traditional semantic parsers usually utilize annotated logical forms to learn the <a href=https://en.wikipedia.org/wiki/Lexicon>lexicon</a>, which often suffer from the lexicon coverage problem. In this paper, we propose a graph-based semi-supervised learning framework that makes use of large text corpora and lexical resources. This framework first constructs a <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a> with a phrase similarity model learned by utilizing many <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpora</a> and lexical resources. Next, graph propagation algorithm identifies the label distribution of unlabeled phrases from labeled ones. We evaluate our approach on two <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a> : <a href=https://en.wikipedia.org/wiki/WebQuest>Webquestions</a> and Free917. The results show that, in both datasets, our method achieves substantial improvement when comparing to the base system that does not utilize the learned lexicon, and gains competitive results when comparing to state-of-the-art systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1240.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1240 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1240 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-1240/>Model-Free Context-Aware Word Composition</a></strong><br><a href=/people/b/bo-an/>Bo An</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a>
|
<a href=/people/l/le-sun/>Le Sun</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1240><div class="card-body p-3 small">Word composition is a promising technique for representation learning of large linguistic units (e.g., phrases, sentences and documents). However, most of the current composition models do not take the ambiguity of words and the context outside of a linguistic unit into consideration for learning representations, and consequently suffer from the inaccurate representation of semantics. To address this issue, we propose a model-free context-aware word composition model, which employs the latent semantic information as global context for learning representations. The proposed <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> attempts to resolve the <a href=https://en.wikipedia.org/wiki/Word-sense_disambiguation>word sense disambiguation</a> and <a href=https://en.wikipedia.org/wiki/Composition_(language)>word composition</a> in a unified framework. Extensive evaluation shows consistent improvements over various strong word representation / composition models at different granularities (including word, phrase and sentence), demonstrating the effectiveness of our proposed method.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1100.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1100 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1100 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1100.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802257 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1100/>TDNN : A Two-stage Deep Neural Network for Prompt-independent Automated Essay Scoring<span class=acl-fixed-case>TDNN</span>: A Two-stage Deep Neural Network for Prompt-independent Automated Essay Scoring</a></strong><br><a href=/people/c/cancan-jin/>Cancan Jin</a>
|
<a href=/people/b/ben-he/>Ben He</a>
|
<a href=/people/k/kai-hui/>Kai Hui</a>
|
<a href=/people/l/le-sun/>Le Sun</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1100><div class="card-body p-3 small">Existing automated essay scoring (AES) models rely on rated essays for the target prompt as training data. Despite their successes in prompt-dependent AES, how to effectively predict essay ratings under a prompt-independent setting remains a challenge, where the rated essays for the target prompt are not available. To close this gap, a two-stage deep neural network (TDNN) is proposed. In particular, in the first stage, using the rated essays for non-target prompts as the training data, a shallow model is learned to select essays with an extreme quality for the target prompt, serving as pseudo training data ; in the second stage, an end-to-end hybrid deep model is proposed to learn a prompt-dependent rating model consuming the pseudo training data from the first step. Evaluation of the proposed TDNN on the standard ASAP dataset demonstrates a promising improvement for the prompt-independent AES task.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3532.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3532 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3532 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3532/>Investigating the content and form of referring expressions in <a href=https://en.wikipedia.org/wiki/Mandarin_Chinese>Mandarin</a> : introducing the Mtuna corpus<span class=acl-fixed-case>M</span>andarin: introducing the Mtuna corpus</a></strong><br><a href=/people/k/kees-van-deemter/>Kees van Deemter</a>
|
<a href=/people/l/le-sun/>Le Sun</a>
|
<a href=/people/r/rint-sybesma/>Rint Sybesma</a>
|
<a href=/people/x/xiao-li/>Xiao Li</a>
|
<a href=/people/b/bo-chen/>Bo Chen</a>
|
<a href=/people/m/muyun-yang/>Muyun Yang</a><br><a href=/volumes/W17-35/ class=text-muted>Proceedings of the 10th International Conference on Natural Language Generation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3532><div class="card-body p-3 small">East Asian languages are thought to handle reference differently from <a href=https://en.wikipedia.org/wiki/Language>languages</a> such as <a href=https://en.wikipedia.org/wiki/English_language>English</a>, particularly in terms of the marking of definiteness and <a href=https://en.wikipedia.org/wiki/Grammatical_number>number</a>. We present the first Data-Text corpus for Referring Expressions in <a href=https://en.wikipedia.org/wiki/Mandarin_Chinese>Mandarin</a>, and we use this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> to test some initial hypotheses inspired by the theoretical linguistics literature. Our findings suggest that function words deserve more attention in Referring Expressions Generation than they have so far received, and they have a bearing on the debate about whether different languages make different trade-offs between clarity and brevity.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1216.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1216 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1216 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238235420 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1216/>Reasoning with Heterogeneous Knowledge for Commonsense Machine Comprehension</a></strong><br><a href=/people/h/hongyu-lin/>Hongyu Lin</a>
|
<a href=/people/l/le-sun/>Le Sun</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1216><div class="card-body p-3 small">Reasoning with <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a> is critical for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a>. Traditional methods for commonsense machine comprehension mostly only focus on one specific kind of knowledge, neglecting the fact that <a href=https://en.wikipedia.org/wiki/Commonsense_reasoning>commonsense reasoning</a> requires simultaneously considering different kinds of commonsense knowledge. In this paper, we propose a multi-knowledge reasoning method, which can exploit heterogeneous knowledge for commonsense machine comprehension. Specifically, we first mine different kinds of knowledge (including event narrative knowledge, entity semantic knowledge and sentiment coherent knowledge) and encode them as inference rules with costs. Then we propose a multi-knowledge reasoning model, which selects <a href=https://en.wikipedia.org/wiki/Rule_of_inference>inference rules</a> for a specific reasoning context using attention mechanism, and reasons by summarizing all valid <a href=https://en.wikipedia.org/wiki/Rule_of_inference>inference rules</a>. Experiments on RocStories show that our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> outperforms traditional <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> significantly.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Le+Sun" title="Search for 'Le Sun' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/x/xianpei-han/ class=align-middle>Xianpei Han</a>
<span class="badge badge-secondary align-middle ml-2">16</span></li><li class=list-group-item><a href=/people/h/hongyu-lin/ class=align-middle>Hongyu Lin</a>
<span class="badge badge-secondary align-middle ml-2">10</span></li><li class=list-group-item><a href=/people/y/yaojie-lu/ class=align-middle>Yaojie Lu</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/j/jialong-tang/ class=align-middle>Jialong Tang</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/b/bo-chen/ class=align-middle>Bo Chen</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/b/bo-an/ class=align-middle>Bo An</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/meng-liao/ class=align-middle>Meng Liao</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jin-xu/ class=align-middle>Jin Xu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/x/xinyan-xiao/ class=align-middle>Xinyan Xiao</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hua-wu/ class=align-middle>Hua Wu (吴华)</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/lingyong-yan/ class=align-middle>Lingyong Yan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/ben-he/ class=align-middle>Ben He</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/w/weijian-xie/ class=align-middle>Weijian Xie</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/annan-li/ class=align-middle>Annan Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shaoyi-chen/ class=align-middle>Shaoyi Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shan-wu/ class=align-middle>Shan Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chunlei-xin/ class=align-middle>Chunlei Xin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/weipeng-zhang/ class=align-middle>Weipeng Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiansong-chen/ class=align-middle>Jiansong Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fan-yang/ class=align-middle>Fan Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xunliang-cai/ class=align-middle>Xunliang Cai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kees-van-deemter/ class=align-middle>Kees van Deemter</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rint-sybesma/ class=align-middle>Rint Sybesma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiao-li/ class=align-middle>Xiao Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/muyun-yang/ class=align-middle>Muyun Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qing-liu/ class=align-middle>Qing Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dai-dai/ class=align-middle>Dai Dai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fangchao-liu/ class=align-middle>Fangchao Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/boxi-cao/ class=align-middle>Boxi Cao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiawei-chen/ class=align-middle>Jiawei Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bin-dong/ class=align-middle>Bin Dong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shanshan-jiang/ class=align-middle>Shanshan Jiang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chen-bo/ class=align-middle>Chen Bo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cancan-jin/ class=align-middle>Cancan Jin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kai-hui/ class=align-middle>Kai Hui</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/ziyao-lu/ class=align-middle>Ziyao Lu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jinsong-su/ class=align-middle>Jinsong Su</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yubin-ge/ class=align-middle>Yubin Ge</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/linfeng-song/ class=align-middle>Linfeng Song</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiebo-luo/ class=align-middle>Jiebo Luo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">9</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>