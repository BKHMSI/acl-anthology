<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Luo Si - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Luo</span> <span class=font-weight-bold>Si</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.162.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--162 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.162 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2022.acl-long.162.software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.acl-long.162" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.162/><span class=acl-fixed-case>IAM</span>: A Comprehensive and Large-Scale Dataset for Integrated Argument Mining Tasks</a></strong><br><a href=/people/l/liying-cheng/>Liying Cheng</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/r/ruidan-he/>Ruidan He</a>
|
<a href=/people/q/qian-yu/>Qian Yu</a>
|
<a href=/people/y/yan-zhang/>Yan Zhang</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--162><div class="card-body p-3 small">Traditionally, a debate usually requires a manual preparation process, including reading plenty of articles, selecting the claims, identifying the stances of the claims, seeking the evidence for the claims, etc. As the AI debate attracts more attention these years, it is worth exploring the methods to automate the tedious process involved in the debating system. In this work, we introduce a comprehensive and large dataset named IAM, which can be applied to a series of argument mining tasks, including claim extraction, stance classification, evidence extraction, etc. Our dataset is collected from over 1k articles related to 123 topics. Near 70k sentences in the dataset are fully annotated based on their argument properties (e.g., claims, stances, evidence, etc.). We further propose two new integrated argument mining tasks associated with the debate preparation process: (1) claim extraction with stance classification (CESC) and (2) claim-evidence pair extraction (CEPE). We adopt a pipeline approach and an end-to-end method for each integrated task separately. Promising experimental results are reported to show the values and challenges of our proposed tasks, and motivate future research on argument mining.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.findings-acl.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--findings-acl--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.findings-acl.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.findings-acl.5" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.findings-acl.5/><span class=acl-fixed-case>R</span>elation<span class=acl-fixed-case>P</span>rompt: Leveraging Prompts to Generate Synthetic Data for Zero-Shot Relation Triplet Extraction</a></strong><br><a href=/people/y/yew-ken-chia/>Yew Ken Chia</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/s/soujanya-poria/>Soujanya Poria</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/2022.findings-acl/ class=text-muted>Findings of the Association for Computational Linguistics: ACL 2022</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--findings-acl--5><div class="card-body p-3 small">Despite the importance of relation extraction in building and representing knowledge, less research is focused on generalizing to unseen relations types. We introduce the task setting of Zero-Shot Relation Triplet Extraction (ZeroRTE) to encourage further research in low-resource relation extraction methods. Given an input sentence, each extracted triplet consists of the head entity, relation label, and tail entity where the relation label is not seen at the training stage. To solve ZeroRTE, we propose to synthesize relation examples by prompting language models to generate structured texts. Concretely, we unify language model prompts and structured text approaches to design a structured prompt template for generating synthetic relation samples when conditioning on relation label prompts (RelationPrompt). To overcome the limitation for extracting multiple relation triplets in a sentence, we design a novel Triplet Search Decoding method. Experiments on FewRel and Wiki-ZSL datasets show the efficacy of RelationPrompt for the ZeroRTE task and zero-shot relation classification. Our code and data are available at github.com/declare-lab/RelationPrompt.</div></div><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.172.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--172 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.172 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.172/>On the Effectiveness of Adapter-based Tuning for Pretrained Language Model Adaptation</a></strong><br><a href=/people/r/ruidan-he/>Ruidan He</a>
|
<a href=/people/l/linlin-liu/>Linlin Liu</a>
|
<a href=/people/h/hai-ye/>Hai Ye</a>
|
<a href=/people/q/qingyu-tan/>Qingyu Tan</a>
|
<a href=/people/b/bosheng-ding/>Bosheng Ding</a>
|
<a href=/people/l/liying-cheng/>Liying Cheng</a>
|
<a href=/people/j/jiawei-low/>Jiawei Low</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--172><div class="card-body p-3 small">Adapter-based tuning has recently arisen as an alternative to <a href=https://en.wikipedia.org/wiki/Musical_tuning>fine-tuning</a>. It works by adding light-weight adapter modules to a pretrained language model (PrLM) and only updating the parameters of adapter modules when learning on a downstream task. As such, it adds only a few trainable parameters per new <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>, allowing a high degree of parameter sharing. Prior studies have shown that adapter-based tuning often achieves comparable results to <a href=https://en.wikipedia.org/wiki/Musical_tuning>fine-tuning</a>. However, existing work only focuses on the parameter-efficient aspect of adapter-based tuning while lacking further investigation on its effectiveness. In this paper, we study the latter. We first show that adapter-based tuning better mitigates forgetting issues than <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> since it yields representations with less deviation from those generated by the initial PrLM. We then empirically compare the two tuning methods on several downstream NLP tasks and settings. We demonstrate that 1) adapter-based tuning outperforms <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> on low-resource and cross-lingual tasks ; 2) it is more robust to <a href=https://en.wikipedia.org/wiki/Overfitting>overfitting</a> and less sensitive to changes in learning rates.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.308.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--308 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.308 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.308" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.308/>VECO : Variable and Flexible Cross-lingual Pre-training for <a href=https://en.wikipedia.org/wiki/Language_understanding>Language Understanding</a> and Generation<span class=acl-fixed-case>VECO</span>: Variable and Flexible Cross-lingual Pre-training for Language Understanding and Generation</a></strong><br><a href=/people/f/fuli-luo/>Fuli Luo</a>
|
<a href=/people/w/wei-wang/>Wei Wang</a>
|
<a href=/people/j/jiahao-liu/>Jiahao Liu</a>
|
<a href=/people/y/yijia-liu/>Yijia Liu</a>
|
<a href=/people/b/bin-bi/>Bin Bi</a>
|
<a href=/people/s/songfang-huang/>Songfang Huang</a>
|
<a href=/people/f/fei-huang/>Fei Huang</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--308><div class="card-body p-3 small">Existing work in multilingual pretraining has demonstrated the potential of cross-lingual transferability by training a unified Transformer encoder for multiple languages. However, much of this work only relies on the shared vocabulary and bilingual contexts to encourage the correlation across languages, which is loose and implicit for aligning the contextual representations between languages. In this paper, we plug a cross-attention module into the Transformer encoder to explicitly build the interdependence between languages. It can effectively avoid the degeneration of predicting masked words only conditioned on the context in its own language. More importantly, when fine-tuning on downstream tasks, the cross-attention module can be plugged in or out on-demand, thus naturally benefiting a wider range of cross-lingual tasks, from <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>language understanding</a> to generation. As a result, the proposed cross-lingual model delivers new state-of-the-art results on various cross-lingual understanding tasks of the XTREME benchmark, covering text classification, sequence labeling, <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>, and sentence retrieval. For cross-lingual generation tasks, it also outperforms all existing cross-lingual models and state-of-the-art Transformer variants on WMT14 English-to-German and English-to-French translation datasets, with gains of up to 1 2 <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.453.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--453 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.453 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.453/>MulDA : A Multilingual Data Augmentation Framework for Low-Resource Cross-Lingual NER<span class=acl-fixed-case>M</span>ul<span class=acl-fixed-case>DA</span>: A Multilingual Data Augmentation Framework for Low-Resource Cross-Lingual <span class=acl-fixed-case>NER</span></a></strong><br><a href=/people/l/linlin-liu/>Linlin Liu</a>
|
<a href=/people/b/bosheng-ding/>Bosheng Ding</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/l/luo-si/>Luo Si</a>
|
<a href=/people/c/chunyan-miao/>Chunyan Miao</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--453><div class="card-body p-3 small">Named Entity Recognition (NER) for low-resource languages is a both practical and challenging research problem. This paper addresses zero-shot transfer for cross-lingual NER, especially when the amount of source-language training data is also limited. The paper first proposes a simple but effective labeled sequence translation method to translate source-language training data to target languages and avoids problems such as word order change and entity span determination. With the source-language data as well as the translated data, a generation-based multilingual data augmentation method is introduced to further increase diversity by generating synthetic labeled data in multiple languages. These augmented data enable the language model based NER models to generalize better with both the language-specific features from the target-language synthetic data and the language-independent features from multilingual synthetic data. An extensive set of experiments were conducted to demonstrate encouraging cross-lingual transfer performance of the new <a href=https://en.wikipedia.org/wiki/Research>research</a> on a wide variety of target languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.496.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--496 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.496 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.496" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.496/>Argument Pair Extraction via Attention-guided Multi-Layer Multi-Cross Encoding</a></strong><br><a href=/people/l/liying-cheng/>Liying Cheng</a>
|
<a href=/people/t/tianyu-wu/>Tianyu Wu</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--496><div class="card-body p-3 small">Argument pair extraction (APE) is a research task for extracting arguments from two passages and identifying potential argument pairs. Prior research work treats this task as a sequence labeling problem and a binary classification problem on two passages that are directly concatenated together, which has a limitation of not fully utilizing the unique characteristics and inherent relations of two different passages. This paper proposes a novel attention-guided multi-layer multi-cross encoding scheme to address the challenges. The new model processes two passages with two individual sequence encoders and updates their <a href=https://en.wikipedia.org/wiki/Representation_theory>representations</a> using each other&#8217;s representations through <a href=https://en.wikipedia.org/wiki/Attention>attention</a>. In addition, the pair prediction part is formulated as a table-filling problem by updating the representations of two sequences&#8217; Cartesian product. Furthermore, an auxiliary attention loss is introduced to guide each argument to align to its paired argument. An extensive set of experiments show that the new <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> significantly improves the APE performance over several alternatives.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.185.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--185 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.185 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.185" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.185/>DialogueCSE : Dialogue-based Contrastive Learning of Sentence Embeddings<span class=acl-fixed-case>D</span>ialogue<span class=acl-fixed-case>CSE</span>: Dialogue-based Contrastive Learning of Sentence Embeddings</a></strong><br><a href=/people/c/che-liu/>Che Liu</a>
|
<a href=/people/r/rui-wang/>Rui Wang</a>
|
<a href=/people/j/jinghua-liu/>Jinghua Liu</a>
|
<a href=/people/j/jian-sun/>Jian Sun</a>
|
<a href=/people/f/fei-huang/>Fei Huang</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--185><div class="card-body p-3 small">Learning sentence embeddings from <a href=https://en.wikipedia.org/wiki/Dialogue>dialogues</a> has drawn increasing attention due to its low annotation cost and high domain adaptability. Conventional approaches employ the siamese-network for this task, which obtains the sentence embeddings through modeling the context-response semantic relevance by applying a feed-forward network on top of the sentence encoders. However, as the semantic textual similarity is commonly measured through the element-wise distance metrics (e.g. cosine and L2 distance), such architecture yields a large gap between training and evaluating. In this paper, we propose DialogueCSE, a dialogue-based contrastive learning approach to tackle this issue. DialogueCSE first introduces a novel matching-guided embedding (MGE) mechanism, which generates a context-aware embedding for each candidate response embedding (i.e. the context-free embedding) according to the guidance of the multi-turn context-response matching matrices. Then it pairs each context-aware embedding with its corresponding context-free embedding and finally minimizes the contrastive loss across all pairs. We evaluate our model on three multi-turn dialogue datasets : the Microsoft Dialogue Corpus, the Jing Dong Dialogue Corpus, and the E-commerce Dialogue Corpus. Evaluation results show that our approach significantly outperforms the baselines across all three <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> in terms of MAP and Spearman&#8217;s correlation measures, demonstrating its effectiveness. Further quantitative experiments show that our approach achieves better performance when leveraging more dialogue context and remains robust when less <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data</a> is provided.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.90.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--90 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.90 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938972 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.90" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.90/>ENT-DESC : Entity Description Generation by Exploring Knowledge Graph<span class=acl-fixed-case>ENT</span>-<span class=acl-fixed-case>DESC</span>: Entity Description Generation by Exploring Knowledge Graph</a></strong><br><a href=/people/l/liying-cheng/>Liying Cheng</a>
|
<a href=/people/d/dekun-wu/>Dekun Wu</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/y/yan-zhang/>Yan Zhang</a>
|
<a href=/people/z/zhanming-jie/>Zhanming Jie</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--90><div class="card-body p-3 small">Previous works on knowledge-to-text generation take as input a few <a href=https://en.wikipedia.org/wiki/Resource_Description_Framework>RDF triples</a> or key-value pairs conveying the knowledge of some entities to generate a <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language description</a>. Existing datasets, such as WIKIBIO, WebNLG, and <a href=https://en.wikipedia.org/wiki/E2E>E2E</a>, basically have a good alignment between an input triple / pair set and its output text. However, in practice, the input knowledge could be more than enough, since the output description may only cover the most significant knowledge. In this paper, we introduce a large-scale and challenging dataset to facilitate the study of such a practical scenario in KG-to-text. Our dataset involves retrieving abundant knowledge of various types of main entities from a large knowledge graph (KG), which makes the current graph-to-sequence models severely suffer from the problems of <a href=https://en.wikipedia.org/wiki/Information_loss>information loss</a> and parameter explosion while generating the descriptions. We address these challenges by proposing a multi-graph structure that is able to represent the original <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph information</a> more comprehensively. Furthermore, we also incorporate aggregation methods that learn to extract the rich graph information. Extensive experiments demonstrate the effectiveness of our model architecture.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.569.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--569 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.569 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939058 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.569" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.569/>APE : Argument Pair Extraction from Peer Review and Rebuttal via <a href=https://en.wikipedia.org/wiki/Multi-task_learning>Multi-task Learning</a><span class=acl-fixed-case>APE</span>: Argument Pair Extraction from Peer Review and Rebuttal via Multi-task Learning</a></strong><br><a href=/people/l/liying-cheng/>Liying Cheng</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/q/qian-yu/>Qian Yu</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--569><div class="card-body p-3 small">Peer review and rebuttal, with rich interactions and argumentative discussions in between, are naturally a good resource to mine arguments. However, few works study both of <a href=https://en.wikipedia.org/wiki/List_of_Latin_phrases_(I)>them</a> simultaneously. In this paper, we introduce a new argument pair extraction (APE) task on peer review and rebuttal in order to study the contents, the structure and the connections between them. We prepare a challenging <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> that contains 4,764 fully annotated review-rebuttal passage pairs from an open review platform to facilitate the study of this task. To automatically detect argumentative propositions and extract argument pairs from this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, we cast it as the combination of a sequence labeling task and a text relation classification task. Thus, we propose a multitask learning framework based on hierarchical LSTM networks. Extensive experiments and analysis demonstrate the effectiveness of our multi-task framework, and also show the challenges of the new <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> as well as motivate future research directions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ecomnlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ecomnlp-1.0/>Proceedings of Workshop on Natural Language Processing in E-Commerce</a></strong><br><a href=/people/h/huasha-zhao/>Huasha Zhao</a>
|
<a href=/people/p/parikshit-sondhi/>Parikshit Sondhi</a>
|
<a href=/people/n/nguyen-bach/>Nguyen Bach</a>
|
<a href=/people/s/sanjika-hewavitharana/>Sanjika Hewavitharana</a>
|
<a href=/people/y/yifan-he/>Yifan He</a>
|
<a href=/people/l/luo-si/>Luo Si</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a><br><a href=/volumes/2020.ecomnlp-1/ class=text-muted>Proceedings of Workshop on Natural Language Processing in E-Commerce</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1640.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1640 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1640 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1640" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1640/>Detect Camouflaged Spam Content via StoneSkipping : Graph and Text Joint Embedding for Chinese Character Variation Representation<span class=acl-fixed-case>S</span>tone<span class=acl-fixed-case>S</span>kipping: Graph and Text Joint Embedding for <span class=acl-fixed-case>C</span>hinese Character Variation Representation</a></strong><br><a href=/people/z/zhuoren-jiang/>Zhuoren Jiang</a>
|
<a href=/people/z/zhe-gao/>Zhe Gao</a>
|
<a href=/people/g/guoxiu-he/>Guoxiu He</a>
|
<a href=/people/y/yangyang-kang/>Yangyang Kang</a>
|
<a href=/people/c/changlong-sun/>Changlong Sun</a>
|
<a href=/people/q/qiong-zhang/>Qiong Zhang</a>
|
<a href=/people/l/luo-si/>Luo Si</a>
|
<a href=/people/x/xiaozhong-liu/>Xiaozhong Liu</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1640><div class="card-body p-3 small">The task of Chinese text spam detection is very challenging due to both glyph and phonetic variations of Chinese characters. This paper proposes a novel framework to jointly model Chinese variational, semantic, and contextualized representations for Chinese text spam detection task. In particular, a Variation Family-enhanced Graph Embedding (VFGE) algorithm is designed based on a Chinese character variation graph. The VFGE can learn both the <a href=https://en.wikipedia.org/wiki/Graph_embedding>graph embeddings</a> of the Chinese characters (local) and the latent variation families (global). Furthermore, an enhanced bidirectional language model, with a combination gate function and an aggregation learning function, is proposed to integrate the graph and text information while capturing the sequential information. Extensive experiments have been conducted on both SMS and review datasets, to show the proposed method outperforms a series of state-of-the-art models for Chinese spam detection.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-2148.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S19-2148 data-toggle=collapse aria-expanded=false aria-controls=abstract-S19-2148 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-2148/>eventAI at SemEval-2019 Task 7 : Rumor Detection on <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a> by Exploiting Content, User Credibility and Propagation Information<span class=acl-fixed-case>AI</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2019 Task 7: Rumor Detection on Social Media by Exploiting Content, User Credibility and Propagation Information</a></strong><br><a href=/people/q/quanzhi-li/>Quanzhi Li</a>
|
<a href=/people/q/qiong-zhang/>Qiong Zhang</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/S19-2/ class=text-muted>Proceedings of the 13th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S19-2148><div class="card-body p-3 small">This paper describes our system for SemEval 2019 RumorEval : Determining rumor veracity and support for rumors (SemEval 2019 Task 7). This track has two tasks : Task A is to determine a user&#8217;s stance towards the source rumor, and Task B is to detect the veracity of the rumor : true, false or unverified. For stance classification, a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network model</a> with <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>language features</a> is utilized. For rumor verification, our approach exploits information from different dimensions : rumor content, source credibility, user credibility, user stance, event propagation path, etc. We use an <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble approach</a> in both tasks, which includes <a href=https://en.wikipedia.org/wiki/Neural_network>neural network models</a> as well as the traditional <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification algorithms</a>. Our system is ranked 1st place in the rumor verification task by both the macro F1 measure and the RMSE measure.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1141.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1141 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1141 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1141.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1141.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1141" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1141/>A Neural Multi-digraph Model for Chinese NER with Gazetteers<span class=acl-fixed-case>C</span>hinese <span class=acl-fixed-case>NER</span> with Gazetteers</a></strong><br><a href=/people/r/ruixue-ding/>Ruixue Ding</a>
|
<a href=/people/p/pengjun-xie/>Pengjun Xie</a>
|
<a href=/people/x/xiaoyan-zhang/>Xiaoyan Zhang</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/l/linlin-li/>Linlin Li</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1141><div class="card-body p-3 small">Gazetteers were shown to be useful resources for named entity recognition (NER). Many existing approaches to incorporating <a href=https://en.wikipedia.org/wiki/Gazetteer>gazetteers</a> into machine learning based NER systems rely on manually defined selection strategies or handcrafted templates, which may not always lead to optimal effectiveness, especially when multiple gazetteers are involved. This is especially the case for the task of Chinese NER, where the words are not naturally tokenized, leading to additional <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguities</a>. To automatically learn how to incorporate multiple <a href=https://en.wikipedia.org/wiki/Gazetteer>gazetteers</a> into an NER system, we propose a novel approach based on graph neural networks with a multi-digraph structure that captures the information that the <a href=https://en.wikipedia.org/wiki/Gazetteer>gazetteers</a> offer. Experiments on various datasets show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is effective in incorporating rich gazetteer information while resolving <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguities</a>, outperforming previous approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1229.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1229 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1229 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1229" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1229/>Semi-supervised Domain Adaptation for Dependency Parsing</a></strong><br><a href=/people/z/zhenghua-li/>Zhenghua Li</a>
|
<a href=/people/x/xue-peng/>Xue Peng</a>
|
<a href=/people/m/min-zhang/>Min Zhang</a>
|
<a href=/people/r/rui-wang/>Rui Wang</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1229><div class="card-body p-3 small">During the past decades, due to the lack of sufficient labeled data, most studies on cross-domain parsing focus on unsupervised domain adaptation, assuming there is no target-domain training data. However, <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised approaches</a> make limited progress so far due to the intrinsic difficulty of both <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> and <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a>. This paper tackles the semi-supervised domain adaptation problem for Chinese dependency parsing, based on two newly-annotated large-scale domain-aware datasets. We propose a simple domain embedding approach to merge the source- and target-domain training data, which is shown to be more effective than both direct corpus concatenation and <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a>. In order to utilize unlabeled target-domain data, we employ the recent contextualized word representations and show that a simple fine-tuning procedure can further boost cross-domain parsing accuracy by large margin.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1215.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1215 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1215 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-1215/>One vs. Many QA Matching with both Word-level and Sentence-level Attention Network<span class=acl-fixed-case>QA</span> Matching with both Word-level and Sentence-level Attention Network</a></strong><br><a href=/people/l/lu-wang/>Lu Wang</a>
|
<a href=/people/s/shoushan-li/>Shoushan Li</a>
|
<a href=/people/c/changlong-sun/>Changlong Sun</a>
|
<a href=/people/l/luo-si/>Luo Si</a>
|
<a href=/people/x/xiaozhong-liu/>Xiaozhong Liu</a>
|
<a href=/people/m/min-zhang/>Min Zhang</a>
|
<a href=/people/g/guodong-zhou/>Guodong Zhou</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1215><div class="card-body p-3 small">Question-Answer (QA) matching is a fundamental task in the Natural Language Processing community. In this paper, we first build a novel QA matching corpus with informal text which is collected from a product reviewing website. Then, we propose a novel QA matching approach, namely One vs. Many Matching, which aims to address the novel scenario where one question sentence often has an answer with multiple sentences. Furthermore, we improve our matching approach by employing both word-level and sentence-level attentions for solving the noisy problem in the informal text. Empirical studies demonstrate the effectiveness of the proposed approach to question-answer matching.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1114.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1114 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1114 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1114/>DM_NLP at SemEval-2018 Task 8 : neural sequence labeling with linguistic features<span class=acl-fixed-case>DM</span>_<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 8: neural sequence labeling with linguistic features</a></strong><br><a href=/people/c/chunping-ma/>Chunping Ma</a>
|
<a href=/people/h/huafei-zheng/>Huafei Zheng</a>
|
<a href=/people/p/pengjun-xie/>Pengjun Xie</a>
|
<a href=/people/c/chen-li/>Chen Li</a>
|
<a href=/people/l/linlin-li/>Linlin Li</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1114><div class="card-body p-3 small">This paper describes our submissions for SemEval-2018 Task 8 : Semantic Extraction from CybersecUrity REports using <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. The DM_NLP participated in two subtasks : SubTask 1 classifies if a sentence is useful for inferring malware actions and capabilities, and SubTask 2 predicts token labels (Action, Entity, Modifier and Others) for a given malware-related sentence. Since we leverage results of Subtask 2 directly to infer the result of Subtask 1, the paper focus on the system solving Subtask 2. By taking Subtask 2 as a sequence labeling task, our system relies on a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network</a> named BiLSTM-CNN-CRF with rich linguistic features, such as POS tags, dependency parsing labels, chunking labels, NER labels, Brown clustering. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieved the highest F1 score in both token level and phrase level.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1148.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1148 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1148 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1148/>NLP_HZ at SemEval-2018 Task 9 : a Nearest Neighbor Approach<span class=acl-fixed-case>NLP</span>_<span class=acl-fixed-case>HZ</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 9: a Nearest Neighbor Approach</a></strong><br><a href=/people/w/wei-qiu/>Wei Qiu</a>
|
<a href=/people/m/mosha-chen/>Mosha Chen</a>
|
<a href=/people/l/linlin-li/>Linlin Li</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1148><div class="card-body p-3 small">Hypernym discovery aims to discover the hypernym word sets given a <a href=https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy>hyponym word</a> and proper corpus. This paper proposes a simple but effective method for the discovery of hypernym sets based on <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a>, which can be used to measure the contextual similarities between words. Given a test <a href=https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy>hyponym word</a>, we get its hypernym lists by computing the similarities between the <a href=https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy>hyponym word</a> and words in the training data, and fill the test word&#8217;s hypernym lists with the hypernym list in the training set of the nearest similarity distance to the test word. In SemEval 2018 task9, our results, achieve 1st on <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, 2nd on <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a>, 6th on <a href=https://en.wikipedia.org/wiki/English_language>English</a> in the metric of MAP.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6465.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6465 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6465 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6465/>Alibaba Submission for WMT18 Quality Estimation Task<span class=acl-fixed-case>A</span>libaba Submission for <span class=acl-fixed-case>WMT</span>18 Quality Estimation Task</a></strong><br><a href=/people/j/jiayi-wang/>Jiayi Wang</a>
|
<a href=/people/k/kai-fan/>Kai Fan</a>
|
<a href=/people/b/bo-li/>Bo Li</a>
|
<a href=/people/f/fengming-zhou/>Fengming Zhou</a>
|
<a href=/people/b/boxing-chen/>Boxing Chen</a>
|
<a href=/people/y/yangbin-shi/>Yangbin Shi</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/W18-64/ class=text-muted>Proceedings of the Third Conference on Machine Translation: Shared Task Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6465><div class="card-body p-3 small">The goal of WMT 2018 Shared Task on Translation Quality Estimation is to investigate automatic methods for estimating the quality of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> results without reference translations. This paper presents the QE Brain system, which proposes the neural Bilingual Expert model as a feature extractor based on conditional target language model with a bidirectional transformer and then processes the semantic representations of source and the translation output with a Bi-LSTM predictive model for automatic quality estimation. The <a href=https://en.wikipedia.org/wiki/System>system</a> has been applied to the sentence-level scoring and ranking tasks as well as the word-level tasks for finding errors for each word in translations. An extensive set of experimental results have shown that our <a href=https://en.wikipedia.org/wiki/System>system</a> outperformed the best results in WMT 2017 Quality Estimation tasks and obtained top results in WMT 2018.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-4006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-4006 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-4006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-4006/>Alibaba at IJCNLP-2017 Task 1 : Embedding Grammatical Features into LSTMs for Chinese Grammatical Error Diagnosis Task<span class=acl-fixed-case>A</span>libaba at <span class=acl-fixed-case>IJCNLP</span>-2017 Task 1: Embedding Grammatical Features into <span class=acl-fixed-case>LSTM</span>s for <span class=acl-fixed-case>C</span>hinese Grammatical Error Diagnosis Task</a></strong><br><a href=/people/y/yi-yang/>Yi Yang</a>
|
<a href=/people/p/pengjun-xie/>Pengjun Xie</a>
|
<a href=/people/j/jun-tao/>Jun Tao</a>
|
<a href=/people/g/guangwei-xu/>Guangwei Xu</a>
|
<a href=/people/l/linlin-li/>Linlin Li</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/I17-4/ class=text-muted>Proceedings of the IJCNLP 2017, Shared Tasks</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-4006><div class="card-body p-3 small">This paper introduces Alibaba NLP team system on IJCNLP 2017 shared task No. 1 Chinese Grammatical Error Diagnosis (CGED). The task is to diagnose four types of grammatical errors which are redundant words (R), missing words (M), bad word selection (S) and disordered words (W). We treat the task as a sequence tagging problem and design some handcraft features to solve it. Our system is mainly based on the LSTM-CRF model and 3 <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble strategies</a> are applied to improve the performance. At the identification level and the position level our <a href=https://en.wikipedia.org/wiki/System>system</a> gets the highest F1 scores. At the position level, which is the most difficult level, we perform best on all metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-4016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-4016 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-4016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-4016/>Alibaba at IJCNLP-2017 Task 2 : A Boosted Deep System for Dimensional Sentiment Analysis of Chinese Phrases<span class=acl-fixed-case>A</span>libaba at <span class=acl-fixed-case>IJCNLP</span>-2017 Task 2: A Boosted Deep System for Dimensional Sentiment Analysis of <span class=acl-fixed-case>C</span>hinese Phrases</a></strong><br><a href=/people/x/xin-zhou/>Xin Zhou</a>
|
<a href=/people/j/jian-wang/>Jian Wang</a>
|
<a href=/people/x/xu-xie/>Xu Xie</a>
|
<a href=/people/c/changlong-sun/>Changlong Sun</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/I17-4/ class=text-muted>Proceedings of the IJCNLP 2017, Shared Tasks</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-4016><div class="card-body p-3 small">This paper introduces Team Alibaba&#8217;s systems participating IJCNLP 2017 shared task No. 2 Dimensional Sentiment Analysis for Chinese Phrases (DSAP). The systems mainly utilize a multi-layer neural networks, with multiple features input such as <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a>, part-of-speech-tagging (POST), word clustering, prefix type, character embedding, cross sentiment input, and AdaBoost method for model training. For word level task our best run achieved MAE 0.545 (ranked 2nd), PCC 0.892 (ranked 2nd) in valence prediction and MAE 0.857 (ranked 1st), PCC 0.678 (ranked 2nd) in arousal prediction. For average performance of word and phrase task we achieved <a href=https://en.wikipedia.org/wiki/Mean_squared_error>MAE</a> 0.5355 (ranked 3rd), <a href=https://en.wikipedia.org/wiki/Proportionality_(mathematics)>PCC</a> 0.8965 (ranked 3rd) in valence prediction and <a href=https://en.wikipedia.org/wiki/Mean_squared_error>MAE</a> 0.661 (ranked 3rd), <a href=https://en.wikipedia.org/wiki/Proportionality_(mathematics)>PCC</a> 0.766 (ranked 2nd) in arousal prediction. In the final our submitted system achieved 2nd in mean rank.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Luo+Si" title="Search for 'Luo Si' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/l/lidong-bing/ class=align-middle>Lidong Bing</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/l/liying-cheng/ class=align-middle>Liying Cheng</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/l/linlin-li/ class=align-middle>Linlin Li</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/c/changlong-sun/ class=align-middle>Changlong Sun</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/p/pengjun-xie/ class=align-middle>Pengjun Xie</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/w/wei-lu/ class=align-middle>Wei Lu</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/x/xiaozhong-liu/ class=align-middle>Xiaozhong Liu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/min-zhang/ class=align-middle>Min Zhang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/ruidan-he/ class=align-middle>Ruidan He</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/linlin-liu/ class=align-middle>Linlin Liu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/bosheng-ding/ class=align-middle>Bosheng Ding</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/f/fei-huang/ class=align-middle>Fei Huang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yan-zhang/ class=align-middle>Yan Zhang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/q/qian-yu/ class=align-middle>Qian Yu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/rui-wang/ class=align-middle>Rui Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/q/qiong-zhang/ class=align-middle>Qiong Zhang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/lu-wang/ class=align-middle>Lu Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shoushan-li/ class=align-middle>Shoushan Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/guodong-zhou/ class=align-middle>Guodong Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hai-ye/ class=align-middle>Hai Ye</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qingyu-tan/ class=align-middle>Qingyu Tan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiawei-low/ class=align-middle>Jiawei Low</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fuli-luo/ class=align-middle>Fuli Luo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wei-wang/ class=align-middle>Wei Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiahao-liu/ class=align-middle>Jiahao Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yijia-liu/ class=align-middle>Yijia Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bin-bi/ class=align-middle>Bin Bi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/songfang-huang/ class=align-middle>Songfang Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shafiq-joty/ class=align-middle>Shafiq Joty</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chunyan-miao/ class=align-middle>Chunyan Miao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tianyu-wu/ class=align-middle>Tianyu Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yi-yang/ class=align-middle>Yi Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jun-tao/ class=align-middle>Jun Tao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/guangwei-xu/ class=align-middle>Guangwei Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xin-zhou/ class=align-middle>Xin Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jian-wang/ class=align-middle>Jian Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xu-xie/ class=align-middle>Xu Xie</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dekun-wu/ class=align-middle>Dekun Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhanming-jie/ class=align-middle>Zhanming Jie</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/che-liu/ class=align-middle>Che Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jinghua-liu/ class=align-middle>Jinghua Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jian-sun/ class=align-middle>Jian Sun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhuoren-jiang/ class=align-middle>Zhuoren Jiang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhe-gao/ class=align-middle>Zhe Gao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/guoxiu-he/ class=align-middle>Guoxiu He</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yangyang-kang/ class=align-middle>Yangyang Kang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/huasha-zhao/ class=align-middle>Huasha Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/parikshit-sondhi/ class=align-middle>Parikshit Sondhi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nguyen-bach/ class=align-middle>Nguyen Bach</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sanjika-hewavitharana/ class=align-middle>Sanjika Hewavitharana</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yifan-he/ class=align-middle>Yifan He</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/heng-ji/ class=align-middle>Heng Ji</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yew-ken-chia/ class=align-middle>Yew Ken Chia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/soujanya-poria/ class=align-middle>Soujanya Poria</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/quanzhi-li/ class=align-middle>Quanzhi Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chunping-ma/ class=align-middle>Chunping Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/huafei-zheng/ class=align-middle>Huafei Zheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chen-li/ class=align-middle>Chen Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wei-qiu/ class=align-middle>Wei Qiu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mosha-chen/ class=align-middle>Mosha Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiayi-wang/ class=align-middle>Jiayi Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kai-fan/ class=align-middle>Kai Fan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bo-li/ class=align-middle>Bo Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fengming-zhou/ class=align-middle>Fengming Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/boxing-chen/ class=align-middle>Boxing Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yangbin-shi/ class=align-middle>Yangbin Shi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ruixue-ding/ class=align-middle>Ruixue Ding</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaoyan-zhang/ class=align-middle>Xiaoyan Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhenghua-li/ class=align-middle>Zhenghua Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xue-peng/ class=align-middle>Xue Peng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/ecomnlp/ class=align-middle>EcomNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>