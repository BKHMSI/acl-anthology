<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Zhiyong Lu - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Zhiyong</span> <span class=font-weight-bold>Lu</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.bionlp-1.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--bionlp-1--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.bionlp-1.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.bionlp-1.27/>Measuring the relative importance of full text sections for <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a> from <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific literature</a>.</a></strong><br><a href=/people/l/lana-yeganova/>Lana Yeganova</a>
|
<a href=/people/w/won-gyu-kim/>Won Gyu Kim</a>
|
<a href=/people/d/donald-c-comeau/>Donald Comeau</a>
|
<a href=/people/w/w-john-wilbur/>W John Wilbur</a>
|
<a href=/people/z/zhiyong-lu/>Zhiyong Lu</a><br><a href=/volumes/2021.bionlp-1/ class=text-muted>Proceedings of the 20th Workshop on Biomedical Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--bionlp-1--27><div class="card-body p-3 small">With the growing availability of full-text articles, integrating <a href=https://en.wikipedia.org/wiki/Abstract_(summary)>abstracts</a> and full texts of documents into a unified representation is essential for comprehensive search of scientific literature. However, previous studies have shown that navely merging <a href=https://en.wikipedia.org/wiki/Abstract_(summary)>abstracts</a> with full texts of articles does not consistently yield better performance. Balancing the contribution of query terms appearing in the abstract and in sections of different importance in full text articles remains a challenge both with traditional bag-of-words IR approaches and for neural retrieval methods. In this work we establish the connection between the BM25 score of a query term appearing in a section of a full text document and the probability of that document being clicked or identified as relevant. Probability is computed using Pool Adjacent Violators (PAV), an isotonic regression algorithm, providing a <a href=https://en.wikipedia.org/wiki/Maximum_likelihood_estimation>maximum likelihood estimate</a> based on the observed data. Using this probabilistic transformation of BM25 scores we show an improved performance on the PubMed Click dataset developed and presented in this study, as well as the 2007 TREC Genomics collection.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5006 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5006" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5006/>Transfer Learning in Biomedical Natural Language Processing : An Evaluation of BERT and ELMo on Ten Benchmarking Datasets<span class=acl-fixed-case>BERT</span> and <span class=acl-fixed-case>ELM</span>o on Ten Benchmarking Datasets</a></strong><br><a href=/people/y/yifan-peng/>Yifan Peng</a>
|
<a href=/people/s/shankai-yan/>Shankai Yan</a>
|
<a href=/people/z/zhiyong-lu/>Zhiyong Lu</a><br><a href=/volumes/W19-50/ class=text-muted>Proceedings of the 18th BioNLP Workshop and Shared Task</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5006><div class="card-body p-3 small">Inspired by the success of the General Language Understanding Evaluation benchmark, we introduce the Biomedical Language Understanding Evaluation (BLUE) benchmark to facilitate research in the development of pre-training language representations in the biomedicine domain. The <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark</a> consists of five tasks with ten <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> that cover both biomedical and clinical texts with different dataset sizes and difficulties. We also evaluate several baselines based on <a href=https://en.wikipedia.org/wiki/Brain-derived_neurotrophic_factor>BERT</a> and ELMo and find that the <a href=https://en.wikipedia.org/wiki/Brain-derived_neurotrophic_factor>BERT model</a> pre-trained on PubMed abstracts and MIMIC-III clinical notes achieves the best results. We make the datasets, pre-trained models, and codes publicly available at https://github.com/ ncbi-nlp / BLUE_Benchmark.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-2318.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-2318 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-2318 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-2318/>SingleCite : Towards an improved Single Citation Search in PubMed<span class=acl-fixed-case>S</span>ingle<span class=acl-fixed-case>C</span>ite: Towards an improved Single Citation Search in <span class=acl-fixed-case>P</span>ub<span class=acl-fixed-case>M</span>ed</a></strong><br><a href=/people/l/lana-yeganova/>Lana Yeganova</a>
|
<a href=/people/d/donald-c-comeau/>Donald C Comeau</a>
|
<a href=/people/w/won-kim/>Won Kim</a>
|
<a href=/people/w/w-john-wilbur/>W John Wilbur</a>
|
<a href=/people/z/zhiyong-lu/>Zhiyong Lu</a><br><a href=/volumes/W18-23/ class=text-muted>Proceedings of the BioNLP 2018 workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-2318><div class="card-body p-3 small">A <a href=https://en.wikipedia.org/wiki/Search_engine_technology>search</a> that is targeted at finding a specific document in databases is called a Single Citation search. Single citation searches are particularly important for scholarly databases, such as <a href=https://en.wikipedia.org/wiki/PubMed>PubMed</a>, because users are frequently searching for a specific publication. In this work we describe SingleCite, a single citation matching system designed to facilitate user&#8217;s search for a specific document. We report on the progress that has been achieved towards building that <a href=https://en.wikipedia.org/wiki/Function_(engineering)>functionality</a>.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2304.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2304 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2304 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2304/>Deep learning for extracting protein-protein interactions from biomedical literature</a></strong><br><a href=/people/y/yifan-peng/>Yifan Peng</a>
|
<a href=/people/z/zhiyong-lu/>Zhiyong Lu</a><br><a href=/volumes/W17-23/ class=text-muted>BioNLP 2017</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2304><div class="card-body p-3 small">State-of-the-art methods for protein-protein interaction (PPI) extraction are primarily feature-based or kernel-based by leveraging lexical and syntactic information. But how to incorporate such knowledge in the recent <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning methods</a> remains an open question. In this paper, we propose a multichannel dependency-based convolutional neural network model (McDepCNN). It applies one channel to the <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>embedding vector</a> of each word in the sentence, and another channel to the <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>embedding vector</a> of the head of the corresponding word. Therefore, the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can use richer information obtained from different channels. Experiments on two public benchmarking datasets, AIMed and BioInfer, demonstrate that McDepCNN provides up to 6 % F1-score improvement over rich feature-based methods and single-kernel methods. In addition, McDepCNN achieves 24.4 % relative improvement in <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> over the state-of-the-art methods on cross-corpus evaluation and 12 % improvement in <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> over kernel-based methods on difficult instances. These results suggest that McDepCNN generalizes more easily over different corpora, and is capable of capturing long distance features in the sentences.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2321.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2321 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2321 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2321/>BioCreative VI Precision Medicine Track : creating a training corpus for mining protein-protein interactions affected by mutations<span class=acl-fixed-case>B</span>io<span class=acl-fixed-case>C</span>reative <span class=acl-fixed-case>VI</span> Precision Medicine Track: creating a training corpus for mining protein-protein interactions affected by mutations</a></strong><br><a href=/people/r/rezarta-islamaj-dogan/>Rezarta Islamaj Doğan</a>
|
<a href=/people/a/andrew-chatr-aryamontri/>Andrew Chatr-aryamontri</a>
|
<a href=/people/s/sun-kim/>Sun Kim</a>
|
<a href=/people/c/chih-hsuan-wei/>Chih-Hsuan Wei</a>
|
<a href=/people/y/yifan-peng/>Yifan Peng</a>
|
<a href=/people/d/donald-c-comeau/>Donald Comeau</a>
|
<a href=/people/z/zhiyong-lu/>Zhiyong Lu</a><br><a href=/volumes/W17-23/ class=text-muted>BioNLP 2017</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2321><div class="card-body p-3 small">The Precision Medicine Track in BioCre-ative VI aims to bring together the Bi-oNLP community for a novel challenge focused on mining the biomedical litera-ture in search of mutations and protein-protein interactions (PPI). In order to support this track with an effective train-ing dataset with limited curator time, the track organizers carefully reviewed Pub-Med articles from two different sources : curated public PPI databases, and the re-sults of state-of-the-art public text mining tools. We detail here the <a href=https://en.wikipedia.org/wiki/Data_collection>data collection</a>, manual review and annotation process and describe this training corpus charac-teristics. We also describe a corpus per-formance baseline. This analysis will provide useful information to developers and researchers for comparing and devel-oping innovative text mining approaches for the BioCreative VI challenge and other Precision Medicine related applica-tions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2328.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2328 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2328 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2328/>Deep Learning for Biomedical Information Retrieval : Learning Textual Relevance from Click Logs</a></strong><br><a href=/people/s/sunil-mohan/>Sunil Mohan</a>
|
<a href=/people/n/nicolas-fiorini/>Nicolas Fiorini</a>
|
<a href=/people/s/sun-kim/>Sun Kim</a>
|
<a href=/people/z/zhiyong-lu/>Zhiyong Lu</a><br><a href=/volumes/W17-23/ class=text-muted>BioNLP 2017</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2328><div class="card-body p-3 small">We describe a Deep Learning approach to modeling the relevance of a document&#8217;s text to a query, applied to biomedical literature. Instead of mapping each document and query to a common semantic space, we compute a variable-length difference vector between the query and document which is then passed through a deep convolution stage followed by a deep regression network to produce the estimated probability of the document&#8217;s relevance to the query. Despite the small amount of training data, this approach produces a more robust predictor than computing similarities between semantic vector representations of the query and document, and also results in significant improvements over traditional IR text factors. In the future, we plan to explore its application in improving <a href=https://en.wikipedia.org/wiki/PubMed>PubMed search</a>.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Zhiyong+Lu" title="Search for 'Zhiyong Lu' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/y/yifan-peng/ class=align-middle>Yifan Peng</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/d/donald-c-comeau/ class=align-middle>Donald C. Comeau</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/sun-kim/ class=align-middle>Sun Kim</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/lana-yeganova/ class=align-middle>Lana Yeganova</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/w/w-john-wilbur/ class=align-middle>W John Wilbur</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/r/rezarta-islamaj-dogan/ class=align-middle>Rezarta Islamaj Dogan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrew-chatr-aryamontri/ class=align-middle>Andrew Chatr-aryamontri</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chih-hsuan-wei/ class=align-middle>Chih-Hsuan Wei</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sunil-mohan/ class=align-middle>Sunil Mohan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nicolas-fiorini/ class=align-middle>Nicolas Fiorini</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/won-kim/ class=align-middle>Won Kim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shankai-yan/ class=align-middle>Shankai Yan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/won-gyu-kim/ class=align-middle>Won Gyu Kim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/bionlp/ class=align-middle>BioNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>