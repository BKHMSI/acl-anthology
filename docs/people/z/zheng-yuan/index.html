<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Zheng Yuan - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Zheng</span> <span class=font-weight-bold>Yuan</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.687.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--687 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.687 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.687/>Multi-Class Grammatical Error Detection for Correction : A Tale of Two Systems<span class=acl-fixed-case>M</span>ulti-Class Grammatical Error Detection for Correction: <span class=acl-fixed-case>A</span> Tale of Two Systems</a></strong><br><a href=/people/z/zheng-yuan/>Zheng Yuan</a>
|
<a href=/people/s/shiva-taslimipoor/>Shiva Taslimipoor</a>
|
<a href=/people/c/christopher-davis/>Christopher Davis</a>
|
<a href=/people/c/christopher-bryant/>Christopher Bryant</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--687><div class="card-body p-3 small">In this paper, we show how a multi-class grammatical error detection (GED) system can be used to improve grammatical error correction (GEC) for <a href=https://en.wikipedia.org/wiki/English_language>English</a>. Specifically, we first develop a new state-of-the-art binary detection system based on pre-trained ELECTRA, and then extend it to multi-class detection using different error type tagsets derived from the ERRANT framework. Output from this detection system is used as auxiliary input to fine-tune a novel encoder-decoder GEC model, and we subsequently re-rank the N-best GEC output to find the hypothesis that most agrees with the GED output. Results show that fine-tuning the GEC system using 4-class GED produces the best model, but re-ranking using 55-class GED leads to the best performance overall. This suggests that different multi-class GED systems benefit GEC in different ways. Ultimately, our system outperforms all other previous work that combines <a href=https://en.wikipedia.org/wiki/General_Educational_Development>GED</a> and GEC, and achieves a new single-model NMT-based state of the art on the BEA-test benchmark.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.96.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--96 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.96 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.96/>Cambridge at SemEval-2021 Task 2 : Neural WiC-Model with Data Augmentation and Exploration of Representation<span class=acl-fixed-case>C</span>ambridge at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 2: Neural <span class=acl-fixed-case>W</span>i<span class=acl-fixed-case>C</span>-Model with Data Augmentation and Exploration of Representation</a></strong><br><a href=/people/z/zheng-yuan/>Zheng Yuan</a>
|
<a href=/people/d/david-strohmaier/>David Strohmaier</a><br><a href=/volumes/2021.semeval-1/ class=text-muted>Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--96><div class="card-body p-3 small">This paper describes the system of the Cambridge team submitted to the SemEval-2021 shared task on Multilingual and Cross-lingual Word-in-Context Disambiguation. Building on top of a pre-trained masked language model, our system is first pre-trained on out-of-domain data, and then fine-tuned on in-domain data. We demonstrate the effectiveness of the proposed two-step training strategy and the benefits of <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> from both existing examples and new resources. We further investigate different <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> and show that the addition of distance-based features is helpful in the word-in-context disambiguation task. Our system yields highly competitive results in the cross-lingual track without training on any cross-lingual data ; and achieves state-of-the-art results in the multilingual track, ranking first in two languages (Arabic and Russian) and second in <a href=https://en.wikipedia.org/wiki/French_language>French</a> out of 171 submitted systems.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4424.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4424 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4424 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4424/>Neural and FST-based approaches to grammatical error correction<span class=acl-fixed-case>FST</span>-based approaches to grammatical error correction</a></strong><br><a href=/people/z/zheng-yuan/>Zheng Yuan</a>
|
<a href=/people/f/felix-stahlberg/>Felix Stahlberg</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/b/bill-byrne/>Bill Byrne</a>
|
<a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a><br><a href=/volumes/W19-44/ class=text-muted>Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4424><div class="card-body p-3 small">In this paper, we describe our submission to the BEA 2019 shared task on grammatical error correction. We present a <a href=https://en.wikipedia.org/wiki/Pipeline_(computing)>system pipeline</a> that utilises both <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error detection and correction models</a>. The input text is first corrected by two complementary neural machine translation systems : one using convolutional networks and <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a>, and another using a neural Transformer-based system. Training is performed on publicly available data, along with artificial examples generated through <a href=https://en.wikipedia.org/wiki/Back-translation>back-translation</a>. The n-best lists of these two <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation systems</a> are then combined and scored using a <a href=https://en.wikipedia.org/wiki/Finite-state_transducer>finite state transducer (FST)</a>. Finally, an unsupervised re-ranking system is applied to the n-best output of the <a href=https://en.wikipedia.org/wiki/Finite-state_machine>FST</a>. The re-ranker uses a number of <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error detection features</a> to re-rank the FST n-best list and identify the final 1-best correction hypothesis. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves 66.75 % F 0.5 on error correction (ranking 4th), and 82.52 % F 0.5 on token-level error detection (ranking 2nd) in the restricted track of the shared task.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-0547.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-0547 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-0547 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-0547/>Neural sequence modelling for learner error prediction</a></strong><br><a href=/people/z/zheng-yuan/>Zheng Yuan</a><br><a href=/volumes/W18-05/ class=text-muted>Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-0547><div class="card-body p-3 small">This paper describes our use of two recurrent neural network sequence models : sequence labelling and sequence-to-sequence models, for the prediction of future learner errors in our submission to the 2018 Duolingo Shared Task on Second Language Acquisition Modeling (SLAM). We show that these two <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> capture complementary information as combining them improves performance. Furthermore, the same network architecture and group of features can be used directly to build competitive prediction models in all three language tracks, demonstrating that our approach generalises well across languages.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5032.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5032 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5032 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5032/>Artificial Error Generation with Machine Translation and Syntactic Patterns</a></strong><br><a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/m/mariano-felice/>Mariano Felice</a>
|
<a href=/people/z/zheng-yuan/>Zheng Yuan</a>
|
<a href=/people/t/ted-briscoe/>Ted Briscoe</a><br><a href=/volumes/W17-50/ class=text-muted>Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5032><div class="card-body p-3 small">Shortage of available training data is holding back progress in the area of automated error detection. This paper investigates two alternative methods for artificially generating writing errors, in order to create additional resources. We propose treating error generation as a machine translation task, where grammatically correct text is translated to contain errors. In addition, we explore a system for extracting textual patterns from an annotated corpus, which can then be used to insert <a href=https://en.wikipedia.org/wiki/Error_(linguistics)>errors</a> into grammatically correct sentences. Our experiments show that the inclusion of <a href=https://en.wikipedia.org/wiki/Errors-in-variables_models>artificially generated errors</a> significantly improves <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error detection accuracy</a> on both FCE and CoNLL 2014 datasets.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Zheng+Yuan" title="Search for 'Zheng Yuan' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/m/marek-rei/ class=align-middle>Marek Rei</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mariano-felice/ class=align-middle>Mariano Felice</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/ted-briscoe/ class=align-middle>Ted Briscoe</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shiva-taslimipoor/ class=align-middle>Shiva Taslimipoor</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christopher-davis/ class=align-middle>Christopher Davis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/c/christopher-bryant/ class=align-middle>Christopher Bryant</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/felix-stahlberg/ class=align-middle>Felix Stahlberg</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bill-byrne/ class=align-middle>Bill Byrne</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/helen-yannakoudakis/ class=align-middle>Helen Yannakoudakis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/david-strohmaier/ class=align-middle>David Strohmaier</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>