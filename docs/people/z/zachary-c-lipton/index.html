<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Zachary C. Lipton - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Zachary C.</span> <span class=font-weight-bold>Lipton</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Zachary <span class=font-weight-normal>Lipton</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.384.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--384 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.384 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.384/>Generating SOAP Notes from Doctor-Patient Conversations Using Modular Summarization Techniques<span class=acl-fixed-case>SOAP</span> Notes from Doctor-Patient Conversations Using Modular Summarization Techniques</a></strong><br><a href=/people/k/kundan-krishna/>Kundan Krishna</a>
|
<a href=/people/s/sopan-khosla/>Sopan Khosla</a>
|
<a href=/people/j/jeffrey-p-bigham/>Jeffrey Bigham</a>
|
<a href=/people/z/zachary-c-lipton/>Zachary C. Lipton</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--384><div class="card-body p-3 small">Following each patient visit, physicians draft long semi-structured clinical summaries called <a href=https://en.wikipedia.org/wiki/SOAP_notes>SOAP notes</a>. While invaluable to clinicians and researchers, creating digital SOAP notes is burdensome, contributing to physician burnout. In this paper, we introduce the first complete <a href=https://en.wikipedia.org/wiki/Pipeline_transport>pipelines</a> to leverage deep summarization models to generate these notes based on transcripts of conversations between physicians and patients. After exploring a spectrum of methods across the extractive-abstractive spectrum, we propose Cluster2Sent, an <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> that (i) extracts important utterances relevant to each summary section ; (ii) clusters together related utterances ; and then (iii) generates one summary sentence per cluster. Cluster2Sent outperforms its purely abstractive counterpart by 8 ROUGE-1 points, and produces significantly more factual and coherent sentences as assessed by expert human evaluators. For <a href=https://en.wikipedia.org/wiki/Reproducibility>reproducibility</a>, we demonstrate similar benefits on the publicly available AMI dataset. Our results speak to the benefits of structuring summaries into sections and annotating supporting evidence when constructing summarization corpora.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.517.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--517 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.517 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.517" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.517/>On the Efficacy of Adversarial Data Collection for <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a> : Results from a Large-Scale Randomized Study</a></strong><br><a href=/people/d/divyansh-kaushik/>Divyansh Kaushik</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/z/zachary-c-lipton/>Zachary C. Lipton</a>
|
<a href=/people/w/wen-tau-yih/>Wen-tau Yih</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--517><div class="card-body p-3 small">In adversarial data collection (ADC), a human workforce interacts with a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in real time, attempting to produce examples that elicit incorrect predictions. Researchers hope that <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> trained on these more challenging <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> will rely less on superficial patterns, and thus be less brittle. However, despite ADC&#8217;s intuitive appeal, it remains unclear when training on adversarial datasets produces more robust models. In this paper, we conduct a large-scale controlled study focused on <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>, assigning workers at random to compose questions either (i) adversarially (with a model in the loop) ; or (ii) in the standard fashion (without a model). Across a variety of <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> and datasets, we find that <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on adversarial data usually perform better on other adversarial datasets but worse on a diverse collection of out-of-domain evaluation sets. Finally, we provide a qualitative analysis of adversarial (vs standard) data, identifying key differences and offering guidance for future research.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1003 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1003.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-1003/>Practical Obstacles to Deploying <a href=https://en.wikipedia.org/wiki/Active_learning>Active Learning</a></a></strong><br><a href=/people/d/david-lowell/>David Lowell</a>
|
<a href=/people/z/zachary-c-lipton/>Zachary C. Lipton</a>
|
<a href=/people/b/byron-c-wallace/>Byron C. Wallace</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1003><div class="card-body p-3 small">Active learning (AL) is a widely-used <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training strategy</a> for maximizing predictive performance subject to a fixed annotation budget. In AL, one iteratively selects training examples for annotation, often those for which the current <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> is most uncertain (by some measure). The hope is that active sampling leads to better performance than would be achieved under independent and identically distributed (i.i.d.) random samples. While AL has shown promise in retrospective evaluations, these studies often ignore practical obstacles to its use. In this paper, we show that while AL may provide benefits when used with specific <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> and for particular domains, the benefits of current approaches do not generalize reliably across models and tasks. This is problematic because in practice, one does not have the opportunity to explore and compare alternative <a href=https://en.wikipedia.org/wiki/Strategy_(game_theory)>AL strategies</a>. Moreover, AL couples the training dataset with the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> used to guide its acquisition. We find that subsequently training a successor model with an actively-acquired dataset does not consistently outperform training on i.i.d. sampled data. Our findings raise the question of whether the downsides inherent to AL are worth the modest and inconsistent performance gains it tends to afford.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1561.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1561 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1561 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1561" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1561/>Combating Adversarial Misspellings with Robust Word Recognition</a></strong><br><a href=/people/d/danish-pruthi/>Danish Pruthi</a>
|
<a href=/people/b/bhuwan-dhingra/>Bhuwan Dhingra</a>
|
<a href=/people/z/zachary-c-lipton/>Zachary C. Lipton</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1561><div class="card-body p-3 small">To combat adversarial spelling mistakes, we propose placing a word recognition model in front of the downstream classifier. Our word recognition models build upon the RNN semi-character architecture, introducing several new backoff strategies for handling rare and unseen words. Trained to recognize words corrupted by random adds, drops, swaps, and keyboard mistakes, our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> achieves 32 % relative (and 3.3 % absolute) <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error reduction</a> over the vanilla semi-character model. Notably, our pipeline confers <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> on the downstream classifier, outperforming both adversarial training and off-the-shelf <a href=https://en.wikipedia.org/wiki/Spell_checker>spell checkers</a>. Against a <a href=https://en.wikipedia.org/wiki/Boolean_satisfiability_problem>BERT model</a> fine-tuned for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, a single adversarially-chosen character attack lowers <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> from 90.3 % to 45.8 %. Our defense restores <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> to 75 %. Surprisingly, better <a href=https://en.wikipedia.org/wiki/Word_recognition>word recognition</a> does not always entail greater <a href=https://en.wikipedia.org/wiki/Robustness_(morphology)>robustness</a>. Our analysis reveals that robustness also depends upon a quantity that we denote the <a href=https://en.wikipedia.org/wiki/Sensitivity_and_specificity>sensitivity</a>.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1318.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1318 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1318 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1318/>Deep Bayesian Active Learning for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a> : Results of a Large-Scale Empirical Study<span class=acl-fixed-case>B</span>ayesian Active Learning for Natural Language Processing: Results of a Large-Scale Empirical Study</a></strong><br><a href=/people/a/aditya-siddhant/>Aditya Siddhant</a>
|
<a href=/people/z/zachary-c-lipton/>Zachary C. Lipton</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1318><div class="card-body p-3 small">Several recent papers investigate Active Learning (AL) for mitigating the <a href=https://en.wikipedia.org/wiki/Data_dependence>data dependence</a> of <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. However, the applicability of AL to real-world problems remains an open question. While in <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised learning</a>, practitioners can try many different methods, evaluating each against a validation set before selecting a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>, AL affords no such luxury. Over the course of one AL run, an agent annotates its dataset exhausting its labeling budget. Thus, given a new <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, we have no opportunity to compare <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> and acquisition functions. This paper provides a large-scale empirical study of deep active learning, addressing multiple tasks and, for each, multiple datasets, multiple models, and a full suite of acquisition functions. We find that across all settings, Bayesian active learning by disagreement, using uncertainty estimates provided either by Dropout or <a href=https://en.wikipedia.org/wiki/Bayes&#8217;_rule>Bayes-by-Backprop</a> significantly improves over i.i.d. baselines and usually outperforms classic uncertainty sampling.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1546.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1546 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1546 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/306140720 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1546/>How Much Reading Does Reading Comprehension Require? A Critical Investigation of Popular Benchmarks</a></strong><br><a href=/people/d/divyansh-kaushik/>Divyansh Kaushik</a>
|
<a href=/people/z/zachary-c-lipton/>Zachary C. Lipton</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1546><div class="card-body p-3 small">Many recent papers address <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>, where examples consist of (question, passage, answer) tuples. Presumably, a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> must combine information from both questions and passages to predict corresponding answers. However, despite intense interest in the topic, with hundreds of published papers vying for leaderboard dominance, basic questions about the difficulty of many popular benchmarks remain unanswered. In this paper, we establish sensible baselines for the bAbI, SQuAD, CBT, CNN, and Who-did-What datasets, finding that question- and passage-only models often perform surprisingly well. On 14 out of 20 bAbI tasks, passage-only models achieve greater than 50 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, sometimes matching the full <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. Interestingly, while <a href=https://en.wikipedia.org/wiki/Cognitive_behavioral_therapy>CBT</a> provides 20-sentence passages, only the last is needed for accurate prediction. By comparison, SQuAD and <a href=https://en.wikipedia.org/wiki/CNN>CNN</a> appear better-constructed.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2630.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2630 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2630 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-2630" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-2630/>Deep Active Learning for Named Entity Recognition</a></strong><br><a href=/people/y/yanyao-shen/>Yanyao Shen</a>
|
<a href=/people/h/hyokun-yun/>Hyokun Yun</a>
|
<a href=/people/z/zachary-c-lipton/>Zachary Lipton</a>
|
<a href=/people/y/yakov-kronrod/>Yakov Kronrod</a>
|
<a href=/people/a/animashree-anandkumar/>Animashree Anandkumar</a><br><a href=/volumes/W17-26/ class=text-muted>Proceedings of the 2nd Workshop on Representation Learning for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2630><div class="card-body p-3 small">Deep neural networks have advanced the state of the art in <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>. However, under typical <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training procedures</a>, advantages over <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>classical methods</a> emerge only with <a href=https://en.wikipedia.org/wiki/Data_set>large datasets</a>. As a result, <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> is employed only when large public datasets or a large budget for manually labeling data is available. In this work, we show otherwise : by combining <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> with active learning, we can outperform classical methods even with a significantly smaller amount of training data.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Zachary+C.+Lipton" title="Search for 'Zachary C. Lipton' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/d/divyansh-kaushik/ class=align-middle>Divyansh Kaushik</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/kundan-krishna/ class=align-middle>Kundan Krishna</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sopan-khosla/ class=align-middle>Sopan Khosla</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jeffrey-p-bigham/ class=align-middle>Jeffrey P. Bigham</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/douwe-kiela/ class=align-middle>Douwe Kiela</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/w/wen-tau-yih/ class=align-middle>Wen-tau Yih</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yanyao-shen/ class=align-middle>Yanyao Shen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hyokun-yun/ class=align-middle>Hyokun Yun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yakov-kronrod/ class=align-middle>Yakov Kronrod</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/animashree-anandkumar/ class=align-middle>Animashree Anandkumar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aditya-siddhant/ class=align-middle>Aditya Siddhant</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/david-lowell/ class=align-middle>David Lowell</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/byron-c-wallace/ class=align-middle>Byron C. Wallace</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/danish-pruthi/ class=align-middle>Danish Pruthi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bhuwan-dhingra/ class=align-middle>Bhuwan Dhingra</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>