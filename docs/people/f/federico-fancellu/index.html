<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Federico Fancellu - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Federico</span> <span class=font-weight-bold>Fancellu</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.blackboxnlp-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--blackboxnlp-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.blackboxnlp-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.blackboxnlp-1.21/>An in-depth look at Euclidean disk embeddings for structure preserving parsing<span class=acl-fixed-case>E</span>uclidean disk embeddings for structure preserving parsing</a></strong><br><a href=/people/f/federico-fancellu/>Federico Fancellu</a>
|
<a href=/people/l/lan-xiao/>Lan Xiao</a>
|
<a href=/people/a/allan-jepson/>Allan Jepson</a>
|
<a href=/people/a/afsaneh-fazly/>Afsaneh Fazly</a><br><a href=/volumes/2021.blackboxnlp-1/ class=text-muted>Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--blackboxnlp-1--21><div class="card-body p-3 small">Preserving the structural properties of trees or graphs when embedding them into a <a href=https://en.wikipedia.org/wiki/Metric_space>metric space</a> allows for a high degree of <a href=https://en.wikipedia.org/wiki/Interpretability>interpretability</a>, and has been shown beneficial for <a href=https://en.wikipedia.org/wiki/Downstream_(computer_science)>downstream tasks</a> (e.g., hypernym detection, natural language inference, multimodal retrieval). However, whereas the majority of prior work looks at using structure-preserving embeddings when encoding a <a href=https://en.wikipedia.org/wiki/Structure>structure</a> given as input, e.g., <a href=https://en.wikipedia.org/wiki/WordNet>WordNet</a> (Fellbaum, 1998), there is little exploration on how to use such <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> when predicting one. We address this gap for two structure generation tasks, namely dependency and semantic parsing. We test the applicability of disk embeddings (Suzuki et al., 2019) that has been proposed for embedding Directed Acyclic Graphs (DAGs) but has not been tested on tasks that generate such structures. Our experimental results show that for both tasks the original disk embedding formulation leads to much worse performance when compared to non-structure-preserving baselines. We propose enhancements to this formulation and show that they almost close the performance gap for dependency parsing. However, the gap still remains notable for <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> due to the complexity of meaning representation graphs, suggesting a challenge for generating interpretable semantic parse representations.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1804.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1804 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1804 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1804/>Universal Dependencies to <a href=https://en.wikipedia.org/wiki/Logical_form>Logical Form</a> with Negation Scope<span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependencies to Logical Form with Negation Scope</a></strong><br><a href=/people/f/federico-fancellu/>Federico Fancellu</a>
|
<a href=/people/s/siva-reddy/>Siva Reddy</a>
|
<a href=/people/a/adam-lopez/>Adam Lopez</a>
|
<a href=/people/b/bonnie-webber/>Bonnie Webber</a><br><a href=/volumes/W17-18/ class=text-muted>Proceedings of the Workshop Computational Semantics Beyond Events and Roles</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1804><div class="card-body p-3 small">Many language technology applications would benefit from the ability to represent <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>negation</a> and its scope on top of widely-used linguistic resources. In this paper, we investigate the possibility of obtaining a <a href=https://en.wikipedia.org/wiki/First-order_logic>first-order logic representation</a> with <a href=https://en.wikipedia.org/wiki/Scope_(computer_science)>negation scope</a> marked using Universal Dependencies. To do so, we enhance UDepLambda, a <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> that converts <a href=https://en.wikipedia.org/wiki/Dependency_graph>dependency graphs</a> to <a href=https://en.wikipedia.org/wiki/Logical_form>logical forms</a>. The resulting UDepLambda is able to handle phenomena related to scope by means of an higher-order type theory, relevant not only to <a href=https://en.wikipedia.org/wiki/Negation>negation</a> but also to <a href=https://en.wikipedia.org/wiki/Universal_quantification>universal quantification</a> and other complex semantic phenomena. The initial conversion we did for <a href=https://en.wikipedia.org/wiki/English_language>English</a> is promising, in that one can represent the scope of negation also in the presence of more complex phenomena such as <a href=https://en.wikipedia.org/wiki/Universal_quantification>universal quantifiers</a>.<i>Universal Dependencies</i>. To do so, we enhance <i>UDepLambda</i>, a framework that converts dependency graphs to logical forms. The resulting <i>UDepLambda<tex-math>\\lnot</tex-math>\n </i>\n\nis able to handle phenomena related to scope by means of an higher-order type theory, relevant not only to negation but also to universal quantification and other complex semantic phenomena. The initial conversion we did for English is promising, in that one can represent the scope of negation also in the presence of more complex phenomena such as universal quantifiers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-2010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-2010 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-2010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-2010/>Detecting negation scope is easy, except when it is n’t</a></strong><br><a href=/people/f/federico-fancellu/>Federico Fancellu</a>
|
<a href=/people/a/adam-lopez/>Adam Lopez</a>
|
<a href=/people/b/bonnie-webber/>Bonnie Webber</a>
|
<a href=/people/h/hangfeng-he/>Hangfeng He</a><br><a href=/volumes/E17-2/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-2010><div class="card-body p-3 small">Several <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a> have been annotated with negation scopethe set of words whose meaning is negated by a cue like the word notleading to the development of <a href=https://en.wikipedia.org/wiki/Classifier_(linguistics)>classifiers</a> that detect negation scope with high accuracy. We show that for nearly all of these corpora, this high accuracy can be attributed to a single fact : they frequently annotate negation scope as a single span of text delimited by <a href=https://en.wikipedia.org/wiki/Punctuation>punctuation</a>. For negation scopes not of this form, detection accuracy is low and under-sampling the easy training examples does not substantially improve <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. We demonstrate that this is partly an artifact of annotation guidelines, and we argue that future negation scope annotation efforts should focus on these more difficult cases.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Federico+Fancellu" title="Search for 'Federico Fancellu' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/a/adam-lopez/ class=align-middle>Adam Lopez</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/bonnie-webber/ class=align-middle>Bonnie Webber</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/siva-reddy/ class=align-middle>Siva Reddy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lan-xiao/ class=align-middle>Lan Xiao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/allan-jepson/ class=align-middle>Allan Jepson</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/a/afsaneh-fazly/ class=align-middle>Afsaneh Fazly</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hangfeng-he/ class=align-middle>Hangfeng He</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/blackboxnlp/ class=align-middle>BlackboxNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>