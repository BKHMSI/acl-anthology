<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Fei Wu - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Fei</span> <span class=font-weight-bold>Wu</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.483.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--483 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.483 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.483" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.483/>CIL : Contrastive Instance Learning Framework for Distantly Supervised Relation Extraction<span class=acl-fixed-case>CIL</span>: Contrastive Instance Learning Framework for Distantly Supervised Relation Extraction</a></strong><br><a href=/people/t/tao-chen/>Tao Chen</a>
|
<a href=/people/h/haizhou-shi/>Haizhou Shi</a>
|
<a href=/people/s/siliang-tang/>Siliang Tang</a>
|
<a href=/people/z/zhigang-chen/>Zhigang Chen</a>
|
<a href=/people/f/fei-wu/>Fei Wu</a>
|
<a href=/people/y/yueting-zhuang/>Yueting Zhuang</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--483><div class="card-body p-3 small">The journey of reducing noise from distant supervision (DS) generated training data has been started since the DS was first introduced into the relation extraction (RE) task. For the past decade, researchers apply the multi-instance learning (MIL) framework to find the most reliable <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature</a> from a bag of sentences. Although the pattern of MIL bags can greatly reduce DS noise, it fails to represent many other useful <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence features</a> in the datasets. In many cases, these sentence features can only be acquired by extra sentence-level human annotation with heavy costs. Therefore, the performance of distantly supervised RE models is bounded. In this paper, we go beyond typical MIL framework and propose a novel contrastive instance learning (CIL) framework. Specifically, we regard the initial MIL as the relational triple encoder and constraint positive pairs against negative pairs for each instance. Experiments demonstrate the effectiveness of our proposed framework, with significant improvements over the previous methods on NYT10, GDS and KBP.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.199.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--199 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.199 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.199/>ConRPG : <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>Paraphrase Generation</a> using Contexts as Regularizer<span class=acl-fixed-case>C</span>on<span class=acl-fixed-case>RPG</span>: Paraphrase Generation using Contexts as Regularizer</a></strong><br><a href=/people/y/yuxian-meng/>Yuxian Meng</a>
|
<a href=/people/x/xiang-ao/>Xiang Ao</a>
|
<a href=/people/q/qing-he/>Qing He</a>
|
<a href=/people/x/xiaofei-sun/>Xiaofei Sun</a>
|
<a href=/people/q/qinghong-han/>Qinghong Han</a>
|
<a href=/people/f/fei-wu/>Fei Wu</a>
|
<a href=/people/c/chun-fan/>Chun Fan</a>
|
<a href=/people/j/jiwei-li/>Jiwei Li</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--199><div class="card-body p-3 small">A long-standing issue with <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a> is the lack of reliable supervision signals. In this paper, we propose a new <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised paradigm</a> for <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a> based on the assumption that the probabilities of generating two sentences with the same meaning given the same context should be the same. Inspired by this fundamental idea, we propose a pipelined system which consists of paraphrase candidate generation based on contextual language models, candidate filtering using scoring functions, and paraphrase model training based on the selected candidates. The proposed paradigm offers merits over existing paraphrase generation methods : (1) using the context regularizer on meanings, the model is able to generate massive amounts of high-quality paraphrase pairs ; (2) the combination of the huge amount of paraphrase candidates and further diversity-promoting filtering yields paraphrases with more lexical and syntactic diversity ; and (3) using human-interpretable scoring functions to select paraphrase pairs from candidates, the proposed framework provides a channel for developers to intervene with the data generation process, leading to a more controllable model. Experimental results across different tasks and datasets demonstrate that the proposed <a href=https://en.wikipedia.org/wiki/Paradigm>paradigm</a> significantly outperforms existing paraphrase approaches in both supervised and unsupervised setups.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.246.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--246 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.246 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.246/>Layer-wise Model Pruning based on <a href=https://en.wikipedia.org/wiki/Mutual_information>Mutual Information</a></a></strong><br><a href=/people/c/chun-fan/>Chun Fan</a>
|
<a href=/people/j/jiwei-li/>Jiwei Li</a>
|
<a href=/people/t/tianwei-zhang/>Tianwei Zhang</a>
|
<a href=/people/x/xiang-ao/>Xiang Ao</a>
|
<a href=/people/f/fei-wu/>Fei Wu</a>
|
<a href=/people/y/yuxian-meng/>Yuxian Meng</a>
|
<a href=/people/x/xiaofei-sun/>Xiaofei Sun</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--246><div class="card-body p-3 small">Inspired by mutual information (MI) based feature selection in SVMs and <a href=https://en.wikipedia.org/wiki/Logistic_regression>logistic regression</a>, in this paper, we propose MI-based layer-wise pruning : for each layer of a multi-layer neural network, neurons with higher values of MI with respect to preserved neurons in the upper layer are preserved. Starting from the top softmax layer, layer-wise pruning proceeds in a top-down fashion until reaching the bottom word embedding layer. The proposed pruning strategy offers merits over weight-based pruning techniques : (1) it avoids irregular memory access since representations and matrices can be squeezed into their smaller but dense counterparts, leading to greater speedup ; (2) in a manner of top-down pruning, the proposed method operates from a more global perspective based on training signals in the top layer, and prunes each layer by propagating the effect of global signals through layers, leading to better performances at the same sparsity level. Extensive experiments show that at the same sparsity level, the proposed strategy offers both greater speedup and higher performances than weight-based pruning methods (e.g., magnitude pruning, movement pruning).</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1026.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1026 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1026 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1026.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1026" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1026/>Learning Dynamic Context Augmentation for Global Entity Linking</a></strong><br><a href=/people/x/xiyuan-yang/>Xiyuan Yang</a>
|
<a href=/people/x/xiaotao-gu/>Xiaotao Gu</a>
|
<a href=/people/s/sheng-lin/>Sheng Lin</a>
|
<a href=/people/s/siliang-tang/>Siliang Tang</a>
|
<a href=/people/y/yueting-zhuang/>Yueting Zhuang</a>
|
<a href=/people/f/fei-wu/>Fei Wu</a>
|
<a href=/people/z/zhigang-chen/>Zhigang Chen</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a>
|
<a href=/people/x/xiang-ren/>Xiang Ren</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1026><div class="card-body p-3 small">Despite of the recent success of collective entity linking (EL) methods, these global inference methods may yield sub-optimal results when the all-mention coherence assumption breaks, and often suffer from high computational cost at the inference stage, due to the complex search space. In this paper, we propose a simple yet effective solution, called Dynamic Context Augmentation (DCA), for collective EL, which requires only one pass through the mentions in a document. DCA sequentially accumulates context information to make efficient, collective inference, and can cope with different local EL models as a plug-and-enhance module. We explore both supervised and reinforcement learning strategies for learning the DCA model. Extensive experiments show the effectiveness of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> with different learning settings, base models, <a href=https://en.wikipedia.org/wiki/Decision-making>decision orders</a> and <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanisms</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1290.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1290 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1290 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-1290/>Posterior-regularized REINFORCE for Instance Selection in Distant Supervision<span class=acl-fixed-case>REINFORCE</span> for Instance Selection in Distant Supervision</a></strong><br><a href=/people/q/qi-zhang/>Qi Zhang</a>
|
<a href=/people/s/siliang-tang/>Siliang Tang</a>
|
<a href=/people/x/xiang-ren/>Xiang Ren</a>
|
<a href=/people/f/fei-wu/>Fei Wu</a>
|
<a href=/people/s/shiliang-pu/>Shiliang Pu</a>
|
<a href=/people/y/yueting-zhuang/>Yueting Zhuang</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1290><div class="card-body p-3 small">This paper provides a new way to improve the efficiency of the REINFORCE training process. We apply <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> to the task of <a href=https://en.wikipedia.org/wiki/Instance_selection>instance selection</a> in distant supervision. Modeling the instance selection in one bag as a sequential decision process, a reinforcement learning agent is trained to determine whether an instance is valuable or not and construct a new bag with less noisy instances. However <a href=https://en.wikipedia.org/wiki/Bias_(statistics)>unbiased methods</a>, such as REINFORCE, could usually take much time to train. This paper adopts posterior regularization (PR) to integrate some domain-specific rules in instance selection using REINFORCE. As the experiment results show, this method remarkably improves the performance of the relation classifier trained on cleaned distant supervision dataset as well as the efficiency of the REINFORCE training.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-3017.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-3017 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-3017 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-3017" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-3017/>KCAT : A Knowledge-Constraint Typing Annotation Tool<span class=acl-fixed-case>KCAT</span>: A Knowledge-Constraint Typing Annotation Tool</a></strong><br><a href=/people/s/sheng-lin/>Sheng Lin</a>
|
<a href=/people/l/luye-zheng/>Luye Zheng</a>
|
<a href=/people/b/bo-chen/>Bo Chen</a>
|
<a href=/people/s/siliang-tang/>Siliang Tang</a>
|
<a href=/people/z/zhigang-chen/>Zhigang Chen</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a>
|
<a href=/people/y/yueting-zhuang/>Yueting Zhuang</a>
|
<a href=/people/f/fei-wu/>Fei Wu</a>
|
<a href=/people/x/xiang-ren/>Xiang Ren</a><br><a href=/volumes/P19-3/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-3017><div class="card-body p-3 small">In this paper, we propose an efficient Knowledge Constraint Fine-grained Entity Typing Annotation Tool, which further improves the entity typing process through entity linking together with some practical functions.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1280.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1280 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1280 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1280/>NITE : A Neural Inductive Teaching Framework for Domain Specific NER<span class=acl-fixed-case>NITE</span>: A Neural Inductive Teaching Framework for Domain Specific <span class=acl-fixed-case>NER</span></a></strong><br><a href=/people/s/siliang-tang/>Siliang Tang</a>
|
<a href=/people/n/ning-zhang/>Ning Zhang</a>
|
<a href=/people/j/jinjiang-zhang/>Jinjiang Zhang</a>
|
<a href=/people/f/fei-wu/>Fei Wu</a>
|
<a href=/people/y/yueting-zhuang/>Yueting Zhuang</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1280><div class="card-body p-3 small">In domain-specific NER, due to insufficient labeled training data, <a href=https://en.wikipedia.org/wiki/Deep_learning>deep models</a> usually fail to behave normally. In this paper, we proposed a novel Neural Inductive TEaching framework (NITE) to transfer knowledge from existing domain-specific NER models into an arbitrary <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural network</a> in a teacher-student training manner. NITE is a general framework that builds upon <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> and <a href=https://en.wikipedia.org/wiki/Multiple_instance_learning>multiple instance learning</a>, which collaboratively not only transfers knowledge to a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep student network</a> but also reduces the noise from teachers. NITE can help <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning methods</a> to effectively utilize existing <a href=https://en.wikipedia.org/wiki/Resource_(computer_science)>resources</a> (i.e., <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a>, labeled and unlabeled data) in a small domain. The experiment resulted on Disease NER proved that without using any labeled data, NITE can significantly boost the performance of a CNN-bidirectional LSTM-CRF NER neural network nearly over 30 % in terms of F1-score.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Fei+Wu" title="Search for 'Fei Wu' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/s/siliang-tang/ class=align-middle>Siliang Tang</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/y/yueting-zhuang/ class=align-middle>Yueting Zhuang</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/z/zhigang-chen/ class=align-middle>Zhigang Chen</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/x/xiang-ren/ class=align-middle>Xiang Ren</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/y/yuxian-meng/ class=align-middle>Yuxian Meng</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/x/xiang-ao/ class=align-middle>Xiang Ao</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/x/xiaofei-sun/ class=align-middle>Xiaofei Sun</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/chun-fan/ class=align-middle>Chun Fan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jiwei-li/ class=align-middle>Jiwei Li</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sheng-lin/ class=align-middle>Sheng Lin</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/g/guoping-hu/ class=align-middle>Guoping Hu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/tao-chen/ class=align-middle>Tao Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haizhou-shi/ class=align-middle>Haizhou Shi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qing-he/ class=align-middle>Qing He</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qinghong-han/ class=align-middle>Qinghong Han</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tianwei-zhang/ class=align-middle>Tianwei Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiyuan-yang/ class=align-middle>Xiyuan Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaotao-gu/ class=align-middle>Xiaotao Gu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/ning-zhang/ class=align-middle>Ning Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jinjiang-zhang/ class=align-middle>Jinjiang Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qi-zhang/ class=align-middle>Qi Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shiliang-pu/ class=align-middle>Shiliang Pu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luye-zheng/ class=align-middle>Luye Zheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bo-chen/ class=align-middle>Bo Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>