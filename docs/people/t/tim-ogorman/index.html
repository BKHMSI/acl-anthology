<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Tim O’Gorman - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Tim</span> <span class=font-weight-bold>O’Gorman</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.395.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--395 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.395 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.395" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.395/>Improved Latent Tree Induction with Distant Supervision via Span Constraints</a></strong><br><a href=/people/z/zhiyang-xu/>Zhiyang Xu</a>
|
<a href=/people/a/andrew-drozdov/>Andrew Drozdov</a>
|
<a href=/people/j/jay-yoon-lee/>Jay Yoon Lee</a>
|
<a href=/people/t/tim-ogorman/>Tim O’Gorman</a>
|
<a href=/people/s/subendhu-rongali/>Subendhu Rongali</a>
|
<a href=/people/d/dylan-finkbeiner/>Dylan Finkbeiner</a>
|
<a href=/people/s/shilpa-suresh/>Shilpa Suresh</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--395><div class="card-body p-3 small">For over thirty years, researchers have developed and analyzed <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> for latent tree induction as an approach for unsupervised syntactic parsing. Nonetheless, modern <a href=https://en.wikipedia.org/wiki/System>systems</a> still do not perform well enough compared to their supervised counterparts to have any practical use as structural annotation of text. In this work, we present a technique that uses distant supervision in the form of <a href=https://en.wikipedia.org/wiki/Constraint_(mathematics)>span constraints</a> (i.e. phrase bracketing) to improve performance in unsupervised constituency parsing. Using a relatively small number of span constraints we can substantially improve the output from DIORA, an already competitive unsupervised parsing system. Compared with full parse tree annotation, span constraints can be acquired with minimal effort, such as with a lexicon derived from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, to find exact text matches. Our experiments show span constraints based on entities improves constituency parsing on English WSJ Penn Treebank by more than 5 F1. Furthermore, our method extends to any domain where span constraints are easily attainable, and as a case study we demonstrate its effectiveness by parsing biomedical text from the CRAFT dataset.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.392.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--392 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.392 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939296 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.392/>Unsupervised Parsing with S-DIORA : Single Tree Encoding for Deep Inside-Outside Recursive Autoencoders<span class=acl-fixed-case>S</span>-<span class=acl-fixed-case>DIORA</span>: Single Tree Encoding for Deep Inside-Outside Recursive Autoencoders</a></strong><br><a href=/people/a/andrew-drozdov/>Andrew Drozdov</a>
|
<a href=/people/s/subendhu-rongali/>Subendhu Rongali</a>
|
<a href=/people/y/yi-pei-chen/>Yi-Pei Chen</a>
|
<a href=/people/t/tim-ogorman/>Tim O’Gorman</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--392><div class="card-body p-3 small">The deep inside-outside recursive autoencoder (DIORA ; Drozdov et al. 2019) is a self-supervised neural model that learns to induce syntactic tree structures for input sentences * without access to labeled training data *. In this paper, we discover that while DIORA exhaustively encodes all possible binary trees of a sentence with a soft dynamic program, its vector averaging approach is locally greedy and can not recover from errors when computing the highest scoring parse tree in bottom-up chart parsing. To fix this issue, we introduce S-DIORA, an improved variant of DIORA that encodes a single tree rather than a softly-weighted mixture of trees by employing a hard argmax operation and a beam at each cell in the chart. Our experiments show that through * fine-tuning * a pre-trained DIORA with our new <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a>, we improve the state of the art in * unsupervised * constituency parsing on the English WSJ Penn Treebank by 2.2-6 % F1, depending on the data used for <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.dmr-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--dmr-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.dmr-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.dmr-1.4/>Cross-lingual annotation : a road map for low- and no-resource languages</a></strong><br><a href=/people/m/meagan-vigus/>Meagan Vigus</a>
|
<a href=/people/j/jens-e-l-van-gysel/>Jens E. L. Van Gysel</a>
|
<a href=/people/t/tim-ogorman/>Tim O’Gorman</a>
|
<a href=/people/a/andrew-cowell/>Andrew Cowell</a>
|
<a href=/people/r/rosa-vallejos/>Rosa Vallejos</a>
|
<a href=/people/w/william-croft/>William Croft</a><br><a href=/volumes/2020.dmr-1/ class=text-muted>Proceedings of the Second International Workshop on Designing Meaning Representations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--dmr-1--4><div class="card-body p-3 small">This paper presents a <a href=https://en.wikipedia.org/wiki/Road_map>road map</a> for the annotation of semantic categories in typologically diverse languages, with potentially few linguistic resources, and often no existing <a href=https://en.wikipedia.org/wiki/Computational_resource>computational resources</a>. Past <a href=https://en.wikipedia.org/wiki/Semantic_annotation>semantic annotation</a> efforts have focused largely on high-resource languages, or relatively low-resource languages with a large number of native speakers. However, there are certain typological traits, namely the synthesis of multiple concepts into a single word, that are more common in languages with a smaller speech community. For example, what is expressed as a sentence in a more <a href=https://en.wikipedia.org/wiki/Analytic_language>analytic language</a> like <a href=https://en.wikipedia.org/wiki/English_language>English</a>, may be expressed as a single word in a more <a href=https://en.wikipedia.org/wiki/Synthetic_language>synthetic language</a> like <a href=https://en.wikipedia.org/wiki/Arapaho_language>Arapaho</a>. This paper proposes solutions for annotating analytic and synthetic languages in a comparable way based on existing typological research, and introduces a road map for the annotation of languages with a dearth of resources.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.270.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--270 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.270 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940651 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.270/>An Instance Level Approach for Shallow Semantic Parsing in Scientific Procedural Text<span class=acl-fixed-case>A</span>n <span class=acl-fixed-case>I</span>nstance <span class=acl-fixed-case>L</span>evel <span class=acl-fixed-case>A</span>pproach for <span class=acl-fixed-case>S</span>hallow <span class=acl-fixed-case>S</span>emantic <span class=acl-fixed-case>P</span>arsing in <span class=acl-fixed-case>S</span>cientific <span class=acl-fixed-case>P</span>rocedural <span class=acl-fixed-case>T</span>ext</a></strong><br><a href=/people/d/daivik-swarup/>Daivik Swarup</a>
|
<a href=/people/a/ahsaas-bajaj/>Ahsaas Bajaj</a>
|
<a href=/people/s/sheshera-mysore/>Sheshera Mysore</a>
|
<a href=/people/t/tim-ogorman/>Tim O’Gorman</a>
|
<a href=/people/r/rajarshi-das/>Rajarshi Das</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--270><div class="card-body p-3 small">In specific domains, such as procedural scientific text, human labeled data for <a href=https://en.wikipedia.org/wiki/Shallow_semantic_parsing>shallow semantic parsing</a> is especially limited and expensive to create. Fortunately, such specific domains often use rather formulaic writing, such that the different ways of expressing relations in a small number of grammatically similar labeled sentences may provide high coverage of semantic structures in the corpus, through an appropriately rich similarity metric. In light of this opportunity, this paper explores an instance-based approach to the relation prediction sub-task within shallow semantic parsing, in which semantic labels from structurally similar sentences in the training set are copied to test sentences. Candidate similar sentences are retrieved using SciBERT embeddings. For labels where it is possible to copy from a similar sentence we employ an instance level copy network, when this is not possible, a globally shared parametric model is employed. Experiments show our approach outperforms both baseline and prior methods by 0.75 to 3 F1 absolute in the Wet Lab Protocol Corpus and 1 F1 absolute in the Materials Science Procedural Text Corpus.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K19-2000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K19-2000/>Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</a></strong><br><a href=/people/s/stephan-oepen/>Stephan Oepen</a>
|
<a href=/people/o/omri-abend/>Omri Abend</a>
|
<a href=/people/j/jan-hajic/>Jan Hajic</a>
|
<a href=/people/d/daniel-hershcovich/>Daniel Hershcovich</a>
|
<a href=/people/m/marco-kuhlmann/>Marco Kuhlmann</a>
|
<a href=/people/t/tim-ogorman/>Tim O’Gorman</a>
|
<a href=/people/n/nianwen-xue/>Nianwen Xue</a><br><a href=/volumes/K19-2/ class=text-muted>Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K19-2001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K19-2001 data-toggle=collapse aria-expanded=false aria-controls=abstract-K19-2001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/K19-2001.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/K19-2001/>MRP 2019 : Cross-Framework Meaning Representation Parsing<span class=acl-fixed-case>MRP</span> 2019: Cross-Framework Meaning Representation Parsing</a></strong><br><a href=/people/s/stephan-oepen/>Stephan Oepen</a>
|
<a href=/people/o/omri-abend/>Omri Abend</a>
|
<a href=/people/j/jan-hajic/>Jan Hajic</a>
|
<a href=/people/d/daniel-hershcovich/>Daniel Hershcovich</a>
|
<a href=/people/m/marco-kuhlmann/>Marco Kuhlmann</a>
|
<a href=/people/t/tim-ogorman/>Tim O’Gorman</a>
|
<a href=/people/n/nianwen-xue/>Nianwen Xue</a>
|
<a href=/people/j/jayeol-chun/>Jayeol Chun</a>
|
<a href=/people/m/milan-straka/>Milan Straka</a>
|
<a href=/people/z/zdenka-uresova/>Zdenka Uresova</a><br><a href=/volumes/K19-2/ class=text-muted>Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K19-2001><div class="card-body p-3 small">The 2019 Shared Task at the Conference for Computational Language Learning (CoNLL) was devoted to Meaning Representation Parsing (MRP) across frameworks. Five distinct approaches to the representation of sentence meaning in the form of <a href=https://en.wikipedia.org/wiki/Directed_graph>directed graph</a> were represented in the training and evaluation data for the task, packaged in a uniform abstract graph representation and <a href=https://en.wikipedia.org/wiki/Serialization>serialization</a>. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> received submissions from eighteen teams, of which five do not participate in the official ranking because they arrived after the closing deadline, made use of additional training data, or involved one of the task co-organizers. All technical information regarding the <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>, including system submissions, official results, and links to supporting resources and software are available from the task web site at : http://mrp.nlpl.eu</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1313.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1313 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1313 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-1313/>AMR Beyond the Sentence : the Multi-sentence AMR corpus<span class=acl-fixed-case>AMR</span> Beyond the Sentence: the Multi-sentence <span class=acl-fixed-case>AMR</span> corpus</a></strong><br><a href=/people/t/tim-ogorman/>Tim O’Gorman</a>
|
<a href=/people/m/michael-regan/>Michael Regan</a>
|
<a href=/people/k/kira-griffitt/>Kira Griffitt</a>
|
<a href=/people/u/ulf-hermjakob/>Ulf Hermjakob</a>
|
<a href=/people/k/kevin-knight/>Kevin Knight</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1313><div class="card-body p-3 small">There are few <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a> that endeavor to represent the semantic content of entire documents. We present a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> that accomplishes one way of capturing document level semantics, by annotating <a href=https://en.wikipedia.org/wiki/Coreference>coreference</a> and similar phenomena (bridging and implicit roles) on top of gold Abstract Meaning Representations of sentence-level semantics. We present a new <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of this <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a>, with analysis of its quality, alongside a plausible baseline for comparison. It is hoped that this Multi-Sentence AMR corpus (MS-AMR) may become a feasible method for developing rich representations of document meaning, useful for tasks such as <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a> and <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-1022.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-1022 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-1022 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/S17-1022.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/S17-1022/>Double Trouble : The Problem of Construal in Semantic Annotation of Adpositions</a></strong><br><a href=/people/j/jena-d-hwang/>Jena D. Hwang</a>
|
<a href=/people/a/archna-bhatia/>Archna Bhatia</a>
|
<a href=/people/n/na-rae-han/>Na-Rae Han</a>
|
<a href=/people/t/tim-ogorman/>Tim O’Gorman</a>
|
<a href=/people/v/vivek-srikumar/>Vivek Srikumar</a>
|
<a href=/people/n/nathan-schneider/>Nathan Schneider</a><br><a href=/volumes/S17-1/ class=text-muted>Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-1022><div class="card-body p-3 small">We consider the semantics of prepositions, revisiting a broad-coverage <a href=https://en.wikipedia.org/wiki/Annotation>annotation scheme</a> used for annotating all 4,250 <a href=https://en.wikipedia.org/wiki/Preposition_and_postposition>preposition tokens</a> in a 55,000 word corpus of English. Attempts to apply the scheme to adpositions and <a href=https://en.wikipedia.org/wiki/Marker_(linguistics)>case markers</a> in other languages, as well as some problematic cases in <a href=https://en.wikipedia.org/wiki/English_language>English</a>, have led us to reconsider the assumption that an adposition&#8217;s lexical contribution is equivalent to the role / relation that it mediates. Our proposal is to embrace the potential for construal in adposition use, expressing such phenomena directly at the token level to manage complexity and avoid sense proliferation. We suggest a framework to represent both the scene role and the adposition&#8217;s lexical function so they can be annotated at scalesupporting automatic, statistical processing of domain-general languageand discuss how this representation would allow for a simpler inventory of labels.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Tim+O%E2%80%99Gorman" title="Search for 'Tim O’Gorman' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/a/andrew-mccallum/ class=align-middle>Andrew McCallum</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/andrew-drozdov/ class=align-middle>Andrew Drozdov</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/subendhu-rongali/ class=align-middle>Subendhu Rongali</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mohit-iyyer/ class=align-middle>Mohit Iyyer</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/stephan-oepen/ class=align-middle>Stephan Oepen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/o/omri-abend/ class=align-middle>Omri Abend</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jan-hajic/ class=align-middle>Jan Hajic</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/daniel-hershcovich/ class=align-middle>Daniel Hershcovich</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/marco-kuhlmann/ class=align-middle>Marco Kuhlmann</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/n/nianwen-xue/ class=align-middle>Nianwen Xue</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/michael-regan/ class=align-middle>Michael Regan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kira-griffitt/ class=align-middle>Kira Griffitt</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/u/ulf-hermjakob/ class=align-middle>Ulf Hermjakob</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kevin-knight/ class=align-middle>Kevin Knight</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/martha-palmer/ class=align-middle>Martha Palmer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yi-pei-chen/ class=align-middle>Yi-Pei Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/meagan-vigus/ class=align-middle>Meagan Vigus</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jens-e-l-van-gysel/ class=align-middle>Jens E. L. Van Gysel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrew-cowell/ class=align-middle>Andrew Cowell</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rosa-vallejos/ class=align-middle>Rosa Vallejos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/william-croft/ class=align-middle>William Croft</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhiyang-xu/ class=align-middle>Zhiyang Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jay-yoon-lee/ class=align-middle>Jay Yoon Lee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dylan-finkbeiner/ class=align-middle>Dylan Finkbeiner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shilpa-suresh/ class=align-middle>Shilpa Suresh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jena-d-hwang/ class=align-middle>Jena D. Hwang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/archna-bhatia/ class=align-middle>Archna Bhatia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/na-rae-han/ class=align-middle>Na-Rae Han</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vivek-srikumar/ class=align-middle>Vivek Srikumar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nathan-schneider/ class=align-middle>Nathan Schneider</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/daivik-swarup/ class=align-middle>Daivik Swarup</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ahsaas-bajaj/ class=align-middle>Ahsaas Bajaj</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sheshera-mysore/ class=align-middle>Sheshera Mysore</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rajarshi-das/ class=align-middle>Rajarshi Das</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jayeol-chun/ class=align-middle>Jayeol Chun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/milan-straka/ class=align-middle>Milan Straka</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zdenka-uresova/ class=align-middle>Zdenka Uresova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/dmr/ class=align-middle>DMR</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>