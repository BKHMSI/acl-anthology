<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Takenobu Tokunaga - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Takenobu</span> <span class=font-weight-bold>Tokunaga</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.bea-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--bea-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.bea-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.bea-1.10" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.bea-1.10/>Parsing Argumentative Structure in English-as-Foreign-Language Essays<span class=acl-fixed-case>E</span>nglish-as-Foreign-Language Essays</a></strong><br><a href=/people/j/jan-wira-gotama-putra/>Jan Wira Gotama Putra</a>
|
<a href=/people/s/simone-teufel/>Simone Teufel</a>
|
<a href=/people/t/takenobu-tokunaga/>Takenobu Tokunaga</a><br><a href=/volumes/2021.bea-1/ class=text-muted>Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--bea-1--10><div class="card-body p-3 small">This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy. The <a href=https://en.wikipedia.org/wiki/Parsing>parsing process</a> consists of two steps, linking related sentences and then labelling their relations. We experiment with several deep learning architectures to address each <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a> independently. In the sentence linking task, a biaffine model performed the best. In the relation labelling task, a fine-tuned BERT model performed the best. Two sentence encoders are employed, and we observed that non-fine-tuning models generally performed better when using Sentence-BERT as opposed to BERT encoder. We trained our models using two types of parallel texts : original noisy EFL essays and those improved by annotators, then evaluate them on the original <a href=https://en.wikipedia.org/wiki/Essay>essays</a>. The experiment shows that an end-to-end in-domain system achieved an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of.341. On the other hand, the cross-domain system achieved 94 % performance of the in-domain system. This signals that well-written texts can also be useful to train argument mining system for noisy texts.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.396.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--396 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.396 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.396/>Effective Use of Target-side Context for Neural Machine Translation</a></strong><br><a href=/people/h/hideya-mino/>Hideya Mino</a>
|
<a href=/people/h/hitoshi-ito/>Hitoshi Ito</a>
|
<a href=/people/i/isao-goto/>Isao Goto</a>
|
<a href=/people/i/ichiro-yamada/>Ichiro Yamada</a>
|
<a href=/people/t/takenobu-tokunaga/>Takenobu Tokunaga</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--396><div class="card-body p-3 small">In this paper, we deal with two problems in Japanese-English machine translation of news articles. The first problem is the quality of <a href=https://en.wikipedia.org/wiki/Parallel_text>parallel corpora</a>. Neural machine translation (NMT) systems suffer degraded performance when trained with <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noisy data</a>. Because there is no clean Japanese-English parallel data for <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>, we build a novel parallel news corpus consisting of Japanese news articles translated into English in a content-equivalent manner. This is the first content-equivalent Japanese-English news corpus translated specifically for training NMT systems. The second problem involves the domain-adaptation technique. NMT systems suffer degraded performance when trained with mixed data having different <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>, such as <a href=https://en.wikipedia.org/wiki/Noisy_data>noisy data</a> and clean data. Though the existing methods try to overcome this problem by using <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>tags</a> for distinguishing the differences between corpora, it is not sufficient. We thus extend a domain-adaptation method using multi-tags to train an NMT model effectively with the clean corpus and existing parallel news corpora with some types of noise. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> increases the translation quality, and that our domain-adaptation method is more effective for learning with the multiple types of corpora than existing domain-adaptation methods are.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.854.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--854 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.854 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.854/>TIARA : A Tool for Annotating Discourse Relations and Sentence Reordering<span class=acl-fixed-case>TIARA</span>: A Tool for Annotating Discourse Relations and Sentence Reordering</a></strong><br><a href=/people/j/jan-wira-gotama-putra/>Jan Wira Gotama Putra</a>
|
<a href=/people/s/simone-teufel/>Simone Teufel</a>
|
<a href=/people/k/kana-matsumura/>Kana Matsumura</a>
|
<a href=/people/t/takenobu-tokunaga/>Takenobu Tokunaga</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--854><div class="card-body p-3 small">This paper introduces <a href=https://en.wikipedia.org/wiki/TIARA>TIARA</a>, a new publicly available web-based annotation tool for <a href=https://en.wikipedia.org/wiki/Discourse_analysis>discourse relations</a> and sentence reordering. Annotation tasks such as these, which are based on relations between large textual objects, are inherently hard to visualise without either cluttering the display and/or confusing the annotators. TIARA deals with the visual complexity during the annotation process by systematically simplifying the layout, and by offering interactive visualisation, including coloured links, <a href=https://en.wikipedia.org/wiki/Indentation_style>indentation</a>, and dual-view. TIARA&#8217;s text view allows annotators to focus on the analysis of logical sequencing between sentences. A separate <a href=https://en.wikipedia.org/wiki/Tree_view>tree view</a> allows them to review their analysis in terms of the overall discourse structure. The dual-view gives <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> an edge over other discourse annotation tools and makes <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> particularly attractive as an <a href=https://en.wikipedia.org/wiki/Educational_technology>educational tool</a> (e.g., for teaching students how to argue more effectively). As it is based on standard web technologies and can be easily customised to other annotation schemes, it can be easily used by anybody. Apart from the project it was originally designed for, in which hundreds of texts were annotated by three annotators, TIARA has already been adopted by a second discourse annotation study, which uses it in the teaching of argumentation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.876.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--876 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.876 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.876/>Gamification Platform for Collecting Task-oriented Dialogue Data</a></strong><br><a href=/people/h/haruna-ogawa/>Haruna Ogawa</a>
|
<a href=/people/h/hitoshi-nishikawa/>Hitoshi Nishikawa</a>
|
<a href=/people/t/takenobu-tokunaga/>Takenobu Tokunaga</a>
|
<a href=/people/h/hikaru-yokono/>Hikaru Yokono</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--876><div class="card-body p-3 small">Demand for massive language resources is increasing as the data-driven approach has established a leading position in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a>. However, creating dialogue corpora is still a difficult task due to the complexity of the human dialogue structure and the diversity of dialogue topics. Though <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a> is majorly used to assemble such <a href=https://en.wikipedia.org/wiki/Data>data</a>, it presents problems such as less-motivated workers. We propose a <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a> for collecting task-oriented situated dialogue data by using <a href=https://en.wikipedia.org/wiki/Gamification>gamification</a>. Combining a <a href=https://en.wikipedia.org/wiki/Video_game>video game</a> with data collection benefits such as motivating workers and <a href=https://en.wikipedia.org/wiki/Cost_reduction>cost reduction</a>. Our <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a> enables data collectors to create their original <a href=https://en.wikipedia.org/wiki/Video_game>video game</a> in which they can collect dialogue data of various types of tasks by using the logging function of the <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a>. Also, the <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a> provides the <a href=https://en.wikipedia.org/wiki/Annotation>annotation function</a> that enables players to annotate their own utterances. The <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a> can be gamified aswell. We aim at high-quality annotation by introducing such self-annotation method. We implemented a <a href=https://en.wikipedia.org/wiki/Prototype>prototype</a> of the proposed <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a> and conducted a preliminary evaluation to obtain promising results in terms of both dialogue data collection and self-annotation.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4436.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4436 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4436 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4436/>Supporting content evaluation of student summaries by Idea Unit embedding</a></strong><br><a href=/people/m/marcello-gecchele/>Marcello Gecchele</a>
|
<a href=/people/h/hiroaki-yamada/>Hiroaki Yamada</a>
|
<a href=/people/t/takenobu-tokunaga/>Takenobu Tokunaga</a>
|
<a href=/people/y/yasuyo-sawaki/>Yasuyo Sawaki</a><br><a href=/volumes/W19-44/ class=text-muted>Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4436><div class="card-body p-3 small">This paper discusses the computer-assisted content evaluation of summaries. We propose a <a href=https://en.wikipedia.org/wiki/Scientific_method>method</a> to make a correspondence between the segments of the source text and its summary. As a unit of the segment, we adopt Idea Unit (IU) which is proposed in <a href=https://en.wikipedia.org/wiki/Applied_linguistics>Applied Linguistics</a>. Introducing IUs enables us to make a correspondence even for the sentences that contain multiple ideas. The IU correspondence is made based on the similarity between vector representations of IU. An evaluation experiment with two source texts and 20 summaries showed that the proposed method is more robust against rephrased expressions than the conventional ROUGE-based baselines. Also, the proposed method outperformed the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> in recall. We im-plemented the proposed method in a GUI toolSegment Matcher that aids teachers to estab-lish a link between corresponding IUs acrossthe summary and source text.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2049.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2049 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2049 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2049/>Key-value Attention Mechanism for Neural Machine Translation</a></strong><br><a href=/people/h/hideya-mino/>Hideya Mino</a>
|
<a href=/people/m/masao-utiyama/>Masao Utiyama</a>
|
<a href=/people/e/eiichiro-sumita/>Eiichiro Sumita</a>
|
<a href=/people/t/takenobu-tokunaga/>Takenobu Tokunaga</a><br><a href=/volumes/I17-2/ class=text-muted>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2049><div class="card-body p-3 small">In this paper, we propose a neural machine translation (NMT) with a key-value attention mechanism on the source-side encoder. The key-value attention mechanism separates the source-side content vector into two types of <a href=https://en.wikipedia.org/wiki/Computer_data_storage>memory</a> known as the key and the value. The <a href=https://en.wikipedia.org/wiki/Key_(cryptography)>key</a> is used for calculating the <a href=https://en.wikipedia.org/wiki/Attention>attention distribution</a>, and the <a href=https://en.wikipedia.org/wiki/Value_(computer_science)>value</a> is used for encoding the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context representation</a>. Experiments on three different tasks indicate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms an NMT model with a conventional <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanism</a>. Furthermore, we perform experiments with a conventional NMT framework, in which a part of the initial value of a weight matrix is set to zero so that the matrix is as the same initial-state as the key-value attention mechanism. As a result, we obtain comparable results with the key-value attention mechanism without changing the <a href=https://en.wikipedia.org/wiki/Neural_circuit>network structure</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2410.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2410 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2410 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-2410.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W17-2410/>Evaluating text coherence based on semantic similarity graph</a></strong><br><a href=/people/j/jan-wira-gotama-putra/>Jan Wira Gotama Putra</a>
|
<a href=/people/t/takenobu-tokunaga/>Takenobu Tokunaga</a><br><a href=/volumes/W17-24/ class=text-muted>Proceedings of TextGraphs-11: the Workshop on Graph-based Methods for Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2410><div class="card-body p-3 small">Coherence is a crucial feature of text because it is indispensable for conveying its communication purpose and meaning to its readers. In this paper, we propose an unsupervised text coherence scoring based on <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph construction</a> in which <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>edges</a> are established between semantically similar sentences represented by vertices. The sentence similarity is calculated based on the cosine similarity of semantic vectors representing sentences. We provide three graph construction methods establishing an <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>edge</a> from a given <a href=https://en.wikipedia.org/wiki/Vertex_(graph_theory)>vertex</a> to a preceding adjacent vertex, to a single similar vertex, or to multiple similar vertices. We evaluated our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> in the document discrimination task and the insertion task by comparing our proposed <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> to the supervised (Entity Grid) and unsupervised (Entity Graph) baselines. In the document discrimination task, our method outperformed the unsupervised baseline but could not do the supervised baseline, while in the insertion task, our method outperformed both baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5008 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5008/>Evaluation of Automatically Generated Pronoun Reference Questions</a></strong><br><a href=/people/a/arief-yudha-satria/>Arief Yudha Satria</a>
|
<a href=/people/t/takenobu-tokunaga/>Takenobu Tokunaga</a><br><a href=/volumes/W17-50/ class=text-muted>Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5008><div class="card-body p-3 small">This study provides a detailed analysis of evaluation of English pronoun reference questions which are created automatically by machine. Pronoun reference questions are multiple choice questions that ask test takers to choose an antecedent of a target pronoun in a reading passage from four options. The <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a> was performed from two perspectives : the perspective of English teachers and that of English learners. Item analysis suggests that machine-generated questions achieve comparable quality with <a href=https://en.wikipedia.org/wiki/Questionnaire>human-made questions</a>. Correlation analysis revealed a strong correlation between the scores of machine-generated questions and that of human-made questions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5103.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5103 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5103 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5103/>Annotation of argument structure in Japanese legal documents<span class=acl-fixed-case>J</span>apanese legal documents</a></strong><br><a href=/people/h/hiroaki-yamada/>Hiroaki Yamada</a>
|
<a href=/people/s/simone-teufel/>Simone Teufel</a>
|
<a href=/people/t/takenobu-tokunaga/>Takenobu Tokunaga</a><br><a href=/volumes/W17-51/ class=text-muted>Proceedings of the 4th Workshop on Argument Mining</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5103><div class="card-body p-3 small">We propose a method for the annotation of Japanese civil judgment documents, with the purpose of creating flexible summaries of these. The first step, described in the current paper, concerns content selection, i.e., the question of which material should be extracted initially for the summary. In particular, we utilize the hierarchical argument structure of the <a href=https://en.wikipedia.org/wiki/Judgment_(law)>judgment documents</a>. Our main contributions are a) the design of an annotation scheme that stresses the connection between legal points (called issue topics) and argument structure, b) an adaptation of rhetorical status to suit the Japanese legal system and c) the definition of a linked argument structure based on legal sub-arguments. In this paper, we report agreement between two annotators on several aspects of the overall task.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Takenobu+Tokunaga" title="Search for 'Takenobu Tokunaga' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/j/jan-wira-gotama-putra/ class=align-middle>Jan Wira Gotama Putra</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/simone-teufel/ class=align-middle>Simone Teufel</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/h/hideya-mino/ class=align-middle>Hideya Mino</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hiroaki-yamada/ class=align-middle>Hiroaki Yamada</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/masao-utiyama/ class=align-middle>Masao Utiyama</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/e/eiichiro-sumita/ class=align-middle>Eiichiro Sumita</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/arief-yudha-satria/ class=align-middle>Arief Yudha Satria</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marcello-gecchele/ class=align-middle>Marcello Gecchele</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yasuyo-sawaki/ class=align-middle>Yasuyo Sawaki</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hitoshi-ito/ class=align-middle>Hitoshi Ito</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/isao-goto/ class=align-middle>Isao Goto</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ichiro-yamada/ class=align-middle>Ichiro Yamada</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kana-matsumura/ class=align-middle>Kana Matsumura</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haruna-ogawa/ class=align-middle>Haruna Ogawa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hitoshi-nishikawa/ class=align-middle>Hitoshi Nishikawa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hikaru-yokono/ class=align-middle>Hikaru Yokono</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/bea/ class=align-middle>BEA</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>