<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Taylor Berg-Kirkpatrick - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Taylor</span> <span class=font-weight-bold>Berg-Kirkpatrick</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.224.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--224 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.224 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2022.acl-long.224.software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.acl-long.224" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.224/>Achieving Conversational Goals with Unsupervised Post-hoc Knowledge Injection</a></strong><br><a href=/people/b/bodhisattwa-prasad-majumder/>Bodhisattwa Prasad Majumder</a>
|
<a href=/people/h/harsh-jhamtani/>Harsh Jhamtani</a>
|
<a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a>
|
<a href=/people/j/julian-mcauley/>Julian McAuley</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--224><div class="card-body p-3 small">A limitation of current neural dialog models is that they tend to suffer from a lack of specificity and informativeness in generated responses, primarily due to dependence on training data that covers a limited variety of scenarios and conveys limited knowledge. One way to alleviate this issue is to extract relevant knowledge from external sources at decoding time and incorporate it into the dialog response. In this paper, we propose a post-hoc knowledge-injection technique where we first retrieve a diverse set of relevant knowledge snippets conditioned on both the dialog history and an initial response from an existing dialog model. We construct multiple candidate responses, individually injecting each retrieved snippet into the initial response using a gradient-based decoding method, and then select the final response with an unsupervised ranking step. Our experiments in goal-oriented and knowledge-grounded dialog settings demonstrate that human annotators judge the outputs from the proposed method to be more engaging and informative compared to responses from prior dialog systems. We further show that knowledge-augmentation promotes success in achieving conversational goals in both experimental settings.</div></div><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.152.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--152 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.152 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.152" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.152/>Style Pooling : Automatic Text Style Obfuscation for Improved Classification Fairness</a></strong><br><a href=/people/f/fatemehsadat-mireshghallah/>Fatemehsadat Mireshghallah</a>
|
<a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--152><div class="card-body p-3 small">Text style can reveal sensitive attributes of the author (e.g. age and race) to the reader, which can, in turn, lead to privacy violations and bias in both human and algorithmic decisions based on text. For example, the style of writing in job applications might reveal protected attributes of the candidate which could lead to bias in <a href=https://en.wikipedia.org/wiki/Recruitment>hiring decisions</a>, regardless of whether <a href=https://en.wikipedia.org/wiki/Recruitment>hiring decisions</a> are made algorithmically or by humans. We propose a VAE-based framework that obfuscates stylistic features of human-generated text through style transfer, by automatically re-writing the text itself. Critically, our framework operationalizes the notion of obfuscated style in a flexible way that enables two distinct notions of obfuscated style : (1) a minimal notion that effectively intersects the various styles seen in training, and (2) a maximal notion that seeks to obfuscate by adding stylistic features of all sensitive attributes to text, in effect, computing a union of styles. Our style-obfuscation framework can be used for multiple purposes, however, we demonstrate its effectiveness in improving the fairness of downstream classifiers. We also conduct a comprehensive study on style-pooling&#8217;s effect on <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a>, semantic consistency, and attribute removal from text, in two and three domain style transfer.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.461.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--461 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.461 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.461" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.461/>Efficient Nearest Neighbor Language Models</a></strong><br><a href=/people/j/junxian-he/>Junxian He</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--461><div class="card-body p-3 small">Non-parametric neural language models (NLMs) learn predictive distributions of text utilizing an external datastore, which allows them to learn through explicitly memorizing the training datapoints. While effective, these models often require retrieval from a large datastore at test time, significantly increasing the <a href=https://en.wikipedia.org/wiki/Overhead_(computing)>inference overhead</a> and thus limiting the deployment of non-parametric NLMs in practical applications. In this paper, we take the recently proposed k-nearest neighbors language model as an example, exploring methods to improve its efficiency along various dimensions. Experiments on the standard WikiText-103 benchmark and domain-adaptation datasets show that our methods are able to achieve up to a 6x speed-up in inference speed while retaining comparable performance. The empirical analysis we present may provide guidelines for future research seeking to develop or deploy more efficient non-parametric NLMs.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.385.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--385 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.385 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939346 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.385/>An Empirical Investigation of Contextualized Number Prediction</a></strong><br><a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a>
|
<a href=/people/d/daniel-spokoyny/>Daniel Spokoyny</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--385><div class="card-body p-3 small">We conduct a large scale empirical investigation of contextualized number prediction in <a href=https://en.wikipedia.org/wiki/Running_text>running text</a>. Specifically, we consider two tasks : (1)masked number prediction predict-ing a missing numerical value within a sentence, and (2)numerical anomaly detectiondetecting an errorful numeric value within a sentence. We experiment with novel combinations of contextual encoders and output distributions over the <a href=https://en.wikipedia.org/wiki/Real_number_line>real number line</a>. Specifically, we introduce a suite of output distribution parameterizations that incorporate <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a> to add expressivity and better fit the natural distribution of numeric values in running text, and combine them with both recur-rent and transformer-based encoder architectures. We evaluate these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on two <a href=https://en.wikipedia.org/wiki/Data_set>numeric datasets</a> in the financial and scientific domain. Our findings show that output distributions that incorporate discrete latent variables and allow for multiple modes outperform simple flow-based counterparts on all datasets, yielding more accurate numerical pre-diction and anomaly detection. We also show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> effectively utilize textual con-text and benefit from general-purpose unsupervised pretraining.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.739.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--739 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.739 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938989 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.739" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.739/>Like hiking? You probably enjoy nature : Persona-grounded Dialog with Commonsense Expansions</a></strong><br><a href=/people/b/bodhisattwa-prasad-majumder/>Bodhisattwa Prasad Majumder</a>
|
<a href=/people/h/harsh-jhamtani/>Harsh Jhamtani</a>
|
<a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a>
|
<a href=/people/j/julian-mcauley/>Julian McAuley</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--739><div class="card-body p-3 small">Existing persona-grounded dialog models often fail to capture simple implications of given persona descriptions, something which humans are able to do seamlessly. For example, state-of-the-art models can not infer that interest in hiking might imply love for nature or longing for a break. In this paper, we propose to expand available persona sentences using existing commonsense knowledge bases and paraphrasing resources to imbue dialog models with access to an expanded and richer set of persona descriptions. Additionally, we introduce fine-grained grounding on <a href=https://en.wikipedia.org/wiki/Persona>personas</a> by encouraging the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to make a discrete choice among persona sentences while synthesizing a dialog response. Since such a choice is not observed in the data, we model it using a discrete latent random variable and use variational learning to sample from hundreds of persona expansions. Our model outperforms competitive baselines on the Persona-Chat dataset in terms of dialog quality and diversity while achieving persona-consistent and controllable dialog generation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.737.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--737 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.737 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929400 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.737" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.737/>Phonetic and Visual Priors for Decipherment of Informal Romanization<span class=acl-fixed-case>R</span>omanization</a></strong><br><a href=/people/m/maria-ryskina/>Maria Ryskina</a>
|
<a href=/people/m/matthew-r-gormley/>Matthew R. Gormley</a>
|
<a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--737><div class="card-body p-3 small">Informal romanization is an idiosyncratic process used by humans in informal digital communication to encode non-Latin script languages into <a href=https://en.wikipedia.org/wiki/Latin_script>Latin character sets</a> found on common keyboards. Character substitution choices differ between users but have been shown to be governed by the same main principles observed across a variety of languagesnamely, character pairs are often associated through phonetic or visual similarity. We propose a noisy-channel WFST cascade model for deciphering the original non-Latin script from observed romanized text in an unsupervised fashion. We train our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> directly on romanized data from two languages : <a href=https://en.wikipedia.org/wiki/Egyptian_Arabic>Egyptian Arabic</a> and <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a>. We demonstrate that adding <a href=https://en.wikipedia.org/wiki/Inductive_bias>inductive bias</a> through phonetic and visual priors on character mappings substantially improves the model&#8217;s performance on both languages, yielding results much closer to the supervised skyline. Finally, we introduce a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of <a href=https://en.wikipedia.org/wiki/Romanization_of_Russian>romanized Russian</a>, collected from a Russian social network website and partially annotated for our experiments.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1225.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1225 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1225 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1225" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1225/>A Deep Factorization of Style and Structure in Fonts</a></strong><br><a href=/people/n/nikita-srivatsan/>Nikita Srivatsan</a>
|
<a href=/people/j/jonathan-barron/>Jonathan Barron</a>
|
<a href=/people/d/dan-klein/>Dan Klein</a>
|
<a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1225><div class="card-body p-3 small">We propose a deep factorization model for typographic analysis that disentangles content from style. Specifically, a variational inference procedure factors each training glyph into the combination of a character-specific content embedding and a latent font-specific style variable. The underlying <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> combines these factors through an asymmetric transpose convolutional process to generate the image of the glyph itself. When trained on corpora of fonts, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> learns a manifold over font styles that can be used to analyze or reconstruct new, unseen fonts. On the task of reconstructing missing glyphs from an unknown font given only a small number of observations, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms both a strong nearest neighbors baseline and a state-of-the-art discriminative model from prior work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1311.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1311 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1311 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1311" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1311/>Cross-Lingual Syntactic Transfer through Unsupervised Adaptation of Invertible Projections</a></strong><br><a href=/people/j/junxian-he/>Junxian He</a>
|
<a href=/people/z/zhisong-zhang/>Zhisong Zhang</a>
|
<a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1311><div class="card-body p-3 small">Cross-lingual transfer is an effective way to build syntactic analysis tools in low-resource languages. However, transfer is difficult when transferring to typologically distant languages, especially when neither annotated target data nor <a href=https://en.wikipedia.org/wiki/Parallel_text>parallel corpora</a> are available. In this paper, we focus on methods for cross-lingual transfer to distant languages and propose to learn a <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> with a structured prior that utilizes labeled source data and unlabeled target data jointly. The parameters of <a href=https://en.wikipedia.org/wiki/Statistical_model>source model</a> and <a href=https://en.wikipedia.org/wiki/Statistical_model>target model</a> are softly shared through a regularized log likelihood objective. An invertible projection is employed to learn a new interlingual latent embedding space that compensates for imperfect cross-lingual word embedding input. We evaluate our method on two syntactic tasks : part-of-speech (POS) tagging and dependency parsing. On the Universal Dependency Treebanks, we use <a href=https://en.wikipedia.org/wiki/English_language>English</a> as the only source corpus and transfer to a wide range of target languages. On the 10 languages in this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> that are distant from <a href=https://en.wikipedia.org/wiki/English_language>English</a>, our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> yields an average of 5.2 % absolute improvement on <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>POS tagging</a> and 8.3 % absolute improvement on dependency parsing over a direct transfer method using state-of-the-art <a href=https://en.wikipedia.org/wiki/Discriminative_model>discriminative models</a>.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1160.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1160 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1160 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/305215139 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1160" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1160/>Unsupervised Learning of Syntactic Structure with Invertible Neural Projections</a></strong><br><a href=/people/j/junxian-he/>Junxian He</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1160><div class="card-body p-3 small">Unsupervised learning of syntactic structure is typically performed using <a href=https://en.wikipedia.org/wiki/Generative_model>generative models</a> with <a href=https://en.wikipedia.org/wiki/Latent_variable>discrete latent variables</a> and <a href=https://en.wikipedia.org/wiki/Multinomial_distribution>multinomial parameters</a>. In most cases, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> have not leveraged continuous word representations. In this work, we propose a novel <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> that jointly learns discrete syntactic structure and continuous word representations in an unsupervised fashion by cascading an invertible neural network with a structured generative prior. We show that the invertibility condition allows for efficient <a href=https://en.wikipedia.org/wiki/Exact_inference>exact inference</a> and marginal likelihood computation in our model so long as the <a href=https://en.wikipedia.org/wiki/Prior_probability>prior</a> is well-behaved. In experiments we instantiate our approach with both Markov and tree-structured priors, evaluating on two tasks : part-of-speech (POS) induction, and unsupervised dependency parsing without gold POS annotation. On the <a href=https://en.wikipedia.org/wiki/Penn_Treebank>Penn Treebank</a>, our <a href=https://en.wikipedia.org/wiki/Markov_chain>Markov-structured model</a> surpasses state-of-the-art results on POS induction. Similarly, we find that our tree-structured model achieves state-of-the-art performance on unsupervised dependency parsing for the difficult training condition where neither gold POS annotation nor punctuation-based constraints are available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1436.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1436 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1436 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1436" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D18-1436/>Learning to Describe Differences Between Pairs of Similar Images</a></strong><br><a href=/people/h/harsh-jhamtani/>Harsh Jhamtani</a>
|
<a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1436><div class="card-body p-3 small">In this paper, we introduce the task of automatically generating text to describe the differences between two similar images. We collect a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> by crowd-sourcing difference descriptions for pairs of <a href=https://en.wikipedia.org/wiki/Film_frame>image frames</a> extracted from <a href=https://en.wikipedia.org/wiki/Closed-circuit_television>video-surveillance footage</a>. Annotators were asked to succinctly describe all the differences in a short paragraph. As a result, our novel <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> provides an opportunity to explore <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that align language and <a href=https://en.wikipedia.org/wiki/Visual_perception>vision</a>, and capture <a href=https://en.wikipedia.org/wiki/Salience_(neuroscience)>visual salience</a>. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> may also be a useful benchmark for coherent multi-sentence generation. We perform a first-pass visual analysis that exposes clusters of differing pixels as a proxy for object-level differences. We propose a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that captures visual salience by using a <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variable</a> to align clusters of differing pixels with output sentences. We find that, for both single-sentence generation and as well as multi-sentence generation, the proposed model outperforms the models that use <a href=https://en.wikipedia.org/wiki/Attention>attention</a> alone.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1154.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1154 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1154 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1154.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1154" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1154/>Learning to Generate Move-by-Move Commentary for Chess Games from Large-Scale Social Forum Data</a></strong><br><a href=/people/h/harsh-jhamtani/>Harsh Jhamtani</a>
|
<a href=/people/v/varun-gangal/>Varun Gangal</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1154><div class="card-body p-3 small">This paper examines the problem of generating natural language descriptions of chess games. We introduce a new large-scale chess commentary dataset and propose methods to generate commentary for individual moves in a <a href=https://en.wikipedia.org/wiki/Chess>chess game</a>. The introduced <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> consists of more than 298 K chess move-commentary pairs across 11 K chess games. We highlight how this task poses unique research challenges in <a href=https://en.wikipedia.org/wiki/Natural-language_generation>natural language generation</a> : the <a href=https://en.wikipedia.org/wiki/Data>data</a> contain a large variety of styles of commentary and frequently depend on pragmatic context. We benchmark various baselines and propose an end-to-end trainable neural model which takes into account multiple pragmatic aspects of the game state that may be commented upon to describe a given chess move. Through a human study on predictions for a subset of the <a href=https://en.wikipedia.org/wiki/Data>data</a> which deals with direct move descriptions, we observe that outputs from our models are rated similar to ground truth commentary texts in terms of <a href=https://en.wikipedia.org/wiki/Correctness_(computer_science)>correctness</a> and <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a>.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2065.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2065 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2065 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-2065.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-2065/>Automatic Compositor Attribution in the First Folio of Shakespeare</a></strong><br><a href=/people/m/maria-ryskina/>Maria Ryskina</a>
|
<a href=/people/h/hannah-alpert-abrams/>Hannah Alpert-Abrams</a>
|
<a href=/people/d/dan-garrette/>Dan Garrette</a>
|
<a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2065><div class="card-body p-3 small">Compositor attribution, the clustering of pages in a historical printed document by the individual who set the type, is a bibliographic task that relies on analysis of orthographic variation and inspection of visual details of the printed page. In this paper, we introduce a novel <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised model</a> that jointly describes the textual and visual features needed to distinguish compositors. Applied to images of Shakespeare&#8217;s First Folio, our model predicts attributions that agree with the manual judgements of bibliographers with an accuracy of 87 %, even on text that is the output of <a href=https://en.wikipedia.org/wiki/Optical_character_recognition>OCR</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1275.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1275 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1275 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D17-1275.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D17-1275" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D17-1275/>Identifying Products in Online Cybercrime Marketplaces : A Dataset for Fine-grained Domain Adaptation</a></strong><br><a href=/people/g/greg-durrett/>Greg Durrett</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a>
|
<a href=/people/r/rebecca-portnoff/>Rebecca Portnoff</a>
|
<a href=/people/s/sadia-afroz/>Sadia Afroz</a>
|
<a href=/people/d/damon-mccoy/>Damon McCoy</a>
|
<a href=/people/k/kirill-levchenko/>Kirill Levchenko</a>
|
<a href=/people/v/vern-paxson/>Vern Paxson</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1275><div class="card-body p-3 small">One weakness of machine-learned NLP models is that they typically perform poorly on out-of-domain data. In this work, we study the task of identifying products being bought and sold in online cybercrime forums, which exhibits particularly challenging cross-domain effects. We formulate a task that represents a hybrid of slot-filling information extraction and <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a> and annotate <a href=https://en.wikipedia.org/wiki/Data>data</a> from four different forums. Each of these <a href=https://en.wikipedia.org/wiki/Internet_forum>forums</a> constitutes its own fine-grained domain in that the <a href=https://en.wikipedia.org/wiki/Internet_forum>forums</a> cover different market sectors with different properties, even though all forums are in the broad domain of <a href=https://en.wikipedia.org/wiki/Cybercrime>cybercrime</a>. We characterize these domain differences in the context of a <a href=https://en.wikipedia.org/wiki/Machine_learning>learning-based system</a> : <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised models</a> see decreased accuracy when applied to new forums, and standard techniques for <a href=https://en.wikipedia.org/wiki/Semi-supervised_learning>semi-supervised learning</a> and <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> have limited effectiveness on this data, which suggests the need to improve these techniques. We release a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 1,938 annotated posts from across the four forums.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Taylor+Berg-Kirkpatrick" title="Search for 'Taylor Berg-Kirkpatrick' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/h/harsh-jhamtani/ class=align-middle>Harsh Jhamtani</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/g/graham-neubig/ class=align-middle>Graham Neubig</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/j/junxian-he/ class=align-middle>Junxian He</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/b/bodhisattwa-prasad-majumder/ class=align-middle>Bodhisattwa Prasad Majumder</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/julian-mcauley/ class=align-middle>Julian McAuley</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/m/maria-ryskina/ class=align-middle>Maria Ryskina</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/daniel-spokoyny/ class=align-middle>Daniel Spokoyny</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/matthew-r-gormley/ class=align-middle>Matthew R. Gormley</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hannah-alpert-abrams/ class=align-middle>Hannah Alpert-Abrams</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dan-garrette/ class=align-middle>Dan Garrette</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fatemehsadat-mireshghallah/ class=align-middle>Fatemehsadat Mireshghallah</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nikita-srivatsan/ class=align-middle>Nikita Srivatsan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jonathan-barron/ class=align-middle>Jonathan Barron</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dan-klein/ class=align-middle>Dan Klein</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/greg-durrett/ class=align-middle>Greg Durrett</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jonathan-k-kummerfeld/ class=align-middle>Jonathan K. Kummerfeld</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rebecca-portnoff/ class=align-middle>Rebecca Portnoff</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sadia-afroz/ class=align-middle>Sadia Afroz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/damon-mccoy/ class=align-middle>Damon McCoy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kirill-levchenko/ class=align-middle>Kirill Levchenko</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vern-paxson/ class=align-middle>Vern Paxson</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/varun-gangal/ class=align-middle>Varun Gangal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eduard-hovy/ class=align-middle>Eduard Hovy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhisong-zhang/ class=align-middle>Zhisong Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">5</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>