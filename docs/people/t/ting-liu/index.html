<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Ting Liu - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Ting</span> <span class=font-weight-bold>Liu</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.33.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--33 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.33 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.acl-long.33" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.33/>e-<span class=acl-fixed-case>CARE</span>: a New Dataset for Exploring Explainable Causal Reasoning</a></strong><br><a href=/people/l/li-du/>Li Du</a>
|
<a href=/people/x/xiao-ding/>Xiao Ding</a>
|
<a href=/people/k/kai-xiong/>Kai Xiong</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/b/bing-qin/>Bing Qin</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--33><div class="card-body p-3 small">Understanding causality has vital importance for various Natural Language Processing (NLP) applications. Beyond the labeled instances, conceptual explanations of the causality can provide deep understanding of the causal fact to facilitate the causal reasoning process. However, such explanation information still remains absent in existing causal reasoning resources. In this paper, we fill this gap by presenting a human-annotated explainable CAusal REasoning dataset (e-CARE), which contains over 20K causal reasoning questions, together with natural language formed explanations of the causal questions. Experimental results show that generating valid explanations for causal facts still remains especially challenging for the state-of-the-art models, and the explanation information can be helpful for promoting the accuracy and stability of causal reasoning models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.421.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--421 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.421 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2022.acl-long.421.software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2022.acl-long.421/><span class=acl-fixed-case>CLIP</span> Models are Few-Shot Learners: Empirical Studies on <span class=acl-fixed-case>VQA</span> and Visual Entailment</a></strong><br><a href=/people/h/haoyu-song/>Haoyu Song</a>
|
<a href=/people/l/li-dong/>Li Dong</a>
|
<a href=/people/w/weinan-zhang/>Weinan Zhang</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/f/furu-wei/>Furu Wei</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--421><div class="card-body p-3 small">CLIP has shown a remarkable zero-shot capability on a wide range of vision tasks. Previously, CLIP is only regarded as a powerful visual encoder. However, after being pre-trained by language supervision from a large amount of image-caption pairs, CLIP itself should also have acquired some few-shot abilities for vision-language tasks. In this work, we empirically show that CLIP can be a strong vision-language few-shot learner by leveraging the power of language. We first evaluate CLIP&#8217;s zero-shot performance on a typical visual question answering task and demonstrate a zero-shot cross-modality transfer capability of CLIP on the visual entailment task. Then we propose a parameter-efficient fine-tuning strategy to boost the few-shot performance on the vqa task. We achieve competitive zero/few-shot results on the visual question answering and visual entailment tasks without introducing any additional pre-training procedure.</div></div><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.14" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.14/>BoB : BERT Over BERT for Training Persona-based Dialogue Models from Limited Personalized Data<span class=acl-fixed-case>B</span>o<span class=acl-fixed-case>B</span>: <span class=acl-fixed-case>BERT</span> Over <span class=acl-fixed-case>BERT</span> for Training Persona-based Dialogue Models from Limited Personalized Data</a></strong><br><a href=/people/h/haoyu-song/>Haoyu Song</a>
|
<a href=/people/y/yan-wang/>Yan Wang</a>
|
<a href=/people/k/kaiyan-zhang/>Kaiyan Zhang</a>
|
<a href=/people/w/weinan-zhang/>Wei-Nan Zhang</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--14><div class="card-body p-3 small">Maintaining a consistent persona is essential for dialogue agents. Although tremendous advancements have been brought, the limited-scale of annotated personalized dialogue datasets is still a barrier towards training robust and consistent persona-based dialogue models. This work shows how this challenge can be addressed by disentangling persona-based dialogue generation into two sub-tasks with a novel BERT-over-BERT (BoB) model. Specifically, the model consists of a BERT-based encoder and two BERT-based decoders, where one decoder is for response generation, and another is for consistency understanding. In particular, to learn the ability of consistency understanding from large-scale non-dialogue inference data, we train the second decoder in an unlikelihood manner. Under different limited data settings, both automatic and human evaluations demonstrate that the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms strong baselines in response quality and persona consistency.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.15" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.15/>GL-GIN : Fast and Accurate Non-Autoregressive Model for Joint Multiple Intent Detection and Slot Filling<span class=acl-fixed-case>GL</span>-<span class=acl-fixed-case>GIN</span>: Fast and Accurate Non-Autoregressive Model for Joint Multiple Intent Detection and Slot Filling</a></strong><br><a href=/people/l/libo-qin/>Libo Qin</a>
|
<a href=/people/f/fuxuan-wei/>Fuxuan Wei</a>
|
<a href=/people/t/tianbao-xie/>Tianbao Xie</a>
|
<a href=/people/x/xiao-xu/>Xiao Xu</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--15><div class="card-body p-3 small">Multi-intent SLU can handle multiple intents in an utterance, which has attracted increasing attention. However, the state-of-the-art joint models heavily rely on <a href=https://en.wikipedia.org/wiki/Autoregressive_model>autoregressive approaches</a>, resulting in two issues : slow inference speed and <a href=https://en.wikipedia.org/wiki/Information_leakage>information leakage</a>. In this paper, we explore a non-autoregressive model for joint multiple intent detection and slot filling, achieving more fast and accurate. Specifically, we propose a Global-Locally Graph Interaction Network (GL-GIN) where a local slot-aware graph interaction layer is proposed to model slot dependency for alleviating uncoordinated slots problem while a global intent-slot graph interaction layer is introduced to model the interaction between multiple intents and all slots in the utterance. Experimental results on two public datasets show that our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> achieves state-of-the-art performance while being 11.5 times faster.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.264.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--264 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.264 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.264" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.264/>Consistency Regularization for Cross-Lingual Fine-Tuning</a></strong><br><a href=/people/b/bo-zheng/>Bo Zheng</a>
|
<a href=/people/l/li-dong/>Li Dong</a>
|
<a href=/people/s/shaohan-huang/>Shaohan Huang</a>
|
<a href=/people/w/wenhui-wang/>Wenhui Wang</a>
|
<a href=/people/z/zewen-chi/>Zewen Chi</a>
|
<a href=/people/s/saksham-singhal/>Saksham Singhal</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/x/xia-song/>Xia Song</a>
|
<a href=/people/f/furu-wei/>Furu Wei</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--264><div class="card-body p-3 small">Fine-tuning pre-trained cross-lingual language models can transfer task-specific supervision from one language to the others. In this work, we propose to improve cross-lingual fine-tuning with consistency regularization. Specifically, we use example consistency regularization to penalize the prediction sensitivity to four types of data augmentations, i.e., subword sampling, <a href=https://en.wikipedia.org/wiki/Gaussian_noise>Gaussian noise</a>, code-switch substitution, and <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. In addition, we employ <a href=https://en.wikipedia.org/wiki/Consistency_(statistics)>model consistency</a> to regularize the <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained with two augmented versions of the same training set. Experimental results on the XTREME benchmark show that our method significantly improves cross-lingual fine-tuning across various tasks, including text classification, <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>, and <a href=https://en.wikipedia.org/wiki/Sequence_labeling>sequence labeling</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.339.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--339 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.339 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.339/>Neural Stylistic Response Generation with Disentangled Latent Variables</a></strong><br><a href=/people/q/qingfu-zhu/>Qingfu Zhu</a>
|
<a href=/people/w/weinan-zhang/>Wei-Nan Zhang</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--339><div class="card-body p-3 small">Generating open-domain conversational responses in the desired style usually suffers from the lack of parallel data in the style. Meanwhile, using monolingual stylistic data to increase style intensity often leads to the expense of decreasing content relevance. In this paper, we propose to disentangle the content and style in latent space by diluting sentence-level information in style representations. Combining the desired style representation and a response content representation will then obtain a stylistic response. Our approach achieves a higher BERT-based style intensity score and comparable BLEU scores, compared with baselines. Human evaluation results show that our approach significantly improves style intensity and maintains content relevance.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.118.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--118 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.118 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938878 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.118" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.118/>Benchmarking Meaning Representations in Neural Semantic Parsing</a></strong><br><a href=/people/j/jiaqi-guo/>Jiaqi Guo</a>
|
<a href=/people/q/qian-liu/>Qian Liu</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/z/zhenwen-li/>Zhenwen Li</a>
|
<a href=/people/x/xueqing-liu/>Xueqing Liu</a>
|
<a href=/people/t/tao-xie/>Tao Xie</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--118><div class="card-body p-3 small">Meaning representation is an important component of <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a>. Although researchers have designed a lot of meaning representations, recent work focuses on only a few of <a href=https://en.wikipedia.org/wiki/List_of_Latin_phrases_(M)>them</a>. Thus, the impact of meaning representation on <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> is less understood. Furthermore, existing work&#8217;s performance is often not comprehensively evaluated due to the lack of readily-available execution engines. Upon identifying these gaps, we propose, a new unified benchmark on meaning representations, by integrating existing semantic parsing datasets, completing the missing logical forms, and implementing the missing execution engines. The resulting unified benchmark contains the complete enumeration of <a href=https://en.wikipedia.org/wiki/Logical_form>logical forms</a> and <a href=https://en.wikipedia.org/wiki/Execution_(computing)>execution engines</a> over three datasets four meaning representations. A thorough experimental study on Unimer reveals that neural semantic parsing approaches exhibit notably different performance when they are trained to generate different meaning representations. Also, program alias and <a href=https://en.wikipedia.org/wiki/Formal_grammar>grammar rules</a> heavily impact the performance of different <a href=https://en.wikipedia.org/wiki/Semantics>meaning representations</a>. Our <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark</a>, execution engines and implementation can be found on : https://github.com/JasperGuo/Unimer.<tex-math>\\times</tex-math> four meaning representations. A thorough experimental study on Unimer reveals that neural semantic parsing approaches exhibit notably different performance when they are trained to generate different meaning representations. Also, program alias and grammar rules heavily impact the performance of different meaning representations. Our benchmark, execution engines and implementation can be found on: https://github.com/JasperGuo/Unimer.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.539.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--539 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.539 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938821 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.539" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.539/>Profile Consistency Identification for Open-domain Dialogue Agents</a></strong><br><a href=/people/h/haoyu-song/>Haoyu Song</a>
|
<a href=/people/y/yan-wang/>Yan Wang</a>
|
<a href=/people/w/weinan-zhang/>Wei-Nan Zhang</a>
|
<a href=/people/z/zhengyu-zhao/>Zhengyu Zhao</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--539><div class="card-body p-3 small">Maintaining a consistent attribute profile is crucial for dialogue agents to naturally converse with humans. Existing studies on improving attribute consistency mainly explored how to incorporate <a href=https://en.wikipedia.org/wiki/Attribute_(computing)>attribute information</a> in the responses, but few efforts have been made to identify the <a href=https://en.wikipedia.org/wiki/Consistency_(database_systems)>consistency relations</a> between response and attribute profile. To facilitate the study of profile consistency identification, we create a large-scale human-annotated dataset with over 110 K single-turn conversations and their key-value attribute profiles. Explicit relation between <a href=https://en.wikipedia.org/wiki/Information_retrieval>response</a> and profile is manually labeled. We also propose a key-value structure information enriched BERT model to identify the profile consistency, and it gained improvements over strong baselines. Further evaluations on <a href=https://en.wikipedia.org/wiki/Downstream_(networking)>downstream tasks</a> demonstrate that the profile consistency identification model is conducive for improving dialogue consistency.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.546.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--546 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.546 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939367 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.546/>Multi-Stage Pre-training for Automated Chinese Essay Scoring<span class=acl-fixed-case>C</span>hinese Essay Scoring</a></strong><br><a href=/people/w/wei-song/>Wei Song</a>
|
<a href=/people/k/kai-zhang/>Kai Zhang</a>
|
<a href=/people/r/ruiji-fu/>Ruiji Fu</a>
|
<a href=/people/l/lizhen-liu/>Lizhen Liu</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/m/miaomiao-cheng/>Miaomiao Cheng</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--546><div class="card-body p-3 small">This paper proposes a pre-training based automated Chinese essay scoring method. The method involves three components : weakly supervised pre-training, supervised cross- prompt fine-tuning and supervised target- prompt fine-tuning. An essay scorer is first pre- trained on a large essay dataset covering diverse topics and with coarse ratings, i.e., good and poor, which are used as a kind of weak supervision. The pre-trained essay scorer would be further fine-tuned on previously rated es- says from existing prompts, which have the same score range with the target prompt and provide extra supervision. At last, the <a href=https://en.wikipedia.org/wiki/Score_(sport)>scorer</a> is fine-tuned on the target-prompt training data. The evaluation on four prompts shows that this method can improve a state-of-the-art neural essay scorer in terms of <a href=https://en.wikipedia.org/wiki/Effectiveness>effectiveness</a> and domain adaptation ability, while in-depth analysis also reveals its limitations..</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.583.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--583 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.583 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938772 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.583/>Is <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>Graph Structure</a> Necessary for Multi-hop Question Answering?<span class=acl-fixed-case>G</span>raph <span class=acl-fixed-case>S</span>tructure <span class=acl-fixed-case>N</span>ecessary for <span class=acl-fixed-case>M</span>ulti-hop <span class=acl-fixed-case>Q</span>uestion <span class=acl-fixed-case>A</span>nswering?</a></strong><br><a href=/people/n/nan-shao/>Nan Shao</a>
|
<a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--583><div class="card-body p-3 small">Recently, attempting to model texts as <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> and introducing graph neural networks to deal with it has become a trend in many <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP research areas</a>. In this paper, we investigate whether the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> is necessary for textual multi-hop reasoning. Our analysis is centered on HotpotQA. We construct a strong baseline model to establish that, with the proper use of pre-trained models, <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> may not be necessary for textual multi-hop reasoning. We point out that both <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> and <a href=https://en.wikipedia.org/wiki/Adjacency_matrix>adjacency matrix</a> are task-related prior knowledge, and graph-attention can be considered as a special case of self-attention. Experiments demonstrate that graph-attention or the entire <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> can be replaced by self-attention or Transformers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928822 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.10/>Slot-consistent NLG for Task-oriented Dialogue Systems with Iterative Rectification Network<span class=acl-fixed-case>NLG</span> for Task-oriented Dialogue Systems with Iterative Rectification Network</a></strong><br><a href=/people/y/yangming-li/>Yangming Li</a>
|
<a href=/people/k/kaisheng-yao/>Kaisheng Yao</a>
|
<a href=/people/l/libo-qin/>Libo Qin</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/x/xiaolong-li/>Xiaolong Li</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--10><div class="card-body p-3 small">Data-driven approaches using <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> have achieved promising performances in natural language generation (NLG). However, neural generators are prone to make mistakes, e.g., neglecting an input slot value and generating a redundant slot value. Prior works refer this to <a href=https://en.wikipedia.org/wiki/Hallucination>hallucination phenomenon</a>. In this paper, we study slot consistency for building reliable NLG systems with all slot values of input dialogue act (DA) properly generated in output sentences. We propose Iterative Rectification Network (IRN) for improving general NLG systems to produce both correct and fluent responses. It applies a <a href=https://en.wikipedia.org/wiki/Bootstrapping_(statistics)>bootstrapping algorithm</a> to sample training candidates and uses <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> to incorporate discrete reward related to slot inconsistency into training. Comprehensive studies have been conducted on multiple benchmark datasets, showing that the proposed methods have significantly reduced the slot error rate (ERR) for all strong baselines. Human evaluations also have confirmed its effectiveness.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.599.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--599 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.599 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928861 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.599" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.599/>Document Modeling with Graph Attention Networks for Multi-grained Machine Reading Comprehension</a></strong><br><a href=/people/b/bo-zheng/>Bo Zheng</a>
|
<a href=/people/h/haoyang-wen/>Haoyang Wen</a>
|
<a href=/people/y/yaobo-liang/>Yaobo Liang</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/d/daxin-jiang/>Daxin Jiang</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--599><div class="card-body p-3 small">Natural Questions is a new challenging machine reading comprehension benchmark with two-grained answers, which are a long answer (typically a paragraph) and a short answer (one or more entities inside the long answer). Despite the effectiveness of existing methods on this <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmark</a>, they treat these two sub-tasks individually during training while ignoring their dependencies. To address this issue, we present a novel multi-grained machine reading comprehension framework that focuses on modeling documents at their hierarchical nature, which are different levels of granularity : documents, paragraphs, sentences, and tokens. We utilize graph attention networks to obtain different levels of <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representations</a> so that they can be learned simultaneously. The long and short answers can be extracted from paragraph-level representation and token-level representation, respectively. In this way, we can model the dependencies between the two-grained answers to provide evidence for each other. We jointly train the two sub-tasks, and our experiments show that our approach significantly outperforms previous systems at both long and short answer criteria.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928594 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-demos.2" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.2/>TextBrewer : An Open-Source Knowledge Distillation Toolkit for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a><span class=acl-fixed-case>T</span>ext<span class=acl-fixed-case>B</span>rewer: <span class=acl-fixed-case>A</span>n <span class=acl-fixed-case>O</span>pen-<span class=acl-fixed-case>S</span>ource <span class=acl-fixed-case>K</span>nowledge <span class=acl-fixed-case>D</span>istillation <span class=acl-fixed-case>T</span>oolkit for <span class=acl-fixed-case>N</span>atural <span class=acl-fixed-case>L</span>anguage <span class=acl-fixed-case>P</span>rocessing</a></strong><br><a href=/people/z/ziqing-yang/>Ziqing Yang</a>
|
<a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/z/zhipeng-chen/>Zhipeng Chen</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a><br><a href=/volumes/2020.acl-demos/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--2><div class="card-body p-3 small">In this paper, we introduce TextBrewer, an open-source knowledge distillation toolkit designed for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. It works with different neural network models and supports various kinds of supervised learning tasks, such as <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a>, <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>, <a href=https://en.wikipedia.org/wiki/Sequence_labeling>sequence labeling</a>. TextBrewer provides a simple and uniform workflow that enables quick setting up of <a href=https://en.wikipedia.org/wiki/Distillation>distillation</a> experiments with highly flexible configurations. It offers a set of predefined distillation methods and can be extended with custom code. As a case study, we use TextBrewer to distill BERT on several typical NLP tasks. With simple configurations, we achieve results that are comparable with or even higher than the public distilled BERT models with similar numbers of parameters.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.122.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--122 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.122 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.122/>A Compare Aggregate Transformer for Understanding Document-grounded Dialogue</a></strong><br><a href=/people/l/longxuan-ma/>Longxuan Ma</a>
|
<a href=/people/w/weinan-zhang/>Wei-Nan Zhang</a>
|
<a href=/people/r/runxin-sun/>Runxin Sun</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--122><div class="card-body p-3 small">Unstructured documents serving as external knowledge of the dialogues help to generate more informative responses. Previous research focused on knowledge selection (KS) in the document with dialogue. However, dialogue history that is not related to the current dialogue may introduce <a href=https://en.wikipedia.org/wiki/Noise_(electronics)>noise</a> in the KS processing. In this paper, we propose a Compare Aggregate Transformer (CAT) to jointly denoise the dialogue context and aggregate the document information for response generation. We designed two different comparison mechanisms to reduce <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a> (before and during decoding). In addition, we propose two <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> for evaluating document utilization efficiency based on word overlap. Experimental results on the CMU_DoG dataset show that the proposed CAT model outperforms the state-of-the-art approach and strong baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.262.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--262 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.262 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.findings-emnlp.262.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.262/>Enhancing Content Planning for Table-to-Text Generation with Data Understanding and Verification</a></strong><br><a href=/people/h/heng-gong/>Heng Gong</a>
|
<a href=/people/w/wei-bi/>Wei Bi</a>
|
<a href=/people/x/xiaocheng-feng/>Xiaocheng Feng</a>
|
<a href=/people/b/bing-qin/>Bing Qin</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--262><div class="card-body p-3 small">Neural table-to-text models, which select and order salient data, as well as verbalizing them fluently via surface realization, have achieved promising progress. Based on results from previous work, the performance bottleneck of current models lies in the stage of content planing (selecting and ordering salient content from the input). That is, performance drops drastically when an <a href=https://en.wikipedia.org/wiki/Oracle_machine>oracle content plan</a> is replaced by a model-inferred one during surface realization. In this paper, we propose to enhance neural content planning by (1) understanding data values with contextual numerical value representations that bring the sense of value comparison into content planning ; (2) verifying the importance and ordering of the selected sequence of records with policy gradient. We evaluated our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on ROTOWIRE and MLB, two datasets on this task, and results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms existing systems with respect to content planning metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.coling-main.4" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.4/>CharBERT : Character-aware Pre-trained Language Model<span class=acl-fixed-case>C</span>har<span class=acl-fixed-case>BERT</span>: Character-aware Pre-trained Language Model</a></strong><br><a href=/people/w/wentao-ma/>Wentao Ma</a>
|
<a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/c/chenglei-si/>Chenglei Si</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--4><div class="card-body p-3 small">Most pre-trained language models (PLMs) construct word representations at subword level with Byte-Pair Encoding (BPE) or its variations, by which OOV (out-of-vocab) words are almost avoidable. However, those methods split a word into subword units and make the representation incomplete and fragile. In this paper, we propose a character-aware pre-trained language model named CharBERT improving on the previous methods (such as BERT, RoBERTa) to tackle these problems. We first construct the contextual word embedding for each token from the sequential character representations, then fuse the representations of characters and the subword representations by a novel heterogeneous interaction module. We also propose a new pre-training task named NLM (Noisy LM) for unsupervised character representation learning. We evaluate our method on <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>, sequence labeling, and text classification tasks, both on the original datasets and adversarial misspelling test sets. The experimental results show that our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> can significantly improve the performance and robustness of PLMs simultaneously.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.238.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--238 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.238 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.coling-main.238" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.238/>Molweni : A Challenge Multiparty Dialogues-based Machine Reading Comprehension Dataset with Discourse Structure</a></strong><br><a href=/people/j/jiaqi-li/>Jiaqi Li</a>
|
<a href=/people/m/ming-liu/>Ming Liu</a>
|
<a href=/people/m/min-yen-kan/>Min-Yen Kan</a>
|
<a href=/people/z/zihao-zheng/>Zihao Zheng</a>
|
<a href=/people/z/zekun-wang/>Zekun Wang</a>
|
<a href=/people/w/wenqiang-lei/>Wenqiang Lei</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/b/bing-qin/>Bing Qin</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--238><div class="card-body p-3 small">Research into the area of multiparty dialog has grown considerably over recent years. We present the Molweni dataset, a machine reading comprehension (MRC) dataset with discourse structure built over multiparty dialog. Molweni&#8217;s source samples from the Ubuntu Chat Corpus, including 10,000 dialogs comprising 88,303 utterances. We annotate 30,066 questions on this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, including both answerable and unanswerable questions. Molweni also uniquely contributes discourse dependency annotations in a modified Segmented Discourse Representation Theory (SDRT ; Asher et al., 2016) style for all of its multiparty dialogs, contributing large-scale (78,245 annotated discourse relations) data to bear on the task of multiparty dialog discourse parsing. Our experiments show that Molweni is a challenging dataset for current MRC models : BERT-wwm, a current, strong SQuAD 2.0 performer, achieves only 67.7 % F1 on Molweni&#8217;s questions, a 20+% significant drop as compared against its SQuAD 2.0 performance.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1013 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1013" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1013/>Entity-Consistent End-to-end Task-Oriented Dialogue System with KB Retriever<span class=acl-fixed-case>KB</span> Retriever</a></strong><br><a href=/people/l/libo-qin/>Libo Qin</a>
|
<a href=/people/y/yijia-liu/>Yijia Liu</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/h/haoyang-wen/>Haoyang Wen</a>
|
<a href=/people/y/yangming-li/>Yangming Li</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1013><div class="card-body p-3 small">Querying the knowledge base (KB) has long been a challenge in the end-to-end task-oriented dialogue system. Previous sequence-to-sequence (Seq2Seq) dialogue generation work treats the <a href=https://en.wikipedia.org/wiki/Kibibyte>KB query</a> as an attention over the entire <a href=https://en.wikipedia.org/wiki/Kibibyte>KB</a>, without the guarantee that the generated entities are consistent with each other. In this paper, we propose a novel <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> which queries the <a href=https://en.wikipedia.org/wiki/Kibibyte>KB</a> in two steps to improve the consistency of generated entities. In the first step, inspired by the observation that a response can usually be supported by a single <a href=https://en.wikipedia.org/wiki/Row_(database)>KB row</a>, we introduce a KB retrieval component which explicitly returns the most relevant <a href=https://en.wikipedia.org/wiki/Row_(database)>KB row</a> given a dialogue history. The retrieval result is further used to filter the irrelevant entities in a Seq2Seq response generation model to improve the consistency among the output entities. In the second step, we further perform the <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanism</a> to address the most correlated KB column. Two methods are proposed to make the training feasible without labeled retrieval data, which include distant supervision and Gumbel-Softmax technique. Experiments on two publicly available task oriented dialog datasets show the effectiveness of our model by outperforming the baseline systems and producing entity-consistent responses.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1029.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1029 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1029 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1029/>Multi-Input Multi-Output Sequence Labeling for Joint Extraction of Fact and Condition Tuples from Scientific Text</a></strong><br><a href=/people/t/tianwen-jiang/>Tianwen Jiang</a>
|
<a href=/people/t/tong-zhao/>Tong Zhao</a>
|
<a href=/people/b/bing-qin/>Bing Qin</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/n/nitesh-chawla/>Nitesh Chawla</a>
|
<a href=/people/m/meng-jiang/>Meng Jiang</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1029><div class="card-body p-3 small">Condition is essential in <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific statement</a>. Without the conditions (e.g., equipment, environment) that were precisely specified, facts (e.g., observations) in the statements may no longer be valid. Existing ScienceIE methods, which aim at extracting factual tuples from scientific text, do not consider the conditions. In this work, we propose a new sequence labeling framework (as well as a new tag schema) to jointly extract the fact and condition tuples from statement sentences. The <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> has (1) a multi-output module to generate one or multiple tuples and (2) a multi-input module to feed in multiple types of signals as sequences. It improves <a href=https://en.wikipedia.org/wiki/F1_score>F1 score</a> relatively by 4.2 % on BioNLP2013 and by 6.2 % on a new bio-text dataset for tuple extraction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1169.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1169 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1169 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1169" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1169/>Cross-Lingual Machine Reading Comprehension</a></strong><br><a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/b/bing-qin/>Bing Qin</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1169><div class="card-body p-3 small">Though the community has made great progress on Machine Reading Comprehension (MRC) task, most of the previous works are solving English-based MRC problems, and there are few efforts on other languages mainly due to the lack of large-scale training data. In this paper, we propose Cross-Lingual Machine Reading Comprehension (CLMRC) task for the languages other than English. Firstly, we present several back-translation approaches for CLMRC task which is straightforward to adopt. However, to exactly align the answer into source language is difficult and could introduce additional noise. In this context, we propose a novel model called Dual BERT, which takes advantage of the large-scale training data provided by rich-resource language (such as English) and learn the semantic relations between the passage and question in bilingual context, and then utilize the learned knowledge to improve <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> performance of low-resource language. We conduct experiments on two Chinese machine reading comprehension datasets CMRC 2018 and DRCD. The results show consistent and significant improvements over various state-of-the-art systems by a large margin, which demonstrate the potentials in CLMRC task. Resources available : https://github.com/ymcui/Cross-Lingual-MRC</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1214.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1214 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1214 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1214" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1214/>A Stack-Propagation Framework with Token-Level Intent Detection for Spoken Language Understanding</a></strong><br><a href=/people/l/libo-qin/>Libo Qin</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/y/yangming-li/>Yangming Li</a>
|
<a href=/people/h/haoyang-wen/>Haoyang Wen</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1214><div class="card-body p-3 small">Intent detection and slot filling are two main tasks for building a spoken language understanding (SLU) system. The two <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> are closely tied and the slots often highly depend on the intent. In this paper, we propose a novel <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> for SLU to better incorporate the intent information, which further guiding the slot filling. In our framework, we adopt a joint model with Stack-Propagation which can directly use the intent information as input for slot filling, thus to capture the intent semantic knowledge. In addition, to further alleviate the <a href=https://en.wikipedia.org/wiki/Error_propagation>error propagation</a>, we perform the token-level intent detection for the Stack-Propagation framework. Experiments on two publicly datasets show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves the state-of-the-art performance and outperforms other previous methods by a large margin. Finally, we use the Bidirectional Encoder Representation from Transformer (BERT) model in our framework, which further boost our performance in SLU task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1495.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1495 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1495 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1495" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1495/>Event Representation Learning Enhanced with External Commonsense Knowledge</a></strong><br><a href=/people/x/xiao-ding/>Xiao Ding</a>
|
<a href=/people/k/kuo-liao/>Kuo Liao</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/z/zhongyang-li/>Zhongyang Li</a>
|
<a href=/people/j/junwen-duan/>Junwen Duan</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1495><div class="card-body p-3 small">Prior work has proposed effective methods to learn <a href=https://en.wikipedia.org/wiki/Event_(computing)>event representations</a> that can capture syntactic and semantic information over <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpus</a>, demonstrating their effectiveness for downstream tasks such as script event prediction. On the other hand, events extracted from raw texts lacks of <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a>, such as the intents and emotions of the event participants, which are useful for distinguishing event pairs when there are only subtle differences in their surface realizations. To address this issue, this paper proposes to leverage external commonsense knowledge about the intent and sentiment of the event. Experiments on three event-related tasks, i.e., event similarity, script event prediction and <a href=https://en.wikipedia.org/wiki/Stock_market_prediction>stock market prediction</a>, show that our model obtains much better event embeddings for the tasks, achieving 78 % improvements on hard similarity task, yielding more precise inferences on subsequent events under given contexts, and better accuracies in predicting the <a href=https://en.wikipedia.org/wiki/Volatility_(finance)>volatilities</a> of the stock market.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1600.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1600 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1600 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1600" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1600/>A Span-Extraction Dataset for Chinese Machine Reading Comprehension<span class=acl-fixed-case>C</span>hinese Machine Reading Comprehension</a></strong><br><a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/l/li-xiao/>Li Xiao</a>
|
<a href=/people/z/zhipeng-chen/>Zhipeng Chen</a>
|
<a href=/people/w/wentao-ma/>Wentao Ma</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1600><div class="card-body p-3 small">Machine Reading Comprehension (MRC) has become enormously popular recently and has attracted a lot of attention. However, the existing reading comprehension datasets are mostly in <a href=https://en.wikipedia.org/wiki/English_language>English</a>. In this paper, we introduce a Span-Extraction dataset for Chinese machine reading comprehension to add <a href=https://en.wikipedia.org/wiki/Language_diversity>language diversities</a> in this area. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is composed by near 20,000 real questions annotated on Wikipedia paragraphs by human experts. We also annotated a challenge set which contains the questions that need comprehensive understanding and multi-sentence inference throughout the context. We present several <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline systems</a> as well as anonymous submissions for demonstrating the difficulties in this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. With the release of the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, we hosted the Second Evaluation Workshop on Chinese Machine Reading Comprehension (CMRC 2018). We hope the release of the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> could further accelerate the Chinese machine reading comprehension research. Resources are available : https://github.com/ymcui/cmrc2018</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1366.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1366 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1366 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1366/>Retrieval-Enhanced Adversarial Training for Neural Response Generation</a></strong><br><a href=/people/q/qingfu-zhu/>Qingfu Zhu</a>
|
<a href=/people/l/lei-cui/>Lei Cui</a>
|
<a href=/people/w/weinan-zhang/>Wei-Nan Zhang</a>
|
<a href=/people/f/furu-wei/>Furu Wei</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1366><div class="card-body p-3 small">Dialogue systems are usually built on either generation-based or retrieval-based approaches, yet they do not benefit from the advantages of different models. In this paper, we propose a Retrieval-Enhanced Adversarial Training (REAT) method for neural response generation. Distinct from existing approaches, the REAT method leverages an encoder-decoder framework in terms of an adversarial training paradigm, while taking advantage of N-best response candidates from a retrieval-based system to construct the discriminator. An empirical study on a large scale public available benchmark dataset shows that the REAT method significantly outperforms the vanilla Seq2Seq model as well as the conventional adversarial training approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1444.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1444 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1444 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1444.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1444" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1444/>Towards Complex Text-to-SQL in Cross-Domain Database with Intermediate Representation<span class=acl-fixed-case>SQL</span> in Cross-Domain Database with Intermediate Representation</a></strong><br><a href=/people/j/jiaqi-guo/>Jiaqi Guo</a>
|
<a href=/people/z/zecheng-zhan/>Zecheng Zhan</a>
|
<a href=/people/y/yan-gao/>Yan Gao</a>
|
<a href=/people/y/yan-xiao/>Yan Xiao</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/d/dongmei-zhang/>Dongmei Zhang</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1444><div class="card-body p-3 small">We present a neural approach called IRNet for complex and cross-domain Text-to-SQL. IRNet aims to address two challenges : 1) the mismatch between intents expressed in natural language (NL) and the implementation details in <a href=https://en.wikipedia.org/wiki/SQL>SQL</a> ; 2) the challenge in predicting columns caused by the large number of out-of-domain words. Instead of end-to-end synthesizing a <a href=https://en.wikipedia.org/wiki/SQL>SQL query</a>, IRNet decomposes the synthesis process into three phases. In the first phase, IRNet performs a schema linking over a question and a <a href=https://en.wikipedia.org/wiki/Database_schema>database schema</a>. Then, IRNet adopts a grammar-based neural model to synthesize a SemQL query which is an intermediate representation that we design to bridge <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NL</a> and <a href=https://en.wikipedia.org/wiki/SQL>SQL</a>. Finally, IRNet deterministically infers a <a href=https://en.wikipedia.org/wiki/SQL>SQL query</a> from the synthesized SemQL query with <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain knowledge</a>. On the challenging Text-to-SQL benchmark Spider, IRNet achieves 46.7 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, obtaining 19.5 % absolute improvement over previous <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>state-of-the-art approaches</a>. At the time of writing, IRNet achieves the first position on the Spider leaderboard.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1002 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=C18-1002" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/C18-1002/>Zero Pronoun Resolution with Attention-based Neural Network</a></strong><br><a href=/people/q/qingyu-yin/>Qingyu Yin</a>
|
<a href=/people/y/yu-zhang/>Yu Zhang</a>
|
<a href=/people/w/weinan-zhang/>Weinan Zhang</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1002><div class="card-body p-3 small">Recent neural network methods for zero pronoun resolution explore multiple models for generating <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representation vectors</a> for zero pronouns and their candidate antecedents. Typically, <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual information</a> is utilized to encode the zero pronouns since they are simply gaps that contain no actual content. To better utilize contexts of the zero pronouns, we here introduce the self-attention mechanism for encoding zero pronouns. With the help of the multiple hops of attention, our model is able to focus on some informative parts of the associated texts and therefore produces an efficient way of encoding the zero pronouns. In addition, an attention-based recurrent neural network is proposed for encoding candidate antecedents by their contents. Experiment results are encouraging : our proposed attention-based model gains the best performance on the Chinese portion of the OntoNotes corpus, substantially surpasses existing Chinese zero pronoun resolution baseline systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1105.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1105 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1105 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=C18-1105" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/C18-1105/>Sequence-to-Sequence Data Augmentation for Dialogue Language Understanding</a></strong><br><a href=/people/y/yutai-hou/>Yutai Hou</a>
|
<a href=/people/y/yijia-liu/>Yijia Liu</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1105><div class="card-body p-3 small">In this paper, we study the problem of <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>language understanding</a> in task-oriented dialogue system. In contrast to previous work which augments an utterance without considering its relation with other utterances, we propose a sequence-to-sequence generation based data augmentation framework that leverages one utterance&#8217;s same semantic alternatives in the training data. A novel diversity rank is incorporated into the utterance representation to make the model produce diverse utterances and these diversely augmented utterances help to improve the language understanding module. Experimental results on the Airline Travel Information System dataset and a newly created semantic frame annotation on Stanford Multi-turn, Multi-domain Dialogue Dataset show that our framework achieves significant improvements of 6.38 and 10.04 F-scores respectively when only a training set of hundreds utterances is represented. Case studies also confirm that our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> generates diverse utterances.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1206.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1206 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1206 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-1206/>Context-Sensitive Generation of Open-Domain Conversational Responses</a></strong><br><a href=/people/w/weinan-zhang/>Weinan Zhang</a>
|
<a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/y/yifa-wang/>Yifa Wang</a>
|
<a href=/people/q/qingfu-zhu/>Qingfu Zhu</a>
|
<a href=/people/l/lingzhi-li/>Lingzhi Li</a>
|
<a href=/people/l/lianqiang-zhou/>Lianqiang Zhou</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1206><div class="card-body p-3 small">Despite the success of existing works on single-turn conversation generation, taking the coherence in consideration, human conversing is actually a context-sensitive process. Inspired by the existing studies, this paper proposed the static and dynamic attention based approaches for context-sensitive generation of open-domain conversational responses. Experimental results on two public datasets show that the proposed static attention based approach outperforms all the baselines on automatic and human evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1320.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1320 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1320 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-1320/>Sequence-to-Sequence Learning for Task-oriented Dialogue with Dialogue State Representation</a></strong><br><a href=/people/h/haoyang-wen/>Haoyang Wen</a>
|
<a href=/people/y/yijia-liu/>Yijia Liu</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/l/libo-qin/>Libo Qin</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1320><div class="card-body p-3 small">Classic <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline models</a> for task-oriented dialogue system require explicit modeling the dialogue states and hand-crafted action spaces to query a domain-specific knowledge base. Conversely, sequence-to-sequence models learn to map dialogue history to the response in current turn without explicit knowledge base querying. In this work, we propose a novel <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> that leverages the advantages of classic pipeline and sequence-to-sequence models. Our framework models a dialogue state as a fixed-size distributed representation and use this <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representation</a> to query a <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base</a> via an attention mechanism. Experiment on Stanford Multi-turn Multi-domain Task-oriented Dialogue Dataset shows that our framework significantly outperforms other sequence-to-sequence based baseline models on both automatic and human evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1048.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1048 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1048 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1048/>Adaptive Multi-pass Decoder for <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a></a></strong><br><a href=/people/x/xinwei-geng/>Xinwei Geng</a>
|
<a href=/people/x/xiaocheng-feng/>Xiaocheng Feng</a>
|
<a href=/people/b/bing-qin/>Bing Qin</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1048><div class="card-body p-3 small">Although end-to-end neural machine translation (NMT) has achieved remarkable progress in the recent years, the idea of adopting multi-pass decoding mechanism into conventional NMT is not well explored. In this paper, we propose a novel architecture called adaptive multi-pass decoder, which introduces a flexible multi-pass polishing mechanism to extend the capacity of NMT via <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a>. More specifically, we adopt an extra policy network to automatically choose a suitable and effective number of decoding passes, according to the <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a> of source sentences and the <a href=https://en.wikipedia.org/wiki/Quality_(business)>quality</a> of the generated translations. Extensive experiments on Chinese-English translation demonstrate the effectiveness of our proposed adaptive multi-pass decoder upon the conventional <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NMT</a> with a significant improvement about 1.55 BLEU.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1183.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1183 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1183 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1183/>Neural Multitask Learning for Simile Recognition</a></strong><br><a href=/people/l/lizhen-liu/>Lizhen Liu</a>
|
<a href=/people/x/xiao-hu/>Xiao Hu</a>
|
<a href=/people/w/wei-song/>Wei Song</a>
|
<a href=/people/r/ruiji-fu/>Ruiji Fu</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1183><div class="card-body p-3 small">Simile is a special type of <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a>, where comparators such as like and as are used to compare two objects. Simile recognition is to recognize <a href=https://en.wikipedia.org/wiki/Simile>simile sentences</a> and extract simile components, i.e., the tenor and the vehicle. This paper presents a study of simile recognition in <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>. We construct an annotated corpus for this research, which consists of 11.3k sentences that contain a <a href=https://en.wikipedia.org/wiki/Comparator>comparator</a>. We propose a neural network framework for jointly optimizing three tasks : simile sentence classification, simile component extraction and <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>. The experimental results show that the neural network based approaches can outperform all rule-based and feature-based baselines. Both simile sentence classification and simile component extraction can benefit from <a href=https://en.wikipedia.org/wiki/Multitask_learning>multitask learning</a>. The <a href=https://en.wikipedia.org/wiki/Conjecture>former</a> can be solved very well, while the <a href=https://en.wikipedia.org/wiki/Conjecture>latter</a> is more difficult.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1189.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1189 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1189 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1189/>SemRegex : A Semantics-Based Approach for Generating <a href=https://en.wikipedia.org/wiki/Regular_expression>Regular Expressions</a> from Natural Language Specifications<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>R</span>egex: A Semantics-Based Approach for Generating Regular Expressions from Natural Language Specifications</a></strong><br><a href=/people/z/zexuan-zhong/>Zexuan Zhong</a>
|
<a href=/people/j/jiaqi-guo/>Jiaqi Guo</a>
|
<a href=/people/w/wei-yang/>Wei Yang</a>
|
<a href=/people/j/jian-peng/>Jian Peng</a>
|
<a href=/people/t/tao-xie/>Tao Xie</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/d/dongmei-zhang/>Dongmei Zhang</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1189><div class="card-body p-3 small">Recent research proposes syntax-based approaches to address the problem of <a href=https://en.wikipedia.org/wiki/Computer_programming>generating programs</a> from <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language specifications</a>. These approaches typically train a sequence-to-sequence learning model using a syntax-based objective : <a href=https://en.wikipedia.org/wiki/Maximum_likelihood_estimation>maximum likelihood estimation (MLE)</a>. Such syntax-based approaches do not effectively address the goal of generating semantically correct programs, because these approaches fail to handle Program Aliasing, i.e., semantically equivalent programs may have many syntactically different forms. To address this issue, in this paper, we propose a semantics-based approach named SemRegex. SemRegex provides solutions for a subtask of the program-synthesis problem : generating <a href=https://en.wikipedia.org/wiki/Regular_expression>regular expressions</a> from <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. Different from the existing syntax-based approaches, SemRegex trains the model by maximizing the expected semantic correctness of the generated <a href=https://en.wikipedia.org/wiki/Regular_expression>regular expressions</a>. The semantic correctness is measured using the DFA-equivalence oracle, random test cases, and distinguishing test cases. The experiments on three public datasets demonstrate the superiority of SemRegex over the existing state-of-the-art approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1264.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1264 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1264 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/306049123 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1264" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1264/>An AMR Aligner Tuned by Transition-based Parser<span class=acl-fixed-case>AMR</span> Aligner Tuned by Transition-based Parser</a></strong><br><a href=/people/y/yijia-liu/>Yijia Liu</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/b/bo-zheng/>Bo Zheng</a>
|
<a href=/people/b/bing-qin/>Bing Qin</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1264><div class="card-body p-3 small">In this paper, we propose a new rich resource enhanced AMR aligner which produces multiple alignments and a new transition system for AMR parsing along with its oracle parser. Our aligner is further tuned by our <a href=https://en.wikipedia.org/wiki/Oracle_machine>oracle parser</a> via picking the alignment that leads to the highest-scored achievable AMR graph. Experimental results show that our aligner outperforms the rule-based aligner in previous work by achieving higher alignment F1 score and consistently improving two open-sourced AMR parsers. Based on our aligner and transition system, we develop a transition-based AMR parser that parses a sentence into its AMR graph directly. An ensemble of our <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a> with only words and POS tags as input leads to 68.4 Smatch F1 score, which outperforms the current state-of-the-art parser.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-2005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K18-2005 data-toggle=collapse aria-expanded=false aria-controls=abstract-K18-2005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K18-2005" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K18-2005/>Towards Better UD Parsing : Deep Contextualized Word Embeddings, Ensemble, and Treebank Concatenation<span class=acl-fixed-case>UD</span> Parsing: Deep Contextualized Word Embeddings, Ensemble, and Treebank Concatenation</a></strong><br><a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/y/yijia-liu/>Yijia Liu</a>
|
<a href=/people/y/yuxuan-wang/>Yuxuan Wang</a>
|
<a href=/people/b/bo-zheng/>Bo Zheng</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/K18-2/ class=text-muted>Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K18-2005><div class="card-body p-3 small">This paper describes our system (HIT-SCIR) submitted to the CoNLL 2018 shared task on Multilingual Parsing from Raw Text to Universal Dependencies. We base our submission on Stanford&#8217;s winning system for the CoNLL 2017 shared task and make two effective extensions : 1) incorporating deep contextualized word embeddings into both the part of speech tagger and <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> ; 2) ensembling parsers trained with different initialization. We also explore different ways of concatenating <a href=https://en.wikipedia.org/wiki/Treebank>treebanks</a> for further improvements. Experimental results on the development data show the effectiveness of our <a href=https://en.wikipedia.org/wiki/Methodology>methods</a>. In the final evaluation, our <a href=https://en.wikipedia.org/wiki/System>system</a> was ranked first according to <a href=https://en.wikipedia.org/wiki/Level_of_service>LAS</a> (75.84 %) and outperformed the other <a href=https://en.wikipedia.org/wiki/System>systems</a> by a large margin.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1034.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1034 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1034 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-1034/>Semantic Parsing with Syntax- and Table-Aware SQL Generation<span class=acl-fixed-case>SQL</span> Generation</a></strong><br><a href=/people/y/yibo-sun/>Yibo Sun</a>
|
<a href=/people/d/duyu-tang/>Duyu Tang</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/j/jianshu-ji/>Jianshu Ji</a>
|
<a href=/people/g/guihong-cao/>Guihong Cao</a>
|
<a href=/people/x/xiaocheng-feng/>Xiaocheng Feng</a>
|
<a href=/people/b/bing-qin/>Bing Qin</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1034><div class="card-body p-3 small">We present a <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> to map <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language questions</a> into <a href=https://en.wikipedia.org/wiki/SQL>SQL queries</a>. Existing neural network based approaches typically generate a SQL query word-by-word, however, a large portion of the generated results is incorrect or not executable due to the mismatch between question words and table contents. Our approach addresses this problem by considering the <a href=https://en.wikipedia.org/wiki/Table_(database)>structure of table</a> and the <a href=https://en.wikipedia.org/wiki/SQL>syntax of SQL language</a>. The quality of the generated SQL query is significantly improved through (1) learning to replicate content from column names, cells or SQL keywords ; and (2) improving the generation of WHERE clause by leveraging the column-cell relation. Experiments are conducted on WikiSQL, a recently released dataset with the largest question- SQL pairs. Our <a href=https://en.wikipedia.org/wiki/Scientific_method>approach</a> significantly improves the state-of-the-art <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>execution accuracy</a> from 69.0 % to 74.4 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1053.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1053 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1053 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1053.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1053" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1053/>Deep Reinforcement Learning for Chinese Zero Pronoun Resolution<span class=acl-fixed-case>C</span>hinese Zero Pronoun Resolution</a></strong><br><a href=/people/q/qingyu-yin/>Qingyu Yin</a>
|
<a href=/people/y/yu-zhang/>Yu Zhang</a>
|
<a href=/people/w/weinan-zhang/>Wei-Nan Zhang</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1053><div class="card-body p-3 small">Recent neural network models for Chinese zero pronoun resolution gain great performance by capturing semantic information for zero pronouns and candidate antecedents, but tend to be short-sighted, operating solely by making local decisions. They typically predict coreference links between the <a href=https://en.wikipedia.org/wiki/Zero_pronoun>zero pronoun</a> and one single candidate antecedent at a time while ignoring their influence on future decisions. Ideally, modeling useful information of preceding potential antecedents is crucial for classifying later zero pronoun-candidate antecedent pairs, a need which leads traditional models of zero pronoun resolution to draw on <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a>. In this paper, we show how to integrate these goals, applying deep reinforcement learning to deal with the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. With the help of the reinforcement learning agent, our system learns the policy of selecting antecedents in a sequential manner, where useful information provided by earlier predicted antecedents could be utilized for making later coreference decisions. Experimental results on OntoNotes 5.0 show that our approach substantially outperforms the state-of-the-art methods under three experimental settings.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3005 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3005/>The HIT-SCIR System for End-to-End Parsing of Universal Dependencies<span class=acl-fixed-case>HIT</span>-<span class=acl-fixed-case>SCIR</span> System for End-to-End Parsing of <span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependencies</a></strong><br><a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/j/jiang-guo/>Jiang Guo</a>
|
<a href=/people/y/yuxuan-wang/>Yuxuan Wang</a>
|
<a href=/people/b/bo-zheng/>Bo Zheng</a>
|
<a href=/people/h/huaipeng-zhao/>Huaipeng Zhao</a>
|
<a href=/people/y/yang-liu/>Yang Liu</a>
|
<a href=/people/d/dechuan-teng/>Dechuan Teng</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/K17-3/ class=text-muted>Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3005><div class="card-body p-3 small">This paper describes our system (HIT-SCIR) for the CoNLL 2017 shared task : Multilingual Parsing from Raw Text to Universal Dependencies. Our system includes three pipelined components : <a href=https://en.wikipedia.org/wiki/Lexical_analysis>tokenization</a>, Part-of-Speech (POS) tagging and dependency parsing. We use character-based bidirectional long short-term memory (LSTM) networks for both tokenization and POS tagging. Afterwards, we employ a list-based transition-based algorithm for general non-projective parsing and present an improved Stack-LSTM-based architecture for representing each transition state and making predictions. Furthermore, to parse low / zero-resource languages and cross-domain data, we use a model transfer approach to make effective use of existing resources. We demonstrate substantial gains against the UDPipe baseline, with an average improvement of 3.76 % in LAS of all languages. And finally, we rank the 4th place on the official test sets.<i>tokenization</i>,\n <i>Part-of-Speech</i> (POS) <i>tagging</i> and <i>dependency parsing</i>.\n We use character-based bidirectional long short-term memory (LSTM) networks for\n both tokenization and POS tagging.\n Afterwards, we employ a list-based transition-based algorithm for general\n non-projective parsing and present an improved Stack-LSTM-based architecture\n for representing each transition state and making predictions.\n Furthermore, to parse low/zero-resource languages and cross-domain data, we use\n a model transfer approach to make effective use of existing resources.\n We demonstrate substantial gains against the UDPipe baseline, with an average\n improvement of 3.76% in LAS of all languages. And finally, we rank the 4th\n place on the official test sets.\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1010 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234953310 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1010/>Generating and Exploiting Large-scale Pseudo Training Data for Zero Pronoun Resolution</a></strong><br><a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/q/qingyu-yin/>Qingyu Yin</a>
|
<a href=/people/w/weinan-zhang/>Wei-Nan Zhang</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1010><div class="card-body p-3 small">Most existing approaches for zero pronoun resolution are heavily relying on annotated data, which is often released by shared task organizers. Therefore, the lack of annotated data becomes a major obstacle in the progress of zero pronoun resolution task. Also, it is expensive to spend manpower on labeling the data for better performance. To alleviate the problem above, in this paper, we propose a simple but novel approach to automatically generate large-scale pseudo training data for zero pronoun resolution. Furthermore, we successfully transfer the cloze-style reading comprehension neural network model into zero pronoun resolution task and propose a two-step training mechanism to overcome the gap between the pseudo training data and the real one. Experimental results show that the proposed <a href=https://en.wikipedia.org/wiki/Design_of_experiments>approach</a> significantly outperforms the state-of-the-art <a href=https://en.wikipedia.org/wiki/System>systems</a> with an absolute improvements of 3.1 % <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> on OntoNotes 5.0 data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1011.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1011 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1011 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234953346 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1011/>Discourse Mode Identification in Essays</a></strong><br><a href=/people/w/wei-song/>Wei Song</a>
|
<a href=/people/d/dong-wang/>Dong Wang</a>
|
<a href=/people/r/ruiji-fu/>Ruiji Fu</a>
|
<a href=/people/l/lizhen-liu/>Lizhen Liu</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1011><div class="card-body p-3 small">Discourse modes play an important role in <a href=https://en.wikipedia.org/wiki/Composition_(language)>writing composition</a> and <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a>. This paper presents a study on the manual and automatic identification of narration, exposition, description, argument and emotion expressing sentences in narrative essays. We annotate a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> to study the characteristics of <a href=https://en.wikipedia.org/wiki/Discourse_analysis>discourse modes</a> and describe a neural sequence labeling model for identification. Evaluation results show that discourse modes can be identified automatically with an average F1-score of 0.7. We further demonstrate that discourse modes can be used as <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> that improve automatic essay scoring (AES). The impacts of discourse modes for <a href=https://en.wikipedia.org/wiki/Advanced_Encryption_Standard>AES</a> are also discussed.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1055.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1055 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1055 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234956590 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P17-1055" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1055/>Attention-over-Attention Neural Networks for Reading Comprehension</a></strong><br><a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/z/zhipeng-chen/>Zhipeng Chen</a>
|
<a href=/people/s/si-wei/>Si Wei</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1055><div class="card-body p-3 small">Cloze-style reading comprehension is a representative problem in mining relationship between document and query. In this paper, we present a simple but novel model called attention-over-attention reader for better solving cloze-style reading comprehension task. The proposed model aims to place another <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanism</a> over the document-level attention and induces attended attention for final answer predictions. One advantage of our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is that <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> is simpler than related works while giving excellent performance. In addition to the primary model, we also propose an N-best re-ranking strategy to double check the validity of the candidates and further improve the performance. Experimental results show that the proposed methods significantly outperform various state-of-the-art systems by a large margin in public datasets, such as <a href=https://en.wikipedia.org/wiki/CNN>CNN</a> and Children&#8217;s Book Test.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2049.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2049 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2049 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2049/>SCIR-QA at SemEval-2017 Task 3 : CNN Model Based on Similar and Dissimilar Information between Keywords for Question Similarity<span class=acl-fixed-case>SCIR</span>-<span class=acl-fixed-case>QA</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 3: <span class=acl-fixed-case>CNN</span> Model Based on Similar and Dissimilar Information between Keywords for Question Similarity</a></strong><br><a href=/people/l/le-qi/>Le Qi</a>
|
<a href=/people/y/yu-zhang/>Yu Zhang</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2049><div class="card-body p-3 small">We describe a method of calculating the similarity of questions in community QA. Question in <a href=https://en.wikipedia.org/wiki/CQA>cQA</a> are usually very long and there are a lot of useless information about calculating the similarity of questions. Therefore, we implement a CNN model based on <a href=https://en.wikipedia.org/wiki/Similarity_measure>similar and dissimilar information</a> between question&#8217;s keywords. We extract the keywords of questions, and then model the similar and dissimilar information between the <a href=https://en.wikipedia.org/wiki/Index_term>keywords</a>, and use the CNN model to calculate the similarity.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1135.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1135 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1135 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1135/>Chinese Zero Pronoun Resolution with Deep Memory Network<span class=acl-fixed-case>C</span>hinese Zero Pronoun Resolution with Deep Memory Network</a></strong><br><a href=/people/q/qingyu-yin/>Qingyu Yin</a>
|
<a href=/people/y/yu-zhang/>Yu Zhang</a>
|
<a href=/people/w/weinan-zhang/>Weinan Zhang</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1135><div class="card-body p-3 small">Existing approaches for Chinese zero pronoun resolution typically utilize only syntactical and lexical features while ignoring semantic information. The fundamental reason is that zero pronouns have no descriptive information, which brings difficulty in explicitly capturing their semantic similarities with antecedents. Meanwhile, representing zero pronouns is challenging since they are merely gaps that convey no actual content. In this paper, we address this issue by building a deep memory network that is capable of encoding zero pronouns into vector representations with information obtained from their contexts and potential antecedents. Consequently, our resolver takes advantage of <a href=https://en.wikipedia.org/wiki/Semantics>semantic information</a> by using these continuous distributed representations. Experiments on the OntoNotes 5.0 dataset show that the proposed memory network could substantially outperform the state-of-the-art systems in various experimental settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1296.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1296 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1296 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D17-1296" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D17-1296/>Transition-Based Disfluency Detection using <a href=https://en.wikipedia.org/wiki/Linear_time-invariant_system>LSTMs</a><span class=acl-fixed-case>LSTM</span>s</a></strong><br><a href=/people/s/shaolei-wang/>Shaolei Wang</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a>
|
<a href=/people/m/meishan-zhang/>Meishan Zhang</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1296><div class="card-body p-3 small">In this paper, we model the problem of disfluency detection using a transition-based framework, which incrementally constructs and labels the disfluency chunk of input sentences using a new transition system without syntax information. Compared with sequence labeling methods, it can capture non-local chunk-level features ; compared with joint parsing and disfluency detection methods, it is free for noise in syntax. Experiments show that our <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> achieves state-of-the-art <a href=https://en.wikipedia.org/wiki/F-score>f-score</a> of 87.5 % on the commonly used English Switchboard test set, and a set of in-house annotated Chinese data.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Ting+Liu" title="Search for 'Ting Liu' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/w/wanxiang-che/ class=align-middle>Wanxiang Che ()</a>
<span class="badge badge-secondary align-middle ml-2">15</span></li><li class=list-group-item><a href=/people/w/weinan-zhang/ class=align-middle>Weinan Zhang</a>
<span class="badge badge-secondary align-middle ml-2">11</span></li><li class=list-group-item><a href=/people/g/guoping-hu/ class=align-middle>Guoping Hu</a>
<span class="badge badge-secondary align-middle ml-2">9</span></li><li class=list-group-item><a href=/people/y/yiming-cui/ class=align-middle>Yiming Cui</a>
<span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/people/b/bing-qin/ class=align-middle>Bing Qin</a>
<span class="badge badge-secondary align-middle ml-2">8</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/s/shijin-wang/ class=align-middle>Shijin Wang</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/y/yijia-liu/ class=align-middle>Yijia Liu</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/l/libo-qin/ class=align-middle>Libo Qin</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/b/bo-zheng/ class=align-middle>Bo Zheng</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/q/qingyu-yin/ class=align-middle>Qingyu Yin</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/y/yu-zhang/ class=align-middle>Yu Zhang</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/h/haoyang-wen/ class=align-middle>Haoyang Wen</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/w/william-yang-wang/ class=align-middle>William Yang Wang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/q/qingfu-zhu/ class=align-middle>Qingfu Zhu</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/h/haoyu-song/ class=align-middle>Haoyu Song</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/f/furu-wei/ class=align-middle>Furu Wei</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/jiaqi-guo/ class=align-middle>Jiaqi Guo</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/jian-guang-lou/ class=align-middle>Jian-Guang Lou</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/w/wei-song/ class=align-middle>Wei Song</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/r/ruiji-fu/ class=align-middle>Ruiji Fu</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/lizhen-liu/ class=align-middle>Lizhen Liu</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/y/yangming-li/ class=align-middle>Yangming Li</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/z/zhipeng-chen/ class=align-middle>Zhipeng Chen</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/x/xiaocheng-feng/ class=align-middle>Xiaocheng Feng</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/y/yan-wang/ class=align-middle>Yan Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/li-dong/ class=align-middle>Li Dong</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/tao-xie/ class=align-middle>Tao Xie</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/x/xiaojiang-liu/ class=align-middle>Xiaojiang Liu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/n/nan-duan/ class=align-middle>Nan Duan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/ming-zhou/ class=align-middle>Ming Zhou</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yuxuan-wang/ class=align-middle>Yuxuan Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/x/xiao-ding/ class=align-middle>Xiao Ding</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/dongmei-zhang/ class=align-middle>Dongmei Zhang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/w/wentao-ma/ class=align-middle>Wentao Ma</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yutai-hou/ class=align-middle>Yutai Hou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yifa-wang/ class=align-middle>Yifa Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lingzhi-li/ class=align-middle>Lingzhi Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lianqiang-zhou/ class=align-middle>Lianqiang Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kaiyan-zhang/ class=align-middle>Kaiyan Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fuxuan-wei/ class=align-middle>Fuxuan Wei</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tianbao-xie/ class=align-middle>Tianbao Xie</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiao-xu/ class=align-middle>Xiao Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shaohan-huang/ class=align-middle>Shaohan Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wenhui-wang/ class=align-middle>Wenhui Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zewen-chi/ class=align-middle>Zewen Chi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/saksham-singhal/ class=align-middle>Saksham Singhal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xia-song/ class=align-middle>Xia Song</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qian-liu/ class=align-middle>Qian Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhenwen-li/ class=align-middle>Zhenwen Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xueqing-liu/ class=align-middle>Xueqing Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhengyu-zhao/ class=align-middle>Zhengyu Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kai-zhang/ class=align-middle>Kai Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/miaomiao-cheng/ class=align-middle>Miaomiao Cheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nan-shao/ class=align-middle>Nan Shao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kaisheng-yao/ class=align-middle>Kaisheng Yao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaolong-li/ class=align-middle>Xiaolong Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yaobo-liang/ class=align-middle>Yaobo Liang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/daxin-jiang/ class=align-middle>Daxin Jiang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/ziqing-yang/ class=align-middle>Ziqing Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiang-guo/ class=align-middle>Jiang Guo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/huaipeng-zhao/ class=align-middle>Huaipeng Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yang-liu/ class=align-middle>Yang Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dechuan-teng/ class=align-middle>Dechuan Teng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dong-wang/ class=align-middle>Dong Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/si-wei/ class=align-middle>Si Wei</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/li-du/ class=align-middle>Li Du</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kai-xiong/ class=align-middle>Kai Xiong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xinwei-geng/ class=align-middle>Xinwei Geng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiao-hu/ class=align-middle>Xiao Hu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zexuan-zhong/ class=align-middle>Zexuan Zhong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wei-yang/ class=align-middle>Wei Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jian-peng/ class=align-middle>Jian Peng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tianwen-jiang/ class=align-middle>Tianwen Jiang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tong-zhao/ class=align-middle>Tong Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nitesh-chawla/ class=align-middle>Nitesh Chawla</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/meng-jiang/ class=align-middle>Meng Jiang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kuo-liao/ class=align-middle>Kuo Liao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhongyang-li/ class=align-middle>Zhongyang Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/junwen-duan/ class=align-middle>Junwen Duan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/li-xiao/ class=align-middle>Li Xiao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/le-qi/ class=align-middle>Le Qi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shaolei-wang/ class=align-middle>Shaolei Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yue-zhang/ class=align-middle>Yue Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/meishan-zhang/ class=align-middle>Meishan Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/longxuan-ma/ class=align-middle>Longxuan Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/runxin-sun/ class=align-middle>Runxin Sun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/heng-gong/ class=align-middle>Heng Gong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wei-bi/ class=align-middle>Wei Bi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chenglei-si/ class=align-middle>Chenglei Si</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiaqi-li/ class=align-middle>Jiaqi Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/ming-liu/ class=align-middle>Ming Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/min-yen-kan/ class=align-middle>Min-Yen Kan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zihao-zheng/ class=align-middle>Zihao Zheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zekun-wang/ class=align-middle>Zekun Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wenqiang-lei/ class=align-middle>Wenqiang Lei</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yibo-sun/ class=align-middle>Yibo Sun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/duyu-tang/ class=align-middle>Duyu Tang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jianshu-ji/ class=align-middle>Jianshu Ji</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/guihong-cao/ class=align-middle>Guihong Cao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lei-cui/ class=align-middle>Lei Cui</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zecheng-zhan/ class=align-middle>Zecheng Zhan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yan-gao/ class=align-middle>Yan Gao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yan-xiao/ class=align-middle>Yan Xiao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">16</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">16</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright &nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>