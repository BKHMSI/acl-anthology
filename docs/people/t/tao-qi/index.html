<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Tao Qi - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Tao</span> <span class=font-weight-bold>Qi</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.423.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--423 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.423 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.423/>HieRec : Hierarchical User Interest Modeling for Personalized News Recommendation<span class=acl-fixed-case>H</span>ie<span class=acl-fixed-case>R</span>ec: Hierarchical User Interest Modeling for Personalized News Recommendation</a></strong><br><a href=/people/t/tao-qi/>Tao Qi</a>
|
<a href=/people/f/fangzhao-wu/>Fangzhao Wu</a>
|
<a href=/people/c/chuhan-wu/>Chuhan Wu</a>
|
<a href=/people/p/peiru-yang/>Peiru Yang</a>
|
<a href=/people/y/yang-yu/>Yang Yu</a>
|
<a href=/people/x/xing-xie/>Xing Xie</a>
|
<a href=/people/y/yongfeng-huang/>Yongfeng Huang</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--423><div class="card-body p-3 small">User interest modeling is critical for personalized news recommendation. Existing news recommendation methods usually learn a single user embedding for each user from their previous behaviors to represent their overall interest. However, user interest is usually diverse and multi-grained, which is difficult to be accurately modeled by a single user embedding. In this paper, we propose a news recommendation method with hierarchical user interest modeling, named HieRec. Instead of a single user embedding, in our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> each user is represented in a hierarchical interest tree to better capture their diverse and multi-grained interest in news. We use a three-level hierarchy to represent 1) overall user interest ; 2) <a href=https://en.wikipedia.org/wiki/Interest_(emotion)>user interest</a> in coarse-grained topics like <a href=https://en.wikipedia.org/wiki/Sport>sports</a> ; and 3) <a href=https://en.wikipedia.org/wiki/Interest_(emotion)>user interest</a> in fine-grained topics like <a href=https://en.wikipedia.org/wiki/Association_football>football</a>. Moreover, we propose a hierarchical user interest matching framework to match candidate news with different levels of user interest for more accurate user interest targeting. Extensive experiments on two real-world datasets validate our method can effectively improve the performance of user modeling for personalized news recommendation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.424.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--424 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.424 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.424/>PP-Rec : News Recommendation with Personalized User Interest and Time-aware News Popularity<span class=acl-fixed-case>PP</span>-Rec: News Recommendation with Personalized User Interest and Time-aware News Popularity</a></strong><br><a href=/people/t/tao-qi/>Tao Qi</a>
|
<a href=/people/f/fangzhao-wu/>Fangzhao Wu</a>
|
<a href=/people/c/chuhan-wu/>Chuhan Wu</a>
|
<a href=/people/y/yongfeng-huang/>Yongfeng Huang</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--424><div class="card-body p-3 small">Personalized news recommendation methods are widely used in <a href=https://en.wikipedia.org/wiki/Online_newspaper>online news services</a>. These methods usually recommend news based on the matching between <a href=https://en.wikipedia.org/wiki/Content_(media)>news content</a> and <a href=https://en.wikipedia.org/wiki/Interest_(emotion)>user interest</a> inferred from historical behaviors. However, these methods usually have difficulties in making accurate recommendations to cold-start users, and tend to recommend similar news with those users have read. In general, popular news usually contain important information and can attract users with different interests. Besides, they are usually diverse in content and topic. Thus, in this paper we propose to incorporate news popularity information to alleviate the cold-start and diversity problems for personalized news recommendation. In our method, the ranking score for recommending a candidate news to a target user is the combination of a personalized matching score and a news popularity score. The former is used to capture the personalized user interest in news. The latter is used to measure time-aware popularity of candidate news, which is predicted based on news content, recency, and real-time CTR using a unified framework. Besides, we propose a popularity-aware user encoder to eliminate the popularity bias in user behaviors for accurate interest modeling. Experiments on two real-world datasets show our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> can effectively improve the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and <a href=https://en.wikipedia.org/wiki/Diversity_(politics)>diversity</a> for <a href=https://en.wikipedia.org/wiki/News_aggregator>news recommendation</a>.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ccl-1.106.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ccl-1--106 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ccl-1.106 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ccl-1.106/>Clickbait Detection with Style-aware Title Modeling and Co-attention</a></strong><br><a href=/people/c/chuhan-wu/>Chuhan Wu</a>
|
<a href=/people/f/fangzhao-wu/>Fangzhao Wu</a>
|
<a href=/people/t/tao-qi/>Tao Qi</a>
|
<a href=/people/y/yongfeng-huang/>Yongfeng Huang</a><br><a href=/volumes/2020.ccl-1/ class=text-muted>Proceedings of the 19th Chinese National Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ccl-1--106><div class="card-body p-3 small">Clickbait is a form of <a href=https://en.wikipedia.org/wiki/Web_content>web content</a> designed to attract attention and entice users to click on specific hyperlinks. The detection of clickbaits is an important task for online platforms to improve the quality of web content and the satisfaction of users. Clickbait detection is typically formed as a binary classification task based on the title and body of a webpage, and existing methods are mainly based on the content of title and the relevance between title and body. However, these methods ignore the stylistic patterns of titles, which can provide important clues on identifying <a href=https://en.wikipedia.org/wiki/Clickbait>clickbaits</a>. In addition, they do not consider the interactions between the contexts within title and body, which are very important for measuring their <a href=https://en.wikipedia.org/wiki/Relevance>relevance</a> for clickbait detection. In this paper, we propose a clickbait detection approach with style-aware title modeling and co-attention. Specifically, we use Transformers to learn content representations of title and body, and respectively compute two content-based clickbait scores for title and body based on their <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a>. In addition, we propose to use a character-level Transformer to learn a style-aware title representation by capturing the stylistic patterns of title, and we compute a title stylistic score based on this representation. Besides, we propose to use a co-attention network to model the relatedness between the contexts within title and body, and further enhance their representations by encoding the interaction information. We compute a title-body matching score based on the representations of title and body enhanced by their interactions. The final clickbait score is predicted by a weighted summation of the aforementioned four kinds of scores.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.aacl-main.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--aacl-main--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.aacl-main.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.aacl-main.22/>Named Entity Recognition in Multi-level Contexts</a></strong><br><a href=/people/y/yubo-chen/>Yubo Chen</a>
|
<a href=/people/c/chuhan-wu/>Chuhan Wu</a>
|
<a href=/people/t/tao-qi/>Tao Qi</a>
|
<a href=/people/z/zhigang-yuan/>Zhigang Yuan</a>
|
<a href=/people/y/yongfeng-huang/>Yongfeng Huang</a><br><a href=/volumes/2020.aacl-main/ class=text-muted>Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--aacl-main--22><div class="card-body p-3 small">Named entity recognition is a critical task in the <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing field</a>. Most existing <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> can only exploit <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual information</a> within a sentence. However, their performance on recognizing entities in limited or ambiguous sentence-level contexts is usually unsatisfactory. Fortunately, other sentences in the same document can provide supplementary document-level contexts to help recognize these entities. In addition, words themselves contain word-level contextual information since they usually have different preferences of entity type and relative position from named entities. In this paper, we propose a unified framework to incorporate <a href=https://en.wikipedia.org/wiki/Context_(computing)>multi-level contexts</a> for <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>. We use TagLM as our basic <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to capture sentence-level contexts. To incorporate document-level contexts, we propose to capture interactions between sentences via a multi-head self attention network. To mine word-level contexts, we propose an auxiliary task to predict the type of each word to capture its type preference. We jointly train our model in entity recognition and the auxiliary classification task via <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a>. The experimental results on several <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark datasets</a> validate the effectiveness of our <a href=https://en.wikipedia.org/wiki/Methodology>method</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1493.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1493 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1493 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1493/>Neural News Recommendation with Heterogeneous User Behavior</a></strong><br><a href=/people/c/chuhan-wu/>Chuhan Wu</a>
|
<a href=/people/f/fangzhao-wu/>Fangzhao Wu</a>
|
<a href=/people/m/mingxiao-an/>Mingxiao An</a>
|
<a href=/people/t/tao-qi/>Tao Qi</a>
|
<a href=/people/j/jianqiang-huang/>Jianqiang Huang</a>
|
<a href=/people/y/yongfeng-huang/>Yongfeng Huang</a>
|
<a href=/people/x/xing-xie/>Xing Xie</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1493><div class="card-body p-3 small">News recommendation is important for <a href=https://en.wikipedia.org/wiki/Online_newspaper>online news platforms</a> to help users find interested news and alleviate <a href=https://en.wikipedia.org/wiki/Information_overload>information overload</a>. Existing news recommendation methods usually rely on the news click history to model <a href=https://en.wikipedia.org/wiki/Interest_(emotion)>user interest</a>. However, these methods may suffer from the data sparsity problem, since the news click behaviors of many users in online news platforms are usually very limited. Fortunately, some other kinds of user behaviors such as <a href=https://en.wikipedia.org/wiki/Web_navigation>webpage browsing</a> and <a href=https://en.wikipedia.org/wiki/Web_search_query>search queries</a> can also provide useful clues of users&#8217; news reading interest. In this paper, we propose a neural news recommendation approach which can exploit heterogeneous user behaviors. Our approach contains two major <a href=https://en.wikipedia.org/wiki/Modular_programming>modules</a>, i.e., <a href=https://en.wikipedia.org/wiki/News_media>news representation</a> and <a href=https://en.wikipedia.org/wiki/User_interface>user representation</a>. In the news representation module, we learn representations of news from their titles via CNN networks, and apply attention networks to select important words. In the user representation module, we propose an attentive multi-view learning framework to learn unified representations of users from their heterogeneous behaviors such as <a href=https://en.wikipedia.org/wiki/Web_search_query>search queries</a>, clicked news and browsed webpages. In addition, we use word- and record-level attentions to select informative words and behavior records. Experiments on a real-world dataset validate the effectiveness of our approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3214.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3214 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3214 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3214/>Detecting and Extracting of Adverse Drug Reaction Mentioning Tweets with Multi-Head Self Attention</a></strong><br><a href=/people/s/suyu-ge/>Suyu Ge</a>
|
<a href=/people/t/tao-qi/>Tao Qi</a>
|
<a href=/people/c/chuhan-wu/>Chuhan Wu</a>
|
<a href=/people/y/yongfeng-huang/>Yongfeng Huang</a><br><a href=/volumes/W19-32/ class=text-muted>Proceedings of the Fourth Social Media Mining for Health Applications (#SMM4H) Workshop & Shared Task</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3214><div class="card-body p-3 small">This paper describes our <a href=https://en.wikipedia.org/wiki/System>system</a> for the first and second shared tasks of the fourth Social Media Mining for Health Applications (SMM4H) workshop. We enhance tweet representation with a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> and distinguish the importance of different words with Multi-Head Self-Attention. In addition, <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> is exploited to make up for the data shortage. Our system achieved competitive results on both <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> with an F1-score of 0.5718 for task 1 and 0.653 (overlap) / 0.357 (strict) for task 2.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Tao+Qi" title="Search for 'Tao Qi' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/c/chuhan-wu/ class=align-middle>Chuhan Wu</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/y/yongfeng-huang/ class=align-middle>Yongfeng Huang</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/f/fangzhao-wu/ class=align-middle>Fangzhao Wu</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/x/xing-xie/ class=align-middle>Xing Xie</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/peiru-yang/ class=align-middle>Peiru Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/y/yang-yu/ class=align-middle>Yang Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yubo-chen/ class=align-middle>Yubo Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhigang-yuan/ class=align-middle>Zhigang Yuan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mingxiao-an/ class=align-middle>Mingxiao An</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jianqiang-huang/ class=align-middle>Jianqiang Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/suyu-ge/ class=align-middle>Suyu Ge</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ccl/ class=align-middle>CCL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/aacl/ class=align-middle>AACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>