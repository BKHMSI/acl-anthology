<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Torsten Zesch - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Torsten</span> <span class=font-weight-bold>Zesch</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.teachingnlp-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--teachingnlp-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.teachingnlp-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.teachingnlp-1.6/>A Crash Course on Ethics for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a></a></strong><br><a href=/people/a/annemarie-friedrich/>Annemarie Friedrich</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a><br><a href=/volumes/2021.teachingnlp-1/ class=text-muted>Proceedings of the Fifth Workshop on Teaching NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--teachingnlp-1--6><div class="card-body p-3 small">It is generally agreed upon in the natural language processing (NLP) community that <a href=https://en.wikipedia.org/wiki/Ethics>ethics</a> should be integrated into any <a href=https://en.wikipedia.org/wiki/Curriculum>curriculum</a>. Being aware of and understanding the relevant core concepts is a prerequisite for following and participating in the discourse on ethical NLP. We here present ready-made teaching material in the form of slides and practical exercises on ethical issues in <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP</a>, which is primarily intended to be integrated into introductory NLP or computational linguistics courses. By making this material freely available, we aim at lowering the threshold to adding <a href=https://en.wikipedia.org/wiki/Ethics>ethics</a> to the <a href=https://en.wikipedia.org/wiki/Curriculum>curriculum</a>. We hope that increased awareness will enable students to identify potentially <a href=https://en.wikipedia.org/wiki/Ethics>unethical behavior</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.bea-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.bea-1.0/>Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications</a></strong><br><a href=/people/j/jill-burstein/>Jill Burstein</a>
|
<a href=/people/a/andrea-horbach/>Andrea Horbach</a>
|
<a href=/people/e/ekaterina-kochmar/>Ekaterina Kochmar</a>
|
<a href=/people/r/ronja-laarmann-quante/>Ronja Laarmann-Quante</a>
|
<a href=/people/c/claudia-leacock/>Claudia Leacock</a>
|
<a href=/people/n/nitin-madnani/>Nitin Madnani</a>
|
<a href=/people/i/ildiko-pilan/>Ildikó Pilán</a>
|
<a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a><br><a href=/volumes/2021.bea-1/ class=text-muted>Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.bea-1.19.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--bea-1--19 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.bea-1.19 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.bea-1.19/>C-Test Collector : A Proficiency Testing Application to Collect Training Data for C-Tests<span class=acl-fixed-case>C</span>-Test Collector: A Proficiency Testing Application to Collect Training Data for <span class=acl-fixed-case>C</span>-Tests</a></strong><br><a href=/people/c/christian-haring/>Christian Haring</a>
|
<a href=/people/r/rene-lehmann/>Rene Lehmann</a>
|
<a href=/people/a/andrea-horbach/>Andrea Horbach</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a><br><a href=/volumes/2021.bea-1/ class=text-muted>Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--bea-1--19><div class="card-body p-3 small">We present the C-Test Collector, a <a href=https://en.wikipedia.org/wiki/Web_application>web-based tool</a> that allows <a href=https://en.wikipedia.org/wiki/Language_acquisition>language learners</a> to test their proficiency level using c-tests. Our tool collects anonymized data on test performance, which allows teachers to gain insights into common error patterns. At the same time, it allows NLP researchers to collect training data for being able to generate c-test variants at the desired difficulty level.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.aacl-main.37.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--aacl-main--37 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.aacl-main.37 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.aacl-main.37.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.aacl-main.37.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.aacl-main.37/>Chinese Content Scoring : Open-Access Datasets and Features on Different Segmentation Levels<span class=acl-fixed-case>C</span>hinese Content Scoring: Open-Access Datasets and Features on Different Segmentation Levels</a></strong><br><a href=/people/y/yuning-ding/>Yuning Ding</a>
|
<a href=/people/a/andrea-horbach/>Andrea Horbach</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a><br><a href=/volumes/2020.aacl-main/ class=text-muted>Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--aacl-main--37><div class="card-body p-3 small">In this paper, we analyse the challenges of Chinese content scoring in comparison to <a href=https://en.wikipedia.org/wiki/English_language>English</a>. As a review of prior work for <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese content scoring</a> shows a lack of <a href=https://en.wikipedia.org/wiki/Open_access>open-access data</a> in the field, we present two short-answer data sets for <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>. The Chinese Educational Short Answers data set (CESA) contains 1800 student answers for five science-related questions. As a second <a href=https://en.wikipedia.org/wiki/Data_set>data set</a>, we collected ASAP-ZH with 942 answers by re-using three existing prompts from the ASAP data set. We adapt a state-of-the-art content scoring system for <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a> and evaluate it in several settings on these <a href=https://en.wikipedia.org/wiki/Data_set>data sets</a>. Results show that <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> on lower segmentation levels such as character n-grams tend to have better performance than <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> on token level.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.709.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--709 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.709 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.709/>Decomposing and Comparing Meaning Relations : <a href=https://en.wikipedia.org/wiki/Paraphrase>Paraphrasing</a>, Textual Entailment, <a href=https://en.wikipedia.org/wiki/Contradiction>Contradiction</a>, and Specificity</a></strong><br><a href=/people/v/venelin-kovatchev/>Venelin Kovatchev</a>
|
<a href=/people/d/darina-gold/>Darina Gold</a>
|
<a href=/people/m/m-antonia-marti/>M. Antonia Marti</a>
|
<a href=/people/m/maria-salamo/>Maria Salamo</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--709><div class="card-body p-3 small">In this paper, we present a methodology for decomposing and comparing multiple meaning relations (paraphrasing, textual entailment, <a href=https://en.wikipedia.org/wiki/Contradiction>contradiction</a>, and specificity). The <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> includes SHARel-a new <a href=https://en.wikipedia.org/wiki/Linguistic_typology>typology</a> that consists of 26 linguistic and 8 reason-based categories. We use the <a href=https://en.wikipedia.org/wiki/Typology_(linguistics)>typology</a> to annotate a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of 520 sentence pairs in English and we demonstrate that unlike previous typologies, SHARel can be applied to all relations of interest with a high inter-annotator agreement. We analyze and compare the frequency and distribution of the linguistic and reason-based phenomena involved in <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrasing</a>, <a href=https://en.wikipedia.org/wiki/Logical_consequence>textual entailment</a>, <a href=https://en.wikipedia.org/wiki/Contradiction>contradiction</a>, and <a href=https://en.wikipedia.org/wiki/Sensitivity_and_specificity>specificity</a>. This comparison allows for a much more in-depth analysis of the workings of the individual relations and the way they interact and compare with each other. We release all resources (typology, annotation guidelines, and annotated corpus) to the community.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bea-1.0/>Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></strong><br><a href=/people/j/jill-burstein/>Jill Burstein</a>
|
<a href=/people/e/ekaterina-kochmar/>Ekaterina Kochmar</a>
|
<a href=/people/c/claudia-leacock/>Claudia Leacock</a>
|
<a href=/people/n/nitin-madnani/>Nitin Madnani</a>
|
<a href=/people/i/ildiko-pilan/>Ildikó Pilán</a>
|
<a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a><br><a href=/volumes/2020.bea-1/ class=text-muted>Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-2121.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S19-2121 data-toggle=collapse aria-expanded=false aria-controls=abstract-S19-2121 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-2121/>LTL-UDE at SemEval-2019 Task 6 : BERT and Two-Vote Classification for Categorizing Offensiveness<span class=acl-fixed-case>LTL</span>-<span class=acl-fixed-case>UDE</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2019 Task 6: <span class=acl-fixed-case>BERT</span> and Two-Vote Classification for Categorizing Offensiveness</a></strong><br><a href=/people/p/piush-aggarwal/>Piush Aggarwal</a>
|
<a href=/people/t/tobias-horsmann/>Tobias Horsmann</a>
|
<a href=/people/m/michael-wojatzki/>Michael Wojatzki</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a><br><a href=/volumes/S19-2/ class=text-muted>Proceedings of the 13th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S19-2121><div class="card-body p-3 small">We present results for Subtask A and C of SemEval 2019 Shared Task 6. In Subtask A, we experiment with an embedding representation of postings and use BERT to categorize postings. Our best result reaches the 10th place (out of 103). In Subtask C, we applied a two-vote classification approach with minority fallback, which is placed on the 19th rank (out of 65).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-0800.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-0800/><span class=acl-fixed-case>RELATIONS</span> - Workshop on meaning relations between phrases and sentences</a></strong><br><a href=/people/v/venelin-kovatchev/>Venelin Kovatchev</a>
|
<a href=/people/d/darina-gold/>Darina Gold</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a><br><a href=/volumes/W19-08/ class=text-muted>RELATIONS - Workshop on meaning relations between phrases and sentences</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4004 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-4004" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-4004/>Annotating and analyzing the interactions between meaning relations</a></strong><br><a href=/people/d/darina-gold/>Darina Gold</a>
|
<a href=/people/v/venelin-kovatchev/>Venelin Kovatchev</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a><br><a href=/volumes/W19-40/ class=text-muted>Proceedings of the 13th Linguistic Annotation Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4004><div class="card-body p-3 small">Pairs of sentences, phrases, or other text pieces can hold semantic relations such as <a href=https://en.wikipedia.org/wiki/Paraphrasing>paraphrasing</a>, textual entailment, <a href=https://en.wikipedia.org/wiki/Contradiction>contradiction</a>, specificity, and <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic similarity</a>. These <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a> are usually studied in isolation and no dataset exists where they can be compared empirically. Here we present a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> annotated with these <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a> and the analysis of these results. The <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> contains 520 sentence pairs, annotated with these <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a>. We measure the annotation reliability of each individual relation and we examine their interactions and correlations. Among the unexpected results revealed by our analysis is that the traditionally considered direct relationship between <a href=https://en.wikipedia.org/wiki/Paraphrasing>paraphrasing</a> and bi-directional entailment does not hold in our <a href=https://en.wikipedia.org/wiki/Data>data</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4400.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4400/>Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></strong><br><a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a>
|
<a href=/people/e/ekaterina-kochmar/>Ekaterina Kochmar</a>
|
<a href=/people/c/claudia-leacock/>Claudia Leacock</a>
|
<a href=/people/n/nitin-madnani/>Nitin Madnani</a>
|
<a href=/people/i/ildiko-pilan/>Ildikó Pilán</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a><br><a href=/volumes/W19-44/ class=text-muted>Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1047.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1047 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1047 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1047/>Divide and Extract Disentangling Clause Splitting and Proposition Extraction</a></strong><br><a href=/people/d/darina-gold/>Darina Gold</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a><br><a href=/volumes/R19-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1047><div class="card-body p-3 small">Proposition extraction from sentences is an important task for information extraction systems Evaluation of such <a href=https://en.wikipedia.org/wiki/System>systems</a> usually conflates two aspects : splitting complex sentences into clauses and the extraction of propositions. It is thus difficult to independently determine the quality of the proposition extraction step. We create a manually annotated proposition dataset from sentences taken from restaurant reviews that distinguishes between clauses that need to be split and those that do not. The resulting proposition evaluation dataset allows us to independently compare the performance of proposition extraction systems on simple and complex clauses. Although performance drastically drops on more complex sentences, we show that the same <a href=https://en.wikipedia.org/wiki/System>systems</a> perform best on both simple and complex clauses. Furthermore, we show that specific kinds of <a href=https://en.wikipedia.org/wiki/Dependent_clause>subordinate clauses</a> pose difficulties to most systems.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-2026.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-2026 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-2026 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=S18-2026" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/S18-2026/>Agree or Disagree : Predicting Judgments on Nuanced Assertions</a></strong><br><a href=/people/m/michael-wojatzki/>Michael Wojatzki</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a>
|
<a href=/people/s/saif-mohammad/>Saif Mohammad</a>
|
<a href=/people/s/svetlana-kiritchenko/>Svetlana Kiritchenko</a><br><a href=/volumes/S18-2/ class=text-muted>Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-2026><div class="card-body p-3 small">Being able to predict whether people agree or disagree with an assertion (i.e. an explicit, self-contained statement) has several applications ranging from predicting how many people will like or dislike a social media post to classifying posts based on whether they are in accordance with a particular point of view. We formalize this as two NLP tasks : predicting judgments of (i) individuals and (ii) groups based on the text of the assertion and previous judgments. We evaluate a wide range of approaches on a crowdsourced data set containing over 100,000 judgments on over 2,000 assertions. We find that predicting individual judgments is a hard task with our best results only slightly exceeding a majority baseline, but that judgments of groups can be more reliably predicted using a Siamese neural network, which outperforms all other approaches by a wide margin.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-0550.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-0550 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-0550 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-0550/>Cross-Lingual Content Scoring</a></strong><br><a href=/people/a/andrea-horbach/>Andrea Horbach</a>
|
<a href=/people/s/sebastian-stennmanns/>Sebastian Stennmanns</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a><br><a href=/volumes/W18-05/ class=text-muted>Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-0550><div class="card-body p-3 small">We investigate the feasibility of cross-lingual content scoring, a scenario where training and test data in an automatic scoring task are from two different languages. Cross-lingual scoring can contribute to <a href=https://en.wikipedia.org/wiki/Educational_equality>educational equality</a> by allowing answers in multiple languages. Training a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> in one language and applying it to another language might also help to overcome data sparsity issues by re-using trained <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> from other languages. As there is no suitable dataset available for this new task, we create a comparable bi-lingual corpus by extending the English ASAP dataset with German answers. Our experiments with cross-lingual scoring based on <a href=https://en.wikipedia.org/wiki/Machine_translation>machine-translating</a> either training or test data show a considerable drop in scoring quality.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5017.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5017 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5017 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5017/>Investigating neural architectures for short answer scoring</a></strong><br><a href=/people/b/brian-riordan/>Brian Riordan</a>
|
<a href=/people/a/andrea-horbach/>Andrea Horbach</a>
|
<a href=/people/a/aoife-cahill/>Aoife Cahill</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a>
|
<a href=/people/c/chungmin-lee/>Chong Min Lee</a><br><a href=/volumes/W17-50/ class=text-muted>Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5017><div class="card-body p-3 small">Neural approaches to <a href=https://en.wikipedia.org/wiki/Automated_essay_scoring>automated essay scoring</a> have recently shown state-of-the-art performance. The automated essay scoring task typically involves a broad notion of writing quality that encompasses <a href=https://en.wikipedia.org/wiki/Content_(media)>content</a>, <a href=https://en.wikipedia.org/wiki/Grammar>grammar</a>, <a href=https://en.wikipedia.org/wiki/Organization>organization</a>, and <a href=https://en.wikipedia.org/wiki/Convention_(norm)>conventions</a>. This differs from the short answer content scoring task, which focuses on content accuracy. The inputs to neural essay scoring models ngrams and embeddings are arguably well-suited to evaluate content in short answer scoring tasks. We investigate how several basic neural approaches similar to those used for automated essay scoring perform on short answer scoring. We show that neural architectures can outperform a strong non-neural baseline, but performance and optimal parameter settings vary across the more diverse types of prompts typical of short answer scoring.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5040.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5040 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5040 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5040/>Fine-grained essay scoring of a complex writing task for native speakers</a></strong><br><a href=/people/a/andrea-horbach/>Andrea Horbach</a>
|
<a href=/people/d/dirk-scholten-akoun/>Dirk Scholten-Akoun</a>
|
<a href=/people/y/yuning-ding/>Yuning Ding</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a><br><a href=/volumes/W17-50/ class=text-muted>Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5040><div class="card-body p-3 small">Automatic essay scoring is nowadays successfully used even in high-stakes tests, but this is mainly limited to holistic scoring of learner essays. We present a new dataset of <a href=https://en.wikipedia.org/wiki/Essay>essays</a> written by highly proficient German native speakers that is scored using a fine-grained rubric with the goal to provide detailed feedback. Our experiments with two state-of-the-art scoring systems (a neural and a SVM-based one) show a large drop in performance compared to existing datasets. This demonstrates the need for such <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> that allow to guide research on more elaborate essay scoring methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5908.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5908 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5908 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5908/>The Influence of Spelling Errors on Content Scoring Performance</a></strong><br><a href=/people/a/andrea-horbach/>Andrea Horbach</a>
|
<a href=/people/y/yuning-ding/>Yuning Ding</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a><br><a href=/volumes/W17-59/ class=text-muted>Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5908><div class="card-body p-3 small">Spelling errors occur frequently in educational settings, but their influence on <a href=https://en.wikipedia.org/wiki/Score_(game)>automatic scoring</a> is largely unknown. We therefore investigate the influence of spelling errors on content scoring performance using the example of the ASAP corpus. We conduct an annotation study on the nature of spelling errors in the ASAP dataset and utilize these finding in machine learning experiments that measure the influence of spelling errors on automatic content scoring. Our main finding is that scoring methods using both token and character n-gram features are robust against spelling errors up to the error frequency in ASAP.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1076.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1076 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1076 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1076/>Do LSTMs really work so well for PoS tagging? A replication study<span class=acl-fixed-case>LSTM</span>s really work so well for <span class=acl-fixed-case>P</span>o<span class=acl-fixed-case>S</span> tagging? – A replication study</a></strong><br><a href=/people/t/tobias-horsmann/>Tobias Horsmann</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1076><div class="card-body p-3 small">A recent study by Plank et al. (2016) found that LSTM-based PoS taggers considerably improve over the current state-of-the-art when evaluated on the corpora of the Universal Dependencies project that use a coarse-grained tagset. We replicate this study using a fresh collection of 27 corpora of 21 languages that are annotated with fine-grained tagsets of varying size. Our replication confirms the result in general, and we additionally find that the advantage of <a href=https://en.wikipedia.org/wiki/Linear_time-invariant_system>LSTMs</a> is even bigger for larger tagsets. However, we also find that for the very large tagsets of morphologically rich languages, hand-crafted morphological lexicons are still necessary to reach state-of-the-art performance.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Torsten+Zesch" title="Search for 'Torsten Zesch' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/a/andrea-horbach/ class=align-middle>Andrea Horbach</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/d/darina-gold/ class=align-middle>Darina Gold</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/y/yuning-ding/ class=align-middle>Yuning Ding</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/v/venelin-kovatchev/ class=align-middle>Venelin Kovatchev</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/h/helen-yannakoudakis/ class=align-middle>Helen Yannakoudakis</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/e/ekaterina-kochmar/ class=align-middle>Ekaterina Kochmar</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/c/claudia-leacock/ class=align-middle>Claudia Leacock</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/n/nitin-madnani/ class=align-middle>Nitin Madnani</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/i/ildiko-pilan/ class=align-middle>Ildikó Pilán</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/t/tobias-horsmann/ class=align-middle>Tobias Horsmann</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/michael-wojatzki/ class=align-middle>Michael Wojatzki</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jill-burstein/ class=align-middle>Jill Burstein</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/annemarie-friedrich/ class=align-middle>Annemarie Friedrich</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/brian-riordan/ class=align-middle>Brian Riordan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aoife-cahill/ class=align-middle>Aoife Cahill</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chungmin-lee/ class=align-middle>Chungmin Lee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dirk-scholten-akoun/ class=align-middle>Dirk Scholten-Akoun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/piush-aggarwal/ class=align-middle>Piush Aggarwal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/saif-mohammad/ class=align-middle>Saif Mohammad</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/svetlana-kiritchenko/ class=align-middle>Svetlana Kiritchenko</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sebastian-stennmanns/ class=align-middle>Sebastian Stennmanns</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/m-antonia-marti/ class=align-middle>M. Antònia Martí</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maria-salamo/ class=align-middle>Maria Salamó</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ronja-laarmann-quante/ class=align-middle>Ronja Laarmann-Quante</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christian-haring/ class=align-middle>Christian Haring</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rene-lehmann/ class=align-middle>Rene Lehmann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/venues/bea/ class=align-middle>BEA</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/teachingnlp/ class=align-middle>TeachingNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/aacl/ class=align-middle>AACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ranlp/ class=align-middle>RANLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>