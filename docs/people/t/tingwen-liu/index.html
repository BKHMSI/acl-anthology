<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Tingwen Liu - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Tingwen</span> <span class=font-weight-bold>Liu</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.63.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--63 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.63 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.63" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.63/>Discontinuous Named Entity Recognition as Maximal Clique Discovery</a></strong><br><a href=/people/y/yucheng-wang/>Yucheng Wang</a>
|
<a href=/people/b/bowen-yu/>Bowen Yu</a>
|
<a href=/people/h/hongsong-zhu/>Hongsong Zhu</a>
|
<a href=/people/t/tingwen-liu/>Tingwen Liu</a>
|
<a href=/people/n/nan-yu/>Nan Yu</a>
|
<a href=/people/l/limin-sun/>Limin Sun</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--63><div class="card-body p-3 small">Named entity recognition (NER) remains challenging when entity mentions can be discontinuous. Existing methods break the recognition process into several <a href=https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations>sequential steps</a>. In training, they predict conditioned on the golden intermediate results, while at <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference</a> relying on the model output of the previous steps, which introduces <a href=https://en.wikipedia.org/wiki/Exposure_bias>exposure bias</a>. To solve this problem, we first construct a segment graph for each sentence, in which each <a href=https://en.wikipedia.org/wiki/Vertex_(graph_theory)>node</a> denotes a segment (a continuous entity on its own, or a part of discontinuous entities), and an <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>edge</a> links two nodes that belong to the same entity. The <a href=https://en.wikipedia.org/wiki/Vertex_(graph_theory)>nodes</a> and <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>edges</a> can be generated respectively in one stage with a grid tagging scheme and learned jointly using a novel <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> named Mac. Then discontinuous NER can be reformulated as a non-parametric process of discovering maximal cliques in the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a> and concatenating the spans in each clique. Experiments on three benchmarks show that our method outperforms the state-of-the-art (SOTA) results, with up to 3.5 percentage points improvement on F1, and achieves 5x speedup over the SOTA model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.839.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--839 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.839 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.839" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.839/>Improving Distantly-Supervised Named Entity Recognition with Self-Collaborative Denoising Learning</a></strong><br><a href=/people/x/xinghua-zhang/>Xinghua Zhang</a>
|
<a href=/people/b/bowen-yu/>Bowen Yu</a>
|
<a href=/people/t/tingwen-liu/>Tingwen Liu</a>
|
<a href=/people/z/zhenyu-zhang/>Zhenyu Zhang</a>
|
<a href=/people/j/jiawei-sheng/>Jiawei Sheng</a>
|
<a href=/people/x/xue-mengge/>Xue Mengge</a>
|
<a href=/people/h/hongbo-xu/>Hongbo Xu</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--839><div class="card-body p-3 small">Distantly supervised named entity recognition (DS-NER) efficiently reduces labor costs but meanwhile intrinsically suffers from the label noise due to the strong assumption of distant supervision. Typically, the wrongly labeled instances comprise numbers of incomplete and inaccurate annotations, while most prior denoising works are only concerned with one kind of <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a> and fail to fully explore useful information in the training set. To address this issue, we propose a robust learning paradigm named Self-Collaborative Denoising Learning (SCDL), which jointly trains two teacher-student networks in a mutually-beneficial manner to iteratively perform noisy label refinery. Each network is designed to exploit reliable labels via self denoising, and two networks communicate with each other to explore unreliable annotations by collaborative denoising. Extensive experimental results on five real-world datasets demonstrate that SCDL is superior to state-of-the-art DS-NER denoising methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-demos.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-demos--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-demos.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-demos.5/>FITAnnotator : A Flexible and Intelligent Text Annotation System<span class=acl-fixed-case>FITA</span>nnotator: A Flexible and Intelligent Text Annotation System</a></strong><br><a href=/people/y/yanzeng-li/>Yanzeng Li</a>
|
<a href=/people/b/bowen-yu/>Bowen Yu</a>
|
<a href=/people/l/li-quangang/>Li Quangang</a>
|
<a href=/people/t/tingwen-liu/>Tingwen Liu</a><br><a href=/volumes/2021.naacl-demos/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-demos--5><div class="card-body p-3 small">In this paper, we introduce FITAnnotator, a generic web-based tool for efficient text annotation. Benefiting from the fully modular architecture design, FITAnnotator provides a systematic solution for the annotation of a variety of natural language processing tasks, including <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a>, sequence tagging and semantic role annotation, regardless of the language. Three kinds of <a href=https://en.wikipedia.org/wiki/Interface_(computing)>interfaces</a> are developed to annotate instances, evaluate annotation quality and manage the annotation task for annotators, reviewers and managers, respectively. FITAnnotator also gives intelligent annotations by introducing task-specific assistant to support and guide the annotators based on <a href=https://en.wikipedia.org/wiki/Active_learning>active learning</a> and incremental learning strategies. This assistant is able to effectively update from the annotator feedbacks and easily handle the incremental labeling scenarios.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.514.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--514 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.514 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938977 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.514" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.514/>Coarse-to-Fine Pre-training for Named Entity Recognition<span class=acl-fixed-case>C</span>oarse-to-<span class=acl-fixed-case>F</span>ine <span class=acl-fixed-case>P</span>re-training for <span class=acl-fixed-case>N</span>amed <span class=acl-fixed-case>E</span>ntity <span class=acl-fixed-case>R</span>ecognition</a></strong><br><a href=/people/x/xue-mengge/>Xue Mengge</a>
|
<a href=/people/b/bowen-yu/>Bowen Yu</a>
|
<a href=/people/z/zhenyu-zhang/>Zhenyu Zhang</a>
|
<a href=/people/t/tingwen-liu/>Tingwen Liu</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a>
|
<a href=/people/b/bin-wang/>Bin Wang</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--514><div class="card-body p-3 small">More recently, <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a> hasachieved great advances aided by pre-trainingapproaches such as <a href=https://en.wikipedia.org/wiki/BERT>BERT</a>. However, currentpre-training techniques focus on building lan-guage modeling objectives to learn a gen-eral representation, ignoring the named entity-related knowledge. To this end, we proposea NER-specific pre-training framework to in-ject coarse-to-fine automatically mined entityknowledge into pre-trained models. Specifi-cally, we first warm-up the model via an en-tity span identification task by training it withWikipedia anchors, which can be deemed asgeneral-typed entities. Then we leverage thegazetteer-based distant supervision strategy totrain the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> extract coarse-grained typedentities. Finally, we devise a self-supervisedauxiliary task to mine the fine-grained namedentity knowledge via clustering. Empiricalstudies on three public NER datasets demon-strate that our framework achieves significantimprovements against several pre-trained base-lines, establishing the new state-of-the-art per-formance on three benchmarks. Besides, weshow that our <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> gains promising re-sults without using human-labeled trainingdata, demonstrating its effectiveness in label-few and low-resource scenarios.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.315.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--315 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.315 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928721 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.315" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.315/>Enhancing Pre-trained Chinese Character Representation with Word-aligned Attention<span class=acl-fixed-case>C</span>hinese Character Representation with Word-aligned Attention</a></strong><br><a href=/people/y/yanzeng-li/>Yanzeng Li</a>
|
<a href=/people/b/bowen-yu/>Bowen Yu</a>
|
<a href=/people/x/xue-mengge/>Xue Mengge</a>
|
<a href=/people/t/tingwen-liu/>Tingwen Liu</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--315><div class="card-body p-3 small">Most <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese pre-trained models</a> take <a href=https://en.wikipedia.org/wiki/Character_(symbol)>character</a> as the basic unit and learn representation according to <a href=https://en.wikipedia.org/wiki/Character_(symbol)>character&#8217;s external contexts</a>, ignoring the semantics expressed in the word, which is the smallest meaningful utterance in <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>. Hence, we propose a novel word-aligned attention to exploit explicit word information, which is complementary to various character-based Chinese pre-trained language models. Specifically, we devise a pooling mechanism to align the character-level attention to the word level and propose to alleviate the potential issue of segmentation error propagation by multi-source information fusion. As a result, word and character information are explicitly integrated at the <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning procedure</a>. Experimental results on five Chinese NLP benchmark tasks demonstrate that our method achieves significant improvements against BERT, <a href=https://en.wikipedia.org/wiki/ERNIE>ERNIE</a> and BERT-wwm.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.138.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--138 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.138 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.coling-main.138" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.138/>TPLinker : Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking<span class=acl-fixed-case>TPL</span>inker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking</a></strong><br><a href=/people/y/yucheng-wang/>Yucheng Wang</a>
|
<a href=/people/b/bowen-yu/>Bowen Yu</a>
|
<a href=/people/y/yueyang-zhang/>Yueyang Zhang</a>
|
<a href=/people/t/tingwen-liu/>Tingwen Liu</a>
|
<a href=/people/h/hongsong-zhu/>Hongsong Zhu</a>
|
<a href=/people/l/limin-sun/>Limin Sun</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--138><div class="card-body p-3 small">Extracting entities and relations from <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured text</a> has attracted increasing attention in recent years but remains challenging, due to the intrinsic difficulty in identifying overlapping relations with shared entities. Prior works show that joint learning can result in a noticeable performance gain. However, they usually involve sequential interrelated steps and suffer from the problem of <a href=https://en.wikipedia.org/wiki/Exposure_bias>exposure bias</a>. At training time, they predict with the ground truth conditions while at inference it has to make extraction from scratch. This discrepancy leads to error accumulation. To mitigate the issue, we propose in this paper a one-stage joint extraction model, namely, TPLinker, which is capable of discovering overlapping relations sharing one or both entities while being immune from the <a href=https://en.wikipedia.org/wiki/Exposure_bias>exposure bias</a>. TPLinker formulates joint extraction as a token pair linking problem and introduces a novel handshaking tagging scheme that aligns the boundary tokens of entity pairs under each relation type. Experiment results show that TPLinker performs significantly better on overlapping and multiple relation extraction, and achieves state-of-the-art performance on two public datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.341.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--341 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.341 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.341/>Learning to Prune Dependency Trees with Rethinking for Neural Relation Extraction</a></strong><br><a href=/people/b/bowen-yu/>Bowen Yu</a>
|
<a href=/people/x/xue-mengge/>Xue Mengge</a>
|
<a href=/people/z/zhenyu-zhang/>Zhenyu Zhang</a>
|
<a href=/people/t/tingwen-liu/>Tingwen Liu</a>
|
<a href=/people/w/wang-yubin/>Wang Yubin</a>
|
<a href=/people/b/bin-wang/>Bin Wang</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--341><div class="card-body p-3 small">Dependency trees have been shown to be effective in capturing long-range relations between target entities. Nevertheless, how to selectively emphasize target-relevant information and remove irrelevant content from the <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>tree</a> is still an open problem. Existing approaches employing pre-defined rules to eliminate <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a> may not always yield optimal results due to the <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a> and variability of natural language. In this paper, we present a novel architecture named Dynamically Pruned Graph Convolutional Network (DP-GCN), which learns to prune the dependency tree with rethinking in an end-to-end scheme. In each layer of DP-GCN, we employ a selection module to concentrate on nodes expressing the target relation by a set of binary gates, and then augment the pruned tree with a pruned semantic graph to ensure the connectivity. After that, we introduce a rethinking mechanism to guide and refine the pruning operation by feeding back the high-level learned features repeatedly. Extensive experimental results demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves impressive results compared to strong <a href=https://en.wikipedia.org/wiki/Competition>competitors</a>.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Tingwen+Liu" title="Search for 'Tingwen Liu' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/b/bowen-yu/ class=align-middle>Bowen Yu</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/x/xue-mengge/ class=align-middle>Xue Mengge</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/z/zhenyu-zhang/ class=align-middle>Zhenyu Zhang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/y/yucheng-wang/ class=align-middle>Yucheng Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hongsong-zhu/ class=align-middle>Hongsong Zhu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/l/limin-sun/ class=align-middle>Limin Sun</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/bin-wang/ class=align-middle>Bin Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yanzeng-li/ class=align-middle>Yanzeng Li</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/n/nan-yu/ class=align-middle>Nan Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yue-zhang/ class=align-middle>Yue Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xinghua-zhang/ class=align-middle>Xinghua Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiawei-sheng/ class=align-middle>Jiawei Sheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hongbo-xu/ class=align-middle>Hongbo Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/li-quangang/ class=align-middle>Li Quangang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yueyang-zhang/ class=align-middle>Yueyang Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wang-yubin/ class=align-middle>Wang Yubin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>