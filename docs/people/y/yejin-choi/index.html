<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Yejin Choi - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Yejin</span> <span class=font-weight-bold>Choi</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.222.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--222 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.222 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.acl-long.222" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.222/>Misinfo Reaction Frames: Reasoning about Readers’ Reactions to News Headlines</a></strong><br><a href=/people/s/saadia-gabriel/>Saadia Gabriel</a>
|
<a href=/people/s/skyler-hallinan/>Skyler Hallinan</a>
|
<a href=/people/m/maarten-sap/>Maarten Sap</a>
|
<a href=/people/p/pemi-nguyen/>Pemi Nguyen</a>
|
<a href=/people/f/franziska-roesner/>Franziska Roesner</a>
|
<a href=/people/e/eunsol-choi/>Eunsol Choi</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--222><div class="card-body p-3 small">Even to a simple and short news headline, readers react in a multitude of ways: cognitively (e.g. inferring the writer&#8217;s intent), emotionally (e.g. feeling distrust), and behaviorally (e.g. sharing the news with their friends). Such reactions are instantaneous and yet complex, as they rely on factors that go beyond interpreting factual content of news.We propose Misinfo Reaction Frames (MRF), a pragmatic formalism for modeling how readers might react to a news headline. In contrast to categorical schema, our free-text dimensions provide a more nuanced way of understanding intent beyond being benign or malicious. We also introduce a Misinfo Reaction Frames corpus, a crowdsourced dataset of reactions to over 25k news headlines focusing on global crises: the Covid-19 pandemic, climate change, and cancer. Empirical results confirm that it is indeed possible for neural models to predict the prominent patterns of readers&#8217; reactions to previously unseen news headlines. Additionally, our user study shows that displaying machine-generated MRF implications alongside news headlines to readers can increase their trust in real news while decreasing their trust in misinformation. Our work demonstrates the feasibility and importance of pragmatic inferences on news headlines to help enhance AI-guided misinformation detection and mitigation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.225.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--225 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.225 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.acl-long.225" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.225/>Generated Knowledge Prompting for Commonsense Reasoning</a></strong><br><a href=/people/j/jiacheng-liu/>Jiacheng Liu</a>
|
<a href=/people/a/alisa-liu/>Alisa Liu</a>
|
<a href=/people/x/ximing-lu/>Ximing Lu</a>
|
<a href=/people/s/sean-welleck/>Sean Welleck</a>
|
<a href=/people/p/peter-west/>Peter West</a>
|
<a href=/people/r/ronan-le-bras/>Ronan Le Bras</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/h/hannaneh-hajishirzi/>Hannaneh Hajishirzi</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--225><div class="card-body p-3 small">It remains an open question whether incorporating external knowledge benefits <a href=https://en.wikipedia.org/wiki/Commonsense_reasoning>commonsense reasoning</a> while maintaining the flexibility of pretrained sequence models To investigate this question we develop generated knowledge prompting which consists of generating knowledge from a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> then providing the knowledge as additional input when answering a question Our method does not require task specific supervision for knowledge integration or access to a structured knowledge base yet it improves performance of large scale state of the art models on four commonsense reasoning tasks achieving state of the art results on numerical commonsense NumerSense general commonsense CommonsenseQA 2.0 and scientific commonsense QASC benchmarks Generated knowledge prompting highlights large scale language models as flexible sources of external knowledge for improving <a href=https://en.wikipedia.org/wiki/Commonsense_reasoning>commonsense reasoning</a> Our code is available at \\url<url>github.com/liujch1998/GKP</url>\n</div></div><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.158.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--158 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.158 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.158/>Edited Media Understanding Frames : Reasoning About the Intent and Implications of Visual Misinformation</a></strong><br><a href=/people/j/jeff-da/>Jeff Da</a>
|
<a href=/people/m/maxwell-forbes/>Maxwell Forbes</a>
|
<a href=/people/r/rowan-zellers/>Rowan Zellers</a>
|
<a href=/people/a/anthony-zheng/>Anthony Zheng</a>
|
<a href=/people/j/jena-d-hwang/>Jena D. Hwang</a>
|
<a href=/people/a/antoine-bosselut/>Antoine Bosselut</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--158><div class="card-body p-3 small">Understanding manipulated media, from automatically generated &#8216;deepfakes&#8217; to manually edited ones, raises novel research challenges. Because the vast majority of edited or manipulated images are benign, such as <a href=https://en.wikipedia.org/wiki/Photo_manipulation>photoshopped images</a> for visual enhancements, the key challenge is to understand the complex layers of underlying intents of media edits and their implications with respect to <a href=https://en.wikipedia.org/wiki/Disinformation>disinformation</a>. In this paper, we study Edited Media Frames, a new formalism to understand visual media manipulation as structured annotations with respect to the intents, emotional reactions, attacks on individuals, and the overall implications of <a href=https://en.wikipedia.org/wiki/Disinformation>disinformation</a>. We introduce a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for our task, EMU, with 56k question-answer pairs written in rich natural language. We evaluate a wide variety of vision-and-language models for our task, and introduce a new model PELICAN, which builds upon recent progress in pretrained multimodal representations. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> obtains promising results on our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, with humans rating its answers as accurate 48.2 % of the time. At the same time, there is still much work to be done and we provide analysis that highlights areas for further progress.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.522.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--522 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.522 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.522" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.522/>DExperts : Decoding-Time Controlled Text Generation with Experts and Anti-Experts<span class=acl-fixed-case>DE</span>xperts: Decoding-Time Controlled Text Generation with Experts and Anti-Experts</a></strong><br><a href=/people/a/alisa-liu/>Alisa Liu</a>
|
<a href=/people/m/maarten-sap/>Maarten Sap</a>
|
<a href=/people/x/ximing-lu/>Ximing Lu</a>
|
<a href=/people/s/swabha-swayamdipta/>Swabha Swayamdipta</a>
|
<a href=/people/c/chandra-bhagavatula/>Chandra Bhagavatula</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--522><div class="card-body p-3 small">Despite recent advances in <a href=https://en.wikipedia.org/wiki/Natural-language_generation>natural language generation</a>, it remains challenging to control attributes of generated text. We propose DExperts : Decoding-time Experts, a decoding-time method for controlled text generation that combines a pretrained language model with expert LMs and/or anti-expert LMs in a product of experts. Intuitively, under the <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble</a>, tokens only get high probability if they are considered likely by the <a href=https://en.wikipedia.org/wiki/Expert>experts</a>, and unlikely by the <a href=https://en.wikipedia.org/wiki/Expert>anti-experts</a>. We apply DExperts to language detoxification and sentiment-controlled generation, where we outperform existing controllable generation methods on both automatic and human evaluations. Moreover, because DExperts operates only on the output of the pretrained LM, it is effective with (anti-)experts of smaller size, including when operating on GPT-3. Our work highlights the promise of tuning small LMs on text with (un)desirable attributes for efficient decoding-time steering.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-main.274.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-main--274 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-main.274 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.eacl-main.274" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-main.274/>Challenges in <a href=https://en.wikipedia.org/wiki/Debiasing>Automated Debiasing</a> for Toxic Language Detection</a></strong><br><a href=/people/x/xuhui-zhou/>Xuhui Zhou</a>
|
<a href=/people/m/maarten-sap/>Maarten Sap</a>
|
<a href=/people/s/swabha-swayamdipta/>Swabha Swayamdipta</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/n/noah-a-smith/>Noah Smith</a><br><a href=/volumes/2021.eacl-main/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-main--274><div class="card-body p-3 small">Biased associations have been a challenge in the development of <a href=https://en.wikipedia.org/wiki/Classifier_(linguistics)>classifiers</a> for detecting toxic language, hindering both fairness and <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. As potential solutions, we investigate recently introduced <a href=https://en.wikipedia.org/wiki/Debiasing>debiasing methods</a> for text classification datasets and <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a>, as applied to toxic language detection. Our focus is on lexical (e.g., <a href=https://en.wikipedia.org/wiki/Profanity>swear words</a>, <a href=https://en.wikipedia.org/wiki/List_of_ethnic_slurs>slurs</a>, identity mentions) and dialectal markers (specifically <a href=https://en.wikipedia.org/wiki/African-American_Vernacular_English>African American English</a>). Our comprehensive experiments establish that existing <a href=https://en.wikipedia.org/wiki/Scientific_method>methods</a> are limited in their ability to prevent <a href=https://en.wikipedia.org/wiki/Bias>biased behavior</a> in current <a href=https://en.wikipedia.org/wiki/Particle_detector>toxicity detectors</a>. We then propose an automatic, dialect-aware data correction method, as a proof-of-concept. Despite the use of synthetic labels, this method reduces dialectal associations with <a href=https://en.wikipedia.org/wiki/Toxicity>toxicity</a>. Overall, our findings show that debiasing a model trained on biased toxic language data is not as effective as simply relabeling the data to remove existing biases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.54.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--54 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.54 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.emnlp-main.54.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.54" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.54/>Moral Stories : Situated Reasoning about Norms, Intents, Actions, and their Consequences</a></strong><br><a href=/people/d/denis-emelin/>Denis Emelin</a>
|
<a href=/people/r/ronan-le-bras/>Ronan Le Bras</a>
|
<a href=/people/j/jena-d-hwang/>Jena D. Hwang</a>
|
<a href=/people/m/maxwell-forbes/>Maxwell Forbes</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--54><div class="card-body p-3 small">In <a href=https://en.wikipedia.org/wiki/Social_environment>social settings</a>, much of human behavior is governed by <a href=https://en.wikipedia.org/wiki/Social_norm>unspoken rules of conduct</a> rooted in <a href=https://en.wikipedia.org/wiki/Social_norm>societal norms</a>. For artificial systems to be fully integrated into <a href=https://en.wikipedia.org/wiki/Social_environment>social environments</a>, adherence to such <a href=https://en.wikipedia.org/wiki/Social_norm>norms</a> is a central prerequisite. To investigate whether language generation models can serve as behavioral priors for systems deployed in social settings, we evaluate their ability to generate action descriptions that achieve predefined goals under normative constraints. Moreover, we examine if models can anticipate likely consequences of actions that either observe or violate known norms, or explain why certain actions are preferable by generating relevant norm hypotheses. For this purpose, we introduce Moral Stories, a crowd-sourced dataset of structured, branching narratives for the study of grounded, goal-oriented social reasoning. Finally, we propose decoding strategies that combine multiple expert models to significantly improve the quality of generated actions, consequences, and norms compared to strong baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.120.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--120 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.120 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.120" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.120/>Contrastive Explanations for Model Interpretability</a></strong><br><a href=/people/a/alon-jacovi/>Alon Jacovi</a>
|
<a href=/people/s/swabha-swayamdipta/>Swabha Swayamdipta</a>
|
<a href=/people/s/shauli-ravfogel/>Shauli Ravfogel</a>
|
<a href=/people/y/yanai-elazar/>Yanai Elazar</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/y/yoav-goldberg/>Yoav Goldberg</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--120><div class="card-body p-3 small">Contrastive explanations clarify why an event occurred in contrast to another. They are inherently intuitive to humans to both produce and comprehend. We propose a method to produce contrastive explanations in the latent space, via a projection of the input representation, such that only the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> that differentiate two potential decisions are captured. Our modification allows model behavior to consider only contrastive reasoning, and uncover which aspects of the input are useful for and against particular decisions. Our contrastive explanations can additionally answer for which label, and against which alternative label, is a given input feature useful. We produce contrastive explanations via both high-level abstract concept attribution and low-level input token / span attribution for two NLP classification benchmarks. Our findings demonstrate the ability of label-contrastive explanations to provide fine-grained interpretability of model decisions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.346.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--346 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.346 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.346/>I’m Not Mad : Commonsense Implications of Negation and Contradiction<span class=acl-fixed-case>I</span>’m Not Mad”: Commonsense Implications of Negation and Contradiction</a></strong><br><a href=/people/l/liwei-jiang/>Liwei Jiang</a>
|
<a href=/people/a/antoine-bosselut/>Antoine Bosselut</a>
|
<a href=/people/c/chandra-bhagavatula/>Chandra Bhagavatula</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--346><div class="card-body p-3 small">Natural language inference requires reasoning about <a href=https://en.wikipedia.org/wiki/Contradiction>contradictions</a>, <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>negations</a>, and their commonsense implications. Given a simple premise (e.g., I&#8217;m mad at you), humans can reason about the varying shades of contradictory statements ranging from straightforward negations (I&#8217;m not mad at you) to commonsense contradictions (I&#8217;m happy). Moreover, these negated or contradictory statements shift the commonsense implications of the original premise in interesting and nontrivial ways. For example, while I&#8217;m mad implies I&#8217;m unhappy about something, negating the premise does not necessarily negate the corresponding commonsense implications. In this paper, we present the first comprehensive study focusing on commonsense implications of <a href=https://en.wikipedia.org/wiki/Negation>negated statements</a> and <a href=https://en.wikipedia.org/wiki/Contradiction>contradictions</a>. We introduce ANION, a new commonsense knowledge graph with 624 K if-then rules focusing on negated and contradictory events. We then present joint generative and discriminative inference models for this new resource, providing novel empirical insights on how logical negations and commonsense contradictions reshape the commonsense implications of their original premises.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.386.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--386 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.386 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.386/>TuringAdvice : A Generative and Dynamic Evaluation of Language Use<span class=acl-fixed-case>T</span>uring<span class=acl-fixed-case>A</span>dvice: A Generative and Dynamic Evaluation of Language Use</a></strong><br><a href=/people/r/rowan-zellers/>Rowan Zellers</a>
|
<a href=/people/a/ari-holtzman/>Ari Holtzman</a>
|
<a href=/people/e/elizabeth-clark/>Elizabeth Clark</a>
|
<a href=/people/l/lianhui-qin/>Lianhui Qin</a>
|
<a href=/people/a/ali-farhadi/>Ali Farhadi</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--386><div class="card-body p-3 small">We propose TuringAdvice, a new challenge task and dataset for language understanding models. Given a written situation that a real person is currently facing, a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> must generate helpful advice in natural language. Our evaluation framework tests a fundamental aspect of human language understanding : our ability to use <a href=https://en.wikipedia.org/wiki/Language>language</a> to resolve open-ended situations by communicating with each other. Empirical results show that today&#8217;s <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> struggle at TuringAdvice, even multibillion parameter models finetuned on 600k in-domain training examples. The best <a href=https://en.wikipedia.org/wiki/Scientific_modelling>model</a>, T5, writes advice that is at least as helpful as human-written advice in only 14 % of cases ; a much larger non-finetunable GPT3 model does even worse at 4 %. This low performance reveals language understanding errors that are hard to spot outside of a generative setting, showing much room for progress.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.602.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--602 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.602 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939042 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.602/>PowerTransformer : Unsupervised Controllable Revision for Biased Language Correction<span class=acl-fixed-case>P</span>ower<span class=acl-fixed-case>T</span>ransformer: Unsupervised Controllable Revision for Biased Language Correction</a></strong><br><a href=/people/x/xinyao-ma/>Xinyao Ma</a>
|
<a href=/people/m/maarten-sap/>Maarten Sap</a>
|
<a href=/people/h/hannah-rashkin/>Hannah Rashkin</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--602><div class="card-body p-3 small">Unconscious biases continue to be prevalent in modern text and media, calling for <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> that can assist writers with bias correction. For example, a female character in a story is often portrayed as passive and powerless (_ She daydreams about being a doctor _) while a man is portrayed as more proactive and powerful (_ He pursues his dream of being a doctor _). We formulate * * Controllable Debiasing * *, a new revision task that aims to rewrite a given text to correct the implicit and potentially undesirable bias in character portrayals. We then introduce PowerTransformer as an approach that debiases text through the lens of connotation frames (Sap et al., 2017), which encode pragmatic knowledge of implied power dynamics with respect to verb predicates. One key challenge of our <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is the lack of parallel corpora. To address this challenge, we adopt an unsupervised approach using auxiliary supervision with related tasks such as <a href=https://en.wikipedia.org/wiki/Paraphrasing>paraphrasing</a> and self-supervision based on a reconstruction loss, building on pretrained language models. Through comprehensive experiments based on automatic and human evaluations, we demonstrate that our approach outperforms <a href=https://en.wikipedia.org/wiki/Ablation>ablations</a> and existing <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> from related <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. Furthermore, we demonstrate the use of PowerTransformer as a step toward mitigating the well-documented gender bias in character portrayal in movie scripts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.486.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--486 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.486 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.486.Dataset.tgz data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928840 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.486/>Social Bias Frames : Reasoning about Social and Power Implications of Language</a></strong><br><a href=/people/m/maarten-sap/>Maarten Sap</a>
|
<a href=/people/s/saadia-gabriel/>Saadia Gabriel</a>
|
<a href=/people/l/lianhui-qin/>Lianhui Qin</a>
|
<a href=/people/d/dan-jurafsky/>Dan Jurafsky</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--486><div class="card-body p-3 small">Warning : this paper contains content that may be offensive or upsetting. Language has the power to reinforce <a href=https://en.wikipedia.org/wiki/Stereotype>stereotypes</a> and project <a href=https://en.wikipedia.org/wiki/Bias>social biases</a> onto others. At the core of the challenge is that it is rarely what is stated explicitly, but rather the implied meanings, that frame people&#8217;s judgments about others. For example, given a statement that we should n&#8217;t lower our standards to hire more women, most listeners will infer the implicature intended by the speaker-that women (candidates) are less qualified. Most semantic formalisms, to date, do not capture such pragmatic implications in which people express social biases and power differentials in language. We introduce Social Bias Frames, a new conceptual formalism that aims to model the pragmatic frames in which people project social biases and stereotypes onto others. In addition, we introduce the Social Bias Inference Corpus to support large-scale modelling and evaluation with 150k structured annotations of social media posts, covering over 34k implications about a thousand demographic groups. We then establish baseline approaches that learn to recover Social Bias Frames from <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured text</a>. We find that while state-of-the-art neural models are effective at high-level categorization of whether a given statement projects unwanted social bias (80 % F1), they are not effective at spelling out more detailed explanations in terms of Social Bias Frames. Our study motivates future work that combines structured pragmatic inference with <a href=https://en.wikipedia.org/wiki/Commonsense_reasoning>commonsense reasoning</a> on social implications.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.90.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--90 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.90 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.findings-emnlp.90.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940138 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.findings-emnlp.90" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.90/>Generative Data Augmentation for Commonsense Reasoning</a></strong><br><a href=/people/y/yiben-yang/>Yiben Yang</a>
|
<a href=/people/c/chaitanya-malaviya/>Chaitanya Malaviya</a>
|
<a href=/people/j/jared-fernandez/>Jared Fernandez</a>
|
<a href=/people/s/swabha-swayamdipta/>Swabha Swayamdipta</a>
|
<a href=/people/r/ronan-le-bras/>Ronan Le Bras</a>
|
<a href=/people/j/ji-ping-wang/>Ji-Ping Wang</a>
|
<a href=/people/c/chandra-bhagavatula/>Chandra Bhagavatula</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/d/doug-downey/>Doug Downey</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--90><div class="card-body p-3 small">Recent advances in <a href=https://en.wikipedia.org/wiki/Commonsense_reasoning>commonsense reasoning</a> depend on large-scale human-annotated training sets to achieve peak performance. However, manual curation of training sets is expensive and has been shown to introduce annotation artifacts that neural models can readily exploit and overfit to. We propose a novel generative data augmentation technique, G-DAUGC, that aims to achieve more accurate and robust learning in a low-resource setting. Our approach generates synthetic examples using pretrained language models and selects the most informative and diverse set of examples for <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a>. On experiments with multiple commonsense reasoning benchmarks, G-DAUGC consistently outperforms existing data augmentation methods based on back-translation, establishing a new state-of-the-art on WinoGrande, <a href=https://en.wikipedia.org/wiki/CODAH>CODAH</a>, and CommonsenseQA, as well as enhances out-of-distribution generalization, proving to be robust against adversaries or perturbations. Our analysis demonstrates that G-DAUGC produces a diverse set of fluent training examples, and that its selection and training approaches are important for performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.301.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--301 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.301 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.findings-emnlp.301" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.301/>RealToxicityPrompts : Evaluating Neural Toxic Degeneration in Language Models<span class=acl-fixed-case>R</span>eal<span class=acl-fixed-case>T</span>oxicity<span class=acl-fixed-case>P</span>rompts: Evaluating Neural Toxic Degeneration in Language Models</a></strong><br><a href=/people/s/samuel-gehman/>Samuel Gehman</a>
|
<a href=/people/s/suchin-gururangan/>Suchin Gururangan</a>
|
<a href=/people/m/maarten-sap/>Maarten Sap</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--301><div class="card-body p-3 small">Pretrained neural language models (LMs) are prone to generating racist, sexist, or otherwise toxic language which hinders their safe deployment. We investigate the extent to which pretrained LMs can be prompted to generate toxic language, and the effectiveness of controllable text generation algorithms at preventing such toxic degeneration. We create and release RealToxicityPrompts, a dataset of 100 K naturally occurring, sentence-level prompts derived from a large corpus of English web text, paired with toxicity scores from a widely-used toxicity classifier. Using RealToxicityPrompts, we find that pretrained LMs can degenerate into toxic text even from seemingly innocuous prompts. We empirically assess several controllable generation methods, and find that while data- or compute-intensive methods (e.g., adaptive pretraining on non-toxic data) are more effective at steering away from <a href=https://en.wikipedia.org/wiki/Toxicity_(disambiguation)>toxicity</a> than simpler solutions (e.g., banning bad words), no current method is failsafe against neural toxic degeneration. To pinpoint the potential cause of such persistent toxic degeneration, we analyze two web text corpora used to pretrain several LMs (including GPT-2 ; Radford et. al, 2019), and find a significant amount of offensive, factually unreliable, and otherwise toxic content. Our work provides a test bed for evaluating toxic generations by LMs and stresses the need for better data selection processes for pretraining.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.418.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--418 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.418 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940700 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.findings-emnlp.418" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.418/>Thinking Like a Skeptic : Defeasible Inference in Natural Language</a></strong><br><a href=/people/r/rachel-rudinger/>Rachel Rudinger</a>
|
<a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/j/jena-d-hwang/>Jena D. Hwang</a>
|
<a href=/people/c/chandra-bhagavatula/>Chandra Bhagavatula</a>
|
<a href=/people/m/maxwell-forbes/>Maxwell Forbes</a>
|
<a href=/people/r/ronan-le-bras/>Ronan Le Bras</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--418><div class="card-body p-3 small">Defeasible inference is a mode of reasoning in which an inference (X is a bird, therefore X flies) may be weakened or overturned in light of new evidence (X is a penguin). Though long recognized in classical AI and philosophy, defeasible inference has not been extensively studied in the context of contemporary data-driven research on <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language inference</a> and <a href=https://en.wikipedia.org/wiki/Commonsense_reasoning>commonsense reasoning</a>. We introduce Defeasible NLI (abbreviated -NLI), a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for defeasible inference in <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. Defeasible NLI contains extensions to three existing inference datasets covering diverse modes of reasoning : <a href=https://en.wikipedia.org/wiki/Common_sense>common sense</a>, natural language inference, and <a href=https://en.wikipedia.org/wiki/Social_norm>social norms</a>. From Defeasible NLI, we develop both a classification and generation task for defeasible inference, and demonstrate that the generation task is much more challenging. Despite lagging human performance, however, <a href=https://en.wikipedia.org/wiki/Generative_model>generative models</a> trained on this <a href=https://en.wikipedia.org/wiki/Data>data</a> are capable of writing sentences that weaken or strengthen a specified <a href=https://en.wikipedia.org/wiki/Inference>inference</a> up to 68 % of the time.<tex-math>\\delta</tex-math>-NLI), a dataset for defeasible inference in natural language. Defeasible NLI contains extensions to three existing inference datasets covering diverse modes of reasoning: common sense, natural language inference, and social norms. From Defeasible NLI, we develop both a classification and generation task for defeasible inference, and demonstrate that the generation task is much more challenging. Despite lagging human performance, however, generative models trained on this data are capable of writing sentences that weaken or strengthen a specified inference up to 68% of the time.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1159.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1159 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1159 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1159.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1159" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1159/>Robust Navigation with Language Pretraining and Stochastic Sampling</a></strong><br><a href=/people/x/xiujun-li/>Xiujun Li</a>
|
<a href=/people/c/chunyuan-li/>Chunyuan Li</a>
|
<a href=/people/q/qiaolin-xia/>Qiaolin Xia</a>
|
<a href=/people/y/yonatan-bisk/>Yonatan Bisk</a>
|
<a href=/people/a/asli-celikyilmaz/>Asli Celikyilmaz</a>
|
<a href=/people/j/jianfeng-gao/>Jianfeng Gao</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1159><div class="card-body p-3 small">Core to the vision-and-language navigation (VLN) challenge is building robust instruction representations and action decoding schemes, which can generalize well to previously unseen instructions and environments. In this paper, we report two simple but highly effective methods to address these challenges and lead to a new state-of-the-art performance. First, we adapt large-scale pretrained language models to learn text representations that generalize better to previously unseen instructions. Second, we propose a stochastic sampling scheme to reduce the considerable gap between the expert actions in training and sampled actions in test, so that the agent can learn to correct its own mistakes during long sequential action decoding. Combining the two techniques, we achieve a new state of the art on the Room-to-Room benchmark with 6 % absolute gain over the previous best result (47 %-53 %) on the Success Rate weighted by Path Length metric.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q19-1014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q19-1014 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q19-1014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q19-1014/>DREAM : A Challenge Data Set and Models for Dialogue-Based Reading Comprehension<span class=acl-fixed-case>DREAM</span>: A Challenge Data Set and Models for Dialogue-Based Reading Comprehension</a></strong><br><a href=/people/k/kai-sun/>Kai Sun</a>
|
<a href=/people/d/dian-yu/>Dian Yu</a>
|
<a href=/people/j/jianshu-chen/>Jianshu Chen</a>
|
<a href=/people/d/dong-yu/>Dong Yu</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/Q19-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 7</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q19-1014><div class="card-body p-3 small">We present <a href=https://en.wikipedia.org/wiki/DREAM>DREAM</a>, the first dialogue-based multiple-choice reading comprehension data set. Collected from English as a Foreign Language examinations designed by human experts to evaluate the comprehension level of Chinese learners of English, our <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> contains 10,197 <a href=https://en.wikipedia.org/wiki/Multiple_choice>multiple-choice questions</a> for 6,444 dialogues. In contrast to existing reading comprehension data sets, DREAM is the first to focus on in-depth multi-turn multi-party dialogue understanding. DREAM is likely to present significant challenges for existing reading comprehension systems : 84 % of answers are non-extractive, 85 % of questions require reasoning beyond a single sentence, and 34 % of questions also involve commonsense knowledge. We apply several popular neural reading comprehension models that primarily exploit surface information within the text and find them to, at best, just barely outperform a rule-based approach. We next investigate the effects of incorporating dialogue structure and different kinds of general world knowledge into both rule-based and (neural and non-neural) machine learning-based reading comprehension models. Experimental results on the DREAM data set show the effectiveness of dialogue structure and <a href=https://en.wikipedia.org/wiki/General_knowledge>general world knowledge</a>. DREAM is available at https://dataset.org/dream/.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1470.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1470 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1470 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1470" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1470/>COMET : Commonsense Transformers for Automatic Knowledge Graph Construction<span class=acl-fixed-case>COMET</span>: Commonsense Transformers for Automatic Knowledge Graph Construction</a></strong><br><a href=/people/a/antoine-bosselut/>Antoine Bosselut</a>
|
<a href=/people/h/hannah-rashkin/>Hannah Rashkin</a>
|
<a href=/people/m/maarten-sap/>Maarten Sap</a>
|
<a href=/people/c/chaitanya-malaviya/>Chaitanya Malaviya</a>
|
<a href=/people/a/asli-celikyilmaz/>Asli Celikyilmaz</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1470><div class="card-body p-3 small">We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs : <a href=https://en.wikipedia.org/wiki/ATOMIC>ATOMIC</a> (Sap et al., 2019) and <a href=https://en.wikipedia.org/wiki/ConceptNet>ConceptNet</a> (Speer et al., 2017). Contrary to many conventional <a href=https://en.wikipedia.org/wiki/Knowledge_base>KBs</a> that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when <a href=https://en.wikipedia.org/wiki/Implicit_knowledge>implicit knowledge</a> from deep pre-trained language models is transferred to generate <a href=https://en.wikipedia.org/wiki/Explicit_knowledge>explicit knowledge</a> in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5 % (ATOMIC) and 91.7 % (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1009 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D18-1009.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/305195438 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1009/>SWAG : A Large-Scale Adversarial Dataset for Grounded Commonsense Inference<span class=acl-fixed-case>SWAG</span>: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference</a></strong><br><a href=/people/r/rowan-zellers/>Rowan Zellers</a>
|
<a href=/people/y/yonatan-bisk/>Yonatan Bisk</a>
|
<a href=/people/r/roy-schwartz/>Roy Schwartz</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1009><div class="card-body p-3 small">Given a partial description like she opened the hood of the car, humans can reason about the situation and anticipate what might come next (then, she examined the engine). In this paper, we introduce the task of grounded commonsense inference, unifying <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language inference</a> and <a href=https://en.wikipedia.org/wiki/Commonsense_reasoning>commonsense reasoning</a>. We present SWAG, a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> with 113k multiple choice questions about a rich spectrum of grounded situations. To address the recurring challenges of the annotation artifacts and human biases found in many existing datasets, we propose Adversarial Filtering (AF), a novel procedure that constructs a de-biased dataset by iteratively training an ensemble of stylistic classifiers, and using them to filter the data. To account for the aggressive adversarial filtering, we use state-of-the-art language models to massively oversample a diverse set of potential <a href=https://en.wikipedia.org/wiki/Counterfactual_conditional>counterfactuals</a>. Empirical results demonstrate that while humans can solve the resulting inference problems with high <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> (88 %), various competitive models struggle on our task. We provide comprehensive analysis that indicates significant opportunities for future research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1060.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1060 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1060 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/305197464 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1060" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1060/>Neural Metaphor Detection in Context</a></strong><br><a href=/people/g/ge-gao/>Ge Gao</a>
|
<a href=/people/e/eunsol-choi/>Eunsol Choi</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1060><div class="card-body p-3 small">We present end-to-end neural models for detecting metaphorical word use in context. We show that relatively standard BiLSTM models which operate on complete sentences work well in this setting, in comparison to previous work that used more restricted forms of linguistic context. These models establish a new state-of-the-art on existing verb metaphor detection benchmarks, and show strong performance on jointly predicting the <a href=https://en.wikipedia.org/wiki/Metaphor>metaphoricity</a> of all words in a running text.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1150.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1150 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1150 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1150/>Deep Communicating Agents for Abstractive Summarization</a></strong><br><a href=/people/a/asli-celikyilmaz/>Asli Celikyilmaz</a>
|
<a href=/people/a/antoine-bosselut/>Antoine Bosselut</a>
|
<a href=/people/x/xiaodong-he/>Xiaodong He</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1150><div class="card-body p-3 small">We present deep communicating agents in an encoder-decoder architecture to address the challenges of representing a long document for abstractive summarization. With deep communicating agents, the task of encoding a long text is divided across multiple collaborating agents, each in charge of a subsection of the input text. These encoders are connected to a single <a href=https://en.wikipedia.org/wiki/Encoder>decoder</a>, trained end-to-end using <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> to generate a focused and coherent summary. Empirical results demonstrate that multiple communicating encoders lead to a higher quality summary compared to several strong baselines, including those based on a single <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> or multiple non-communicating encoders.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-5020.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-5020 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-5020 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-5020/>Sounding Board : A User-Centric and Content-Driven Social Chatbot</a></strong><br><a href=/people/h/hao-fang/>Hao Fang</a>
|
<a href=/people/h/hao-cheng/>Hao Cheng</a>
|
<a href=/people/m/maarten-sap/>Maarten Sap</a>
|
<a href=/people/e/elizabeth-clark/>Elizabeth Clark</a>
|
<a href=/people/a/ari-holtzman/>Ari Holtzman</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a>
|
<a href=/people/m/mari-ostendorf/>Mari Ostendorf</a><br><a href=/volumes/N18-5/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-5020><div class="card-body p-3 small">We present Sounding Board, a social chatbot that won the 2017 Amazon Alexa Prize. The system architecture consists of several components including spoken language processing, <a href=https://en.wikipedia.org/wiki/Dialogue_management>dialogue management</a>, <a href=https://en.wikipedia.org/wiki/Language_generation>language generation</a>, and <a href=https://en.wikipedia.org/wiki/Content_management>content management</a>, with emphasis on user-centric and content-driven design. We also share insights gained from large-scale online logs based on 160,000 conversations with real-world users.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1009 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1009.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285807855 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1009/>Ultra-Fine Entity Typing</a></strong><br><a href=/people/e/eunsol-choi/>Eunsol Choi</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1009><div class="card-body p-3 small">We introduce a new entity typing task : given a sentence with an entity mention, the goal is to predict a set of free-form phrases (e.g. skyscraper, <a href=https://en.wikipedia.org/wiki/Songwriter>songwriter</a>, or criminal) that describe appropriate types for the target entity. This formulation allows us to use a new type of distant supervision at large scale : head words, which indicate the type of the noun phrases they appear in. We show that these ultra-fine types can be crowd-sourced, and introduce new evaluation sets that are much more diverse and fine-grained than existing <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a>. We present a model that can predict ultra-fine types, and is trained using a multitask objective that pools our new head-word supervision with prior supervision from <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity linking</a>. Experimental results demonstrate that our model is effective in predicting entity types at varying granularity ; it achieves state of the art performance on an existing fine-grained entity typing benchmark, and sets baselines for our newly-introduced datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1152.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1152 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1152 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1152.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1152.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1152" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1152/>Learning to Write with Cooperative Discriminators</a></strong><br><a href=/people/a/ari-holtzman/>Ari Holtzman</a>
|
<a href=/people/j/jan-buys/>Jan Buys</a>
|
<a href=/people/m/maxwell-forbes/>Maxwell Forbes</a>
|
<a href=/people/a/antoine-bosselut/>Antoine Bosselut</a>
|
<a href=/people/d/david-golub/>David Golub</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1152><div class="card-body p-3 small">Despite their local fluency, long-form text generated from RNNs is often generic, repetitive, and even self-contradictory. We propose a unified learning framework that collectively addresses all the above issues by composing a committee of discriminators that can guide a base RNN generator towards more globally coherent generations. More concretely, discriminators each specialize in a different principle of communication, such as <a href=https://en.wikipedia.org/wiki/Grice&#8217;s_maxims>Grice&#8217;s maxims</a>, and are collectively combined with the base RNN generator through a composite decoding objective. Human evaluation demonstrates that text generated by our model is preferred over that of baselines by a large margin, significantly enhancing the overall coherence, style, and information of the generations.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-1004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-1004 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-1004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K17-1004" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K17-1004/>The Effect of Different Writing Tasks on Linguistic Style : A Case Study of the ROC Story Cloze Task<span class=acl-fixed-case>ROC</span> Story Cloze Task</a></strong><br><a href=/people/r/roy-schwartz/>Roy Schwartz</a>
|
<a href=/people/m/maarten-sap/>Maarten Sap</a>
|
<a href=/people/i/ioannis-konstas/>Ioannis Konstas</a>
|
<a href=/people/l/leila-zilles/>Leila Zilles</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a><br><a href=/volumes/K17-1/ class=text-muted>Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-1004><div class="card-body p-3 small">A writer&#8217;s style depends not just on <a href=https://en.wikipedia.org/wiki/Trait_theory>personal traits</a> but also on her intent and mental state. In this paper, we show how variants of the same writing task can lead to measurable differences in <a href=https://en.wikipedia.org/wiki/Writing_style>writing style</a>. We present a case study based on the story cloze task (Mostafazadeh et al., 2016a), where annotators were assigned similar writing tasks with different constraints : (1) writing an entire story, (2) adding a story ending for a given story context, and (3) adding an incoherent ending to a story. We show that a simple <a href=https://en.wikipedia.org/wiki/Linear_classifier>linear classifier</a> informed by stylistic features is able to successfully distinguish among the three cases, without even looking at the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>story context</a>. In addition, combining our stylistic features with language model predictions reaches state of the art performance on the story cloze challenge. Our results demonstrate that different <a href=https://en.wikipedia.org/wiki/Framing_(social_sciences)>task framings</a> can dramatically affect the way people write.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1014 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-1014.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234952236 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P17-1014" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1014/>Neural AMR : Sequence-to-Sequence Models for Parsing and Generation<span class=acl-fixed-case>AMR</span>: Sequence-to-Sequence Models for Parsing and Generation</a></strong><br><a href=/people/i/ioannis-konstas/>Ioannis Konstas</a>
|
<a href=/people/s/srinivasan-iyer/>Srinivasan Iyer</a>
|
<a href=/people/m/mark-yatskar/>Mark Yatskar</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1014><div class="card-body p-3 small">Sequence-to-sequence models have shown strong performance across a broad range of applications. However, their application to <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a> and generating text using Abstract Meaning Representation (AMR) has been limited, due to the relatively limited amount of labeled data and the non-sequential nature of the AMR graphs. We present a novel training procedure that can lift this limitation using millions of unlabeled sentences and careful preprocessing of the AMR graphs. For AMR parsing, our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> achieves competitive results of 62.1 SMATCH, the current best score reported without significant use of external semantic resources. For AMR generation, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> establishes a new state-of-the-art performance of BLEU 33.8. We present extensive ablative and qualitative analysis including strong evidence that sequence-based AMR models are robust against ordering variations of graph-to-sequence conversions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1025.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1025 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1025 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234954495 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1025/>Verb Physics : Relative Physical Knowledge of Actions and Objects</a></strong><br><a href=/people/m/maxwell-forbes/>Maxwell Forbes</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1025><div class="card-body p-3 small">Learning commonsense knowledge from <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language text</a> is nontrivial due to reporting bias : people rarely state the obvious, e.g., My house is bigger than me. However, while rarely stated explicitly, this trivial everyday knowledge does influence the way people talk about the world, which provides indirect clues to reason about the world. For example, a statement like, Tyler entered his house implies that his house is bigger than Tyler. In this paper, we present an approach to infer relative physical knowledge of actions and objects along five dimensions (e.g., size, weight, and strength) from unstructured natural language text. We frame <a href=https://en.wikipedia.org/wiki/Knowledge_acquisition>knowledge acquisition</a> as joint inference over two closely related problems : learning (1) relative physical knowledge of object pairs and (2) physical implications of actions when applied to those object pairs. Empirical results demonstrate that it is possible to extract knowledge of actions and objects from <a href=https://en.wikipedia.org/wiki/Language>language</a> and that joint inference over different types of <a href=https://en.wikipedia.org/wiki/Knowledge>knowledge</a> improves performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2073.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2073 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2073 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P17-2073/>Multilingual Connotation Frames : A Case Study on <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a> for Targeted Sentiment Analysis and Forecast</a></strong><br><a href=/people/h/hannah-rashkin/>Hannah Rashkin</a>
|
<a href=/people/e/eric-bell/>Eric Bell</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/s/svitlana-volkova/>Svitlana Volkova</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2073><div class="card-body p-3 small">People around the globe respond to major real world events through <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. To study targeted public sentiments across many languages and geographic locations, we introduce multilingual connotation frames : an extension from English connotation frames of Rashkin et al. (2016) with 10 additional <a href=https://en.wikipedia.org/wiki/Languages_of_Europe>European languages</a>, focusing on the implied sentiments among event participants engaged in a frame. As a case study, we present large scale analysis on targeted public sentiments toward salient events and <a href=https://en.wikipedia.org/wiki/Non-physical_entity>entities</a> using 1.2 million multilingual connotation frames extracted from <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1099.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1099 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1099 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D17-1099" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D17-1099/>Zero-Shot Activity Recognition with Verb Attribute Induction</a></strong><br><a href=/people/r/rowan-zellers/>Rowan Zellers</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1099><div class="card-body p-3 small">In this paper, we investigate large-scale zero-shot activity recognition by modeling the visual and linguistic attributes of action verbs. For example, the verb salute has several properties, such as being a light movement, a <a href=https://en.wikipedia.org/wiki/Social_actions>social act</a>, and short in duration. We use these attributes as the internal mapping between visual and textual representations to reason about a previously unseen action. In contrast to much prior work that assumes access to gold standard attributes for zero-shot classes and focuses primarily on object attributes, our model uniquely learns to infer action attributes from dictionary definitions and distributed word representations. Experimental results confirm that action attributes inferred from <a href=https://en.wikipedia.org/wiki/Language>language</a> can provide a predictive signal for zero-shot prediction of previously unseen activities.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1195.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1195 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1195 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D17-1195" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D17-1195/>Dynamic Entity Representations in Neural Language Models</a></strong><br><a href=/people/y/yangfeng-ji/>Yangfeng Ji</a>
|
<a href=/people/c/chenhao-tan/>Chenhao Tan</a>
|
<a href=/people/s/sebastian-martschat/>Sebastian Martschat</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1195><div class="card-body p-3 small">Understanding a long document requires tracking how entities are introduced and evolve over time. We present a new type of <a href=https://en.wikipedia.org/wiki/Language_model>language model</a>, EntityNLM, that can explicitly model entities, dynamically update their representations, and contextually generate their mentions. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is generative and flexible ; it can model an arbitrary number of entities in context while generating each entity mention at an arbitrary length. In addition, it can be used for several different tasks such as <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>, <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a>, and <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity prediction</a>. Experimental results with all these tasks demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> consistently outperforms strong baselines and prior work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1247.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1247 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1247 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D17-1247.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1247/>Connotation Frames of Power and Agency in Modern Films</a></strong><br><a href=/people/m/maarten-sap/>Maarten Sap</a>
|
<a href=/people/m/marcella-cindy-prasettio/>Marcella Cindy Prasettio</a>
|
<a href=/people/a/ari-holtzman/>Ari Holtzman</a>
|
<a href=/people/h/hannah-rashkin/>Hannah Rashkin</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1247><div class="card-body p-3 small">The framing of an action influences how we perceive its actor. We introduce connotation frames of power and agency, a pragmatic formalism organized using frame semantic representations, to model how different levels of <a href=https://en.wikipedia.org/wiki/Power_(social_and_political)>power</a> and <a href=https://en.wikipedia.org/wiki/Agency_(sociology)>agency</a> are implicitly projected on actors through their actions. We use the new power and agency frames to measure the subtle, but prevalent, gender bias in the portrayal of modern film characters and provide insights that deviate from the well-known <a href=https://en.wikipedia.org/wiki/Bechdel_test>Bechdel test</a>. Our contributions include an extended lexicon of connotation frames along with a <a href=https://en.wikipedia.org/wiki/User_interface>web interface</a> that provides a comprehensive analysis through the lens of connotation frames.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1317.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1317 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1317 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238236521 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1317/>Truth of Varying Shades : Analyzing Language in Fake News and Political Fact-Checking</a></strong><br><a href=/people/h/hannah-rashkin/>Hannah Rashkin</a>
|
<a href=/people/e/eunsol-choi/>Eunsol Choi</a>
|
<a href=/people/j/jin-yea-jang/>Jin Yea Jang</a>
|
<a href=/people/s/svitlana-volkova/>Svitlana Volkova</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1317><div class="card-body p-3 small">We present an analytic study on the language of news media in the context of <a href=https://en.wikipedia.org/wiki/Fact-checking>political fact-checking</a> and fake news detection. We compare the language of real news with that of <a href=https://en.wikipedia.org/wiki/Satire>satire</a>, <a href=https://en.wikipedia.org/wiki/Hoax>hoaxes</a>, and <a href=https://en.wikipedia.org/wiki/Propaganda>propaganda</a> to find linguistic characteristics of untrustworthy text. To probe the feasibility of automatic political fact-checking, we also present a <a href=https://en.wikipedia.org/wiki/Case_study>case study</a> based on <a href=https://en.wikipedia.org/wiki/PolitiFact>PolitiFact.com</a> using their factuality judgments on a 6-point scale. Experiments show that while media fact-checking remains to be an open research question, stylistic cues can help determine the truthfulness of text.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Yejin+Choi" title="Search for 'Yejin Choi' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/m/maarten-sap/ class=align-middle>Maarten Sap</a>
<span class="badge badge-secondary align-middle ml-2">10</span></li><li class=list-group-item><a href=/people/n/noah-a-smith/ class=align-middle>Noah A. Smith</a>
<span class="badge badge-secondary align-middle ml-2">9</span></li><li class=list-group-item><a href=/people/m/maxwell-forbes/ class=align-middle>Maxwell Forbes</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/a/antoine-bosselut/ class=align-middle>Antoine Bosselut</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/h/hannah-rashkin/ class=align-middle>Hannah Rashkin</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/r/rowan-zellers/ class=align-middle>Rowan Zellers</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/s/swabha-swayamdipta/ class=align-middle>Swabha Swayamdipta</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/c/chandra-bhagavatula/ class=align-middle>Chandra Bhagavatula</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/e/eunsol-choi/ class=align-middle>Eunsol Choi</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/r/ronan-le-bras/ class=align-middle>Ronan Le Bras</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/a/ari-holtzman/ class=align-middle>Ari Holtzman</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/j/jena-d-hwang/ class=align-middle>Jena D. Hwang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/luke-zettlemoyer/ class=align-middle>Luke Zettlemoyer</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/asli-celikyilmaz/ class=align-middle>Asli Celikyilmaz</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/alisa-liu/ class=align-middle>Alisa Liu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/x/ximing-lu/ class=align-middle>Ximing Lu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/saadia-gabriel/ class=align-middle>Saadia Gabriel</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/lianhui-qin/ class=align-middle>Lianhui Qin</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/roy-schwartz/ class=align-middle>Roy Schwartz</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/i/ioannis-konstas/ class=align-middle>Ioannis Konstas</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/svitlana-volkova/ class=align-middle>Svitlana Volkova</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yonatan-bisk/ class=align-middle>Yonatan Bisk</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/elizabeth-clark/ class=align-middle>Elizabeth Clark</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/chaitanya-malaviya/ class=align-middle>Chaitanya Malaviya</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jeff-da/ class=align-middle>Jeff Da</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anthony-zheng/ class=align-middle>Anthony Zheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xinyao-ma/ class=align-middle>Xinyao Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dan-jurafsky/ class=align-middle>Dan Jurafsky</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/leila-zilles/ class=align-middle>Leila Zilles</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/srinivasan-iyer/ class=align-middle>Srinivasan Iyer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mark-yatskar/ class=align-middle>Mark Yatskar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eric-bell/ class=align-middle>Eric Bell</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xuhui-zhou/ class=align-middle>Xuhui Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/skyler-hallinan/ class=align-middle>Skyler Hallinan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pemi-nguyen/ class=align-middle>Pemi Nguyen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/franziska-roesner/ class=align-middle>Franziska Roesner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiacheng-liu/ class=align-middle>Jiacheng Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sean-welleck/ class=align-middle>Sean Welleck</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/peter-west/ class=align-middle>Peter West</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hannaneh-hajishirzi/ class=align-middle>Hannaneh Hajishirzi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/ge-gao/ class=align-middle>Ge Gao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/denis-emelin/ class=align-middle>Denis Emelin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alon-jacovi/ class=align-middle>Alon Jacovi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shauli-ravfogel/ class=align-middle>Shauli Ravfogel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yanai-elazar/ class=align-middle>Yanai Elazar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yoav-goldberg/ class=align-middle>Yoav Goldberg</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiujun-li/ class=align-middle>Xiujun Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chunyuan-li/ class=align-middle>Chunyuan Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qiaolin-xia/ class=align-middle>Qiaolin Xia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jianfeng-gao/ class=align-middle>Jianfeng Gao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yangfeng-ji/ class=align-middle>Yangfeng Ji</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chenhao-tan/ class=align-middle>Chenhao Tan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sebastian-martschat/ class=align-middle>Sebastian Martschat</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marcella-cindy-prasettio/ class=align-middle>Marcella Cindy Prasettio</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jin-yea-jang/ class=align-middle>Jin Yea Jang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kai-sun/ class=align-middle>Kai Sun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dian-yu/ class=align-middle>Dian Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jianshu-chen/ class=align-middle>Jianshu Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dong-yu/ class=align-middle>Dong Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/claire-cardie/ class=align-middle>Claire Cardie</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/liwei-jiang/ class=align-middle>Liwei Jiang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ali-farhadi/ class=align-middle>Ali Farhadi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yiben-yang/ class=align-middle>Yiben Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jared-fernandez/ class=align-middle>Jared Fernandez</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/ji-ping-wang/ class=align-middle>Ji-Ping Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/doug-downey/ class=align-middle>Doug Downey</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/samuel-gehman/ class=align-middle>Samuel Gehman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/suchin-gururangan/ class=align-middle>Suchin Gururangan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rachel-rudinger/ class=align-middle>Rachel Rudinger</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vered-shwartz/ class=align-middle>Vered Shwartz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaodong-he/ class=align-middle>Xiaodong He</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hao-fang/ class=align-middle>Hao Fang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hao-cheng/ class=align-middle>Hao Cheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mari-ostendorf/ class=align-middle>Mari Ostendorf</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/omer-levy/ class=align-middle>Omer Levy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jan-buys/ class=align-middle>Jan Buys</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/david-golub/ class=align-middle>David Golub</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">11</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">10</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/tacl/ class=align-middle>TACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>