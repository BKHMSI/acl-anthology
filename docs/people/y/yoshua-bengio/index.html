<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Yoshua Bengio - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Yoshua</span> <span class=font-weight-bold>Bengio</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ltedi-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ltedi-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ltedi-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ltedi-1.4/>hBERT + BiasCorp-Fighting Racism on the Web<span class=acl-fixed-case>BERT</span> + <span class=acl-fixed-case>B</span>ias<span class=acl-fixed-case>C</span>orp - Fighting Racism on the Web</a></strong><br><a href=/people/o/olawale-onabola/>Olawale Onabola</a>
|
<a href=/people/z/zhuang-ma/>Zhuang Ma</a>
|
<a href=/people/x/xie-yang/>Xie Yang</a>
|
<a href=/people/b/benjamin-akera/>Benjamin Akera</a>
|
<a href=/people/i/ibraheem-abdulrahman/>Ibraheem Abdulrahman</a>
|
<a href=/people/j/jia-xue/>Jia Xue</a>
|
<a href=/people/d/dianbo-liu/>Dianbo Liu</a>
|
<a href=/people/y/yoshua-bengio/>Yoshua Bengio</a><br><a href=/volumes/2021.ltedi-1/ class=text-muted>Proceedings of the First Workshop on Language Technology for Equality, Diversity and Inclusion</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ltedi-1--4><div class="card-body p-3 small">Subtle and overt racism is still present both in physical and online communities today and has impacted many lives in different segments of the society. In this short piece of work, we present how we&#8217;re tackling this societal issue with <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a>. We are releasing BiasCorp, a dataset containing 139,090 comments and news segment from three specific sources-Fox News, <a href=https://en.wikipedia.org/wiki/Breitbart_News>BreitbartNews</a> and <a href=https://en.wikipedia.org/wiki/YouTube>YouTube</a>. The first batch (45,000 manually annotated) is ready for publication. We are currently in the final phase of manually labeling the remaining <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> using <a href=https://en.wikipedia.org/wiki/Amazon_Mechanical_Turk>Amazon Mechanical Turk</a>. BERT has been used widely in several downstream tasks. In this work, we present hBERT, where we modify certain layers of the pretrained BERT model with the new Hopfield Layer. hBert generalizes well across different distributions with the added advantage of a reduced model complexity. We are also releasing a JavaScript library 3 and a Chrome Extension Application, to help developers make use of our trained model in web applications (say chat application) and for users to identify and report racially biased contents on the web respectively</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1280.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1280 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1280 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1280.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1280" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1280/>Interactive Language Learning by Question Answering</a></strong><br><a href=/people/x/xingdi-yuan/>Xingdi Yuan</a>
|
<a href=/people/m/marc-alexandre-cote/>Marc-Alexandre Côté</a>
|
<a href=/people/j/jie-fu/>Jie Fu</a>
|
<a href=/people/z/zhouhan-lin/>Zhouhan Lin</a>
|
<a href=/people/c/christopher-pal/>Chris Pal</a>
|
<a href=/people/y/yoshua-bengio/>Yoshua Bengio</a>
|
<a href=/people/a/adam-trischler/>Adam Trischler</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1280><div class="card-body p-3 small">Humans observe and interact with the world to acquire knowledge. However, most existing machine reading comprehension (MRC) tasks miss the interactive, information-seeking component of comprehension. Such <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> present <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> with static documents that contain all necessary information, usually concentrated in a single short substring. Thus, <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> can achieve strong performance through simple word- and phrase-based pattern matching. We address this problem by formulating a novel text-based question answering task : Question Answering with Interactive Text (QAit). In QAit, an agent must interact with a partially observable text-based environment to gather information required to answer questions. QAit poses questions about the existence, location, and attributes of objects found in the environment. The <a href=https://en.wikipedia.org/wiki/Data>data</a> is built using a text-based game generator that defines the underlying dynamics of interaction with the environment. We propose and evaluate a set of <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline models</a> for the QAit task that includes deep reinforcement learning agents. Experiments show that the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> presents a major challenge for machine reading systems, while humans solve it with relative ease.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1004 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383952222 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1004" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1004/>Do Neural Dialog Systems Use the Conversation History Effectively? An Empirical Study</a></strong><br><a href=/people/c/chinnadhurai-sankar/>Chinnadhurai Sankar</a>
|
<a href=/people/s/sandeep-subramanian/>Sandeep Subramanian</a>
|
<a href=/people/c/christopher-pal/>Chris Pal</a>
|
<a href=/people/s/sarath-chandar/>Sarath Chandar</a>
|
<a href=/people/y/yoshua-bengio/>Yoshua Bengio</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1004><div class="card-body p-3 small">Neural generative models have been become increasingly popular when building <a href=https://en.wikipedia.org/wiki/Intelligent_agent>conversational agents</a>. They offer flexibility, can be easily adapted to <a href=https://en.wikipedia.org/wiki/Domain_of_unknown_function>new domains</a>, and require minimal domain engineering. A common criticism of these <a href=https://en.wikipedia.org/wiki/System>systems</a> is that they seldom understand or use the available dialog history effectively. In this paper, we take an empirical approach to understanding how these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> use the available dialog history by studying the sensitivity of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> to artificially introduced unnatural changes or perturbations to their context at test time. We experiment with 10 different types of perturbations on 4 multi-turn dialog datasets and find that commonly used neural dialog architectures like recurrent and transformer-based seq2seq models are rarely sensitive to most perturbations such as missing or reordering utterances, shuffling words, etc. Also, by open-sourcing our <a href=https://en.wikipedia.org/wiki/Source_code>code</a>, we believe that it will serve as a useful diagnostic tool for evaluating <a href=https://en.wikipedia.org/wiki/Dialog_(software)>dialog systems</a> in the future.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-1002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-1002 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-1002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-1002/>Commonsense mining as knowledge base completion? A study on the impact of <a href=https://en.wikipedia.org/wiki/Novelty>novelty</a></a></strong><br><a href=/people/s/stanislaw-jastrzebski/>Stanislaw Jastrzębski</a>
|
<a href=/people/d/dzmitry-bahdanau/>Dzmitry Bahdanau</a>
|
<a href=/people/s/seyedarian-hosseini/>Seyedarian Hosseini</a>
|
<a href=/people/m/michael-noukhovitch/>Michael Noukhovitch</a>
|
<a href=/people/y/yoshua-bengio/>Yoshua Bengio</a>
|
<a href=/people/j/jackie-chi-kit-cheung/>Jackie Cheung</a><br><a href=/volumes/W18-10/ class=text-muted>Proceedings of the Workshop on Generalization in the Age of Deep Learning</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-1002><div class="card-body p-3 small">Commonsense knowledge bases such as <a href=https://en.wikipedia.org/wiki/ConceptNet>ConceptNet</a> represent knowledge in the form of relational triples. Inspired by recent work by Li et al., we analyse if knowledge base completion models can be used to mine <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a> from raw text. We propose novelty of predicted triples with respect to the training set as an important factor in interpreting results. We critically analyse the difficulty of mining novel commonsense knowledge, and show that a simple baseline method that outperforms the previous state of the art on predicting more novel triples.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3020.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3020 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3020 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3020/>Learning Hierarchical Structures On-The-Fly with a Recurrent-Recursive Model for Sequences</a></strong><br><a href=/people/a/athul-paul-jacob/>Athul Paul Jacob</a>
|
<a href=/people/z/zhouhan-lin/>Zhouhan Lin</a>
|
<a href=/people/a/alessandro-sordoni/>Alessandro Sordoni</a>
|
<a href=/people/y/yoshua-bengio/>Yoshua Bengio</a><br><a href=/volumes/W18-30/ class=text-muted>Proceedings of The Third Workshop on Representation Learning for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3020><div class="card-body p-3 small">We propose a <a href=https://en.wikipedia.org/wiki/Hierarchical_model>hierarchical model</a> for sequential data that learns a <a href=https://en.wikipedia.org/wiki/Tree_(graph_theory)>tree</a> on-the-fly, i.e. while reading the sequence. In the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent network</a> adapts its structure and reuses recurrent weights in a recursive manner. This creates adaptive skip-connections that ease the learning of long-term dependencies. The <a href=https://en.wikipedia.org/wiki/Tree_structure>tree structure</a> can either be inferred without <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervision</a> through <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a>, or learned in a supervised manner. We provide preliminary experiments in a novel Math Expression Evaluation (MEE) task, which is created to have a hierarchical tree structure that can be used to study the effectiveness of our model. Additionally, we test our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in a well-known propositional logic and language modelling tasks. Experimental results have shown the potential of our <a href=https://en.wikipedia.org/wiki/Scientific_method>approach</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1108.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1108 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1108 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1108.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802441 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1108" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1108/>Straight to the Tree : Constituency Parsing with Neural Syntactic Distance</a></strong><br><a href=/people/y/yikang-shen/>Yikang Shen</a>
|
<a href=/people/z/zhouhan-lin/>Zhouhan Lin</a>
|
<a href=/people/a/athul-paul-jacob/>Athul Paul Jacob</a>
|
<a href=/people/a/alessandro-sordoni/>Alessandro Sordoni</a>
|
<a href=/people/a/aaron-courville/>Aaron Courville</a>
|
<a href=/people/y/yoshua-bengio/>Yoshua Bengio</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1108><div class="card-body p-3 small">In this work, we propose a novel constituency parsing scheme. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> first predicts a real-valued scalar, named syntactic distance, for each split position in the sentence. The topology of grammar tree is then determined by the values of syntactic distances. Compared to traditional shift-reduce parsing schemes, our approach is free from the potentially disastrous compounding error. It is also easier to parallelize and much faster. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves the state-of-the-art single model F1 score of 92.1 on PTB and 86.4 on CTB dataset, which surpasses the previous single model results by a large margin.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1103.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1103 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1103 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-1103.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234958888 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P17-1103" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1103/>Towards an Automatic Turing Test : Learning to Evaluate Dialogue Responses<span class=acl-fixed-case>T</span>uring Test: Learning to Evaluate Dialogue Responses</a></strong><br><a href=/people/r/ryan-lowe/>Ryan Lowe</a>
|
<a href=/people/m/michael-noseworthy/>Michael Noseworthy</a>
|
<a href=/people/i/iulian-vlad-serban/>Iulian Vlad Serban</a>
|
<a href=/people/n/nicolas-angelard-gontier/>Nicolas Angelard-Gontier</a>
|
<a href=/people/y/yoshua-bengio/>Yoshua Bengio</a>
|
<a href=/people/j/joelle-pineau/>Joelle Pineau</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1103><div class="card-body p-3 small">Automatically evaluating the quality of dialogue responses for <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured domains</a> is a challenging problem. Unfortunately, existing automatic evaluation metrics are biased and correlate very poorly with human judgements of response quality (Liu et al., 2016). Yet having an accurate automatic evaluation procedure is crucial for dialogue research, as it allows rapid prototyping and testing of new <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> with fewer expensive human evaluations. In response to this challenge, we formulate automatic dialogue evaluation as a learning problem. We present an evaluation model (ADEM)that learns to predict human-like scores to input responses, using a new dataset of human response scores. We show that the ADEM model&#8217;s predictions correlate significantly, and at a level much higher than word-overlap metrics such as <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>, with human judgements at both the utterance and system-level. We also show that ADEM can generalize to evaluating dialogue mod-els unseen during training, an important step for automatic dialogue evaluation.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Yoshua+Bengio" title="Search for 'Yoshua Bengio' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/z/zhouhan-lin/ class=align-middle>Zhouhan Lin</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/c/christopher-pal/ class=align-middle>Christopher Pal</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/athul-paul-jacob/ class=align-middle>Athul Paul Jacob</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/alessandro-sordoni/ class=align-middle>Alessandro Sordoni</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/o/olawale-onabola/ class=align-middle>Olawale Onabola</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/z/zhuang-ma/ class=align-middle>Zhuang Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xie-yang/ class=align-middle>Xie Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/benjamin-akera/ class=align-middle>Benjamin Akera</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ibraheem-abdulrahman/ class=align-middle>Ibraheem Abdulrahman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jia-xue/ class=align-middle>Jia Xue</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dianbo-liu/ class=align-middle>Dianbo Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ryan-lowe/ class=align-middle>Ryan Lowe</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-noseworthy/ class=align-middle>Michael Noseworthy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/iulian-vlad-serban/ class=align-middle>Iulian Vlad Serban</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nicolas-angelard-gontier/ class=align-middle>Nicolas Angelard-Gontier</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joelle-pineau/ class=align-middle>Joelle Pineau</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xingdi-yuan/ class=align-middle>Xingdi Yuan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marc-alexandre-cote/ class=align-middle>Marc-Alexandre Côté</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jie-fu/ class=align-middle>Jie Fu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/adam-trischler/ class=align-middle>Adam Trischler</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stanislaw-jastrzebski/ class=align-middle>Stanislaw Jastrzębski</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dzmitry-bahdanau/ class=align-middle>Dzmitry Bahdanau</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/seyedarian-hosseini/ class=align-middle>Seyedarian Hosseini</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-noukhovitch/ class=align-middle>Michael Noukhovitch</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jackie-chi-kit-cheung/ class=align-middle>Jackie Chi Kit Cheung</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yikang-shen/ class=align-middle>Yikang Shen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aaron-courville/ class=align-middle>Aaron Courville</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chinnadhurai-sankar/ class=align-middle>Chinnadhurai Sankar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sandeep-subramanian/ class=align-middle>Sandeep Subramanian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sarath-chandar/ class=align-middle>Sarath Chandar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ltedi/ class=align-middle>LTEDI</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>