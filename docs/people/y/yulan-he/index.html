<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Yulan He - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Yulan</span> <span class=font-weight-bold>He</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.125.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--125 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.125 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.125" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.125/>Topic-Driven and Knowledge-Aware Transformer for Dialogue Emotion Detection</a></strong><br><a href=/people/l/lixing-zhu/>Lixing Zhu</a>
|
<a href=/people/g/gabriele-pergola/>Gabriele Pergola</a>
|
<a href=/people/l/lin-gui/>Lin Gui</a>
|
<a href=/people/d/deyu-zhou/>Deyu Zhou</a>
|
<a href=/people/y/yulan-he/>Yulan He</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--125><div class="card-body p-3 small">Emotion detection in dialogues is challenging as it often requires the identification of thematic topics underlying a <a href=https://en.wikipedia.org/wiki/Conversation>conversation</a>, the relevant commonsense knowledge, and the intricate transition patterns between the affective states. In this paper, we propose a Topic-Driven Knowledge-Aware Transformer to handle the challenges above. We firstly design a topic-augmented language model (LM) with an additional layer specialized for topic detection. The topic-augmented LM is then combined with commonsense statements derived from a <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base</a> based on the dialogue contextual information. Finally, a transformer-based encoder-decoder architecture fuses the topical and commonsense information, and performs the emotion label sequence prediction. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> has been experimented on four <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> in dialogue emotion detection, demonstrating its superiority empirically over the existing state-of-the-art approaches. Quantitative and qualitative results show that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can discover topics which help in distinguishing emotion categories.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.128.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--128 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.128 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.128" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.128/>Topic-Aware Evidence Reasoning and Stance-Aware Aggregation for Fact Verification</a></strong><br><a href=/people/j/jiasheng-si/>Jiasheng Si</a>
|
<a href=/people/d/deyu-zhou/>Deyu Zhou</a>
|
<a href=/people/t/tongzhe-li/>Tongzhe Li</a>
|
<a href=/people/x/xingyu-shi/>Xingyu Shi</a>
|
<a href=/people/y/yulan-he/>Yulan He</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--128><div class="card-body p-3 small">Fact verification is a challenging task that requires simultaneously <a href=https://en.wikipedia.org/wiki/Reason>reasoning</a> and aggregating over multiple retrieved pieces of evidence to evaluate the truthfulness of a claim. Existing approaches typically (i) explore the semantic interaction between the claim and evidence at different granularity levels but fail to capture their topical consistency during the reasoning process, which we believe is crucial for verification ; (ii) aggregate multiple pieces of evidence equally without considering their implicit stances to the claim, thereby introducing spurious information. To alleviate the above issues, we propose a novel topic-aware evidence reasoning and stance-aware aggregation model for more accurate fact verification, with the following four key properties : 1) checking topical consistency between the claim and evidence ; 2) maintaining topical coherence among multiple pieces of evidence ; 3) ensuring semantic similarity between the global topic information and the semantic representation of evidence ; 4) aggregating evidence based on their implicit stances to the claim. Extensive experiments conducted on the two benchmark datasets demonstrate the superiority of the proposed model over several state-of-the-art approaches for fact verification. The source code can be obtained from https://github.com/jasenchn/TARSA.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.261.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--261 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.261 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.261" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.261/>Position Bias Mitigation : A Knowledge-Aware Graph Model for Emotion Cause Extraction</a></strong><br><a href=/people/h/hanqi-yan/>Hanqi Yan</a>
|
<a href=/people/l/lin-gui/>Lin Gui</a>
|
<a href=/people/g/gabriele-pergola/>Gabriele Pergola</a>
|
<a href=/people/y/yulan-he/>Yulan He</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--261><div class="card-body p-3 small">The Emotion Cause Extraction (ECE) task aims to identify clauses which contain emotion-evoking information for a particular <a href=https://en.wikipedia.org/wiki/Emotion>emotion</a> expressed in text. We observe that a widely-used ECE dataset exhibits a bias that the majority of annotated cause clauses are either directly before their associated emotion clauses or are the emotion clauses themselves. Existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> for ECE tend to explore such relative position information and suffer from the dataset bias. To investigate the degree of reliance of existing ECE models on clause relative positions, we propose a novel strategy to generate adversarial examples in which the relative position information is no longer the indicative feature of cause clauses. We test the performance of existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on such adversarial examples and observe a significant performance drop. To address the dataset bias, we propose a novel graph-based method to explicitly model the emotion triggering paths by leveraging the commonsense knowledge to enhance the semantic dependencies between a candidate clause and an emotion clause. Experimental results show that our proposed approach performs on par with the existing state-of-the-art methods on the original ECE dataset, and is more robust against adversarial attacks compared to existing models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.636.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--636 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.636 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.636" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.636/>Extracting Event Temporal Relations via <a href=https://en.wikipedia.org/wiki/Hyperbolic_geometry>Hyperbolic Geometry</a></a></strong><br><a href=/people/x/xingwei-tan/>Xingwei Tan</a>
|
<a href=/people/g/gabriele-pergola/>Gabriele Pergola</a>
|
<a href=/people/y/yulan-he/>Yulan He</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--636><div class="card-body p-3 small">Detecting events and their evolution through time is a crucial task in <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a>. Recent neural approaches to event temporal relation extraction typically map events to embeddings in the <a href=https://en.wikipedia.org/wiki/Euclidean_space>Euclidean space</a> and train a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> to detect temporal relations between event pairs. However, embeddings in the <a href=https://en.wikipedia.org/wiki/Euclidean_space>Euclidean space</a> can not capture richer <a href=https://en.wikipedia.org/wiki/Asymmetric_relation>asymmetric relations</a> such as event temporal relations. We thus propose to embed <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>events</a> into hyperbolic spaces, which are intrinsically oriented at modeling <a href=https://en.wikipedia.org/wiki/Hierarchical_organization>hierarchical structures</a>. We introduce two approaches to encode <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>events</a> and their temporal relations in hyperbolic spaces. One approach leverages hyperbolic embeddings to directly infer <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>event relations</a> through simple <a href=https://en.wikipedia.org/wiki/Operation_(mathematics)>geometrical operations</a>. In the second one, we devise an <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end architecture</a> composed of hyperbolic neural units tailored for the temporal relation extraction task. Thorough experimental assessments on widely used datasets have shown the benefits of revisiting the tasks on a different <a href=https://en.wikipedia.org/wiki/Space>geometrical space</a>, resulting in state-of-the-art performance on several standard <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a>. Finally, the ablation study and several qualitative analyses highlighted the rich event semantics implicitly encoded into hyperbolic spaces.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.0/>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></strong><br><a href=/people/b/bonnie-webber/>Bonnie Webber</a>
|
<a href=/people/t/trevor-cohn/>Trevor Cohn</a>
|
<a href=/people/y/yulan-he/>Yulan He</a>
|
<a href=/people/y/yang-liu-icsi/>Yang Liu</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.32.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--32 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.32 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928999 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.32/>Neural Topic Modeling with Bidirectional Adversarial Training</a></strong><br><a href=/people/r/rui-wang/>Rui Wang</a>
|
<a href=/people/x/xuemeng-hu/>Xuemeng Hu</a>
|
<a href=/people/d/deyu-zhou/>Deyu Zhou</a>
|
<a href=/people/y/yulan-he/>Yulan He</a>
|
<a href=/people/y/yuxuan-xiong/>Yuxuan Xiong</a>
|
<a href=/people/c/chenchen-ye/>Chenchen Ye</a>
|
<a href=/people/h/haiyang-xu/>Haiyang Xu</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--32><div class="card-body p-3 small">Recent years have witnessed a surge of interests of using neural topic models for automatic topic extraction from text, since they avoid the complicated mathematical derivations for <a href=https://en.wikipedia.org/wiki/Statistical_inference>model inference</a> as in traditional <a href=https://en.wikipedia.org/wiki/Topic_model>topic models</a> such as Latent Dirichlet Allocation (LDA). However, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> either typically assume <a href=https://en.wikipedia.org/wiki/Improper_prior>improper prior</a> (e.g. Gaussian or Logistic Normal) over latent topic space or could not infer topic distribution for a given document. To address these limitations, we propose a neural topic modeling approach, called Bidirectional Adversarial Topic (BAT) model, which represents the first attempt of applying bidirectional adversarial training for neural topic modeling. The proposed BAT builds a <a href=https://en.wikipedia.org/wiki/Projection_(linear_algebra)>two-way projection</a> between the document-topic distribution and the document-word distribution. It uses a generator to capture the semantic patterns from texts and an <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> for topic inference. Furthermore, to incorporate word relatedness information, the Bidirectional Adversarial Topic model with Gaussian (Gaussian-BAT) is extended from BAT. To verify the effectiveness of BAT and Gaussian-BAT, three benchmark corpora are used in our experiments. The experimental results show that BAT and Gaussian-BAT obtain more coherent topics, outperforming several competitive baselines. Moreover, when performing text clustering based on the extracted topics, our models outperform all the baselines, with more significant improvements achieved by Gaussian-BAT where an increase of near 6 % is observed in accuracy.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.0/>Findings of the Association for Computational Linguistics: EMNLP 2020</a></strong><br><a href=/people/t/trevor-cohn/>Trevor Cohn</a>
|
<a href=/people/y/yulan-he/>Yulan He</a>
|
<a href=/people/y/yang-liu-icsi/>Yang Liu</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.229.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--229 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.229 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.coling-main.229" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.229/>CHIME : Cross-passage Hierarchical Memory Network for Generative Review Question Answering<span class=acl-fixed-case>CHIME</span>: Cross-passage Hierarchical Memory Network for Generative Review Question Answering</a></strong><br><a href=/people/j/junru-lu/>Junru Lu</a>
|
<a href=/people/g/gabriele-pergola/>Gabriele Pergola</a>
|
<a href=/people/l/lin-gui/>Lin Gui</a>
|
<a href=/people/b/binyang-li/>Binyang Li</a>
|
<a href=/people/y/yulan-he/>Yulan He</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--229><div class="card-body p-3 small">We introduce <a href=https://en.wikipedia.org/wiki/CHIME>CHIME</a>, a cross-passage hierarchical memory network for question answering (QA) via text generation. It extends XLNet introducing an auxiliary memory module consisting of two components : the context memory collecting cross-passage evidences, and the answer memory working as a buffer continually refining the generated answers. Empirically, we show the efficacy of the proposed architecture in the multi-passage generative QA, outperforming the state-of-the-art baselines with better syntactically well-formed answers and increased precision in addressing the questions of the AmazonQA review dataset. An additional qualitative analysis revealed the <a href=https://en.wikipedia.org/wiki/Interpretability>interpretability</a> introduced by the <a href=https://en.wikipedia.org/wiki/Memory_module>memory module</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1350.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1350 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1350 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1350/>Neural Topic Model with <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>Reinforcement Learning</a></a></strong><br><a href=/people/l/lin-gui/>Lin Gui</a>
|
<a href=/people/j/jia-leng/>Jia Leng</a>
|
<a href=/people/g/gabriele-pergola/>Gabriele Pergola</a>
|
<a href=/people/y/yu-zhou/>Yu Zhou</a>
|
<a href=/people/r/ruifeng-xu/>Ruifeng Xu</a>
|
<a href=/people/y/yulan-he/>Yulan He</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1350><div class="card-body p-3 small">In recent years, advances in neural variational inference have achieved many successes in <a href=https://en.wikipedia.org/wiki/Text_processing>text processing</a>. Examples include neural topic models which are typically built upon variational autoencoder (VAE) with an objective of minimising the error of reconstructing original documents based on the learned latent topic vectors. However, minimising reconstruction errors does not necessarily lead to high quality topics. In this paper, we borrow the idea of <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> and incorporate topic coherence measures as reward signals to guide the learning of a VAE-based topic model. Furthermore, our proposed model is able to automatically separating background words dynamically from topic words, thus eliminating the pre-processing step of filtering infrequent and/or top frequent words, typically required for learning traditional topic models. Experimental results on the 20 Newsgroups and the NIPS datasets show superior performance both on perplexity and topic coherence measure compared to state-of-the-art neural topic models.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1379.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1379 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1379 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1379/>An Interpretable Neural Network with Topical Information for Relevant Emotion Ranking</a></strong><br><a href=/people/y/yang-yang/>Yang Yang</a>
|
<a href=/people/d/deyu-zhou/>Deyu Zhou</a>
|
<a href=/people/y/yulan-he/>Yulan He</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1379><div class="card-body p-3 small">Text might express or evoke multiple emotions with varying intensities. As such, it is crucial to predict and rank multiple relevant emotions by their intensities. Moreover, as <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a> might be evoked by hidden topics, it is important to unveil and incorporate such topical information to understand how the <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a> are evoked. We proposed a novel interpretable neural network approach for relevant emotion ranking. Specifically, motivated by <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>, the <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> is initialized to make the hidden layer approximate the behavior of <a href=https://en.wikipedia.org/wiki/Topic_model>topic models</a>. Moreover, a novel <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error function</a> is defined to optimize the whole <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> for relevant emotion ranking. Experimental results on three real-world corpora show that the proposed approach performs remarkably better than the state-of-the-art emotion detection approaches and multi-label learning methods. Moreover, the extracted emotion-associated topic words indeed represent <a href=https://en.wikipedia.org/wiki/Emotion>emotion-evoking events</a> and are in line with our <a href=https://en.wikipedia.org/wiki/Common_sense>common-sense knowledge</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1052.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1052 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1052 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1052/>Relevant Emotion Ranking from Text Constrained with Emotion Relationships</a></strong><br><a href=/people/d/deyu-zhou/>Deyu Zhou</a>
|
<a href=/people/y/yang-yang/>Yang Yang</a>
|
<a href=/people/y/yulan-he/>Yulan He</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1052><div class="card-body p-3 small">Text might contain or invoke multiple emotions with varying intensities. As such, <a href=https://en.wikipedia.org/wiki/Emotion_detection>emotion detection</a>, to predict multiple <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a> associated with a given text, can be cast into a multi-label classification problem. We would like to go one step further so that a ranked list of relevant emotions are generated where top ranked emotions are more intensely associated with text compared to lower ranked emotions, whereas the rankings of irrelevant emotions are not important. A novel framework of relevant emotion ranking is proposed to tackle the <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a>. In the <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a>, the <a href=https://en.wikipedia.org/wiki/Loss_function>objective loss function</a> is designed elaborately so that both emotion prediction and <a href=https://en.wikipedia.org/wiki/Ranking>rankings</a> of only relevant emotions can be achieved. Moreover, we observe that some emotions co-occur more often while other emotions rarely co-exist. Such information is incorporated into the <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> as <a href=https://en.wikipedia.org/wiki/Constraint_(mathematics)>constraints</a> to improve the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of <a href=https://en.wikipedia.org/wiki/Emotion_detection>emotion detection</a>. Experimental results on two real-world corpora show that the proposed framework can effectively deal with <a href=https://en.wikipedia.org/wiki/Emotion_detection>emotion detection</a> and performs remarkably better than the state-of-the-art <a href=https://en.wikipedia.org/wiki/Emotion_detection>emotion detection approaches</a> and multi-label learning methods.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1165.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1165 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1165 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238232359 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D17-1165" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1165/>Detecting Perspectives in Political Debates</a></strong><br><a href=/people/d/david-vilares/>David Vilares</a>
|
<a href=/people/y/yulan-he/>Yulan He</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1165><div class="card-body p-3 small">We explore how to detect people&#8217;s perspectives that occupy a certain proposition. We propose a Bayesian modelling approach where topics (or propositions) and their associated perspectives (or viewpoints) are modeled as <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a>. Words associated with topics or perspectives follow different <a href=https://en.wikipedia.org/wiki/Generative_grammar>generative routes</a>. Based on the extracted perspectives, we can extract the top associated sentences from text to generate a succinct summary which allows a quick glimpse of the main viewpoints in a document. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is evaluated on debates from the House of Commons of the UK Parliament, revealing perspectives from the debates without the use of labelled data and obtaining better results than previous related solutions under a variety of evaluations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-1076.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-1076 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-1076 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-1076/>Event extraction from <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> using Non-Parametric Bayesian Mixture Model with Word Embeddings<span class=acl-fixed-case>T</span>witter using Non-Parametric <span class=acl-fixed-case>B</span>ayesian Mixture Model with Word Embeddings</a></strong><br><a href=/people/d/deyu-zhou/>Deyu Zhou</a>
|
<a href=/people/x/xuan-zhang/>Xuan Zhang</a>
|
<a href=/people/y/yulan-he/>Yulan He</a><br><a href=/volumes/E17-1/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-1076><div class="card-body p-3 small">To extract structured representations of newsworthy events from <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>, <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised models</a> typically assume that tweets involving the same named entities and expressed using similar words are likely to belong to the same event. Hence, they group tweets into clusters based on the <a href=https://en.wikipedia.org/wiki/Co-occurrence>co-occurrence patterns</a> of <a href=https://en.wikipedia.org/wiki/Named_entity>named entities</a> and <a href=https://en.wikipedia.org/wiki/Index_term>topical keywords</a>. However, there are two main limitations. First, they require the number of events to be known beforehand, which is not realistic in practical applications. Second, they do n&#8217;t recognise that the same named entity might be referred to by multiple mentions and tweets using different mentions would be wrongly assigned to different events. To overcome these limitations, we propose a non-parametric Bayesian mixture model with <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> for <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>event extraction</a>, in which the number of events can be inferred automatically and the issue of lexical variations for the same named entity can be dealt with properly. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> has been evaluated on three <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> with sizes ranging between 2,499 and over 60 million tweets. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms the baseline approach on all <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> by 5-8 % in <a href=https://en.wikipedia.org/wiki/F-measure>F-measure</a>.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Yulan+He" title="Search for 'Yulan He' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/d/deyu-zhou/ class=align-middle>Deyu Zhou</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/g/gabriele-pergola/ class=align-middle>Gabriele Pergola</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/l/lin-gui/ class=align-middle>Lin Gui</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/t/trevor-cohn/ class=align-middle>Trevor Cohn</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yang-liu-icsi/ class=align-middle>Yang Liu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/y/yang-yang/ class=align-middle>Yang Yang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/lixing-zhu/ class=align-middle>Lixing Zhu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiasheng-si/ class=align-middle>Jiasheng Si</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tongzhe-li/ class=align-middle>Tongzhe Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xingyu-shi/ class=align-middle>Xingyu Shi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hanqi-yan/ class=align-middle>Hanqi Yan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bonnie-webber/ class=align-middle>Bonnie Webber</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rui-wang/ class=align-middle>Rui Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xuemeng-hu/ class=align-middle>Xuemeng Hu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yuxuan-xiong/ class=align-middle>Yuxuan Xiong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chenchen-ye/ class=align-middle>Chenchen Ye</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haiyang-xu/ class=align-middle>Haiyang Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xingwei-tan/ class=align-middle>Xingwei Tan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jia-leng/ class=align-middle>Jia Leng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yu-zhou/ class=align-middle>Yu Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ruifeng-xu/ class=align-middle>Ruifeng Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/david-vilares/ class=align-middle>David Vilares</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/junru-lu/ class=align-middle>Junru Lu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/binyang-li/ class=align-middle>Binyang Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xuan-zhang/ class=align-middle>Xuan Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>