<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Yuki Arase - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Yuki</span> <span class=font-weight-bold>Arase</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-srw.24.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-srw--24 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-srw.24 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-srw.24/>Edit Distance Based Curriculum Learning for Paraphrase Generation</a></strong><br><a href=/people/s/sora-kadotani/>Sora Kadotani</a>
|
<a href=/people/t/tomoyuki-kajiwara/>Tomoyuki Kajiwara</a>
|
<a href=/people/y/yuki-arase/>Yuki Arase</a>
|
<a href=/people/m/makoto-onizuka/>Makoto Onizuka</a><br><a href=/volumes/2021.acl-srw/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-srw--24><div class="card-body p-3 small">Curriculum learning has improved the quality of <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>, where only source-side features are considered in the <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> to determine the difficulty of <a href=https://en.wikipedia.org/wiki/Translation>translation</a>. In this study, we apply <a href=https://en.wikipedia.org/wiki/Curriculum>curriculum learning</a> to <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a> for the first time. Different from <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a> allows a certain level of discrepancy in <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> between source and target, which results in diverse transformations from <a href=https://en.wikipedia.org/wiki/Lexical_substitution>lexical substitution</a> to reordering of clauses. Hence, the difficulty of transformations requires considering both source and target contexts. Experiments on formality transfer using GYAFC showed that our curriculum learning with <a href=https://en.wikipedia.org/wiki/Edit_distance>edit distance</a> improves the quality of <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a>. Additionally, the proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> improves the quality of difficult samples, which was not possible for previous <a href=https://en.wikipedia.org/wiki/Methodology>methods</a>.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.eamt-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--eamt-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.eamt-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.eamt-1.17/>Fine-Grained Error Analysis on English-to-Japanese Machine Translation in the Medical Domain<span class=acl-fixed-case>E</span>nglish-to-<span class=acl-fixed-case>J</span>apanese Machine Translation in the Medical Domain</a></strong><br><a href=/people/t/takeshi-hayakawa/>Takeshi Hayakawa</a>
|
<a href=/people/y/yuki-arase/>Yuki Arase</a><br><a href=/volumes/2020.eamt-1/ class=text-muted>Proceedings of the 22nd Annual Conference of the European Association for Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--eamt-1--17><div class="card-body p-3 small">We performed a detailed <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error analysis</a> in domain-specific neural machine translation (NMT) for the English and Japanese language pair with fine-grained manual annotation. Despite its importance for advancing NMT technologies, research on the performance of domain-specific NMT and non-European languages has been limited. In this study, we designed an error typology based on the error types that were typically generated by NMT systems and might cause significant impact in technical translations : <a href=https://en.wikipedia.org/wiki/Addition>Addition</a>, Omission, <a href=https://en.wikipedia.org/wiki/Mistranslation>Mistranslation</a>, <a href=https://en.wikipedia.org/wiki/Grammar>Grammar</a>, and <a href=https://en.wikipedia.org/wiki/Terminology>Terminology</a>. The <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error annotation</a> was targeted to the <a href=https://en.wikipedia.org/wiki/Medicine>medical domain</a> and was performed by experienced professional translators specialized in <a href=https://en.wikipedia.org/wiki/Medicine>medicine</a> under careful quality control. The <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a> detected 4,912 errors on 2,480 sentences, and the frequency and distribution of errors were analyzed. We found that the major errors in NMT were <a href=https://en.wikipedia.org/wiki/Mistranslation>Mistranslation</a> and Terminology rather than <a href=https://en.wikipedia.org/wiki/Addition>Addition</a> and Omission, which have been reported as typical problems of NMT. Interestingly, more errors occurred in documents for professionals compared with those for the general public. The results of our annotation work will be published as a parallel corpus with error labels, which are expected to contribute to developing better NMT models, automatic evaluation metrics, and quality estimation models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.aacl-srw.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--aacl-srw--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.aacl-srw.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.aacl-srw.22/>Text Simplification with <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>Reinforcement Learning</a> Using <a href=https://en.wikipedia.org/wiki/Supervised_learning>Supervised Rewards</a> on <a href=https://en.wikipedia.org/wiki/Grammaticality>Grammaticality</a>, Meaning Preservation, and <a href=https://en.wikipedia.org/wiki/Simplicity>Simplicity</a></a></strong><br><a href=/people/a/akifumi-nakamachi/>Akifumi Nakamachi</a>
|
<a href=/people/t/tomoyuki-kajiwara/>Tomoyuki Kajiwara</a>
|
<a href=/people/y/yuki-arase/>Yuki Arase</a><br><a href=/volumes/2020.aacl-srw/ class=text-muted>Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing: Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--aacl-srw--22><div class="card-body p-3 small">We optimize rewards of <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> in <a href=https://en.wikipedia.org/wiki/Text_simplification>text simplification</a> using <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> that are highly correlated with human-perspectives. To address problems of <a href=https://en.wikipedia.org/wiki/Exposure_bias>exposure bias</a> and loss-evaluation mismatch, text-to-text generation tasks employ <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> that rewards task-specific metrics. Previous studies in <a href=https://en.wikipedia.org/wiki/Text_simplification>text simplification</a> employ the weighted sum of sub-rewards from three perspectives : <a href=https://en.wikipedia.org/wiki/Grammaticality>grammaticality</a>, meaning preservation, and <a href=https://en.wikipedia.org/wiki/Simplicity>simplicity</a>. However, the previous rewards do not align with <a href=https://en.wikipedia.org/wiki/Human_psychology>human-perspectives</a> for these <a href=https://en.wikipedia.org/wiki/Point_of_view_(philosophy)>perspectives</a>. In this study, we propose to use BERT regressors fine-tuned for <a href=https://en.wikipedia.org/wiki/Grammaticality>grammaticality</a>, meaning preservation, and <a href=https://en.wikipedia.org/wiki/Simplicity>simplicity</a> as reward estimators to achieve text simplification conforming to human-perspectives. Experimental results show that <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> with our <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>rewards</a> balances meaning preservation and <a href=https://en.wikipedia.org/wiki/Simplicity>simplicity</a>. Additionally, human evaluation confirmed that simplified texts by our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> are preferred by humans compared to previous studies.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1542.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1542 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1542 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1542/>Transfer Fine-Tuning : A BERT Case Study<span class=acl-fixed-case>BERT</span> Case Study</a></strong><br><a href=/people/y/yuki-arase/>Yuki Arase</a>
|
<a href=/people/j/junichi-tsujii/>Jun’ichi Tsujii</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1542><div class="card-body p-3 small">A semantic equivalence assessment is defined as a task that assesses <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic equivalence</a> in a sentence pair by binary judgment (i.e., paraphrase identification) or grading (i.e., semantic textual similarity measurement). It constitutes a set of <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> crucial for research on <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a>. Recently, BERT realized a breakthrough in sentence representation learning (Devlin et al., 2019), which is broadly transferable to various NLP tasks. While <a href=https://en.wikipedia.org/wiki/BERT>BERT</a>&#8217;s performance improves by increasing its model size, the required <a href=https://en.wikipedia.org/wiki/Computational_power>computational power</a> is an obstacle preventing practical applications from adopting the <a href=https://en.wikipedia.org/wiki/Technology>technology</a>. Herein, we propose to inject phrasal paraphrase relations into BERT in order to generate suitable representations for semantic equivalence assessment instead of increasing the model size. Experiments on standard natural language understanding tasks confirm that our method effectively improves a smaller BERT model while maintaining the model size. The generated <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> exhibits superior performance compared to a larger BERT model on semantic equivalence assessment tasks. Furthermore, it achieves larger performance gains on tasks with limited training datasets for <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a>, which is a property desirable for <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5552.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5552 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5552 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5552/>Contextualized context2vec</a></strong><br><a href=/people/k/kazuki-ashihara/>Kazuki Ashihara</a>
|
<a href=/people/t/tomoyuki-kajiwara/>Tomoyuki Kajiwara</a>
|
<a href=/people/y/yuki-arase/>Yuki Arase</a>
|
<a href=/people/s/satoru-uchida/>Satoru Uchida</a><br><a href=/volumes/D19-55/ class=text-muted>Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5552><div class="card-body p-3 small">Lexical substitution ranks substitution candidates from the viewpoint of paraphrasability for a target word in a given sentence. There are two major approaches for <a href=https://en.wikipedia.org/wiki/Lexical_substitution>lexical substitution</a> : (1) generating contextualized word embeddings by assigning multiple embeddings to one word and (2) generating context embeddings using the sentence. Herein we propose a method that combines these two approaches to contextualize word embeddings for <a href=https://en.wikipedia.org/wiki/Lexical_substitution>lexical substitution</a>. Experiments demonstrate that our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> outperforms the current state-of-the-art method. We also create CEFR-LP, a new evaluation dataset for the lexical substitution task. It has a wider coverage of substitution candidates than previous <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> and assigns <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>English proficiency levels</a> to all target words and substitution candidates.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4115.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4115 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4115 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4115/>Relevant and Informative Response Generation using <a href=https://en.wikipedia.org/wiki/Pointwise_mutual_information>Pointwise Mutual Information</a></a></strong><br><a href=/people/j/junya-takayama/>Junya Takayama</a>
|
<a href=/people/y/yuki-arase/>Yuki Arase</a><br><a href=/volumes/W19-41/ class=text-muted>Proceedings of the First Workshop on NLP for Conversational AI</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4115><div class="card-body p-3 small">A sequence-to-sequence model tends to generate generic responses with little information for input utterances. To solve this problem, we propose a neural model that generates relevant and informative responses. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> has simple architecture to enable easy application to existing neural dialogue models. Specifically, using positive pointwise mutual information, it first identifies <a href=https://en.wikipedia.org/wiki/Index_term>keywords</a> that frequently co-occur in responses given an utterance. Then, the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> encourages the <a href=https://en.wikipedia.org/wiki/Codec>decoder</a> to use the <a href=https://en.wikipedia.org/wiki/Index_term>keywords</a> for response generation. Experiment results demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> successfully diversifies responses relative to previous <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4116.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4116 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4116 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-4116" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-4116/>Responsive and Self-Expressive Dialogue Generation</a></strong><br><a href=/people/k/kozo-chikai/>Kozo Chikai</a>
|
<a href=/people/j/junya-takayama/>Junya Takayama</a>
|
<a href=/people/y/yuki-arase/>Yuki Arase</a><br><a href=/volumes/W19-41/ class=text-muted>Proceedings of the First Workshop on NLP for Conversational AI</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4116><div class="card-body p-3 small">A neural conversation model is a promising approach to develop dialogue systems with the ability of <a href=https://en.wikipedia.org/wiki/Chit-chat>chit-chat</a>. It allows training a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in an end-to-end manner without complex rule design nor <a href=https://en.wikipedia.org/wiki/Feature_engineering>feature engineering</a>. However, as a side effect, the neural model tends to generate safe but uninformative and insensitive responses like OK and I do n&#8217;t know. Such replies are called generic responses and regarded as a critical problem for user-engagement of dialogue systems. For a more engaging chit-chat experience, we propose a neural conversation model that generates responsive and self-expressive replies. Specifically, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> generates domain-aware and sentiment-rich responses. Experiments empirically confirmed that our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> outperformed the sequence-to-sequence model ; 68.1 % of our responses were domain-aware with <a href=https://en.wikipedia.org/wiki/Sentimentality>sentiment polarities</a>, which was only 2.7 % for responses generated by the sequence-to-sequence model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-2027.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-2027 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-2027 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-2027/>Dialogue-Act Prediction of Future Responses Based on Conversation History</a></strong><br><a href=/people/k/koji-tanaka/>Koji Tanaka</a>
|
<a href=/people/j/junya-takayama/>Junya Takayama</a>
|
<a href=/people/y/yuki-arase/>Yuki Arase</a><br><a href=/volumes/P19-2/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-2027><div class="card-body p-3 small">Sequence-to-sequence models are a common approach to develop a <a href=https://en.wikipedia.org/wiki/Chatbot>chatbot</a>. They can train a <a href=https://en.wikipedia.org/wiki/Conversational_model>conversational model</a> in an end-to-end manner. One significant drawback of such a neural network based approach is that the response generation process is a black-box, and how a specific response is generated is unclear. To tackle this problem, an interpretable response generation mechanism is desired. As a step toward this direction, we focus on dialogue-acts (DAs) that may provide insight to understand the response generation process. In particular, we propose a method to predict a DA of the next response based on the history of previous utterances and their DAs. Experiments using a Switch Board Dialogue Act corpus show that compared to the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> considering only a single utterance, our <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> achieves 10.8 % higher <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> and 3.0 % higher <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on DA prediction.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1001 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D17-1001.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238234373 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1001/>Monolingual Phrase Alignment on Parse Forests</a></strong><br><a href=/people/y/yuki-arase/>Yuki Arase</a>
|
<a href=/people/j/junichi-tsujii/>Junichi Tsujii</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1001><div class="card-body p-3 small">We propose an efficient method to conduct phrase alignment on <a href=https://en.wikipedia.org/wiki/Parse_forest>parse forests</a> for <a href=https://en.wikipedia.org/wiki/Paraphrase_detection>paraphrase detection</a>. Unlike previous studies, our method identifies syntactic paraphrases under linguistically motivated grammar. In addition, it allows phrases to non-compositionally align to handle <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrases</a> with non-homographic phrase correspondences. A <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> that provides gold parse trees and their phrase alignments is created. The experimental results confirm that the proposed method conducts highly accurate phrase alignment compared to human performance.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Yuki+Arase" title="Search for 'Yuki Arase' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/t/tomoyuki-kajiwara/ class=align-middle>Tomoyuki Kajiwara</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/junya-takayama/ class=align-middle>Junya Takayama</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/junichi-tsujii/ class=align-middle>Jun’ichi Tsujii</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/takeshi-hayakawa/ class=align-middle>Takeshi Hayakawa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sora-kadotani/ class=align-middle>Sora Kadotani</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/m/makoto-onizuka/ class=align-middle>Makoto Onizuka</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/akifumi-nakamachi/ class=align-middle>Akifumi Nakamachi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kazuki-ashihara/ class=align-middle>Kazuki Ashihara</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/satoru-uchida/ class=align-middle>Satoru Uchida</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kozo-chikai/ class=align-middle>Kozo Chikai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/koji-tanaka/ class=align-middle>Koji Tanaka</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/eamt/ class=align-middle>EAMT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/aacl/ class=align-middle>AACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>