<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Yi Tay - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Yi</span> <span class=font-weight-bold>Tay</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.465.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--465 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.465 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.465" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.465/>Do Transformer Modifications Transfer Across Implementations and Applications?</a></strong><br><a href=/people/s/sharan-narang/>Sharan Narang</a>
|
<a href=/people/h/hyung-won-chung/>Hyung Won Chung</a>
|
<a href=/people/y/yi-tay/>Yi Tay</a>
|
<a href=/people/l/liam-fedus/>Liam Fedus</a>
|
<a href=/people/t/thibault-fevry/>Thibault Fevry</a>
|
<a href=/people/m/michael-matena/>Michael Matena</a>
|
<a href=/people/k/karishma-malkan/>Karishma Malkan</a>
|
<a href=/people/n/noah-fiedel/>Noah Fiedel</a>
|
<a href=/people/n/noam-shazeer/>Noam Shazeer</a>
|
<a href=/people/z/zhenzhong-lan/>Zhenzhong Lan</a>
|
<a href=/people/y/yanqi-zhou/>Yanqi Zhou</a>
|
<a href=/people/w/wei-li/>Wei Li</a>
|
<a href=/people/n/nan-ding/>Nan Ding</a>
|
<a href=/people/j/jake-marcus/>Jake Marcus</a>
|
<a href=/people/a/adam-roberts/>Adam Roberts</a>
|
<a href=/people/c/colin-raffel/>Colin Raffel</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--465><div class="card-body p-3 small">The research community has proposed copious modifications to the Transformer architecture since it was introduced over three years ago, relatively few of which have seen widespread adoption. In this paper, we comprehensively evaluate many of these modifications in a shared experimental setting that covers most of the common uses of the Transformer in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. Surprisingly, we find that most <a href=https://en.wikipedia.org/wiki/Mod_(video_gaming)>modifications</a> do not meaningfully improve performance. Furthermore, most of the Transformer variants we found beneficial were either developed in the same <a href=https://en.wikipedia.org/wiki/Codebase>codebase</a> that we used or are relatively minor changes. We conjecture that performance improvements may strongly depend on implementation details and correspondingly make some recommendations for improving the generality of experimental results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.1/>Knowledge Router : Learning Disentangled Representations for Knowledge Graphs</a></strong><br><a href=/people/s/shuai-zhang/>Shuai Zhang</a>
|
<a href=/people/x/xi-rao/>Xi Rao</a>
|
<a href=/people/y/yi-tay/>Yi Tay</a>
|
<a href=/people/c/ce-zhang/>Ce Zhang</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--1><div class="card-body p-3 small">The design of expressive representations of entities and relations in a <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graph</a> is an important endeavor. While many of the existing approaches have primarily focused on learning from relational patterns and structural information, the intrinsic <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a> of KG entities has been more or less overlooked. More concretely, we hypothesize KG entities may be more complex than we think, i.e., an entity may wear many hats and relational triplets may form due to more than a single reason. To this end, this paper proposes to learn disentangled representations of KG entities-a new method that disentangles the inner latent properties of KG entities. Our disentangled process operates at the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph level</a> and a neighborhood mechanism is leveraged to disentangle the hidden properties of each entity. This disentangled representation learning approach is model agnostic and compatible with canonical KG embedding approaches. We conduct extensive experiments on several benchmark datasets, equipping a variety of models (DistMult, SimplE, and QuatE) with our proposed disentangling mechanism. Experimental results demonstrate that our proposed approach substantially improves performance on key metrics.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.25.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--25 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.25 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929268 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.25/>Reverse Engineering Configurations of Neural Text Generation Models</a></strong><br><a href=/people/y/yi-tay/>Yi Tay</a>
|
<a href=/people/d/dara-bahri/>Dara Bahri</a>
|
<a href=/people/c/che-zheng/>Che Zheng</a>
|
<a href=/people/c/clifford-brunk/>Clifford Brunk</a>
|
<a href=/people/d/donald-metzler/>Donald Metzler</a>
|
<a href=/people/a/andrew-tomkins/>Andrew Tomkins</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--25><div class="card-body p-3 small">Recent advances in neural text generation modeling have resulted in a number of societal concerns related to how such approaches might be used in malicious ways. It is therefore desirable to develop a deeper understanding of the fundamental properties of such <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. The study of artifacts that emerge in machine generated text as a result of modeling choices is a nascent research area. To this end, the extent and degree to which these artifacts surface in generated text is still unclear. In the spirit of better understanding generative text models and their artifacts, we propose the new task of distinguishing which of several variants of a given <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> generated some piece of text. Specifically, we conduct an extensive suite of <a href=https://en.wikipedia.org/wiki/Statistical_hypothesis_testing>diagnostic tests</a> to observe whether <a href=https://en.wikipedia.org/wiki/Statistical_model>modeling choices</a> (e.g., <a href=https://en.wikipedia.org/wiki/Sampling_(statistics)>sampling methods</a>, top-k probabilities, <a href=https://en.wikipedia.org/wiki/Computer_simulation>model architectures</a>, etc.) leave detectable artifacts in the text they generate. Our key finding, which is backed by a rigorous set of experiments, is that such artifacts are present and that different modeling choices can be inferred by looking at generated text alone. This suggests that neural text generators may actually be more sensitive to various modeling choices than previously thought.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.373.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--373 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.373 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940808 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.findings-emnlp.373" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.373/>Poison Attacks against Text Datasets with Conditional Adversarially Regularized Autoencoder</a></strong><br><a href=/people/a/alvin-chan/>Alvin Chan</a>
|
<a href=/people/y/yi-tay/>Yi Tay</a>
|
<a href=/people/y/yew-soon-ong/>Yew-Soon Ong</a>
|
<a href=/people/a/aston-zhang/>Aston Zhang</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--373><div class="card-body p-3 small">This paper demonstrates a fatal vulnerability in natural language inference (NLI) and text classification systems. More concretely, we present a &#8216;backdoor poisoning&#8217; attack on <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP models</a>. Our poisoning attack utilizes conditional adversarially regularized autoencoder (CARA) to generate poisoned training samples by poison injection in latent space. Just by adding 1 % poisoned data, our experiments show that a victim BERT finetuned classifier&#8217;s predictions can be steered to the poison target class with success rates of > 80 % when the input hypothesis is injected with the poison signature, demonstrating that NLI and text classification systems face a huge security risk.<tex-math>>80\\%</tex-math> when the input hypothesis is injected with the poison signature, demonstrating that NLI and text classification systems face a huge security risk.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1540.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1540 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1540 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1540/>Bridging the Gap between Relevance Matching and <a href=https://en.wikipedia.org/wiki/Semantic_matching>Semantic Matching</a> for Short Text Similarity Modeling</a></strong><br><a href=/people/j/jinfeng-rao/>Jinfeng Rao</a>
|
<a href=/people/l/linqing-liu/>Linqing Liu</a>
|
<a href=/people/y/yi-tay/>Yi Tay</a>
|
<a href=/people/w/wei-yang/>Wei Yang</a>
|
<a href=/people/p/peng-shi/>Peng Shi</a>
|
<a href=/people/j/jimmy-lin/>Jimmy Lin</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1540><div class="card-body p-3 small">A core problem of information retrieval (IR) is relevance matching, which is to rank documents by relevance to a user&#8217;s query. On the other hand, many NLP problems, such as <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> and paraphrase identification, can be considered variants of <a href=https://en.wikipedia.org/wiki/Semantic_matching>semantic matching</a>, which is to measure the <a href=https://en.wikipedia.org/wiki/Semantic_distance>semantic distance</a> between two pieces of short texts. While at a high level both <a href=https://en.wikipedia.org/wiki/Relevance_(information_retrieval)>relevance</a> and <a href=https://en.wikipedia.org/wiki/Semantic_matching>semantic matching</a> require modeling textual similarity, many existing techniques for one can not be easily adapted to the other. To bridge this gap, we propose a novel model, HCAN (Hybrid Co-Attention Network), that comprises (1) a hybrid encoder module that includes ConvNet-based and LSTM-based encoders, (2) a relevance matching module that measures soft term matches with importance weighting at multiple granularities, and (3) a semantic matching module with co-attention mechanisms that capture context-aware semantic relatedness. Evaluations on multiple IR and NLP benchmarks demonstrate state-of-the-art effectiveness compared to approaches that do not exploit pretraining on external data. Extensive ablation studies suggest that relevance and semantic matching signals are complementary across many problem settings, regardless of the choice of underlying <a href=https://en.wikipedia.org/wiki/Encoder>encoders</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1317.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1317 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1317 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1317/>Robust Representation Learning of Biomedical Names</a></strong><br><a href=/people/m/minh-c-phan/>Minh C. Phan</a>
|
<a href=/people/a/aixin-sun/>Aixin Sun</a>
|
<a href=/people/y/yi-tay/>Yi Tay</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1317><div class="card-body p-3 small">Biomedical concepts are often mentioned in <a href=https://en.wikipedia.org/wiki/Medical_record>medical documents</a> under different name variations (synonyms). This mismatch between surface forms is problematic, resulting in difficulties pertaining to learning effective <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a>. Consequently, this has tremendous implications such as rendering downstream applications inefficacious and/or potentially unreliable. This paper proposes a new <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> for learning robust representations of biomedical names and terms. The idea behind our approach is to consider and encode <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual meaning</a>, conceptual meaning, and the <a href=https://en.wikipedia.org/wiki/Synonym>similarity between synonyms</a> during the representation learning process. Via extensive experiments, we show that our proposed method outperforms other baselines on a battery of retrieval, similarity and relatedness benchmarks. Moreover, our proposed method is also able to compute meaningful representations for unseen names, resulting in high practical utility in real-world applications.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1238.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1238 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1238 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1238/>Multi-Granular Sequence Encoding via Dilated Compositional Units for Reading Comprehension</a></strong><br><a href=/people/y/yi-tay/>Yi Tay</a>
|
<a href=/people/a/anh-tuan-luu/>Anh Tuan Luu</a>
|
<a href=/people/s/siu-cheung-hui/>Siu Cheung Hui</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1238><div class="card-body p-3 small">Sequence encoders are crucial components in many neural architectures for learning to read and comprehend. This paper presents a new compositional encoder for reading comprehension (RC). Our proposed <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> is not only aimed at being fast but also expressive. Specifically, the key novelty behind our <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> is that it explicitly models across multiple granularities using a new dilated composition mechanism. In our approach, gating functions are learned by modeling relationships and reasoning over multi-granular sequence information, enabling compositional learning that is aware of both long and short term information. We conduct experiments on three RC datasets, showing that our proposed <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> demonstrates very promising results both as a standalone encoder as well as a complementary building block. Empirical results show that simple Bi-Attentive architectures augmented with our proposed <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> not only achieves state-of-the-art / highly competitive results but is also considerably faster than other published works.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1381.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1381 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1381 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1381/>Attentive Gated Lexicon Reader with Contrastive Contextual Co-Attention for Sentiment Classification</a></strong><br><a href=/people/y/yi-tay/>Yi Tay</a>
|
<a href=/people/a/anh-tuan-luu/>Anh Tuan Luu</a>
|
<a href=/people/s/siu-cheung-hui/>Siu Cheung Hui</a>
|
<a href=/people/j/jian-su/>Jian Su</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1381><div class="card-body p-3 small">This paper proposes a new neural architecture that exploits readily available sentiment lexicon resources. The key idea is that that incorporating a word-level prior can aid in the representation learning process, eventually improving <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performance. To this end, our model employs two distinctly unique components, i.e., (1) we introduce a lexicon-driven contextual attention mechanism to imbue lexicon words with long-range contextual information and (2), we introduce a contrastive co-attention mechanism that models contrasting polarities between all positive and negative words in a sentence. Via extensive experiments, we show that our approach outperforms many other neural baselines on sentiment classification tasks on multiple benchmark datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1479.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1479 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1479 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1479/>Co-Stack Residual Affinity Networks with Multi-level Attention Refinement for Matching Text Sequences</a></strong><br><a href=/people/y/yi-tay/>Yi Tay</a>
|
<a href=/people/a/anh-tuan-luu/>Anh Tuan Luu</a>
|
<a href=/people/s/siu-cheung-hui/>Siu Cheung Hui</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1479><div class="card-body p-3 small">Learning a <a href=https://en.wikipedia.org/wiki/Matching_function>matching function</a> between two text sequences is a long standing problem in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP research</a>. This <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> enables many potential <a href=https://en.wikipedia.org/wiki/Application_software>applications</a> such as <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> and paraphrase identification. This paper proposes Co-Stack Residual Affinity Networks (CSRAN), a new and universal neural architecture for this problem. CSRAN is a deep architecture, involving stacked (multi-layered) recurrent encoders. Stacked / Deep architectures are traditionally difficult to train, due to the inherent weaknesses such as difficulty with feature propagation and <a href=https://en.wikipedia.org/wiki/Vanishing_gradient>vanishing gradients</a>. CSRAN incorporates two novel <a href=https://en.wikipedia.org/wiki/Component-based_software_engineering>components</a> to take advantage of the stacked architecture. Firstly, it introduces a new bidirectional alignment mechanism that learns <a href=https://en.wikipedia.org/wiki/Ligand_(biochemistry)>affinity weights</a> by fusing sequence pairs across stacked hierarchies. Secondly, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> leverages a multi-level attention refinement component between stacked recurrent layers. The key intuition is that, by leveraging information across all <a href=https://en.wikipedia.org/wiki/Hierarchy>network hierarchies</a>, we can not only improve <a href=https://en.wikipedia.org/wiki/Gradient_flow>gradient flow</a> but also improve overall performance. We conduct extensive experiments on six well-studied text sequence matching datasets, achieving state-of-the-art performance on all.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Yi+Tay" title="Search for 'Yi Tay' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/a/anh-tuan-luu/ class=align-middle>Anh Tuan Luu</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/siu-cheung-hui/ class=align-middle>Siu Cheung Hui</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/d/dara-bahri/ class=align-middle>Dara Bahri</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/che-zheng/ class=align-middle>Che Zheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/clifford-brunk/ class=align-middle>Clifford Brunk</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/d/donald-metzler/ class=align-middle>Donald Metzler</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrew-tomkins/ class=align-middle>Andrew Tomkins</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jian-su/ class=align-middle>Jian Su</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sharan-narang/ class=align-middle>Sharan Narang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hyung-won-chung/ class=align-middle>Hyung Won Chung</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/liam-fedus/ class=align-middle>Liam Fedus</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thibault-fevry/ class=align-middle>Thibault Févry</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-matena/ class=align-middle>Michael Matena</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/karishma-malkan/ class=align-middle>Karishma Malkan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/noah-fiedel/ class=align-middle>Noah Fiedel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/noam-shazeer/ class=align-middle>Noam Shazeer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhenzhong-lan/ class=align-middle>Zhenzhong Lan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yanqi-zhou/ class=align-middle>Yanqi Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wei-li/ class=align-middle>Wei Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nan-ding/ class=align-middle>Nan Ding</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jake-marcus/ class=align-middle>Jake Marcus</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/adam-roberts/ class=align-middle>Adam Roberts</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/colin-raffel/ class=align-middle>Colin Raffel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jinfeng-rao/ class=align-middle>Jinfeng Rao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/linqing-liu/ class=align-middle>Linqing Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wei-yang/ class=align-middle>Wei Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/peng-shi/ class=align-middle>Peng Shi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jimmy-lin/ class=align-middle>Jimmy Lin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shuai-zhang/ class=align-middle>Shuai Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xi-rao/ class=align-middle>Xi Rao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/ce-zhang/ class=align-middle>Ce Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alvin-chan/ class=align-middle>Alvin Chan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yew-soon-ong/ class=align-middle>Yew-Soon Ong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aston-zhang/ class=align-middle>Aston Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/minh-c-phan/ class=align-middle>Minh C. Phan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aixin-sun/ class=align-middle>Aixin Sun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>