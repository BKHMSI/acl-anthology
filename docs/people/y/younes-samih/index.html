<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Younes Samih - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Younes</span> <span class=font-weight-bold>Samih</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-main.227.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-main--227 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-main.227 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.eacl-main.227.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.eacl-main.227/>A Few Topical Tweets are Enough for Effective User Stance Detection</a></strong><br><a href=/people/y/younes-samih/>Younes Samih</a>
|
<a href=/people/k/kareem-darwish/>Kareem Darwish</a><br><a href=/volumes/2021.eacl-main/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-main--227><div class="card-body p-3 small">User stance detection entails ascertaining the position of a user towards a target, such as an entity, topic, or claim. Recent work that employs <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised classification</a> has shown that performing stance detection on vocal Twitter users, who have many tweets on a target, can be highly accurate (+98 %). However, such methods perform poorly or fail completely for less vocal users, who may have authored only a few tweets about a target. In this paper, we tackle stance detection for such <a href=https://en.wikipedia.org/wiki/User_(computing)>users</a> using two approaches. In the first approach, we improve user-level stance detection by representing tweets using contextualized embeddings, which capture latent meanings of words in context. We show that this approach outperforms two strong baselines and achieves 89.6 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and 91.3 % macro F-measure on eight controversial topics. In the second approach, we expand the tweets of a given user using their Twitter timeline tweets, which may not be topically relevant, and then we perform <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised classification</a> of the user, which entails clustering a user with other users in the training set. This approach achieves 95.6 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and 93.1 % <a href=https://en.wikipedia.org/wiki/F-measure>macro F-measure</a>.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.osact-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--osact-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.osact-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.osact-1.9/>ALT Submission for OSACT Shared Task on Offensive Language Detection<span class=acl-fixed-case>ALT</span> Submission for <span class=acl-fixed-case>OSACT</span> Shared Task on Offensive Language Detection</a></strong><br><a href=/people/s/sabit-hassan/>Sabit Hassan</a>
|
<a href=/people/y/younes-samih/>Younes Samih</a>
|
<a href=/people/h/hamdy-mubarak/>Hamdy Mubarak</a>
|
<a href=/people/a/ahmed-abdelali/>Ahmed Abdelali</a>
|
<a href=/people/a/ammar-rashed/>Ammar Rashed</a>
|
<a href=/people/s/shammur-absar-chowdhury/>Shammur Absar Chowdhury</a><br><a href=/volumes/2020.osact-1/ class=text-muted>Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--osact-1--9><div class="card-body p-3 small">In this paper, we describe our efforts at OSACT Shared Task on Offensive Language Detection. The shared <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a> consists of two subtasks : offensive language detection (Subtask A) and hate speech detection (Subtask B). For offensive language detection, a system combination of Support Vector Machines (SVMs) and <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Neural Networks (DNNs)</a> achieved the best results on development set, which ranked 1st in the official results for Subtask A with F1-score of 90.51 % on the test set. For hate speech detection, DNNs were less effective and a system combination of multiple SVMs with different parameters achieved the best results on development set, which ranked 4th in official results for Subtask B with F1-macro score of 80.63 % on the test set.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4603.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4603 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4603 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4603/>POS Tagging for Improving Code-Switching Identification in Arabic<span class=acl-fixed-case>POS</span> Tagging for Improving Code-Switching Identification in <span class=acl-fixed-case>A</span>rabic</a></strong><br><a href=/people/m/mohammed-attia/>Mohammed Attia</a>
|
<a href=/people/y/younes-samih/>Younes Samih</a>
|
<a href=/people/a/ali-elkahky/>Ali Elkahky</a>
|
<a href=/people/h/hamdy-mubarak/>Hamdy Mubarak</a>
|
<a href=/people/a/ahmed-abdelali/>Ahmed Abdelali</a>
|
<a href=/people/k/kareem-darwish/>Kareem Darwish</a><br><a href=/volumes/W19-46/ class=text-muted>Proceedings of the Fourth Arabic Natural Language Processing Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4603><div class="card-body p-3 small">When speakers code-switch between their native language and a second language or language variant, they follow a syntactic pattern where words and phrases from the embedded language are inserted into the matrix language. This paper explores the possibility of utilizing this pattern in improving code-switching identification between <a href=https://en.wikipedia.org/wiki/Modern_Standard_Arabic>Modern Standard Arabic (MSA)</a> and <a href=https://en.wikipedia.org/wiki/Egyptian_Arabic>Egyptian Arabic (EA)</a>. We try to answer the question of how strong is the POS signal in word-level code-switching identification. We build a deep learning model enriched with linguistic features (including POS tags) that outperforms the state-of-the-art results by 1.9 % on the development set and 1.0 % on the test set. We also show that in intra-sentential code-switching, the selection of lexical items is constrained by POS categories, where function words tend to come more often from the <a href=https://en.wikipedia.org/wiki/Dialect>dialectal language</a> while the majority of content words come from the <a href=https://en.wikipedia.org/wiki/Standard_language>standard language</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4639.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4639 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4639 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4639/>QC-GO Submission for MADAR Shared Task : Arabic Fine-Grained Dialect Identification<span class=acl-fixed-case>QC</span>-<span class=acl-fixed-case>GO</span> Submission for <span class=acl-fixed-case>MADAR</span> Shared Task: <span class=acl-fixed-case>A</span>rabic Fine-Grained Dialect Identification</a></strong><br><a href=/people/y/younes-samih/>Younes Samih</a>
|
<a href=/people/h/hamdy-mubarak/>Hamdy Mubarak</a>
|
<a href=/people/a/ahmed-abdelali/>Ahmed Abdelali</a>
|
<a href=/people/m/mohammed-attia/>Mohammed Attia</a>
|
<a href=/people/m/mohamed-eldesouki/>Mohamed Eldesouki</a>
|
<a href=/people/k/kareem-darwish/>Kareem Darwish</a><br><a href=/volumes/W19-46/ class=text-muted>Proceedings of the Fourth Arabic Natural Language Processing Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4639><div class="card-body p-3 small">This paper describes the QC-GO team submission to the MADAR Shared Task Subtask 1 (travel domain dialect identification) and Subtask 2 (Twitter user location identification). In our participation in both subtasks, we explored a number of approaches and system combinations to obtain the best performance for both tasks. These include <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural nets</a> and <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a>. Since individual <a href=https://en.wikipedia.org/wiki/Methodology>approaches</a> suffer from various shortcomings, the combination of different approaches was able to fill some of these gaps. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves F1-Scores of 66.1 % and 67.0 % on the development sets for Subtasks 1 and 2 respectively.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3212.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3212 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3212 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3212/>GHHT at CALCS 2018 : Named Entity Recognition for Dialectal Arabic Using Neural Networks<span class=acl-fixed-case>GHHT</span> at <span class=acl-fixed-case>CALCS</span> 2018: Named Entity Recognition for Dialectal <span class=acl-fixed-case>A</span>rabic Using Neural Networks</a></strong><br><a href=/people/m/mohammed-attia/>Mohammed Attia</a>
|
<a href=/people/y/younes-samih/>Younes Samih</a>
|
<a href=/people/w/wolfgang-maier/>Wolfgang Maier</a><br><a href=/volumes/W18-32/ class=text-muted>Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3212><div class="card-body p-3 small">This paper describes our system submission to the CALCS 2018 shared task on <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a> on code-switched data for the language variant pair of <a href=https://en.wikipedia.org/wiki/Modern_Standard_Arabic>Modern Standard Arabic</a> and <a href=https://en.wikipedia.org/wiki/Egyptian_Arabic>Egyptian dialectal Arabic</a>. We build a a <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Neural Network</a> that combines word and character-based representations in convolutional and recurrent networks with a CRF layer. The model is augmented with stacked layers of enriched information such pre-trained embeddings, Brown clusters and <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity gazetteers</a>. Our <a href=https://en.wikipedia.org/wiki/System>system</a> is ranked second among those participating in the shared task achieving an FB1 average of 70.09 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-4929.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-4929 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-4929 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-4929/>Mumpitz at PARSEME Shared Task 2018 : A Bidirectional LSTM for the Identification of Verbal Multiword Expressions<span class=acl-fixed-case>M</span>umpitz at <span class=acl-fixed-case>PARSEME</span> Shared Task 2018: A Bidirectional <span class=acl-fixed-case>LSTM</span> for the Identification of Verbal Multiword Expressions</a></strong><br><a href=/people/r/rafael-ehren/>Rafael Ehren</a>
|
<a href=/people/t/timm-lichte/>Timm Lichte</a>
|
<a href=/people/y/younes-samih/>Younes Samih</a><br><a href=/volumes/W18-49/ class=text-muted>Proceedings of the Joint Workshop on Linguistic Annotation, Multiword Expressions and Constructions (LAW-MWE-CxG-2018)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-4929><div class="card-body p-3 small">In this paper, we describe Mumpitz, the system we submitted to the PARSEME Shared task on automatic identification of verbal multiword expressions (VMWEs). Mumpitz consists of a Bidirectional Recurrent Neural Network (BRNN) with Long Short-Term Memory (LSTM) units and a <a href=https://en.wikipedia.org/wiki/Heuristic>heuristic</a> that leverages the dependency information provided in the PARSEME corpus data to differentiate VMWEs in a sentence. We submitted results for seven languages in the closed track of the task and for one language in the open track. For the open track we used the same <a href=https://en.wikipedia.org/wiki/System>system</a>, but with pretrained instead of randomly initialized word embeddings to improve the <a href=https://en.wikipedia.org/wiki/System>system</a> performance.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-1043.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-1043 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-1043 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-1043/>Learning from Relatives : Unified Dialectal Arabic Segmentation<span class=acl-fixed-case>A</span>rabic Segmentation</a></strong><br><a href=/people/y/younes-samih/>Younes Samih</a>
|
<a href=/people/m/mohamed-eldesouki/>Mohamed Eldesouki</a>
|
<a href=/people/m/mohammed-attia/>Mohammed Attia</a>
|
<a href=/people/k/kareem-darwish/>Kareem Darwish</a>
|
<a href=/people/a/ahmed-abdelali/>Ahmed Abdelali</a>
|
<a href=/people/h/hamdy-mubarak/>Hamdy Mubarak</a>
|
<a href=/people/l/laura-kallmeyer/>Laura Kallmeyer</a><br><a href=/volumes/K17-1/ class=text-muted>Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-1043><div class="card-body p-3 small">Arabic dialects do not just share a common koin, but there are shared pan-dialectal linguistic phenomena that allow <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational models</a> for <a href=https://en.wikipedia.org/wiki/Dialect>dialects</a> to learn from each other. In this paper we build a unified segmentation model where the training data for different dialects are combined and a single <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> is trained. The model yields higher accuracies than dialect-specific models, eliminating the need for dialect identification before segmentation. We also measure the degree of <a href=https://en.wikipedia.org/wiki/Coefficient_of_relationship>relatedness</a> between four major <a href=https://en.wikipedia.org/wiki/Varieties_of_Arabic>Arabic dialects</a> by testing how a segmentation model trained on one dialect performs on the other dialects. We found that linguistic relatedness is contingent with <a href=https://en.wikipedia.org/wiki/Proxemics>geographical proximity</a>. In our experiments we use SVM-based ranking and bi-LSTM-CRF sequence labeling.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1306.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1306 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1306 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1306/>A Neural Architecture for Dialectal Arabic Segmentation<span class=acl-fixed-case>A</span>rabic Segmentation</a></strong><br><a href=/people/y/younes-samih/>Younes Samih</a>
|
<a href=/people/m/mohammed-attia/>Mohammed Attia</a>
|
<a href=/people/m/mohamed-eldesouki/>Mohamed Eldesouki</a>
|
<a href=/people/a/ahmed-abdelali/>Ahmed Abdelali</a>
|
<a href=/people/h/hamdy-mubarak/>Hamdy Mubarak</a>
|
<a href=/people/l/laura-kallmeyer/>Laura Kallmeyer</a>
|
<a href=/people/k/kareem-darwish/>Kareem Darwish</a><br><a href=/volumes/W17-13/ class=text-muted>Proceedings of the Third Arabic Natural Language Processing Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1306><div class="card-body p-3 small">The automated processing of <a href=https://en.wikipedia.org/wiki/Arabic_dialects>Arabic Dialects</a> is challenging due to the lack of spelling standards and to the scarcity of annotated data and resources in general. Segmentation of words into its constituent parts is an important processing building block. In this paper, we show how a segmenter can be trained using only 350 annotated tweets using <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> without any <a href=https://en.wikipedia.org/wiki/Normalization_(statistics)>normalization</a> or use of lexical features or lexical resources. We deal with segmentation as a sequence labeling problem at the <a href=https://en.wikipedia.org/wiki/Character_(computing)>character level</a>. We show experimentally that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can rival state-of-the-art methods that rely on additional resources.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Younes+Samih" title="Search for 'Younes Samih' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/m/mohammed-attia/ class=align-middle>Mohammed Attia</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/k/kareem-darwish/ class=align-middle>Kareem Darwish</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/a/ahmed-abdelali/ class=align-middle>Ahmed Abdelali</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/h/hamdy-mubarak/ class=align-middle>Hamdy Mubarak</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/m/mohamed-eldesouki/ class=align-middle>Mohamed Eldesouki</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/l/laura-kallmeyer/ class=align-middle>Laura Kallmeyer</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sabit-hassan/ class=align-middle>Sabit Hassan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ammar-rashed/ class=align-middle>Ammar Rashed</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shammur-absar-chowdhury/ class=align-middle>Shammur Absar Chowdhury</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wolfgang-maier/ class=align-middle>Wolfgang Maier</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rafael-ehren/ class=align-middle>Rafael Ehren</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/timm-lichte/ class=align-middle>Timm Lichte</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ali-elkahky/ class=align-middle>Ali Elkahky</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/osact/ class=align-middle>OSACT</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>