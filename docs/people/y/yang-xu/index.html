<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Yang Xu - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Yang</span> <span class=font-weight-bold>Xu</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.325.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--325 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.325 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.325" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.325/>How is BERT surprised? Layerwise detection of linguistic anomalies<span class=acl-fixed-case>BERT</span> surprised? Layerwise detection of linguistic anomalies</a></strong><br><a href=/people/b/bai-li/>Bai Li</a>
|
<a href=/people/z/zining-zhu/>Zining Zhu</a>
|
<a href=/people/g/guillaume-thomas/>Guillaume Thomas</a>
|
<a href=/people/y/yang-xu/>Yang Xu</a>
|
<a href=/people/f/frank-rudzicz/>Frank Rudzicz</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--325><div class="card-body p-3 small">Transformer language models have shown remarkable ability in detecting when a word is anomalous in context, but likelihood scores offer no information about the cause of the anomaly. In this work, we use Gaussian models for density estimation at intermediate layers of three language models (BERT, RoBERTa, and XLNet), and evaluate our method on BLiMP, a grammaticality judgement benchmark. In lower layers, surprisal is highly correlated to low token frequency, but this correlation diminishes in upper layers. Next, we gather datasets of <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphosyntactic</a>, semantic, and commonsense anomalies from psycholinguistic studies ; we find that the best performing model RoBERTa exhibits surprisal in earlier layers when the anomaly is <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphosyntactic</a> than when it is semantic, while commonsense anomalies do not exhibit surprisal at any intermediate layer. These results suggest that language models employ separate mechanisms to detect different types of linguistic anomalies.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.71.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--71 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.71 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.71" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.71/>Predicting emergent linguistic compositions through time : Syntactic frame extension via multimodal chaining</a></strong><br><a href=/people/l/lei-yu/>Lei Yu</a>
|
<a href=/people/y/yang-xu/>Yang Xu</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--71><div class="card-body p-3 small">Natural language relies on a finite lexicon to express an unbounded set of emerging ideas. One result of this tension is the formation of new compositions, such that existing linguistic units can be combined with emerging items into novel expressions. We develop a framework that exploits the cognitive mechanisms of chaining and multimodal knowledge to predict emergent compositional expressions through time. We present the syntactic frame extension model (SFEM) that draws on the theory of chaining and knowledge from percept, concept, and language to infer how verbs extend their frames to form new compositions with existing and novel nouns. We evaluate SFEM rigorously on the 1) modalities of knowledge and 2) categorization models of chaining, in a syntactically parsed English corpus over the past 150 years. We show that multimodal SFEM predicts newly emerged verb syntax and arguments substantially better than competing models using purely linguistic or unimodal knowledge. We find support for an exemplar view of chaining as opposed to a prototype view and reveal how the joint approach of multimodal chaining may be fundamental to the creation of literal and figurative language uses including <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a> and <a href=https://en.wikipedia.org/wiki/Metonymy>metonymy</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.lchange-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.lchange-1.0/>Proceedings of the 2nd International Workshop on Computational Approaches to Historical Language Change 2021</a></strong><br><a href=/people/n/nina-tahmasebi/>Nina Tahmasebi</a>
|
<a href=/people/a/adam-jatowt/>Adam Jatowt</a>
|
<a href=/people/y/yang-xu/>Yang Xu</a>
|
<a href=/people/s/simon-hengchen/>Simon Hengchen</a>
|
<a href=/people/s/syrielle-montariol/>Syrielle Montariol</a>
|
<a href=/people/h/haim-dubossarsky/>Haim Dubossarsky</a><br><a href=/volumes/2021.lchange-1/ class=text-muted>Proceedings of the 2nd International Workshop on Computational Approaches to Historical Language Change 2021</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.lchange-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--lchange-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.lchange-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.lchange-1.5/>A diachronic evaluation of gender asymmetry in euphemism</a></strong><br><a href=/people/a/anna-kapron-king/>Anna Kapron-King</a>
|
<a href=/people/y/yang-xu/>Yang Xu</a><br><a href=/volumes/2021.lchange-1/ class=text-muted>Proceedings of the 2nd International Workshop on Computational Approaches to Historical Language Change 2021</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--lchange-1--5><div class="card-body p-3 small">The use of <a href=https://en.wikipedia.org/wiki/Euphemism>euphemisms</a> is a known driver of <a href=https://en.wikipedia.org/wiki/Language_change>language change</a>. It has been proposed that women use <a href=https://en.wikipedia.org/wiki/Euphemism>euphemisms</a> more than men. Although there have been several studies investigating gender differences in language, the claim about euphemism usage has not been tested comprehensively through time. If women do use <a href=https://en.wikipedia.org/wiki/Euphemism>euphemisms</a> more, this could mean that women also lead the formation of new <a href=https://en.wikipedia.org/wiki/Euphemism>euphemisms</a> and <a href=https://en.wikipedia.org/wiki/Language_change>language change</a> over time. Using four large diachronic text corpora of English, we evaluate the claim that women use <a href=https://en.wikipedia.org/wiki/Euphemism>euphemisms</a> more than men through a <a href=https://en.wikipedia.org/wiki/Quantitative_research>quantitative analysis</a>. We assembled a list of 106 euphemism-taboo pairs to analyze their relative use through time by each gender in the corpora. Contrary to the existing belief, our results show that women do not use <a href=https://en.wikipedia.org/wiki/Euphemism>euphemisms</a> with a higher proportion than men. We repeated the <a href=https://en.wikipedia.org/wiki/Analysis>analysis</a> using different subsets of the euphemism-taboo pairs list and found that our result was robust. Our study indicates that in a broad range of settings involving both speech and writing, and with varying degrees of formality, women do not use or form <a href=https://en.wikipedia.org/wiki/Euphemism>euphemisms</a> more than men.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.259.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--259 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.259 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.findings-emnlp.259" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.259/>Inferring symmetry in <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a></a></strong><br><a href=/people/c/chelsea-tanchip/>Chelsea Tanchip</a>
|
<a href=/people/l/lei-yu/>Lei Yu</a>
|
<a href=/people/a/aotao-xu/>Aotao Xu</a>
|
<a href=/people/y/yang-xu/>Yang Xu</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--259><div class="card-body p-3 small">We present a methodological framework for inferring symmetry of verb predicates in <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. Empirical work on predicate symmetry has taken two main approaches. The feature-based approach focuses on <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a> pertaining to <a href=https://en.wikipedia.org/wiki/Symmetry>symmetry</a>. The context-based approach denies the existence of absolute symmetry but instead argues that such <a href=https://en.wikipedia.org/wiki/Inference>inference</a> is context dependent. We develop methods that formalize these approaches and evaluate them against a novel symmetry inference sentence (SIS) dataset comprised of 400 naturalistic usages of literature-informed verbs spanning the spectrum of symmetry-asymmetry. Our results show that a hybrid transfer learning model that integrates <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a> with contextualized language models most faithfully predicts the <a href=https://en.wikipedia.org/wiki/Empirical_evidence>empirical data</a>. Our work integrates existing approaches to symmetry in natural language and suggests how symmetry inference can improve systematicity in state-of-the-art <a href=https://en.wikipedia.org/wiki/Language_model>language models</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1472.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1472 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1472 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1472.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-1472/>Text-based inference of moral sentiment change</a></strong><br><a href=/people/j/jing-yi-xie/>Jing Yi Xie</a>
|
<a href=/people/r/renato-ferreira-pinto-junior/>Renato Ferreira Pinto Junior</a>
|
<a href=/people/g/graeme-hirst/>Graeme Hirst</a>
|
<a href=/people/y/yang-xu/>Yang Xu</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1472><div class="card-body p-3 small">We present a text-based framework for investigating moral sentiment change of the public via <a href=https://en.wikipedia.org/wiki/Longitudinal_study>longitudinal corpora</a>. Our framework is based on the premise that language use can inform people&#8217;s moral perception toward right or wrong, and we build our <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> by exploring moral biases learned from diachronic word embeddings. We demonstrate how a parameter-free model supports inference of historical shifts in moral sentiment toward concepts such as <a href=https://en.wikipedia.org/wiki/Slavery>slavery</a> and <a href=https://en.wikipedia.org/wiki/Democracy>democracy</a> over centuries at three incremental levels : moral relevance, moral polarity, and fine-grained moral dimensions. We apply this methodology to visualizing moral time courses of individual concepts and analyzing the relations between psycholinguistic variables and rates of moral sentiment change at scale. Our work offers opportunities for applying <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> toward characterizing moral sentiment change in society.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4700.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4700/>Proceedings of the 1st International Workshop on Computational Approaches to Historical Language Change</a></strong><br><a href=/people/n/nina-tahmasebi/>Nina Tahmasebi</a>
|
<a href=/people/l/lars-borin/>Lars Borin</a>
|
<a href=/people/a/adam-jatowt/>Adam Jatowt</a>
|
<a href=/people/y/yang-xu/>Yang Xu</a><br><a href=/volumes/W19-47/ class=text-muted>Proceedings of the 1st International Workshop on Computational Approaches to Historical Language Change</a></span></p><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1015.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1015 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1015 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-1015/>Incorporating <a href=https://en.wikipedia.org/wiki/Image_matching>Image Matching</a> Into <a href=https://en.wikipedia.org/wiki/Knowledge_acquisition>Knowledge Acquisition</a> for Event-Oriented Relation Recognition</a></strong><br><a href=/people/y/yu-hong/>Yu Hong</a>
|
<a href=/people/y/yang-xu/>Yang Xu</a>
|
<a href=/people/h/huibin-ruan/>Huibin Ruan</a>
|
<a href=/people/b/bowei-zou/>Bowei Zou</a>
|
<a href=/people/j/jianmin-yao/>Jianmin Yao</a>
|
<a href=/people/g/guodong-zhou/>Guodong Zhou</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1015><div class="card-body p-3 small">Event relation recognition is a challenging <a href=https://en.wikipedia.org/wiki/Language_processing_in_the_brain>language processing task</a>. It is required to determine the relation class of a pair of query events, such as <a href=https://en.wikipedia.org/wiki/Causality>causality</a>, under the condition that there is n&#8217;t any reliable clue for use. We follow the traditional statistical approach in this paper, speculating the relation class of the target events based on the relation-class distributions on the similar events. There is minimal <a href=https://en.wikipedia.org/wiki/Supervisor>supervision</a> used during the <a href=https://en.wikipedia.org/wiki/Speculation>speculation process</a>. In particular, we incorporate <a href=https://en.wikipedia.org/wiki/Digital_image_processing>image processing</a> into the acquisition of similar event instances, including the utilization of images for visually representing event scenes, and the use of the neural network based image matching for approximate calculation between events. We test our method on the ACE-R2 corpus and compared our model with the fully-supervised neural network models. Experimental results show that we achieve a comparable performance to CNN while slightly better than LSTM.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1079.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1079 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1079 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1079" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D18-1079/>Using active learning to expand training data for implicit discourse relation recognition</a></strong><br><a href=/people/y/yang-xu/>Yang Xu</a>
|
<a href=/people/y/yu-hong/>Yu Hong</a>
|
<a href=/people/h/huibin-ruan/>Huibin Ruan</a>
|
<a href=/people/j/jianmin-yao/>Jianmin Yao</a>
|
<a href=/people/m/min-zhang/>Min Zhang</a>
|
<a href=/people/g/guodong-zhou/>Guodong Zhou</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1079><div class="card-body p-3 small">We tackle discourse-level relation recognition, a problem of determining semantic relations between text spans. Implicit relation recognition is challenging due to the lack of explicit relational clues. The increasingly popular <a href=https://en.wikipedia.org/wiki/Neural_network>neural network techniques</a> have been proven effective for semantic encoding, whereby widely employed to boost semantic relation discrimination. However, learning to predict semantic relations at a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep level</a> heavily relies on a great deal of training data, but the scale of the publicly available data in this field is limited. In this paper, we follow Rutherford and Xue (2015) to expand the training data set using the corpus of explicitly-related arguments, by arbitrarily dropping the overtly presented discourse connectives. On the basis, we carry out an experiment of <a href=https://en.wikipedia.org/wiki/Sampling_(statistics)>sampling</a>, in which a simple active learning approach is used, so as to take the informative instances for data expansion. The goal is to verify whether the selective use of external data not only reduces the time consumption of <a href=https://en.wikipedia.org/wiki/Retraining>retraining</a> but also ensures a better <a href=https://en.wikipedia.org/wiki/System>system</a> performance. Using the expanded training data, we retrain a convolutional neural network (CNN) based classifer which is a simplified version of Qin et al. (2016)&#8217;s stacking gated relation recognizer. Experimental results show that expanding the training set with small-scale carefully-selected external data yields substantial performance gain, with the improvements of about 4 % for <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and 3.6 % for <a href=https://en.wikipedia.org/wiki/F-score>F-score</a>. This allows a <a href=https://en.wikipedia.org/wiki/Weak_classifier>weak classifier</a> to achieve a comparable performance against the state-of-the-art systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1142.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1142 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1142 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D18-1142.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1142/>Is Nike female? Exploring the role of <a href=https://en.wikipedia.org/wiki/Sound_symbolism>sound symbolism</a> in predicting brand name gender<span class=acl-fixed-case>N</span>ike female? Exploring the role of sound symbolism in predicting brand name gender</a></strong><br><a href=/people/s/sridhar-moorthy/>Sridhar Moorthy</a>
|
<a href=/people/r/ruth-pogacar/>Ruth Pogacar</a>
|
<a href=/people/s/samin-khan/>Samin Khan</a>
|
<a href=/people/y/yang-xu/>Yang Xu</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1142><div class="card-body p-3 small">Are <a href=https://en.wikipedia.org/wiki/Brand>brand names</a> such as Nike female or male? Previous research suggests that the sound of a person&#8217;s first name is associated with the person&#8217;s gender, but no research has tried to use this knowledge to assess the gender of brand names. We present a simple computational approach that uses <a href=https://en.wikipedia.org/wiki/Sound_symbolism>sound symbolism</a> to address this open issue. Consistent with previous research, a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> trained on various linguistic features of name endings predicts human gender with high <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. Applying this model to a data set of over a thousand commercially-traded brands in 17 product categories, our results reveal an overall bias toward male names, cutting across both male-oriented product categories as well as female-oriented categories. In addition, we find variation within categories, suggesting that firms might be seeking to imbue their brands with differentiating characteristics as part of their competitive strategy.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1058.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1058 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1058 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234958072 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1058/>Spectral Analysis of <a href=https://en.wikipedia.org/wiki/Information_density>Information Density</a> in <a href=https://en.wikipedia.org/wiki/Dialogue>Dialogue</a> Predicts Collaborative Task Performance</a></strong><br><a href=/people/y/yang-xu/>Yang Xu</a>
|
<a href=/people/d/david-reitter/>David Reitter</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1058><div class="card-body p-3 small">We propose a <a href=https://en.wikipedia.org/wiki/Point_of_view_(philosophy)>perspective</a> on <a href=https://en.wikipedia.org/wiki/Dialogue>dialogue</a> that focuses on relative information contributions of conversation partners as a key to successful communication. We predict the success of collaborative task in English and Danish corpora of task-oriented dialogue. Two features are extracted from the frequency domain representations of the lexical entropy series of each interlocutor, power spectrum overlap (PSO) and relative phase (RP). We find that PSO is a negative predictor of task success, while RP is a positive one. An <a href=https://en.wikipedia.org/wiki/Symmetric_multiprocessing>SVM</a> with these <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> significantly improved on previous task success prediction models. Our findings suggest that the strategic distribution of information density between interlocutors is relevant to task success.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Yang+Xu" title="Search for 'Yang Xu' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/y/yu-hong/ class=align-middle>Yu Hong</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/huibin-ruan/ class=align-middle>Huibin Ruan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jianmin-yao/ class=align-middle>Jianmin Yao</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/g/guodong-zhou/ class=align-middle>Guodong Zhou</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/lei-yu/ class=align-middle>Lei Yu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/n/nina-tahmasebi/ class=align-middle>Nina Tahmasebi</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/adam-jatowt/ class=align-middle>Adam Jatowt</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/bowei-zou/ class=align-middle>Bowei Zou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bai-li/ class=align-middle>Bai Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zining-zhu/ class=align-middle>Zining Zhu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/guillaume-thomas/ class=align-middle>Guillaume Thomas</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/frank-rudzicz/ class=align-middle>Frank Rudzicz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/david-reitter/ class=align-middle>David Reitter</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/min-zhang/ class=align-middle>Min Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sridhar-moorthy/ class=align-middle>Sridhar Moorthy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ruth-pogacar/ class=align-middle>Ruth Pogacar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/samin-khan/ class=align-middle>Samin Khan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jing-yi-xie/ class=align-middle>Jing Yi Xie</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/renato-ferreira-pinto-junior/ class=align-middle>Renato Ferreira Pinto Junior</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/graeme-hirst/ class=align-middle>Graeme Hirst</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/simon-hengchen/ class=align-middle>Simon Hengchen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/syrielle-montariol/ class=align-middle>Syrielle Montariol</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haim-dubossarsky/ class=align-middle>Haim Dubossarsky</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anna-kapron-king/ class=align-middle>Anna Kapron-King</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chelsea-tanchip/ class=align-middle>Chelsea Tanchip</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aotao-xu/ class=align-middle>Aotao Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lars-borin/ class=align-middle>Lars Borin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/lchange/ class=align-middle>LChange</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>