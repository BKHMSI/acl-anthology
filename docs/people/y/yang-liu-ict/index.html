<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Yang Liu - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Yang</span> <span class=font-weight-bold>Liu</span></h2><p class="font-weight-light text-muted">刘洋; ICT, Tsinghua, Beijing Academy of Artificial Intelligence</p><p class="font-weight-light text-muted"><span class=font-italic>Other people with similar names:</span>
<a href=/people/y/yang-liu/>Yang Liu</a>
(May refer to several people),
<a href=/people/y/yang-liu-3m/>Yang Liu</a>
(3M Health Information Systems),
<a href=/people/y/yang-liu-Helsinki/>Yang Liu</a>
(University of Helsinki),
<a href=/people/y/yang-liu-dt/>Yang Liu</a>
(National University of Defense Technology),
<a href=/people/y/yang-liu-edinburgh/>Yang Liu</a>
(Edinburgh),
<a href=/people/y/yang-liu-georgetown/>Yang (Janet) Liu</a>
(刘洋; Georgetown),
<a href=/people/y/yang-liu-gt/>Yang Liu</a>
(Georgetown University),
<a href=/people/y/yang-liu-hk/>Yang Liu</a>
(The Chinese University of Hong Kong (Shenzhen)),
<a href=/people/y/yang-liu-icsi/>Yang Liu</a>
(刘扬; Ph.D Purdue; ICSI, Dallas, Facebook, Liulishuo, Amazon),
<a href=/people/y/yang-liu-microsoft/>Yang Liu</a>
(Microsoft Cognitive Services Research),
<a href=/people/y/yang-liu-pk/>Yang Liu</a>
(Peking University),
<a href=/people/y/yang-liu-umich/>Yang Liu</a>
(Univ. of Michigan, UC Santa Cruz)</p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ccl-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ccl-1.0/>Proceedings of the 20th Chinese National Conference on Computational Linguistics</a></strong><br><a href=/people/s/sheng-li/>Sheng Li (李生)</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun (孙茂松)</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu (刘洋)</a>
|
<a href=/people/h/hua-wu/>Hua Wu (吴华)</a>
|
<a href=/people/k/kang-liu/>Kang Liu (刘康)</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che (车万翔)</a>
|
<a href=/people/s/shizhu-he/>Shizhu He (何世柱)</a>
|
<a href=/people/g/gaoqi-rao/>Gaoqi Rao (饶高琦)</a><br><a href=/volumes/2021.ccl-1/ class=text-muted>Proceedings of the 20th Chinese National Conference on Computational Linguistics</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.158.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--158 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.158 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.158/>Segment, Mask, and Predict : Augmenting Chinese Word Segmentation with Self-Supervision<span class=acl-fixed-case>C</span>hinese Word Segmentation with Self-Supervision</a></strong><br><a href=/people/m/mieradilijiang-maimaiti/>Mieradilijiang Maimaiti</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu</a>
|
<a href=/people/y/yuanhang-zheng/>Yuanhang Zheng</a>
|
<a href=/people/g/gang-chen/>Gang Chen</a>
|
<a href=/people/k/kaiyu-huang/>Kaiyu Huang</a>
|
<a href=/people/j/ji-zhang/>Ji Zhang</a>
|
<a href=/people/h/huanbo-luan/>Huanbo Luan</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--158><div class="card-body p-3 small">Recent state-of-the-art (SOTA) effective neural network methods and fine-tuning methods based on pre-trained models (PTM) have been used in Chinese word segmentation (CWS), and they achieve great results. However, previous works focus on training the <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> with the fixed corpus at every iteration. The intermediate generated information is also valuable. Besides, the <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> of the previous <a href=https://en.wikipedia.org/wiki/Artificial_neural_network>neural methods</a> is limited by the large-scale annotated data. There are a few noises in the annotated corpus. Limited efforts have been made by previous studies to deal with such problems. In this work, we propose a self-supervised CWS approach with a straightforward and effective <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a>. First, we train a word segmentation model and use it to generate the segmentation results. Then, we use a revised masked language model (MLM) to evaluate the quality of the segmentation results based on the predictions of the MLM. Finally, we leverage the evaluations to aid the training of the segmenter by improved minimum risk training. Experimental results show that our approach outperforms previous methods on 9 different CWS datasets with single criterion training and multiple criteria training and achieves better robustness.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.267.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--267 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.267 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.267/>Self-Supervised Quality Estimation for <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a></a></strong><br><a href=/people/y/yuanhang-zheng/>Yuanhang Zheng</a>
|
<a href=/people/z/zhixing-tan/>Zhixing Tan</a>
|
<a href=/people/m/meng-zhang/>Meng Zhang</a>
|
<a href=/people/m/mieradilijiang-maimaiti/>Mieradilijiang Maimaiti</a>
|
<a href=/people/h/huanbo-luan/>Huanbo Luan</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun</a>
|
<a href=/people/q/qun-liu/>Qun Liu</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--267><div class="card-body p-3 small">Quality estimation (QE) of machine translation (MT) aims to evaluate the quality of machine-translated sentences without references and is important in practical applications of MT. Training QE models require massive parallel data with hand-crafted quality annotations, which are time-consuming and labor-intensive to obtain. To address the issue of the absence of annotated training data, previous studies attempt to develop unsupervised QE methods. However, very few of them can be applied to both sentence- and word-level QE tasks, and they may suffer from noises in the synthetic data. To reduce the negative impact of noises, we propose a self-supervised method for both sentence- and word-level QE, which performs quality estimation by recovering the masked target words. Experimental results show that our method outperforms previous <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised methods</a> on several QE tasks in different language pairs and domains.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ccl-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ccl-1.0/>Proceedings of the 19th Chinese National Conference on Computational Linguistics</a></strong><br><a href=/people/m/maosong-sun/>Maosong Sun (孙茂松)</a>
|
<a href=/people/s/sujian-li/>Sujian Li (李素建)</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang (张岳)</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu (刘洋)</a><br><a href=/volumes/2020.ccl-1/ class=text-muted>Proceedings of the 19th Chinese National Conference on Computational Linguistics</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.autosimtrans-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.autosimtrans-1.0/>Proceedings of the First Workshop on Automatic Simultaneous Translation</a></strong><br><a href=/people/h/hua-wu/>Hua Wu</a>
|
<a href=/people/c/collin-cherry/>Collin Cherry</a>
|
<a href=/people/l/liang-huang/>Liang Huang</a>
|
<a href=/people/z/zhongjun-he/>Zhongjun He</a>
|
<a href=/people/m/mark-liberman/>Mark Liberman</a>
|
<a href=/people/j/james-cross/>James Cross</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu</a><br><a href=/volumes/2020.autosimtrans-1/ class=text-muted>Proceedings of the First Workshop on Automatic Simultaneous Translation</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1623.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1623 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1623 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1623/>Reducing Word Omission Errors in Neural Machine Translation : A Contrastive Learning Approach</a></strong><br><a href=/people/z/zonghan-yang/>Zonghan Yang</a>
|
<a href=/people/y/yong-cheng/>Yong Cheng</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1623><div class="card-body p-3 small">While neural machine translation (NMT) has achieved remarkable success, NMT systems are prone to make word omission errors. In this work, we propose a contrastive learning approach to reducing word omission errors in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NMT</a>. The basic idea is to enable the NMT model to assign a higher probability to a ground-truth translation and a lower probability to an erroneous translation, which is automatically constructed from the ground-truth translation by omitting words. We design different types of negative examples depending on the number of omitted words, <a href=https://en.wikipedia.org/wiki/Word_frequency>word frequency</a>, and <a href=https://en.wikipedia.org/wiki/Part_of_speech>part of speech</a>. Experiments on Chinese-to-English, German-to-English, and Russian-to-English translation tasks show that our approach is effective in reducing word omission errors and achieves better <a href=https://en.wikipedia.org/wiki/Translation>translation</a> performance than three baseline methods.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1029.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1029 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1029 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1029" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/Q18-1029/>Learning to Remember Translation History with a Continuous Cache</a></strong><br><a href=/people/z/zhaopeng-tu/>Zhaopeng Tu</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu</a>
|
<a href=/people/s/shuming-shi/>Shuming Shi</a>
|
<a href=/people/t/tong-zhang/>Tong Zhang</a><br><a href=/volumes/Q18-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 6</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1029><div class="card-body p-3 small">Existing neural machine translation (NMT) models generally translate sentences in isolation, missing the opportunity to take advantage of document-level information. In this work, we propose to augment NMT models with a very light-weight cache-like memory network, which stores recent hidden representations as translation history. The <a href=https://en.wikipedia.org/wiki/Probability_distribution>probability distribution</a> over generated words is updated online depending on the translation history retrieved from the <a href=https://en.wikipedia.org/wiki/Computer_memory>memory</a>, endowing NMT models with the capability to dynamically adapt over time. Experiments on multiple domains with different topics and styles show the effectiveness of the proposed approach with negligible impact on the <a href=https://en.wikipedia.org/wiki/Computational_cost>computational cost</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1163.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1163 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1163 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1163.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1163/>Towards Robust Neural Machine Translation</a></strong><br><a href=/people/y/yong-cheng/>Yong Cheng</a>
|
<a href=/people/z/zhaopeng-tu/>Zhaopeng Tu</a>
|
<a href=/people/f/fandong-meng/>Fandong Meng</a>
|
<a href=/people/j/junjie-zhai/>Junjie Zhai</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1163><div class="card-body p-3 small">Small perturbations in the input can severely distort intermediate representations and thus impact translation quality of neural machine translation (NMT) models. In this paper, we propose to improve the <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> of NMT models with adversarial stability training. The basic idea is to make both the encoder and decoder in NMT models robust against input perturbations by enabling them to behave similarly for the original input and its perturbed counterpart. Experimental results on Chinese-English, English-German and English-French translation tasks show that our approaches can not only achieve significant improvements over strong NMT systems but also improve the robustness of NMT models.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1106.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1106 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1106 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234946242 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1106/>Visualizing and Understanding Neural Machine Translation</a></strong><br><a href=/people/y/yanzhuo-ding/>Yanzhuo Ding</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu</a>
|
<a href=/people/h/huanbo-luan/>Huanbo Luan</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1106><div class="card-body p-3 small">While <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation (NMT)</a> has made remarkable progress in recent years, it is hard to interpret its internal workings due to the continuous representations and <a href=https://en.wikipedia.org/wiki/Nonlinear_system>non-linearity</a> of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>. In this work, we propose to use layer-wise relevance propagation (LRP) to compute the contribution of each contextual word to arbitrary hidden states in the attention-based encoder-decoder framework. We show that <a href=https://en.wikipedia.org/wiki/Visualization_(graphics)>visualization</a> with LRP helps to interpret the internal workings of NMT and analyze translation errors.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1139.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1139 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1139 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P17-1139" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P17-1139/>Prior Knowledge Integration for <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> using Posterior Regularization</a></strong><br><a href=/people/j/jiacheng-zhang/>Jiacheng Zhang</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu</a>
|
<a href=/people/h/huanbo-luan/>Huanbo Luan</a>
|
<a href=/people/j/jingfang-xu/>Jingfang Xu</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1139><div class="card-body p-3 small">Although <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a> has made significant progress recently, how to integrate multiple overlapping, arbitrary prior knowledge sources remains a challenge. In this work, we propose to use posterior regularization to provide a general framework for integrating prior knowledge into <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>. We represent prior knowledge sources as <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> in a <a href=https://en.wikipedia.org/wiki/Log-linear_model>log-linear model</a>, which guides the learning processing of the neural translation model. Experiments on Chinese-English dataset show that our approach leads to significant improvements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1176.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1176 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1176 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P17-1176/>A Teacher-Student Framework for Zero-Resource Neural Machine Translation</a></strong><br><a href=/people/y/yun-chen/>Yun Chen</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu</a>
|
<a href=/people/y/yong-cheng/>Yong Cheng</a>
|
<a href=/people/v/victor-o-k-li/>Victor O.K. Li</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1176><div class="card-body p-3 small">While end-to-end neural machine translation (NMT) has made remarkable progress recently, it still suffers from the data scarcity problem for low-resource language pairs and domains. In this paper, we propose a method for zero-resource NMT by assuming that parallel sentences have close probabilities of generating a sentence in a <a href=https://en.wikipedia.org/wiki/Third_language>third language</a>. Based on the assumption, our method is able to train a source-to-target NMT model (student) without parallel corpora available guided by an existing pivot-to-target NMT model (teacher) on a source-pivot parallel corpus. Experimental results show that the proposed method significantly improves over a baseline pivot-based model by +3.0 BLEU points across various language pairs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1179.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1179 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1179 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-1179.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-1179.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1179/>Adversarial Training for Unsupervised Bilingual Lexicon Induction</a></strong><br><a href=/people/m/meng-zhang/>Meng Zhang</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu</a>
|
<a href=/people/h/huanbo-luan/>Huanbo Luan</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1179><div class="card-body p-3 small">Word embeddings are well known to capture <a href=https://en.wikipedia.org/wiki/Regularization_(linguistics)>linguistic regularities</a> of the language on which they are trained. Researchers also observe that these regularities can transfer across languages. However, previous endeavors to connect separate monolingual word embeddings typically require cross-lingual signals as supervision, either in the form of <a href=https://en.wikipedia.org/wiki/Parallel_corpus>parallel corpus</a> or seed lexicon. In this work, we show that such cross-lingual connection can actually be established without any form of <a href=https://en.wikipedia.org/wiki/Supervisor>supervision</a>. We achieve this end by formulating the <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> as a natural adversarial game, and investigating techniques that are crucial to successful <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a>. We carry out evaluation on the unsupervised bilingual lexicon induction task. Even though this task appears intrinsically cross-lingual, we are able to demonstrate encouraging performance without any cross-lingual clues.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q17-1007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q17-1007 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q17-1007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234951517 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q17-1007" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/Q17-1007/>Context Gates for <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a></a></strong><br><a href=/people/z/zhaopeng-tu/>Zhaopeng Tu</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu</a>
|
<a href=/people/z/zhengdong-lu/>Zhengdong Lu</a>
|
<a href=/people/x/xiaohua-liu/>Xiaohua Liu</a>
|
<a href=/people/h/hang-li/>Hang Li</a><br><a href=/volumes/Q17-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 5</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q17-1007><div class="card-body p-3 small">In <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation (NMT)</a>, generation of a target word depends on both source and target contexts. We find that source contexts have a direct impact on the adequacy of a translation while target contexts affect the <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a>. Intuitively, generation of a content word should rely more on the source context and generation of a functional word should rely more on the target context. Due to the lack of effective control over the influence from source and target contexts, conventional NMT tends to yield fluent but inadequate translations. To address this problem, we propose context gates which dynamically control the ratios at which source and target contexts contribute to the generation of target words. In this way, we can enhance both the <a href=https://en.wikipedia.org/wiki/Adequality>adequacy</a> and <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a> of NMT with more careful control of the information flow from contexts. Experiments show that our approach significantly improves upon a standard attention-based NMT system by +2.3 BLEU points.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1207.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1207 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1207 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238232779 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1207/>Earth Mover’s Distance Minimization for Unsupervised Bilingual Lexicon Induction</a></strong><br><a href=/people/m/meng-zhang/>Meng Zhang</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu</a>
|
<a href=/people/h/huanbo-luan/>Huanbo Luan</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1207><div class="card-body p-3 small">Cross-lingual natural language processing hinges on the premise that there exists invariance across languages. At the word level, researchers have identified such <a href=https://en.wikipedia.org/wiki/Invariant_(mathematics)>invariance</a> in the word embedding semantic spaces of different languages. However, in order to connect the separate spaces, cross-lingual supervision encoded in parallel data is typically required. In this paper, we attempt to establish the cross-lingual connection without relying on any cross-lingual supervision. By viewing word embedding spaces as <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distributions</a>, we propose to minimize their earth mover&#8217;s distance, a measure of divergence between distributions. We demonstrate the success on the unsupervised bilingual lexicon induction task. In addition, we reveal an interesting finding that the earth mover&#8217;s distance shows potential as a measure of <a href=https://en.wikipedia.org/wiki/Language>language difference</a>.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Yang+Liu" title="Search for 'Yang Liu' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/m/maosong-sun/ class=align-middle>Maosong Sun (孙茂松)</a>
<span class="badge badge-secondary align-middle ml-2">9</span></li><li class=list-group-item><a href=/people/h/huanbo-luan/ class=align-middle>Huanbo Luan</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/y/yong-cheng/ class=align-middle>Yong Cheng</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/meng-zhang/ class=align-middle>Meng Zhang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/z/zhaopeng-tu/ class=align-middle>Zhaopeng Tu</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/h/hua-wu/ class=align-middle>Hua Wu (吴华)</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mieradilijiang-maimaiti/ class=align-middle>Mieradilijiang Maimaiti</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yuanhang-zheng/ class=align-middle>Yuanhang Zheng</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sheng-li/ class=align-middle>Sheng Li (李生)</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kang-liu/ class=align-middle>Kang Liu (刘康)</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wanxiang-che/ class=align-middle>Wanxiang Che (车万翔)</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shizhu-he/ class=align-middle>Shizhu He (何世柱)</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gaoqi-rao/ class=align-middle>Gaoqi Rao (饶高琦)</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sujian-li/ class=align-middle>Sujian Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yue-zhang/ class=align-middle>Yue Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yanzhuo-ding/ class=align-middle>Yanzhuo Ding</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiacheng-zhang/ class=align-middle>Jiacheng Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jingfang-xu/ class=align-middle>Jingfang Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yun-chen/ class=align-middle>Yun Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/victor-o-k-li/ class=align-middle>Victor O.K. Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/collin-cherry/ class=align-middle>Collin Cherry</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/liang-huang/ class=align-middle>Liang Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhongjun-he/ class=align-middle>Zhongjun He</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mark-liberman/ class=align-middle>Mark Liberman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/james-cross/ class=align-middle>James Cross</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhengdong-lu/ class=align-middle>Zhengdong Lu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaohua-liu/ class=align-middle>Xiaohua Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hang-li/ class=align-middle>Hang Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gang-chen/ class=align-middle>Gang Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kaiyu-huang/ class=align-middle>Kaiyu Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/ji-zhang/ class=align-middle>Ji Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhixing-tan/ class=align-middle>Zhixing Tan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qun-liu/ class=align-middle>Qun Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shuming-shi/ class=align-middle>Shuming Shi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tong-zhang/ class=align-middle>Tong Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fandong-meng/ class=align-middle>Fandong Meng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/junjie-zhai/ class=align-middle>Junjie Zhai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zonghan-yang/ class=align-middle>Zonghan Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/ccl/ class=align-middle>CCL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/tacl/ class=align-middle>TACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/autosimtrans/ class=align-middle>AutoSimTrans</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>