<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Barnabás Poczós - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Barnabás</span> <span class=font-weight-bold>Poczós</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Barnabas <span class=font-weight-normal>Poczos</span></p><hr><div class=row><div class=col-lg-9><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.39.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--39 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.39 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939206 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.39/>Efficient Meta Lifelong-Learning with Limited Memory</a></strong><br><a href=/people/z/zirui-wang/>Zirui Wang</a>
|
<a href=/people/s/sanket-vaibhav-mehta/>Sanket Vaibhav Mehta</a>
|
<a href=/people/b/barnabas-poczos/>Barnabas Poczos</a>
|
<a href=/people/j/jaime-g-carbonell/>Jaime Carbonell</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--39><div class="card-body p-3 small">Current <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language processing models</a> work well on a single <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, yet they often fail to continuously learn new tasks without forgetting previous ones as they are re-trained throughout their lifetime, a challenge known as <a href=https://en.wikipedia.org/wiki/Lifelong_learning>lifelong learning</a>. State-of-the-art lifelong language learning methods store past examples in <a href=https://en.wikipedia.org/wiki/Episodic_memory>episodic memory</a> and replay them at both training and inference time. However, as we show later in our experiments, there are three significant impediments : (1) needing unrealistically large memory module to achieve good performance, (2) suffering from negative transfer, (3) requiring multiple local adaptation steps for each test example that significantly slows down the inference speed. In this paper, we identify three common principles of lifelong learning methods and propose an efficient meta-lifelong framework that combines them in a synergistic fashion. To achieve sample efficiency, our method trains the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in a manner that it learns a better initialization for local adaptation. Extensive experiments on text classification and question answering benchmarks demonstrate the effectiveness of our framework by achieving state-of-the-art performance using merely 1 % memory size and narrowing the gap with multi-task learning. We further show that our method alleviates both catastrophic forgetting and <a href=https://en.wikipedia.org/wiki/Negative_transfer>negative transfer</a> at the same time.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.169.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--169 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.169 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929267 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.169/>Politeness Transfer : A Tag and Generate Approach</a></strong><br><a href=/people/a/aman-madaan/>Aman Madaan</a>
|
<a href=/people/a/amrith-setlur/>Amrith Setlur</a>
|
<a href=/people/t/tanmay-parekh/>Tanmay Parekh</a>
|
<a href=/people/b/barnabas-poczos/>Barnabas Poczos</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/y/yiming-yang/>Yiming Yang</a>
|
<a href=/people/r/ruslan-salakhutdinov/>Ruslan Salakhutdinov</a>
|
<a href=/people/a/alan-w-black/>Alan W Black</a>
|
<a href=/people/s/shrimai-prabhumoye/>Shrimai Prabhumoye</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--169><div class="card-body p-3 small">This paper introduces a new task of politeness transfer which involves converting non-polite sentences to polite sentences while preserving the <a href=https://en.wikipedia.org/wiki/Meaning_(linguistics)>meaning</a>. We also provide a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of more than 1.39 instances automatically labeled for <a href=https://en.wikipedia.org/wiki/Politeness>politeness</a> to encourage benchmark evaluations on this new <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. We design a tag and generate pipeline that identifies stylistic attributes and subsequently generates a sentence in the target style while preserving most of the source content. For <a href=https://en.wikipedia.org/wiki/Politeness>politeness</a> as well as five other transfer tasks, our model outperforms the state-of-the-art methods on automatic metrics for content preservation, with a comparable or better performance on style transfer accuracy. Additionally, our model surpasses existing methods on human evaluations for <a href=https://en.wikipedia.org/wiki/Grammaticality>grammaticality</a>, meaning preservation and transfer accuracy across all the six style transfer tasks. The data and code is located at https://github.com/tag-and-generate.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1119.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1119 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1119 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/347406566 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-1119/>Competence-based Curriculum Learning for Neural Machine Translation</a></strong><br><a href=/people/e/emmanouil-antonios-platanios/>Emmanouil Antonios Platanios</a>
|
<a href=/people/o/otilia-stretcu/>Otilia Stretcu</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/b/barnabas-poczos/>Barnabas Poczos</a>
|
<a href=/people/t/tom-mitchell/>Tom Mitchell</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1119><div class="card-body p-3 small">Current state-of-the-art NMT systems use large neural networks that are not only slow to train, but also often require many <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a> and optimization tricks, such as specialized learning rate schedules and large batch sizes. This is undesirable as <a href=https://en.wikipedia.org/wiki/It_(2017_film)>it</a> requires extensive hyperparameter tuning. In this paper, we propose a curriculum learning framework for NMT that reduces training time, reduces the need for specialized heuristics or large batch sizes, and results in overall better performance. Our framework consists of a principled way of deciding which training samples are shown to the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> at different times during training, based on the estimated difficulty of a sample and the current competence of the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>. Filtering training samples in this manner prevents the model from getting stuck in bad local optima, making it converge faster and reach a better solution than the common approach of uniformly sampling training examples. Furthermore, the proposed method can be easily applied to existing NMT models by simply modifying their input data pipelines. We show that our framework can help improve the <a href=https://en.wikipedia.org/wiki/Time_complexity>training time</a> and the performance of both <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network models</a> and Transformers, achieving up to a 70 % decrease in <a href=https://en.wikipedia.org/wiki/Time_complexity>training time</a>, while at the same time obtaining accuracy improvements of up to 2.2 BLEU.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3308.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3308 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3308 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3308/>Seq2Seq2Sentiment : Multimodal Sequence to Sequence Models for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a><span class=acl-fixed-case>S</span>eq2<span class=acl-fixed-case>S</span>eq2<span class=acl-fixed-case>S</span>entiment: Multimodal Sequence to Sequence Models for Sentiment Analysis</a></strong><br><a href=/people/h/hai-pham/>Hai Pham</a>
|
<a href=/people/t/thomas-manzini/>Thomas Manzini</a>
|
<a href=/people/p/paul-pu-liang/>Paul Pu Liang</a>
|
<a href=/people/b/barnabas-poczos/>Barnabás Poczós</a><br><a href=/volumes/W18-33/ class=text-muted>Proceedings of Grand Challenge and Workshop on Human Multimodal Language (Challenge-HML)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3308><div class="card-body p-3 small">Multimodal machine learning is a core research area spanning the language, visual and acoustic modalities. The central challenge in <a href=https://en.wikipedia.org/wiki/Multimodal_learning>multimodal learning</a> involves learning representations that can process and relate information from multiple modalities. In this paper, we propose two methods for unsupervised learning of joint multimodal representations using sequence to sequence (Seq2Seq) methods : a Seq2Seq Modality Translation Model and a Hierarchical Seq2Seq Modality Translation Model. We also explore multiple different variations on the multimodal inputs and outputs of these seq2seq models. Our experiments on <a href=https://en.wikipedia.org/wiki/Multimodal_sentiment_analysis>multimodal sentiment analysis</a> using the CMU-MOSI dataset indicate that our methods learn informative multimodal representations that outperform the baselines and achieve improved performance on <a href=https://en.wikipedia.org/wiki/Multimodal_sentiment_analysis>multimodal sentiment analysis</a>, specifically in the Bimodal case where our model is able to improve F1 Score by twelve points. We also discuss future directions for multimodal Seq2Seq methods.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Barnab%C3%A1s+Pocz%C3%B3s" title="Search for 'Barnabás Poczós' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/g/graham-neubig/ class=align-middle>Graham Neubig</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/zirui-wang/ class=align-middle>Zirui Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sanket-vaibhav-mehta/ class=align-middle>Sanket Vaibhav Mehta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jaime-g-carbonell/ class=align-middle>Jaime G. Carbonell</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aman-madaan/ class=align-middle>Aman Madaan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/a/amrith-setlur/ class=align-middle>Amrith Setlur</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tanmay-parekh/ class=align-middle>Tanmay Parekh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yiming-yang/ class=align-middle>Yiming Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ruslan-salakhutdinov/ class=align-middle>Ruslan Salakhutdinov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alan-w-black/ class=align-middle>Alan W. Black</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shrimai-prabhumoye/ class=align-middle>Shrimai Prabhumoye</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hai-pham/ class=align-middle>Hai Pham</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thomas-manzini/ class=align-middle>Thomas Manzini</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paul-pu-liang/ class=align-middle>Paul Pu Liang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/emmanouil-antonios-platanios/ class=align-middle>Emmanouil Antonios Platanios</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/otilia-stretcu/ class=align-middle>Otilia Stretcu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tom-mitchell/ class=align-middle>Tom Mitchell</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>