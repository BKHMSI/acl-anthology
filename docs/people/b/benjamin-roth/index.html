<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Benjamin Roth - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Benjamin</span> <span class=font-weight-bold>Roth</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.repl4nlp-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--repl4nlp-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.repl4nlp-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.repl4nlp-1.12" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.repl4nlp-1.12/>Knodle : Modular Weakly Supervised Learning with PyTorch<span class=acl-fixed-case>P</span>y<span class=acl-fixed-case>T</span>orch</a></strong><br><a href=/people/a/anastasiia-sedova/>Anastasiia Sedova</a>
|
<a href=/people/a/andreas-stephan/>Andreas Stephan</a>
|
<a href=/people/m/marina-speranskaya/>Marina Speranskaya</a>
|
<a href=/people/b/benjamin-roth/>Benjamin Roth</a><br><a href=/volumes/2021.repl4nlp-1/ class=text-muted>Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--repl4nlp-1--12><div class="card-body p-3 small">Strategies for improving the <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training and prediction quality</a> of weakly supervised machine learning models vary in how much they are tailored to a specific task or integrated with a specific model architecture. In this work, we introduce Knodle, a <a href=https://en.wikipedia.org/wiki/Software_framework>software framework</a> that treats weak data annotations, <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning models</a>, and methods for improving weakly supervised training as separate, modular components. This modularization gives the training process access to fine-grained information such as data set characteristics, matches of <a href=https://en.wikipedia.org/wiki/Heuristic_(computer_science)>heuristic rules</a>, or elements of the <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning model</a> ultimately used for prediction. Hence, our framework can encompass a wide range of training methods for improving weak supervision, ranging from methods that only look at correlations of rules and output classes (independently of the <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning model</a> trained with the resulting labels), to those that harness the interplay of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> and weakly labeled data. We illustrate the benchmarking potential of the <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> with a performance comparison of several reference implementations on a selection of datasets that are already available in Knodle.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.506.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--506 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.506 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.506/>UniSent : Universal Adaptable Sentiment Lexica for 1000 + Languages<span class=acl-fixed-case>U</span>ni<span class=acl-fixed-case>S</span>ent: Universal Adaptable Sentiment Lexica for 1000+ Languages</a></strong><br><a href=/people/e/ehsaneddin-asgari/>Ehsaneddin Asgari</a>
|
<a href=/people/f/fabienne-braune/>Fabienne Braune</a>
|
<a href=/people/b/benjamin-roth/>Benjamin Roth</a>
|
<a href=/people/c/christoph-ringlstetter/>Christoph Ringlstetter</a>
|
<a href=/people/m/mohammad-mofrad/>Mohammad Mofrad</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--506><div class="card-body p-3 small">In this paper, we introduce UniSent universal sentiment lexica for <a href=https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers>1000 + languages</a>. Sentiment lexica are vital for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> in absence of document-level annotations, a very common scenario for low-resource languages. To the best of our knowledge, UniSent is the largest sentiment resource to date in terms of the number of covered languages, including many low resource ones. In this work, we use a massively parallel Bible corpus to project <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment information</a> from <a href=https://en.wikipedia.org/wiki/English_language>English</a> to other languages for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> on <a href=https://en.wikipedia.org/wiki/Twitter>Twitter data</a>. We introduce a method called DomDrift to mitigate the huge domain mismatch between <a href=https://en.wikipedia.org/wiki/Bible>Bible</a> and <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> by a confidence weighting scheme that uses domain-specific embeddings to compare the <a href=https://en.wikipedia.org/wiki/Nearest_neighbor_search>nearest neighbors</a> for a candidate sentiment word in the source (Bible) and target (Twitter) domain. We evaluate the quality of UniSent in a subset of languages for which manually created ground truth was available, <a href=https://en.wikipedia.org/wiki/Macedonian_language>Macedonian</a>, <a href=https://en.wikipedia.org/wiki/Czech_language>Czech</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a>, <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, and <a href=https://en.wikipedia.org/wiki/French_language>French</a>. We show that the quality of UniSent is comparable to manually created sentiment resources when it is used as the sentiment seed for the task of word sentiment prediction on top of embedding representations. In addition, we show that emoticon sentiments could be reliably predicted in the Twitter domain using only UniSent and monolingual embeddings in <a href=https://en.wikipedia.org/wiki/German_language>German</a>, <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, <a href=https://en.wikipedia.org/wiki/French_language>French</a>, and <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a>. With the publication of this paper, we release the UniSent sentiment lexica at http://language-lab.info/unisent.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2600.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2600/>Proceedings of the Workshop on Extracting Structured Knowledge from Scientific Publications</a></strong><br><a href=/people/v/vivi-nastase/>Vivi Nastase</a>
|
<a href=/people/b/benjamin-roth/>Benjamin Roth</a>
|
<a href=/people/l/laura-dietz/>Laura Dietz</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a><br><a href=/volumes/W19-26/ class=text-muted>Proceedings of the Workshop on Extracting Structured Knowledge from Scientific Publications</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1488.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1488 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1488 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385215761 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1488/>Interpretable Question Answering on <a href=https://en.wikipedia.org/wiki/Knowledge_base>Knowledge Bases</a> and Text</a></strong><br><a href=/people/a/alona-sydorova/>Alona Sydorova</a>
|
<a href=/people/n/nina-poerner/>Nina Poerner</a>
|
<a href=/people/b/benjamin-roth/>Benjamin Roth</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1488><div class="card-body p-3 small">Interpretability of <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning (ML) models</a> becomes more relevant with their increasing adoption. In this work, we address the <a href=https://en.wikipedia.org/wiki/Interpretability>interpretability</a> of <a href=https://en.wikipedia.org/wiki/Question_answering>ML based question answering (QA) models</a> on a combination of <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge bases (KB)</a> and text documents. We adapt post hoc explanation methods such as LIME and input perturbation (IP) and compare them with the self-explanatory attention mechanism of the model. For this purpose, we propose an automatic evaluation paradigm for explanation methods in the context of <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA</a>. We also conduct a study with human annotators to evaluate whether explanations help them identify better QA models. Our results suggest that IP provides better explanations than LIME or <a href=https://en.wikipedia.org/wiki/Attention>attention</a>, according to both automatic and human evaluation. We obtain the same ranking of methods in both experiments, which supports the validity of our automatic evaluation paradigm.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1139.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1139 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1139 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1139/>Joint Aspect and Polarity Classification for Aspect-based Sentiment Analysis with End-to-End Neural Networks</a></strong><br><a href=/people/m/martin-schmitt/>Martin Schmitt</a>
|
<a href=/people/s/simon-steinheber/>Simon Steinheber</a>
|
<a href=/people/k/konrad-schreiber/>Konrad Schreiber</a>
|
<a href=/people/b/benjamin-roth/>Benjamin Roth</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1139><div class="card-body p-3 small">In this work, we propose a new <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> for aspect-based sentiment analysis. In contrast to previous approaches, we jointly model the <a href=https://en.wikipedia.org/wiki/Detection_theory>detection of aspects</a> and the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification of their polarity</a> in an end-to-end trainable neural network. We conduct experiments with different neural architectures and word representations on the recent GermEval 2017 dataset. We were able to show considerable performance gains by using the joint modeling approach in all settings compared to pipeline approaches. The combination of a <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural network</a> and fasttext embeddings outperformed the best submission of the shared task in 2017, establishing a new state of the art.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-1063.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-1063 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-1063 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/I17-1063.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/I17-1063/>Towards Bootstrapping a Polarity Shifter Lexicon using <a href=https://en.wikipedia.org/wiki/Linguistic_feature>Linguistic Features</a></a></strong><br><a href=/people/m/marc-schulder/>Marc Schulder</a>
|
<a href=/people/m/michael-wiegand/>Michael Wiegand</a>
|
<a href=/people/j/josef-ruppenhofer/>Josef Ruppenhofer</a>
|
<a href=/people/b/benjamin-roth/>Benjamin Roth</a><br><a href=/volumes/I17-1/ class=text-muted>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-1063><div class="card-body p-3 small">We present a major step towards the creation of the first high-coverage lexicon of polarity shifters. In this work, we bootstrap a lexicon of verbs by exploiting various <a href=https://en.wikipedia.org/wiki/Linguistic_feature>linguistic features</a>. Polarity shifters, such as abandon, are similar to negations (e.g. not) in that they move the polarity of a phrase towards its inverse, as in abandon all hope. While there exist lists of <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>negation words</a>, creating comprehensive lists of polarity shifters is far more challenging due to their sheer number. On a sample of manually annotated verbs we examine a variety of <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a> for this task. Then we build a <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised classifier</a> to increase <a href=https://en.wikipedia.org/wiki/Coverage_(statistics)>coverage</a>. We show that this approach drastically reduces the annotation effort while ensuring a high-precision lexicon. We also show that our acquired knowledge of verbal polarity shifters improves phrase-level sentiment analysis.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Benjamin+Roth" title="Search for 'Benjamin Roth' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/m/marc-schulder/ class=align-middle>Marc Schulder</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-wiegand/ class=align-middle>Michael Wiegand</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/josef-ruppenhofer/ class=align-middle>Josef Ruppenhofer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anastasiia-sedova/ class=align-middle>Anastasiia Sedova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andreas-stephan/ class=align-middle>Andreas Stephan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/m/marina-speranskaya/ class=align-middle>Marina Speranskaya</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/martin-schmitt/ class=align-middle>Martin Schmitt</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/simon-steinheber/ class=align-middle>Simon Steinheber</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/konrad-schreiber/ class=align-middle>Konrad Schreiber</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vivi-nastase/ class=align-middle>Vivi Nastase</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/laura-dietz/ class=align-middle>Laura Dietz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrew-mccallum/ class=align-middle>Andrew McCallum</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/ehsaneddin-asgari/ class=align-middle>Ehsaneddin Asgari</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fabienne-braune/ class=align-middle>Fabienne Braune</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christoph-ringlstetter/ class=align-middle>Christoph Ringlstetter</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mohammad-mofrad/ class=align-middle>Mohammad Mofrad</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alona-sydorova/ class=align-middle>Alona Sydorova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nina-poerner/ class=align-middle>Nina Poerner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/repl4nlp/ class=align-middle>RepL4NLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>