<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Bin Wang - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Bin</span> <span class=font-weight-bold>Wang</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.25.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--25 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.25 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.acl-long.25" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.25/><span class=acl-fixed-case>MISC</span>: A Mixed Strategy-Aware Model integrating <span class=acl-fixed-case>COMET</span> for Emotional Support Conversation</a></strong><br><a href=/people/q/quan-tu/>Quan Tu</a>
|
<a href=/people/y/yanran-li/>Yanran Li</a>
|
<a href=/people/j/jianwei-cui/>Jianwei Cui</a>
|
<a href=/people/b/bin-wang/>Bin Wang</a>
|
<a href=/people/j/ji-rong-wen/>Ji-Rong Wen</a>
|
<a href=/people/r/rui-yan/>Rui Yan</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--25><div class="card-body p-3 small">Applying existing methods to emotional support conversation&#8212;which provides valuable assistance to people who are in need&#8212;has two major limitations: (a) they generally employ a conversation-level emotion label, which is too coarse-grained to capture user&#8217;s instant mental state; (b) most of them focus on expressing empathy in the response(s) rather than gradually reducing user&#8217;s distress. To address the problems, we propose a novel model <tex-math>\\textbf{MISC}</tex-math>, which firstly infers the user&#8217;s fine-grained emotional status, and then responds skillfully using a mixture of strategy. Experimental results on the benchmark dataset demonstrate the effectiveness of our method and reveal the benefits of fine-grained emotion understanding as well as mixed-up strategy modeling.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.419.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--419 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.419 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.acl-long.419" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.419/>Just Rank Rethinking Evaluation with Word and Sentence Similarities</a></strong><br><a href=/people/b/bin-wang/>Bin Wang</a>
|
<a href=/people/c/c-c-kuo/>C.-c. Kuo</a>
|
<a href=/people/h/haizhou-li/>Haizhou Li</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--419><div class="card-body p-3 small">Word and sentence embeddings are useful feature representations in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> However intrinsic evaluation for <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> lags far behind and there has been no significant update since the past decade Word and sentence similarity tasks have become the de facto evaluation method It leads models to overfit to such <a href=https://en.wikipedia.org/wiki/Evaluation>evaluations</a> negatively impacting <a href=https://en.wikipedia.org/wiki/Embedding>embedding models</a> development This paper first points out the problems using <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic similarity</a> as the gold standard for word and sentence embedding evaluations Further we propose a new intrinsic evaluation method called EvalRank which shows a much stronger correlation with downstream tasks Extensive experiments are conducted based on models and popular datasets to certify our judgments Finally the practical evaluation toolkit is released for future benchmarking purposes</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.514.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--514 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.514 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938977 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.514" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.514/>Coarse-to-Fine Pre-training for Named Entity Recognition<span class=acl-fixed-case>C</span>oarse-to-<span class=acl-fixed-case>F</span>ine <span class=acl-fixed-case>P</span>re-training for <span class=acl-fixed-case>N</span>amed <span class=acl-fixed-case>E</span>ntity <span class=acl-fixed-case>R</span>ecognition</a></strong><br><a href=/people/x/xue-mengge/>Xue Mengge</a>
|
<a href=/people/b/bowen-yu/>Bowen Yu</a>
|
<a href=/people/z/zhenyu-zhang/>Zhenyu Zhang</a>
|
<a href=/people/t/tingwen-liu/>Tingwen Liu</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a>
|
<a href=/people/b/bin-wang/>Bin Wang</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--514><div class="card-body p-3 small">More recently, <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a> hasachieved great advances aided by pre-trainingapproaches such as <a href=https://en.wikipedia.org/wiki/BERT>BERT</a>. However, currentpre-training techniques focus on building lan-guage modeling objectives to learn a gen-eral representation, ignoring the named entity-related knowledge. To this end, we proposea NER-specific pre-training framework to in-ject coarse-to-fine automatically mined entityknowledge into pre-trained models. Specifi-cally, we first warm-up the model via an en-tity span identification task by training it withWikipedia anchors, which can be deemed asgeneral-typed entities. Then we leverage thegazetteer-based distant supervision strategy totrain the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> extract coarse-grained typedentities. Finally, we devise a self-supervisedauxiliary task to mine the fine-grained namedentity knowledge via clustering. Empiricalstudies on three public NER datasets demon-strate that our framework achieves significantimprovements against several pre-trained base-lines, establishing the new state-of-the-art per-formance on three benchmarks. Besides, weshow that our <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> gains promising re-sults without using human-labeled trainingdata, demonstrating its effectiveness in label-few and low-resource scenarios.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.autosimtrans-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--autosimtrans-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.autosimtrans-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929921 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.autosimtrans-1.5/>Modeling Discourse Structure for Document-level Neural Machine Translation</a></strong><br><a href=/people/j/junxuan-chen/>Junxuan Chen</a>
|
<a href=/people/x/xiang-li/>Xiang Li</a>
|
<a href=/people/j/jiarui-zhang/>Jiarui Zhang</a>
|
<a href=/people/c/chulun-zhou/>Chulun Zhou</a>
|
<a href=/people/j/jianwei-cui/>Jianwei Cui</a>
|
<a href=/people/b/bin-wang/>Bin Wang</a>
|
<a href=/people/j/jinsong-su/>Jinsong Su</a><br><a href=/volumes/2020.autosimtrans-1/ class=text-muted>Proceedings of the First Workshop on Automatic Simultaneous Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--autosimtrans-1--5><div class="card-body p-3 small">Recently, document-level neural machine translation (NMT) has become a hot topic in the community of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. Despite its success, most of existing studies ignored the discourse structure information of the input document to be translated, which has shown effective in other tasks. In this paper, we propose to improve document-level NMT with the aid of discourse structure information. Our <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> is based on a hierarchical attention network (HAN) (Miculicich et al., 2018). Specifically, we first parse the input document to obtain its discourse structure. Then, we introduce a Transformer-based path encoder to embed the discourse structure information of each word. Finally, we combine the discourse structure information with the <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a> before it is fed into the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a>. Experimental results on the English-to-German dataset show that our model can significantly outperform both Transformer and Transformer+HAN.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.semeval-1.86.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--semeval-1--86 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.semeval-1.86 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.semeval-1.86/>Lee at SemEval-2020 Task 5 : ALBERT Model Based on the Maximum Ensemble Strategy and Different Data Sampling Methods for Detecting Counterfactual Statements<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2020 Task 5: <span class=acl-fixed-case>ALBERT</span> Model Based on the Maximum Ensemble Strategy and Different Data Sampling Methods for Detecting Counterfactual Statements</a></strong><br><a href=/people/j/junyi-li/>Junyi Li</a>
|
<a href=/people/y/yuhang-wu/>Yuhang Wu</a>
|
<a href=/people/b/bin-wang/>Bin Wang</a>
|
<a href=/people/h/haiyan-ding/>Haiyan Ding</a><br><a href=/volumes/2020.semeval-1/ class=text-muted>Proceedings of the Fourteenth Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--semeval-1--86><div class="card-body p-3 small">This article describes the system submitted to SemEval 2020 Task 5 : Modelling Causal Reasoning in Language : Detecting Counterfactuals. In this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, we only participate in the subtask A which is detecting counterfactual statements. In order to solve this sub-task, first of all, because of the problem of data balance, we use the undersampling and oversampling methods to process the data set. Second, we used the ALBERT model and the maximum ensemble method based on the ALBERT model. Our <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> achieved a F1 score of 0.85 in subtask A.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.341.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--341 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.341 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.341/>Learning to Prune Dependency Trees with Rethinking for Neural Relation Extraction</a></strong><br><a href=/people/b/bowen-yu/>Bowen Yu</a>
|
<a href=/people/x/xue-mengge/>Xue Mengge</a>
|
<a href=/people/z/zhenyu-zhang/>Zhenyu Zhang</a>
|
<a href=/people/t/tingwen-liu/>Tingwen Liu</a>
|
<a href=/people/w/wang-yubin/>Wang Yubin</a>
|
<a href=/people/b/bin-wang/>Bin Wang</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--341><div class="card-body p-3 small">Dependency trees have been shown to be effective in capturing long-range relations between target entities. Nevertheless, how to selectively emphasize target-relevant information and remove irrelevant content from the <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>tree</a> is still an open problem. Existing approaches employing pre-defined rules to eliminate <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a> may not always yield optimal results due to the <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a> and variability of natural language. In this paper, we present a novel architecture named Dynamically Pruned Graph Convolutional Network (DP-GCN), which learns to prune the dependency tree with rethinking in an end-to-end scheme. In each layer of DP-GCN, we employ a selection module to concentrate on nodes expressing the target relation by a set of binary gates, and then augment the pruned tree with a pruned semantic graph to ensure the connectivity. After that, we introduce a rethinking mechanism to guide and refine the pruning operation by feeding back the high-level learned features repeatedly. Extensive experimental results demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves impressive results compared to strong <a href=https://en.wikipedia.org/wiki/Competition>competitors</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-2095.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S19-2095 data-toggle=collapse aria-expanded=false aria-controls=abstract-S19-2095 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-2095/>YNU NLP at SemEval-2019 Task 5 : Attention and Capsule Ensemble for Identifying Hate Speech<span class=acl-fixed-case>YNU</span> <span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2019 Task 5: Attention and Capsule Ensemble for Identifying Hate Speech</a></strong><br><a href=/people/b/bin-wang/>Bin Wang</a>
|
<a href=/people/h/haiyan-ding/>Haiyan Ding</a><br><a href=/volumes/S19-2/ class=text-muted>Proceedings of the 13th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S19-2095><div class="card-body p-3 small">This paper describes the system submitted to SemEval 2019 Task 5 : Multilingual detection of hate speech against immigrants and women in Twitter (hatEval). Its main purpose is to conduct hate speech detection on <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>, which mainly includes two specific different targets, immigrants and women. We participate in both subtask A and subtask B for <a href=https://en.wikipedia.org/wiki/English_language>English</a>. In order to address this task, we develope an ensemble of an attention-LSTM model based on HAN and an BiGRU-capsule model. Both <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> use fastText pre-trained embeddings, and we use this model in both subtasks. In comparison to other participating teams, our system is ranked 16th in the Sub-task A for <a href=https://en.wikipedia.org/wiki/English_language>English</a>, and 12th in the Sub-task B for <a href=https://en.wikipedia.org/wiki/English_language>English</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-2143.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S19-2143 data-toggle=collapse aria-expanded=false aria-controls=abstract-S19-2143 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-2143/>YNUWB at SemEval-2019 Task 6 : K-max pooling CNN with average meta-embedding for identifying offensive language<span class=acl-fixed-case>YNUWB</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2019 Task 6: K-max pooling <span class=acl-fixed-case>CNN</span> with average meta-embedding for identifying offensive language</a></strong><br><a href=/people/b/bin-wang/>Bin Wang</a>
|
<a href=/people/x/xiaobing-zhou/>Xiaobing Zhou</a>
|
<a href=/people/x/xuejie-zhang/>Xuejie Zhang</a><br><a href=/volumes/S19-2/ class=text-muted>Proceedings of the 13th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S19-2143><div class="card-body p-3 small">This paper describes the <a href=https://en.wikipedia.org/wiki/System>system</a> submitted to SemEval 2019 Task 6 : OffensEval 2019. The task aims to identify and categorize <a href=https://en.wikipedia.org/wiki/Profanity>offensive language</a> in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, we only participate in Sub-task A, which aims to identify <a href=https://en.wikipedia.org/wiki/Profanity>offensive language</a>. In order to address this task, we propose a system based on a K-max pooling convolutional neural network model, and use an argument for averaging as a valid meta-embedding technique to get a metaembedding. Finally, we also use a cyclic learning rate policy to improve <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performance. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves a Macro F1-score of 0.802 (ranked 9/103) in the Sub-task A.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/U19-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-U19-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-U19-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/U19-1024/>An Improved Coarse-to-Fine Method for Solving Generation Tasks</a></strong><br><a href=/people/w/wenyv-guan/>Wenyv Guan</a>
|
<a href=/people/q/qianying-liu/>Qianying Liu</a>
|
<a href=/people/g/guangzhi-han/>Guangzhi Han</a>
|
<a href=/people/b/bin-wang/>Bin Wang</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a><br><a href=/volumes/U19-1/ class=text-muted>Proceedings of the The 17th Annual Workshop of the Australasian Language Technology Association</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-U19-1024><div class="card-body p-3 small">The coarse-to-fine (coarse2fine) methods have recently been widely used in the generation tasks. The methods first generate a rough sketch in the coarse stage and then use the sketch to get the final result in the fine stage. However, <a href=https://en.wikipedia.org/wiki/They_(2017_film)>they</a> usually lack the correction ability when getting a wrong sketch. To solve this problem, in this paper, we propose an improved coarse2fine model with a control mechanism, with which our method can control the influence of the sketch on the final results in the fine stage. Even if the sketch is wrong, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> still has the opportunity to get a correct result. We have experimented our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> on the tasks of <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> and math word problem solving. The results have shown the effectiveness of our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1103.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1103 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1103 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/353480570 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-1103/>Adaptive Convolution for Multi-Relational Learning</a></strong><br><a href=/people/x/xiaotian-jiang/>Xiaotian Jiang</a>
|
<a href=/people/q/quan-wang/>Quan Wang</a>
|
<a href=/people/b/bin-wang/>Bin Wang</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1103><div class="card-body p-3 small">We consider the problem of learning <a href=https://en.wikipedia.org/wiki/Distributed_representation>distributed representations</a> for entities and relations of multi-relational data so as to predict missing links therein. Convolutional neural networks have recently shown their superiority for this <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a>, bringing increased model expressiveness while remaining parameter efficient. Despite the success, previous convolution designs fail to model full interactions between input entities and relations, which potentially limits the performance of link prediction. In this work we introduce ConvR, an adaptive convolutional network designed to maximize entity-relation interactions in a convolutional fashion. ConvR adaptively constructs convolution filters from <a href=https://en.wikipedia.org/wiki/Binary_relation>relation representations</a>, and applies these filters across <a href=https://en.wikipedia.org/wiki/Binary_relation>entity representations</a> to generate <a href=https://en.wikipedia.org/wiki/Convolution>convolutional features</a>. As such, ConvR enables rich interactions between entity and relation representations at diverse regions, and all the <a href=https://en.wikipedia.org/wiki/Convolution>convolutional features</a> generated will be able to capture such <a href=https://en.wikipedia.org/wiki/Interaction>interactions</a>. We evaluate ConvR on multiple benchmark datasets. Experimental results show that : (1) ConvR performs substantially better than competitive baselines in almost all the metrics and on all the datasets ; (2) Compared with state-of-the-art convolutional models, ConvR is not only more effective but also more efficient. It offers a 7 % increase in MRR and a 6 % increase in Hits@10, while saving 12 % in parameter storage.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Bin+Wang" title="Search for 'Bin Wang' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/x/xue-mengge/ class=align-middle>Xue Mengge</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/bowen-yu/ class=align-middle>Bowen Yu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/zhenyu-zhang/ class=align-middle>Zhenyu Zhang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/tingwen-liu/ class=align-middle>Tingwen Liu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jianwei-cui/ class=align-middle>Jianwei Cui</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/h/haiyan-ding/ class=align-middle>Haiyan Ding</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yue-zhang/ class=align-middle>Yue Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/quan-tu/ class=align-middle>Quan Tu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yanran-li/ class=align-middle>Yanran Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/ji-rong-wen/ class=align-middle>Ji-Rong Wen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rui-yan/ class=align-middle>Rui Yan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/c-c-kuo/ class=align-middle>C.-c. Kuo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haizhou-li/ class=align-middle>Haizhou Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/junxuan-chen/ class=align-middle>Junxuan Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiang-li/ class=align-middle>Xiang Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiarui-zhang/ class=align-middle>Jiarui Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chulun-zhou/ class=align-middle>Chulun Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jinsong-su/ class=align-middle>Jinsong Su</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/junyi-li/ class=align-middle>Junyi Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yuhang-wu/ class=align-middle>Yuhang Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaobing-zhou/ class=align-middle>Xiaobing Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xuejie-zhang/ class=align-middle>Xuejie Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wang-yubin/ class=align-middle>Wang Yubin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wenyv-guan/ class=align-middle>Wenyv Guan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qianying-liu/ class=align-middle>Qianying Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/guangzhi-han/ class=align-middle>Guangzhi Han</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sujian-li/ class=align-middle>Sujian Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaotian-jiang/ class=align-middle>Xiaotian Jiang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/quan-wang/ class=align-middle>Quan Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/autosimtrans/ class=align-middle>AutoSimTrans</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/alta/ class=align-middle>ALTA</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>