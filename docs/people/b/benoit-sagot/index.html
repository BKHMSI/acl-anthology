<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Benoît Sagot - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Benoît</span> <span class=font-weight-bold>Sagot</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.47.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--47 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.47 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.47/>Can Character-based Language Models Improve Downstream Task Performances In Low-Resource And Noisy Language Scenarios?</a></strong><br><a href=/people/a/arij-riabi/>Arij Riabi</a>
|
<a href=/people/b/benoit-sagot/>Benoît Sagot</a>
|
<a href=/people/d/djame-seddah/>Djamé Seddah</a><br><a href=/volumes/2021.wnut-1/ class=text-muted>Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--47><div class="card-body p-3 small">Recent impressive improvements in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, largely based on the success of contextual neural language models, have been mostly demonstrated on at most a couple dozen high- resource languages. Building language mod- els and, more generally, NLP systems for non- standardized and low-resource languages remains a challenging task. In this work, we fo- cus on North-African colloquial dialectal Arabic written using an extension of the <a href=https://en.wikipedia.org/wiki/Latin_script>Latin script</a>, called NArabizi, found mostly on social media and messaging communication. In this low-resource scenario with data display- ing a high level of variability, we compare the downstream performance of a character-based language model on <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a> and dependency parsing to that of monolingual and multilingual models. We show that a character-based model trained on only 99k sentences of NArabizi and fined-tuned on a small treebank of this language leads to performance close to those obtained with the same architecture pre- trained on large multilingual and monolingual models. Confirming these results a on much larger data set of noisy French user-generated content, we argue that such character-based language models can be an asset for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> in low-resource and high language variability set- tings.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4hala-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lt4hala-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lt4hala-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.lt4hala-1.12" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.lt4hala-1.12/>Comparing Statistical and Neural Models for Learning Sound Correspondences</a></strong><br><a href=/people/c/clementine-fourrier/>Clémentine Fourrier</a>
|
<a href=/people/b/benoit-sagot/>Benoît Sagot</a><br><a href=/volumes/2020.lt4hala-1/ class=text-muted>Proceedings of LT4HALA 2020 - 1st Workshop on Language Technologies for Historical and Ancient Languages</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lt4hala-1--12><div class="card-body p-3 small">Cognate prediction and proto-form reconstruction are key tasks in computational historical linguistics that rely on the study of sound change regularity. Solving these tasks appears to be very similar to <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, though methods from that field have barely been applied to <a href=https://en.wikipedia.org/wiki/Historical_linguistics>historical linguistics</a>. Therefore, in this paper, we investigate the learnability of sound correspondences between a proto-language and daughter languages for two machine-translation-inspired models, one statistical, the other neural. We first carry out our experiments on plausible artificial languages, without <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a>, in order to study the role of each parameter on the algorithms respective performance under almost perfect conditions. We then study real languages, namely <a href=https://en.wikipedia.org/wiki/Latin>Latin</a>, <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a> and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, to see if those performances generalise well. We show that both model types manage to learn sound changes despite data scarcity, although the best performing model type depends on several parameters such as the size of the training data, the ambiguity, and the prediction direction.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-2023.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K18-2023 data-toggle=collapse aria-expanded=false aria-controls=abstract-K18-2023 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K18-2023/>ELMoLex : Connecting ELMo and Lexicon Features for Dependency Parsing<span class=acl-fixed-case>ELM</span>o<span class=acl-fixed-case>L</span>ex: Connecting <span class=acl-fixed-case>ELM</span>o and Lexicon Features for Dependency Parsing</a></strong><br><a href=/people/g/ganesh-jawahar/>Ganesh Jawahar</a>
|
<a href=/people/b/benjamin-muller/>Benjamin Muller</a>
|
<a href=/people/a/amal-fethi/>Amal Fethi</a>
|
<a href=/people/l/louis-martin/>Louis Martin</a>
|
<a href=/people/e/eric-villemonte-de-la-clergerie/>Éric Villemonte de la Clergerie</a>
|
<a href=/people/b/benoit-sagot/>Benoît Sagot</a>
|
<a href=/people/d/djame-seddah/>Djamé Seddah</a><br><a href=/volumes/K18-2/ class=text-muted>Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K18-2023><div class="card-body p-3 small">In this paper, we present the details of the neural dependency parser and the neural tagger submitted by our team &#8216;ParisNLP&#8217; to the CoNLL 2018 Shared Task on parsing from raw text to Universal Dependencies. We augment the deep Biaffine (BiAF) parser (Dozat and Manning, 2016) with novel features to perform competitively : we utilize an indomain version of ELMo features (Peters et al., 2018) which provide context-dependent word representations ; we utilize disambiguated, embedded, morphosyntactic features from lexicons (Sagot, 2018), which complements the existing feature set. Henceforth, we call our <a href=https://en.wikipedia.org/wiki/System>system</a> &#8216;ELMoLex&#8217;. In addition to incorporating character embeddings, ELMoLex benefits from pre-trained word vectors, ELMo and morphosyntactic features (whenever available) to correctly handle rare or unknown words which are prevalent in languages with complex morphology. ELMoLex ranked 11th by Labeled Attachment Score metric (70.64 %), Morphology-aware LAS metric (55.74 %) and ranked 9th by Bilexical dependency metric (60.70 %).</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3026.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3026 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3026 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3026/>The ParisNLP entry at the ConLL UD Shared Task 2017 : A Tale of a # ParsingTragedy<span class=acl-fixed-case>P</span>aris<span class=acl-fixed-case>NLP</span> entry at the <span class=acl-fixed-case>C</span>on<span class=acl-fixed-case>LL</span> <span class=acl-fixed-case>UD</span> Shared Task 2017: A Tale of a #<span class=acl-fixed-case>P</span>arsing<span class=acl-fixed-case>T</span>ragedy</a></strong><br><a href=/people/e/eric-villemonte-de-la-clergerie/>Éric de La Clergerie</a>
|
<a href=/people/b/benoit-sagot/>Benoît Sagot</a>
|
<a href=/people/d/djame-seddah/>Djamé Seddah</a><br><a href=/volumes/K17-3/ class=text-muted>Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3026><div class="card-body p-3 small">We present the ParisNLP entry at the UD CoNLL 2017 parsing shared task. In addition to the UDpipe models provided, we built our own data-driven tokenization models, sentence segmenter and lexicon-based morphological analyzers. All of these were used with a range of different parsing models (neural or not, feature-rich or not, transition or graph-based, etc.) and the best combination for each language was selected. Unfortunately, a glitch in the shared task&#8217;s Matrix led our model selector to run generic, weakly lexicalized models, tailored for surprise languages, instead of our dataset-specific models. Because of this # ParsingTragedy, we officially ranked 27th, whereas our real models finally unofficially ranked 6th.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-0805.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-0805 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-0805 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-0805" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-0805/>Annotating omission in statement pairs</a></strong><br><a href=/people/h/hector-martinez-alonso/>Héctor Martínez Alonso</a>
|
<a href=/people/a/amaury-delamaire/>Amaury Delamaire</a>
|
<a href=/people/b/benoit-sagot/>Benoît Sagot</a><br><a href=/volumes/W17-08/ class=text-muted>Proceedings of the 11th Linguistic Annotation Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-0805><div class="card-body p-3 small">We focus on the identification of omission in statement pairs. We compare three <a href=https://en.wikipedia.org/wiki/Crowdsourcing>annotation schemes</a>, namely two different <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing schemes</a> and <a href=https://en.wikipedia.org/wiki/Crowdsourcing>manual expert annotation</a>. We show that the simplest of the two crowdsourcing approaches yields a better annotation quality than the more complex one. We use a dedicated <a href=https://en.wikipedia.org/wiki/Classifier_(linguistics)>classifier</a> to assess whether the annotators&#8217; behavior can be explained by straightforward <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a>. The <a href=https://en.wikipedia.org/wiki/Classifier_(linguistics)>classifier</a> benefits from a <a href=https://en.wikipedia.org/wiki/Conceptual_model>modeling</a> that uses lexical information beyond length and overlap measures. However, for our task, we argue that expert and not crowdsourcing-based annotation is the best compromise between annotation cost and <a href=https://en.wikipedia.org/wiki/Quality_(business)>quality</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2212.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2212 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2212 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2212/>Speeding up corpus development for linguistic research : <a href=https://en.wikipedia.org/wiki/Language_documentation>language documentation</a> and acquisition in Romansh Tuatschin<span class=acl-fixed-case>R</span>omansh Tuatschin</a></strong><br><a href=/people/g/geraldine-walther/>Géraldine Walther</a>
|
<a href=/people/b/benoit-sagot/>Benoît Sagot</a><br><a href=/volumes/W17-22/ class=text-muted>Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2212><div class="card-body p-3 small">In this paper, we present ongoing work for developing language resources and basic NLP tools for an undocumented variety of Romansh, in the context of a language documentation and language acquisition project. Our tools are meant to improve the speed and reliability of corpus annotations for noisy data involving large amounts of <a href=https://en.wikipedia.org/wiki/Code-switching>code-switching</a>, occurrences of child-speech and orthographic noise. Being able to increase the efficiency of language resource development for language documentation and acquisition research also constitutes a step towards solving the data sparsity issues with which researchers have been struggling.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Beno%C3%AEt+Sagot" title="Search for 'Benoît Sagot' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/d/djame-seddah/ class=align-middle>Djamé Seddah</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/e/eric-villemonte-de-la-clergerie/ class=align-middle>Éric Villemonte de la Clergerie</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hector-martinez-alonso/ class=align-middle>Héctor Martínez Alonso</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/amaury-delamaire/ class=align-middle>Amaury Delamaire</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/geraldine-walther/ class=align-middle>Géraldine Walther</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/c/clementine-fourrier/ class=align-middle>Clémentine Fourrier</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/arij-riabi/ class=align-middle>Arij Riabi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/ganesh-jawahar/ class=align-middle>Ganesh Jawahar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/benjamin-muller/ class=align-middle>Benjamin Muller</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/amal-fethi/ class=align-middle>Amal Fethi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/louis-martin/ class=align-middle>Louis Martin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/lt4hala/ class=align-middle>LT4HALA</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wnut/ class=align-middle>WNUT</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>