<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Nelson F. Liu - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Nelson F.</span> <span class=font-weight-bold>Liu</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Nelson <span class=font-weight-normal>Liu</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mwe-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mwe-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mwe-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.mwe-1.6.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.mwe-1.6" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.mwe-1.6/>Lexical Semantic Recognition</a></strong><br><a href=/people/n/nelson-f-liu/>Nelson F. Liu</a>
|
<a href=/people/d/daniel-hershcovich/>Daniel Hershcovich</a>
|
<a href=/people/m/michael-kranzlein/>Michael Kranzlein</a>
|
<a href=/people/n/nathan-schneider/>Nathan Schneider</a><br><a href=/volumes/2021.mwe-1/ class=text-muted>Proceedings of the 17th Workshop on Multiword Expressions (MWE 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mwe-1--6><div class="card-body p-3 small">In <a href=https://en.wikipedia.org/wiki/Lexical_semantics>lexical semantics</a>, full-sentence segmentation and segment labeling of various <a href=https://en.wikipedia.org/wiki/Phenomenon>phenomena</a> are generally treated separately, despite their interdependence. We hypothesize that a unified lexical semantic recognition task is an effective way to encapsulate previously disparate styles of <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a>, including multiword expression identification / classification and supersense tagging. Using the STREUSLE corpus, we train a neural CRF sequence tagger and evaluate its performance along various axes of annotation. As the label set generalizes that of previous tasks (PARSEME, DiMSUM), we additionally evaluate how well the model generalizes to those test sets, finding that it approaches or surpasses existing models despite training only on STREUSLE. Our work also establishes <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline models</a> and evaluation metrics for integrated and accurate modeling of <a href=https://en.wikipedia.org/wiki/Lexical_semantics>lexical semantics</a>, facilitating future work in this area.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-srw.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-srw.0/>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop</a></strong><br><a href=/people/e/esin-durmus/>Esin Durmus</a>
|
<a href=/people/v/vivek-gupta/>Vivek Gupta</a>
|
<a href=/people/n/nelson-f-liu/>Nelson Liu</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/y/yu-su/>Yu Su</a><br><a href=/volumes/2021.naacl-srw/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlposs-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nlposs-1.0/>Proceedings of Second Workshop for NLP Open Source Software (NLP-OSS)</a></strong><br><a href=/people/e/eunjeong-l-park/>Eunjeong L. Park</a>
|
<a href=/people/m/masato-hagiwara/>Masato Hagiwara</a>
|
<a href=/people/d/dmitrijs-milajevs/>Dmitrijs Milajevs</a>
|
<a href=/people/n/nelson-f-liu/>Nelson F. Liu</a>
|
<a href=/people/g/geeticka-chauhan/>Geeticka Chauhan</a>
|
<a href=/people/l/liling-tan/>Liling Tan</a><br><a href=/volumes/2020.nlposs-1/ class=text-muted>Proceedings of Second Workshop for NLP Open Source Software (NLP-OSS)</a></span></p><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-1206.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-1206 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-1206 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-1206/>Discovering Phonesthemes with Sparse Regularization</a></strong><br><a href=/people/n/nelson-f-liu/>Nelson F. Liu</a>
|
<a href=/people/g/gina-anne-levow/>Gina-Anne Levow</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a><br><a href=/volumes/W18-12/ class=text-muted>Proceedings of the Second Workshop on Subword/Character LEvel Models</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-1206><div class="card-body p-3 small">We introduce a simple method for extracting non-arbitrary form-meaning representations from a collection of semantic vectors. We treat the problem as one of <a href=https://en.wikipedia.org/wiki/Feature_selection>feature selection</a> for a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> trained to predict word vectors from subword features. We apply this model to the problem of automatically discovering phonesthemes, which are submorphemic sound clusters that appear in words with similar meaning. Many of our model-predicted phonesthemes overlap with those proposed in the linguistics literature, and we validate our approach with human judgments.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-2501.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-2501 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-2501 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-2501" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-2501/>AllenNLP : A Deep Semantic Natural Language Processing Platform<span class=acl-fixed-case>A</span>llen<span class=acl-fixed-case>NLP</span>: A Deep Semantic Natural Language Processing Platform</a></strong><br><a href=/people/m/matt-gardner/>Matt Gardner</a>
|
<a href=/people/j/joel-grus/>Joel Grus</a>
|
<a href=/people/m/mark-neumann/>Mark Neumann</a>
|
<a href=/people/o/oyvind-tafjord/>Oyvind Tafjord</a>
|
<a href=/people/p/pradeep-dasigi/>Pradeep Dasigi</a>
|
<a href=/people/n/nelson-f-liu/>Nelson F. Liu</a>
|
<a href=/people/m/matthew-e-peters/>Matthew Peters</a>
|
<a href=/people/m/michael-schmitz/>Michael Schmitz</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a><br><a href=/volumes/W18-25/ class=text-muted>Proceedings of Workshop for NLP Open Source Software (NLP-OSS)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-2501><div class="card-body p-3 small">Modern natural language processing (NLP) research requires writing code. Ideally this <a href=https://en.wikipedia.org/wiki/Source_code>code</a> would provide a precise definition of the approach, easy repeatability of results, and a basis for extending the <a href=https://en.wikipedia.org/wiki/Research>research</a>. However, many research codebases bury high-level parameters under implementation details, are challenging to run and debug, and are difficult enough to extend that they are more likely to be rewritten. This paper describes AllenNLP, a library for applying deep learning methods to NLP research that addresses these issues with easy-to-use command-line tools, declarative configuration-driven experiments, and modular NLP abstractions. AllenNLP has already increased the rate of research experimentation and the sharing of NLP components at the Allen Institute for Artificial Intelligence, and we are working to have the same impact across the field.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3024 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3024/>LSTMs Exploit Linguistic Attributes of Data<span class=acl-fixed-case>LSTM</span>s Exploit Linguistic Attributes of Data</a></strong><br><a href=/people/n/nelson-f-liu/>Nelson F. Liu</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a>
|
<a href=/people/r/roy-schwartz/>Roy Schwartz</a>
|
<a href=/people/c/chenhao-tan/>Chenhao Tan</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a><br><a href=/volumes/W18-30/ class=text-muted>Proceedings of The Third Workshop on Representation Learning for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3024><div class="card-body p-3 small">While <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural networks</a> have found success in a variety of natural language processing applications, they are general models of sequential data. We investigate how the properties of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language data</a> affect an LSTM&#8217;s ability to learn a nonlinguistic task : recalling elements from its input. We find that <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on natural language data are able to recall tokens from much longer sequences than <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on non-language sequential data. Furthermore, we show that the LSTM learns to solve the memorization task by explicitly using a subset of its <a href=https://en.wikipedia.org/wiki/Neuron>neurons</a> to count timesteps in the input. We hypothesize that the patterns and structure in natural language data enable LSTMs to learn by providing approximate ways of reducing loss, but understanding the effect of different <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data</a> on the learnability of LSTMs remains an open question.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4413.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4413 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4413 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4413/>Crowdsourcing Multiple Choice Science Questions</a></strong><br><a href=/people/j/johannes-welbl/>Johannes Welbl</a>
|
<a href=/people/n/nelson-f-liu/>Nelson F. Liu</a>
|
<a href=/people/m/matt-gardner/>Matt Gardner</a><br><a href=/volumes/W17-44/ class=text-muted>Proceedings of the 3rd Workshop on Noisy User-generated Text</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4413><div class="card-body p-3 small">We present a novel method for obtaining high-quality, domain-targeted multiple choice questions from crowd workers. Generating these questions can be difficult without trading away originality, <a href=https://en.wikipedia.org/wiki/Relevance>relevance</a> or diversity in the answer options. Our method addresses these problems by leveraging a large corpus of domain-specific text and a small set of existing questions. It produces model suggestions for document selection and answer distractor choice which aid the human question generation process. With this <a href=https://en.wikipedia.org/wiki/Methodology>method</a> we have assembled SciQ, a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 13.7 K multiple choice science exam questions. We demonstrate that the method produces in-domain questions by providing an analysis of this new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and by showing that humans can not distinguish the crowdsourced questions from original questions. When using SciQ as additional training data to existing questions, we observe accuracy improvements on real science exams.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Nelson+F.+Liu" title="Search for 'Nelson F. Liu' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/m/matt-gardner/ class=align-middle>Matt Gardner</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/n/noah-a-smith/ class=align-middle>Noah A. Smith</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/daniel-hershcovich/ class=align-middle>Daniel Hershcovich</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-kranzlein/ class=align-middle>Michael Kranzlein</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nathan-schneider/ class=align-middle>Nathan Schneider</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/j/johannes-welbl/ class=align-middle>Johannes Welbl</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eunjeong-l-park/ class=align-middle>Eunjeong L. Park</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/masato-hagiwara/ class=align-middle>Masato Hagiwara</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dmitrijs-milajevs/ class=align-middle>Dmitrijs Milajevs</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/geeticka-chauhan/ class=align-middle>Geeticka Chauhan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/liling-tan/ class=align-middle>Liling Tan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/esin-durmus/ class=align-middle>Esin Durmus</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vivek-gupta/ class=align-middle>Vivek Gupta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nanyun-peng/ class=align-middle>Nanyun Peng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yu-su/ class=align-middle>Yu Su</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gina-anne-levow/ class=align-middle>Gina-Anne Levow</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joel-grus/ class=align-middle>Joel Grus</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mark-neumann/ class=align-middle>Mark Neumann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/oyvind-tafjord/ class=align-middle>Oyvind Tafjord</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pradeep-dasigi/ class=align-middle>Pradeep Dasigi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/matthew-e-peters/ class=align-middle>Matthew E. Peters</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-schmitz/ class=align-middle>Michael Schmitz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luke-zettlemoyer/ class=align-middle>Luke Zettlemoyer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/omer-levy/ class=align-middle>Omer Levy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/roy-schwartz/ class=align-middle>Roy Schwartz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chenhao-tan/ class=align-middle>Chenhao Tan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/mwe/ class=align-middle>MWE</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/nlposs/ class=align-middle>NLPOSS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>