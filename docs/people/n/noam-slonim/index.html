<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Noam Slonim - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Noam</span> <span class=font-weight-bold>Slonim</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.262.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--262 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.262 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.acl-long.262.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.acl-long.262/>Every Bite Is an Experience : Key Point Analysis of Business Reviews<span class=acl-fixed-case>K</span>ey <span class=acl-fixed-case>P</span>oint <span class=acl-fixed-case>A</span>nalysis of Business Reviews</a></strong><br><a href=/people/r/roy-bar-haim/>Roy Bar-Haim</a>
|
<a href=/people/l/lilach-eden/>Lilach Eden</a>
|
<a href=/people/y/yoav-kantor/>Yoav Kantor</a>
|
<a href=/people/r/roni-friedman/>Roni Friedman</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--262><div class="card-body p-3 small">Previous work on review summarization focused on measuring the sentiment toward the main aspects of the reviewed product or business, or on creating a textual summary. These approaches provide only a partial view of the data : aspect-based sentiment summaries lack sufficient explanation or justification for the aspect rating, while textual summaries do not quantify the significance of each element, and are not well-suited for representing conflicting views. Recently, Key Point Analysis (KPA) has been proposed as a summarization framework that provides both textual and quantitative summary of the main points in the data. We adapt KPA to review data by introducing Collective Key Point Mining for better key point extraction ; integrating <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> into KPA ; identifying good key point candidates for review summaries ; and leveraging the massive amount of available reviews and their metadata. We show empirically that these novel extensions of <a href=https://en.wikipedia.org/wiki/KPA>KPA</a> substantially improve its performance. We demonstrate that promising results can be achieved without any domain-specific annotation, while human supervision can lead to further improvement.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-tutorials.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-tutorials--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-tutorials.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-tutorials.1/>Advances in Debating Technologies : Building AI That Can Debate Humans<span class=acl-fixed-case>AI</span> That Can Debate Humans</a></strong><br><a href=/people/r/roy-bar-haim/>Roy Bar-Haim</a>
|
<a href=/people/l/liat-ein-dor/>Liat Ein-Dor</a>
|
<a href=/people/m/matan-orbach/>Matan Orbach</a>
|
<a href=/people/e/elad-venezian/>Elad Venezian</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/2021.acl-tutorials/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Tutorial Abstracts</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-tutorials--1><div class="card-body p-3 small">The tutorial focuses on Debating Technologies, a sub-field of computational argumentation defined as computational technologies developed directly to enhance, support, and engage with human debating (Gurevych et al., 2016). A recent milestone in this field is <a href=https://en.wikipedia.org/wiki/Project_Debater>Project Debater</a>, which was revealed in 2019 as the first AI system that can debate human experts on complex topics. Project Debater is the third in the series of IBM Research AI&#8217;s grand challenges, following Deep Blue and Watson. It has been developed for over six years by a large team of researchers and engineers, and its live demonstration in February 2019 received massive media attention. This research effort has resulted in more than 50 scientific papers to date, and many datasets freely available for research purposes. We discuss the scientific challenges that arise when building such a system, including <a href=https://en.wikipedia.org/wiki/Argument_mining>argument mining</a>, argument quality assessment, stance classification, principled argument detection, narrative generation, and rebutting a human opponent. Many of the underlying capabilities of <a href=https://en.wikipedia.org/wiki/Project_Debater>Project Debater</a> have been made freely available for academic research, and the tutorial will include a detailed explanation of how to use and leverage these tools. In addition to discussing individual components, the tutorial also provides a holistic view of a <a href=https://en.wikipedia.org/wiki/Debate>debating system</a>. Such a view is largely missing in the academic literature, where each paper typically addresses a specific problem in isolation. We present a complete pipeline of a <a href=https://en.wikipedia.org/wiki/Debate>debating system</a>, and discuss the <a href=https://en.wikipedia.org/wiki/Information_flow>information flow</a> and the interaction between the various components. Finally, we discuss practical applications and future challenges of debating technologies.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939172 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.3" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.3/>Quantitative argument summarization and beyond : Cross-domain key point analysis</a></strong><br><a href=/people/r/roy-bar-haim/>Roy Bar-Haim</a>
|
<a href=/people/y/yoav-kantor/>Yoav Kantor</a>
|
<a href=/people/l/lilach-eden/>Lilach Eden</a>
|
<a href=/people/r/roni-friedman/>Roni Friedman</a>
|
<a href=/people/d/dan-lahav/>Dan Lahav</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--3><div class="card-body p-3 small">When summarizing a collection of views, arguments or opinions on some topic, it is often desirable not only to extract the most salient points, but also to quantify their prevalence. Work on <a href=https://en.wikipedia.org/wiki/Multi-document_summarization>multi-document summarization</a> has traditionally focused on creating textual summaries, which lack this quantitative aspect. Recent work has proposed to summarize arguments by mapping them to a small set of expert-generated key points, where the salience of each key point corresponds to the number of its matching arguments. The current work advances key point analysis in two important respects : first, we develop a method for automatic extraction of key points, which enables fully automatic analysis, and is shown to achieve performance comparable to a human expert. Second, we demonstrate that the applicability of key point analysis goes well beyond <a href=https://en.wikipedia.org/wiki/Argumentation_theory>argumentation data</a>. Using <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on publicly available argumentation datasets, we achieve promising results in two additional domains : <a href=https://en.wikipedia.org/wiki/Survey_methodology>municipal surveys</a> and <a href=https://en.wikipedia.org/wiki/User_review>user reviews</a>. An additional contribution is an in-depth evaluation of argument-to-key point matching models, where we substantially outperform previous results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.633.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--633 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.633 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928964 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.633/>Out of the Echo Chamber : Detecting Countering Debate Speeches<span class=acl-fixed-case>D</span>etecting Countering Debate Speeches</a></strong><br><a href=/people/m/matan-orbach/>Matan Orbach</a>
|
<a href=/people/y/yonatan-bilu/>Yonatan Bilu</a>
|
<a href=/people/a/assaf-toledo/>Assaf Toledo</a>
|
<a href=/people/d/dan-lahav/>Dan Lahav</a>
|
<a href=/people/m/michal-jacovi/>Michal Jacovi</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--633><div class="card-body p-3 small">An educated and informed consumption of media content has become a challenge in modern times. With the shift from traditional news outlets to <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> and similar venues, a major concern is that readers are becoming encapsulated in echo chambers and may fall prey to fake news and disinformation, lacking easy access to dissenting views. We suggest a novel task aiming to alleviate some of these concerns that of detecting articles that most effectively counter the arguments and not just the stance made in a given text. We study this <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> in the context of <a href=https://en.wikipedia.org/wiki/Public_speaking>debate speeches</a>. Given such a <a href=https://en.wikipedia.org/wiki/Public_speaking>speech</a>, we aim to identify, from among a set of <a href=https://en.wikipedia.org/wiki/Public_speaking>speeches</a> on the same topic and with an opposing stance, the ones that directly counter it. We provide a large dataset of 3,685 such speeches (in English), annotated for this relation, which hopefully would be of general interest to the NLP community. We explore several <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> addressing this task, and while some are successful, all fall short of expert human performance, suggesting room for further research. All data collected during this work is freely available for research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.243.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--243 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.243 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.findings-emnlp.243.OptionalSupplementaryMaterial.txt data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.243/>Unsupervised Expressive Rules Provide Explainability and Assist Human Experts Grasping New Domains</a></strong><br><a href=/people/e/eyal-shnarch/>Eyal Shnarch</a>
|
<a href=/people/l/leshem-choshen/>Leshem Choshen</a>
|
<a href=/people/g/guy-moshkowich/>Guy Moshkowich</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--243><div class="card-body p-3 small">Approaching new data can be quite deterrent ; you do not know how your categories of interest are realized in it, commonly, there is no labeled data at hand, and the performance of domain adaptation methods is unsatisfactory. Aiming to assist domain experts in their first steps into a new task over a new corpus, we present an unsupervised approach to reveal complex rules which cluster the unexplored corpus by its prominent categories (or facets). These <a href=https://en.wikipedia.org/wiki/Rule_of_inference>rules</a> are human-readable, thus providing an important ingredient which has become in short supply lately-explainability. Each <a href=https://en.wikipedia.org/wiki/Rule_of_inference>rule</a> provides an explanation for the commonality of all the texts it clusters together. The experts can then identify which <a href=https://en.wikipedia.org/wiki/Rule_of_inference>rules</a> best capture texts of their categories of interest, and utilize them to deepen their understanding of these categories. These rules can also bootstrap the process of data labeling by pointing at a subset of the corpus which is enriched with texts demonstrating the target categories. We present an extensive evaluation of the usefulness of these rules in identifying target categories, as well as a user study which assesses their interpretability.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1564.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1564 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1564 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1564.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-1564/>Automatic Argument Quality Assessment-New Datasets and Methods</a></strong><br><a href=/people/a/assaf-toledo/>Assaf Toledo</a>
|
<a href=/people/s/shai-gretz/>Shai Gretz</a>
|
<a href=/people/e/edo-cohen-karlik/>Edo Cohen-Karlik</a>
|
<a href=/people/r/roni-friedman/>Roni Friedman</a>
|
<a href=/people/e/elad-venezian/>Elad Venezian</a>
|
<a href=/people/d/dan-lahav/>Dan Lahav</a>
|
<a href=/people/m/michal-jacovi/>Michal Jacovi</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1564><div class="card-body p-3 small">We explore the task of automatic assessment of argument quality. To that end, we actively collected 6.3k arguments, more than a factor of five compared to previously examined data. Each argument was explicitly and carefully annotated for its quality. In addition, 14k pairs of arguments were annotated independently, identifying the higher quality argument in each pair. In spite of the inherent subjective nature of the task, both <a href=https://en.wikipedia.org/wiki/Annotation>annotation schemes</a> led to surprisingly consistent results. We release the labeled datasets to the community. Furthermore, we suggest <a href=https://en.wikipedia.org/wiki/Artificial_neural_network>neural methods</a> based on a recently released <a href=https://en.wikipedia.org/wiki/Language_model>language model</a>, for argument ranking as well as for argument-pair classification. In the former <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, our results are comparable to <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> ; in the latter <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> our results significantly outperform earlier <a href=https://en.wikipedia.org/wiki/Methodology>methods</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5102.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5102 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5102 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5102/>Financial Event Extraction Using Wikipedia-Based Weak Supervision<span class=acl-fixed-case>W</span>ikipedia-Based Weak Supervision</a></strong><br><a href=/people/l/liat-ein-dor/>Liat Ein-Dor</a>
|
<a href=/people/a/ariel-gera/>Ariel Gera</a>
|
<a href=/people/o/orith-toledo-ronen/>Orith Toledo-Ronen</a>
|
<a href=/people/a/alon-halfon/>Alon Halfon</a>
|
<a href=/people/b/benjamin-sznajder/>Benjamin Sznajder</a>
|
<a href=/people/l/lena-dankin/>Lena Dankin</a>
|
<a href=/people/y/yonatan-bilu/>Yonatan Bilu</a>
|
<a href=/people/y/yoav-katz/>Yoav Katz</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/D19-51/ class=text-muted>Proceedings of the Second Workshop on Economics and Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5102><div class="card-body p-3 small">Extraction of financial and economic events from <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text</a> has previously been done mostly using rule-based methods, with more recent works employing <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning techniques</a>. This work is in line with this latter approach, leveraging relevant Wikipedia sections to extract weak labels for sentences describing economic events. Whereas previous weakly supervised approaches required a knowledge-base of such events, or corresponding financial figures, our approach requires no such additional data, and can be employed to extract economic events related to companies which are not even mentioned in the training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5905.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5905 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5905 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-5905.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-5905/>Crowd-sourcing annotation of complex NLU tasks : A case study of argumentative content annotation<span class=acl-fixed-case>NLU</span> tasks: A case study of argumentative content annotation</a></strong><br><a href=/people/t/tamar-lavee/>Tamar Lavee</a>
|
<a href=/people/l/lili-kotlerman/>Lili Kotlerman</a>
|
<a href=/people/m/matan-orbach/>Matan Orbach</a>
|
<a href=/people/y/yonatan-bilu/>Yonatan Bilu</a>
|
<a href=/people/m/michal-jacovi/>Michal Jacovi</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/D19-59/ class=text-muted>Proceedings of the First Workshop on Aggregating and Analysing Crowdsourced Annotations for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5905><div class="card-body p-3 small">Recent advancements in <a href=https://en.wikipedia.org/wiki/Machine_reading>machine reading</a> and listening comprehension involve the annotation of long texts. Such <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a> are typically time consuming, making crowd-annotations an attractive solution, yet their complexity often makes such a <a href=https://en.wikipedia.org/wiki/Solution>solution</a> unfeasible. In particular, a major concern is that crowd annotators may be tempted to skim through long texts, and answer questions without reading thoroughly. We present a case study of adapting this type of <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> to the crowd. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is to identify claims in a several minute long debate speech. We show that sentence-by-sentence annotation does not scale and that labeling only a subset of sentences is insufficient. Instead, we propose a scheme for effectively performing the full, complex task with crowd annotators, allowing the collection of large scale annotated datasets. We believe that the encountered challenges and pitfalls, as well as lessons learned, are relevant in general when collecting data for large scale natural language understanding (NLU) tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2009 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W19-2009.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W19-2009.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-2009" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-2009/>Syntactic Interchangeability in Word Embedding Models</a></strong><br><a href=/people/d/daniel-hershcovich/>Daniel Hershcovich</a>
|
<a href=/people/a/assaf-toledo/>Assaf Toledo</a>
|
<a href=/people/a/alon-halfon/>Alon Halfon</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/W19-20/ class=text-muted>Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2009><div class="card-body p-3 small">Nearest neighbors in word embedding models are commonly observed to be semantically similar, but the relations between them can vary greatly. We investigate the extent to which word embedding models preserve syntactic interchangeability, as reflected by distances between word vectors, and the effect of hyper-parameterscontext window size in particular. We use part of speech (POS) as a proxy for syntactic interchangeability, as generally speaking, words with the same POS are syntactically valid in the same contexts. We also investigate the relationship between <a href=https://en.wikipedia.org/wiki/Interchangeability>interchangeability</a> and <a href=https://en.wikipedia.org/wiki/Similarity_measure>similarity</a> as judged by commonly-used word similarity benchmarks, and correlate the result with the performance of word embedding models on these benchmarks. Our results will inform future research and applications in the selection of word embedding model, suggesting a principle for an appropriate selection of the context window size parameter depending on the use-case.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4507.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4507 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4507 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4507/>Towards Effective Rebuttal : <a href=https://en.wikipedia.org/wiki/Listening_comprehension>Listening Comprehension</a> Using Corpus-Wide Claim Mining</a></strong><br><a href=/people/t/tamar-lavee/>Tamar Lavee</a>
|
<a href=/people/m/matan-orbach/>Matan Orbach</a>
|
<a href=/people/l/lili-kotlerman/>Lili Kotlerman</a>
|
<a href=/people/y/yoav-kantor/>Yoav Kantor</a>
|
<a href=/people/s/shai-gretz/>Shai Gretz</a>
|
<a href=/people/l/lena-dankin/>Lena Dankin</a>
|
<a href=/people/m/michal-jacovi/>Michal Jacovi</a>
|
<a href=/people/y/yonatan-bilu/>Yonatan Bilu</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/W19-45/ class=text-muted>Proceedings of the 6th Workshop on Argument Mining</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4507><div class="card-body p-3 small">Engaging in a live debate requires, among other things, the ability to effectively rebut arguments claimed by your opponent. In particular, this requires identifying these arguments. Here, we suggest doing so by automatically mining claims from a corpus of news articles containing billions of sentences, and searching for them in a given speech. This raises the question of whether such claims indeed correspond to those made in spoken speeches. To this end, we collected a large dataset of 400 speeches in English discussing 200 controversial topics, mined claims for each topic, and asked annotators to identify the mined claims mentioned in each speech. Results show that in the vast majority of speeches debaters indeed make use of such claims. In addition, we present several <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> for the automatic detection of mined claims in <a href=https://en.wikipedia.org/wiki/Public_speaking>speeches</a>, forming the basis for future work. All collected data is freely available for research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1093.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1093 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1093 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384469154 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1093/>Are You Convinced? Choosing the More Convincing Evidence with a Siamese Network<span class=acl-fixed-case>S</span>iamese Network</a></strong><br><a href=/people/m/martin-gleize/>Martin Gleize</a>
|
<a href=/people/e/eyal-shnarch/>Eyal Shnarch</a>
|
<a href=/people/l/leshem-choshen/>Leshem Choshen</a>
|
<a href=/people/l/lena-dankin/>Lena Dankin</a>
|
<a href=/people/g/guy-moshkowich/>Guy Moshkowich</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1093><div class="card-body p-3 small">With the advancement in argument detection, we suggest to pay more attention to the challenging task of identifying the more convincing arguments. Machines capable of responding and interacting with humans in helpful ways have become ubiquitous. We now expect them to discuss with us the more delicate questions in our world, and they should do so armed with effective arguments. But what makes an argument more persuasive? What will convince you? In this paper, we present a new <a href=https://en.wikipedia.org/wiki/Data_set>data set</a>, IBM-EviConv, of pairs of evidence labeled for convincingness, designed to be more challenging than existing alternatives. We also propose a Siamese neural network architecture shown to outperform several baselines on both a prior convincingness data set and our own. Finally, we provide insights into our experimental results and the various kinds of argumentative value our method is capable of detecting.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1094.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1094 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1094 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384469239 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1094/>From Surrogacy to Adoption ; From <a href=https://en.wikipedia.org/wiki/Bitcoin>Bitcoin</a> to <a href=https://en.wikipedia.org/wiki/Cryptocurrency>Cryptocurrency</a> : Debate Topic Expansion</a></strong><br><a href=/people/r/roy-bar-haim/>Roy Bar-Haim</a>
|
<a href=/people/d/dalia-krieger/>Dalia Krieger</a>
|
<a href=/people/o/orith-toledo-ronen/>Orith Toledo-Ronen</a>
|
<a href=/people/l/lilach-edelstein/>Lilach Edelstein</a>
|
<a href=/people/y/yonatan-bilu/>Yonatan Bilu</a>
|
<a href=/people/a/alon-halfon/>Alon Halfon</a>
|
<a href=/people/y/yoav-katz/>Yoav Katz</a>
|
<a href=/people/a/amir-menczel/>Amir Menczel</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1094><div class="card-body p-3 small">When debating a controversial topic, it is often desirable to expand the boundaries of discussion. For example, we may consider the pros and cons of possible alternatives to the debate topic, make generalizations, or give specific examples. We introduce the task of Debate Topic Expansion-finding such related topics for a given debate topic, along with a novel annotated dataset for the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. We focus on relations between Wikipedia concepts, and show that they differ from well-studied lexical-semantic relations such as <a href=https://en.wikipedia.org/wiki/Hypernymy>hypernyms</a>, <a href=https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy>hyponyms</a> and <a href=https://en.wikipedia.org/wiki/Opposite_(semantics)>antonyms</a>. We present <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> for finding both consistent and contrastive expansions and demonstrate their effectiveness empirically. We suggest that debate topic expansion may have various use cases in argumentation mining.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5200.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5200/>Proceedings of the 5th Workshop on Argument Mining</a></strong><br><a href=/people/n/noam-slonim/>Noam Slonim</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a><br><a href=/volumes/W18-52/ class=text-muted>Proceedings of the 5th Workshop on Argument Mining</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-2095.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-2095 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-2095 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-2095.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-2095/>Will it Blend? Blending Weak and Strong Labeled Data in a <a href=https://en.wikipedia.org/wiki/Neural_network>Neural Network</a> for Argumentation Mining</a></strong><br><a href=/people/e/eyal-shnarch/>Eyal Shnarch</a>
|
<a href=/people/c/carlos-alzate/>Carlos Alzate</a>
|
<a href=/people/l/lena-dankin/>Lena Dankin</a>
|
<a href=/people/m/martin-gleize/>Martin Gleize</a>
|
<a href=/people/y/yufang-hou/>Yufang Hou</a>
|
<a href=/people/l/leshem-choshen/>Leshem Choshen</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/P18-2/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-2095><div class="card-body p-3 small">The process of obtaining high quality <a href=https://en.wikipedia.org/wiki/Labeled_data>labeled data</a> for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding tasks</a> is often slow, error-prone, complicated and expensive. With the vast usage of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>, this issue becomes more notorious since these networks require a large amount of labeled data to produce satisfactory results. We propose a <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> to blend high quality but scarce strong labeled data with noisy but abundant weak labeled data during the training of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>. Experiments in the context of topic-dependent evidence detection with two forms of weak labeled data show the advantages of the blending scheme. In addition, we provide a manually annotated data set for the task of topic-dependent evidence detection. We believe that blending weak and strong labeled data is a general notion that may be applicable to many language understanding tasks, and can especially assist researchers who wish to train a <a href=https://en.wikipedia.org/wiki/Computer_network>network</a> but have a small amount of high quality <a href=https://en.wikipedia.org/wiki/Labeled_data>labeled data</a> for their task of interest.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5100.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5100/>Proceedings of the 4th Workshop on Argument Mining</a></strong><br><a href=/people/i/ivan-habernal/>Ivan Habernal</a>
|
<a href=/people/i/iryna-gurevych/>Iryna Gurevych</a>
|
<a href=/people/k/kevin-d-ashley/>Kevin Ashley</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a>
|
<a href=/people/n/nancy-green/>Nancy Green</a>
|
<a href=/people/d/diane-litman/>Diane Litman</a>
|
<a href=/people/g/georgios-petasis/>Georgios Petasis</a>
|
<a href=/people/c/chris-reed/>Chris Reed</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a>
|
<a href=/people/v/vern-walker/>Vern Walker</a><br><a href=/volumes/W17-51/ class=text-muted>Proceedings of the 4th Workshop on Argument Mining</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5104.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5104 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5104 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5104/>Improving Claim Stance Classification with Lexical Knowledge Expansion and Context Utilization</a></strong><br><a href=/people/r/roy-bar-haim/>Roy Bar-Haim</a>
|
<a href=/people/l/lilach-edelstein/>Lilach Edelstein</a>
|
<a href=/people/c/charles-jochim/>Charles Jochim</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/W17-51/ class=text-muted>Proceedings of the 4th Workshop on Argument Mining</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5104><div class="card-body p-3 small">Stance classification is a core component in on-demand argument construction pipelines. Previous work on claim stance classification relied on background knowledge such as manually-composed sentiment lexicons. We show that both <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and <a href=https://en.wikipedia.org/wiki/Coverage_(telecommunication)>coverage</a> can be significantly improved through automatic expansion of the initial lexicon. We also developed a set of contextual features that further improves the state-of-the-art for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5110.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5110 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5110 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-5110.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W17-5110/>Unsupervised corpuswide claim detection</a></strong><br><a href=/people/r/ran-levy/>Ran Levy</a>
|
<a href=/people/s/shai-gretz/>Shai Gretz</a>
|
<a href=/people/b/benjamin-sznajder/>Benjamin Sznajder</a>
|
<a href=/people/s/shay-hummel/>Shay Hummel</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/W17-51/ class=text-muted>Proceedings of the 4th Workshop on Argument Mining</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5110><div class="card-body p-3 small">Automatic claim detection is a fundamental argument mining task that aims to automatically mine claims regarding a topic of consideration. Previous works on mining argumentative content have assumed that a set of relevant documents is given in advance. Here, we present a first corpus wide claim detection framework, that can be directly applied to massive corpora. Using simple and intuitive empirical observations, we derive a claim sentence query by which we are able to directly retrieve sentences in which the <a href=https://en.wikipedia.org/wiki/Prior_probability>prior probability</a> to include topic-relevant claims is greatly enhanced. Next, we employ simple <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a> to rank the sentences, leading to an unsupervised corpuswide claim detection system, with precision that outperforms previously reported results on the task of claim detection given relevant documents and labeled data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1140.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1140 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1140 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D17-1140.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1140/>GRASP : Rich Patterns for Argumentation Mining<span class=acl-fixed-case>GRASP</span>: Rich Patterns for Argumentation Mining</a></strong><br><a href=/people/e/eyal-shnarch/>Eyal Shnarch</a>
|
<a href=/people/r/ran-levy/>Ran Levy</a>
|
<a href=/people/v/vikas-raykar/>Vikas Raykar</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1140><div class="card-body p-3 small">GRASP (GReedy Augmented Sequential Patterns) is an <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> for automatically extracting patterns that characterize subtle linguistic phenomena. To that end, GRASP augments each term of input text with multiple <a href=https://en.wikipedia.org/wiki/Linguistic_description>layers of linguistic information</a>. These different facets of the text terms are systematically combined to reveal rich patterns. We report highly promising experimental results in several challenging text analysis tasks within the field of Argumentation Mining. We believe that GRASP is general enough to be useful for other domains too. For example, each of the following sentences includes a claim for a [ topic ] : 1. Opponents often argue that the open primary is unconstitutional. [ Open Primaries ] 2. Prof. Smith suggested that <a href=https://en.wikipedia.org/wiki/Affirmative_action>affirmative action</a> devalues the accomplishments of the chosen. [ Affirmative Action ] 3. The majority stated that the First Amendment does not guarantee the right to offend others. [ Freedom of Speech ] These sentences share almost no words in common, however, they are similar at a more abstract level. A human observer may notice the following underlying common structure, or pattern : [ someone][argue / suggest / state][that][topic term][sentiment term ]. GRASP aims to automatically capture such underlying structures of the given data. For the above examples it finds the pattern [ noun][express][that][noun, topic][sentiment ], where [ express ] stands for all its (in)direct hyponyms, and [ noun, topic ] means a noun which is also related to the topic.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-1024/>Stance Classification of Context-Dependent Claims</a></strong><br><a href=/people/r/roy-bar-haim/>Roy Bar-Haim</a>
|
<a href=/people/i/indrajit-bhattacharya/>Indrajit Bhattacharya</a>
|
<a href=/people/f/francesco-dinuzzo/>Francesco Dinuzzo</a>
|
<a href=/people/a/amrita-saha/>Amrita Saha</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a><br><a href=/volumes/E17-1/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-1024><div class="card-body p-3 small">Recent work has addressed the problem of detecting relevant claims for a given controversial topic. We introduce the complementary task of Claim Stance Classification, along with the first <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark dataset</a> for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. We decompose this problem into : (a) open-domain target identification for topic and claim (b) sentiment classification for each target, and (c) open-domain contrast detection between the topic and the claim targets. Manual annotation of the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> confirms the applicability and validity of our <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>. We describe an implementation of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, focusing on a novel <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> for contrast detection. Our approach achieves promising results, and is shown to outperform several baselines, which represent the common practice of applying a single, monolithic classifier for stance classification.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Noam+Slonim" title="Search for 'Noam Slonim' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/r/ranit-aharonov/ class=align-middle>Ranit Aharonov</a>
<span class="badge badge-secondary align-middle ml-2">10</span></li><li class=list-group-item><a href=/people/r/roy-bar-haim/ class=align-middle>Roy Bar-Haim</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/y/yonatan-bilu/ class=align-middle>Yonatan Bilu</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/m/matan-orbach/ class=align-middle>Matan Orbach</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/m/michal-jacovi/ class=align-middle>Michal Jacovi</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/l/lena-dankin/ class=align-middle>Lena Dankin</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/e/eyal-shnarch/ class=align-middle>Eyal Shnarch</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/y/yoav-kantor/ class=align-middle>Yoav Kantor</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/r/roni-friedman/ class=align-middle>Roni Friedman</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/d/dan-lahav/ class=align-middle>Dan Lahav</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/assaf-toledo/ class=align-middle>Assaf Toledo</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/shai-gretz/ class=align-middle>Shai Gretz</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/alon-halfon/ class=align-middle>Alon Halfon</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/leshem-choshen/ class=align-middle>Leshem Choshen</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/lilach-eden/ class=align-middle>Lilach Eden</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/liat-ein-dor/ class=align-middle>Liat Ein Dor</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/elad-venezian/ class=align-middle>Elad Venezian</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/lilach-edelstein/ class=align-middle>Lilach Edelstein</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/ran-levy/ class=align-middle>Ran Levy</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/benjamin-sznajder/ class=align-middle>Benjamin Sznajder</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/o/orith-toledo-ronen/ class=align-middle>Orith Toledo-Ronen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yoav-katz/ class=align-middle>Yoav Katz</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/tamar-lavee/ class=align-middle>Tamar Lavee</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/lili-kotlerman/ class=align-middle>Lili Kotlerman</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/g/guy-moshkowich/ class=align-middle>Guy Moshkowich</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/martin-gleize/ class=align-middle>Martin Gleize</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/i/ivan-habernal/ class=align-middle>Ivan Habernal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/iryna-gurevych/ class=align-middle>Iryna Gurevych</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kevin-d-ashley/ class=align-middle>Kevin D. Ashley</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/claire-cardie/ class=align-middle>Claire Cardie</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nancy-green/ class=align-middle>Nancy Green</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/diane-litman/ class=align-middle>Diane Litman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/georgios-petasis/ class=align-middle>Georgios Petasis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chris-reed/ class=align-middle>Chris Reed</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vern-walker/ class=align-middle>Vern Walker</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/charles-jochim/ class=align-middle>Charles Jochim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shay-hummel/ class=align-middle>Shay Hummel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/edo-cohen-karlik/ class=align-middle>Edo Cohen-Karlik</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ariel-gera/ class=align-middle>Ariel Gera</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vikas-raykar/ class=align-middle>Vikas Raykar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/daniel-hershcovich/ class=align-middle>Daniel Hershcovich</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/indrajit-bhattacharya/ class=align-middle>Indrajit Bhattacharya</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/francesco-dinuzzo/ class=align-middle>Francesco Dinuzzo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/amrita-saha/ class=align-middle>Amrita Saha</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/carlos-alzate/ class=align-middle>Carlos Alzate</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yufang-hou/ class=align-middle>Yufang Hou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dalia-krieger/ class=align-middle>Dalia Krieger</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/amir-menczel/ class=align-middle>Amir Menczel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>