<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Nanyun Peng - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Nanyun</span> <span class=font-weight-bold>Peng</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-short.45.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-short--45 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-short.45 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.acl-short.45.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-short.45" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-short.45/>Men Are Elected, Women Are Married : Events Gender Bias on Wikipedia<span class=acl-fixed-case>W</span>ikipedia</a></strong><br><a href=/people/j/jiao-sun/>Jiao Sun</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/2021.acl-short/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-short--45><div class="card-body p-3 small">Human activities can be seen as sequences of events, which are crucial to understanding societies. Disproportional event distribution for different demographic groups can manifest and amplify <a href=https://en.wikipedia.org/wiki/Stereotypes_of_East_Asians_in_the_United_States>social stereotypes</a>, and potentially jeopardize the ability of members in some groups to pursue certain goals. In this paper, we present the first event-centric study of <a href=https://en.wikipedia.org/wiki/Gender_bias>gender biases</a> in a <a href=https://en.wikipedia.org/wiki/Web_of_Science>Wikipedia corpus</a>. To facilitate the study, we curate a corpus of career and personal life descriptions with demographic information consisting of 7,854 fragments from 10,412 celebrities. Then we detect <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>events</a> with a state-of-the-art event detection model, calibrate the results using strategically generated templates, and extract <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>events</a> that have asymmetric associations with genders. Our study discovers that the Wikipedia pages tend to intermingle personal life events with professional events for females but not for males, which calls for the awareness of the Wikipedia community to formalize guidelines and train the editors to mind the implicit biases that contributors carry. Our work also lays the foundation for future works on quantifying and discovering event biases at the corpus level.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.nuse-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--nuse-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.nuse-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.nuse-1.4/>Document-level Event Extraction with Efficient End-to-end Learning of Cross-event Dependencies</a></strong><br><a href=/people/k/kung-hsiang-huang/>Kung-Hsiang Huang</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/2021.nuse-1/ class=text-muted>Proceedings of the Third Workshop on Narrative Understanding</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--nuse-1--4><div class="card-body p-3 small">Fully understanding narratives often requires identifying events in the context of whole documents and modeling the event relations. However, document-level event extraction is a challenging task as it requires the extraction of event and entity coreference, and capturing arguments that span across different sentences. Existing works on <a href=https://en.wikipedia.org/wiki/Event_extraction>event extraction</a> usually confine on extracting events from single sentences, which fail to capture the relationships between the event mentions at the scale of a document, as well as the event arguments that appear in a different sentence than the event trigger. In this paper, we propose an end-to-end model leveraging Deep Value Networks (DVN), a structured prediction algorithm, to efficiently capture cross-event dependencies for document-level event extraction. Experimental results show that our approach achieves comparable performance to CRF-based models on ACE05, while enjoys significantly higher computational efficiency.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-main.218.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-main--218 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-main.218 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.eacl-main.218" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-main.218/>Scientific Discourse Tagging for Evidence Extraction</a></strong><br><a href=/people/x/xiangci-li/>Xiangci Li</a>
|
<a href=/people/g/gully-burns/>Gully Burns</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/2021.eacl-main/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-main--218><div class="card-body p-3 small">Evidence plays a crucial role in any biomedical research narrative, providing justification for some claims and refutation for others. We seek to build models of scientific argument using <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction methods</a> from <a href=https://en.wikipedia.org/wiki/Academic_publishing>full-text papers</a>. We present the capability of automatically extracting text fragments from primary research papers that describe the evidence presented in that paper&#8217;s figures, which arguably provides the raw material of any scientific argument made within the paper. We apply richly contextualized deep representation learning pre-trained on biomedical domain corpus to the analysis of scientific discourse structures and the extraction of evidence fragments (i.e., the text in the results section describing data presented in a specified subfigure) from a set of biomedical experimental research articles. We first demonstrate our state-of-the-art scientific discourse tagger on two scientific discourse tagging datasets and its transferability to new <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>. We then show the benefit of leveraging scientific discourse tags for downstream tasks such as claim-extraction and evidence fragment detection. Our work demonstrates the potential of using evidence fragments derived from figure spans for improving the quality of scientific claims by cataloging, indexing and reusing evidence fragments as independent documents.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.162.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--162 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.162 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.162" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.162/>Broaden the Vision : Geo-Diverse Visual Commonsense Reasoning</a></strong><br><a href=/people/d/da-yin/>Da Yin</a>
|
<a href=/people/l/liunian-harold-li/>Liunian Harold Li</a>
|
<a href=/people/z/ziniu-hu/>Ziniu Hu</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--162><div class="card-body p-3 small">Commonsense is defined as the knowledge on which everyone agrees. However, certain types of <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a> are correlated with culture and geographic locations and they are only shared locally. For example, the scenes of wedding ceremonies vary across regions due to different customs influenced by historical and religious factors. Such regional characteristics, however, are generally omitted in prior work. In this paper, we construct a Geo-Diverse Visual Commonsense Reasoning dataset (GD-VCR) to test vision-and-language models&#8217; ability to understand cultural and geo-location-specific commonsense. In particular, we study two state-of-the-art Vision-and-Language models, VisualBERT and ViLBERT trained on <a href=https://en.wikipedia.org/wiki/Videocassette_recorder>VCR</a>, a standard benchmark with images primarily from Western regions. We then evaluate how well the trained <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> can generalize to answering the questions in GD-VCR. We find that the performance of both models for non-Western regions including <a href=https://en.wikipedia.org/wiki/East_Asia>East Asia</a>, <a href=https://en.wikipedia.org/wiki/South_Asia>South Asia</a>, and <a href=https://en.wikipedia.org/wiki/Africa>Africa</a> is significantly lower than that for <a href=https://en.wikipedia.org/wiki/Western_world>Western region</a>. We analyze the reasons behind the performance disparity and find that the performance gap is larger on QA pairs that : 1) are concerned with <a href=https://en.wikipedia.org/wiki/Culture>culture-related scenarios</a>, e.g., <a href=https://en.wikipedia.org/wiki/Wedding>weddings</a>, <a href=https://en.wikipedia.org/wiki/Religion>religious activities</a>, and <a href=https://en.wikipedia.org/wiki/Festival>festivals</a> ; 2) require high-level geo-diverse commonsense reasoning rather than low-order perception and recognition. Dataset and code are released at https://github.com/WadeYin9712/GD-VCR.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.420.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--420 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.420 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.420" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.420/>AESOP : Paraphrase Generation with Adaptive Syntactic Control<span class=acl-fixed-case>AESOP</span>: Paraphrase Generation with Adaptive Syntactic Control</a></strong><br><a href=/people/j/jiao-sun/>Jiao Sun</a>
|
<a href=/people/x/xuezhe-ma/>Xuezhe Ma</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--420><div class="card-body p-3 small">We propose to control <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a> through carefully chosen target syntactic structures to generate more proper and higher quality <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrases</a>. Our model, AESOP, leverages a pretrained language model and adds deliberately chosen syntactical control via a retrieval-based selection module to generate fluent paraphrases. Experiments show that AESOP achieves state-of-the-art performances on semantic preservation and syntactic conformation on two benchmark datasets with ground-truth syntactic control from human-annotated exemplars. Moreover, with the retrieval-based target syntax selection module, AESOP generates paraphrases with even better qualities than the current best model using human-annotated target syntactic parses according to human evaluation. We further demonstrate the effectiveness of AESOP to improve classification models&#8217; <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> to syntactic perturbation by <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> on two GLUE tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.436.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--436 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.436 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.436" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.436/>ECONET : Effective Continual Pretraining of <a href=https://en.wikipedia.org/wiki/Language_model>Language Models</a> for Event Temporal Reasoning<span class=acl-fixed-case>ECONET</span>: Effective Continual Pretraining of Language Models for Event Temporal Reasoning</a></strong><br><a href=/people/r/rujun-han/>Rujun Han</a>
|
<a href=/people/x/xiang-ren/>Xiang Ren</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--436><div class="card-body p-3 small">While pre-trained language models (PTLMs) have achieved noticeable success on many NLP tasks, they still struggle for tasks that require event temporal reasoning, which is essential for event-centric applications. We present a continual pre-training approach that equips PTLMs with targeted knowledge about event temporal relations. We design self-supervised learning objectives to recover masked-out event and temporal indicators and to discriminate sentences from their corrupted counterparts (where event or temporal indicators got replaced). By further pre-training a PTLM with these objectives jointly, we reinforce its attention to event and temporal information, yielding enhanced capability on event temporal reasoning. This * * E**ffective * * CON**tinual pre-training framework for * * E**vent * * T**emporal reasoning (ECONET) improves the PTLMs&#8217; fine-tuning performances across five relation extraction and question answering tasks and achieves new or on-par state-of-the-art performances in most of our downstream tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.513.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--513 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.513 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.513/>Improving Pre-trained Vision-and-Language Embeddings for Phrase Grounding</a></strong><br><a href=/people/z/zi-yi-dou/>Zi-Yi Dou</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--513><div class="card-body p-3 small">Phrase grounding aims to map textual phrases to their associated image regions, which can be a prerequisite for multimodal reasoning and can benefit tasks requiring identifying objects based on language. With pre-trained vision-and-language models achieving impressive performance across tasks, it remains unclear if we can directly utilize their learned embeddings for phrase grounding without <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a>. To this end, we propose a method to extract matched phrase-region pairs from pre-trained vision-and-language embeddings and propose four fine-tuning objectives to improve the model phrase grounding ability using image-caption data without any supervised grounding signals. Experiments on two representative datasets demonstrate the effectiveness of our objectives, outperforming baseline models in both weakly-supervised and supervised phrase grounding settings. In addition, we evaluate the aligned embeddings on several other downstream tasks and show that we can achieve better phrase grounding without sacrificing <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representation generality</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.60.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--60 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.60 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.60/>Nice Try, Kiddo : Investigating Ad Hominems in Dialogue Responses</a></strong><br><a href=/people/e/emily-sheng/>Emily Sheng</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/p/prem-natarajan/>Prem Natarajan</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--60><div class="card-body p-3 small">Ad hominem attacks are those that target some feature of a person&#8217;s character instead of the position the person is maintaining. These attacks are harmful because they propagate implicit biases and diminish a person&#8217;s credibility. Since <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a> respond directly to <a href=https://en.wikipedia.org/wiki/Input_(computer_science)>user input</a>, it is important to study ad hominems in dialogue responses. To this end, we propose categories of ad hominems, compose an annotated dataset, and build a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> to analyze human and dialogue system responses to English Twitter posts. We specifically compare responses to Twitter topics about marginalized communities (# BlackLivesMatter, # MeToo) versus other topics (# Vegan, # WFH), because the abusive language of ad hominems could further amplify the skew of power away from marginalized populations. Furthermore, we propose a constrained decoding technique that uses salient n-gram similarity as a soft constraint for top-k sampling to reduce the amount of ad hominems generated. Our results indicate that 1) responses from both humans and DialoGPT contain more <a href=https://en.wikipedia.org/wiki/Ad_hominem>ad hominems</a> for discussions around marginalized communities, 2) different quantities of <a href=https://en.wikipedia.org/wiki/Ad_hominem>ad hominems</a> in the training data can influence the likelihood of generating <a href=https://en.wikipedia.org/wiki/Ad_hominem>ad hominems</a>, and 3) we can use constrained decoding techniques to reduce <a href=https://en.wikipedia.org/wiki/Ad_hominem>ad hominems</a> in generated dialogue responses.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.336.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--336 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.336 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.336" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.336/>MERMAID : Metaphor Generation with <a href=https://en.wikipedia.org/wiki/Symbol>Symbolism</a> and Discriminative Decoding<span class=acl-fixed-case>MERMAID</span>: Metaphor Generation with Symbolism and Discriminative Decoding</a></strong><br><a href=/people/t/tuhin-chakrabarty/>Tuhin Chakrabarty</a>
|
<a href=/people/x/xurui-zhang/>Xurui Zhang</a>
|
<a href=/people/s/smaranda-muresan/>Smaranda Muresan</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--336><div class="card-body p-3 small">Generating metaphors is a challenging task as it requires a proper understanding of <a href=https://en.wikipedia.org/wiki/Abstraction>abstract concepts</a>, making connections between unrelated concepts, and deviating from the <a href=https://en.wikipedia.org/wiki/Literal_and_figurative_language>literal meaning</a>. In this paper, we aim to generate a metaphoric sentence given a <a href=https://en.wikipedia.org/wiki/Literal_and_figurative_language>literal expression</a> by replacing relevant verbs. Based on a theoretically-grounded connection between metaphors and symbols, we propose a method to automatically construct a parallel corpus by transforming a large number of metaphorical sentences from the Gutenberg Poetry corpus (CITATION) to their literal counterpart using recent advances in masked language modeling coupled with commonsense inference. For the generation task, we incorporate a metaphor discriminator to guide the decoding of a sequence to sequence model fine-tuned on our parallel data to generate high-quality metaphors. Human evaluation on an independent test set of literal statements shows that our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> generates <a href=https://en.wikipedia.org/wiki/Metaphor>metaphors</a> better than three well-crafted baselines 66 % of the time on average. A task-based evaluation shows that human-written poems enhanced with <a href=https://en.wikipedia.org/wiki/Metaphor>metaphors</a> proposed by our model are preferred 68 % of the time compared to poems without <a href=https://en.wikipedia.org/wiki/Metaphor>metaphors</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-demos.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-demos--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-demos.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-demos.7/>EventPlus : A Temporal Event Understanding Pipeline<span class=acl-fixed-case>E</span>vent<span class=acl-fixed-case>P</span>lus: A Temporal Event Understanding Pipeline</a></strong><br><a href=/people/m/mingyu-derek-ma/>Mingyu Derek Ma</a>
|
<a href=/people/j/jiao-sun/>Jiao Sun</a>
|
<a href=/people/m/mu-yang/>Mu Yang</a>
|
<a href=/people/k/kung-hsiang-huang/>Kung-Hsiang Huang</a>
|
<a href=/people/n/nuan-wen/>Nuan Wen</a>
|
<a href=/people/s/shikhar-singh/>Shikhar Singh</a>
|
<a href=/people/r/rujun-han/>Rujun Han</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/2021.naacl-demos/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-demos--7><div class="card-body p-3 small">We present EventPlus, a temporal event understanding pipeline that integrates various state-of-the-art event understanding components including event trigger and type detection, event argument detection, event duration and temporal relation extraction. Event information, especially event temporal knowledge, is a type of common sense knowledge that helps people understand how stories evolve and provides predictive hints for future events. EventPlus as the first comprehensive temporal event understanding pipeline provides a convenient tool for users to quickly obtain annotations about events and their temporal information for any user-provided document. Furthermore, we show EventPlus can be easily adapted to other domains (e.g., biomedical domain). We make EventPlus publicly available to facilitate event-related information extraction and downstream applications.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-srw.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-srw.0/>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop</a></strong><br><a href=/people/e/esin-durmus/>Esin Durmus</a>
|
<a href=/people/v/vivek-gupta/>Vivek Gupta</a>
|
<a href=/people/n/nelson-f-liu/>Nelson Liu</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/y/yu-su/>Yu Su</a><br><a href=/volumes/2021.naacl-srw/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nuse-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nuse-1.0/>Proceedings of the First Joint Workshop on Narrative Understanding, Storylines, and Events</a></strong><br><a href=/people/c/claire-bonial/>Claire Bonial</a>
|
<a href=/people/t/tommaso-caselli/>Tommaso Caselli</a>
|
<a href=/people/s/snigdha-chaturvedi/>Snigdha Chaturvedi</a>
|
<a href=/people/e/elizabeth-clark/>Elizabeth Clark</a>
|
<a href=/people/r/ruihong-huang/>Ruihong Huang</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/a/alejandro-jaimes/>Alejandro Jaimes</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/l/lara-j-martin/>Lara J. Martin</a>
|
<a href=/people/b/ben-miller/>Ben Miller</a>
|
<a href=/people/t/teruko-mitamura/>Teruko Mitamura</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/j/joel-tetreault/>Joel Tetreault</a><br><a href=/volumes/2020.nuse-1/ class=text-muted>Proceedings of the First Joint Workshop on Narrative Understanding, Storylines, and Events</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.461.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--461 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.461 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939236 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.461" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.461/>Domain Knowledge Empowered Structured Neural Net for End-to-End Event Temporal Relation Extraction</a></strong><br><a href=/people/r/rujun-han/>Rujun Han</a>
|
<a href=/people/y/yichao-zhou/>Yichao Zhou</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--461><div class="card-body p-3 small">Extracting event temporal relations is a critical task for <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a> and plays an important role in <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a>. Prior systems leverage <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> and pre-trained <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> to improve the performance of the task. However, these systems often suffer from two shortcomings : 1) when performing maximum a posteriori (MAP) inference based on neural models, previous systems only used structured knowledge that is assumed to be absolutely correct, i.e., hard constraints ; 2) biased predictions on dominant temporal relations when training with a limited amount of data. To address these issues, we propose a framework that enhances <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural network</a> with <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distributional constraints</a> constructed by probabilistic domain knowledge. We solve the constrained inference problem via <a href=https://en.wikipedia.org/wiki/Lagrangian_and_Eulerian_specification_of_the_flow_field>Lagrangian Relaxation</a> and apply it to end-to-end event temporal relation extraction tasks. Experimental results show our framework is able to improve the baseline neural network models with strong <a href=https://en.wikipedia.org/wiki/Statistical_significance>statistical significance</a> on two widely used datasets in news and clinical domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.291.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--291 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.291 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.findings-emnlp.291" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.291/>Towards Controllable Biases in Language Generation<span class=acl-fixed-case>C</span>ontrollable <span class=acl-fixed-case>B</span>iases in <span class=acl-fixed-case>L</span>anguage <span class=acl-fixed-case>G</span>eneration</a></strong><br><a href=/people/e/emily-sheng/>Emily Sheng</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/p/prem-natarajan/>Prem Natarajan</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--291><div class="card-body p-3 small">We present a general approach towards controllable societal biases in natural language generation (NLG). Building upon the idea of adversarial triggers, we develop a method to induce societal biases in generated text when input prompts contain mentions of specific demographic groups. We then analyze two scenarios : 1) inducing negative biases for one demographic and positive biases for another demographic, and 2) equalizing biases between demographics. The former <a href=https://en.wikipedia.org/wiki/Scenario>scenario</a> enables us to detect the types of <a href=https://en.wikipedia.org/wiki/Bias>biases</a> present in the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. Specifically, we show the effectiveness of our approach at facilitating bias analysis by finding topics that correspond to demographic inequalities in generated text and comparing the relative effectiveness of inducing biases for different demographics. The second <a href=https://en.wikipedia.org/wiki/Scenario>scenario</a> is useful for mitigating biases in downstream applications such as dialogue generation. In our experiments, the mitigation technique proves to be effective at equalizing the amount of biases across demographics while simultaneously generating less negatively biased text overall.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1339.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1339 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1339 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1339.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1339" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1339/>The Woman Worked as a Babysitter : On Biases in Language Generation</a></strong><br><a href=/people/e/emily-sheng/>Emily Sheng</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/p/prem-natarajan/>Premkumar Natarajan</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1339><div class="card-body p-3 small">We present a systematic study of biases in natural language generation (NLG) by analyzing text generated from prompts that contain mentions of different demographic groups. In this work, we introduce the notion of the regard towards a demographic, use the varying levels of regard towards different demographics as a defining metric for bias in NLG, and analyze the extent to which sentiment scores are a relevant proxy metric for <a href=https://en.wikipedia.org/wiki/Opinion_poll>regard</a>. To this end, we collect strategically-generated text from <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> and manually annotate the text with both sentiment and regard scores. Additionally, we build an automatic regard classifier through <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>, so that we can analyze biases in unseen text. Together, these <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> reveal the extent of the biased nature of language model generations. Our analysis provides a study of biases in NLG, bias metrics and correlated human judgments, and empirical evidence on the usefulness of our annotated dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1672.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1672 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1672 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1672/>What Matters for Neural Cross-Lingual Named Entity Recognition : An Empirical Analysis</a></strong><br><a href=/people/x/xiaolei-huang/>Xiaolei Huang</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1672><div class="card-body p-3 small">Building named entity recognition (NER) models for languages that do not have much training data is a challenging task. While recent work has shown promising results on cross-lingual transfer from high-resource languages, it is unclear what knowledge is transferred. In this paper, we first propose a simple and efficient neural architecture for cross-lingual NER. Experiments show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves competitive performance with the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a>. We further explore how <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> works for cross-lingual NER on two transferable factors : sequential order and multilingual embedding. Our results shed light on future research for improving cross-lingual NER.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6100.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6100/>Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019)</a></strong><br><a href=/people/c/colin-cherry/>Colin Cherry</a>
|
<a href=/people/g/greg-durrett/>Greg Durrett</a>
|
<a href=/people/g/george-foster/>George Foster</a>
|
<a href=/people/g/gholamreza-haffari/>Reza Haffari</a>
|
<a href=/people/s/shahram-khadivi/>Shahram Khadivi</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/x/xiang-ren/>Xiang Ren</a>
|
<a href=/people/s/swabha-swayamdipta/>Swabha Swayamdipta</a><br><a href=/volumes/D19-61/ class=text-muted>Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2310.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2310 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2310 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2310/>Better Automatic Evaluation of Open-Domain Dialogue Systems with Contextualized Embeddings</a></strong><br><a href=/people/s/sarik-ghazarian/>Sarik Ghazarian</a>
|
<a href=/people/j/johnny-wei/>Johnny Wei</a>
|
<a href=/people/a/aram-galstyan/>Aram Galstyan</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/W19-23/ class=text-muted>Proceedings of the Workshop on Methods for Optimizing and Evaluating Neural Language Generation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2310><div class="card-body p-3 small">Despite advances in open-domain dialogue systems, automatic evaluation of such <a href=https://en.wikipedia.org/wiki/System>systems</a> is still a challenging problem. Traditional reference-based metrics such as <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a> are ineffective because there could be many valid responses for a given context that share no common words with reference responses. A recent work proposed Referenced metric and Unreferenced metric Blended Evaluation Routine (RUBER) to combine a learning-based metric, which predicts relatedness between a generated response and a given query, with reference-based metric ; it showed high correlation with human judgments. In this paper, we explore using contextualized word embeddings to compute more accurate <a href=https://en.wikipedia.org/wiki/Coefficient_of_relationship>relatedness scores</a>, thus better evaluation metrics. Experiments show that our evaluation metrics outperform RUBER, which is trained on static embeddings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1172.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1172 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1172 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/359670150 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1172" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-1172/>Pun Generation with Surprise</a></strong><br><a href=/people/h/he-he/>He He</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/p/percy-liang/>Percy Liang</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1172><div class="card-body p-3 small">We tackle the problem of generating a pun sentence given a pair of homophones (e.g., died and dyed). Puns are by their very nature statistically anomalous and not amenable to most text generation methods that are supervised by a <a href=https://en.wikipedia.org/wiki/Text_corpus>large corpus</a>. In this paper, we propose an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised approach</a> to <a href=https://en.wikipedia.org/wiki/Pun>pun generation</a> based on lots of raw (unhumorous) text and a surprisal principle. Specifically, we posit that in a pun sentence, there is a strong association between the pun word (e.g., dyed) and the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>distant context</a>, but a strong association between the alternative word (e.g., died) and the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>immediate context</a>. We instantiate the surprisal principle in two ways : (i) as a measure based on the ratio of probabilities given by a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a>, and (ii) a retrieve-and-edit approach based on words suggested by a skip-gram model. Based on human evaluation, our retrieve-and-edit approach generates puns successfully 30 % of the time, doubling the success rate of a neural generation baseline.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1253.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1253 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1253 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N19-1253.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1253" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N19-1253/>On Difficulties of Cross-Lingual Transfer with Order Differences : A Case Study on Dependency Parsing</a></strong><br><a href=/people/w/wasi-ahmad/>Wasi Ahmad</a>
|
<a href=/people/z/zhisong-zhang/>Zhisong Zhang</a>
|
<a href=/people/x/xuezhe-ma/>Xuezhe Ma</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1253><div class="card-body p-3 small">Different languages might have different <a href=https://en.wikipedia.org/wiki/Part_of_speech>word orders</a>. In this paper, we investigate crosslingual transfer and posit that an orderagnostic model will perform better when transferring to distant foreign languages. To test our hypothesis, we train dependency parsers on an <a href=https://en.wikipedia.org/wiki/English_language>English corpus</a> and evaluate their transfer performance on 30 other languages. Specifically, we compare <a href=https://en.wikipedia.org/wiki/Encoder>encoders</a> and <a href=https://en.wikipedia.org/wiki/Code>decoders</a> based on <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>Recurrent Neural Networks (RNNs)</a> and modified self-attentive architectures. The former relies on sequential information while the latter is more flexible at modeling <a href=https://en.wikipedia.org/wiki/Word_order>word order</a>. Rigorous experiments and detailed analysis shows that RNN-based architectures transfer well to languages that are close to <a href=https://en.wikipedia.org/wiki/English_language>English</a>, while self-attentive models have better overall cross-lingual transferability and perform especially well on distant languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-4016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-4016 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-4016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-4016" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N19-4016/>Plan, Write, and Revise : an Interactive System for Open-Domain Story Generation</a></strong><br><a href=/people/s/seraphina-goldfarb-tarrant/>Seraphina Goldfarb-Tarrant</a>
|
<a href=/people/h/haining-feng/>Haining Feng</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/N19-4/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-4016><div class="card-body p-3 small">Story composition is a challenging problem for machines and even for humans. We present a neural narrative generation system that interacts with humans to generate stories. Our system has different levels of human interaction, which enables us to understand at what stage of story-writing human collaboration is most productive, both to improving story quality and human engagement in the writing process. We compare different varieties of interaction in story-writing, story-planning, and diversity controls under time constraints, and show that increased types of human collaboration at both planning and writing stages results in a 10-50 % improvement in story quality as compared to less interactive baselines. We also show an accompanying increase in user engagement and satisfaction with stories as compared to our own less interactive systems and to previous turn-taking approaches to <a href=https://en.wikipedia.org/wiki/Interaction>interaction</a>. Finally, we find that humans tasked with collaboratively improving a particular characteristic of a story are in fact able to do so, which has implications for future uses of human-in-the-loop systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K19-1062.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K19-1062 data-toggle=collapse aria-expanded=false aria-controls=abstract-K19-1062 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K19-1062" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K19-1062/>Deep Structured Neural Network for Event Temporal Relation Extraction</a></strong><br><a href=/people/r/rujun-han/>Rujun Han</a>
|
<a href=/people/i/i-hung-hsu/>I-Hung Hsu</a>
|
<a href=/people/m/mu-yang/>Mu Yang</a>
|
<a href=/people/a/aram-galstyan/>Aram Galstyan</a>
|
<a href=/people/r/ralph-weischedel/>Ralph Weischedel</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a><br><a href=/volumes/K19-1/ class=text-muted>Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K19-1062><div class="card-body p-3 small">We propose a novel deep structured learning framework for event temporal relation extraction. The model consists of 1) a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network (RNN)</a> to learn scoring functions for pair-wise relations, and 2) a <a href=https://en.wikipedia.org/wiki/Structured_support_vector_machine>structured support vector machine (SSVM)</a> to make joint predictions. The <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> automatically learns representations that account for long-term contexts to provide robust features for the structured model, while the SSVM incorporates <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain knowledge</a> such as transitive closure of temporal relations as constraints to make better globally consistent decisions. By jointly training the two components, our <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> combines the benefits of both <a href=https://en.wikipedia.org/wiki/Data-driven_learning>data-driven learning</a> and knowledge exploitation. Experimental results on three high-quality event temporal relation datasets (TCR, MATRES, and TB-Dense) demonstrate that incorporated with pre-trained contextualized embeddings, the proposed model achieves significantly better performances than the state-of-the-art methods on all three datasets. We also provide thorough ablation studies to investigate our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-1505.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-1505 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-1505 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-1505/>Towards Controllable Story Generation</a></strong><br><a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/m/marjan-ghazvininejad/>Marjan Ghazvininejad</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/k/kevin-knight/>Kevin Knight</a><br><a href=/volumes/W18-15/ class=text-muted>Proceedings of the First Workshop on Storytelling</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-1505><div class="card-body p-3 small">We present a general <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> of analyzing existing story corpora to generate controllable and creative new stories. The proposed <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> needs little manual annotation to achieve controllable story generation. It creates a new interface for humans to interact with computers to generate personalized stories. We apply the framework to build recurrent neural network (RNN)-based generation models to control story ending valence and <a href=https://en.wikipedia.org/wiki/Plot_(narrative)>storyline</a>. Experiments show that our methods successfully achieve the control and enhance the coherence of stories through introducing <a href=https://en.wikipedia.org/wiki/Plot_(narrative)>storylines</a>. with additional control factors, the generation model gets lower perplexity, and yields more coherent stories that are faithful to the control factors according to human evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-6003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-6003 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-6003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/279154243 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-6003/>Scalable Construction and Reasoning of Massive Knowledge Bases</a></strong><br><a href=/people/x/xiang-ren/>Xiang Ren</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/N18-6/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorial Abstracts</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-6003><div class="card-body p-3 small">In today&#8217;s information-based society, there is abundant knowledge out there carried in the form of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language texts</a> (e.g., <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>, <a href=https://en.wikipedia.org/wiki/Social_media>social media posts</a>, scientific publications), which spans across various domains (e.g., corporate documents, <a href=https://en.wikipedia.org/wiki/Advertising>advertisements</a>, <a href=https://en.wikipedia.org/wiki/Act_of_Parliament>legal acts</a>, medical reports), which grows at an astonishing rate. Yet this knowledge is mostly inaccessible to computers and overwhelming for human experts to absorb. How to turn such massive and unstructured text data into structured, actionable knowledge, and furthermore, how to teach machines learn to reason and complete the extracted knowledge is a grand challenge to the research community. Traditional IE systems assume abundant human annotations for training high quality machine learning models, which is impractical when trying to deploy IE systems to a broad range of domains, settings and languages. In the first part of the tutorial, we introduce how to extract structured facts (i.e., entities and their relations for types of interest) from <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpora</a> to construct <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge bases</a>, with a focus on methods that are weakly-supervised and domain-independent for timely knowledge base construction across various application domains. In the second part, we introduce how to leverage other knowledge, such as the distributional statistics of characters and words, the annotations for other tasks and other domains, and the linguistics and problem structures, to combat the problem of inadequate supervision, and conduct low-resource information extraction. In the third part, we describe recent advances in knowledge base reasoning.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1130.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1130 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1130 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1130.Notes.zip data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1130.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285803695 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1130" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1130/>Stack-Pointer Networks for Dependency Parsing</a></strong><br><a href=/people/x/xuezhe-ma/>Xuezhe Ma</a>
|
<a href=/people/z/zecong-hu/>Zecong Hu</a>
|
<a href=/people/j/jingzhou-liu/>Jingzhou Liu</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1130><div class="card-body p-3 small">We introduce a novel <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> for dependency parsing : stack-pointer networks (StackPtr). Combining pointer networks (Vinyals et al., 2015) with an internal stack, the proposed model first reads and encodes the whole sentence, then builds the dependency tree top-down (from root-to-leaf) in a depth-first fashion. The <a href=https://en.wikipedia.org/wiki/Call_stack>stack</a> tracks the status of the <a href=https://en.wikipedia.org/wiki/Depth-first_search>depth-first search</a> and the pointer networks select one child for the word at the top of the stack at each step. The StackPtr parser benefits from the information of whole sentence and all previously derived subtree structures, and removes the left-to-right restriction in classical transition-based parsers. Yet the number of steps for building any (non-projective) parse tree is linear in the length of the sentence just as other transition-based parsers, yielding an efficient decoding algorithm with O(n^2) time complexity. We evaluate our model on 29 treebanks spanning 20 languages and different dependency annotation schemas, and achieve state-of-the-art performances on 21 of them<tex-math>O(n^2)</tex-math> time complexity. We evaluate our model on 29 treebanks spanning 20 languages and different dependency annotation schemas, and achieve state-of-the-art performances on 21 of them</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2065.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2065 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2065 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2065/>A Multi-task Learning Approach to Adapting Bilingual Word Embeddings for Cross-lingual Named Entity Recognition</a></strong><br><a href=/people/d/dingquan-wang/>Dingquan Wang</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/k/kevin-duh/>Kevin Duh</a><br><a href=/volumes/I17-2/ class=text-muted>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2065><div class="card-body p-3 small">We show how to adapt bilingual word embeddings (BWE&#8217;s) to bootstrap a cross-lingual name-entity recognition (NER) system in a language with no labeled data. We assume a setting where we are given a comparable corpus with NER labels for the source language only ; our goal is to build a <a href=https://en.wikipedia.org/wiki/NER_model>NER model</a> for the target language. The proposed multi-task model jointly trains bilingual word embeddings while optimizing a NER objective. This creates <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> that are both shared between languages and fine-tuned for the NER task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2612.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2612 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2612 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2612/>Multi-task Domain Adaptation for Sequence Tagging</a></strong><br><a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a><br><a href=/volumes/W17-26/ class=text-muted>Proceedings of the 2nd Workshop on Representation Learning for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2612><div class="card-body p-3 small">Many domain adaptation approaches rely on learning cross domain shared representations to transfer the knowledge learned in one domain to other domains. Traditional <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> only considers adapting for one task. In this paper, we explore multi-task representation learning under the domain adaptation scenario. We propose a neural network framework that supports <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> for multiple tasks simultaneously, and learns shared representations that better generalize for <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a>. We apply the proposed framework to <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> for sequence tagging problems considering two tasks : <a href=https://en.wikipedia.org/wiki/Chinese_word_segmentation>Chinese word segmentation</a> and <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>. Experiments show that multi-task domain adaptation works better than disjoint domain adaptation for each task, and achieves the state-of-the-art results for both tasks in the <a href=https://en.wikipedia.org/wiki/Social_media>social media domain</a>.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Nanyun+Peng" title="Search for 'Nanyun Peng' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/k/kai-wei-chang/ class=align-middle>Kai-Wei Chang</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/r/rujun-han/ class=align-middle>Rujun Han</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/j/jiao-sun/ class=align-middle>Jiao Sun</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/x/xuezhe-ma/ class=align-middle>Xuezhe Ma</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/x/xiang-ren/ class=align-middle>Xiang Ren</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/e/emily-sheng/ class=align-middle>Emily Sheng</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/p/prem-natarajan/ class=align-middle>Prem Natarajan</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/k/kung-hsiang-huang/ class=align-middle>Kung-Hsiang Huang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jonathan-may/ class=align-middle>Jonathan May</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mu-yang/ class=align-middle>Mu Yang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/aram-galstyan/ class=align-middle>Aram Galstyan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/eduard-hovy/ class=align-middle>Eduard Hovy</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/claire-bonial/ class=align-middle>Claire Bonial</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tommaso-caselli/ class=align-middle>Tommaso Caselli</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/snigdha-chaturvedi/ class=align-middle>Snigdha Chaturvedi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elizabeth-clark/ class=align-middle>Elizabeth Clark</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ruihong-huang/ class=align-middle>Ruihong Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mohit-iyyer/ class=align-middle>Mohit Iyyer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alejandro-jaimes/ class=align-middle>Alejandro Jaimes</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/heng-ji/ class=align-middle>Heng Ji</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lara-j-martin/ class=align-middle>Lara J. Martin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/ben-miller/ class=align-middle>Ben Miller</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/teruko-mitamura/ class=align-middle>Teruko Mitamura</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joel-tetreault/ class=align-middle>Joel Tetreault</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dingquan-wang/ class=align-middle>Dingquan Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kevin-duh/ class=align-middle>Kevin Duh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yichao-zhou/ class=align-middle>Yichao Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiangci-li/ class=align-middle>Xiangci Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gully-burns/ class=align-middle>Gully Burns</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mark-dredze/ class=align-middle>Mark Dredze</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/da-yin/ class=align-middle>Da Yin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/liunian-harold-li/ class=align-middle>Liunian Harold Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/ziniu-hu/ class=align-middle>Ziniu Hu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zi-yi-dou/ class=align-middle>Zi-Yi Dou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaolei-huang/ class=align-middle>Xiaolei Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/colin-cherry/ class=align-middle>Colin Cherry</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/greg-durrett/ class=align-middle>Greg Durrett</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/george-foster/ class=align-middle>George Foster</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gholamreza-haffari/ class=align-middle>Gholamreza Haffari</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shahram-khadivi/ class=align-middle>Shahram Khadivi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/swabha-swayamdipta/ class=align-middle>Swabha Swayamdipta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tuhin-chakrabarty/ class=align-middle>Tuhin Chakrabarty</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xurui-zhang/ class=align-middle>Xurui Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/smaranda-muresan/ class=align-middle>Smaranda Muresan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mingyu-derek-ma/ class=align-middle>Mingyu Derek Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nuan-wen/ class=align-middle>Nuan Wen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shikhar-singh/ class=align-middle>Shikhar Singh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/esin-durmus/ class=align-middle>Esin Durmus</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vivek-gupta/ class=align-middle>Vivek Gupta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nelson-f-liu/ class=align-middle>Nelson F. Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yu-su/ class=align-middle>Yu Su</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marjan-ghazvininejad/ class=align-middle>Marjan Ghazvininejad</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kevin-knight/ class=align-middle>Kevin Knight</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sarik-ghazarian/ class=align-middle>Sarik Ghazarian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/johnny-wei/ class=align-middle>Johnny Wei</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/he-he/ class=align-middle>He He</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/percy-liang/ class=align-middle>Percy Liang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wasi-ahmad/ class=align-middle>Wasi Ahmad</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhisong-zhang/ class=align-middle>Zhisong Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/seraphina-goldfarb-tarrant/ class=align-middle>Seraphina Goldfarb-Tarrant</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haining-feng/ class=align-middle>Haining Feng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/william-yang-wang/ class=align-middle>William Yang Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zecong-hu/ class=align-middle>Zecong Hu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jingzhou-liu/ class=align-middle>Jingzhou Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/graham-neubig/ class=align-middle>Graham Neubig</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/i-hung-hsu/ class=align-middle>I-Hung Hsu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ralph-weischedel/ class=align-middle>Ralph Weischedel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/nuse/ class=align-middle>NUSE</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright &nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>