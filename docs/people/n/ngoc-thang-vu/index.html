<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Ngoc Thang Vu - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Ngoc Thang</span> <span class=font-weight-bold>Vu</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.1/>It’s our fault ! : Insights Into Users’ Understanding and Interaction With an Explanatory Collaborative Dialog System</a></strong><br><a href=/people/k/katharina-weitz/>Katharina Weitz</a>
|
<a href=/people/l/lindsey-vanderlyn/>Lindsey Vanderlyn</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a>
|
<a href=/people/e/elisabeth-andre/>Elisabeth André</a><br><a href=/volumes/2021.conll-1/ class=text-muted>Proceedings of the 25th Conference on Computational Natural Language Learning</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--1><div class="card-body p-3 small">Human-AI collaboration, a long standing goal in <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI</a>, refers to a partnership where a human and artificial intelligence work together towards a shared goal. Collaborative dialog allows human-AI teams to communicate and leverage strengths from both partners. To design collaborative dialog systems, it is important to understand what mental models users form about their AI-dialog partners, however, how users perceive these <a href=https://en.wikipedia.org/wiki/System>systems</a> is not fully understood. In this study, we designed a novel, collaborative, communication-based puzzle game and explanatory dialog system. We created a public corpus from 117 conversations and post-surveys and used this to analyze what <a href=https://en.wikipedia.org/wiki/Mental_model>mental models</a> users formed. Key takeaways include : Even when users were not engaged in the <a href=https://en.wikipedia.org/wiki/Game>game</a>, they perceived the AI-dialog partner as intelligent and likeable, implying they saw it as a partner separate from the game. This was further supported by users often overestimating the <a href=https://en.wikipedia.org/wiki/System>system</a>&#8217;s abilities and projecting human-like attributes which led to miscommunications. We conclude that creating shared mental models between users and <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI systems</a> is important to achieving successful dialogs. We propose that our insights on mental models and miscommunication, the <a href=https://en.wikipedia.org/wiki/Game>game</a>, and our <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> provide useful tools for designing collaborative dialog systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-demo.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-demo--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-demo.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-demo.14" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-demo.14/>Beyond <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>Accuracy</a> : A Consolidated Tool for Visual Question Answering Benchmarking</a></strong><br><a href=/people/d/dirk-vath/>Dirk Väth</a>
|
<a href=/people/p/pascal-tilli/>Pascal Tilli</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a><br><a href=/volumes/2021.emnlp-demo/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-demo--14><div class="card-body p-3 small">On the way towards general Visual Question Answering (VQA) systems that are able to answer arbitrary questions, the need arises for evaluation beyond single-metric leaderboards for specific datasets. To this end, we propose a browser-based benchmarking tool for researchers and challenge organizers, with an API for easy integration of new models and datasets to keep up with the fast-changing landscape of VQA. Our tool helps test generalization capabilities of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> across multiple datasets, evaluating not just <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, but also performance in more realistic real-world scenarios such as <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> to input noise. Additionally, we include <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> that measure <a href=https://en.wikipedia.org/wiki/Bias>biases</a> and <a href=https://en.wikipedia.org/wiki/Uncertainty>uncertainty</a>, to further explain model behavior. Interactive filtering facilitates discovery of problematic behavior, down to the <a href=https://en.wikipedia.org/wiki/Sample_(statistics)>data sample level</a>. As proof of concept, we perform a case study on four <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. We find that state-of-the-art VQA models are optimized for specific tasks or datasets, but fail to generalize even to other in-domain test sets, for example they can not recognize text in images. Our <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> allow us to quantify which image and question embeddings provide most robustness to a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. All code s publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.americasnlp-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--americasnlp-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.americasnlp-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.americasnlp-1.23/>Findings of the AmericasNLP 2021 Shared Task on Open Machine Translation for Indigenous Languages of the Americas<span class=acl-fixed-case>A</span>mericas<span class=acl-fixed-case>NLP</span> 2021 Shared Task on Open Machine Translation for Indigenous Languages of the <span class=acl-fixed-case>A</span>mericas</a></strong><br><a href=/people/m/manuel-mager/>Manuel Mager</a>
|
<a href=/people/a/arturo-oncevay/>Arturo Oncevay</a>
|
<a href=/people/a/abteen-ebrahimi/>Abteen Ebrahimi</a>
|
<a href=/people/j/john-ortega/>John Ortega</a>
|
<a href=/people/a/annette-rios-gonzales/>Annette Rios</a>
|
<a href=/people/a/angela-fan/>Angela Fan</a>
|
<a href=/people/x/ximena-gutierrez-vasques/>Ximena Gutierrez-Vasques</a>
|
<a href=/people/l/luis-chiruzzo/>Luis Chiruzzo</a>
|
<a href=/people/g/gustavo-gimenez-lugo/>Gustavo Giménez-Lugo</a>
|
<a href=/people/r/ricardo-ramos/>Ricardo Ramos</a>
|
<a href=/people/i/ivan-meza-ruiz/>Ivan Vladimir Meza Ruiz</a>
|
<a href=/people/r/rolando-coto-solano/>Rolando Coto-Solano</a>
|
<a href=/people/a/alexis-palmer/>Alexis Palmer</a>
|
<a href=/people/e/elisabeth-mager-hois/>Elisabeth Mager-Hois</a>
|
<a href=/people/v/vishrav-chaudhary/>Vishrav Chaudhary</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a>
|
<a href=/people/k/katharina-kann/>Katharina Kann</a><br><a href=/volumes/2021.americasnlp-1/ class=text-muted>Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--americasnlp-1--23><div class="card-body p-3 small">This paper presents the results of the 2021 Shared Task on Open Machine Translation for <a href=https://en.wikipedia.org/wiki/Indigenous_languages_of_the_Americas>Indigenous Languages of the Americas</a>. The shared task featured two independent tracks, and participants submitted <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation systems</a> for up to 10 <a href=https://en.wikipedia.org/wiki/Indigenous_language>indigenous languages</a>. Overall, 8 teams participated with a total of 214 submissions. We provided <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training sets</a> consisting of data collected from various sources, as well as manually translated sentences for the <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>development and test sets</a>. An official <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baseline</a> trained on this <a href=https://en.wikipedia.org/wiki/Data>data</a> was also provided. Team submissions featured a variety of <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a>, including both statistical and neural models, and for the majority of languages, many teams were able to considerably improve over the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a>. The best performing <a href=https://en.wikipedia.org/wiki/System>systems</a> achieved 12.97 ChrF higher than <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a>, when averaged across languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--blackboxnlp-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.blackboxnlp-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.blackboxnlp-1.3" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.blackboxnlp-1.3/>Does <a href=https://en.wikipedia.org/wiki/Knowledge>External Knowledge</a> Help Explainable <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>Natural Language Inference</a>? Automatic Evaluation vs. Human Ratings</a></strong><br><a href=/people/h/hendrik-schuff/>Hendrik Schuff</a>
|
<a href=/people/h/hsiu-yu-yang/>Hsiu-Yu Yang</a>
|
<a href=/people/h/heike-adel/>Heike Adel</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a><br><a href=/volumes/2021.blackboxnlp-1/ class=text-muted>Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--blackboxnlp-1--3><div class="card-body p-3 small">Natural language inference (NLI) requires models to learn and apply commonsense knowledge. These reasoning abilities are particularly important for explainable NLI systems that generate a <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language explanation</a> in addition to their label prediction. The integration of external knowledge has been shown to improve NLI systems, here we investigate whether it can also improve their explanation capabilities. For this, we investigate different sources of external knowledge and evaluate the performance of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on in-domain data as well as on special transfer datasets that are designed to assess fine-grained reasoning capabilities. We find that different sources of knowledge have a different effect on reasoning abilities, for example, <a href=https://en.wikipedia.org/wiki/Implicit_knowledge>implicit knowledge</a> stored in language models can hinder reasoning on numbers and <a href=https://en.wikipedia.org/wiki/Negation>negations</a>. Finally, we conduct the largest and most fine-grained explainable NLI crowdsourcing study to date. It reveals that even large differences in automatic performance scores do neither reflect in human ratings of label, explanation, commonsense nor <a href=https://en.wikipedia.org/wiki/Grammar>grammar correctness</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.metanlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.metanlp-1.0/>Proceedings of the 1st Workshop on Meta Learning and Its Applications to Natural Language Processing</a></strong><br><a href=/people/h/hung-yi-lee/>Hung-Yi Lee</a>
|
<a href=/people/m/mitra-mohtarami/>Mitra Mohtarami</a>
|
<a href=/people/s/shang-wen-li/>Shang-Wen Li</a>
|
<a href=/people/d/di-jin/>Di Jin</a>
|
<a href=/people/m/mandy-korpusik/>Mandy Korpusik</a>
|
<a href=/people/s/shuyan-dong/>Shuyan Dong</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a>
|
<a href=/people/d/dilek-hakkani-tur/>Dilek Hakkani-Tur</a><br><a href=/volumes/2021.metanlp-1/ class=text-muted>Proceedings of the 1st Workshop on Meta Learning and Its Applications to Natural Language Processing</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.134.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--134 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.134 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928825 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.134/>Fast and Accurate Non-Projective Dependency Tree Linearization</a></strong><br><a href=/people/x/xiang-yu/>Xiang Yu</a>
|
<a href=/people/s/simon-tannert/>Simon Tannert</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a>
|
<a href=/people/j/jonas-kuhn/>Jonas Kuhn</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--134><div class="card-body p-3 small">We propose a graph-based method to tackle the dependency tree linearization task. We formulate the task as a Traveling Salesman Problem (TSP), and use a biaffine attention model to calculate the edge costs. We facilitate the decoding by solving the <a href=https://en.wikipedia.org/wiki/Tree_(graph_theory)>TSP</a> for each subtree and combining the solution into a projective tree. We then design a <a href=https://en.wikipedia.org/wiki/Transition_system>transition system</a> as <a href=https://en.wikipedia.org/wiki/Post-processing>post-processing</a>, inspired by non-projective transition-based parsing, to obtain non-projective sentences. Our proposed method outperforms the state-of-the-art <a href=https://en.wikipedia.org/wiki/Linearizer>linearizer</a> while being 10 times faster in <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a> and <a href=https://en.wikipedia.org/wiki/Decoding_methods>decoding</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sustainlp-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sustainlp-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sustainlp-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939432 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.sustainlp-1.10/>A Two-stage Model for Slot Filling in Low-resource Settings : Domain-agnostic Non-slot Reduction and Pretrained Contextual Embeddings</a></strong><br><a href=/people/c/cennet-oguz/>Cennet Oguz</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a><br><a href=/volumes/2020.sustainlp-1/ class=text-muted>Proceedings of SustaiNLP: Workshop on Simple and Efficient Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sustainlp-1--10><div class="card-body p-3 small">Learning-based slot filling-a key component of spoken language understanding systems-typically requires a large amount of in-domain hand-labeled data for training. In this paper, we propose a novel two-stage model architecture that can be trained with only a few in-domain hand-labeled examples. The first step is designed to remove non-slot tokens (i.e., O labeled tokens), as they introduce <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a> in the input of slot filling models. This step is domain-agnostic and therefore, can be trained by exploiting out-of-domain data. The second step identifies slot names only for slot tokens by using state-of-the-art pretrained contextual embeddings such as <a href=https://en.wikipedia.org/wiki/ELMO>ELMO</a> and BERT. We show that our approach outperforms other state-of-art systems on the SNIPS benchmark dataset.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5908.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5908 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5908 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5908/>To Combine or Not To Combine? A Rainbow Deep Reinforcement Learning Agent for Dialog Policies</a></strong><br><a href=/people/d/dirk-vath/>Dirk Väth</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a><br><a href=/volumes/W19-59/ class=text-muted>Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5908><div class="card-body p-3 small">In this paper, we explore state-of-the-art deep reinforcement learning methods for dialog policy training such as prioritized experience replay, double deep Q-Networks, dueling network architectures and distributional learning. Our main findings show that each individual method improves the rewards and the task success rate but combining these methods in a Rainbow agent, which performs best across tasks and environments, is a non-trivial task. We, therefore, provide insights about the influence of each method on the combination and how to combine them to form a Rainbow agent.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-1204.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-1204 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-1204 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-1204/>Addressing Low-Resource Scenarios with Character-aware Embeddings</a></strong><br><a href=/people/s/sean-papay/>Sean Papay</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a><br><a href=/volumes/W18-12/ class=text-muted>Proceedings of the Second Workshop on Subword/Character LEvel Models</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-1204><div class="card-body p-3 small">Most modern approaches to computing word embeddings assume the availability of <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpora</a> with billions of words. In this paper, we explore a setup where only <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a> with millions of words are available, and many words in any new text are out of vocabulary. This setup is both of practical interests modeling the situation for specific domains and low-resource languages and of psycholinguistic interest, since it corresponds much more closely to the actual experiences and challenges of human language learning and use. We compare standard skip-gram word embeddings with character-based embeddings on word relatedness prediction. Skip-grams excel on large corpora, while character-based embeddings do well on small corpora generally and rare and complex words specifically. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> can be combined easily.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6021.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6021 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6021 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6021/>Approximate Dynamic Oracle for Dependency Parsing with <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>Reinforcement Learning</a></a></strong><br><a href=/people/x/xiang-yu/>Xiang Yu</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a>
|
<a href=/people/j/jonas-kuhn/>Jonas Kuhn</a><br><a href=/volumes/W18-60/ class=text-muted>Proceedings of the Second Workshop on Universal Dependencies (UDW 2018)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6021><div class="card-body p-3 small">We present a general approach with <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning (RL)</a> to approximate dynamic oracles for transition systems where exact dynamic oracles are difficult to derive. We treat <a href=https://en.wikipedia.org/wiki/Oracle_machine>oracle parsing</a> as a reinforcement learning problem, design the reward function inspired by the classical dynamic oracle, and use Deep Q-Learning (DQN) techniques to train the <a href=https://en.wikipedia.org/wiki/Oracle_machine>oracle</a> with gold trees as features. The combination of a priori knowledge and <a href=https://en.wikipedia.org/wiki/Data-driven_programming>data-driven methods</a> enables an efficient dynamic oracle, which improves the <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> performance over static oracles in several <a href=https://en.wikipedia.org/wiki/Transition_system>transition systems</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2032.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-2032 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-2032 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-2032/>Introducing Two Vietnamese Datasets for Evaluating Semantic Models of (Dis-)Similarity and Relatedness<span class=acl-fixed-case>V</span>ietnamese Datasets for Evaluating Semantic Models of (Dis-)Similarity and Relatedness</a></strong><br><a href=/people/k/kim-anh-nguyen/>Kim Anh Nguyen</a>
|
<a href=/people/s/sabine-schulte-im-walde/>Sabine Schulte im Walde</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-2032><div class="card-body p-3 small">We present two novel datasets for the low-resource language Vietnamese to assess models of semantic similarity : ViCon comprises pairs of <a href=https://en.wikipedia.org/wiki/Synonym>synonyms</a> and <a href=https://en.wikipedia.org/wiki/Opposite_(semantics)>antonyms</a> across word classes, thus offering data to distinguish between similarity and dissimilarity. ViSim-400 provides degrees of similarity across five semantic relations, as rated by human judges. The two <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> are verified through standard co-occurrence and neural network models, showing results comparable to the respective English datasets.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2106.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2106 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2106 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P17-2106/>Character Composition Model with <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>Convolutional Neural Networks</a> for Dependency Parsing on Morphologically Rich Languages</a></strong><br><a href=/people/x/xiang-yu/>Xiang Yu</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2106><div class="card-body p-3 small">We present a transition-based dependency parser that uses a <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural network</a> to compose word representations from characters. The character composition model shows great improvement over the word-lookup model, especially for parsing <a href=https://en.wikipedia.org/wiki/Agglutinative_language>agglutinative languages</a>. These improvements are even better than using pre-trained word embeddings from extra data. On the SPMRL data sets, our <a href=https://en.wikipedia.org/wiki/System>system</a> outperforms the previous best greedy parser (Ballesteros et. al, 2015) by a margin of 3 % on average.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4118.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4118 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4118 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4118/>A General-Purpose Tagger with <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>Convolutional Neural Networks</a></a></strong><br><a href=/people/x/xiang-yu/>Xiang Yu</a>
|
<a href=/people/a/agnieszka-falenska/>Agnieszka Falenska</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a><br><a href=/volumes/W17-41/ class=text-muted>Proceedings of the First Workshop on Subword and Character Level Models in NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4118><div class="card-body p-3 small">We present a general-purpose tagger based on convolutional neural networks (CNN), used for both composing word vectors and encoding context information. The CNN tagger is robust across different tagging tasks : without task-specific tuning of hyper-parameters, it achieves state-of-the-art results in <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a>, morphological tagging and supertagging. The CNN tagger is also robust against the out-of-vocabulary problem ; it performs well on artificially unnormalized texts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5530.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5530 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5530 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5530/>Neural-based Context Representation Learning for Dialog Act Classification</a></strong><br><a href=/people/d/daniel-ortega/>Daniel Ortega</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a><br><a href=/volumes/W17-55/ class=text-muted>Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5530><div class="card-body p-3 small">We explore context representation learning methods in neural-based models for dialog act classification. We propose and compare extensively different methods which combine <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network architectures</a> and attention mechanisms (AMs) at different context levels. Our experimental results on two benchmark datasets show consistent improvements compared to the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> without contextual information and reveal that the most suitable AM in the <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> depends on the nature of the dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1022.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1022 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1022 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1022/>Hierarchical Embeddings for Hypernymy Detection and Directionality</a></strong><br><a href=/people/k/kim-anh-nguyen/>Kim Anh Nguyen</a>
|
<a href=/people/m/maximilian-koper/>Maximilian Köper</a>
|
<a href=/people/s/sabine-schulte-im-walde/>Sabine Schulte im Walde</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1022><div class="card-body p-3 small">We present a novel neural model HyperVec to learn hierarchical embeddings for hypernymy detection and directionality. While previous <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> have shown limitations on prototypical hypernyms, HyperVec represents an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised measure</a> where <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> are learned in a specific order and capture the hypernymhyponym distributional hierarchy. Moreover, our model is able to generalize over unseen hypernymy pairs, when using only small sets of training data, and by mapping to other languages. Results on benchmark datasets show that HyperVec outperforms both state-of-the-art unsupervised measures and embedding models on hypernymy detection and directionality, and on predicting graded lexical entailment.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-1008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-1008 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-1008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=E17-1008" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/E17-1008/>Distinguishing Antonyms and Synonyms in a Pattern-based Neural Network</a></strong><br><a href=/people/k/kim-anh-nguyen/>Kim Anh Nguyen</a>
|
<a href=/people/s/sabine-schulte-im-walde/>Sabine Schulte im Walde</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a><br><a href=/volumes/E17-1/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-1008><div class="card-body p-3 small">Distinguishing between <a href=https://en.wikipedia.org/wiki/Opposite_(semantics)>antonyms</a> and <a href=https://en.wikipedia.org/wiki/Synonym>synonyms</a> is a key task to achieve high performance in NLP systems. While they are notoriously difficult to distinguish by distributional co-occurrence models, pattern-based methods have proven effective to differentiate between the relations. In this paper, we present a novel neural network model AntSynNET that exploits lexico-syntactic patterns from syntactic parse trees. In addition to the lexical and syntactic information, we successfully integrate the distance between the related words along the syntactic path as a new pattern feature. The results from <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> experiments show that AntSynNET improves the performance over prior <a href=https://en.wikipedia.org/wiki/Pattern_recognition>pattern-based methods</a>.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Ngoc+Thang+Vu" title="Search for 'Ngoc Thang Vu' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/x/xiang-yu/ class=align-middle>Xiang Yu</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/k/kim-anh-nguyen/ class=align-middle>Kim Anh Nguyen</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/sabine-schulte-im-walde/ class=align-middle>Sabine Schulte im Walde</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/jonas-kuhn/ class=align-middle>Jonas Kuhn</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/dirk-vath/ class=align-middle>Dirk Väth</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/s/simon-tannert/ class=align-middle>Simon Tannert</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/katharina-weitz/ class=align-middle>Katharina Weitz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lindsey-vanderlyn/ class=align-middle>Lindsey Vanderlyn</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elisabeth-andre/ class=align-middle>Elisabeth Andre</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/agnieszka-falenska/ class=align-middle>Agnieszka Falenska</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/daniel-ortega/ class=align-middle>Daniel Ortega</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pascal-tilli/ class=align-middle>Pascal Tilli</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maximilian-koper/ class=align-middle>Maximilian Köper</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/manuel-mager/ class=align-middle>Manuel Mager</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/arturo-oncevay/ class=align-middle>Arturo Oncevay</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/abteen-ebrahimi/ class=align-middle>Abteen Ebrahimi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/john-ortega/ class=align-middle>John Ortega</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/annette-rios-gonzales/ class=align-middle>Annette Rios Gonzales</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/angela-fan/ class=align-middle>Angela Fan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/ximena-gutierrez-vasques/ class=align-middle>Ximena Gutierrez-Vasques</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luis-chiruzzo/ class=align-middle>Luis Chiruzzo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gustavo-gimenez-lugo/ class=align-middle>Gustavo Giménez-Lugo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ricardo-ramos/ class=align-middle>Ricardo Ramos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ivan-meza-ruiz/ class=align-middle>Ivan Meza-Ruiz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rolando-coto-solano/ class=align-middle>Rolando Coto-Solano</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexis-palmer/ class=align-middle>Alexis Palmer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elisabeth-mager-hois/ class=align-middle>Elisabeth Mager-Hois</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vishrav-chaudhary/ class=align-middle>Vishrav Chaudhary</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/graham-neubig/ class=align-middle>Graham Neubig</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/katharina-kann/ class=align-middle>Katharina Kann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hendrik-schuff/ class=align-middle>Hendrik Schuff</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hsiu-yu-yang/ class=align-middle>Hsiu-Yu Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/heike-adel/ class=align-middle>Heike Adel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sean-papay/ class=align-middle>Sean Papay</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sebastian-pado/ class=align-middle>Sebastian Padó</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hung-yi-lee/ class=align-middle>Hung-Yi Lee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mitra-mohtarami/ class=align-middle>Mitra Mohtarami</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shang-wen-li/ class=align-middle>Shang-Wen Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/di-jin/ class=align-middle>Di Jin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mandy-korpusik/ class=align-middle>Mandy Korpusik</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shuyan-dong/ class=align-middle>Shuyan Dong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dilek-hakkani-tur/ class=align-middle>Dilek Hakkani-Tur</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cennet-oguz/ class=align-middle>Cennet Oguz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/americasnlp/ class=align-middle>AmericasNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/blackboxnlp/ class=align-middle>BlackboxNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/metanlp/ class=align-middle>MetaNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/sustainlp/ class=align-middle>sustainlp</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>