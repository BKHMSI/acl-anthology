<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Hui Liu - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Hui</span> <span class=font-weight-bold>Liu</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.126.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--126 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.126 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.126/>Toward Annotator Group Bias in Crowdsourcing</a></strong><br><a href=/people/h/haochen-liu/>Haochen Liu</a>
|
<a href=/people/j/joseph-thekinen/>Joseph Thekinen</a>
|
<a href=/people/s/sinem-mollaoglu/>Sinem Mollaoglu</a>
|
<a href=/people/d/da-tang/>Da Tang</a>
|
<a href=/people/j/ji-yang/>Ji Yang</a>
|
<a href=/people/y/youlong-cheng/>Youlong Cheng</a>
|
<a href=/people/h/hui-liu/>Hui Liu</a>
|
<a href=/people/j/jiliang-tang/>Jiliang Tang</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--126><div class="card-body p-3 small">Crowdsourcing has emerged as a popular approach for collecting annotated data to train <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised machine learning models</a> However annotator bias can lead to defective annotations Though there are a few works investigating individual annotator bias the group effects in annotators are largely overlooked In this work we reveal that annotators within the same demographic group tend to show consistent group bias in annotation tasks and thus we conduct an initial study on annotator group bias We first empirically verify the existence of annotator group bias in various real world crowdsourcing datasets Then we develop a novel probabilistic graphical framework GroupAnno to capture annotator group bias with an extended Expectation Maximization EM algorithm We conduct experiments on both synthetic and real world datasets Experimental results demonstrate the effectiveness of our model in modeling annotator group bias in label aggregation and model learning over competitive baselines</div></div><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-short.36.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-short--36 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-short.36 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-short.36" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-short.36/>Enhancing Descriptive Image Captioning with Natural Language Inference</a></strong><br><a href=/people/z/zhan-shi/>Zhan Shi</a>
|
<a href=/people/h/hui-liu/>Hui Liu</a>
|
<a href=/people/x/xiaodan-zhu/>Xiaodan Zhu</a><br><a href=/volumes/2021.acl-short/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-short--36><div class="card-body p-3 small">Generating descriptive sentences that convey non-trivial, detailed, and salient information about <a href=https://en.wikipedia.org/wiki/Image>images</a> is an important goal of image captioning. In this paper we propose a novel approach to encourage captioning models to produce more detailed captions using natural language inference, based on the motivation that, among different captions of an image, descriptive captions are more likely to entail less descriptive captions. Specifically, we construct directed inference graphs for <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>reference captions</a> based on <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language inference</a>. A <a href=https://en.wikipedia.org/wiki/PageRank>PageRank algorithm</a> is then employed to estimate the descriptiveness score of each <a href=https://en.wikipedia.org/wiki/Vertex_(graph_theory)>node</a>. Built on that, we use reference sampling and weighted designated rewards to guide <a href=https://en.wikipedia.org/wiki/Closed_captioning>captioning</a> to generate descriptive captions. The results on MSCOCO show that the proposed method outperforms the baselines significantly on a wide range of conventional and descriptiveness-related evaluation metrics.<i>descriptive</i> sentences that convey non-trivial, detailed, and salient information about images is an important goal of image captioning. In this paper we propose a novel approach to encourage captioning models to produce more detailed captions using natural language inference, based on the motivation that, among different captions of an image, descriptive captions are more likely to entail less descriptive captions. Specifically, we construct directed inference graphs for reference captions based on natural language inference. A PageRank algorithm is then employed to estimate the descriptiveness score of each node. Built on that, we use reference sampling and weighted designated rewards to guide captioning to generate descriptive captions. The results on MSCOCO show that the proposed method outperforms the baselines significantly on a wide range of conventional and descriptiveness-related evaluation metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.181.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--181 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.181 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.181" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.181/>Unsupervised Conversation Disentanglement through <a href=https://en.wikipedia.org/wiki/Co-training>Co-Training</a></a></strong><br><a href=/people/h/hui-liu/>Hui Liu</a>
|
<a href=/people/z/zhan-shi/>Zhan Shi</a>
|
<a href=/people/x/xiaodan-zhu/>Xiaodan Zhu</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--181><div class="card-body p-3 small">Conversation disentanglement aims to separate intermingled messages into detached sessions, which is a fundamental task in understanding multi-party conversations. Existing work on conversation disentanglement relies heavily upon human-annotated datasets, which is expensive to obtain in practice. In this work, we explore training a conversation disentanglement model without referencing any human annotations. Our method is built upon the deep co-training algorithm, which consists of two <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> : a message-pair classifier and a session classifier. The former is responsible of retrieving local relations between two messages while the latter categorizes a message to a session by capturing context-aware information. Both the two <a href=https://en.wikipedia.org/wiki/Computer_network>networks</a> are initialized respectively with pseudo data built from the <a href=https://en.wikipedia.org/wiki/Text_corpus>unannotated corpus</a>. During the deep co-training process, we use the session classifier as a reinforcement learning component to learn a session assigning policy by maximizing the local rewards given by the message-pair classifier. For the message-pair classifier, we enrich its training data by retrieving message pairs with high confidence from the disentangled sessions predicted by the session classifier. Experimental results on the large Movie Dialogue Dataset demonstrate that our proposed approach achieves competitive performance compared to previous supervised methods. Further experiments show that the predicted disentangled conversations can promote the performance on the downstream task of multi-party response selection.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.390.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--390 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.390 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.coling-main.390" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.390/>Does Gender Matter? Towards Fairness in Dialogue Systems</a></strong><br><a href=/people/h/haochen-liu/>Haochen Liu</a>
|
<a href=/people/j/jamell-dacon/>Jamell Dacon</a>
|
<a href=/people/w/wenqi-fan/>Wenqi Fan</a>
|
<a href=/people/h/hui-liu/>Hui Liu</a>
|
<a href=/people/z/zitao-liu/>Zitao Liu</a>
|
<a href=/people/j/jiliang-tang/>Jiliang Tang</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--390><div class="card-body p-3 small">Recently there are increasing concerns about the <a href=https://en.wikipedia.org/wiki/Fairness>fairness</a> of <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>Artificial Intelligence (AI)</a> in real-world applications such as <a href=https://en.wikipedia.org/wiki/Computer_vision>computer vision</a> and <a href=https://en.wikipedia.org/wiki/Recommender_system>recommendations</a>. For example, <a href=https://en.wikipedia.org/wiki/Computer_vision>recognition algorithms</a> in <a href=https://en.wikipedia.org/wiki/Computer_vision>computer vision</a> are unfair to black people such as poorly detecting their faces and inappropriately identifying them as <a href=https://en.wikipedia.org/wiki/Gorilla>gorillas</a>. As one crucial application of <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI</a>, <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a> have been extensively applied in our society. They are usually built with real human conversational data ; thus they could inherit some fairness issues which are held in the real world. However, the <a href=https://en.wikipedia.org/wiki/Equity_(economics)>fairness</a> of <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a> has not been well investigated. In this paper, we perform a pioneering study about the <a href=https://en.wikipedia.org/wiki/Fair_division>fairness issues</a> in <a href=https://en.wikipedia.org/wiki/Dialogue>dialogue systems</a>. In particular, we construct a benchmark dataset and propose quantitative measures to understand <a href=https://en.wikipedia.org/wiki/Equity_(economics)>fairness</a> in dialogue models. Our studies demonstrate that popular dialogue models show significant prejudice towards different genders and races. Besides, to mitigate the bias in <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a>, we propose two simple but effective debiasing methods. Experiments show that our <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> can reduce the bias in <a href=https://en.wikipedia.org/wiki/Dialogue>dialogue systems</a> significantly. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and the implementation are released to foster fairness research in <a href=https://en.wikipedia.org/wiki/Dialogue>dialogue systems</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-4004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-4004 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-4004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-4004/>INS : An Interactive Chinese News Synthesis System<span class=acl-fixed-case>INS</span>: An Interactive <span class=acl-fixed-case>C</span>hinese News Synthesis System</a></strong><br><a href=/people/h/hui-liu/>Hui Liu</a>
|
<a href=/people/w/wentao-qin/>Wentao Qin</a>
|
<a href=/people/x/xiaojun-wan/>Xiaojun Wan</a><br><a href=/volumes/N19-4/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-4004><div class="card-body p-3 small">Nowadays, we are surrounded by more and more <a href=https://en.wikipedia.org/wiki/Online_newspaper>online news articles</a>. Tens or hundreds of <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a> need to be read if we wish to explore a hot news event or topic. So it is of vital importance to automatically synthesize a batch of <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a> related to the event or topic into a new synthesis article (or overview article) for reader&#8217;s convenience. It is so challenging to make news synthesis fully automatic that there is no successful solution by now. In this paper, we put forward a novel Interactive News Synthesis system (i.e. INS), which can help generate news overview articles automatically or by interacting with users. More importantly, <a href=https://en.wikipedia.org/wiki/Immigration_and_Naturalization_Service>INS</a> can serve as a tool for editors to help them finish their jobs. In our experiments, INS performs well on both <a href=https://en.wikipedia.org/wiki/Topic_and_comment>topic representation</a> and synthesis article generation. A <a href=https://en.wikipedia.org/wiki/User_study>user study</a> also demonstrates the usefulness and users&#8217; satisfaction with the INS tool. A demo video is available at.<url>https://youtu.be/7ItteKW3GEk</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1560.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1560 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1560 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1560/>Towards Explainable NLP : A Generative Explanation Framework for Text Classification<span class=acl-fixed-case>NLP</span>: A Generative Explanation Framework for Text Classification</a></strong><br><a href=/people/h/hui-liu/>Hui Liu</a>
|
<a href=/people/q/qingyu-yin/>Qingyu Yin</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1560><div class="card-body p-3 small">Building explainable systems is a critical problem in the field of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing (NLP)</a>, since most <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning models</a> provide no explanations for the predictions. Existing approaches for explainable machine learning systems tend to focus on interpreting the outputs or the connections between inputs and outputs. However, the fine-grained information (e.g. textual explanations for the labels) is often ignored, and the systems do not explicitly generate the human-readable explanations. To solve this problem, we propose a novel generative explanation framework that learns to make classification decisions and generate fine-grained explanations at the same time. More specifically, we introduce the explainable factor and the minimum risk training approach that learn to generate more reasonable explanations. We construct two new <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> that contain summaries, rating scores, and fine-grained reasons. We conduct experiments on both <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, comparing with several strong neural network baseline systems. Experimental results show that our method surpasses all baselines on both <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, and is able to generate concise explanations at the same time.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Hui+Liu" title="Search for 'Hui Liu' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/z/zhan-shi/ class=align-middle>Zhan Shi</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/x/xiaodan-zhu/ class=align-middle>Xiaodan Zhu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/haochen-liu/ class=align-middle>Haochen Liu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jiliang-tang/ class=align-middle>Jiliang Tang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/joseph-thekinen/ class=align-middle>Joseph Thekinen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/s/sinem-mollaoglu/ class=align-middle>Sinem Mollaoglu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/da-tang/ class=align-middle>Da Tang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/ji-yang/ class=align-middle>Ji Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/youlong-cheng/ class=align-middle>Youlong Cheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jamell-dacon/ class=align-middle>Jamell Dacon</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wenqi-fan/ class=align-middle>Wenqi Fan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zitao-liu/ class=align-middle>Zitao Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wentao-qin/ class=align-middle>Wentao Qin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaojun-wan/ class=align-middle>Xiaojun Wan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qingyu-yin/ class=align-middle>Qingyu Yin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/william-yang-wang/ class=align-middle>William Yang Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>