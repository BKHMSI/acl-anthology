<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Hiroyuki Shinnou - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Hiroyuki</span> <span class=font-weight-bold>Shinnou</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ranlp-1.72.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ranlp-1--72 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ranlp-1.72 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ranlp-1.72/>Domain-Specific Japanese ELECTRA Model Using a Small Corpus<span class=acl-fixed-case>J</span>apanese <span class=acl-fixed-case>ELECTRA</span> Model Using a Small Corpus</a></strong><br><a href=/people/y/youki-itoh/>Youki Itoh</a>
|
<a href=/people/h/hiroyuki-shinnou/>Hiroyuki Shinnou</a><br><a href=/volumes/2021.ranlp-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ranlp-1--72><div class="card-body p-3 small">Recently, domain shift, which affects <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> due to differences in data between source and target domains, has become a serious issue when using <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning methods</a> to solve <a href=https://en.wikipedia.org/wiki/Natural-language_processing>natural language processing tasks</a>. With additional pretraining and fine-tuning using a target domain corpus, pretraining models such as BERT (Bidirectional Encoder Representations from Transformers) can address this issue. However, the additional pretraining of the BERT model is difficult because it requires significant computing resources. The efficiently learning an encoder that classifies token replacements accurately (ELECTRA) pretraining model replaces the BERT pretraining method&#8217;s masked language modeling with a method called replaced token detection, which improves the computational efficiency and allows the additional pretraining of the model to a practical extent. Herein, we propose a method for addressing the computational efficiency of pretraining models in domain shift by constructing an ELECTRA pretraining model on a Japanese dataset and additional pretraining this model in a downstream task using a corpus from the target domain. We constructed a pretraining model for ELECTRA in <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> and conducted experiments on a document classification task using data from <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese news articles</a>. Results show that even a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> smaller than the pretrained model performs equally well.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ranlp-1.77.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ranlp-1--77 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ranlp-1.77 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ranlp-1.77/>Application of Mix-Up Method in Document Classification Task Using BERT<span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/n/naoki-kikuta/>Naoki Kikuta</a>
|
<a href=/people/h/hiroyuki-shinnou/>Hiroyuki Shinnou</a><br><a href=/volumes/2021.ranlp-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ranlp-1--77><div class="card-body p-3 small">The mix-up method (Zhang et al., 2017), one of the methods for <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a>, is known to be easy to implement and highly effective. Although the mix-up method is intended for image identification, it can also be applied to <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. In this paper, we attempt to apply the mix-up method to a document classification task using bidirectional encoder representations from transformers (BERT) (Devlin et al., 2018). Since BERT allows for two-sentence input, we concatenated word sequences from two documents with different labels and used the multi-class output as the supervised data with a one-hot vector. In an experiment using the livedoor news corpus, which is <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>, we compared the accuracy of <a href=https://en.wikipedia.org/wiki/Document_classification>document classification</a> using two methods for selecting documents to be concatenated with that of ordinary document classification. As a result, we found that the proposed method is better than the normal classification when the documents with labels shortages are mixed preferentially. This indicates that how to choose documents for mix-up has a significant impact on the results.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bucc-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bucc-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bucc-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bucc-1.4/>Automatic Creation of Correspondence Table of Meaning Tags from Two Dictionaries in One Language Using Bilingual Word Embedding</a></strong><br><a href=/people/t/teruo-hirabayashi/>Teruo Hirabayashi</a>
|
<a href=/people/k/kanako-komiya/>Kanako Komiya</a>
|
<a href=/people/m/masayuki-asahara/>Masayuki Asahara</a>
|
<a href=/people/h/hiroyuki-shinnou/>Hiroyuki Shinnou</a><br><a href=/volumes/2020.bucc-1/ class=text-muted>Proceedings of the 13th Workshop on Building and Using Comparable Corpora</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bucc-1--4><div class="card-body p-3 small">In this paper, we show how to use bilingual word embeddings (BWE) to automatically create a corresponding table of meaning tags from two dictionaries in one language and examine the effectiveness of the method. To do this, we had a problem : the meaning tags do not always correspond one-to-one because the granularities of the <a href=https://en.wikipedia.org/wiki/Word_sense>word senses</a> and the <a href=https://en.wikipedia.org/wiki/Concept>concepts</a> are different from each other. Therefore, we regarded the concept tag that corresponds to a <a href=https://en.wikipedia.org/wiki/Word_sense>word sense</a> the most as the correct concept tag corresponding the <a href=https://en.wikipedia.org/wiki/Word_sense>word sense</a>. We used two BWE methods, a <a href=https://en.wikipedia.org/wiki/Linear_map>linear transformation matrix</a> and VecMap. We evaluated the most frequent sense (MFS) method and the corpus concatenation method for comparison. The accuracies of the proposed methods were higher than the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of the random baseline but lower than those of the MFS and corpus concatenation methods. However, because our method utilized the embedding vectors of the word senses, the relations of the sense tags corresponding to concept tags could be examined by mapping the sense embeddings to the vector space of the concept tags. Also, our methods could be performed when we have only concept or word sense embeddings whereas the MFS method requires a <a href=https://en.wikipedia.org/wiki/Parallel_corpus>parallel corpus</a> and the corpus concatenation method needs two tagged corpora.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3408.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3408 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3408 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3408/>Investigating Effective Parameters for Fine-tuning of Word Embeddings Using Only a Small Corpus</a></strong><br><a href=/people/k/kanako-komiya/>Kanako Komiya</a>
|
<a href=/people/h/hiroyuki-shinnou/>Hiroyuki Shinnou</a><br><a href=/volumes/W18-34/ class=text-muted>Proceedings of the Workshop on Deep Learning Approaches for Low-Resource NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3408><div class="card-body p-3 small">Fine-tuning is a popular <a href=https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations>method</a> to achieve better performance when only a small target corpus is available. However, <a href=https://en.wikipedia.org/wiki/Italian_language>it</a> requires tuning of a number of metaparameters and thus it might carry risk of adverse effect when inappropriate metaparameters are used. Therefore, we investigate effective parameters for <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> when only a small target corpus is available. In the current study, we target at improving Japanese word embeddings created from a <a href=https://en.wikipedia.org/wiki/Text_corpus>huge corpus</a>. First, we demonstrate that even the <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> created from the huge corpus are affected by domain shift. After that, we investigate effective <a href=https://en.wikipedia.org/wiki/Parameter>parameters</a> for <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> of the <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> using a small target corpus. We used perplexity of a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> obtained from a Long Short-Term Memory network to assess the word embeddings input into the <a href=https://en.wikipedia.org/wiki/Computer_network>network</a>. The experiments revealed that <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> sometimes give adverse effect when only a small target corpus is used and batch size is the most important parameter for <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a>. In addition, we confirmed that effect of <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> is higher when size of a target corpus was larger.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Hiroyuki+Shinnou" title="Search for 'Hiroyuki Shinnou' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/k/kanako-komiya/ class=align-middle>Kanako Komiya</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/youki-itoh/ class=align-middle>Youki Itoh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/naoki-kikuta/ class=align-middle>Naoki Kikuta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/teruo-hirabayashi/ class=align-middle>Teruo Hirabayashi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/masayuki-asahara/ class=align-middle>Masayuki Asahara</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ranlp/ class=align-middle>RANLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/bucc/ class=align-middle>BUCC</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>