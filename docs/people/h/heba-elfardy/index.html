<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Heba Elfardy - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Heba</span> <span class=font-weight-bold>Elfardy</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-main.211.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-main--211 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-main.211 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><span class="align-middle mr-1" data-toggle=tooltip data-placement=bottom title="Honorable Mention for Best Long Paper"><i class="fas fa-award"></i></span></span>
<span class=d-block><strong><a class=align-middle href=/2021.eacl-main.211/>Hidden Biases in Unreliable News Detection Datasets</a></strong><br><a href=/people/x/xiang-zhou/>Xiang Zhou</a>
|
<a href=/people/h/heba-elfardy/>Heba Elfardy</a>
|
<a href=/people/c/christos-christodoulopoulos/>Christos Christodoulopoulos</a>
|
<a href=/people/t/thomas-butler/>Thomas Butler</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a><br><a href=/volumes/2021.eacl-main/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-main--211><div class="card-body p-3 small">Automatic unreliable news detection is a research problem with great potential impact. Recently, several papers have shown promising results on large-scale news datasets with models that only use the article itself without resorting to any <a href=https://en.wikipedia.org/wiki/Fact-checking>fact-checking mechanism</a> or retrieving any supporting evidence. In this work, we take a closer look at these <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>. While they all provide valuable resources for future research, we observe a number of problems that may lead to results that do not generalize in more realistic settings. Specifically, we show that <a href=https://en.wikipedia.org/wiki/Selection_bias>selection bias</a> during data collection leads to undesired artifacts in the <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>. In addition, while most systems train and predict at the level of individual articles, overlapping article sources in the training and evaluation data can provide a strong <a href=https://en.wikipedia.org/wiki/Confounding>confounding factor</a> that <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> can exploit. In the presence of this <a href=https://en.wikipedia.org/wiki/Confounding>confounding factor</a>, the models can achieve good performance by directly memorizing the site-label mapping instead of modeling the real task of unreliable news detection. We observed a significant drop (10 %) in <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> for all <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> tested in a clean split with no train / test source overlap. Using the observations and experimental results, we provide practical suggestions on how to create more reliable <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> for the unreliable news detection task. We suggest future dataset creation include a simple <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> as a difficulty / bias probe and future model development use a clean non-overlapping site and date split.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4convai-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlp4convai-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlp4convai-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.nlp4convai-1.9.Software.txt data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.nlp4convai-1.9.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929630 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlp4convai-1.9/>Automating Template Creation for Ranking-Based Dialogue Models</a></strong><br><a href=/people/j/jingxiang-chen/>Jingxiang Chen</a>
|
<a href=/people/h/heba-elfardy/>Heba Elfardy</a>
|
<a href=/people/s/simi-wang/>Simi Wang</a>
|
<a href=/people/a/andrea-kahn/>Andrea Kahn</a>
|
<a href=/people/j/jared-kramer/>Jared Kramer</a><br><a href=/volumes/2020.nlp4convai-1/ class=text-muted>Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlp4convai-1--9><div class="card-body p-3 small">Dialogue response generation models that use template ranking rather than direct sequence generation allow model developers to limit generated responses to pre-approved messages. However, manually creating templates is time-consuming and requires domain expertise. To alleviate this problem, we explore automating the process of creating dialogue templates by using <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised methods</a> to cluster historical utterances and selecting representative utterances from each <a href=https://en.wikipedia.org/wiki/Cluster_analysis>cluster</a>. Specifically, we propose an end-to-end model called Deep Sentence Encoder Clustering (DSEC) that uses an auto-encoder structure to jointly learn the utterance representation and construct template clusters. We compare this method to a random baseline that randomly assigns templates to clusters as well as a strong baseline that performs the sentence encoding and the utterance clustering sequentially. To evaluate the performance of the proposed method, we perform an automatic evaluation with two annotated customer service datasets to assess clustering effectiveness, and a human-in-the-loop experiment using a live customer service application to measure the acceptance rate of the generated templates. DSEC performs best in the automatic evaluation, beats both the sequential and random baselines on most metrics in the human-in-the-loop experiment, and shows promising results when compared to gold / manually created templates.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-4009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-4009 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-4009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-4009/>Bingo at IJCNLP-2017 Task 4 : Augmenting Data using <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a> for Cross-linguistic Customer Feedback Classification<span class=acl-fixed-case>IJCNLP</span>-2017 Task 4: Augmenting Data using Machine Translation for Cross-linguistic Customer Feedback Classification</a></strong><br><a href=/people/h/heba-elfardy/>Heba Elfardy</a>
|
<a href=/people/m/manisha-srivastava/>Manisha Srivastava</a>
|
<a href=/people/w/wei-xiao/>Wei Xiao</a>
|
<a href=/people/j/jared-kramer/>Jared Kramer</a>
|
<a href=/people/t/tarun-agarwal/>Tarun Agarwal</a><br><a href=/volumes/I17-4/ class=text-muted>Proceedings of the IJCNLP 2017, Shared Tasks</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-4009><div class="card-body p-3 small">The ability to automatically and accurately process <a href=https://en.wikipedia.org/wiki/Customer_service>customer feedback</a> is a necessity in the private sector. Unfortunately, <a href=https://en.wikipedia.org/wiki/Customer_feedback>customer feedback</a> can be one of the most difficult types of data to work with due to the sheer volume and variety of services, products, languages, and cultures that comprise the customer experience. In order to address this issue, our team built a suite of <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> trained on a four-language, multi-label corpus released as part of the shared task on Customer Feedback Analysis at IJCNLP 2017. In addition to standard text preprocessing, we translated each <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> into each other language to increase the size of the training datasets. Additionally, we also used <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> in our feature engineering step. Ultimately, we trained classifiers using <a href=https://en.wikipedia.org/wiki/Logistic_regression>Logistic Regression</a>, <a href=https://en.wikipedia.org/wiki/Random_forest>Random Forest</a>, and Long Short-Term Memory (LSTM) Recurrent Neural Networks. Overall, we achieved a Macro-Average F-score between 48.7 % and 56.0 % for the four languages and ranked 3/12 for <a href=https://en.wikipedia.org/wiki/English_language>English</a>, 3/7 for <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, 1/8 for <a href=https://en.wikipedia.org/wiki/French_language>French</a>, and 2/7 for <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Heba+Elfardy" title="Search for 'Heba Elfardy' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/j/jared-kramer/ class=align-middle>Jared Kramer</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/manisha-srivastava/ class=align-middle>Manisha Srivastava</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wei-xiao/ class=align-middle>Wei Xiao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tarun-agarwal/ class=align-middle>Tarun Agarwal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiang-zhou/ class=align-middle>Xiang Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/c/christos-christodoulopoulos/ class=align-middle>Christos Christodoulopoulos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thomas-butler/ class=align-middle>Thomas Butler</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mohit-bansal/ class=align-middle>Mohit Bansal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jingxiang-chen/ class=align-middle>Jingxiang Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/simi-wang/ class=align-middle>Simi Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrea-kahn/ class=align-middle>Andrea Kahn</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/nlp4convai/ class=align-middle>NLP4ConvAI</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>