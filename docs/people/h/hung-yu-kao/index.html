<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Hung-Yu Kao - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Hung-Yu</span> <span class=font-weight-bold>Kao</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.232.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--232 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.232 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.232" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.232/>Unsupervised Extractive Summarization-Based Representations for Accurate and Explainable Collaborative Filtering</a></strong><br><a href=/people/r/reinald-adrian-pugoy/>Reinald Adrian Pugoy</a>
|
<a href=/people/h/hung-yu-kao/>Hung-Yu Kao</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--232><div class="card-body p-3 small">We pioneer the first extractive summarization-based collaborative filtering model called ESCOFILT. Our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> specifically produces extractive summaries for each item and user. Unlike other types of <a href=https://en.wikipedia.org/wiki/Explanation>explanations</a>, summary-level explanations closely resemble real-life explanations. The strength of ESCOFILT lies in the fact that it unifies <a href=https://en.wikipedia.org/wiki/Representation_(arts)>representation</a> and explanation. In other words, extractive summaries both represent and explain the items and users. Our model uniquely integrates BERT, K-Means embedding clustering, and <a href=https://en.wikipedia.org/wiki/Multilayer_perceptron>multilayer perceptron</a> to learn sentence embeddings, representation-explanations, and user-item interactions, respectively. We argue that our approach enhances both rating prediction accuracy and user / item explainability. Our experiments illustrate that ESCOFILT&#8217;s prediction accuracy is better than the other state-of-the-art recommender models. Furthermore, we propose a comprehensive set of criteria that assesses the real-life explainability of explanations. Our explainability study demonstrates the superiority of and preference for summary-level explanations over other explanation types.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4if-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlp4if-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlp4if-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.nlp4if-1.2" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.nlp4if-1.2/>Measuring Alignment to Authoritarian State Media as Framing Bias</a></strong><br><a href=/people/t/timothy-niven/>Timothy Niven</a>
|
<a href=/people/h/hung-yu-kao/>Hung-Yu Kao</a><br><a href=/volumes/2020.nlp4if-1/ class=text-muted>Proceedings of the 3rd NLP4IF Workshop on NLP for Internet Freedom: Censorship, Disinformation, and Propaganda</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlp4if-1--2><div class="card-body p-3 small">We introduce what is to the best of our knowledge a new task in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> : measuring alignment to authoritarian state media. We operationalize alignment in terms of sociological definitions of <a href=https://en.wikipedia.org/wiki/Media_bias>media bias</a>. We take as a case study the alignment of four <a href=https://en.wikipedia.org/wiki/Media_of_Taiwan>Taiwanese media outlets</a> to the <a href=https://en.wikipedia.org/wiki/State_media>Chinese Communist Party state media</a>. We present the results of an initial investigation using the frequency of words in psychologically meaningful categories. Our findings suggest that the chosen word categories correlate with <a href=https://en.wikipedia.org/wiki/Framing_(social_sciences)>framing choices</a>. We develop a calculation method that yields reasonable results for measuring <a href=https://en.wikipedia.org/wiki/Sequence_alignment>alignment</a>, agreeing well with the known labels. We confirm that our method does capture event selection bias, but whether it captures <a href=https://en.wikipedia.org/wiki/Framing_bias>framing bias</a> requires further investigation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.473.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--473 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.473 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.473/>Exploiting Microblog Conversation Structures to Detect Rumors</a></strong><br><a href=/people/j/jiawen-li/>Jiawen Li</a>
|
<a href=/people/y/yudianto-sujana/>Yudianto Sujana</a>
|
<a href=/people/h/hung-yu-kao/>Hung-Yu Kao</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--473><div class="card-body p-3 small">As one of the most popular <a href=https://en.wikipedia.org/wiki/Social_media>social media platforms</a>, <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> has become a primary source of information for many people. Unfortunately, both valid information and <a href=https://en.wikipedia.org/wiki/Rumor>rumors</a> are propagated on <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> due to the lack of an automatic information verification system. Twitter users communicate by replying to other users&#8217; messages, forming a conversation structure. Using this <a href=https://en.wikipedia.org/wiki/Structure>structure</a>, users can decide whether the information in the source tweet is a <a href=https://en.wikipedia.org/wiki/Rumor>rumor</a> by reading the tweet&#8217;s replies, which voice other users&#8217; stances on the tweet. The majority of rumor detection researchers process such tweets based on time, ignoring the conversation structure. To reap the benefits of the Twitter conversation structure, we developed a model to detect <a href=https://en.wikipedia.org/wiki/Rumor>rumors</a> by modeling conversation structure as a <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a>. Thus, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s improved representation of the conversation structure enhances its rumor detection accuracy. The experimental results on two rumor datasets show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms several baseline models, including a state-of-the-art model</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1459.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1459 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1459 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1459" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1459/>Probing Neural Network Comprehension of Natural Language Arguments</a></strong><br><a href=/people/t/timothy-niven/>Timothy Niven</a>
|
<a href=/people/h/hung-yu-kao/>Hung-Yu Kao</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1459><div class="card-body p-3 small">We are surprised to find that BERT&#8217;s peak performance of 77 % on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. We analyze the nature of these <a href=https://en.wikipedia.org/wiki/Sensory_cue>cues</a> and demonstrate that a range of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> all exploit them. This analysis informs the construction of an adversarial dataset on which all <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1185.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1185 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1185 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=S18-1185" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/S18-1185/>NLITrans at SemEval-2018 Task 12 : Transfer of Semantic Knowledge for Argument Comprehension<span class=acl-fixed-case>NLIT</span>rans at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 12: Transfer of Semantic Knowledge for Argument Comprehension</a></strong><br><a href=/people/t/timothy-niven/>Timothy Niven</a>
|
<a href=/people/h/hung-yu-kao/>Hung-Yu Kao</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1185><div class="card-body p-3 small">The Argument Reasoning Comprehension Task is a difficult challenge requiring significant <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>language understanding</a> and complex reasoning over <a href=https://en.wikipedia.org/wiki/Epistemology>world knowledge</a>. We focus on transfer of a sentence encoder to bootstrap more complicated architectures given the small size of the dataset. Our best model uses a pre-trained BiLSTM to encode input sentences, learns task-specific features for the argument and warrants, then performs independent argument-warrant matching. This <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves mean test set accuracy of 61.31 %. Encoder transfer yields a significant gain to our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> over random initialization. Sharing parameters for independent warrant evaluation provides regularization and effectively doubles the size of the dataset. We demonstrate that <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization</a> comes from ignoring statistical correlations between warrant positions. We also report an experiment with our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that only matches warrants to reasons, ignoring claims. Performance is still competitive, suggesting that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is not necessarily learning the intended task.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2081.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2081 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2081 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2081/>IKM at SemEval-2017 Task 8 : <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>Convolutional Neural Networks</a> for stance detection and rumor verification<span class=acl-fixed-case>IKM</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 8: Convolutional Neural Networks for stance detection and rumor verification</a></strong><br><a href=/people/y/yi-chin-chen/>Yi-Chin Chen</a>
|
<a href=/people/z/zhao-yang-liu/>Zhao-Yang Liu</a>
|
<a href=/people/h/hung-yu-kao/>Hung-Yu Kao</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2081><div class="card-body p-3 small">This paper describes our approach for SemEval-2017 Task 8. We aim at detecting the stance of tweets and determining the veracity of the given rumor. We utilize a <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural network</a> for short text categorization using multiple <a href=https://en.wikipedia.org/wiki/Filter_(signal_processing)>filter sizes</a>. Our approach beats the baseline classifiers on different <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>event data</a> with good <a href=https://en.wikipedia.org/wiki/F1_score>F1 scores</a>. The best of our submitted runs achieves rank 1st among all scores on subtask B.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Hung-Yu+Kao" title="Search for 'Hung-Yu Kao' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/t/timothy-niven/ class=align-middle>Timothy Niven</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/r/reinald-adrian-pugoy/ class=align-middle>Reinald Adrian Pugoy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yi-chin-chen/ class=align-middle>Yi-Chin Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhao-yang-liu/ class=align-middle>Zhao-Yang Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiawen-li/ class=align-middle>Jiawen Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/y/yudianto-sujana/ class=align-middle>Yudianto Sujana</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/nlp4if/ class=align-middle>NLP4IF</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>