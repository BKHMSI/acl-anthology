<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Heng Ji - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Heng</span> <span class=font-weight-bold>Ji</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.0/>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations</a></strong><br><a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/j/jong-c-park/>Jong C. Park</a>
|
<a href=/people/r/rui-xia/>Rui Xia</a><br><a href=/volumes/2021.acl-demo/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.428.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--428 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.428 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.428" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.428/>Lifelong Event Detection with Knowledge Transfer</a></strong><br><a href=/people/p/pengfei-yu/>Pengfei Yu</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/p/prem-natarajan/>Prem Natarajan</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--428><div class="card-body p-3 small">Traditional supervised Information Extraction (IE) methods can extract structured knowledge elements from <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured data</a>, but it is limited to a pre-defined target ontology. In reality, the ontology of interest may change over time, adding emergent new types or more fine-grained subtypes. We propose a new lifelong learning framework to address this challenge. We focus on lifelong event detection as an exemplar case and propose a new problem formulation that is also generalizable to other IE tasks. In event detection and more general IE tasks, rich correlations or <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic relatedness</a> exist among hierarchical knowledge element types. In our proposed <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a>, knowledge is being transferred between learned <a href=https://en.wikipedia.org/wiki/Event_(computing)>old event types</a> and <a href=https://en.wikipedia.org/wiki/Event_(computing)>new event types</a>. Specifically, we update old knowledge with new event types&#8217; mentions using a self-training loss. In addition, we aggregate old event types&#8217; representations based on their similarities with new event types to initialize the new event types&#8217; representations. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> outperforms competitive <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> with a 5.1 % absolute gain in the F1 score. Moreover, our proposed framework can boost the F1 score for over 30 % absolute gain on some new long-tail rare event types with few training instances. Our knowledge transfer module improves performance on both learned event types and new event types under the lifelong learning setting, showing that it helps consolidate old knowledge and improve novel <a href=https://en.wikipedia.org/wiki/Knowledge_acquisition>knowledge acquisition</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.441.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--441 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.441 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.441" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.441/>Corpus-based Open-Domain Event Type Induction</a></strong><br><a href=/people/j/jiaming-shen/>Jiaming Shen</a>
|
<a href=/people/y/yunyi-zhang/>Yunyi Zhang</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/j/jiawei-han/>Jiawei Han</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--441><div class="card-body p-3 small">Traditional event extraction methods require predefined <a href=https://en.wikipedia.org/wiki/Event_(computing)>event types</a> and their corresponding annotations to learn event extractors. These prerequisites are often hard to be satisfied in real-world applications. This work presents a corpus-based open-domain event type induction method that automatically discovers a set of event types from a given corpus. As events of the same type could be expressed in multiple ways, we propose to represent each event type as a cluster of predicate sense, object head pairs. Specifically, our method (1) selects salient predicates and object heads, (2) disambiguates predicate senses using only a verb sense dictionary, and (3) obtains event types by jointly embedding and clustering predicate sense, object head pairs in a latent spherical space. Our experiments, on three datasets from different domains, show our method can discover salient and high-quality event types, according to both automatic and human evaluations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.69.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--69 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.69 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.69.OptionalSupplementaryData.zip data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.69" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.69/>Document-Level Event Argument Extraction by Conditional Generation</a></strong><br><a href=/people/s/sha-li/>Sha Li</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/j/jiawei-han/>Jiawei Han</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--69><div class="card-body p-3 small">Event extraction has long been treated as a sentence-level task in the IE community. We argue that this <a href=https://en.wikipedia.org/wiki/Setting_(narrative)>setting</a> does not match human informative seeking behavior and leads to incomplete and uninformative extraction results. We propose a document-level neural event argument extraction model by formulating the task as conditional generation following event templates. We also compile a new document-level event extraction benchmark dataset WikiEvents which includes complete event and coreference annotation. On the task of argument extraction, we achieve an absolute gain of 7.6 % <a href=https://en.wikipedia.org/wiki/F-number>F1</a> and 5.7 % <a href=https://en.wikipedia.org/wiki/F-number>F1</a> over the next best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on the RAMS and WikiEvents dataset respectively. On the more challenging task of informative argument extraction, which requires implicit coreference reasoning, we achieve a 9.3 % F1 gain over the best <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a>. To demonstrate the portability of our model, we also create the first end-to-end zero-shot event extraction framework and achieve 97 % of fully supervised model&#8217;s trigger extraction performance and 82 % of the argument extraction performance given only access to 10 out of the 33 types on ACE.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.112.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--112 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.112 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.112" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.112/>Efficient Attentions for Long Document Summarization</a></strong><br><a href=/people/l/luyang-huang/>Luyang Huang</a>
|
<a href=/people/s/shuyang-cao/>Shuyang Cao</a>
|
<a href=/people/n/nikolaus-parulian/>Nikolaus Parulian</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/l/lu-wang/>Lu Wang</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--112><div class="card-body p-3 small">The quadratic computational and memory complexities of large Transformers have limited their scalability for long document summarization. In this paper, we propose Hepos, a novel efficient encoder-decoder attention with head-wise positional strides to effectively pinpoint salient information from the source. We further conduct a systematic study of existing efficient <a href=https://en.wikipedia.org/wiki/Self-interest>self-attentions</a>. Combined with Hepos, we are able to process ten times more tokens than existing models that use full attentions. For evaluation, we present a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, GovReport, with significantly longer documents and summaries. Results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> produce significantly higher ROUGE scores than competitive comparisons, including new state-of-the-art results on <a href=https://en.wikipedia.org/wiki/PubMed>PubMed</a>. Human evaluation also shows that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> generate more informative summaries with fewer unfaithful errors.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-demos.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-demos--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-demos.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-demos.16" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-demos.16/>RESIN : A Dockerized Schema-Guided Cross-document Cross-lingual Cross-media Information Extraction and Event Tracking System<span class=acl-fixed-case>RESIN</span>: A Dockerized Schema-Guided Cross-document Cross-lingual Cross-media Information Extraction and Event Tracking System</a></strong><br><a href=/people/h/haoyang-wen/>Haoyang Wen</a>
|
<a href=/people/y/ying-lin/>Ying Lin</a>
|
<a href=/people/t/tuan-lai/>Tuan Lai</a>
|
<a href=/people/x/xiaoman-pan/>Xiaoman Pan</a>
|
<a href=/people/s/sha-li/>Sha Li</a>
|
<a href=/people/x/xudong-lin/>Xudong Lin</a>
|
<a href=/people/b/ben-zhou/>Ben Zhou</a>
|
<a href=/people/m/manling-li/>Manling Li</a>
|
<a href=/people/h/haoyu-wang/>Haoyu Wang</a>
|
<a href=/people/h/hongming-zhang/>Hongming Zhang</a>
|
<a href=/people/x/xiaodong-yu/>Xiaodong Yu</a>
|
<a href=/people/a/alexander-dong/>Alexander Dong</a>
|
<a href=/people/z/zhenhailong-wang/>Zhenhailong Wang</a>
|
<a href=/people/y/yi-fung/>Yi Fung</a>
|
<a href=/people/p/piyush-mishra/>Piyush Mishra</a>
|
<a href=/people/q/qing-lyu/>Qing Lyu</a>
|
<a href=/people/d/didac-suris/>Dídac Surís</a>
|
<a href=/people/b/brian-chen/>Brian Chen</a>
|
<a href=/people/s/susan-windisch-brown/>Susan Windisch Brown</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/c/chris-callison-burch/>Chris Callison-Burch</a>
|
<a href=/people/c/carl-vondrick/>Carl Vondrick</a>
|
<a href=/people/j/jiawei-han/>Jiawei Han</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a>
|
<a href=/people/s/shih-fu-chang/>Shih-Fu Chang</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a><br><a href=/volumes/2021.naacl-demos/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-demos--16><div class="card-body p-3 small">We present a new information extraction system that can automatically construct temporal event graphs from a collection of news documents from multiple sources, multiple languages (English and Spanish for our experiment), and multiple data modalities (speech, text, image and video). The system advances state-of-the-art from two aspects : (1) extending from sentence-level event extraction to cross-document cross-lingual cross-media event extraction, coreference resolution and temporal event tracking ; (2) using human curated event schema library to match and enhance the extraction output. We have made the dockerlized system publicly available for research purpose at GitHub, with a demo video.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nuse-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nuse-1.0/>Proceedings of the First Joint Workshop on Narrative Understanding, Storylines, and Events</a></strong><br><a href=/people/c/claire-bonial/>Claire Bonial</a>
|
<a href=/people/t/tommaso-caselli/>Tommaso Caselli</a>
|
<a href=/people/s/snigdha-chaturvedi/>Snigdha Chaturvedi</a>
|
<a href=/people/e/elizabeth-clark/>Elizabeth Clark</a>
|
<a href=/people/r/ruihong-huang/>Ruihong Huang</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/a/alejandro-jaimes/>Alejandro Jaimes</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/l/lara-j-martin/>Lara J. Martin</a>
|
<a href=/people/b/ben-miller/>Ben Miller</a>
|
<a href=/people/t/teruko-mitamura/>Teruko Mitamura</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/j/joel-tetreault/>Joel Tetreault</a><br><a href=/volumes/2020.nuse-1/ class=text-muted>Proceedings of the First Joint Workshop on Narrative Understanding, Storylines, and Events</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.50.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--50 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.50 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938669 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.50/>Connecting the Dots : Event Graph Schema Induction with Path Language Modeling</a></strong><br><a href=/people/m/manling-li/>Manling Li</a>
|
<a href=/people/q/qi-zeng/>Qi Zeng</a>
|
<a href=/people/y/ying-lin/>Ying Lin</a>
|
<a href=/people/k/kyunghyun-cho/>Kyunghyun Cho</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/n/nathanael-chambers/>Nathanael Chambers</a>
|
<a href=/people/c/clare-voss/>Clare Voss</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--50><div class="card-body p-3 small">Event schemas can guide our understanding and ability to make predictions with respect to what might happen next. We propose a new Event Graph Schema, where two event types are connected through multiple paths involving entities that fill important roles in a coherent story. We then introduce Path Language Model, an auto-regressive language model trained on event-event paths, and select salient and coherent paths to probabilistically construct these graph schemas. We design two evaluation metrics, instance coverage and instance coherence, to evaluate the quality of graph schema induction, by checking when coherent event instances are covered by the schema graph. Intrinsic evaluations show that our approach is highly effective at inducing salient and coherent schemas. Extrinsic evaluations show the induced schema repository provides significant improvement to downstream end-to-end Information Extraction over a state-of-the-art joint neural extraction model, when used as additional global features to unfold instance graphs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.53.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--53 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.53 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939118 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.53/>Semi-supervised New Event Type Induction and Event Detection</a></strong><br><a href=/people/l/lifu-huang/>Lifu Huang</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--53><div class="card-body p-3 small">Most previous event extraction studies assume a set of target event types and corresponding event annotations are given, which could be very expensive. In this paper, we work on a new task of semi-supervised event type induction, aiming to automatically discover a set of unseen types from a given corpus by leveraging annotations available for a few seen types. We design a Semi-Supervised Vector Quantized Variational Autoencoder framework to automatically learn a discrete latent type representation for each seen and unseen type and optimize them using seen type event annotations. A variational autoencoder is further introduced to enforce the reconstruction of each event mention conditioned on its latent type distribution. Experiments show that our approach can not only achieve state-of-the-art performance on supervised event detection but also discover high-quality new event types.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.724.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--724 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.724 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938946 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.724" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.724/>Text Classification Using Label Names Only : A Language Model Self-Training Approach</a></strong><br><a href=/people/y/yu-meng/>Yu Meng</a>
|
<a href=/people/y/yunyi-zhang/>Yunyi Zhang</a>
|
<a href=/people/j/jiaxin-huang/>Jiaxin Huang</a>
|
<a href=/people/c/chenyan-xiong/>Chenyan Xiong</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/c/chao-zhang/>Chao Zhang</a>
|
<a href=/people/j/jiawei-han/>Jiawei Han</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--724><div class="card-body p-3 small">Current text classification methods typically require a good number of human-labeled documents as training data, which can be costly and difficult to obtain in real applications. Humans can perform <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> without seeing any labeled examples but only based on a small set of words describing the categories to be classified. In this paper, we explore the potential of only using the label name of each class to train <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification models</a> on unlabeled data, without using any labeled documents. We use pre-trained neural language models both as general linguistic knowledge sources for <a href=https://en.wikipedia.org/wiki/Categorization>category understanding</a> and as <a href=https://en.wikipedia.org/wiki/Representation_learning>representation learning models</a> for <a href=https://en.wikipedia.org/wiki/Document_classification>document classification</a>. Our method (1) associates semantically related words with the label names, (2) finds category-indicative words and trains the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to predict their implied categories, and (3) generalizes the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> via self-training. We show that our model achieves around 90 % accuracy on four benchmark datasets including topic and sentiment classification without using any labeled documents but learning from unlabeled data supervised by at most 3 words (1 in most cases) per class as the label name.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.713.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--713 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.713 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929257 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.713/>A Joint Neural Model for <a href=https://en.wikipedia.org/wiki/Information_extraction>Information Extraction</a> with Global Features</a></strong><br><a href=/people/y/ying-lin/>Ying Lin</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/f/fei-huang/>Fei Huang</a>
|
<a href=/people/l/lingfei-wu/>Lingfei Wu</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--713><div class="card-body p-3 small">Most existing joint neural models for Information Extraction (IE) use local task-specific classifiers to predict labels for individual instances (e.g., trigger, relation) regardless of their interactions. For example, a victim of a die event is likely to be a victim of an attack event in the same sentence. In order to capture such cross-subtask and cross-instance inter-dependencies, we propose a joint neural framework, OneIE, that aims to extract the globally optimal IE result as a <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a> from an input sentence. OneIE performs end-to-end IE in four stages : (1) Encoding a given sentence as contextualized word representations ; (2) Identifying entity mentions and event triggers as <a href=https://en.wikipedia.org/wiki/Vertex_(graph_theory)>nodes</a> ; (3) Computing label scores for all <a href=https://en.wikipedia.org/wiki/Vertex_(graph_theory)>nodes</a> and their pairwise links using local classifiers ; (4) Searching for the globally optimal graph with a beam decoder. At the decoding stage, we incorporate global features to capture the cross-subtask and cross-instance interactions. Experiments show that adding global features improves the performance of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> and achieves new state of-the-art on all subtasks. In addition, as OneIE does not use any language-specific feature, we prove it can be easily applied to new languages or trained in a multilingual manner.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ecomnlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ecomnlp-1.0/>Proceedings of Workshop on Natural Language Processing in E-Commerce</a></strong><br><a href=/people/h/huasha-zhao/>Huasha Zhao</a>
|
<a href=/people/p/parikshit-sondhi/>Parikshit Sondhi</a>
|
<a href=/people/n/nguyen-bach/>Nguyen Bach</a>
|
<a href=/people/s/sanjika-hewavitharana/>Sanjika Hewavitharana</a>
|
<a href=/people/y/yifan-he/>Yifan He</a>
|
<a href=/people/l/luo-si/>Luo Si</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a><br><a href=/volumes/2020.ecomnlp-1/ class=text-muted>Proceedings of Workshop on Natural Language Processing in E-Commerce</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1025.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1025 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1025 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1025" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1025/>Low-Resource Name Tagging Learned with Weakly Labeled Data</a></strong><br><a href=/people/y/yixin-cao/>Yixin Cao</a>
|
<a href=/people/z/zikun-hu/>Zikun Hu</a>
|
<a href=/people/t/tat-seng-chua/>Tat-seng Chua</a>
|
<a href=/people/z/zhiyuan-liu/>Zhiyuan Liu</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1025><div class="card-body p-3 small">Name tagging in low-resource languages or domains suffers from inadequate training data. Existing work heavily relies on additional information, while leaving those noisy annotations unexplored that extensively exist on the web. In this paper, we propose a novel neural model for name tagging solely based on weakly labeled (WL) data, so that it can be applied in any low-resource settings. To take the best advantage of all WL sentences, we split them into high-quality and noisy portions for two modules, respectively : (1) a classification module focusing on the large portion of noisy data can efficiently and robustly pretrain the tag classifier by capturing textual context semantics ; and (2) a costly sequence labeling module focusing on high-quality data utilizes Partial-CRFs with non-entity sampling to achieve global optimum. Two <a href=https://en.wikipedia.org/wiki/Module_(computer_science)>modules</a> are combined via <a href=https://en.wikipedia.org/wiki/Parameter_(computer_programming)>shared parameters</a>. Extensive experiments involving five low-resource languages and fine-grained food domain demonstrate our superior performance (6 % and 7.8 % F1 gains on average) as well as <a href=https://en.wikipedia.org/wiki/Efficiency>efficiency</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1030.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1030 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1030 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1030/>Cross-lingual Structure Transfer for Relation and Event Extraction</a></strong><br><a href=/people/a/ananya-subburathinam/>Ananya Subburathinam</a>
|
<a href=/people/d/di-lu/>Di Lu</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/s/shih-fu-chang/>Shih-Fu Chang</a>
|
<a href=/people/a/avirup-sil/>Avirup Sil</a>
|
<a href=/people/c/clare-voss/>Clare Voss</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1030><div class="card-body p-3 small">The identification of complex semantic structures such as <a href=https://en.wikipedia.org/wiki/Event_(philosophy)>events</a> and <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity relations</a>, already a challenging Information Extraction task, is doubly difficult from sources written in under-resourced and under-annotated languages. We investigate the suitability of cross-lingual structure transfer techniques for these <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. We exploit relation- and event-relevant language-universal features, leveraging both symbolic (including part-of-speech and dependency path) and distributional (including type representation and contextualized representation) information. By representing all entity mentions, event triggers, and contexts into this complex and structured multilingual common space, using graph convolutional networks, we can train a relation or event extractor from source language annotations and apply it to the target language. Extensive experiments on cross-lingual relation and event transfer among <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, and <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a> demonstrate that our approach achieves performance comparable to state-of-the-art <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised models</a> trained on up to 3,000 manually annotated mentions : up to 62.6 % F-score for Relation Extraction, and 63.1 % F-score for Event Argument Role Labeling. The event argument role labeling model transferred from <a href=https://en.wikipedia.org/wiki/English_language>English</a> to <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a> achieves similar performance as the model trained from <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>. We thus find that language-universal symbolic and distributional representations are complementary for cross-lingual structure transfer.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1145.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1145 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1145 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-1145/>Biomedical Event Extraction based on Knowledge-driven Tree-LSTM<span class=acl-fixed-case>LSTM</span></a></strong><br><a href=/people/d/diya-li/>Diya Li</a>
|
<a href=/people/l/lifu-huang/>Lifu Huang</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/j/jiawei-han/>Jiawei Han</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1145><div class="card-body p-3 small">Event extraction for the biomedical domain is more challenging than that in the general news domain since it requires broader acquisition of domain-specific knowledge and deeper understanding of complex contexts. To better encode contextual information and external background knowledge, we propose a novel knowledge base (KB)-driven tree-structured long short-term memory networks (Tree-LSTM) framework, incorporating two new types of features : (1) dependency structures to capture wide contexts ; (2) entity properties (types and category descriptions) from external ontologies via entity linking. We evaluate our approach on the BioNLP shared task with Genia dataset and achieve a new state-of-the-art result. In addition, both quantitative and qualitative studies demonstrate the advancement of the Tree-LSTM and the external knowledge representation for biomedical event extraction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1252.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1252 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1252 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1252" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N19-1252/>A Grounded Unsupervised Universal Part-of-Speech Tagger for Low-Resource Languages</a></strong><br><a href=/people/r/ronald-cardenas/>Ronald Cardenas</a>
|
<a href=/people/y/ying-lin/>Ying Lin</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1252><div class="card-body p-3 small">Unsupervised part of speech (POS) tagging is often framed as a clustering problem, but practical taggers need to ground their clusters as well. Grounding generally requires reference labeled data, a luxury a low-resource language might not have. In this work, we describe an approach for low-resource unsupervised POS tagging that yields fully grounded output and requires no labeled training data. We find the classic <a href=https://en.wikipedia.org/wiki/Scientific_method>method</a> of Brown et al. (1992) clusters well in our use case and employ a decipherment-based approach to grounding. This approach presumes a sequence of cluster IDs is a &#8216;ciphertext&#8217; and seeks a POS tag-to-cluster ID mapping that will reveal the POS sequence. We show intrinsically that, despite the difficulty of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, we obtain reasonable performance across a variety of languages. We also show extrinsically that incorporating our <a href=https://en.wikipedia.org/wiki/POS_tagger>POS tagger</a> into a name tagger leads to state-of-the-art tagging performance in <a href=https://en.wikipedia.org/wiki/Sinhala_language>Sinhalese</a> and <a href=https://en.wikipedia.org/wiki/Kinyarwanda>Kinyarwanda</a>, two languages with nearly no labeled POS data available. We further demonstrate our tagger&#8217;s utility by incorporating it into a true &#8216;zero-resource&#8217; variant of the MALOPA (Ammar et al., 2016) dependency parser model that removes the current reliance on multilingual resources and gold POS tags for new languages. Experiments show that including our <a href=https://en.wikipedia.org/wiki/Tagger>tagger</a> makes up much of the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> lost when gold POS tags are unavailable.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1023.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1023 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1023 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1023/>Multi-lingual Common Semantic Space Construction via Cluster-consistent Word Embedding</a></strong><br><a href=/people/l/lifu-huang/>Lifu Huang</a>
|
<a href=/people/k/kyunghyun-cho/>Kyunghyun Cho</a>
|
<a href=/people/b/boliang-zhang/>Boliang Zhang</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/k/kevin-knight/>Kevin Knight</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1023><div class="card-body p-3 small">We construct a multilingual common semantic space based on <a href=https://en.wikipedia.org/wiki/Distributional_semantics>distributional semantics</a>, where words from multiple languages are projected into a shared space via which all available resources and knowledge can be shared across multiple languages. Beyond <a href=https://en.wikipedia.org/wiki/Word_alignment>word alignment</a>, we introduce multiple cluster-level alignments and enforce the word clusters to be consistently distributed across multiple languages. We exploit three signals for clustering : (1) neighbor words in the monolingual word embedding space ; (2) character-level information ; and (3) <a href=https://en.wikipedia.org/wiki/Semantic_property>linguistic properties</a> (e.g., <a href=https://en.wikipedia.org/wiki/Apposition>apposition</a>, locative suffix) derived from linguistic structure knowledge bases available for thousands of languages. We introduce a new cluster-consistent correlational neural network to construct the common semantic space by aligning words as well as <a href=https://en.wikipedia.org/wiki/Cluster_analysis>clusters</a>. Intrinsic evaluation on monolingual and multilingual QVEC tasks shows our approach achieves significantly higher correlation with linguistic features which are extracted from manually crafted lexical resources than state-of-the-art multi-lingual embedding learning methods do. Using low-resource language name tagging as a case study for extrinsic evaluation, our <a href=https://en.wikipedia.org/wiki/Methodology>approach</a> achieves up to 14.6 % absolute F-score gain over the state of the art on cross-lingual direct transfer. Our approach is also shown to be robust even when the size of <a href=https://en.wikipedia.org/wiki/Bilingual_dictionary>bilingual dictionary</a> is small.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1435.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1435 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1435 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1435/>Entity-aware Image Caption Generation</a></strong><br><a href=/people/d/di-lu/>Di Lu</a>
|
<a href=/people/s/spencer-whitehead/>Spencer Whitehead</a>
|
<a href=/people/l/lifu-huang/>Lifu Huang</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/s/shih-fu-chang/>Shih-Fu Chang</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1435><div class="card-body p-3 small">Current image captioning approaches generate descriptions which lack specific information, such as <a href=https://en.wikipedia.org/wiki/Named_entity>named entities</a> that are involved in the <a href=https://en.wikipedia.org/wiki/Image>images</a>. In this paper we propose a new task which aims to generate informative image captions, given <a href=https://en.wikipedia.org/wiki/Image>images</a> and <a href=https://en.wikipedia.org/wiki/Hashtag>hashtags</a> as input. We propose a simple but effective <a href=https://en.wikipedia.org/wiki/Scientific_method>approach</a> to tackle this <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a>. We first train a convolutional neural networks-long short term memory networks (CNN-LSTM) model to generate a template caption based on the input image. Then we use a knowledge graph based collective inference algorithm to fill in the template with specific named entities retrieved via the hashtags. Experiments on a new benchmark dataset collected from <a href=https://en.wikipedia.org/wiki/Flickr>Flickr</a> show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> generates news-style image descriptions with much richer information. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms <a href=https://en.wikipedia.org/wiki/Unimodality>unimodal baselines</a> significantly with various evaluation metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-4203.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-4203 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-4203 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-4203/>Creative Language Encoding under Censorship</a></strong><br><a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/k/kevin-knight/>Kevin Knight</a><br><a href=/volumes/W18-42/ class=text-muted>Proceedings of the First Workshop on Natural Language Processing for Internet Freedom</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-4203><div class="card-body p-3 small">People often create obfuscated language for online communication to avoid <a href=https://en.wikipedia.org/wiki/Internet_censorship>Internet censorship</a>, share sensitive information, express strong sentiment or emotion, plan for secret actions, trade illegal products, or simply hold interesting conversations. In this position paper we systematically categorize human-created obfuscated language on various levels, investigate their basic mechanisms, give an overview on automated techniques needed to simulate human encoding. These encoders have potential to frustrate and evade, co-evolve with dynamic human or automated decoders, and produce interesting and adoptable code words. We also summarize remaining challenges for future research on the interaction between Natural Language Processing (NLP) and <a href=https://en.wikipedia.org/wiki/Encryption>encryption</a>, and leveraging NLP techniques for encoding and decoding.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6502.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6502 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6502 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-6502" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-6502/>Describing a Knowledge Base</a></strong><br><a href=/people/q/qingyun-wang/>Qingyun Wang</a>
|
<a href=/people/x/xiaoman-pan/>Xiaoman Pan</a>
|
<a href=/people/l/lifu-huang/>Lifu Huang</a>
|
<a href=/people/b/boliang-zhang/>Boliang Zhang</a>
|
<a href=/people/z/zhiying-jiang/>Zhiying Jiang</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/k/kevin-knight/>Kevin Knight</a><br><a href=/volumes/W18-65/ class=text-muted>Proceedings of the 11th International Conference on Natural Language Generation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6502><div class="card-body p-3 small">We aim to automatically generate <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language descriptions</a> about an input structured knowledge base (KB). We build our generation framework based on a pointer network which can copy facts from the input KB, and add two attention mechanisms : (i) slot-aware attention to capture the association between a slot type and its corresponding slot value ; and (ii) a new table position self-attention to capture the inter-dependencies among related slots. For evaluation, besides standard metrics including <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>, <a href=https://en.wikipedia.org/wiki/METEOR>METEOR</a>, and ROUGE, we propose a <a href=https://en.wikipedia.org/wiki/Binary_logarithm>KB reconstruction based metric</a> by extracting a <a href=https://en.wikipedia.org/wiki/Binary_logarithm>KB</a> from the generation output and comparing it with the input KB. We also create a new <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> which includes 106,216 pairs of structured KBs and their corresponding <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language descriptions</a> for two distinct entity types. Experiments show that our approach significantly outperforms <a href=https://en.wikipedia.org/wiki/State-of-the-art>state-of-the-art methods</a>. The reconstructed KB achieves 68.8 %-72.6 % F-score.<i>slot-aware attention</i> to capture the association between a slot type and its corresponding slot value; and (ii) a new <i>table position self-attention</i> to capture the inter-dependencies among related slots. For evaluation, besides standard metrics including BLEU, METEOR, and ROUGE, we propose a <i>KB reconstruction</i> based metric by extracting a KB from the generation output and comparing it with the input KB. We also create a new data set which includes 106,216 pairs of structured KBs and their corresponding natural language descriptions for two distinct entity types. Experiments show that our approach significantly outperforms state-of-the-art methods. The reconstructed KB achieves 68.8% - 72.6% F-score.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1000/>Proceedings of the 2018 Conference of the North <span class=acl-fixed-case>A</span>merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></strong><br><a href=/people/m/marilyn-walker/>Marilyn Walker</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/a/amanda-stent/>Amanda Stent</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-2000/>Proceedings of the 2018 Conference of the North <span class=acl-fixed-case>A</span>merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></strong><br><a href=/people/m/marilyn-walker/>Marilyn Walker</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/a/amanda-stent/>Amanda Stent</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-5009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-5009 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-5009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-5009/>ELISA-EDL : A Cross-lingual Entity Extraction, Linking and Localization System<span class=acl-fixed-case>ELISA</span>-<span class=acl-fixed-case>EDL</span>: A Cross-lingual Entity Extraction, Linking and Localization System</a></strong><br><a href=/people/b/boliang-zhang/>Boliang Zhang</a>
|
<a href=/people/y/ying-lin/>Ying Lin</a>
|
<a href=/people/x/xiaoman-pan/>Xiaoman Pan</a>
|
<a href=/people/d/di-lu/>Di Lu</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/k/kevin-knight/>Kevin Knight</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a><br><a href=/volumes/N18-5/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-5009><div class="card-body p-3 small">We demonstrate ELISA-EDL, a state-of-the-art re-trainable system to extract entity mentions from low-resource languages, link them to external English knowledge bases, and visualize locations related to disaster topics on a world heatmap. We make all of our data sets, resources and system training and testing APIs publicly available for research purpose.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-1009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K18-1009 data-toggle=collapse aria-expanded=false aria-controls=abstract-K18-1009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K18-1009/>Global Attention for Name Tagging</a></strong><br><a href=/people/b/boliang-zhang/>Boliang Zhang</a>
|
<a href=/people/s/spencer-whitehead/>Spencer Whitehead</a>
|
<a href=/people/l/lifu-huang/>Lifu Huang</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a><br><a href=/volumes/K18-1/ class=text-muted>Proceedings of the 22nd Conference on Computational Natural Language Learning</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K18-1009><div class="card-body p-3 small">Many name tagging approaches use <a href=https://en.wikipedia.org/wiki/Context_(language_use)>local contextual information</a> with much success, but can fail when the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>local context</a> is ambiguous or limited. We present a new <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> to improve <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>name tagging</a> by utilizing local, document-level, and corpus-level contextual information. For each word, we retrieve document-level context from other sentences within the same document and corpus-level context from sentences in other documents. We propose a model that learns to incorporate document-level and corpus-level contextual information alongside local contextual information via document-level and corpus-level attentions, which dynamically weight their respective contextual information and determines the influence of this <a href=https://en.wikipedia.org/wiki/Information>information</a> through gating mechanisms. Experiments on benchmark datasets show the effectiveness of our approach, which achieves state-of-the-art results for <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a>, and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a> on the CoNLL-2002 and CoNLL-2003 datasets. We will make our code and pre-trained models publicly available for research purposes.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1074.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1074 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1074 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1074.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285800977 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1074" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1074/>A Multi-lingual Multi-task Architecture for Low-resource Sequence Labeling</a></strong><br><a href=/people/y/ying-lin/>Ying Lin</a>
|
<a href=/people/s/shengqi-yang/>Shengqi Yang</a>
|
<a href=/people/v/veselin-stoyanov/>Veselin Stoyanov</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1074><div class="card-body p-3 small">We propose a multi-lingual multi-task architecture to develop <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised models</a> with a minimal amount of labeled data for <a href=https://en.wikipedia.org/wiki/Sequence_labeling>sequence labeling</a>. In this new <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a>, we combine various <a href=https://en.wikipedia.org/wiki/Transfer_function>transfer models</a> using two layers of parameter sharing. On the first layer, we construct the basis of the <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> to provide universal word representation and feature extraction capability for all <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a>. On the second level, we adopt different parameter sharing strategies for different transfer schemes. This <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> proves to be particularly effective for low-resource settings, when there are less than 200 training sentences for the target <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. Using Name Tagging as a target task, our <a href=https://en.wikipedia.org/wiki/Design_of_experiments>approach</a> achieved 4.3%-50.5 % absolute F-score gains compared to the mono-lingual single-task baseline model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1201.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1201 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1201 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1201.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805384 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1201" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1201/>Zero-Shot Transfer Learning for Event Extraction</a></strong><br><a href=/people/l/lifu-huang/>Lifu Huang</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/k/kyunghyun-cho/>Kyunghyun Cho</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a>
|
<a href=/people/s/sebastian-riedel/>Sebastian Riedel</a>
|
<a href=/people/c/clare-voss/>Clare Voss</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1201><div class="card-body p-3 small">Most previous supervised event extraction methods have relied on features derived from manual annotations, and thus can not be applied to new event types without extra annotation effort. We take a fresh look at <a href=https://en.wikipedia.org/wiki/Event_extraction>event extraction</a> and model it as a generic grounding problem : mapping each event mention to a specific type in a target event ontology. We design a transferable architecture of structural and compositional neural networks to jointly represent and map event mentions and types into a shared semantic space. Based on this new framework, we can select, for each event mention, the event type which is semantically closest in this space as its type. By leveraging manual annotations available for a small set of existing <a href=https://en.wikipedia.org/wiki/Event_(computing)>event types</a>, our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> can be applied to new unseen event types without additional manual annotations. When tested on 23 unseen event types, our zero-shot framework, without manual annotations, achieved performance comparable to a <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised model</a> trained from 3,000 sentences annotated with 500 event mentions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-2042.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-2042 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-2042 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-2042.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-2042" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-2042/>Paper Abstract Writing through Editing Mechanism</a></strong><br><a href=/people/q/qingyun-wang/>Qingyun Wang</a>
|
<a href=/people/z/zhihao-zhou/>Zhihao Zhou</a>
|
<a href=/people/l/lifu-huang/>Lifu Huang</a>
|
<a href=/people/s/spencer-whitehead/>Spencer Whitehead</a>
|
<a href=/people/b/boliang-zhang/>Boliang Zhang</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/k/kevin-knight/>Kevin Knight</a><br><a href=/volumes/P18-2/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-2042><div class="card-body p-3 small">We present a paper abstract writing system based on an attentive neural sequence-to-sequence model that can take a title as input and automatically generate an abstract. We design a novel Writing-editing Network that can attend to both the title and the previously generated abstract drafts and then iteratively revise and polish the abstract. With two series of <a href=https://en.wikipedia.org/wiki/Turing_test>Turing tests</a>, where the human judges are asked to distinguish the system-generated abstracts from human-written ones, our system passes <a href=https://en.wikipedia.org/wiki/Turing_test>Turing tests</a> by junior domain experts at a rate up to 30 % and by non-expert at a rate up to 80 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-4001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-4001 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-4001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-4001/>Platforms for Non-speakers Annotating Names in Any Language</a></strong><br><a href=/people/y/ying-lin/>Ying Lin</a>
|
<a href=/people/c/cash-costello/>Cash Costello</a>
|
<a href=/people/b/boliang-zhang/>Boliang Zhang</a>
|
<a href=/people/d/di-lu/>Di Lu</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/j/james-mayfield/>James Mayfield</a>
|
<a href=/people/p/paul-mcnamee/>Paul McNamee</a><br><a href=/volumes/P18-4/ class=text-muted>Proceedings of ACL 2018, System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-4001><div class="card-body p-3 small">We demonstrate two annotation platforms that allow an English speaker to annotate names for any language without knowing the language. These platforms provided high-quality&#8217; &#8216;silver standard annotations for low-resource language name taggers (Zhang et al., 2017) that achieved state-of-the-art performance on two surprise languages (Oromo and Tigrinya) at LoreHLT20171 and ten languages at TAC-KBP EDL2017 (Ji et al., 2017). We discuss strengths and limitations and compare other methods of creating silver- and gold-standard annotations using <a href=https://en.wikipedia.org/wiki/First_language>native speakers</a>. We will make our tools publicly available for research use.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-1037.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-1037 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-1037 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-1037/>Embracing Non-Traditional Linguistic Resources for Low-resource Language Name Tagging</a></strong><br><a href=/people/b/boliang-zhang/>Boliang Zhang</a>
|
<a href=/people/d/di-lu/>Di Lu</a>
|
<a href=/people/x/xiaoman-pan/>Xiaoman Pan</a>
|
<a href=/people/y/ying-lin/>Ying Lin</a>
|
<a href=/people/h/halidanmu-abudukelimu/>Halidanmu Abudukelimu</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/k/kevin-knight/>Kevin Knight</a><br><a href=/volumes/I17-1/ class=text-muted>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-1037><div class="card-body p-3 small">Current supervised name tagging approaches are inadequate for most low-resource languages due to the lack of annotated data and actionable linguistic knowledge. All supervised learning methods (including deep neural networks (DNN)) are sensitive to <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a> and thus they are not quite portable without massive clean annotations. We found that the <a href=https://en.wikipedia.org/wiki/F-number>F-scores</a> of DNN-based name taggers drop rapidly (20%-30 %) when we replace clean manual annotations with noisy annotations in the training data. We propose a new solution to incorporate many non-traditional language universal resources that are readily available but rarely explored in the Natural Language Processing (NLP) community, such as the World Atlas of Linguistic Structure, CIA names, PanLex and survival guides. We acquire and encode various types of non-traditional linguistic resources into a DNN name tagger. Experiments on three low-resource languages show that feeding linguistic knowledge can make DNN significantly more robust to <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a>, achieving 8%-22 % absolute <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> gains on <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>name tagging</a> without using any human annotation</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-1086.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-1086 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-1086 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-1086/>Open Relation Extraction and Grounding</a></strong><br><a href=/people/d/dian-yu/>Dian Yu</a>
|
<a href=/people/l/lifu-huang/>Lifu Huang</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a><br><a href=/volumes/I17-1/ class=text-muted>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-1086><div class="card-body p-3 small">Previous open Relation Extraction (open RE) approaches mainly rely on linguistic patterns and constraints to extract important relational triples from large-scale corpora. However, they lack of abilities to cover diverse relation expressions or measure the relative importance of candidate triples within a sentence. It is also challenging to name the relation type of a relational triple merely based on context words, which could limit the usefulness of open RE in downstream applications. We propose a novel importance-based open RE approach by exploiting the global structure of a dependency tree to extract salient triples. We design an unsupervised relation type naming method by grounding relational triples to a large-scale Knowledge Base (KB) schema, leveraging KB triples and weighted context words associated with relational triples. Experiments on the English Slot Filling 2013 dataset demonstrate that our <a href=https://en.wikipedia.org/wiki/Methodology>approach</a> achieves 8.1 % higher <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> over state-of-the-art open RE methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1149.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1149 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1149 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P17-1149/>Bridge Text and Knowledge by Learning Multi-Prototype Entity Mention Embedding</a></strong><br><a href=/people/y/yixin-cao/>Yixin Cao</a>
|
<a href=/people/l/lifu-huang/>Lifu Huang</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/x/xu-chen/>Xu Chen</a>
|
<a href=/people/j/juanzi-li/>Juanzi Li</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1149><div class="card-body p-3 small">Integrating text and knowledge into a unified semantic space has attracted significant research interests recently. However, the ambiguity in the common space remains a challenge, namely that the same mention phrase usually refers to various entities. In this paper, to deal with the ambiguity of entity mentions, we propose a novel Multi-Prototype Mention Embedding model, which learns multiple sense embeddings for each mention by jointly modeling words from textual contexts and entities derived from a <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base</a>. In addition, we further design an efficient language model based approach to disambiguate each mention to a specific sense. In experiments, both qualitative and quantitative analysis demonstrate the high quality of the word, entity and multi-prototype mention embeddings. Using <a href=https://en.wikipedia.org/wiki/Entity_linking>entity linking</a> as a study case, we apply our disambiguation method as well as the multi-prototype mention embeddings on the benchmark dataset, and achieve state-of-the-art performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1178.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1178 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1178 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P17-1178/>Cross-lingual Name Tagging and Linking for 282 Languages</a></strong><br><a href=/people/x/xiaoman-pan/>Xiaoman Pan</a>
|
<a href=/people/b/boliang-zhang/>Boliang Zhang</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/j/joel-nothman/>Joel Nothman</a>
|
<a href=/people/k/kevin-knight/>Kevin Knight</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1178><div class="card-body p-3 small">The ambitious goal of this work is to develop a cross-lingual name tagging and linking framework for 282 languages that exist in <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>. Given a document in any of these languages, our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> is able to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to an English Knowledge Base (KB) if it is linkable. We achieve this goal by performing a series of new KB mining methods : generating silver-standard annotations by transferring annotations from English to other languages through cross-lingual links and KB properties, refining annotations through self-training and topic selection, deriving language-specific morphology features from anchor links, and mining word translation pairs from cross-lingual links. Both name tagging and linking results for 282 languages are promising on Wikipedia data and on-Wikipedia data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2085.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2085 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2085 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P17-2085/>List-only Entity Linking</a></strong><br><a href=/people/y/ying-lin/>Ying Lin</a>
|
<a href=/people/c/chin-yew-lin/>Chin-Yew Lin</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2085><div class="card-body p-3 small">Traditional Entity Linking (EL) technologies rely on rich structures and properties in the target knowledge base (KB). However, in many applications, the <a href=https://en.wikipedia.org/wiki/Kibibyte>KB</a> may be as simple and sparse as lists of names of the same type (e.g., lists of products). We call <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> as List-only Entity Linking problem. Fortunately, some mentions may have more cues for linking, which can be used as seed mentions to bridge other mentions and the uninformative entities. In this work, we select most linkable mentions as <a href=https://en.wikipedia.org/wiki/List_of_Latin_phrases_(S)>seed mentions</a> and disambiguate other mentions by comparing them with the <a href=https://en.wikipedia.org/wiki/List_of_Latin_phrases_(S)>seed mentions</a> rather than directly with the entities. Our experiments on linking mentions to seven automatically mined lists show promising results and demonstrate the effectiveness of our approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-4000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P17-4000/>Proceedings of <span class=acl-fixed-case>ACL</span> 2017, System Demonstrations</a></strong><br><a href=/people/m/mohit-bansal/>Mohit Bansal</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a><br><a href=/volumes/P17-4/ class=text-muted>Proceedings of ACL 2017, System Demonstrations</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5603.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5603 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5603 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5603/>Learning Phrase Embeddings from <a href=https://en.wikipedia.org/wiki/Paraphrase>Paraphrases</a> with GRUs<span class=acl-fixed-case>GRU</span>s</a></strong><br><a href=/people/z/zhihao-zhou/>Zhihao Zhou</a>
|
<a href=/people/l/lifu-huang/>Lifu Huang</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a><br><a href=/volumes/W17-56/ class=text-muted>Proceedings of the First Workshop on Curation and Applications of Parallel and Comparable Corpora</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5603><div class="card-body p-3 small">Learning phrase representations has been widely explored in many <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing tasks</a> (e.g., <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a>, <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a>) and has shown promising improvements. Previous studies either learn non-compositional phrase representations with general word embedding learning techniques or learn compositional phrase representations based on syntactic structures, which either require huge amounts of human annotations or can not be easily generalized to all phrases. In this work, we propose to take advantage of large-scaled paraphrase database and present a pairwise-GRU framework to generate compositional phrase representations. Our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> can be re-used to generate <a href=https://en.wikipedia.org/wiki/Representation_(systemics)>representations</a> for any phrases. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> achieves state-of-the-art results on several phrase similarity tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1005 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238228823 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D17-1005" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1005/>Heterogeneous Supervision for Relation Extraction : A Representation Learning Approach</a></strong><br><a href=/people/l/liyuan-liu/>Liyuan Liu</a>
|
<a href=/people/x/xiang-ren/>Xiang Ren</a>
|
<a href=/people/q/qi-zhu/>Qi Zhu</a>
|
<a href=/people/s/shi-zhi/>Shi Zhi</a>
|
<a href=/people/h/huan-gui/>Huan Gui</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/j/jiawei-han/>Jiawei Han</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1005><div class="card-body p-3 small">Relation extraction is a fundamental task in <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a>. Most existing methods have heavy reliance on <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> labeled by human experts, which are costly and time-consuming. To overcome this drawback, we propose a novel framework, REHession, to conduct relation extractor learning using annotations from heterogeneous information source, e.g., knowledge base and domain heuristics. These annotations, referred as heterogeneous supervision, often conflict with each other, which brings a new challenge to the original relation extraction task : how to infer the true label from noisy labels for a given instance. Identifying context information as the backbone of both relation extraction and true label discovery, we adopt embedding techniques to learn the distributed representations of context, which bridges all components with mutual enhancement in an iterative fashion. Extensive experimental results demonstrate the superiority of REHession over the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1055.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1055 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1055 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1055/>Identifying and Tracking Sentiments and Topics from Social Media Texts during Natural Disasters</a></strong><br><a href=/people/m/min-yang/>Min Yang</a>
|
<a href=/people/j/jincheng-mei/>Jincheng Mei</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/w/wei-zhao/>Wei Zhao</a>
|
<a href=/people/z/zhou-zhao/>Zhou Zhao</a>
|
<a href=/people/x/xiaojun-chen/>Xiaojun Chen</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1055><div class="card-body p-3 small">We study the problem of identifying the topics and sentiments and tracking their shifts from social media texts in different geographical regions during emergencies and disasters. We propose a location-based dynamic sentiment-topic model (LDST) which can jointly model topic, sentiment, time and Geolocation information. The experimental results demonstrate that LDST performs very well at discovering topics and sentiments from <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> and tracking their shifts in different geographical regions during emergencies and disasters. We will release the data and source code after this work is published.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1274.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1274 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1274 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1274/>Improving Slot Filling Performance with Attentive Neural Networks on Dependency Structures</a></strong><br><a href=/people/l/lifu-huang/>Lifu Huang</a>
|
<a href=/people/a/avirup-sil/>Avirup Sil</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/r/radu-florian/>Radu Florian</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1274><div class="card-body p-3 small">Slot Filling (SF) aims to extract the values of certain types of attributes (or slots, such as person : cities_of_residence) for a given entity from a large collection of source documents. In this paper we propose an effective DNN architecture for SF with the following new strategies : (1). Take a regularized dependency graph instead of a raw sentence as input to DNN, to compress the wide contexts between query and candidate filler ; (2). Incorporate two attention mechanisms : local attention learned from query and candidate filler, and global attention learned from external knowledge bases, to guide the model to better select indicative contexts to determine slot type. Experiments show that this framework outperforms <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> on both <a href=https://en.wikipedia.org/wiki/Relation_extraction>relation extraction</a> (16 % absolute F-score gain) and slot filling validation for each individual <a href=https://en.wikipedia.org/wiki/System>system</a> (up to 8.5 % absolute F-score gain).</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Heng+Ji" title="Search for 'Heng Ji' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/l/lifu-huang/ class=align-middle>Lifu Huang</a>
<span class="badge badge-secondary align-middle ml-2">12</span></li><li class=list-group-item><a href=/people/y/ying-lin/ class=align-middle>Ying Lin</a>
<span class="badge badge-secondary align-middle ml-2">9</span></li><li class=list-group-item><a href=/people/b/boliang-zhang/ class=align-middle>Boliang Zhang</a>
<span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/people/k/kevin-knight/ class=align-middle>Kevin Knight</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/j/jiawei-han/ class=align-middle>Jiawei Han</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/d/di-lu/ class=align-middle>Di Lu</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/x/xiaoman-pan/ class=align-middle>Xiaoman Pan</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/j/jonathan-may/ class=align-middle>Jonathan May</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/k/kyunghyun-cho/ class=align-middle>Kyunghyun Cho</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/c/clare-voss/ class=align-middle>Clare Voss</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/spencer-whitehead/ class=align-middle>Spencer Whitehead</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/shih-fu-chang/ class=align-middle>Shih-Fu Chang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/manling-li/ class=align-middle>Manling Li</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yunyi-zhang/ class=align-middle>Yunyi Zhang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yixin-cao/ class=align-middle>Yixin Cao</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/zhihao-zhou/ class=align-middle>Zhihao Zhou</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/avirup-sil/ class=align-middle>Avirup Sil</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sha-li/ class=align-middle>Sha Li</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/q/qingyun-wang/ class=align-middle>Qingyun Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/marilyn-walker/ class=align-middle>Marilyn Walker</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/amanda-stent/ class=align-middle>Amanda Stent</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jong-c-park/ class=align-middle>Jong C. Park</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rui-xia/ class=align-middle>Rui Xia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/claire-bonial/ class=align-middle>Claire Bonial</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tommaso-caselli/ class=align-middle>Tommaso Caselli</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/snigdha-chaturvedi/ class=align-middle>Snigdha Chaturvedi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elizabeth-clark/ class=align-middle>Elizabeth Clark</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ruihong-huang/ class=align-middle>Ruihong Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mohit-iyyer/ class=align-middle>Mohit Iyyer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alejandro-jaimes/ class=align-middle>Alejandro Jaimes</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lara-j-martin/ class=align-middle>Lara J. Martin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/ben-miller/ class=align-middle>Ben Miller</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/teruko-mitamura/ class=align-middle>Teruko Mitamura</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nanyun-peng/ class=align-middle>Nanyun Peng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joel-tetreault/ class=align-middle>Joel Tetreault</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/halidanmu-abudukelimu/ class=align-middle>Halidanmu Abudukelimu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dian-yu/ class=align-middle>Dian Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qi-zeng/ class=align-middle>Qi Zeng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nathanael-chambers/ class=align-middle>Nathanael Chambers</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yu-meng/ class=align-middle>Yu Meng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiaxin-huang/ class=align-middle>Jiaxin Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chenyan-xiong/ class=align-middle>Chenyan Xiong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chao-zhang/ class=align-middle>Chao Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fei-huang/ class=align-middle>Fei Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lingfei-wu/ class=align-middle>Lingfei Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xu-chen/ class=align-middle>Xu Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/juanzi-li/ class=align-middle>Juanzi Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joel-nothman/ class=align-middle>Joel Nothman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chin-yew-lin/ class=align-middle>Chin-Yew Lin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mohit-bansal/ class=align-middle>Mohit Bansal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pengfei-yu/ class=align-middle>Pengfei Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/prem-natarajan/ class=align-middle>Prem Natarajan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiaming-shen/ class=align-middle>Jiaming Shen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zikun-hu/ class=align-middle>Zikun Hu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tat-seng-chua/ class=align-middle>Tat-Seng Chua</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhiyuan-liu/ class=align-middle>Zhiyuan Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ananya-subburathinam/ class=align-middle>Ananya Subburathinam</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/huasha-zhao/ class=align-middle>Huasha Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/parikshit-sondhi/ class=align-middle>Parikshit Sondhi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nguyen-bach/ class=align-middle>Nguyen Bach</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sanjika-hewavitharana/ class=align-middle>Sanjika Hewavitharana</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yifan-he/ class=align-middle>Yifan He</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luo-si/ class=align-middle>Luo Si</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/liyuan-liu/ class=align-middle>Liyuan Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiang-ren/ class=align-middle>Xiang Ren</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qi-zhu/ class=align-middle>Qi Zhu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shi-zhi/ class=align-middle>Shi Zhi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/huan-gui/ class=align-middle>Huan Gui</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/min-yang/ class=align-middle>Min Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jincheng-mei/ class=align-middle>Jincheng Mei</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wei-zhao/ class=align-middle>Wei Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhou-zhao/ class=align-middle>Zhou Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaojun-chen/ class=align-middle>Xiaojun Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/radu-florian/ class=align-middle>Radu Florian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luyang-huang/ class=align-middle>Luyang Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shuyang-cao/ class=align-middle>Shuyang Cao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nikolaus-parulian/ class=align-middle>Nikolaus Parulian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lu-wang/ class=align-middle>Lu Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haoyang-wen/ class=align-middle>Haoyang Wen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tuan-lai/ class=align-middle>Tuan Lai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xudong-lin/ class=align-middle>Xudong Lin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/ben-zhou/ class=align-middle>Ben Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haoyu-wang/ class=align-middle>Haoyu Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hongming-zhang/ class=align-middle>Hongming Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaodong-yu/ class=align-middle>Xiaodong Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexander-dong/ class=align-middle>Alexander Dong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhenhailong-wang/ class=align-middle>Zhenhailong Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yi-fung/ class=align-middle>Yi Fung</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/piyush-mishra/ class=align-middle>Piyush Mishra</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qing-lyu/ class=align-middle>Qing Lyu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/didac-suris/ class=align-middle>Dídac Surís</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/brian-chen/ class=align-middle>Brian Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/susan-windisch-brown/ class=align-middle>Susan Windisch Brown</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/martha-palmer/ class=align-middle>Martha Palmer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chris-callison-burch/ class=align-middle>Chris Callison-Burch</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/carl-vondrick/ class=align-middle>Carl Vondrick</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dan-roth/ class=align-middle>Dan Roth</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhiying-jiang/ class=align-middle>Zhiying Jiang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/diya-li/ class=align-middle>Diya Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ronald-cardenas/ class=align-middle>Ronald Cardenas</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shengqi-yang/ class=align-middle>Shengqi Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/veselin-stoyanov/ class=align-middle>Veselin Stoyanov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ido-dagan/ class=align-middle>Ido Dagan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sebastian-riedel/ class=align-middle>Sebastian Riedel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cash-costello/ class=align-middle>Cash Costello</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/james-mayfield/ class=align-middle>James Mayfield</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paul-mcnamee/ class=align-middle>Paul McNamee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">12</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">10</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/nuse/ class=align-middle>NUSE</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ecomnlp/ class=align-middle>EcomNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>