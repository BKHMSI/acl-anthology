<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Hatem Haddad - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Hatem</span> <span class=font-weight-bold>Haddad</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.nlp4if-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--nlp4if-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.nlp4if-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.nlp4if-1.17/>iCompass at NLP4IF-2021Fighting the COVID-19 Infodemic<span class=acl-fixed-case>C</span>ompass at <span class=acl-fixed-case>NLP</span>4<span class=acl-fixed-case>IF</span>-2021â€“Fighting the <span class=acl-fixed-case>COVID</span>-19 Infodemic</a></strong><br><a href=/people/w/wassim-henia/>Wassim Henia</a>
|
<a href=/people/o/oumayma-rjab/>Oumayma Rjab</a>
|
<a href=/people/h/hatem-haddad/>Hatem Haddad</a>
|
<a href=/people/c/chayma-fourati/>Chayma Fourati</a><br><a href=/volumes/2021.nlp4if-1/ class=text-muted>Proceedings of the Fourth Workshop on NLP for Internet Freedom: Censorship, Disinformation, and Propaganda</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--nlp4if-1--17><div class="card-body p-3 small">This paper provides a detailed overview of the system and its outcomes, which were produced as part of the NLP4IF Shared Task on Fighting the COVID-19 Infodemic at NAACL 2021. This <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is accomplished using a variety of techniques. We used state-of-the-art contextualized text representation models that were fine-tuned for the downstream task in hand. ARBERT, MARBERT, AraBERT, Arabic ALBERT and BERT-base-arabic were used. According to the results, BERT-base-arabic had the highest 0.784 F1 score on the test set.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wanlp-1.25.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wanlp-1--25 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wanlp-1.25 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wanlp-1.25/>Introducing A large Tunisian Arabizi Dialectal Dataset for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a><span class=acl-fixed-case>T</span>unisian <span class=acl-fixed-case>A</span>rabizi Dialectal Dataset for Sentiment Analysis</a></strong><br><a href=/people/c/chayma-fourati/>Chayma Fourati</a>
|
<a href=/people/h/hatem-haddad/>Hatem Haddad</a>
|
<a href=/people/a/abir-messaoudi/>Abir Messaoudi</a>
|
<a href=/people/m/moez-benhajhmida/>Moez BenHajhmida</a>
|
<a href=/people/a/aymen-ben-elhaj-mabrouk/>Aymen Ben Elhaj Mabrouk</a>
|
<a href=/people/m/malek-naski/>Malek Naski</a><br><a href=/volumes/2021.wanlp-1/ class=text-muted>Proceedings of the Sixth Arabic Natural Language Processing Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wanlp-1--25><div class="card-body p-3 small">On various Social Media platforms, people, tend to use the informal way to communicate, or write posts and comments : their local dialects. In <a href=https://en.wikipedia.org/wiki/Africa>Africa</a>, more than 1500 dialects and languages exist. Particularly, Tunisians talk and write informally using <a href=https://en.wikipedia.org/wiki/Latin_script>Latin letters</a> and numbers rather than <a href=https://en.wikipedia.org/wiki/Arabic_script>Arabic ones</a>. In this paper, we introduce a large common-crawl-based Tunisian Arabizi dialectal dataset dedicated for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a>. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> consists of a total of 100k comments (about <a href=https://en.wikipedia.org/wiki/Film>movies</a>, <a href=https://en.wikipedia.org/wiki/Politics>politic</a>, <a href=https://en.wikipedia.org/wiki/Sport>sport</a>, etc.) annotated manually by Tunisian native speakers as Positive, negative and Neutral. We evaluate our dataset on sentiment analysis task using the Bidirectional Encoder Representations from Transformers (BERT) as a contextual language model in its multilingual version (mBERT) as an embedding technique then combining mBERT with Convolutional Neural Network (CNN) as classifier. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wanlp-1.50.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wanlp-1--50 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wanlp-1.50 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wanlp-1.50/>iCompass at Shared Task on <a href=https://en.wikipedia.org/wiki/Sarcasm>Sarcasm</a> and Sentiment Detection in Arabic<span class=acl-fixed-case>C</span>ompass at Shared Task on Sarcasm and Sentiment Detection in <span class=acl-fixed-case>A</span>rabic</a></strong><br><a href=/people/m/malek-naski/>Malek Naski</a>
|
<a href=/people/a/abir-messaoudi/>Abir Messaoudi</a>
|
<a href=/people/h/hatem-haddad/>Hatem Haddad</a>
|
<a href=/people/m/moez-benhajhmida/>Moez BenHajhmida</a>
|
<a href=/people/c/chayma-fourati/>Chayma Fourati</a>
|
<a href=/people/a/aymen-ben-elhaj-mabrouk/>Aymen Ben Elhaj Mabrouk</a><br><a href=/volumes/2021.wanlp-1/ class=text-muted>Proceedings of the Sixth Arabic Natural Language Processing Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wanlp-1--50><div class="card-body p-3 small">We describe our submitted <a href=https://en.wikipedia.org/wiki/System>system</a> to the 2021 Shared Task on Sarcasm and Sentiment Detection in <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a> (Abu Farha et al., 2021). We tackled both subtasks, namely Sarcasm Detection (Subtask 1) and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a> (Subtask 2). We used state-of-the-art pretrained contextualized text representation models and fine-tuned them according to the downstream task in hand. As a first approach, we used Google&#8217;s multilingual BERT and then other Arabic variants : AraBERT, ARBERT and MARBERT. The results found show that MARBERT outperforms all of the previously mentioned models overall, either on Subtask 1 or Subtask 2.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-2090.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S19-2090 data-toggle=collapse aria-expanded=false aria-controls=abstract-S19-2090 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-2090/>Tw-StAR at SemEval-2019 Task 5 : N-gram embeddings for Hate Speech Detection in Multilingual Tweets<span class=acl-fixed-case>S</span>t<span class=acl-fixed-case>AR</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2019 Task 5: N-gram embeddings for Hate Speech Detection in Multilingual Tweets</a></strong><br><a href=/people/h/hala-mulki/>Hala Mulki</a>
|
<a href=/people/c/chedi-bechikh-ali/>Chedi Bechikh Ali</a>
|
<a href=/people/h/hatem-haddad/>Hatem Haddad</a>
|
<a href=/people/i/ismail-babaoglu/>Ismail BabaoÄŸlu</a><br><a href=/volumes/S19-2/ class=text-muted>Proceedings of the 13th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S19-2090><div class="card-body p-3 small">In this paper, we describe our contribution in SemEval-2019 : subtask A of task 5 Multilingual detection of hate speech against immigrants and women in Twitter (HatEval). We developed two hate speech detection model variants through Tw-StAR framework. While the first model adopted one-hot encoding ngrams to train an NB classifier, the second generated and learned n-gram embeddings within a <a href=https://en.wikipedia.org/wiki/Feedforward_neural_network>feedforward neural network</a>. For both <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, specific terms, selected via MWT patterns, were tagged in the input data. With two feature types employed, we could investigate the ability of n-gram embeddings to rival one-hot n-grams. Our results showed that in <a href=https://en.wikipedia.org/wiki/English_language>English</a>, n-gram embeddings outperformed one-hot ngrams. However, representing Spanish tweets by one-hot n-grams yielded a slightly better performance compared to that of n-gram embeddings. The official ranking indicated that Tw-StAR ranked 9th for <a href=https://en.wikipedia.org/wiki/English_language>English</a> and 20th for <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3512.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3512 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3512 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3512/>L-HSAB : A Levantine Twitter Dataset for Hate Speech and Abusive Language<span class=acl-fixed-case>L</span>-<span class=acl-fixed-case>HSAB</span>: A <span class=acl-fixed-case>L</span>evantine <span class=acl-fixed-case>T</span>witter Dataset for Hate Speech and Abusive Language</a></strong><br><a href=/people/h/hala-mulki/>Hala Mulki</a>
|
<a href=/people/h/hatem-haddad/>Hatem Haddad</a>
|
<a href=/people/c/chedi-bechikh-ali/>Chedi Bechikh Ali</a>
|
<a href=/people/h/halima-alshabani/>Halima Alshabani</a><br><a href=/volumes/W19-35/ class=text-muted>Proceedings of the Third Workshop on Abusive Language Online</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3512><div class="card-body p-3 small">Hate speech and abusive language have become a common phenomenon on Arabic social media. Automatic hate speech and abusive detection systems can facilitate the prohibition of toxic textual contents. The <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a>, informality and ambiguity of the <a href=https://en.wikipedia.org/wiki/Varieties_of_Arabic>Arabic dialects</a> hindered the provision of the needed resources for Arabic abusive / hate speech detection research. In this paper, we introduce the first publicly-available Levantine Hate Speech and Abusive (L-HSAB) Twitter dataset with the objective to be a benchmark dataset for automatic detection of online Levantine toxic contents. We, further, provide a detailed review of the data collection steps and how we design the annotation guidelines such that a reliable dataset annotation is guaranteed. This has been later emphasized through the comprehensive evaluation of the <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> as the annotation agreement metrics of Cohen&#8217;s Kappa (k) and Krippendorff&#8217;s alpha () indicated the consistency of the annotations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4604.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4604 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4604 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4604/>Syntax-Ignorant N-gram Embeddings for Sentiment Analysis of Arabic Dialects<span class=acl-fixed-case>A</span>rabic Dialects</a></strong><br><a href=/people/h/hala-mulki/>Hala Mulki</a>
|
<a href=/people/h/hatem-haddad/>Hatem Haddad</a>
|
<a href=/people/m/mourad-gridach/>Mourad Gridach</a>
|
<a href=/people/i/ismail-babaoglu/>Ismail BabaoÄŸlu</a><br><a href=/volumes/W19-46/ class=text-muted>Proceedings of the Fourth Arabic Natural Language Processing Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4604><div class="card-body p-3 small">Arabic sentiment analysis models have employed compositional embedding features to represent the <a href=https://en.wikipedia.org/wiki/Varieties_of_Arabic>Arabic dialectal content</a>. These embeddings are usually composed via ordered, syntax-aware composition functions and learned within <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural frameworks</a>. With the <a href=https://en.wikipedia.org/wiki/Free_word_order>free word order</a> and the varying syntax nature across the different <a href=https://en.wikipedia.org/wiki/Varieties_of_Arabic>Arabic dialects</a>, a <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis system</a> developed for one dialect might not be efficient for the others. Here we present syntax-ignorant n-gram embeddings to be used in <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> of several <a href=https://en.wikipedia.org/wiki/Varieties_of_Arabic>Arabic dialects</a>. The proposed <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> were composed and learned using an unordered composition function and a shallow neural model. Five datasets of different dialects were used to evaluate the produced <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> in the sentiment analysis task. The obtained results revealed that, our syntax-ignorant embeddings could outperform word2vec model and doc2vec both variant models in addition to hand-crafted system baselines, while a competent performance was noticed towards baseline systems that adopted more complicated neural architectures.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1024/>Tw-StAR at SemEval-2018 Task 1 : Preprocessing Impact on Multi-label Emotion Classification<span class=acl-fixed-case>S</span>t<span class=acl-fixed-case>AR</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Preprocessing Impact on Multi-label Emotion Classification</a></strong><br><a href=/people/h/hala-mulki/>Hala Mulki</a>
|
<a href=/people/c/chedi-bechikh-ali/>Chedi Bechikh Ali</a>
|
<a href=/people/h/hatem-haddad/>Hatem Haddad</a>
|
<a href=/people/i/ismail-babaoglu/>Ismail BabaoÄŸlu</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1024><div class="card-body p-3 small">In this paper, we describe our contribution in SemEval-2018 contest. We tackled task 1 Affect in <a href=https://en.wikipedia.org/wiki/Twitter>Tweets</a>, subtask E-c Detecting Emotions (multi-label classification). A multilabel classification system Tw-StAR was developed to recognize the emotions embedded in Arabic, English and Spanish tweets. To handle the multi-label classification problem via traditional classifiers, we employed the binary relevance transformation strategy while a TF-IDF scheme was used to generate the tweets&#8217; features. We investigated using single and combinations of several preprocessing tasks to further improve the performance. The results showed that specific combinations of preprocessing tasks could significantly improve the evaluation measures. This has been later emphasized by the official results as our system ranked 3rd for both Arabic and Spanish datasets and 14th for the English dataset.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2110.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2110 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2110 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2110/>Tw-StAR at SemEval-2017 Task 4 : Sentiment Classification of Arabic Tweets<span class=acl-fixed-case>S</span>t<span class=acl-fixed-case>AR</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 4: Sentiment Classification of <span class=acl-fixed-case>A</span>rabic Tweets</a></strong><br><a href=/people/h/hala-mulki/>Hala Mulki</a>
|
<a href=/people/h/hatem-haddad/>Hatem Haddad</a>
|
<a href=/people/m/mourad-gridach/>Mourad Gridach</a>
|
<a href=/people/i/ismail-babaoglu/>Ismail Babaoglu</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2110><div class="card-body p-3 small">In this paper, we present our contribution in SemEval 2017 international workshop. We have tackled task 4 entitled <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment analysis</a> in <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>, specifically subtask 4A-Arabic. We propose two Arabic sentiment classification models implemented using <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised and unsupervised learning strategies</a>. In both models, Arabic tweets were preprocessed first then various schemes of bag-of-N-grams were extracted to be used as <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>. The final submission was selected upon the best performance achieved by the <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised learning-based model</a>. However, the results obtained by the unsupervised learning-based model are considered promising and evolvable if more rich lexica are adopted in further work.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Hatem+Haddad" title="Search for 'Hatem Haddad' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/h/hala-mulki/ class=align-middle>Hala Mulki</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/i/ismail-babaoglu/ class=align-middle>Ismail BabaoÄŸlu</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/c/chayma-fourati/ class=align-middle>Chayma Fourati</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/c/chedi-bechikh-ali/ class=align-middle>Chedi Bechikh Ali</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/mourad-gridach/ class=align-middle>Mourad Gridach</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/a/abir-messaoudi/ class=align-middle>Abir Messaoudi</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/moez-benhajhmida/ class=align-middle>Moez BenHajhmida</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/aymen-ben-elhaj-mabrouk/ class=align-middle>Aymen Ben Elhaj Mabrouk</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/malek-naski/ class=align-middle>Malek Naski</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/w/wassim-henia/ class=align-middle>Wassim Henia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/oumayma-rjab/ class=align-middle>Oumayma Rjab</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/halima-alshabani/ class=align-middle>Halima Alshabani</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/wanlp/ class=align-middle>WANLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/nlp4if/ class=align-middle>NLP4IF</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>