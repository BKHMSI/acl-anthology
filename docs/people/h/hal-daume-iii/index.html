<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Hal Daumé III - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Hal</span> <span class=font-weight-bold>Daumé III</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Hal <span class=font-weight-normal>Daumé</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.756.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--756 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.756 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.756" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.756/>Distantly-Supervised Dense Retrieval Enables Open-Domain Question Answering without Evidence Annotation</a></strong><br><a href=/people/c/chen-zhao/>Chen Zhao</a>
|
<a href=/people/c/chenyan-xiong/>Chenyan Xiong</a>
|
<a href=/people/j/jordan-boyd-graber/>Jordan Boyd-Graber</a>
|
<a href=/people/h/hal-daume-iii/>Hal Daumé III</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--756><div class="card-body p-3 small">Open-domain question answering answers a question based on evidence retrieved from a <a href=https://en.wikipedia.org/wiki/Text_corpus>large corpus</a>. State-of-the-art neural approaches require intermediate evidence annotations for training. However, such intermediate annotations are expensive, and <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> that rely on them can not transfer to the more common setting, where only questionanswer pairs are available. This paper investigates whether <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> can learn to find evidence from a large corpus, with only distant supervision from answer labels for model training, thereby generating no additional annotation cost. We introduce a novel approach (DistDR) that iteratively improves over a weak retriever by alternately finding evidence from the up-to-date model and encouraging the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to learn the most likely evidence. Without using any evidence labels, DistDR is on par with fully-supervised state-of-the-art methods on both multi-hop and single-hop QA benchmarks. Our analysis confirms that DistDR finds more accurate evidence over iterations, which leads to model improvements. The code is available at https://github.com/henryzhao5852/DistDR.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.418.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--418 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.418 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929030 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.418" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.418/>Toward Gender-Inclusive Coreference Resolution</a></strong><br><a href=/people/y/yang-trista-cao/>Yang Trista Cao</a>
|
<a href=/people/h/hal-daume-iii/>Hal Daumé III</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--418><div class="card-body p-3 small">Correctly resolving textual mentions of people fundamentally entails making inferences about those people. Such inferences raise the risk of systemic biases in coreference resolution systems, including biases that can harm binary and non-binary trans and cis stakeholders. To better understand such biases, we foreground nuanced conceptualizations of <a href=https://en.wikipedia.org/wiki/Gender>gender</a> from <a href=https://en.wikipedia.org/wiki/Sociology>sociology</a> and <a href=https://en.wikipedia.org/wiki/Sociolinguistics>sociolinguistics</a>, and develop two new datasets for interrogating bias in crowd annotations and in existing coreference resolution systems. Through these studies, conducted on <a href=https://en.wikipedia.org/wiki/English_language>English text</a>, we confirm that without acknowledging and building systems that recognize the complexity of gender, we build <a href=https://en.wikipedia.org/wiki/System>systems</a> that lead to many potential harms.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1063.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1063 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1063 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1063.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1063" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1063/>Help, Anna ! Visual Navigation with Natural Multimodal Assistance via Retrospective Curiosity-Encouraging Imitation Learning</a></strong><br><a href=/people/k/khanh-nguyen/>Khanh Nguyen</a>
|
<a href=/people/h/hal-daume-iii/>Hal Daumé III</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1063><div class="card-body p-3 small">Mobile agents that can leverage help from humans can potentially accomplish more complex tasks than they could entirely on their own. We develop <a href=https://en.wikipedia.org/wiki/Help_(TV_series)>Help</a>, Anna ! (HANNA), an interactive photo-realistic simulator in which an <a href=https://en.wikipedia.org/wiki/Intelligent_agent>agent</a> fulfills object-finding tasks by requesting and interpreting natural language-and-vision assistance. An agent solving tasks in a HANNA environment can leverage simulated human assistants, called ANNA (Automatic Natural Navigation Assistants), which, upon request, provide natural language and visual instructions to direct the agent towards the goals. To address the HANNA problem, we develop a memory-augmented neural agent that hierarchically models multiple levels of <a href=https://en.wikipedia.org/wiki/Decision-making>decision-making</a>, and an imitation learning algorithm that teaches the agent to avoid repeating past mistakes while simultaneously predicting its own chances of making future progress. Empirically, our approach is able to ask for help more effectively than competitive baselines and, thus, attains higher task success rate on both previously seen and previously unseen environments.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1489.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1489 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1489 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1489/>Comparing and Developing Tools to Measure the Readability of Domain-Specific Texts</a></strong><br><a href=/people/e/elissa-redmiles/>Elissa Redmiles</a>
|
<a href=/people/l/lisa-maszkiewicz/>Lisa Maszkiewicz</a>
|
<a href=/people/e/emily-hwang/>Emily Hwang</a>
|
<a href=/people/d/dhruv-kuchhal/>Dhruv Kuchhal</a>
|
<a href=/people/e/everest-liu/>Everest Liu</a>
|
<a href=/people/m/miraida-morales/>Miraida Morales</a>
|
<a href=/people/d/denis-peskov/>Denis Peskov</a>
|
<a href=/people/s/sudha-rao/>Sudha Rao</a>
|
<a href=/people/r/rock-stevens/>Rock Stevens</a>
|
<a href=/people/k/kristina-gligoric/>Kristina Gligorić</a>
|
<a href=/people/s/sean-kross/>Sean Kross</a>
|
<a href=/people/m/michelle-mazurek/>Michelle Mazurek</a>
|
<a href=/people/h/hal-daume-iii/>Hal Daumé III</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1489><div class="card-body p-3 small">The <a href=https://en.wikipedia.org/wiki/Readability>readability</a> of a digital text can influence people&#8217;s ability to learn new things about a range topics from <a href=https://en.wikipedia.org/wiki/Web_resource>digital resources</a> (e.g., <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, <a href=https://en.wikipedia.org/wiki/WebMD>WebMD</a>). Readability also impacts <a href=https://en.wikipedia.org/wiki/Search_engine_results_page>search rankings</a>, and is used to evaluate the performance of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP systems</a>. Despite this, we lack a thorough understanding of how to validly measure <a href=https://en.wikipedia.org/wiki/Readability>readability</a> at scale, especially for domain-specific texts. In this work, we present a comparison of the <a href=https://en.wikipedia.org/wiki/Validity_(statistics)>validity</a> of well-known readability measures and introduce a novel approach, Smart Cloze, which is designed to address shortcomings of existing measures. We compare these approaches across four different corpora : crowdworker-generated stories, Wikipedia articles, security and privacy advice, and health information. On these corpora, we evaluate the convergent and content validity of each measure, and detail tradeoffs in score precision, domain-specificity, and participant burden. These results provide a foundation for more accurate readability measurements and better evaluation of new <a href=https://en.wikipedia.org/wiki/Natural-language_processing>natural-language-processing systems</a> and tools.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3619 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3619 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3619/>Controlling the Specificity of Clarification Question Generation</a></strong><br><a href=/people/y/yang-trista-cao/>Yang Trista Cao</a>
|
<a href=/people/s/sudha-rao/>Sudha Rao</a>
|
<a href=/people/h/hal-daume-iii/>Hal Daumé III</a><br><a href=/volumes/W19-36/ class=text-muted>Proceedings of the 2019 Workshop on Widening NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3619><div class="card-body p-3 small">Unlike comprehension-style questions, clarification questions look for some missing information in a given context. However, without guidance, neural models for question generation, similar to dialog generation models, lead to generic and bland questions that cannot elicit useful information. We argue that controlling the level of specificity of the generated questions can have useful applications and propose a neural clarification question generation model for the same. We first train a classifier that annotates a clarification question with its level of specificity (generic or specific) to the given context. Our results on the Amazon questions dataset demonstrate that training a clarification question generation model on specificity annotated data can generate questions with varied levels of specificity to the given context.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3620 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3620 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3620/>Non-Monotonic Sequential Text Generation</a></strong><br><a href=/people/k/kiante-brantley/>Kiante Brantley</a>
|
<a href=/people/k/kyunghyun-cho/>Kyunghyun Cho</a>
|
<a href=/people/h/hal-daume-iii/>Hal Daumé</a>
|
<a href=/people/s/sean-welleck/>Sean Welleck</a><br><a href=/volumes/W19-36/ class=text-muted>Proceedings of the 2019 Workshop on Widening NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3620><div class="card-body p-3 small">Standard sequential generation methods assume a pre-specified generation order, such as text generation methods which generate words from left to right. In this work, we propose a framework for training models of text generation that operate in non-monotonic orders; the model directly learns good orders, without any additional annotation. Our framework operates by generating a word at an arbitrary position, and then recursively generating words to its left and then words to its right, yielding a binary tree. Learning is framed as imitation learning, including a coaching method which moves from imitating an oracle to reinforcing the policy&#8217;s own preferences. Experimental results demonstrate that using the proposed method, it is possible to learn policies which generate text without pre-specifying a generation order while achieving competitive performance with conventional left-to-right generation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1013 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N19-1013.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/353418933 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1013" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-1013/>Answer-based Adversarial Training for Generating Clarification Questions<span class=acl-fixed-case>A</span>nswer-based <span class=acl-fixed-case>A</span>dversarial <span class=acl-fixed-case>T</span>raining for <span class=acl-fixed-case>G</span>enerating <span class=acl-fixed-case>C</span>larification <span class=acl-fixed-case>Q</span>uestions</a></strong><br><a href=/people/s/sudha-rao/>Sudha Rao</a>
|
<a href=/people/h/hal-daume-iii/>Hal Daumé III</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1013><div class="card-body p-3 small">We present an approach for generating clarification questions with the goal of eliciting new information that would make the given textual context more complete. We propose that modeling hypothetical answers (to clarification questions) as <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a> can guide our approach into generating more useful clarification questions. We develop a Generative Adversarial Network (GAN) where the generator is a sequence-to-sequence model and the discriminator is a utility function that models the value of updating the context with the answer to the clarification question. We evaluate on two datasets, using both automatic metrics and human judgments of usefulness, specificity and relevance, showing that our approach outperforms both a retrieval-based model and ablations that exclude the utility model and the adversarial training.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1208.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1208 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1208 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D18-1208.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/305886331 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1208" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1208/>Content Selection in Deep Learning Models of Summarization</a></strong><br><a href=/people/c/chris-kedzie/>Chris Kedzie</a>
|
<a href=/people/k/kathleen-mckeown/>Kathleen McKeown</a>
|
<a href=/people/h/hal-daume-iii/>Hal Daumé III</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1208><div class="card-body p-3 small">We carry out experiments with deep learning models of <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> across the domains of <a href=https://en.wikipedia.org/wiki/News>news</a>, personal stories, meetings, and <a href=https://en.wikipedia.org/wiki/Medicine>medical articles</a> in order to understand how content selection is performed. We find that many sophisticated <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> of state of the art extractive summarizers do not improve performance over simpler <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. These results suggest that it is easier to create a <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarizer</a> for a new domain than previous work suggests and bring into question the benefit of <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning models</a> for <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> for those domains that do have <a href=https://en.wikipedia.org/wiki/Big_data>massive datasets</a> (i.e., news). At the same time, they suggest important questions for new research in summarization ; namely, new forms of sentence representations or external knowledge sources are needed that are better suited to the sumarization task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-0603.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-0603 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-0603 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-0603/>Expert, Crowdsourced, and Machine Assessment of Suicide Risk via Online Postings</a></strong><br><a href=/people/h/han-chin-shing/>Han-Chin Shing</a>
|
<a href=/people/s/suraj-nair/>Suraj Nair</a>
|
<a href=/people/a/ayah-zirikly/>Ayah Zirikly</a>
|
<a href=/people/m/meir-friedenberg/>Meir Friedenberg</a>
|
<a href=/people/h/hal-daume-iii/>Hal Daumé III</a>
|
<a href=/people/p/philip-resnik/>Philip Resnik</a><br><a href=/volumes/W18-06/ class=text-muted>Proceedings of the Fifth Workshop on Computational Linguistics and Clinical Psychology: From Keyboard to Clinic</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-0603><div class="card-body p-3 small">We report on the creation of a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for studying <a href=https://en.wikipedia.org/wiki/Suicide_risk_assessment>assessment of suicide risk</a> via online postings in <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a>. Evaluation of risk-level annotations by experts yields what is, to our knowledge, the first demonstration of reliability in <a href=https://en.wikipedia.org/wiki/Risk_assessment>risk assessment</a> by clinicians based on social media postings. We also introduce and demonstrate the value of a new, detailed rubric for assessing suicide risk, compare crowdsourced with expert performance, and present baseline predictive modeling experiments using the new dataset, which will be made available to researchers through the American Association of Suicidology.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2315.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2315 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2315 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2315/>Biomedical Event Extraction using Abstract Meaning Representation<span class=acl-fixed-case>A</span>bstract <span class=acl-fixed-case>M</span>eaning <span class=acl-fixed-case>R</span>epresentation</a></strong><br><a href=/people/s/sudha-rao/>Sudha Rao</a>
|
<a href=/people/d/daniel-marcu/>Daniel Marcu</a>
|
<a href=/people/k/kevin-knight/>Kevin Knight</a>
|
<a href=/people/h/hal-daume-iii/>Hal Daumé III</a><br><a href=/volumes/W17-23/ class=text-muted>BioNLP 2017</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2315><div class="card-body p-3 small">We propose a novel, Abstract Meaning Representation (AMR) based approach to identifying molecular events / interactions in biomedical text. Our key contributions are : (1) an empirical validation of our hypothesis that an event is a subgraph of the AMR graph, (2) a neural network-based model that identifies such an event subgraph given an AMR, and (3) a distant supervision based approach to gather additional training data. We evaluate our approach on the 2013 Genia Event Extraction dataset and show promising results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4304.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4304 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4304 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4304/>Structured Prediction via Learning to Search under Bandit Feedback</a></strong><br><a href=/people/a/amr-sharaf/>Amr Sharaf</a>
|
<a href=/people/h/hal-daume-iii/>Hal Daumé III</a><br><a href=/volumes/W17-43/ class=text-muted>Proceedings of the 2nd Workshop on Structured Prediction for Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4304><div class="card-body p-3 small">We present an <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> for <a href=https://en.wikipedia.org/wiki/Structured_prediction>structured prediction</a> under online bandit feedback. The <a href=https://en.wikipedia.org/wiki/Learning>learner</a> repeatedly predicts a sequence of actions, generating a structured output. It then observes <a href=https://en.wikipedia.org/wiki/Feedback>feedback</a> for that <a href=https://en.wikipedia.org/wiki/Output_(economics)>output</a> and no others. We consider two cases : a pure bandit setting in which it only observes a loss, and more fine-grained feedback in which it observes a loss for every action. We find that the fine-grained feedback is necessary for strong empirical performance, because it allows for a robust variance-reduction strategy. We empirically compare a number of different <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> and exploration methods and show the efficacy of BLS on sequence labeling and dependency parsing tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5400.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5400/>Proceedings of the First Workshop on Building Linguistically Generalizable <span class=acl-fixed-case>NLP</span> Systems</a></strong><br><a href=/people/e/emily-m-bender/>Emily Bender</a>
|
<a href=/people/h/hal-daume-iii/>Hal Daumé III</a>
|
<a href=/people/a/allyson-ettinger/>Allyson Ettinger</a>
|
<a href=/people/s/sudha-rao/>Sudha Rao</a><br><a href=/volumes/W17-54/ class=text-muted>Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5401.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5401 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5401 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5401/>Towards Linguistically Generalizable NLP Systems : A Workshop and Shared Task<span class=acl-fixed-case>NLP</span> Systems: A Workshop and Shared Task</a></strong><br><a href=/people/a/allyson-ettinger/>Allyson Ettinger</a>
|
<a href=/people/s/sudha-rao/>Sudha Rao</a>
|
<a href=/people/h/hal-daume-iii/>Hal Daumé III</a>
|
<a href=/people/e/emily-m-bender/>Emily M. Bender</a><br><a href=/volumes/W17-54/ class=text-muted>Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5401><div class="card-body p-3 small">This paper presents a summary of the first Workshop on Building Linguistically Generalizable Natural Language Processing Systems, and the associated Build It Break It, The Language Edition shared task. The goal of this workshop was to bring together researchers in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> and <a href=https://en.wikipedia.org/wiki/Linguistics>linguistics</a> with a carefully designed shared task aimed at testing the generalizability of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP systems</a> beyond the distributions of their training data. We describe the motivation, setup, and participation of the shared task, provide discussion of some highlighted results, and discuss lessons learned.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1153.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1153 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1153 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D17-1153.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D17-1153" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D17-1153/>Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback</a></strong><br><a href=/people/k/khanh-nguyen/>Khanh Nguyen</a>
|
<a href=/people/h/hal-daume-iii/>Hal Daumé III</a>
|
<a href=/people/j/jordan-boyd-graber/>Jordan Boyd-Graber</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1153><div class="card-body p-3 small">Machine translation is a natural candidate problem for <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> from human feedback : users provide quick, dirty ratings on candidate translations to guide a system to improve. Yet, current neural machine translation training focuses on expensive human-generated reference translations. We describe a <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning algorithm</a> that improves neural machine translation systems from simulated human feedback. Our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> combines the advantage actor-critic algorithm (Mnih et al., 2016) with the attention-based neural encoder-decoder architecture (Luong et al., 2015). This <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> (a) is well-designed for problems with a large action space and delayed rewards, (b) effectively optimizes traditional corpus-level machine translation metrics, and (c) is robust to skewed, high-variance, granular feedback modeled after actual human behaviors.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Hal+Daum%C3%A9+III" title="Search for 'Hal Daumé III' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/s/sudha-rao/ class=align-middle>Sudha Rao</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/y/yang-trista-cao/ class=align-middle>Yang Trista Cao</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/emily-m-bender/ class=align-middle>Emily M. Bender</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/allyson-ettinger/ class=align-middle>Allyson Ettinger</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jordan-boyd-graber/ class=align-middle>Jordan Boyd-Graber</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/k/khanh-nguyen/ class=align-middle>Khanh Nguyen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/daniel-marcu/ class=align-middle>Daniel Marcu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kevin-knight/ class=align-middle>Kevin Knight</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/amr-sharaf/ class=align-middle>Amr Sharaf</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chris-kedzie/ class=align-middle>Chris Kedzie</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kathleen-mckeown/ class=align-middle>Kathleen McKeown</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chen-zhao/ class=align-middle>Chen Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chenyan-xiong/ class=align-middle>Chenyan Xiong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elissa-redmiles/ class=align-middle>Elissa Redmiles</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lisa-maszkiewicz/ class=align-middle>Lisa Maszkiewicz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/emily-hwang/ class=align-middle>Emily Hwang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dhruv-kuchhal/ class=align-middle>Dhruv Kuchhal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/everest-liu/ class=align-middle>Everest Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/miraida-morales/ class=align-middle>Miraida Morales</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/denis-peskov/ class=align-middle>Denis Peskov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rock-stevens/ class=align-middle>Rock Stevens</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kristina-gligoric/ class=align-middle>Kristina Gligorić</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sean-kross/ class=align-middle>Sean Kross</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michelle-mazurek/ class=align-middle>Michelle Mazurek</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/han-chin-shing/ class=align-middle>Han-Chin Shing</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/suraj-nair/ class=align-middle>Suraj Nair</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ayah-zirikly/ class=align-middle>Ayah Zirikly</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/meir-friedenberg/ class=align-middle>Meir Friedenberg</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/philip-resnik/ class=align-middle>Philip Resnik</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kiante-brantley/ class=align-middle>Kianté Brantley</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kyunghyun-cho/ class=align-middle>Kyunghyun Cho</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sean-welleck/ class=align-middle>Sean Welleck</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>