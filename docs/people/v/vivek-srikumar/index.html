<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Vivek Srikumar - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Vivek</span> <span class=font-weight-bold>Srikumar</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.231.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--231 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.231 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.231/>Right for the Right Reason Evidence Extraction for Trustworthy Tabular Reasoning</a></strong><br><a href=/people/v/vivek-gupta/>Vivek Gupta</a>
|
<a href=/people/s/shuo-zhang/>Shuo Zhang</a>
|
<a href=/people/a/alakananda-vempala/>Alakananda Vempala</a>
|
<a href=/people/y/yujie-he/>Yujie He</a>
|
<a href=/people/t/temma-choji/>Temma Choji</a>
|
<a href=/people/v/vivek-srikumar/>Vivek Srikumar</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--231><div class="card-body p-3 small">When pre trained contextualized embedding based models developed for <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured data</a> are adapted for structured tabular data they perform admirably However recent probing studies show that these models use spurious correlations and often predict inference labels by focusing on false evidence or ignoring it altogether To study this issue we introduce the task of Trustworthy Tabular Reasoning where a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> needs to extract evidence to be used for <a href=https://en.wikipedia.org/wiki/Reason>reasoning</a> in addition to predicting the label As a case study we propose a two stage sequential prediction approach which includes an evidence extraction and an <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference stage</a> First we crowdsource evidence row labels and develop several unsupervised and supervised evidence extraction strategies for InfoTabS a tabular NLI benchmark Our evidence extraction strategy outperforms earlier <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> On the downstream tabular inference task using only the automatically extracted evidence as the premise our approach outperforms prior benchmarks</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.744.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--744 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.744 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929153 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.744" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.744/>Structured Tuning for Semantic Role Labeling</a></strong><br><a href=/people/t/tao-li/>Tao Li</a>
|
<a href=/people/p/parth-anand-jawale/>Parth Anand Jawale</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/v/vivek-srikumar/>Vivek Srikumar</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--744><div class="card-body p-3 small">Recent neural network-driven semantic role labeling (SRL) systems have shown impressive improvements in F1 scores. These improvements are due to expressive input representations, which, at least at the surface, are orthogonal to knowledge-rich constrained decoding mechanisms that helped linear SRL models. Introducing the benefits of <a href=https://en.wikipedia.org/wiki/Mathematical_structure>structure</a> to inform neural models presents a methodological challenge. In this paper, we present a structured tuning framework to improve <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> using softened constraints only at training time. Our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> leverages the expressiveness of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> and provides <a href=https://en.wikipedia.org/wiki/Supervisor>supervision</a> with structured loss components. We start with a strong <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> (RoBERTa) to validate the impact of our approach, and show that our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> outperforms the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> by learning to comply with declarative constraints. Additionally, our experiments with smaller training sizes show that we can achieve consistent improvements under low-resource scenarios.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3316.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3316 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3316 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W19-3316.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-3316" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-3316/>Preparing SNACS for Subjects and Objects<span class=acl-fixed-case>SNACS</span> for Subjects and Objects</a></strong><br><a href=/people/a/adi-shalev/>Adi Shalev</a>
|
<a href=/people/j/jena-d-hwang/>Jena D. Hwang</a>
|
<a href=/people/n/nathan-schneider/>Nathan Schneider</a>
|
<a href=/people/v/vivek-srikumar/>Vivek Srikumar</a>
|
<a href=/people/o/omri-abend/>Omri Abend</a>
|
<a href=/people/a/ari-rappoport/>Ari Rappoport</a><br><a href=/volumes/W19-33/ class=text-muted>Proceedings of the First International Workshop on Designing Meaning Representations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3316><div class="card-body p-3 small">Research on adpositions and possessives in multiple languages has led to a small inventory of general-purpose meaning classes that disambiguate tokens. Importantly, that work has argued for a principled separation of the semantic role in a scene from the function coded by <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphosyntax</a>. Here, we ask whether this approach can be generalized beyond adpositions and <a href=https://en.wikipedia.org/wiki/Possessive>possessives</a> to cover all scene participantsincluding subjects and objectsdirectly, without reference to a <a href=https://en.wikipedia.org/wiki/Frame_language>frame lexicon</a>. We present new guidelines for <a href=https://en.wikipedia.org/wiki/English_language>English</a> and the results of an interannotator agreement study.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1028.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1028 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1028 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383997156 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1028" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1028/>Augmenting Neural Networks with <a href=https://en.wikipedia.org/wiki/First-order_logic>First-order Logic</a></a></strong><br><a href=/people/t/tao-li/>Tao Li</a>
|
<a href=/people/v/vivek-srikumar/>Vivek Srikumar</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1028><div class="card-body p-3 small">Today, the dominant paradigm for training <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> involves minimizing task loss on a large dataset. Using <a href=https://en.wikipedia.org/wiki/World_knowledge>world knowledge</a> to inform a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>, and yet retain the ability to perform end-to-end training remains an open question. In this paper, we present a novel framework for introducing declarative knowledge to neural network architectures in order to guide <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a> and <a href=https://en.wikipedia.org/wiki/Prediction>prediction</a>. Our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> systematically compiles logical statements into computation graphs that augment a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> without extra learnable parameters or manual redesign. We evaluate our modeling strategy on three tasks : machine comprehension, natural language inference, and text chunking. Our experiments show that knowledge-augmented networks can strongly improve over <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>, especially in low-data regimes.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1563.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1563 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1563 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1563.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385223469 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1563" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1563/>Observing Dialogue in Therapy : Categorizing and Forecasting Behavioral Codes</a></strong><br><a href=/people/j/jie-cao/>Jie Cao</a>
|
<a href=/people/m/michael-tanana/>Michael Tanana</a>
|
<a href=/people/z/zac-imel/>Zac Imel</a>
|
<a href=/people/e/eric-poitras/>Eric Poitras</a>
|
<a href=/people/d/david-atkins/>David Atkins</a>
|
<a href=/people/v/vivek-srikumar/>Vivek Srikumar</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1563><div class="card-body p-3 small">Automatically analyzing dialogue can help understand and guide behavior in domains such as <a href=https://en.wikipedia.org/wiki/List_of_counseling_topics>counseling</a>, where interactions are largely mediated by <a href=https://en.wikipedia.org/wiki/Conversation>conversation</a>. In this paper, we study modeling behavioral codes used to asses a psychotherapy treatment style called Motivational Interviewing (MI), which is effective for addressing substance abuse and related problems. Specifically, we address the problem of providing real-time guidance to therapists with a dialogue observer that (1) categorizes therapist and client MI behavioral codes and, (2) forecasts codes for upcoming utterances to help guide the conversation and potentially alert the therapist. For both tasks, we define <a href=https://en.wikipedia.org/wiki/Neural_network>neural network models</a> that build upon recent successes in dialogue modeling. Our experiments demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> can outperform several <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> for both <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. We also report the results of a careful analysis that reveals the impact of the various network design tradeoffs for modeling therapy dialogue.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K19-1042.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K19-1042 data-toggle=collapse aria-expanded=false aria-controls=abstract-K19-1042 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K19-1042/>On the Limits of Learning to Actively Learn Semantic Representations</a></strong><br><a href=/people/o/omri-koshorek/>Omri Koshorek</a>
|
<a href=/people/g/gabriel-stanovsky/>Gabriel Stanovsky</a>
|
<a href=/people/y/yichu-zhou/>Yichu Zhou</a>
|
<a href=/people/v/vivek-srikumar/>Vivek Srikumar</a>
|
<a href=/people/j/jonathan-berant/>Jonathan Berant</a><br><a href=/volumes/K19-1/ class=text-muted>Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K19-1042><div class="card-body p-3 small">One of the goals of <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a> is to develop <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> that map sentences into meaning representations. However, training such <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> requires expensive annotation of complex structures, which hinders their adoption. Learning to actively-learn(LTAL) is a recent paradigm for reducing the amount of labeled data by learning a policy that selects which samples should be labeled. In this work, we examine <a href=https://en.wikipedia.org/wiki/LTAL>LTAL</a> for learning semantic representations, such as QA-SRL. We show that even an oracle policy that is allowed to pick examples that maximize performance on the test set (and constitutes an upper bound on the potential of LTAL), does not substantially improve performance compared to a random policy. We investigate factors that could explain this finding and show that a distinguishing characteristic of successful applications of LTAL is the interaction between <a href=https://en.wikipedia.org/wiki/Mathematical_optimization>optimization</a> and the oracle policy selection process. In successful applications of LTAL, the examples selected by the oracle policy do not substantially depend on the <a href=https://en.wikipedia.org/wiki/Mathematical_optimization>optimization procedure</a>, while in our setup the stochastic nature of <a href=https://en.wikipedia.org/wiki/Mathematical_optimization>optimization</a> strongly affects the examples selected by the oracle. We conclude that the current applicability of LTAL for improving <a href=https://en.wikipedia.org/wiki/Data_efficiency>data efficiency</a> in learning semantic meaning representations is limited.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-2007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-2007 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-2007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-2007/>Visual Interrogation of Attention-Based Models for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>Natural Language Inference</a> and Machine Comprehension</a></strong><br><a href=/people/s/shusen-liu/>Shusen Liu</a>
|
<a href=/people/t/tao-li/>Tao Li</a>
|
<a href=/people/z/zhimin-li/>Zhimin Li</a>
|
<a href=/people/v/vivek-srikumar/>Vivek Srikumar</a>
|
<a href=/people/v/valerio-pascucci/>Valerio Pascucci</a>
|
<a href=/people/p/peer-timo-bremer/>Peer-Timo Bremer</a><br><a href=/volumes/D18-2/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-2007><div class="card-body p-3 small">Neural networks models have gained unprecedented popularity in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> due to their state-of-the-art performance and the flexible end-to-end training scheme. Despite their advantages, the lack of interpretability hinders the deployment and refinement of the <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a>. In this work, we present a flexible visualization library for creating customized visual analytic environments, in which the user can investigate and interrogate the relationships among the input, the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model internals</a> (i.e., <a href=https://en.wikipedia.org/wiki/Attentional_control>attention</a>), and the output predictions, which in turn shed light on the <a href=https://en.wikipedia.org/wiki/Decision-making_software>model decision-making process</a>.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1173.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1173 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1173 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P17-1173/>An Algebra for Feature Extraction</a></strong><br><a href=/people/v/vivek-srikumar/>Vivek Srikumar</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1173><div class="card-body p-3 small">Though <a href=https://en.wikipedia.org/wiki/Feature_extraction>feature extraction</a> is a necessary first step in statistical NLP, it is often seen as a mere preprocessing step. Yet, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> can dominate <a href=https://en.wikipedia.org/wiki/Time_complexity>computation time</a>, both during training, and especially at deployment. In this paper, we formalize <a href=https://en.wikipedia.org/wiki/Feature_extraction>feature extraction</a> from an algebraic perspective. Our formalization allows us to define a message passing algorithm that can restructure <a href=https://en.wikipedia.org/wiki/Software_feature>feature templates</a> to be more computationally efficient. We show via experiments on text chunking and relation extraction that this restructuring does indeed speed up <a href=https://en.wikipedia.org/wiki/Feature_extraction>feature extraction</a> in practice by reducing redundant computation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4300.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4300/>Proceedings of the 2nd Workshop on Structured Prediction for Natural Language Processing</a></strong><br><a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/m/ming-wei-chang/>Ming-Wei Chang</a>
|
<a href=/people/v/vivek-srikumar/>Vivek Srikumar</a>
|
<a href=/people/a/alexander-m-rush/>Alexander M. Rush</a><br><a href=/volumes/W17-43/ class=text-muted>Proceedings of the 2nd Workshop on Structured Prediction for Natural Language Processing</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-1022.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-1022 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-1022 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/S17-1022.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/S17-1022/>Double Trouble : The Problem of Construal in Semantic Annotation of Adpositions</a></strong><br><a href=/people/j/jena-d-hwang/>Jena D. Hwang</a>
|
<a href=/people/a/archna-bhatia/>Archna Bhatia</a>
|
<a href=/people/n/na-rae-han/>Na-Rae Han</a>
|
<a href=/people/t/tim-ogorman/>Tim O’Gorman</a>
|
<a href=/people/v/vivek-srikumar/>Vivek Srikumar</a>
|
<a href=/people/n/nathan-schneider/>Nathan Schneider</a><br><a href=/volumes/S17-1/ class=text-muted>Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-1022><div class="card-body p-3 small">We consider the semantics of prepositions, revisiting a broad-coverage <a href=https://en.wikipedia.org/wiki/Annotation>annotation scheme</a> used for annotating all 4,250 <a href=https://en.wikipedia.org/wiki/Preposition_and_postposition>preposition tokens</a> in a 55,000 word corpus of English. Attempts to apply the scheme to adpositions and <a href=https://en.wikipedia.org/wiki/Marker_(linguistics)>case markers</a> in other languages, as well as some problematic cases in <a href=https://en.wikipedia.org/wiki/English_language>English</a>, have led us to reconsider the assumption that an adposition&#8217;s lexical contribution is equivalent to the role / relation that it mediates. Our proposal is to embrace the potential for construal in adposition use, expressing such phenomena directly at the token level to manage complexity and avoid sense proliferation. We suggest a framework to represent both the scene role and the adposition&#8217;s lexical function so they can be annotated at scalesupporting automatic, statistical processing of domain-general languageand discuss how this representation would allow for a simpler inventory of labels.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-5005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-5005 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-5005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-5005/>Integer Linear Programming formulations in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a></a></strong><br><a href=/people/d/dan-roth/>Dan Roth</a>
|
<a href=/people/v/vivek-srikumar/>Vivek Srikumar</a><br><a href=/volumes/E17-5/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Tutorial Abstracts</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-5005><div class="card-body p-3 small">Making decisions in natural language processing problems often involves assigning values to sets of <a href=https://en.wikipedia.org/wiki/Dependent_and_independent_variables>interdependent variables</a> where the expressive dependency structure can influence, or even dictate what assignments are possible. This setting includes a broad range of structured prediction problems such as <a href=https://en.wikipedia.org/wiki/Semantic_role_labeling>semantic role labeling</a>, <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity and relation recognition</a>, co-reference resolution, dependency parsing and <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a>. The setting is also appropriate for cases that may require making global decisions that involve multiple components, possibly pre-designed or pre-learned, as in event recognition and analysis, <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a>, <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrasing</a>, textual entailment and <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>. In all these cases, it is natural to formulate the <a href=https://en.wikipedia.org/wiki/Decision_problem>decision problem</a> as a constrained optimization problem, with an <a href=https://en.wikipedia.org/wiki/Loss_function>objective function</a> that is composed of learned models, subject to domain or problem specific constraints. Over the last few years, starting with a couple of papers written by (Roth & Yih, 2004, 2005), dozens of papers have been using the Integer linear programming (ILP) formulation developed there, including several award-winning papers (e.g., (Martins, Smith, & Xing, 2009 ; Koo, Rush, Collins, Jaakkola, & Sontag., 2010 ; Berant, Dagan, & Goldberger, 2011)).This tutorial will present the key ingredients of ILP formulations of natural language processing problems, aiming at guiding readers through the key modeling steps, explaining the learning and inference paradigms and exemplifying these by providing examples from the literature. We will cover a range of topics, from the theoretical foundations of learning and inference with ILP models, to practical modeling guides, to software packages and applications. The goal of this tutorial is to introduce the computational framework to broader ACL community, motivate it as a generic framework for learning and inference in global NLP decision problems, present some of the key theoretical and practical issues involved and survey some of the existing applications of it as a way to promote further development of the framework and additional applications. We will also make connections with some of the hot topics in current NLP research and show how they can be used within the general framework proposed here. The tutorial will thus be useful for many of the senior and junior researchers that have interest in global decision problems in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, providing a concise overview of recent perspectives and research results.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Vivek+Srikumar" title="Search for 'Vivek Srikumar' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/t/tao-li/ class=align-middle>Tao Li</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/jena-d-hwang/ class=align-middle>Jena D. Hwang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/n/nathan-schneider/ class=align-middle>Nathan Schneider</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/parth-anand-jawale/ class=align-middle>Parth Anand Jawale</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/martha-palmer/ class=align-middle>Martha Palmer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/k/kai-wei-chang/ class=align-middle>Kai-Wei Chang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/ming-wei-chang/ class=align-middle>Ming-Wei Chang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexander-m-rush/ class=align-middle>Alexander M. Rush</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vivek-gupta/ class=align-middle>Vivek Gupta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shuo-zhang/ class=align-middle>Shuo Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alakananda-vempala/ class=align-middle>Alakananda Vempala</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yujie-he/ class=align-middle>Yujie He</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/temma-choji/ class=align-middle>Temma Choji</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shusen-liu/ class=align-middle>Shusen Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhimin-li/ class=align-middle>Zhimin Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/valerio-pascucci/ class=align-middle>Valerio Pascucci</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/peer-timo-bremer/ class=align-middle>Peer-Timo Bremer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/archna-bhatia/ class=align-middle>Archna Bhatia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/na-rae-han/ class=align-middle>Na-Rae Han</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tim-ogorman/ class=align-middle>Tim O’Gorman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/adi-shalev/ class=align-middle>Adi Shalev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/omri-abend/ class=align-middle>Omri Abend</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ari-rappoport/ class=align-middle>Ari Rappoport</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dan-roth/ class=align-middle>Dan Roth</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jie-cao/ class=align-middle>Jie Cao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-tanana/ class=align-middle>Michael Tanana</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zac-imel/ class=align-middle>Zac Imel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eric-poitras/ class=align-middle>Eric Poitras</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/david-atkins/ class=align-middle>David Atkins</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/omri-koshorek/ class=align-middle>Omri Koshorek</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gabriel-stanovsky/ class=align-middle>Gabriel Stanovsky</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yichu-zhou/ class=align-middle>Yichu Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jonathan-berant/ class=align-middle>Jonathan Berant</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>