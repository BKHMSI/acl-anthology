<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Vered Shwartz - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Vered</span> <span class=font-weight-bold>Shwartz</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.repl4nlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.repl4nlp-1.0/>Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)</a></strong><br><a href=/people/a/anna-rogers/>Anna Rogers</a>
|
<a href=/people/i/iacer-calixto/>Iacer Calixto</a>
|
<a href=/people/i/ivan-vulic/>Ivan VuliÄ‡</a>
|
<a href=/people/n/naomi-saphra/>Naomi Saphra</a>
|
<a href=/people/n/nora-kassner/>Nora Kassner</a>
|
<a href=/people/o/oana-maria-camburu/>Oana-Maria Camburu</a>
|
<a href=/people/t/trapit-bansal/>Trapit Bansal</a>
|
<a href=/people/v/vered-shwartz/>Vered Shwartz</a><br><a href=/volumes/2021.repl4nlp-1/ class=text-muted>Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.556.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--556 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.556 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938640 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.556/>You are grounded ! : Latent Name Artifacts in Pre-trained Language Models</a></strong><br><a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/r/rachel-rudinger/>Rachel Rudinger</a>
|
<a href=/people/o/oyvind-tafjord/>Oyvind Tafjord</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--556><div class="card-body p-3 small">Pre-trained language models (LMs) may perpetuate biases originating in their training corpus to downstream models. We focus on artifacts associated with the representation of given names (e.g., Donald), which, depending on the corpus, may be associated with specific <a href=https://en.wikipedia.org/wiki/Non-physical_entity>entities</a>, as indicated by next token prediction (e.g., Trump). While helpful in some contexts, grounding happens also in under-specified or inappropriate contexts. For example, endings generated for &#8216;Donald is a&#8217; substantially differ from those of other names, and often have more-than-average negative sentiment. We demonstrate the potential effect on downstream tasks with reading comprehension probes where name perturbation changes the model answers. As a silver lining, our experiments suggest that additional <a href=https://en.wikipedia.org/wiki/Training>pre-training</a> on different corpora may mitigate this bias.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.418.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--418 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.418 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940700 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.findings-emnlp.418" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.418/>Thinking Like a Skeptic : Defeasible Inference in Natural Language</a></strong><br><a href=/people/r/rachel-rudinger/>Rachel Rudinger</a>
|
<a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/j/jena-d-hwang/>Jena D. Hwang</a>
|
<a href=/people/c/chandra-bhagavatula/>Chandra Bhagavatula</a>
|
<a href=/people/m/maxwell-forbes/>Maxwell Forbes</a>
|
<a href=/people/r/ronan-le-bras/>Ronan Le Bras</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--418><div class="card-body p-3 small">Defeasible inference is a mode of reasoning in which an inference (X is a bird, therefore X flies) may be weakened or overturned in light of new evidence (X is a penguin). Though long recognized in classical AI and philosophy, defeasible inference has not been extensively studied in the context of contemporary data-driven research on <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language inference</a> and <a href=https://en.wikipedia.org/wiki/Commonsense_reasoning>commonsense reasoning</a>. We introduce Defeasible NLI (abbreviated -NLI), a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for defeasible inference in <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. Defeasible NLI contains extensions to three existing inference datasets covering diverse modes of reasoning : <a href=https://en.wikipedia.org/wiki/Common_sense>common sense</a>, natural language inference, and <a href=https://en.wikipedia.org/wiki/Social_norm>social norms</a>. From Defeasible NLI, we develop both a classification and generation task for defeasible inference, and demonstrate that the generation task is much more challenging. Despite lagging human performance, however, <a href=https://en.wikipedia.org/wiki/Generative_model>generative models</a> trained on this <a href=https://en.wikipedia.org/wiki/Data>data</a> are capable of writing sentences that weaken or strengthen a specified <a href=https://en.wikipedia.org/wiki/Inference>inference</a> up to 68 % of the time.<tex-math>\\delta</tex-math>-NLI), a dataset for defeasible inference in natural language. Defeasible NLI contains extensions to three existing inference datasets covering diverse modes of reasoning: common sense, natural language inference, and social norms. From Defeasible NLI, we develop both a classification and generation task for defeasible inference, and demonstrate that the generation task is much more challenging. Despite lagging human performance, however, generative models trained on this data are capable of writing sentences that weaken or strengthen a specified inference up to 68% of the time.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sustainlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sustainlp-1.0/>Proceedings of SustaiNLP: Workshop on Simple and Efficient Natural Language Processing</a></strong><br><a href=/people/n/nafise-sadat-moosavi/>Nafise Sadat Moosavi</a>
|
<a href=/people/a/angela-fan/>Angela Fan</a>
|
<a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/g/goran-glavas/>Goran GlavaÅ¡</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/a/alex-wang/>Alex Wang</a>
|
<a href=/people/t/thomas-wolf/>Thomas Wolf</a><br><a href=/volumes/2020.sustainlp-1/ class=text-muted>Proceedings of SustaiNLP: Workshop on Simple and Efficient Natural Language Processing</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K19-1019.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K19-1019 data-toggle=collapse aria-expanded=false aria-controls=abstract-K19-1019 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K19-1019" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K19-1019/>Diversify Your Datasets : Analyzing Generalization via Controlled Variance in Adversarial Datasets</a></strong><br><a href=/people/o/ohad-rozen/>Ohad Rozen</a>
|
<a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/r/roee-aharoni/>Roee Aharoni</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a><br><a href=/volumes/K19-1/ class=text-muted>Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K19-1019><div class="card-body p-3 small">Phenomenon-specific adversarial datasets have been recently designed to perform targeted stress-tests for particular inference types. Recent work (Liu et al., 2019a) proposed that such datasets can be utilized for training NLI and other types of models, often allowing to learn the phenomenon in focus and improve on the challenge dataset, indicating a blind spot in the original training data. Yet, although a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can improve in such a training process, it might still be vulnerable to other challenge datasets targeting the same phenomenon but drawn from a different distribution, such as having a different syntactic complexity level. In this work, we extend this method to drive conclusions about a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>&#8217;s ability to learn and generalize a target phenomenon rather than to learn a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, by controlling additional aspects in the adversarial datasets. We demonstrate our approach on two inference phenomena dative alternation and numerical reasoning, elaborating, and in some cases contradicting, the results of Liu et al.. Our methodology enables building better challenge datasets for creating more robust models, and may yield better model understanding and subsequent overarching improvements.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1115.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1115 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1115 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1115/>SemEval-2018 Task 9 : Hypernym Discovery<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 9: Hypernym Discovery</a></strong><br><a href=/people/j/jose-camacho-collados/>Jose Camacho-Collados</a>
|
<a href=/people/c/claudio-delli-bovi/>Claudio Delli Bovi</a>
|
<a href=/people/l/luis-espinosa-anke/>Luis Espinosa-Anke</a>
|
<a href=/people/s/sergio-oramas/>Sergio Oramas</a>
|
<a href=/people/t/tommaso-pasini/>Tommaso Pasini</a>
|
<a href=/people/e/enrico-santus/>Enrico Santus</a>
|
<a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/r/roberto-navigli/>Roberto Navigli</a>
|
<a href=/people/h/horacio-saggion/>Horacio Saggion</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1115><div class="card-body p-3 small">This paper describes the SemEval 2018 Shared Task on Hypernym Discovery. We put forward this task as a complementary benchmark for modeling <a href=https://en.wikipedia.org/wiki/Hypernymy>hypernymy</a>, a problem which has traditionally been cast as a binary classification task, taking a pair of candidate words as input. Instead, our reformulated task is defined as follows : given an input term, retrieve (or discover) its suitable <a href=https://en.wikipedia.org/wiki/Hypernym>hypernyms</a> from a target corpus. We proposed five different subtasks covering three languages (English, Spanish, and Italian), and two specific domains of knowledge in English (Medical and Music). Participants were allowed to compete in any or all of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>subtasks</a>. Overall, a total of 11 teams participated, with a total of 39 different systems submitted through all subtasks. Data, results and further information about the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> can be found at.<url>https://competitions.codalab.org/competitions/17119</url>.\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-2020.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-2020 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-2020 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-2020/>Integrating Multiplicative Features into Supervised Distributional Methods for <a href=https://en.wikipedia.org/wiki/Lexical_analysis>Lexical Entailment</a></a></strong><br><a href=/people/t/tu-vu/>Tu Vu</a>
|
<a href=/people/v/vered-shwartz/>Vered Shwartz</a><br><a href=/volumes/S18-2/ class=text-muted>Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-2020><div class="card-body p-3 small">Supervised distributional methods are applied successfully in lexical entailment, but recent work questioned whether these methods actually learn a relation between two words. Specifically, Levy et al. (2015) claimed that <a href=https://en.wikipedia.org/wiki/Linear_classifier>linear classifiers</a> learn only separate properties of each word. We suggest a cheap and easy way to boost the performance of these <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> by integrating multiplicative features into commonly used <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a>. We provide an extensive evaluation with different <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> and evaluation setups, and suggest a suitable evaluation setup for the task, eliminating biases existing in previous ones.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-2103.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-2103 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-2103 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-2103.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805874 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-2103" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-2103/>Breaking NLI Systems with Sentences that Require Simple <a href=https://en.wikipedia.org/wiki/Lexical_analysis>Lexical Inferences</a><span class=acl-fixed-case>NLI</span> Systems with Sentences that Require Simple Lexical Inferences</a></strong><br><a href=/people/m/max-glockner/>Max Glockner</a>
|
<a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/y/yoav-goldberg/>Yoav Goldberg</a><br><a href=/volumes/P18-2/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-2103><div class="card-body p-3 small">We create a new NLI test set that shows the deficiency of state-of-the-art models in inferences that require lexical and world knowledge. The new examples are simpler than the SNLI test set, containing sentences that differ by at most one word from sentences in the training set. Yet, the performance on the new <a href=https://en.wikipedia.org/wiki/Test_set>test set</a> is substantially worse across <a href=https://en.wikipedia.org/wiki/System>systems</a> trained on SNLI, demonstrating that these <a href=https://en.wikipedia.org/wiki/System>systems</a> are limited in their generalization ability, failing to capture many simple inferences.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-3000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-3000/>Proceedings of <span class=acl-fixed-case>ACL</span> 2018, Student Research Workshop</a></strong><br><a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/j/jeniya-tabassum/>Jeniya Tabassum</a>
|
<a href=/people/r/rob-voigt/>Rob Voigt</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/m/marie-catherine-de-marneffe/>Marie-Catherine de Marneffe</a>
|
<a href=/people/m/malvina-nissim/>Malvina Nissim</a><br><a href=/volumes/P18-3/ class=text-muted>Proceedings of ACL 2018, Student Research Workshop</a></span></p><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-0902.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-0902 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-0902 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-0902" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-0902/>A Consolidated Open Knowledge Representation for Multiple Texts</a></strong><br><a href=/people/r/rachel-wities/>Rachel Wities</a>
|
<a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/g/gabriel-stanovsky/>Gabriel Stanovsky</a>
|
<a href=/people/m/meni-adler/>Meni Adler</a>
|
<a href=/people/o/ori-shapira/>Ori Shapira</a>
|
<a href=/people/s/shyam-upadhyay/>Shyam Upadhyay</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a>
|
<a href=/people/e/eugenio-martinez-camara/>Eugenio Martinez Camara</a>
|
<a href=/people/i/iryna-gurevych/>Iryna Gurevych</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a><br><a href=/volumes/W17-09/ class=text-muted>Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-0902><div class="card-body p-3 small">We propose to move from Open Information Extraction (OIE) ahead to Open Knowledge Representation (OKR), aiming to represent information conveyed jointly in a set of texts in an open text-based manner. We do so by consolidating OIE extractions using entity and predicate coreference, while modeling information containment between coreferring elements via lexical entailment. We suggest that generating OKR structures can be a useful step in the NLP pipeline, to give semantic applications an easy handle on consolidated information across multiple texts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-1019.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-1019 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-1019 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-1019/>Acquiring Predicate Paraphrases from News Tweets</a></strong><br><a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/g/gabriel-stanovsky/>Gabriel Stanovsky</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a><br><a href=/volumes/S17-1/ class=text-muted>Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-1019><div class="card-body p-3 small">We present a simple method for ever-growing extraction of predicate paraphrases from <a href=https://en.wikipedia.org/wiki/Headline>news headlines</a> in <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>. Analysis of the output of ten weeks of collection shows that the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrases</a> with different support levels is estimated between 60-86 %. We also demonstrate that our <a href=https://en.wikipedia.org/wiki/Resource>resource</a> is to a large extent complementary to existing resources, providing many novel <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrases</a>. Our <a href=https://en.wikipedia.org/wiki/Resource>resource</a> is publicly available, continuously expanding based on <a href=https://en.wikipedia.org/wiki/News>daily news</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-1007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-1007 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-1007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=E17-1007" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/E17-1007/>Hypernyms under Siege : Linguistically-motivated Artillery for Hypernymy Detection</a></strong><br><a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/e/enrico-santus/>Enrico Santus</a>
|
<a href=/people/d/dominik-schlechtweg/>Dominik Schlechtweg</a><br><a href=/volumes/E17-1/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-1007><div class="card-body p-3 small">The fundamental role of <a href=https://en.wikipedia.org/wiki/Hypernymy>hypernymy</a> in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> has motivated the development of many methods for the automatic identification of this relation, most of which rely on word distribution. We investigate an extensive number of such <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised measures</a>, using several distributional semantic models that differ by <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context type</a> and feature weighting. We analyze the performance of the different <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> based on their linguistic motivation. Comparison to the state-of-the-art supervised methods shows that while supervised methods generally outperform the unsupervised ones, the former are sensitive to the distribution of training instances, hurting their reliability. Being based on general linguistic hypotheses and independent from training data, unsupervised measures are more robust, and therefore are still useful artillery for hypernymy detection.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Vered+Shwartz" title="Search for 'Vered Shwartz' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/i/ido-dagan/ class=align-middle>Ido Dagan</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/r/rachel-rudinger/ class=align-middle>Rachel Rudinger</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/g/gabriel-stanovsky/ class=align-middle>Gabriel Stanovsky</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/enrico-santus/ class=align-middle>Enrico Santus</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/o/oyvind-tafjord/ class=align-middle>Oyvind Tafjord</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/a/anna-rogers/ class=align-middle>Anna Rogers</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/iacer-calixto/ class=align-middle>Iacer Calixto</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ivan-vulic/ class=align-middle>Ivan VuliÄ‡</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/naomi-saphra/ class=align-middle>Naomi Saphra</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nora-kassner/ class=align-middle>Nora Kassner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/oana-maria-camburu/ class=align-middle>Oana-Maria Camburu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/trapit-bansal/ class=align-middle>Trapit Bansal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rachel-wities/ class=align-middle>Rachel Wities</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/meni-adler/ class=align-middle>Meni Adler</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/ori-shapira/ class=align-middle>Ori Shapira</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shyam-upadhyay/ class=align-middle>Shyam Upadhyay</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dan-roth/ class=align-middle>Dan Roth</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eugenio-martinez-camara/ class=align-middle>Eugenio MartÃ­nez-CÃ¡mara</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/iryna-gurevych/ class=align-middle>Iryna Gurevych</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jena-d-hwang/ class=align-middle>Jena D. Hwang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chandra-bhagavatula/ class=align-middle>Chandra Bhagavatula</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maxwell-forbes/ class=align-middle>Maxwell Forbes</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ronan-le-bras/ class=align-middle>Ronan Le Bras</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/noah-a-smith/ class=align-middle>Noah A. Smith</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yejin-choi/ class=align-middle>Yejin Choi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jose-camacho-collados/ class=align-middle>Jose Camacho-Collados</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/claudio-delli-bovi/ class=align-middle>Claudio Delli Bovi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luis-espinosa-anke/ class=align-middle>Luis Espinosa Anke</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sergio-oramas/ class=align-middle>Sergio Oramas</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tommaso-pasini/ class=align-middle>Tommaso Pasini</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/roberto-navigli/ class=align-middle>Roberto Navigli</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/horacio-saggion/ class=align-middle>Horacio Saggion</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tu-vu/ class=align-middle>Tu Vu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dominik-schlechtweg/ class=align-middle>Dominik Schlechtweg</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/max-glockner/ class=align-middle>Max Glockner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yoav-goldberg/ class=align-middle>Yoav Goldberg</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jeniya-tabassum/ class=align-middle>Jeniya Tabassum</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rob-voigt/ class=align-middle>Rob Voigt</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wanxiang-che/ class=align-middle>Wanxiang Che (è½¦ä¸‡ç¿”)</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marie-catherine-de-marneffe/ class=align-middle>Marie-Catherine de Marneffe</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/malvina-nissim/ class=align-middle>Malvina Nissim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/ohad-rozen/ class=align-middle>Ohad Rozen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/roee-aharoni/ class=align-middle>Roee Aharoni</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nafise-sadat-moosavi/ class=align-middle>Nafise Sadat Moosavi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/angela-fan/ class=align-middle>Angela Fan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/goran-glavas/ class=align-middle>Goran GlavaÅ¡</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shafiq-joty/ class=align-middle>Shafiq Joty</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alex-wang/ class=align-middle>Alex Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thomas-wolf/ class=align-middle>Thomas Wolf</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/repl4nlp/ class=align-middle>RepL4NLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/sustainlp/ class=align-middle>sustainlp</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>