<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Valentin Malykh - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Valentin</span> <span class=font-weight-bold>Malykh</span></h2><hr><div class=row><div class=col-lg-9><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.381.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--381 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.381 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939106 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.381" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.381/>RussianSuperGLUE : A Russian Language Understanding Evaluation Benchmark<span class=acl-fixed-case>R</span>ussian<span class=acl-fixed-case>S</span>uper<span class=acl-fixed-case>GLUE</span>: A <span class=acl-fixed-case>R</span>ussian Language Understanding Evaluation Benchmark</a></strong><br><a href=/people/t/tatiana-shavrina/>Tatiana Shavrina</a>
|
<a href=/people/a/alena-fenogenova/>Alena Fenogenova</a>
|
<a href=/people/e/emelyanov-anton/>Emelyanov Anton</a>
|
<a href=/people/d/denis-shevelev/>Denis Shevelev</a>
|
<a href=/people/e/ekaterina-artemova/>Ekaterina Artemova</a>
|
<a href=/people/v/valentin-malykh/>Valentin Malykh</a>
|
<a href=/people/v/vladislav-mikhailov/>Vladislav Mikhailov</a>
|
<a href=/people/m/maria-tikhonova/>Maria Tikhonova</a>
|
<a href=/people/a/andrey-chertok/>Andrey Chertok</a>
|
<a href=/people/a/andrey-evlampiev/>Andrey Evlampiev</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--381><div class="card-body p-3 small">In this paper, we introduce an advanced Russian general language understanding evaluation benchmark Russian SuperGLUE. Recent advances in the field of universal language models and transformers require the development of a methodology for their broad diagnostics and testing for general intellectual skills-detection of natural language inference, commonsense reasoning, ability to perform simple logical operations regardless of text subject or lexicon. For the first time, a <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark</a> of nine tasks, collected and organized analogically to the SuperGLUE methodology, was developed from scratch for the <a href=https://en.wikipedia.org/wiki/Russian_language>Russian language</a>. We also provide baselines, human level evaluation, open-source framework for evaluating <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, and an overall leaderboard of transformer models for the <a href=https://en.wikipedia.org/wiki/Russian_language>Russian language</a>. Besides, we present the first results of comparing multilingual models in the translated diagnostic test set and offer the first steps to further expanding or assessing State-of-the-art <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> independently of language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.loresmt-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.loresmt-1.0/>Proceedings of the 3rd Workshop on Technologies for MT of Low Resource Languages</a></strong><br><a href=/people/a/alina-karakanta/>Alina Karakanta</a>
|
<a href=/people/a/atul-kr-ojha/>Atul Kr. Ojha</a>
|
<a href=/people/c/chao-hong-liu/>Chao-Hong Liu</a>
|
<a href=/people/j/jade-abbott/>Jade Abbott</a>
|
<a href=/people/j/john-ortega/>John Ortega</a>
|
<a href=/people/j/jonathan-washington/>Jonathan Washington</a>
|
<a href=/people/n/nathaniel-oco/>Nathaniel Oco</a>
|
<a href=/people/s/surafel-melaku-lakew/>Surafel Melaku Lakew</a>
|
<a href=/people/t/tommi-a-pirinen/>Tommi A Pirinen</a>
|
<a href=/people/v/valentin-malykh/>Valentin Malykh</a>
|
<a href=/people/v/varvara-logacheva/>Varvara Logacheva</a>
|
<a href=/people/x/xiaobing-zhao/>Xiaobing Zhao</a><br><a href=/volumes/2020.loresmt-1/ class=text-muted>Proceedings of the 3rd Workshop on Technologies for MT of Low Resource Languages</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.loresmt-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--loresmt-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.loresmt-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.loresmt-1.4/>Findings of the LoResMT 2020 Shared Task on Zero-Shot for Low-Resource languages<span class=acl-fixed-case>L</span>o<span class=acl-fixed-case>R</span>es<span class=acl-fixed-case>MT</span> 2020 Shared Task on Zero-Shot for Low-Resource languages</a></strong><br><a href=/people/a/atul-kr-ojha/>Atul Kr. Ojha</a>
|
<a href=/people/v/valentin-malykh/>Valentin Malykh</a>
|
<a href=/people/a/alina-karakanta/>Alina Karakanta</a>
|
<a href=/people/c/chao-hong-liu/>Chao-Hong Liu</a><br><a href=/volumes/2020.loresmt-1/ class=text-muted>Proceedings of the 3rd Workshop on Technologies for MT of Low Resource Languages</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--loresmt-1--4><div class="card-body p-3 small">This paper presents the findings of the LoResMT 2020 Shared Task on zero-shot translation for low resource languages. This task was organised as part of the 3rd Workshop on Technologies for MT of Low Resource Languages (LoResMT) at AACL-IJCNLP 2020. The focus was on the zero-shot approach as a notable development in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> to build MT systems for language pairs where parallel corpora are small or even non-existent. The shared task experience suggests that back-translation and domain adaptation methods result in better <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> for small-size datasets. We further noted that, although <a href=https://en.wikipedia.org/wiki/Translation>translation</a> between similar languages is no cakewalk, linguistically distinct languages require more data to give better results.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3605 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3605 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3605/><span class=acl-fixed-case>A</span>spe<span class=acl-fixed-case>R</span>a: Aspect-Based Rating Prediction Based on User Reviews</a></strong><br><a href=/people/e/elena-tutubalina/>Elena Tutubalina</a>
|
<a href=/people/v/valentin-malykh/>Valentin Malykh</a>
|
<a href=/people/s/sergey-nikolenko/>Sergey Nikolenko</a>
|
<a href=/people/a/anton-alekseev/>Anton Alekseev</a>
|
<a href=/people/i/ilya-shenbin/>Ilya Shenbin</a><br><a href=/volumes/W19-36/ class=text-muted>Proceedings of the 2019 Workshop on Widening NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3605><div class="card-body p-3 small">We propose a novel Aspect-based Rating Prediction model (AspeRa) that estimates user rating based on review texts for the items. It is based on aspect extraction with neural networks and combines the advantages of deep learning and topic modeling. It is mainly designed for recommendations, but an important secondary goal of AspeRa is to discover coherent aspects of reviews that can be used to explain predictions or for user profiling. We conduct a comprehensive empirical study of AspeRa, showing that it outperforms state-of-the-art models in terms of recommendation quality and produces interpretable aspects. This paper is an abridged version of our work (Nikolenko et al., 2019)</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-6800.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-6800/>Proceedings of the 2nd Workshop on Technologies for MT of Low Resource Languages</a></strong><br><a href=/people/a/alina-karakanta/>Alina Karakanta</a>
|
<a href=/people/a/atul-kr-ojha/>Atul Kr. Ojha</a>
|
<a href=/people/c/chao-hong-liu/>Chao-Hong Liu</a>
|
<a href=/people/j/jonathan-washington/>Jonathan Washington</a>
|
<a href=/people/n/nathaniel-oco/>Nathaniel Oco</a>
|
<a href=/people/s/surafel-melaku-lakew/>Surafel Melaku Lakew</a>
|
<a href=/people/v/valentin-malykh/>Valentin Malykh</a>
|
<a href=/people/x/xiaobing-zhao/>Xiaobing Zhao</a><br><a href=/volumes/W19-68/ class=text-muted>Proceedings of the 2nd Workshop on Technologies for MT of Low Resource Languages</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-2002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-2002 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-2002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-2002" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-2002/>Robust to Noise Models in Natural Language Processing Tasks</a></strong><br><a href=/people/v/valentin-malykh/>Valentin Malykh</a><br><a href=/volumes/P19-2/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-2002><div class="card-body p-3 small">There are a lot of noise texts surrounding a person in modern life. The traditional approach is to use spelling correction, yet the existing solutions are far from perfect. We propose robust to noise word embeddings model, which outperforms existing commonly used models, like fasttext and <a href=https://en.wikipedia.org/wiki/Word2vec>word2vec</a> in different tasks. In addition, we investigate the noise robustness of current <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> in different natural language processing tasks. We propose extensions for modern <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> in three <a href=https://en.wikipedia.org/wiki/Downstream_(networking)>downstream tasks</a>, i.e. text classification, named entity recognition and aspect extraction, which shows improvement in noise robustness over existing solutions.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-4021.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-4021 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-4021 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-4021/>DeepPavlov : Open-Source Library for Dialogue Systems<span class=acl-fixed-case>D</span>eep<span class=acl-fixed-case>P</span>avlov: Open-Source Library for Dialogue Systems</a></strong><br><a href=/people/m/mikhail-burtsev/>Mikhail Burtsev</a>
|
<a href=/people/a/alexander-seliverstov/>Alexander Seliverstov</a>
|
<a href=/people/r/rafael-airapetyan/>Rafael Airapetyan</a>
|
<a href=/people/m/mikhail-arkhipov/>Mikhail Arkhipov</a>
|
<a href=/people/d/dilyara-baymurzina/>Dilyara Baymurzina</a>
|
<a href=/people/n/nickolay-bushkov/>Nickolay Bushkov</a>
|
<a href=/people/o/olga-gureenkova/>Olga Gureenkova</a>
|
<a href=/people/t/taras-khakhulin/>Taras Khakhulin</a>
|
<a href=/people/y/yurii-kuratov/>Yuri Kuratov</a>
|
<a href=/people/d/denis-kuznetsov/>Denis Kuznetsov</a>
|
<a href=/people/a/alexey-litinsky/>Alexey Litinsky</a>
|
<a href=/people/v/varvara-logacheva/>Varvara Logacheva</a>
|
<a href=/people/a/alexey-lymar/>Alexey Lymar</a>
|
<a href=/people/v/valentin-malykh/>Valentin Malykh</a>
|
<a href=/people/m/maxim-petrov/>Maxim Petrov</a>
|
<a href=/people/v/vadim-polulyakh/>Vadim Polulyakh</a>
|
<a href=/people/l/leonid-pugachev/>Leonid Pugachev</a>
|
<a href=/people/a/alexey-sorokin/>Alexey Sorokin</a>
|
<a href=/people/m/maria-vikhreva/>Maria Vikhreva</a>
|
<a href=/people/m/marat-zaynutdinov/>Marat Zaynutdinov</a><br><a href=/volumes/P18-4/ class=text-muted>Proceedings of ACL 2018, System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-4021><div class="card-body p-3 small">Adoption of messaging communication and voice assistants has grown rapidly in the last years. This creates a demand for tools that speed up prototyping of feature-rich dialogue systems. An open-source library DeepPavlov is tailored for development of <a href=https://en.wikipedia.org/wiki/Intelligent_agent>conversational agents</a>. The <a href=https://en.wikipedia.org/wiki/Library_(computing)>library</a> prioritises efficiency, modularity, and extensibility with the goal to make it easier to develop dialogue systems from scratch and with limited data available. It supports modular as well as <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end approaches</a> to implementation of <a href=https://en.wikipedia.org/wiki/Intelligent_agent>conversational agents</a>. Conversational agent consists of skills and every skill can be decomposed into components. Components are usually models which solve typical NLP tasks such as intent classification, <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a> or pre-trained word vectors. Sequence-to-sequence chit-chat skill, question answering skill or task-oriented skill can be assembled from components provided in the <a href=https://en.wikipedia.org/wiki/Library_(computing)>library</a>.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Valentin+Malykh" title="Search for 'Valentin Malykh' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/a/alina-karakanta/ class=align-middle>Alina Karakanta</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/atul-kr-ojha/ class=align-middle>Atul Kr. Ojha</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/c/chao-hong-liu/ class=align-middle>Chao-Hong Liu</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/jonathan-washington/ class=align-middle>Jonathan Washington</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/n/nathaniel-oco/ class=align-middle>Nathaniel Oco</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/s/surafel-melaku-lakew/ class=align-middle>Surafel Melaku Lakew</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/x/xiaobing-zhao/ class=align-middle>Xiaobing Zhao</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/v/varvara-logacheva/ class=align-middle>Varvara Logacheva</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/tatiana-shavrina/ class=align-middle>Tatiana Shavrina</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alena-fenogenova/ class=align-middle>Alena Fenogenova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/emelyanov-anton/ class=align-middle>Emelyanov Anton</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/denis-shevelev/ class=align-middle>Denis Shevelev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/ekaterina-artemova/ class=align-middle>Ekaterina Artemova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vladislav-mikhailov/ class=align-middle>Vladislav Mikhailov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maria-tikhonova/ class=align-middle>Maria Tikhonova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrey-chertok/ class=align-middle>Andrey Chertok</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrey-evlampiev/ class=align-middle>Andrey Evlampiev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elena-tutubalina/ class=align-middle>Elena Tutubalina</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sergey-nikolenko/ class=align-middle>Sergey Nikolenko</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anton-alekseev/ class=align-middle>Anton Alekseev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ilya-shenbin/ class=align-middle>Ilya Shenbin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jade-abbott/ class=align-middle>Jade Abbott</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/john-ortega/ class=align-middle>John Ortega</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tommi-a-pirinen/ class=align-middle>Tommi A. Pirinen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mikhail-burtsev/ class=align-middle>Mikhail Burtsev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexander-seliverstov/ class=align-middle>Alexander Seliverstov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rafael-airapetyan/ class=align-middle>Rafael Airapetyan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mikhail-arkhipov/ class=align-middle>Mikhail Arkhipov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dilyara-baymurzina/ class=align-middle>Dilyara Baymurzina</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nickolay-bushkov/ class=align-middle>Nickolay Bushkov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/olga-gureenkova/ class=align-middle>Olga Gureenkova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/taras-khakhulin/ class=align-middle>Taras Khakhulin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yurii-kuratov/ class=align-middle>Yurii Kuratov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/denis-kuznetsov/ class=align-middle>Denis Kuznetsov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexey-litinsky/ class=align-middle>Alexey Litinsky</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexey-lymar/ class=align-middle>Alexey Lymar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maxim-petrov/ class=align-middle>Maxim Petrov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vadim-polulyakh/ class=align-middle>Vadim Polulyakh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/leonid-pugachev/ class=align-middle>Leonid Pugachev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexey-sorokin/ class=align-middle>Alexey Sorokin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maria-vikhreva/ class=align-middle>Maria Vikhreva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marat-zaynutdinov/ class=align-middle>Marat Zaynutdinov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/loresmt/ class=align-middle>loresmt</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>