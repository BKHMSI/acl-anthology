<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Vivek Kulkarni - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Vivek</span> <span class=font-weight-bold>Kulkarni</span></h2><hr><div class=row><div class=col-lg-9><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.152.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--152 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.152 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940122 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.findings-emnlp.152" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.152/>TopicBERT for Energy Efficient Document Classification<span class=acl-fixed-case>T</span>opic<span class=acl-fixed-case>BERT</span> for Energy Efficient Document Classification</a></strong><br><a href=/people/y/yatin-chaudhary/>Yatin Chaudhary</a>
|
<a href=/people/p/pankaj-gupta/>Pankaj Gupta</a>
|
<a href=/people/k/khushbu-saxena/>Khushbu Saxena</a>
|
<a href=/people/v/vivek-kulkarni/>Vivek Kulkarni</a>
|
<a href=/people/t/thomas-runkler/>Thomas Runkler</a>
|
<a href=/people/h/hinrich-schutze/>Hinrich Sch√ºtze</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--152><div class="card-body p-3 small">Prior research notes that BERT&#8217;s computational cost grows quadratically with sequence length thus leading to longer <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training times</a>, higher GPU memory constraints and <a href=https://en.wikipedia.org/wiki/Greenhouse_gas>carbon emissions</a>. While recent work seeks to address these scalability issues at pre-training, these issues are also prominent in <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> especially for long sequence tasks like <a href=https://en.wikipedia.org/wiki/Document_classification>document classification</a>. Our work thus focuses on optimizing the <a href=https://en.wikipedia.org/wiki/Computational_cost>computational cost</a> of <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> for <a href=https://en.wikipedia.org/wiki/Document_classification>document classification</a>. We achieve this by complementary learning of both topic and language models in a unified framework, named TopicBERT. This significantly reduces the number of self-attention operations a main performance bottleneck. Consequently, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves a 1.4x (40 %) <a href=https://en.wikipedia.org/wiki/Speedup>speedup</a> with 40 % reduction in <a href=https://en.wikipedia.org/wiki/Carbon_dioxide_in_Earth&#8217;s_atmosphere>CO2 emission</a> while retaining 99.9 % performance over 5 datasets.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1496.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1496 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1496 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385272712 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1496/>TWEETQA : A Social Media Focused Question Answering Dataset<span class=acl-fixed-case>TWEETQA</span>: A Social Media Focused Question Answering Dataset</a></strong><br><a href=/people/w/wenhan-xiong/>Wenhan Xiong</a>
|
<a href=/people/j/jiawei-wu/>Jiawei Wu</a>
|
<a href=/people/h/hong-wang/>Hong Wang</a>
|
<a href=/people/v/vivek-kulkarni/>Vivek Kulkarni</a>
|
<a href=/people/m/mo-yu/>Mo Yu</a>
|
<a href=/people/s/shiyu-chang/>Shiyu Chang</a>
|
<a href=/people/x/xiaoxiao-guo/>Xiaoxiao Guo</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1496><div class="card-body p-3 small">With <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> becoming increasingly popular on which lots of news and real-time events are reported, developing automated question answering systems is critical to the effective-ness of many applications that rely on real-time knowledge. While previous datasets have concentrated on <a href=https://en.wikipedia.org/wiki/Question_answering>question answering (QA)</a> for formal text like <a href=https://en.wikipedia.org/wiki/News>news</a> and <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, we present the first large-scale dataset for QA over <a href=https://en.wikipedia.org/wiki/Social_media>social media data</a>. To ensure that the tweets we collected are useful, we only gather tweets used by journalists to write <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>. We then ask human annotators to write questions and answers upon these tweets. Unlike otherQA datasets like SQuAD in which the answers are extractive, we allow the answers to be abstractive. We show that two recently proposed neural models that perform well on <a href=https://en.wikipedia.org/wiki/Formal_language>formal texts</a> are limited in their performance when applied to our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. In addition, even the fine-tuned BERT model is still lagging behind human performance with a large margin. Our results thus point to the need of improved <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA systems</a> targeting <a href=https://en.wikipedia.org/wiki/Social_media>social media text</a>.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1388.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1388 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1388 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1388/>Multi-view Models for Political Ideology Detection of News Articles</a></strong><br><a href=/people/v/vivek-kulkarni/>Vivek Kulkarni</a>
|
<a href=/people/j/junting-ye/>Junting Ye</a>
|
<a href=/people/s/steven-skiena/>Steve Skiena</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1388><div class="card-body p-3 small">A news article&#8217;s title, content and link structure often reveal its <a href=https://en.wikipedia.org/wiki/Ideology>political ideology</a>. However, most existing works on automatic political ideology detection only leverage textual cues. Drawing inspiration from recent advances in neural inference, we propose a novel attention based multi-view model to leverage cues from all of the above views to identify the <a href=https://en.wikipedia.org/wiki/Ideology>ideology</a> evinced by a <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news article</a>. Our model draws on advances in representation learning in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> and <a href=https://en.wikipedia.org/wiki/Network_science>network science</a> to capture cues from both textual content and the network structure of <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>. We empirically evaluate our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> against a battery of baselines and show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms state of the art by 10 percentage points F1 score.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2013 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234955925 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-2013/>On the Distribution of Lexical Features at Multiple Levels of Analysis</a></strong><br><a href=/people/f/fatemeh-almodaresi/>Fatemeh Almodaresi</a>
|
<a href=/people/l/lyle-ungar/>Lyle Ungar</a>
|
<a href=/people/v/vivek-kulkarni/>Vivek Kulkarni</a>
|
<a href=/people/m/mohsen-zakeri/>Mohsen Zakeri</a>
|
<a href=/people/s/salvatore-giorgi/>Salvatore Giorgi</a>
|
<a href=/people/h/h-andrew-schwartz/>H. Andrew Schwartz</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2013><div class="card-body p-3 small">Natural language processing has increasingly moved from modeling documents and words toward studying the people behind the language. This move to working with data at the user or community level has presented the field with different characteristics of linguistic data. In this paper, we empirically characterize various lexical distributions at different levels of analysis, showing that, while most features are decidedly sparse and non-normal at the message-level (as with traditional NLP), they follow the <a href=https://en.wikipedia.org/wiki/Central_limit_theorem>central limit theorem</a> to become much more <a href=https://en.wikipedia.org/wiki/Log-normal_distribution>Log-normal</a> or even Normal at the user- and county-levels. Finally, we demonstrate that modeling lexical features for the correct level of analysis leads to marked improvements in common social scientific prediction tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1119.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1119 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1119 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238233454 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1119/>Human Centered NLP with User-Factor Adaptation<span class=acl-fixed-case>NLP</span> with User-Factor Adaptation</a></strong><br><a href=/people/v/veronica-lynn/>Veronica Lynn</a>
|
<a href=/people/y/youngseo-son/>Youngseo Son</a>
|
<a href=/people/v/vivek-kulkarni/>Vivek Kulkarni</a>
|
<a href=/people/n/niranjan-balasubramanian/>Niranjan Balasubramanian</a>
|
<a href=/people/h/h-andrew-schwartz/>H. Andrew Schwartz</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1119><div class="card-body p-3 small">We pose the general task of user-factor adaptation adapting supervised learning models to real-valued user factors inferred from a background of their language, reflecting the idea that a piece of text should be understood within the context of the user that wrote it. We introduce a continuous adaptation technique, suited for real-valued user factors that are common in <a href=https://en.wikipedia.org/wiki/Social_science>social science</a> and bringing us closer to personalized NLP, adapting to each user uniquely. We apply this technique with known user factors including age, gender, and personality traits, as well as latent factors, evaluating over five tasks : POS tagging, PP-attachment, <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, sarcasm detection, and stance detection. Adaptation provides statistically significant benefits for 3 of the 5 tasks : up to +1.2 points for PP-attachment, +3.4 points for <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a>, and +3.0 points for <a href=https://en.wikipedia.org/wiki/List_of_human_positions>stance</a>.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Vivek+Kulkarni" title="Search for 'Vivek Kulkarni' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/h/h-andrew-schwartz/ class=align-middle>H. Andrew Schwartz</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/w/william-yang-wang/ class=align-middle>William Yang Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/f/fatemeh-almodaresi/ class=align-middle>Fatemeh Almodaresi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lyle-ungar/ class=align-middle>Lyle Ungar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mohsen-zakeri/ class=align-middle>Mohsen Zakeri</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/s/salvatore-giorgi/ class=align-middle>Salvatore Giorgi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/junting-ye/ class=align-middle>Junting Ye</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/steven-skiena/ class=align-middle>Steven Skiena</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/veronica-lynn/ class=align-middle>Veronica Lynn</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/youngseo-son/ class=align-middle>Youngseo Son</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/niranjan-balasubramanian/ class=align-middle>Niranjan Balasubramanian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yatin-chaudhary/ class=align-middle>Yatin Chaudhary</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pankaj-gupta/ class=align-middle>Pankaj Gupta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/khushbu-saxena/ class=align-middle>Khushbu Saxena</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thomas-runkler/ class=align-middle>Thomas Runkler</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hinrich-schutze/ class=align-middle>Hinrich Sch√ºtze</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wenhan-xiong/ class=align-middle>Wenhan Xiong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiawei-wu/ class=align-middle>Jiawei Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hong-wang/ class=align-middle>Hong Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mo-yu/ class=align-middle>Mo Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shiyu-chang/ class=align-middle>Shiyu Chang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaoxiao-guo/ class=align-middle>Xiaoxiao Guo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ¬©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>