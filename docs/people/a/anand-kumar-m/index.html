<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Anand Kumar M - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Anand</span> <span class=font-weight-bold>Kumar M</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Anand Kumar <span class=font-weight-normal>M</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.0/>Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages</a></strong><br><a href=/people/b/bharathi-raja-chakravarthi/>Bharathi Raja Chakravarthi</a>
|
<a href=/people/r/ruba-priyadharshini/>Ruba Priyadharshini</a>
|
<a href=/people/a/anand-kumar-m/>Anand Kumar M</a>
|
<a href=/people/p/parameswari-krishnamurthy/>Parameswari Krishnamurthy</a>
|
<a href=/people/e/elizabeth-sherly/>Elizabeth Sherly</a><br><a href=/volumes/2021.dravidianlangtech-1/ class=text-muted>Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.17/>Findings of the Shared Task on Offensive Language Identification in <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a>, <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a>, and <a href=https://en.wikipedia.org/wiki/Kannada>Kannada</a><span class=acl-fixed-case>T</span>amil, <span class=acl-fixed-case>M</span>alayalam, and <span class=acl-fixed-case>K</span>annada</a></strong><br><a href=/people/b/bharathi-raja-chakravarthi/>Bharathi Raja Chakravarthi</a>
|
<a href=/people/r/ruba-priyadharshini/>Ruba Priyadharshini</a>
|
<a href=/people/n/navya-jose/>Navya Jose</a>
|
<a href=/people/a/anand-kumar-m/>Anand Kumar M</a>
|
<a href=/people/t/thomas-mandl/>Thomas Mandl</a>
|
<a href=/people/p/prasanna-kumar-kumaresan/>Prasanna Kumar Kumaresan</a>
|
<a href=/people/r/rahul-ponnusamy/>Rahul Ponnusamy</a>
|
<a href=/people/h/hariharan-r-l/>Hariharan R L</a>
|
<a href=/people/j/john-philip-mccrae/>John P. McCrae</a>
|
<a href=/people/e/elizabeth-sherly/>Elizabeth Sherly</a><br><a href=/volumes/2021.dravidianlangtech-1/ class=text-muted>Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--17><div class="card-body p-3 small">Detecting <a href=https://en.wikipedia.org/wiki/Profanity>offensive language</a> in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> in <a href=https://en.wikipedia.org/wiki/Language_localisation>local languages</a> is critical for moderating user-generated content. Thus, the field of offensive language identification in under-resourced Tamil, <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a> and <a href=https://en.wikipedia.org/wiki/Kannada>Kannada languages</a> are essential. As the <a href=https://en.wikipedia.org/wiki/User-generated_content>user-generated content</a> is more code-mixed and not well studied for under-resourced languages, it is imperative to create resources and conduct benchmarking studies to encourage research in under-resourced Dravidian languages. We created a shared task on offensive language detection in <a href=https://en.wikipedia.org/wiki/Dravidian_languages>Dravidian languages</a>. We summarize here the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for this challenge which are openly available at https://competitions.codalab.org/competitions/27654, and present an overview of the <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> and the results of the competing systems.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.fnp-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--fnp-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.fnp-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.fnp-1.9/>NITK NLP at FinCausal-2020 Task 1 Using BERT and Linear models.<span class=acl-fixed-case>NITK</span> <span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>F</span>in<span class=acl-fixed-case>C</span>ausal-2020 Task 1 Using <span class=acl-fixed-case>BERT</span> and Linear models.</a></strong><br><a href=/people/h/hariharan-r-l/>Hariharan R L</a>
|
<a href=/people/a/anand-kumar-m/>Anand Kumar M</a><br><a href=/volumes/2020.fnp-1/ class=text-muted>Proceedings of the 1st Joint Workshop on Financial Narrative Processing and MultiLing Financial Summarisation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--fnp-1--9><div class="card-body p-3 small">FinCausal-2020 is the shared task which focuses on the causality detection of factual data for <a href=https://en.wikipedia.org/wiki/Financial_analysis>financial analysis</a>. The financial data facts do n&#8217;t provide much explanation on the variability of these <a href=https://en.wikipedia.org/wiki/Data>data</a>. This paper aims to propose an efficient method to classify the data into one which is having any financial cause or not. Many models were used to classify the data, out of which <a href=https://en.wikipedia.org/wiki/Statistical_model>SVM model</a> gave an <a href=https://en.wikipedia.org/wiki/F-score>F-Score</a> of 0.9435, BERT with specific <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> achieved best results with <a href=https://en.wikipedia.org/wiki/F-score>F-Score</a> of 0.9677.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1078.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1078 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1078 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1078/>CENNLP at SemEval-2018 Task 2 : Enhanced Distributed Representation of Text using Target Classes for Emoji Prediction Representation<span class=acl-fixed-case>CENNLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: Enhanced Distributed Representation of Text using Target Classes for Emoji Prediction Representation</a></strong><br><a href=/people/n/naveen-j-r/>Naveen J R</a>
|
<a href=/people/h/hariharan-v/>Hariharan V</a>
|
<a href=/people/b/barathi-ganesh-h-b/>Barathi Ganesh H. B.</a>
|
<a href=/people/a/anand-kumar-m/>Anand Kumar M</a>
|
<a href=/people/s/soman-k-p/>Soman K P</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1078><div class="card-body p-3 small">Emoji is one of the fastest growing language in <a href=https://en.wikipedia.org/wiki/Popular_culture>pop-culture</a>, especially in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> and it is very unlikely for its usage to decrease. These are generally used to bring an extra level of meaning to the texts, posted on <a href=https://en.wikipedia.org/wiki/Social_media>social media platforms</a>. Providing such an added info, gives more insights to the <a href=https://en.wikipedia.org/wiki/Plain_text>plain text</a>, arising to hidden interpretation within the text. This paper explains our analysis on Task 2, Multilingual Emoji Prediction sharedtask conducted by Semeval-2018. In the task, a predicted <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> based on a piece of Twitter text are labelled under 20 different classes (most commonly used emojis) where these <a href=https://en.wikipedia.org/wiki/Class_(computer_programming)>classes</a> are learnt and further predicted are made for unseen Twitter text. In this work, we have experimented and analysed emojis predicted based on Twitter text, as a classification problem where the entailing <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> is considered as a label for every individual text data. We have implemented this using distributed representation of text through <a href=https://en.wikipedia.org/wiki/FastText>fastText</a>. Also, we have made an effort to demonstrate how fastText framework can be useful in case of emoji prediction. This <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is divide into two subtask, they are based on dataset presented in two different languages English and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1166.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1166 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1166 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1166/>AmritaNLP at SemEval-2018 Task 10 : Capturing discriminative attributes using convolution neural network over global vector representation.<span class=acl-fixed-case>A</span>mrita<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 10: Capturing discriminative attributes using convolution neural network over global vector representation.</a></strong><br><a href=/people/v/vivek-vinayan/>Vivek Vinayan</a>
|
<a href=/people/a/anand-kumar-m/>Anand Kumar M</a>
|
<a href=/people/s/soman-k-p/>Soman K P</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1166><div class="card-body p-3 small">The Capturing Discriminative Attributes sharedtask is the tenth <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>, conjoint with SemEval2018. The task is to predict if a word can capture distinguishing attributes of one word from another. We use GloVe word embedding, pre-trained on openly sourced corpus for this task. A base <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representation</a> is initially established over varied dimensions. These representations are evaluated based on validation scores over two <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, first on an SVM based classifier and second on a one dimension CNN model. The scores are used to further develop the <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representation</a> with vector combinations, by considering various distance measures. These measures correspond to offset vectors which are concatenated as <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>, mainly to improve upon the F1score, with the best <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. The <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> are then further tuned on the validation scores, to achieve highest F1score. Our evaluation narrowed down to two <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representations</a>, classified on CNN models, having a total dimension length of 1204 & 1203 for the final submissions. Of the two, the latter feature representation delivered our best F1score of 0.658024 (as per result).</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Anand+Kumar+M" title="Search for 'Anand Kumar M' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/s/soman-k-p/ class=align-middle>Soman K P</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/bharathi-raja-chakravarthi/ class=align-middle>Bharathi Raja Chakravarthi</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/ruba-priyadharshini/ class=align-middle>Ruba Priyadharshini</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/elizabeth-sherly/ class=align-middle>Elizabeth Sherly</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hariharan-r-l/ class=align-middle>Hariharan R L</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/n/naveen-j-r/ class=align-middle>Naveen J R</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hariharan-v/ class=align-middle>Hariharan V</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/barathi-ganesh-h-b/ class=align-middle>Barathi Ganesh H. B.</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vivek-vinayan/ class=align-middle>Vivek Vinayan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/parameswari-krishnamurthy/ class=align-middle>Parameswari Krishnamurthy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/navya-jose/ class=align-middle>Navya Jose</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thomas-mandl/ class=align-middle>Thomas Mandl</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/prasanna-kumar-kumaresan/ class=align-middle>Prasanna Kumar Kumaresan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rahul-ponnusamy/ class=align-middle>Rahul Ponnusamy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/john-philip-mccrae/ class=align-middle>John Philip McCrae</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/dravidianlangtech/ class=align-middle>DravidianLangTech</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/fnp/ class=align-middle>FNP</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>