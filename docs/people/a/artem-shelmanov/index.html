<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Artem Shelmanov - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Artem</span> <span class=font-weight-bold>Shelmanov</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.findings-acl.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--findings-acl--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.findings-acl.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2022.findings-acl.21/>RuCCoN Clinical Concept Normalization in Russian<span class=acl-fixed-case>R</span>u<span class=acl-fixed-case>CC</span>o<span class=acl-fixed-case>N</span>: Clinical Concept Normalization in <span class=acl-fixed-case>R</span>ussian</a></strong><br><a href=/people/a/alexandr-nesterov/>Alexandr Nesterov</a>
|
<a href=/people/g/galina-zubkova/>Galina Zubkova</a>
|
<a href=/people/z/zulfat-miftahutdinov/>Zulfat Miftahutdinov</a>
|
<a href=/people/v/vladimir-kokh/>Vladimir Kokh</a>
|
<a href=/people/e/elena-tutubalina/>Elena Tutubalina</a>
|
<a href=/people/a/artem-shelmanov/>Artem Shelmanov</a>
|
<a href=/people/a/anton-alekseev/>Anton Alekseev</a>
|
<a href=/people/m/manvel-avetisian/>Manvel Avetisian</a>
|
<a href=/people/a/andrey-chertok/>Andrey Chertok</a>
|
<a href=/people/s/sergey-nikolenko/>Sergey Nikolenko</a><br><a href=/volumes/2022.findings-acl/ class=text-muted>Findings of the Association for Computational Linguistics: ACL 2022</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--findings-acl--21><div class="card-body p-3 small">We present RuCCoN a new dataset for clinical concept normalization in <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a> manually annotated by medical professionals It contains over 16,028 entity mentions manually linked to over 2,409 unique concepts from the Russian language part of the UMLS ontology We provide train test splits for different settings stratified zero shot and CUI less and present strong baselines obtained with state of the art models such as SapBERT At present Russian medical NLP is lacking in both <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> and trained <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> and we view this work as an important step towards filling this gap Our dataset and annotation guidelines are available at https://github.com/sberbank-ai-lab/RuCCoN.</div></div><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-main.145.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-main--145 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-main.145 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-main.145/>Active Learning for Sequence Tagging with Deep Pre-trained Models and Bayesian Uncertainty Estimates<span class=acl-fixed-case>B</span>ayesian Uncertainty Estimates</a></strong><br><a href=/people/a/artem-shelmanov/>Artem Shelmanov</a>
|
<a href=/people/d/dmitri-puzyrev/>Dmitri Puzyrev</a>
|
<a href=/people/l/lyubov-kupriyanova/>Lyubov Kupriyanova</a>
|
<a href=/people/d/denis-belyakov/>Denis Belyakov</a>
|
<a href=/people/d/daniil-larionov/>Daniil Larionov</a>
|
<a href=/people/n/nikita-khromov/>Nikita Khromov</a>
|
<a href=/people/o/olga-kozlova/>Olga Kozlova</a>
|
<a href=/people/e/ekaterina-artemova/>Ekaterina Artemova</a>
|
<a href=/people/d/dmitry-v-dylov/>Dmitry V. Dylov</a>
|
<a href=/people/a/alexander-panchenko/>Alexander Panchenko</a><br><a href=/volumes/2021.eacl-main/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-main--145><div class="card-body p-3 small">Annotating training data for sequence tagging of texts is usually very time-consuming. Recent advances in <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> in conjunction with active learning open the possibility to significantly reduce the necessary annotation budget. We are the first to thoroughly investigate this powerful combination for the sequence tagging task. We conduct an extensive empirical study of various Bayesian uncertainty estimation methods and Monte Carlo dropout options for deep pre-trained models in the active learning framework and find the best combinations for different types of <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a>. Besides, we also demonstrate that to acquire instances during <a href=https://en.wikipedia.org/wiki/Active_learning>active learning</a>, a full-size Transformer can be substituted with a distilled version, which yields better computational performance and reduces obstacles for applying deep active learning in practice.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.717.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--717 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.717 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.717" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.717/>NB-MLM : Efficient Domain Adaptation of Masked Language Models for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a><span class=acl-fixed-case>NB</span>-<span class=acl-fixed-case>MLM</span>: Efficient Domain Adaptation of Masked Language Models for Sentiment Analysis</a></strong><br><a href=/people/n/nikolay-arefyev/>Nikolay Arefyev</a>
|
<a href=/people/d/dmitrii-kharchev/>Dmitrii Kharchev</a>
|
<a href=/people/a/artem-shelmanov/>Artem Shelmanov</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--717><div class="card-body p-3 small">While Masked Language Models (MLM) are pre-trained on massive datasets, the additional training with the MLM objective on domain or task-specific data before fine-tuning for the final task is known to improve the final performance. This is usually referred to as the domain or task adaptation step. However, unlike the initial pre-training, this step is performed for each domain or task individually and is still rather slow, requiring several GPU days compared to several GPU hours required for the final task fine-tuning. We argue that the standard MLM objective leads to inefficiency when it is used for the adaptation step because it mostly learns to predict the most frequent words, which are not necessarily related to a final task. We propose a technique for more efficient <a href=https://en.wikipedia.org/wiki/Adaptation>adaptation</a> that focuses on predicting words with large weights of the <a href=https://en.wikipedia.org/wiki/Naive_Bayes_classifier>Naive Bayes classifier</a> trained for the task at hand, which are likely more relevant than the most frequent words. The proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> provides faster adaptation and better final performance for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> compared to the standard approach.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.pam-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--pam-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.pam-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.pam-1.13/>Generating Lexical Representations of Frames using Lexical Substitution</a></strong><br><a href=/people/s/saba-anwar/>Saba Anwar</a>
|
<a href=/people/a/artem-shelmanov/>Artem Shelmanov</a>
|
<a href=/people/a/alexander-panchenko/>Alexander Panchenko</a>
|
<a href=/people/c/chris-biemann/>Chris Biemann</a><br><a href=/volumes/2020.pam-1/ class=text-muted>Proceedings of the Probability and Meaning Conference (PaM 2020)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--pam-1--13><div class="card-body p-3 small">Semantic frames are <a href=https://en.wikipedia.org/wiki/Formal_language>formal linguistic structures</a> describing situations / actions / events, e.g. Commercial transfer of goods. Each frame provides a set of <a href=https://en.wikipedia.org/wiki/Character_(arts)>roles</a> corresponding to the situation participants, e.g. Buyer and Goods, and lexical units (LUs) words and phrases that can evoke this particular <a href=https://en.wikipedia.org/wiki/Frame_story>frame</a> in texts, e.g. Sell. The scarcity of annotated resources hinders wider adoption of <a href=https://en.wikipedia.org/wiki/Frame_semantics_(linguistics)>frame semantics</a> across languages and domains. We investigate a simple yet effective method, <a href=https://en.wikipedia.org/wiki/Lexical_substitution>lexical substitution</a> with word representation models, to automatically expand a small set of frame-annotated sentences with new words for their respective roles and LUs. We evaluate the expansion quality using <a href=https://en.wikipedia.org/wiki/FrameNet>FrameNet</a>. Contextualized models demonstrate overall superior performance compared to the non-contextualized ones on roles. However, the latter show comparable performance on the task of LU expansion.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.728.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--728 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.728 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.728/>Word Sense Disambiguation for 158 Languages using Word Embeddings Only</a></strong><br><a href=/people/v/varvara-logacheva/>Varvara Logacheva</a>
|
<a href=/people/d/denis-teslenko/>Denis Teslenko</a>
|
<a href=/people/a/artem-shelmanov/>Artem Shelmanov</a>
|
<a href=/people/s/steffen-remus/>Steffen Remus</a>
|
<a href=/people/d/dmitry-ustalov/>Dmitry Ustalov</a>
|
<a href=/people/a/andrey-kutuzov/>Andrey Kutuzov</a>
|
<a href=/people/e/ekaterina-artemova/>Ekaterina Artemova</a>
|
<a href=/people/c/chris-biemann/>Chris Biemann</a>
|
<a href=/people/s/simone-paolo-ponzetto/>Simone Paolo Ponzetto</a>
|
<a href=/people/a/alexander-panchenko/>Alexander Panchenko</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--728><div class="card-body p-3 small">Disambiguation of word senses in context is easy for humans, but is a major challenge for automatic approaches. Sophisticated supervised and knowledge-based models were developed to solve this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. However, (i) the inherent <a href=https://en.wikipedia.org/wiki/Zipfian_distribution>Zipfian distribution</a> of supervised training instances for a given word and/or (ii) the quality of linguistic knowledge representations motivate the development of completely unsupervised and knowledge-free approaches to word sense disambiguation (WSD). They are particularly useful for under-resourced languages which do not have any resources for building either supervised and/or knowledge-based models. In this paper, we present a method that takes as input a standard pre-trained word embedding model and induces a fully-fledged word sense inventory, which can be used for disambiguation in context. We use this method to induce a collection of sense inventories for 158 languages on the basis of the original pre-trained fastText word embeddings by Grave et al., (2018), enabling WSD in these <a href=https://en.wikipedia.org/wiki/Language>languages</a>. Models and system are available online.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2711.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2711 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2711 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W19-2711.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W19-2711/>Towards the Data-driven System for Rhetorical Parsing of Russian Texts<span class=acl-fixed-case>R</span>ussian Texts</a></strong><br><a href=/people/a/artem-shelmanov/>Artem Shelmanov</a>
|
<a href=/people/d/dina-pisarevskaya/>Dina Pisarevskaya</a>
|
<a href=/people/e/elena-chistova/>Elena Chistova</a>
|
<a href=/people/s/svetlana-toldova/>Svetlana Toldova</a>
|
<a href=/people/m/maria-kobozeva/>Maria Kobozeva</a>
|
<a href=/people/i/ivan-smirnov/>Ivan Smirnov</a><br><a href=/volumes/W19-27/ class=text-muted>Proceedings of the Workshop on Discourse Relation Parsing and Treebanking 2019</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2711><div class="card-body p-3 small">Results of the first experimental evaluation of <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning models</a> trained on Ru-RSTreebank first Russian corpus annotated within RST framework are presented. Various lexical, quantitative, morphological, and semantic features were used. In rhetorical relation classification, ensemble of CatBoost model with selected <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> and a linear SVM model provides the best score (macro F1 = 54.67 0.38). We discover that most of the important features for rhetorical relation classification are related to discourse connectives derived from the connectives lexicon for <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a> and from other sources.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3708.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3708 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3708 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-3708" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-3708/>A Dataset for Noun Compositionality Detection for a <a href=https://en.wikipedia.org/wiki/Slavic_languages>Slavic Language</a><span class=acl-fixed-case>S</span>lavic Language</a></strong><br><a href=/people/d/dmitry-puzyrev/>Dmitry Puzyrev</a>
|
<a href=/people/a/artem-shelmanov/>Artem Shelmanov</a>
|
<a href=/people/a/alexander-panchenko/>Alexander Panchenko</a>
|
<a href=/people/e/ekaterina-artemova/>Ekaterina Artemova</a><br><a href=/volumes/W19-37/ class=text-muted>Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3708><div class="card-body p-3 small">This paper presents the first gold-standard resource for <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a> annotated with compositionality information of noun compounds. The compound phrases are collected from the Universal Dependency treebanks according to part of speech patterns, such as ADJ+NOUN or NOUN+NOUN, using the gold-standard annotations. Each <a href=https://en.wikipedia.org/wiki/Compound_(linguistics)>compound phrase</a> is annotated by two experts and a moderator according to the following schema : the phrase can be either compositional, non-compositional, or ambiguous (i.e., depending on the context it can be interpreted both as compositional or non-compositional). We conduct an experimental evaluation of <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> and <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> for predicting compositionality of noun compounds in unsupervised and supervised setups. We show that <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> from previous work evaluated on the proposed Russian-language resource achieve the performance comparable with results on <a href=https://en.wikipedia.org/wiki/English_language>English corpora</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1073.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1073 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1073 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1073/>Semantic Role Labeling with Pretrained Language Models for Known and Unknown Predicates</a></strong><br><a href=/people/d/daniil-larionov/>Daniil Larionov</a>
|
<a href=/people/a/artem-shelmanov/>Artem Shelmanov</a>
|
<a href=/people/e/elena-chistova/>Elena Chistova</a>
|
<a href=/people/i/ivan-smirnov/>Ivan Smirnov</a><br><a href=/volumes/R19-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1073><div class="card-body p-3 small">We build the first full <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline</a> for semantic role labelling of Russian texts. The <a href=https://en.wikipedia.org/wiki/Pipeline_transport>pipeline</a> implements predicate identification, argument extraction, argument classification (labeling), and global scoring via <a href=https://en.wikipedia.org/wiki/Integer_linear_programming>integer linear programming</a>. We train supervised neural network models for argument classification using Russian semantically annotated corpus FrameBank. However, we note that this resource provides <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> only to a very limited set of predicates. We combat the problem of annotation scarcity by introducing two models that rely on different sets of <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> : one for known predicates that are present in the training set and one for unknown predicates that are not. We show that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> for unknown predicates can alleviate the lack of <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a> by using pretrained embeddings. We perform experiments with various types of embeddings including the ones generated by deep pretrained language models : word2vec, FastText, ELMo, BERT, and show that embeddings generated by deep pretrained language models are superior to classical shallow embeddings for argument classification of both known and unknown predicates.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Artem+Shelmanov" title="Search for 'Artem Shelmanov' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/a/alexander-panchenko/ class=align-middle>Alexander Panchenko</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/e/ekaterina-artemova/ class=align-middle>Ekaterina Artemova</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/c/chris-biemann/ class=align-middle>Chris Biemann</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/daniil-larionov/ class=align-middle>Daniil Larionov</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/elena-chistova/ class=align-middle>Elena Chistova</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/i/ivan-smirnov/ class=align-middle>Ivan Smirnov</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/saba-anwar/ class=align-middle>Saba Anwar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dmitri-puzyrev/ class=align-middle>Dmitri Puzyrev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lyubov-kupriyanova/ class=align-middle>Lyubov Kupriyanova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/denis-belyakov/ class=align-middle>Denis Belyakov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nikita-khromov/ class=align-middle>Nikita Khromov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/olga-kozlova/ class=align-middle>Olga Kozlova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dmitry-v-dylov/ class=align-middle>Dmitry V. Dylov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nikolay-arefyev/ class=align-middle>Nikolay Arefyev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dmitrii-kharchev/ class=align-middle>Dmitrii Kharchev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexandr-nesterov/ class=align-middle>Alexandr Nesterov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/galina-zubkova/ class=align-middle>Galina Zubkova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zulfat-miftahutdinov/ class=align-middle>Zulfat Miftahutdinov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vladimir-kokh/ class=align-middle>Vladimir Kokh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elena-tutubalina/ class=align-middle>Elena Tutubalina</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anton-alekseev/ class=align-middle>Anton Alekseev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/manvel-avetisian/ class=align-middle>Manvel Avetisian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrey-chertok/ class=align-middle>Andrey Chertok</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sergey-nikolenko/ class=align-middle>Sergey Nikolenko</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dina-pisarevskaya/ class=align-middle>Dina Pisarevskaya</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/svetlana-toldova/ class=align-middle>Svetlana Toldova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maria-kobozeva/ class=align-middle>Maria Kobozeva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dmitry-puzyrev/ class=align-middle>Dmitry Puzyrev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/varvara-logacheva/ class=align-middle>Varvara Logacheva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/denis-teslenko/ class=align-middle>Denis Teslenko</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/steffen-remus/ class=align-middle>Steffen Remus</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dmitry-ustalov/ class=align-middle>Dmitry Ustalov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrey-kutuzov/ class=align-middle>Andrey Kutuzov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/simone-paolo-ponzetto/ class=align-middle>Simone Paolo Ponzetto</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/pam/ class=align-middle>PaM</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ranlp/ class=align-middle>RANLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>