<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Anoop Kunchukuttan - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Anoop</span> <span class=font-weight-bold>Kunchukuttan</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wat-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wat-1.0/>Proceedings of the 8th Workshop on Asian Translation (WAT2021)</a></strong><br><a href=/people/t/toshiaki-nakazawa/>Toshiaki Nakazawa</a>
|
<a href=/people/h/hideki-nakayama/>Hideki Nakayama</a>
|
<a href=/people/i/isao-goto/>Isao Goto</a>
|
<a href=/people/h/hideya-mino/>Hideya Mino</a>
|
<a href=/people/c/chenchen-ding/>Chenchen Ding</a>
|
<a href=/people/r/raj-dabre/>Raj Dabre</a>
|
<a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/s/shohei-higashiyama/>Shohei Higashiyama</a>
|
<a href=/people/h/hiroshi-manabe/>Hiroshi Manabe</a>
|
<a href=/people/w/win-pa-pa/>Win Pa Pa</a>
|
<a href=/people/s/shantipriya-parida/>Shantipriya Parida</a>
|
<a href=/people/o/ondrej-bojar/>Ondřej Bojar</a>
|
<a href=/people/c/chenhui-chu/>Chenhui Chu</a>
|
<a href=/people/a/akiko-eriguchi/>Akiko Eriguchi</a>
|
<a href=/people/k/kaori-abe/>Kaori Abe</a>
|
<a href=/people/y/yusuke-oda/>Yusuke Oda</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/s/sadao-kurohashi/>Sadao Kurohashi</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/2021.wat-1/ class=text-muted>Proceedings of the 8th Workshop on Asian Translation (WAT2021)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wat-1.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wat-1--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wat-1.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wat-1.22/>Itihasa : A <a href=https://en.wikipedia.org/wiki/Text_corpus>large-scale corpus</a> for Sanskrit to English translation<span class=acl-fixed-case>S</span>anskrit to <span class=acl-fixed-case>E</span>nglish translation</a></strong><br><a href=/people/r/rahul-aralikatte/>Rahul Aralikatte</a>
|
<a href=/people/m/miryam-de-lhoneux/>Miryam de Lhoneux</a>
|
<a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/a/anders-sogaard/>Anders Søgaard</a><br><a href=/volumes/2021.wat-1/ class=text-muted>Proceedings of the 8th Workshop on Asian Translation (WAT2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wat-1--22><div class="card-body p-3 small">This work introduces <a href=https://en.wikipedia.org/wiki/Itihasa>Itihasa</a>, a large-scale translation dataset containing 93,000 pairs of Sanskrit shlokas and their English translations. The <a href=https://en.wikipedia.org/wiki/Shloka>shlokas</a> are extracted from two <a href=https://en.wikipedia.org/wiki/Indian_epic_poetry>Indian epics</a> viz., The <a href=https://en.wikipedia.org/wiki/Ramayana>Ramayana</a> and The <a href=https://en.wikipedia.org/wiki/Mahabharata>Mahabharata</a>. We first describe the motivation behind the curation of such a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and follow up with empirical analysis to bring out its nuances. We then benchmark the performance of standard translation models on this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> and show that even state-of-the-art transformer architectures perform poorly, emphasizing the complexity of the dataset.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.repl4nlp-1.6.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929772 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.6/>Learning Geometric Word Meta-Embeddings</a></strong><br><a href=/people/p/pratik-jawanpuria/>Pratik Jawanpuria</a>
|
<a href=/people/s/satya-dev-n-t-v/>Satya Dev N T V</a>
|
<a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/b/bamdev-mishra/>Bamdev Mishra</a><br><a href=/volumes/2020.repl4nlp-1/ class=text-muted>Proceedings of the 5th Workshop on Representation Learning for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--6><div class="card-body p-3 small">We propose a geometric framework for learning meta-embeddings of words from different embedding sources. Our framework transforms the <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> into a common latent space, where, for example, simple averaging or concatenation of different embeddings (of a given word) is more amenable. The proposed latent space arises from two particular geometric transformations-source embedding specific orthogonal rotations and a common Mahalanobis metric scaling. Empirical results on several word similarity and word analogy benchmarks illustrate the efficacy of the proposed framework.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.445.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--445 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.445 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.445/>IndicNLPSuite : Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indian Languages</a><span class=acl-fixed-case>I</span>ndic<span class=acl-fixed-case>NLPS</span>uite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for <span class=acl-fixed-case>I</span>ndian Languages</a></strong><br><a href=/people/d/divyanshu-kakwani/>Divyanshu Kakwani</a>
|
<a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/s/satish-golla/>Satish Golla</a>
|
<a href=/people/g/gokul-n-c/>Gokul N.C.</a>
|
<a href=/people/a/avik-bhattacharyya/>Avik Bhattacharyya</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a>
|
<a href=/people/p/pratyush-kumar/>Pratyush Kumar</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--445><div class="card-body p-3 small">In this paper, we introduce NLP resources for 11 major <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indian languages</a> from two major language families. These resources include : (a) large-scale sentence-level monolingual corpora, (b) pre-trained word embeddings, (c) pre-trained language models, and (d) multiple NLU evaluation datasets (IndicGLUE benchmark). The monolingual corpora contains a total of 8.8 billion tokens across all 11 languages and <a href=https://en.wikipedia.org/wiki/Indian_English>Indian English</a>, primarily sourced from <a href=https://en.wikipedia.org/wiki/Web_crawler>news crawls</a>. The <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> are based on <a href=https://en.wikipedia.org/wiki/FastText>FastText</a>, hence suitable for handling morphological complexity of <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indian languages</a>. The pre-trained language models are based on the compact ALBERT model. Lastly, we compile the (IndicGLUE benchmark for Indian language NLU. To this end, we create datasets for the following tasks : Article Genre Classification, Headline Prediction, Wikipedia Section-Title Prediction, Cloze-style Multiple choice QA, Winograd NLI and COPA. We also include publicly available datasets for some Indic languages for tasks like <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a>, Cross-lingual Sentence Retrieval, <a href=https://en.wikipedia.org/wiki/Paraphrase_detection>Paraphrase detection</a>, etc. Our <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> are competitive or better than existing pre-trained embeddings on multiple tasks. We hope that the availability of the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> will accelerate Indic NLP research which has the potential to impact more than a billion people. It can also help the community in evaluating advances in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> over a more diverse pool of languages. The data and models are available at.<i>IndicGLUE</i> benchmark). The monolingual corpora contains a total of 8.8 billion tokens across all 11 languages and Indian English, primarily sourced from news crawls. The word embeddings are based on <i>FastText</i>, hence suitable for handling morphological complexity of Indian languages. The pre-trained language models are based on the compact ALBERT model. Lastly, we compile the (<i>IndicGLUE</i> benchmark for Indian language NLU. To this end, we create datasets for the following tasks: Article Genre Classification, Headline Prediction, Wikipedia Section-Title Prediction, Cloze-style Multiple choice QA, Winograd NLI and COPA. We also include publicly available datasets for some Indic languages for tasks like Named Entity Recognition, Cross-lingual Sentence Retrieval, Paraphrase detection, <i>etc.</i> Our embeddings are competitive or better than existing pre-trained embeddings on multiple tasks. We hope that the availability of the dataset will accelerate Indic NLP research which has the potential to impact more than a billion people. It can also help the community in evaluating advances in NLP over a more diverse pool of languages. The data and models are available at <url>https://indicnlp.ai4bharat.org</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wat-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.wat-1.0/>Proceedings of the 7th Workshop on Asian Translation</a></strong><br><a href=/people/t/toshiaki-nakazawa/>Toshiaki Nakazawa</a>
|
<a href=/people/h/hideki-nakayama/>Hideki Nakayama</a>
|
<a href=/people/c/chenchen-ding/>Chenchen Ding</a>
|
<a href=/people/r/raj-dabre/>Raj Dabre</a>
|
<a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/w/win-pa-pa/>Win Pa Pa</a>
|
<a href=/people/o/ondrej-bojar/>Ondřej Bojar</a>
|
<a href=/people/s/shantipriya-parida/>Shantipriya Parida</a>
|
<a href=/people/i/isao-goto/>Isao Goto</a>
|
<a href=/people/h/hidaya-mino/>Hidaya Mino</a>
|
<a href=/people/h/hiroshi-manabe/>Hiroshi Manabe</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/s/sadao-kurohashi/>Sadao Kurohashi</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/2020.wat-1/ class=text-muted>Proceedings of the 7th Workshop on Asian Translation</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5200.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5200/>Proceedings of the 6th Workshop on Asian Translation</a></strong><br><a href=/people/t/toshiaki-nakazawa/>Toshiaki Nakazawa</a>
|
<a href=/people/c/chenchen-ding/>Chenchen Ding</a>
|
<a href=/people/r/raj-dabre/>Raj Dabre</a>
|
<a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/n/nobushige-doi/>Nobushige Doi</a>
|
<a href=/people/y/yusuke-oda/>Yusuke Oda</a>
|
<a href=/people/o/ondrej-bojar/>Ondřej Bojar</a>
|
<a href=/people/s/shantipriya-parida/>Shantipriya Parida</a>
|
<a href=/people/i/isao-goto/>Isao Goto</a>
|
<a href=/people/h/hidaya-mino/>Hidaya Mino</a><br><a href=/volumes/D19-52/ class=text-muted>Proceedings of the 6th Workshop on Asian Translation</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5201.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5201 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5201 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5201/>Overview of the 6th Workshop on Asian Translation<span class=acl-fixed-case>A</span>sian Translation</a></strong><br><a href=/people/t/toshiaki-nakazawa/>Toshiaki Nakazawa</a>
|
<a href=/people/n/nobushige-doi/>Nobushige Doi</a>
|
<a href=/people/s/shohei-higashiyama/>Shohei Higashiyama</a>
|
<a href=/people/c/chenchen-ding/>Chenchen Ding</a>
|
<a href=/people/r/raj-dabre/>Raj Dabre</a>
|
<a href=/people/h/hideya-mino/>Hideya Mino</a>
|
<a href=/people/i/isao-goto/>Isao Goto</a>
|
<a href=/people/w/win-pa-pa/>Win Pa Pa</a>
|
<a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/y/yusuke-oda/>Yusuke Oda</a>
|
<a href=/people/s/shantipriya-parida/>Shantipriya Parida</a>
|
<a href=/people/o/ondrej-bojar/>Ondřej Bojar</a>
|
<a href=/people/s/sadao-kurohashi/>Sadao Kurohashi</a><br><a href=/volumes/D19-52/ class=text-muted>Proceedings of the 6th Workshop on Asian Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5201><div class="card-body p-3 small">This paper presents the results of the shared tasks from the 6th workshop on Asian translation (WAT2019) including JaEn, JaZh scientific paper translation subtasks, JaEn, JaKo, JaEn patent translation subtasks, HiEn, MyEn, KmEn, TaEn mixed domain subtasks and RuJa news commentary translation task. For the WAT2019, 25 teams participated in the shared tasks. We also received 10 research paper submissions out of which 61 were accepted. About 400 translation results were submitted to the automatic evaluation server, and selected submis- sions were manually evaluated.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1022.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1022 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1022 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q18-1022/>Leveraging Orthographic Similarity for Multilingual Neural Transliteration</a></strong><br><a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh Khapra</a>
|
<a href=/people/g/gurneet-singh/>Gurneet Singh</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/Q18-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 6</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1022><div class="card-body p-3 small">We address the task of joint training of transliteration models for multiple language pairs (multilingual transliteration). This is an instance of <a href=https://en.wikipedia.org/wiki/Multitask_learning>multitask learning</a>, where individual tasks (language pairs) benefit from sharing knowledge with related tasks. We focus on <a href=https://en.wikipedia.org/wiki/Transliteration>transliteration</a> involving related <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> i.e., <a href=https://en.wikipedia.org/wiki/Language_family>languages sharing writing systems</a> and <a href=https://en.wikipedia.org/wiki/Phoneme>phonetic properties</a> (orthographically similar languages). We propose a modified neural encoder-decoder model that maximizes parameter sharing across language pairs in order to effectively leverage orthographic similarity. We show that multilingual transliteration significantly outperforms bilingual transliteration in different scenarios (average increase of 58 % across a variety of languages we experimented with). We also show that multilingual transliteration models can generalize well to languages / language pairs not encountered during training and hence perform well on the zeroshot transliteration task. We show that further improvements can be achieved by using phonetic feature input.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2048.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2048 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2048 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2048/>Utilizing Lexical Similarity between Related, Low-resource Languages for Pivot-based SMT<span class=acl-fixed-case>SMT</span></a></strong><br><a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/m/maulik-shah/>Maulik Shah</a>
|
<a href=/people/p/pradyot-prakash/>Pradyot Prakash</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/I17-2/ class=text-muted>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2048><div class="card-body p-3 small">We investigate pivot-based translation between related languages in a low resource, phrase-based SMT setting. We show that a subword-level pivot-based SMT model using a related pivot language is substantially better than word and morpheme-level pivot models. It is also highly competitive with the best direct translation model, which is encouraging as no direct source-target training corpus is used. We also show that combining multiple related language pivot models can rival a direct translation model. Thus, the use of <a href=https://en.wikipedia.org/wiki/Subword>subwords</a> as translation units coupled with multiple related pivot languages can compensate for the lack of a direct parallel corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4102.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4102 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4102 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4102/>Learning variable length units for SMT between related languages via Byte Pair Encoding<span class=acl-fixed-case>SMT</span> between related languages via Byte Pair Encoding</a></strong><br><a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/W17-41/ class=text-muted>Proceedings of the First Workshop on Subword and Character Level Models in NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4102><div class="card-body p-3 small">We explore the use of <a href=https://en.wikipedia.org/wiki/Segment_(linguistics)>segments</a> learnt using Byte Pair Encoding (referred to as BPE units) as basic units for <a href=https://en.wikipedia.org/wiki/Statistical_machine_translation>statistical machine translation</a> between related languages and compare it with orthographic syllables, which are currently the best performing basic units for this translation task. BPE identifies the most frequent character sequences as basic units, while orthographic syllables are linguistically motivated pseudo-syllables. We show that BPE units modestly outperform orthographic syllables as units of translation, showing up to 11 % increase in BLEU score. While orthographic syllables can be used only for languages whose <a href=https://en.wikipedia.org/wiki/Writing_system>writing systems</a> use vowel representations, BPE is writing system independent and we show that BPE outperforms other units for non-vowel writing systems too. Our results are supported by extensive experimentation spanning multiple language families and <a href=https://en.wikipedia.org/wiki/Writing_system>writing systems</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5717.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5717 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5717 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5717/>Comparing Recurrent and Convolutional Architectures for English-Hindi Neural Machine Translation<span class=acl-fixed-case>E</span>nglish-<span class=acl-fixed-case>H</span>indi Neural Machine Translation</a></strong><br><a href=/people/s/sandhya-singh/>Sandhya Singh</a>
|
<a href=/people/r/ritesh-panjwani/>Ritesh Panjwani</a>
|
<a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/W17-57/ class=text-muted>Proceedings of the 4th Workshop on Asian Translation (WAT2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5717><div class="card-body p-3 small">In this paper, we empirically compare the two encoder-decoder neural machine translation architectures : convolutional sequence to sequence model (ConvS2S) and recurrent sequence to sequence model (RNNS2S) for English-Hindi language pair as part of IIT Bombay&#8217;s submission to WAT2017 shared task. We report the results for both English-Hindi and Hindi-English direction of language pair.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Anoop+Kunchukuttan" title="Search for 'Anoop Kunchukuttan' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/p/pushpak-bhattacharyya/ class=align-middle>Pushpak Bhattacharyya</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/t/toshiaki-nakazawa/ class=align-middle>Toshiaki Nakazawa</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/c/chenchen-ding/ class=align-middle>Chenchen Ding</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/r/raj-dabre/ class=align-middle>Raj Dabre</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/o/ondrej-bojar/ class=align-middle>Ondřej Bojar</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/s/shantipriya-parida/ class=align-middle>Shantipriya Parida</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/i/isao-goto/ class=align-middle>Isao Goto</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/y/yusuke-oda/ class=align-middle>Yusuke Oda</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/w/win-pa-pa/ class=align-middle>Win Pa Pa</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/sadao-kurohashi/ class=align-middle>Sadao Kurohashi</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/n/nobushige-doi/ class=align-middle>Nobushige Doi</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hidaya-mino/ class=align-middle>Hidaya Mino</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/shohei-higashiyama/ class=align-middle>Shohei Higashiyama</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hideya-mino/ class=align-middle>Hideya Mino</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mitesh-m-khapra/ class=align-middle>Mitesh M. Khapra</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hideki-nakayama/ class=align-middle>Hideki Nakayama</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hiroshi-manabe/ class=align-middle>Hiroshi Manabe</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/katsuhito-sudoh/ class=align-middle>Katsuhito Sudoh</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/maulik-shah/ class=align-middle>Maulik Shah</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pradyot-prakash/ class=align-middle>Pradyot Prakash</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sandhya-singh/ class=align-middle>Sandhya Singh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ritesh-panjwani/ class=align-middle>Ritesh Panjwani</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pratik-jawanpuria/ class=align-middle>Pratik Jawanpuria</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/satya-dev-n-t-v/ class=align-middle>Satya Dev N T V</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bamdev-mishra/ class=align-middle>Bamdev Mishra</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gurneet-singh/ class=align-middle>Gurneet Singh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/divyanshu-kakwani/ class=align-middle>Divyanshu Kakwani</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/satish-golla/ class=align-middle>Satish Golla</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gokul-n-c/ class=align-middle>Gokul N.C.</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/avik-bhattacharyya/ class=align-middle>Avik Bhattacharyya</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pratyush-kumar/ class=align-middle>Pratyush Kumar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chenhui-chu/ class=align-middle>Chenhui Chu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/akiko-eriguchi/ class=align-middle>Akiko Eriguchi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kaori-abe/ class=align-middle>Kaori Abe</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rahul-aralikatte/ class=align-middle>Rahul Aralikatte</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/miryam-de-lhoneux/ class=align-middle>Miryam de Lhoneux</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anders-sogaard/ class=align-middle>Anders Søgaard</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/wat/ class=align-middle>WAT</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/repl4nlp/ class=align-middle>RepL4NLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/tacl/ class=align-middle>TACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>