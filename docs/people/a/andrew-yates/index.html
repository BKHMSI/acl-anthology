<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Andrew Yates - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Andrew</span> <span class=font-weight-bold>Yates</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.nlp4prog-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--nlp4prog-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.nlp4prog-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.nlp4prog-1.10/>Bag-of-Words Baselines for Semantic Code Search</a></strong><br><a href=/people/x/xinyu-zhang/>Xinyu Zhang</a>
|
<a href=/people/j/ji-xin/>Ji Xin</a>
|
<a href=/people/a/andrew-yates/>Andrew Yates</a>
|
<a href=/people/j/jimmy-lin/>Jimmy Lin</a><br><a href=/volumes/2021.nlp4prog-1/ class=text-muted>Proceedings of the 1st Workshop on Natural Language Processing for Programming (NLP4Prog 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--nlp4prog-1--10><div class="card-body p-3 small">The task of semantic code search is to retrieve <a href=https://en.wikipedia.org/wiki/Snippet_(programming)>code snippets</a> from a <a href=https://en.wikipedia.org/wiki/Text_corpus>source code corpus</a> based on an information need expressed in <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. The semantic gap between natural language and programming languages has for long been regarded as one of the most significant obstacles to the effectiveness of keyword-based information retrieval (IR) methods. It is a common assumption that traditional bag-of-words IR methods are poorly suited for semantic code search : our work empirically investigates this assumption. Specifically, we examine the effectiveness of two traditional IR methods, namely <a href=https://en.wikipedia.org/wiki/BM25>BM25</a> and <a href=https://en.wikipedia.org/wiki/RM3>RM3</a>, on the CodeSearchNet Corpus, which consists of natural language queries paired with relevant code snippets. We find that the two keyword-based methods outperform several pre-BERT neural models. We also compare several code-specific data pre-processing strategies and find that specialized tokenization improves effectiveness.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.clpsych-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.clpsych-1.0/>Proceedings of the Seventh Workshop on Computational Linguistics and Clinical Psychology: Improving Access</a></strong><br><a href=/people/n/nazli-goharian/>Nazli Goharian</a>
|
<a href=/people/p/philip-resnik/>Philip Resnik</a>
|
<a href=/people/a/andrew-yates/>Andrew Yates</a>
|
<a href=/people/m/molly-ireland/>Molly Ireland</a>
|
<a href=/people/k/kate-niederhoffer/>Kate Niederhoffer</a>
|
<a href=/people/r/rebecca-resnik/>Rebecca Resnik</a><br><a href=/volumes/2021.clpsych-1/ class=text-muted>Proceedings of the Seventh Workshop on Computational Linguistics and Clinical Psychology: Improving Access</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.434.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--434 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.434 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.434.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939312 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.434/>CHARM : Inferring Personal Attributes from Conversations<span class=acl-fixed-case>CHARM</span>: Inferring Personal Attributes from Conversations</a></strong><br><a href=/people/a/anna-tigunova/>Anna Tigunova</a>
|
<a href=/people/a/andrew-yates/>Andrew Yates</a>
|
<a href=/people/p/paramita-mirza/>Paramita Mirza</a>
|
<a href=/people/g/gerhard-weikum/>Gerhard Weikum</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--434><div class="card-body p-3 small">Personal knowledge about users&#8217; professions, hobbies, favorite food, and travel preferences, among others, is a valuable asset for individualized AI, such as <a href=https://en.wikipedia.org/wiki/Recommender_system>recommenders</a> or <a href=https://en.wikipedia.org/wiki/Chatbot>chatbots</a>. Conversations in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, such as <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a>, are a rich source of data for inferring personal facts. Prior work developed supervised methods to extract this knowledge, but these approaches can not generalize beyond attribute values with ample labeled training samples. This paper overcomes this limitation by devising CHARM : a zero-shot learning method that creatively leverages keyword extraction and document retrieval in order to predict attribute values that were never seen during training. Experiments with large datasets from <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a> show the viability of CHARM for open-ended attributes, such as <a href=https://en.wikipedia.org/wiki/Profession>professions</a> and <a href=https://en.wikipedia.org/wiki/Hobby>hobbies</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sustainlp-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sustainlp-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sustainlp-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939436 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.sustainlp-1.14/>A Little Bit Is Worse Than None : Ranking with Limited Training Data</a></strong><br><a href=/people/x/xinyu-zhang/>Xinyu Zhang</a>
|
<a href=/people/a/andrew-yates/>Andrew Yates</a>
|
<a href=/people/j/jimmy-lin/>Jimmy Lin</a><br><a href=/volumes/2020.sustainlp-1/ class=text-muted>Proceedings of SustaiNLP: Workshop on Simple and Efficient Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sustainlp-1--14><div class="card-body p-3 small">Researchers have proposed simple yet effective techniques for the retrieval problem based on using BERT as a relevance classifier to rerank initial candidates from <a href=https://en.wikipedia.org/wiki/Keyword_search>keyword search</a>. In this work, we tackle the challenge of fine-tuning these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> for specific domains in a data and computationally efficient manner. Typically, researchers fine-tune <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> using corpus-specific labeled data from sources such as TREC. We first answer the question : How much data of this type do we need? Recognizing that the most computationally efficient training is no training, we explore zero-shot ranking using BERT models that have already been fine-tuned with the large MS MARCO passage retrieval dataset. We arrive at the surprising and novel finding that some labeled in-domain data can be worse than none at all.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1675.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1675 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1675 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1675/>STANCY : Stance Classification Based on Consistency Cues<span class=acl-fixed-case>STANCY</span>: Stance Classification Based on Consistency Cues</a></strong><br><a href=/people/k/kashyap-popat/>Kashyap Popat</a>
|
<a href=/people/s/subhabrata-mukherjee/>Subhabrata Mukherjee</a>
|
<a href=/people/a/andrew-yates/>Andrew Yates</a>
|
<a href=/people/g/gerhard-weikum/>Gerhard Weikum</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1675><div class="card-body p-3 small">Controversial claims are abundant in <a href=https://en.wikipedia.org/wiki/Mass_media>online media</a> and <a href=https://en.wikipedia.org/wiki/Internet_forum>discussion forums</a>. A better understanding of such claims requires analyzing them from different perspectives. Stance classification is a necessary step for inferring these <a href=https://en.wikipedia.org/wiki/Point_of_view_(philosophy)>perspectives</a> in terms of supporting or opposing the claim. In this work, we present a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network model</a> for stance classification leveraging BERT representations and augmenting them with a novel consistency constraint. Experiments on the Perspectrum dataset, consisting of claims and users&#8217; perspectives from various debate websites, demonstrate the effectiveness of our approach over state-of-the-art baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-0421.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-0421 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-0421 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-0421" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-0421/>Using Multi-Sense Vector Embeddings for Reverse Dictionaries</a></strong><br><a href=/people/m/michael-a-hedderich/>Michael A. Hedderich</a>
|
<a href=/people/a/andrew-yates/>Andrew Yates</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a>
|
<a href=/people/g/gerard-de-melo/>Gerard de Melo</a><br><a href=/volumes/W19-04/ class=text-muted>Proceedings of the 13th International Conference on Computational Semantics - Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-0421><div class="card-body p-3 small">Popular word embedding methods such as <a href=https://en.wikipedia.org/wiki/Word2vec>word2vec</a> and GloVe assign a single vector representation to each word, even if a word has multiple distinct meanings. Multi-sense embeddings instead provide different vectors for each sense of a word. However, they typically can not serve as a drop-in replacement for conventional single-sense embeddings, because the correct sense vector needs to be selected for each word. In this work, we study the effect of multi-sense embeddings on the task of <a href=https://en.wikipedia.org/wiki/Reverse_dictionary>reverse dictionaries</a>. We propose a <a href=https://en.wikipedia.org/wiki/Scientific_technique>technique</a> to easily integrate them into an existing <a href=https://en.wikipedia.org/wiki/Neural_network>neural network architecture</a> using an <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanism</a>. Our experiments demonstrate that large improvements can be obtained when employing multi-sense embeddings both in the input sequence as well as for the target representation. An analysis of the sense distributions and of the learned attention is provided as well.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1126.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1126 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1126 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-1126/>SMHD : a Large-Scale Resource for Exploring Online Language Usage for Multiple Mental Health Conditions<span class=acl-fixed-case>SMHD</span>: a Large-Scale Resource for Exploring Online Language Usage for Multiple Mental Health Conditions</a></strong><br><a href=/people/a/arman-cohan/>Arman Cohan</a>
|
<a href=/people/b/bart-desmet/>Bart Desmet</a>
|
<a href=/people/a/andrew-yates/>Andrew Yates</a>
|
<a href=/people/l/luca-soldaini/>Luca Soldaini</a>
|
<a href=/people/s/sean-macavaney/>Sean MacAvaney</a>
|
<a href=/people/n/nazli-goharian/>Nazli Goharian</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1126><div class="card-body p-3 small">Mental health is a significant and growing public health concern. As language usage can be leveraged to obtain crucial insights into mental health conditions, there is a need for large-scale, labeled, mental health-related datasets of users who have been diagnosed with one or more of such conditions. In this paper, we investigate the creation of high-precision patterns to identify self-reported diagnoses of nine different <a href=https://en.wikipedia.org/wiki/Mental_disorder>mental health conditions</a>, and obtain high-quality labeled data without the need for manual labelling. We introduce the SMHD (Self-reported Mental Health Diagnoses) dataset and make it available. SMHD is a novel large dataset of social media posts from users with one or multiple <a href=https://en.wikipedia.org/wiki/Mental_disorder>mental health conditions</a> along with matched control users. We examine distinctions in users&#8217; language, as measured by linguistic and psychological variables. We further explore text classification methods to identify individuals with <a href=https://en.wikipedia.org/wiki/Mental_disorder>mental conditions</a> through their language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1003 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/305203523 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1003" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1003/>DeClarE : Debunking Fake News and False Claims using Evidence-Aware Deep Learning<span class=acl-fixed-case>D</span>e<span class=acl-fixed-case>C</span>lar<span class=acl-fixed-case>E</span>: Debunking Fake News and False Claims using Evidence-Aware Deep Learning</a></strong><br><a href=/people/k/kashyap-popat/>Kashyap Popat</a>
|
<a href=/people/s/subhabrata-mukherjee/>Subhabrata Mukherjee</a>
|
<a href=/people/a/andrew-yates/>Andrew Yates</a>
|
<a href=/people/g/gerhard-weikum/>Gerhard Weikum</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1003><div class="card-body p-3 small">Misinformation such as <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a> is one of the big challenges of our society. Research on automated fact-checking has proposed methods based on <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised learning</a>, but these approaches do not consider external evidence apart from labeled training instances. Recent approaches counter this deficit by considering <a href=https://en.wikipedia.org/wiki/Source_text>external sources</a> related to a claim. However, these <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> require substantial <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature modeling</a> and rich lexicons. This paper overcomes these limitations of prior work with an end-to-end model for evidence-aware credibility assessment of arbitrary textual claims, without any human intervention. It presents a neural network model that judiciously aggregates signals from external evidence articles, the language of these articles and the trustworthiness of their sources. It also derives informative features for generating user-comprehensible explanations that makes the neural network predictions transparent to the end-user. Experiments with four datasets and ablation studies show the strength of our <a href=https://en.wikipedia.org/wiki/Methodology>method</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-0618.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-0618 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-0618 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-0618/>RSDD-Time : Temporal Annotation of Self-Reported Mental Health Diagnoses<span class=acl-fixed-case>RSDD</span>-Time: Temporal Annotation of Self-Reported Mental Health Diagnoses</a></strong><br><a href=/people/s/sean-macavaney/>Sean MacAvaney</a>
|
<a href=/people/b/bart-desmet/>Bart Desmet</a>
|
<a href=/people/a/arman-cohan/>Arman Cohan</a>
|
<a href=/people/l/luca-soldaini/>Luca Soldaini</a>
|
<a href=/people/a/andrew-yates/>Andrew Yates</a>
|
<a href=/people/a/ayah-zirikly/>Ayah Zirikly</a>
|
<a href=/people/n/nazli-goharian/>Nazli Goharian</a><br><a href=/volumes/W18-06/ class=text-muted>Proceedings of the Fifth Workshop on Computational Linguistics and Clinical Psychology: From Keyboard to Clinic</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-0618><div class="card-body p-3 small">Self-reported diagnosis statements have been widely employed in studying language related to mental health in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. However, existing research has largely ignored the temporality of mental health diagnoses. In this work, we introduce RSDD-Time : a new dataset of 598 manually annotated self-reported depression diagnosis posts from <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a> that include temporal information about the diagnosis. Annotations include whether a <a href=https://en.wikipedia.org/wiki/Mental_disorder>mental health condition</a> is present and how recently the diagnosis happened. Furthermore, we include exact temporal spans that relate to the date of diagnosis. This information is valuable for various computational methods to examine <a href=https://en.wikipedia.org/wiki/Mental_health>mental health</a> through <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> because one&#8217;s mental health state is not static. We also test several baseline classification and extraction approaches, which suggest that extracting temporal information from self-reported diagnosis statements is challenging.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1110.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1110 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1110 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238235171 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D17-1110" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1110/>PACRR : A Position-Aware Neural IR Model for Relevance Matching<span class=acl-fixed-case>PACRR</span>: A Position-Aware Neural <span class=acl-fixed-case>IR</span> Model for Relevance Matching</a></strong><br><a href=/people/k/kai-hui/>Kai Hui</a>
|
<a href=/people/a/andrew-yates/>Andrew Yates</a>
|
<a href=/people/k/klaus-berberich/>Klaus Berberich</a>
|
<a href=/people/g/gerard-de-melo/>Gerard de Melo</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1110><div class="card-body p-3 small">In order to adopt <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> for <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a>, <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are needed that can capture all relevant information required to assess the relevance of a document to a given user query. While previous works have successfully captured unigram term matches, how to fully employ position-dependent information such as proximity and term dependencies has been insufficiently explored. In this work, we propose a novel neural IR model named PACRR aiming at better modeling position-dependent interactions between a query and a document. Extensive experiments on six years&#8217; TREC Web Track data confirm that the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> yields better results under multiple benchmarks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1322.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1322 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1322 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1322/>Depression and Self-Harm Risk Assessment in Online Forums</a></strong><br><a href=/people/a/andrew-yates/>Andrew Yates</a>
|
<a href=/people/a/arman-cohan/>Arman Cohan</a>
|
<a href=/people/n/nazli-goharian/>Nazli Goharian</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1322><div class="card-body p-3 small">Users suffering from <a href=https://en.wikipedia.org/wiki/Mental_disorder>mental health conditions</a> often turn to online resources for support, including specialized online support communities or general communities such as <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> and <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a>. In this work, we present a <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> for supporting and studying users in both types of <a href=https://en.wikipedia.org/wiki/Community>communities</a>. We propose <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> for identifying posts in <a href=https://en.wikipedia.org/wiki/Peer_support>support communities</a> that may indicate a risk of <a href=https://en.wikipedia.org/wiki/Self-harm>self-harm</a>, and demonstrate that our approach outperforms strong previously proposed <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> for identifying such posts. Self-harm is closely related to <a href=https://en.wikipedia.org/wiki/Depression_(mood)>depression</a>, which makes identifying depressed users on <a href=https://en.wikipedia.org/wiki/Internet_forum>general forums</a> a crucial related task. We introduce a large-scale general forum dataset consisting of users with self-reported depression diagnoses matched with control users. We show how our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> can be applied to effectively identify <a href=https://en.wikipedia.org/wiki/Depression_(mood)>depressed users</a> from their use of language alone. We demonstrate that our method outperforms strong <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baselines</a> on this general forum dataset.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Andrew+Yates" title="Search for 'Andrew Yates' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/n/nazli-goharian/ class=align-middle>Nazli Goharian</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/a/arman-cohan/ class=align-middle>Arman Cohan</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/g/gerhard-weikum/ class=align-middle>Gerhard Weikum</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/b/bart-desmet/ class=align-middle>Bart Desmet</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/luca-soldaini/ class=align-middle>Luca Soldaini</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/s/sean-macavaney/ class=align-middle>Sean MacAvaney</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/x/xinyu-zhang/ class=align-middle>Xinyu Zhang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jimmy-lin/ class=align-middle>Jimmy Lin</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/kashyap-popat/ class=align-middle>Kashyap Popat</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/subhabrata-mukherjee/ class=align-middle>Subhabrata Mukherjee</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/g/gerard-de-melo/ class=align-middle>Gerard de Melo</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/anna-tigunova/ class=align-middle>Anna Tigunova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paramita-mirza/ class=align-middle>Paramita Mirza</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/ji-xin/ class=align-middle>Ji Xin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kai-hui/ class=align-middle>Kai Hui</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/klaus-berberich/ class=align-middle>Klaus Berberich</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ayah-zirikly/ class=align-middle>Ayah Zirikly</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-a-hedderich/ class=align-middle>Michael A. Hedderich</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dietrich-klakow/ class=align-middle>Dietrich Klakow</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/philip-resnik/ class=align-middle>Philip Resnik</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/molly-ireland/ class=align-middle>Molly Ireland</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kate-niederhoffer/ class=align-middle>Kate Niederhoffer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rebecca-resnik/ class=align-middle>Rebecca Resnik</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/nlp4prog/ class=align-middle>NLP4Prog</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/clpsych/ class=align-middle>CLPsych</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/sustainlp/ class=align-middle>sustainlp</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>