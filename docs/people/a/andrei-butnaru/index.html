<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Andrei Butnaru - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Andrei</span> <span class=font-weight-bold>Butnaru</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Andrei M. <span class=font-weight-normal>Butnaru</span></p><hr><div class=row><div class=col-lg-9><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-1413.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-1413 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-1413 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-1413/>BAM : A combination of deep and shallow models for German Dialect Identification.<span class=acl-fixed-case>BAM</span>: A combination of deep and shallow models for <span class=acl-fixed-case>G</span>erman Dialect Identification.</a></strong><br><a href=/people/a/andrei-butnaru/>Andrei M. Butnaru</a><br><a href=/volumes/W19-14/ class=text-muted>Proceedings of the Sixth Workshop on NLP for Similar Languages, Varieties and Dialects</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-1413><div class="card-body p-3 small">* This is a submission for the Third VarDial Evaluation Campaign * In this paper, we present a machine learning approach for the German Dialect Identification (GDI) Closed Shared Task of the DSL 2019 Challenge. The proposed approach combines deep and shallow models, by applying a voting scheme on the outputs resulted from a Character-level Convolutional Neural Networks (Char-CNN), a Long Short-Term Memory (LSTM) network, and a model based on String Kernels. The first <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> used is the Char-CNN model that merges multiple convolutions computed with <a href=https://en.wikipedia.org/wiki/Kernel_(statistics)>kernels</a> of different sizes. The second model is the LSTM network which applies a global max pooling over the returned sequences over time. Both <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> pass the activation maps to two <a href=https://en.wikipedia.org/wiki/Connected_space>fully-connected layers</a>. The final model is based on <a href=https://en.wikipedia.org/wiki/String_kernel>String Kernels</a>, computed on character p-grams extracted from <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech transcripts</a>. The model combines two blended kernel functions, one is the presence bits kernel, and the other is the intersection kernel. The empirical results obtained in the shared task prove that the <a href=https://en.wikipedia.org/wiki/Methodology>approach</a> can achieve good results. The <a href=https://en.wikipedia.org/wiki/System>system</a> proposed in this paper obtained the fourth place with a macro-F1 score of 62.55 %</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1068.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1068 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1068 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1068" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1068/>MOROCO : The Moldavian and Romanian Dialectal Corpus<span class=acl-fixed-case>MOROCO</span>: The <span class=acl-fixed-case>M</span>oldavian and <span class=acl-fixed-case>R</span>omanian Dialectal Corpus</a></strong><br><a href=/people/a/andrei-butnaru/>Andrei Butnaru</a>
|
<a href=/people/r/radu-tudor-ionescu/>Radu Tudor Ionescu</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1068><div class="card-body p-3 small">In this work, we introduce the MOldavian and ROmanian Dialectal COrpus (MOROCO), which is freely available for download at https://github.com/butnaruandrei/MOROCO. The <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> contains 33564 samples of text (with over 10 million tokens) collected from the <a href=https://en.wikipedia.org/wiki/News_media>news domain</a>. The samples belong to one of the following six topics : <a href=https://en.wikipedia.org/wiki/Culture>culture</a>, <a href=https://en.wikipedia.org/wiki/Finance>finance</a>, <a href=https://en.wikipedia.org/wiki/Politics>politics</a>, <a href=https://en.wikipedia.org/wiki/Science>science</a>, sports and tech. The <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> is divided into 21719 samples for training, 5921 samples for validation and another 5924 samples for testing. For each sample, we provide corresponding dialectal and category labels. This allows us to perform empirical studies on several classification tasks such as (i) binary discrimination of Moldavian versus Romanian text samples, (ii) intra-dialect multi-class categorization by topic and (iii) cross-dialect multi-class categorization by topic. We perform experiments using a shallow approach based on <a href=https://en.wikipedia.org/wiki/String_kernel>string kernels</a>, as well as a novel deep approach based on character-level convolutional neural networks containing Squeeze-and-Excitation blocks. We also present and analyze the most discriminative features of our best performing <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, before and after named entity removal.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1135.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1135 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1135 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1135/>Improving the results of string kernels in <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> and Arabic dialect identification by adapting them to your test set<span class=acl-fixed-case>A</span>rabic dialect identification by adapting them to your test set</a></strong><br><a href=/people/r/radu-tudor-ionescu/>Radu Tudor Ionescu</a>
|
<a href=/people/a/andrei-butnaru/>Andrei M. Butnaru</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1135><div class="card-body p-3 small">Recently, <a href=https://en.wikipedia.org/wiki/String_kernel>string kernels</a> have obtained state-of-the-art results in various text classification tasks such as Arabic dialect identification or native language identification. In this paper, we apply two simple yet effective transductive learning approaches to further improve the results of <a href=https://en.wikipedia.org/wiki/String_kernel>string kernels</a>. The first approach is based on interpreting the pairwise string kernel similarities between samples in the training set and samples in the test set as <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>. Our second approach is a simple self-training method based on two learning iterations. In the first <a href=https://en.wikipedia.org/wiki/Iteration>iteration</a>, a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> is trained on the training set and tested on the test set, as usual. In the second iteration, a number of test samples (to which the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> associated higher confidence scores) are added to the training set for another round of training. However, the ground-truth labels of the added test samples are not necessary. Instead, we use the labels predicted by the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> in the first training iteration. By adapting <a href=https://en.wikipedia.org/wiki/String_kernel>string kernels</a> to the <a href=https://en.wikipedia.org/wiki/Test_set>test set</a>, we report significantly better accuracy rates in English polarity classification and Arabic dialect identification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-2080.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-2080 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-2080 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-2080.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-2080/>Automated essay scoring with string kernels and word embeddings</a></strong><br><a href=/people/m/madalina-cozma/>Mădălina Cozma</a>
|
<a href=/people/a/andrei-butnaru/>Andrei Butnaru</a>
|
<a href=/people/r/radu-tudor-ionescu/>Radu Tudor Ionescu</a><br><a href=/volumes/P18-2/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-2080><div class="card-body p-3 small">In this work, we present an approach based on combining <a href=https://en.wikipedia.org/wiki/String_kernel>string kernels</a> and <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> for automatic essay scoring. String kernels capture the similarity among strings based on counting common character n-grams, which are a low-level yet powerful type of feature, demonstrating state-of-the-art results in various text classification tasks such as Arabic dialect identification or native language identification. To our best knowledge, we are the first to apply <a href=https://en.wikipedia.org/wiki/String_(computer_science)>string kernels</a> to automatically score essays. We are also the first to combine them with a high-level semantic feature representation, namely the bag-of-super-word-embeddings. We report the best performance on the Automated Student Assessment Prize data set, in both in-domain and cross-domain settings, surpassing recent state-of-the-art deep learning approaches.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-1086.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-1086 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-1086 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-1086/>ShotgunWSD : An unsupervised algorithm for global word sense disambiguation inspired by <a href=https://en.wikipedia.org/wiki/DNA_sequencing>DNA sequencing</a><span class=acl-fixed-case>S</span>hotgun<span class=acl-fixed-case>WSD</span>: An unsupervised algorithm for global word sense disambiguation inspired by <span class=acl-fixed-case>DNA</span> sequencing</a></strong><br><a href=/people/a/andrei-butnaru/>Andrei Butnaru</a>
|
<a href=/people/r/radu-tudor-ionescu/>Radu Tudor Ionescu</a>
|
<a href=/people/f/florentina-hristea/>Florentina Hristea</a><br><a href=/volumes/E17-1/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-1086><div class="card-body p-3 small">In this paper, we present a novel <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised algorithm</a> for word sense disambiguation (WSD) at the document level. Our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> is inspired by a widely-used approach in the field of <a href=https://en.wikipedia.org/wiki/Genetics>genetics</a> for <a href=https://en.wikipedia.org/wiki/Whole_genome_sequencing>whole genome sequencing</a>, known as the Shotgun sequencing technique. The proposed WSD algorithm is based on three main steps. First, a brute-force WSD algorithm is applied to short context windows (up to 10 words) selected from the document in order to generate a short list of likely sense configurations for each window. In the second step, these local sense configurations are assembled into longer composite configurations based on suffix and prefix matching. The resulted configurations are ranked by their length, and the sense of each word is chosen based on a <a href=https://en.wikipedia.org/wiki/Electoral_system>voting scheme</a> that considers only the top k configurations in which the word appears. We compare our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> with other state-of-the-art unsupervised WSD algorithms and demonstrate better performance, sometimes by a very large margin. We also show that our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> can yield better performance than the Most Common Sense (MCS) baseline on one data set. Moreover, our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> has a very small number of parameters, is robust to parameter tuning, and, unlike other bio-inspired methods, it gives a deterministic solution (it does not involve random choices).</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Andrei+Butnaru" title="Search for 'Andrei Butnaru' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/r/radu-tudor-ionescu/ class=align-middle>Radu Tudor Ionescu</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/f/florentina-hristea/ class=align-middle>Florentina Hristea</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/madalina-cozma/ class=align-middle>Mădălina Cozma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>