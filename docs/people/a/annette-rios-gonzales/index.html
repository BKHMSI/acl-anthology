<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Annette Rios Gonzales - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Annette</span> <span class=font-weight-bold>Rios Gonzales</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Annette <span class=font-weight-normal>Rios</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.americasnlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.americasnlp-1.0/>Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas</a></strong><br><a href=/people/m/manuel-mager/>Manuel Mager</a>
|
<a href=/people/a/arturo-oncevay/>Arturo Oncevay</a>
|
<a href=/people/a/annette-rios-gonzales/>Annette Rios</a>
|
<a href=/people/i/ivan-vladimir-meza-ruiz/>Ivan Vladimir Meza Ruiz</a>
|
<a href=/people/a/alexis-palmer/>Alexis Palmer</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/k/katharina-kann/>Katharina Kann</a><br><a href=/volumes/2021.americasnlp-1/ class=text-muted>Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.americasnlp-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--americasnlp-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.americasnlp-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.americasnlp-1.23/>Findings of the AmericasNLP 2021 Shared Task on Open Machine Translation for Indigenous Languages of the Americas<span class=acl-fixed-case>A</span>mericas<span class=acl-fixed-case>NLP</span> 2021 Shared Task on Open Machine Translation for Indigenous Languages of the <span class=acl-fixed-case>A</span>mericas</a></strong><br><a href=/people/m/manuel-mager/>Manuel Mager</a>
|
<a href=/people/a/arturo-oncevay/>Arturo Oncevay</a>
|
<a href=/people/a/abteen-ebrahimi/>Abteen Ebrahimi</a>
|
<a href=/people/j/john-ortega/>John Ortega</a>
|
<a href=/people/a/annette-rios-gonzales/>Annette Rios</a>
|
<a href=/people/a/angela-fan/>Angela Fan</a>
|
<a href=/people/x/ximena-gutierrez-vasques/>Ximena Gutierrez-Vasques</a>
|
<a href=/people/l/luis-chiruzzo/>Luis Chiruzzo</a>
|
<a href=/people/g/gustavo-gimenez-lugo/>Gustavo Giménez-Lugo</a>
|
<a href=/people/r/ricardo-ramos/>Ricardo Ramos</a>
|
<a href=/people/i/ivan-meza-ruiz/>Ivan Vladimir Meza Ruiz</a>
|
<a href=/people/r/rolando-coto-solano/>Rolando Coto-Solano</a>
|
<a href=/people/a/alexis-palmer/>Alexis Palmer</a>
|
<a href=/people/e/elisabeth-mager-hois/>Elisabeth Mager-Hois</a>
|
<a href=/people/v/vishrav-chaudhary/>Vishrav Chaudhary</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a>
|
<a href=/people/k/katharina-kann/>Katharina Kann</a><br><a href=/volumes/2021.americasnlp-1/ class=text-muted>Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--americasnlp-1--23><div class="card-body p-3 small">This paper presents the results of the 2021 Shared Task on Open Machine Translation for <a href=https://en.wikipedia.org/wiki/Indigenous_languages_of_the_Americas>Indigenous Languages of the Americas</a>. The shared task featured two independent tracks, and participants submitted <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation systems</a> for up to 10 <a href=https://en.wikipedia.org/wiki/Indigenous_language>indigenous languages</a>. Overall, 8 teams participated with a total of 214 submissions. We provided <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training sets</a> consisting of data collected from various sources, as well as manually translated sentences for the <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>development and test sets</a>. An official <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baseline</a> trained on this <a href=https://en.wikipedia.org/wiki/Data>data</a> was also provided. Team submissions featured a variety of <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a>, including both statistical and neural models, and for the majority of languages, many teams were able to considerably improve over the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a>. The best performing <a href=https://en.wikipedia.org/wiki/System>systems</a> achieved 12.97 ChrF higher than <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a>, when averaged across languages.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1458.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1458 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1458 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/306131741 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1458" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1458/>Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures</a></strong><br><a href=/people/g/gongbo-tang/>Gongbo Tang</a>
|
<a href=/people/m/mathias-muller/>Mathias Müller</a>
|
<a href=/people/a/annette-rios-gonzales/>Annette Rios</a>
|
<a href=/people/r/rico-sennrich/>Rico Sennrich</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1458><div class="card-body p-3 small">Recently, non-recurrent architectures (convolutional, self-attentional) have outperformed RNNs in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>. CNNs and self-attentional networks can connect distant words via shorter network paths than RNNs, and it has been speculated that this improves their ability to model long-range dependencies. However, this theoretical argument has not been tested empirically, nor have alternative explanations for their strong performance been explored in-depth. We hypothesize that the strong performance of CNNs and self-attentional networks could also be due to their ability to extract semantic features from the source text, and we evaluate RNNs, CNNs and self-attention networks on two tasks : subject-verb agreement (where capturing long-range dependencies is required) and word sense disambiguation (where semantic feature extraction is required). Our experimental results show that : 1) self-attentional networks and CNNs do not outperform RNNs in modeling subject-verb agreement over long distances ; 2) self-attentional networks perform distinctly better than RNNs and CNNs on <a href=https://en.wikipedia.org/wiki/Word-sense_disambiguation>word sense disambiguation</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6307.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6307 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6307 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-6307" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-6307/>A Large-Scale Test Set for the Evaluation of Context-Aware Pronoun Translation in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a></a></strong><br><a href=/people/m/mathias-muller/>Mathias Müller</a>
|
<a href=/people/a/annette-rios-gonzales/>Annette Rios</a>
|
<a href=/people/e/elena-voita/>Elena Voita</a>
|
<a href=/people/r/rico-sennrich/>Rico Sennrich</a><br><a href=/volumes/W18-63/ class=text-muted>Proceedings of the Third Conference on Machine Translation: Research Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6307><div class="card-body p-3 small">The translation of pronouns presents a special challenge to <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> to this day, since <a href=https://en.wikipedia.org/wiki/It_(2017_film)>it</a> often requires context outside the current sentence. Recent work on <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that have access to information across sentence boundaries has seen only moderate improvements in terms of automatic evaluation metrics such as <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>. However, <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> that quantify the overall translation quality are ill-equipped to measure gains from additional context. We argue that a different kind of <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a> is needed to assess how well <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> translate inter-sentential phenomena such as <a href=https://en.wikipedia.org/wiki/Pronoun>pronouns</a>. This paper therefore presents a test suite of contrastive translations focused specifically on the translation of pronouns. Furthermore, we perform experiments with several context-aware models. We show that, while gains in BLEU are moderate for those systems, they outperform baselines by a large margin in terms of <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on our contrastive test set. Our experiments also show the effectiveness of parameter tying for multi-encoder architectures.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6437.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6437 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6437 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6437/>The Word Sense Disambiguation Test Suite at WMT18<span class=acl-fixed-case>WMT</span>18</a></strong><br><a href=/people/a/annette-rios-gonzales/>Annette Rios</a>
|
<a href=/people/m/mathias-muller/>Mathias Müller</a>
|
<a href=/people/r/rico-sennrich/>Rico Sennrich</a><br><a href=/volumes/W18-64/ class=text-muted>Proceedings of the Third Conference on Machine Translation: Shared Task Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6437><div class="card-body p-3 small">We present a task to measure an MT system&#8217;s capability to translate ambiguous words with their correct sense according to the given context. The task is based on the GermanEnglish Word Sense Disambiguation (WSD) test set ContraWSD (Rios Gonzales et al., 2017), but it has been filtered to reduce noise, and the evaluation has been adapted to assess MT output directly rather than scoring existing translations. We evaluate all GermanEnglish submissions to the WMT&#8217;18 shared translation task, plus a number of submissions from previous years, and find that performance on the task has markedly improved compared to the 2016 WMT submissions (81%93 % accuracy on the WSD task). We also find that the unsupervised submissions to the task have a low WSD capability, and predominantly translate ambiguous source words with the same sense.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-2100.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-2100 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-2100 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=E17-2100" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/E17-2100/>Machine Translation of Spanish Personal and Possessive Pronouns Using Anaphora Probabilities<span class=acl-fixed-case>S</span>panish Personal and Possessive Pronouns Using Anaphora Probabilities</a></strong><br><a href=/people/n/ngoc-quang-luong/>Ngoc Quang Luong</a>
|
<a href=/people/a/andrei-popescu-belis/>Andrei Popescu-Belis</a>
|
<a href=/people/a/annette-rios-gonzales/>Annette Rios Gonzales</a>
|
<a href=/people/d/don-tuggener/>Don Tuggener</a><br><a href=/volumes/E17-2/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-2100><div class="card-body p-3 small">We implement a fully probabilistic model to combine the hypotheses of a Spanish anaphora resolution system with those of a Spanish-English machine translation system. The probabilities over antecedents are converted into probabilities for the features of translated pronouns, and are integrated with phrase-based MT using an additional translation model for <a href=https://en.wikipedia.org/wiki/Pronoun>pronouns</a>. The system improves the translation of several Spanish personal and possessive pronouns into <a href=https://en.wikipedia.org/wiki/English_language>English</a>, by solving translation divergencies such as &#8216;ella&#8217; vs. &#8216;she&#8217;/&#8216;it&#8217; or &#8216;su&#8217; vs. &#8216;his&#8217;/&#8216;her&#8217;/&#8216;its&#8217;/&#8216;their&#8217;. On a test set with 2,286 <a href=https://en.wikipedia.org/wiki/Pronoun>pronouns</a>, a baseline system correctly translates 1,055 of them, while ours improves this by 41. Moreover, with oracle antecedents, <a href=https://en.wikipedia.org/wiki/Possessive>possessives</a> are translated with an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 83 %.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Annette+Rios+Gonzales" title="Search for 'Annette Rios Gonzales' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/m/mathias-muller/ class=align-middle>Mathias Müller</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/r/rico-sennrich/ class=align-middle>Rico Sennrich</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/manuel-mager/ class=align-middle>Manuel Mager</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/arturo-oncevay/ class=align-middle>Arturo Oncevay</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/alexis-palmer/ class=align-middle>Alexis Palmer</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/g/graham-neubig/ class=align-middle>Graham Neubig</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/katharina-kann/ class=align-middle>Katharina Kann</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/g/gongbo-tang/ class=align-middle>Gongbo Tang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ivan-vladimir-meza-ruiz/ class=align-middle>Ivan Vladimir Meza Ruiz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/abteen-ebrahimi/ class=align-middle>Abteen Ebrahimi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/john-ortega/ class=align-middle>John Ortega</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/angela-fan/ class=align-middle>Angela Fan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/ximena-gutierrez-vasques/ class=align-middle>Ximena Gutierrez-Vasques</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luis-chiruzzo/ class=align-middle>Luis Chiruzzo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gustavo-gimenez-lugo/ class=align-middle>Gustavo Giménez-Lugo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ricardo-ramos/ class=align-middle>Ricardo Ramos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ivan-meza-ruiz/ class=align-middle>Ivan Meza-Ruiz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rolando-coto-solano/ class=align-middle>Rolando Coto-Solano</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elisabeth-mager-hois/ class=align-middle>Elisabeth Mager-Hois</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vishrav-chaudhary/ class=align-middle>Vishrav Chaudhary</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/ngoc-thang-vu/ class=align-middle>Ngoc Thang Vu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elena-voita/ class=align-middle>Elena Voita</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/ngoc-quang-luong/ class=align-middle>Ngoc Quang Luong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrei-popescu-belis/ class=align-middle>Andrei Popescu-Belis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/don-tuggener/ class=align-middle>Don Tuggener</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/americasnlp/ class=align-middle>AmericasNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>