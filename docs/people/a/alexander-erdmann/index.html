<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Alexander Erdmann - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Alexander</span> <span class=font-weight-bold>Erdmann</span></h2><hr><div class=row><div class=col-lg-9><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.695.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--695 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.695 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928868 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.695" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.695/>The Paradigm Discovery Problem</a></strong><br><a href=/people/a/alexander-erdmann/>Alexander Erdmann</a>
|
<a href=/people/m/micha-elsner/>Micha Elsner</a>
|
<a href=/people/s/shijie-wu/>Shijie Wu</a>
|
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a>
|
<a href=/people/n/nizar-habash/>Nizar Habash</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--695><div class="card-body p-3 small">This work treats the paradigm discovery problem (PDP), the task of learning an inflectional morphological system from unannotated sentences. We formalize the <a href=https://en.wikipedia.org/wiki/Programmable_Data_Processor>PDP</a> and develop evaluation metrics for judging systems. Using currently available resources, we construct datasets for the <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>. We also devise a heuristic benchmark for the <a href=https://en.wikipedia.org/wiki/Programmed_Data_Processor>PDP</a> and report empirical results on five diverse languages. Our benchmark system first makes use of <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> and <a href=https://en.wikipedia.org/wiki/String_similarity>string similarity</a> to cluster forms by cell and by <a href=https://en.wikipedia.org/wiki/Paradigm>paradigm</a>. Then, we bootstrap a neural transducer on top of the clustered data to predict words to realize the empty paradigm slots. An error analysis of our <a href=https://en.wikipedia.org/wiki/System>system</a> suggests clustering by cell across different inflection classes is the most pressing challenge for future work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.733.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--733 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.733 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928759 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.733/>Frugal Paradigm Completion</a></strong><br><a href=/people/a/alexander-erdmann/>Alexander Erdmann</a>
|
<a href=/people/t/tom-kenter/>Tom Kenter</a>
|
<a href=/people/m/markus-becker/>Markus Becker</a>
|
<a href=/people/c/christian-schallhart/>Christian Schallhart</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--733><div class="card-body p-3 small">Lexica distinguishing all morphologically related forms of each <a href=https://en.wikipedia.org/wiki/Lexeme>lexeme</a> are crucial to many language technologies, yet building them is expensive. We propose a frugal paradigm completion approach that predicts all related forms in a morphological paradigm from as few manually provided forms as possible. It induces <a href=https://en.wikipedia.org/wiki/Typology_(linguistics)>typological information</a> during training which <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> uses to determine the best sources at test time. We evaluate our language-agnostic approach on 7 diverse languages. Compared to popular alternative approaches, ours reduces <a href=https://en.wikipedia.org/wiki/Manual_labour>manual labor</a> by 16-63 % and is the most robust to typological variation.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4214.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4214 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4214 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4214/>A Little Linguistics Goes a Long Way : Unsupervised Segmentation with Limited Language Specific Guidance</a></strong><br><a href=/people/a/alexander-erdmann/>Alexander Erdmann</a>
|
<a href=/people/s/salam-khalifa/>Salam Khalifa</a>
|
<a href=/people/m/mai-oudah/>Mai Oudah</a>
|
<a href=/people/n/nizar-habash/>Nizar Habash</a>
|
<a href=/people/h/houda-bouamor/>Houda Bouamor</a><br><a href=/volumes/W19-42/ class=text-muted>Proceedings of the 16th Workshop on Computational Research in Phonetics, Phonology, and Morphology</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4214><div class="card-body p-3 small">We present de-lexical segmentation, a linguistically motivated alternative to greedy or other unsupervised methods, requiring only minimal language specific input. Our technique involves creating a small grammar of closed-class affixes which can be written in a few hours. The <a href=https://en.wikipedia.org/wiki/Grammar>grammar</a> over generates analyses for word forms attested in a raw corpus which are disambiguated based on features of the linguistic base proposed for each form. Extending the <a href=https://en.wikipedia.org/wiki/Grammar>grammar</a> to cover orthographic, morpho-syntactic or lexical variation is simple, making it an ideal solution for challenging corpora with noisy, dialect-inconsistent, or otherwise non-standard content. In two evaluations, we consistently outperform competitive unsupervised baselines and approach the performance of state-of-the-art <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised models</a> trained on large amounts of data, providing evidence for the value of linguistic input during preprocessing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1231.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1231 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1231 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1231" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N19-1231/>Practical, Efficient, and Customizable <a href=https://en.wikipedia.org/wiki/Active_learning>Active Learning</a> for Named Entity Recognition in the <a href=https://en.wikipedia.org/wiki/Digital_humanities>Digital Humanities</a></a></strong><br><a href=/people/a/alexander-erdmann/>Alexander Erdmann</a>
|
<a href=/people/d/david-joseph-wrisley/>David Joseph Wrisley</a>
|
<a href=/people/b/benjamin-allen/>Benjamin Allen</a>
|
<a href=/people/c/christopher-brown/>Christopher Brown</a>
|
<a href=/people/s/sophie-cohen-bodenes/>Sophie Cohen-Bodénès</a>
|
<a href=/people/m/micha-elsner/>Micha Elsner</a>
|
<a href=/people/y/yukun-feng/>Yukun Feng</a>
|
<a href=/people/b/brian-joseph/>Brian Joseph</a>
|
<a href=/people/b/beatrice-joyeux-prunel/>Béatrice Joyeux-Prunel</a>
|
<a href=/people/m/marie-catherine-de-marneffe/>Marie-Catherine de Marneffe</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1231><div class="card-body p-3 small">Scholars in inter-disciplinary fields like the <a href=https://en.wikipedia.org/wiki/Digital_humanities>Digital Humanities</a> are increasingly interested in semantic annotation of specialized corpora. Yet, under-resourced languages, imperfect or noisily structured data, and user-specific classification tasks make it difficult to meet their needs using off-the-shelf models. Manual annotation of large corpora from scratch, meanwhile, can be prohibitively expensive. Thus, we propose an active learning solution for <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>, attempting to maximize a custom model&#8217;s improvement per additional unit of manual annotation. Our system robustly handles any domain or user-defined label set and requires no external resources, enabling quality <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a> for Humanities corpora where such resources are not available. Evaluating on typologically disparate languages and datasets, we reduce required annotation by 20-60 % and greatly outperform a competitive active learning baseline.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1087.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1087 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1087 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1087/>Noise-Robust Morphological Disambiguation for Dialectal Arabic<span class=acl-fixed-case>A</span>rabic</a></strong><br><a href=/people/n/nasser-zalmout/>Nasser Zalmout</a>
|
<a href=/people/a/alexander-erdmann/>Alexander Erdmann</a>
|
<a href=/people/n/nizar-habash/>Nizar Habash</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1087><div class="card-body p-3 small">User-generated text tends to be noisy with many lexical and orthographic inconsistencies, making natural language processing (NLP) tasks more challenging. The challenging nature of noisy text processing is exacerbated for dialectal content, where in addition to spelling and lexical differences, dialectal text is characterized with morpho-syntactic and phonetic variations. These issues increase sparsity in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP models</a> and reduce <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. We present a neural morphological tagging and disambiguation model for <a href=https://en.wikipedia.org/wiki/Egyptian_Arabic>Egyptian Arabic</a>, with various extensions to handle noisy and inconsistent content. Our models achieve about 5 % <a href=https://en.wikipedia.org/wiki/Errors-in-variables_models>relative error reduction</a> (1.1 % absolute improvement) for full morphological analysis, and around 22 % <a href=https://en.wikipedia.org/wiki/Errors-in-variables_models>relative error reduction</a> (1.8 % absolute improvement) for <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a>, over a state-of-the-art baseline.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-2089.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-2089 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-2089 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-2089.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-2089/>Addressing Noise in Multidialectal Word Embeddings</a></strong><br><a href=/people/a/alexander-erdmann/>Alexander Erdmann</a>
|
<a href=/people/n/nasser-zalmout/>Nasser Zalmout</a>
|
<a href=/people/n/nizar-habash/>Nizar Habash</a><br><a href=/volumes/P18-2/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-2089><div class="card-body p-3 small">Word embeddings are crucial to many <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing tasks</a>. The quality of <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> relies on large non-noisy corpora. Arabic dialects lack <a href=https://en.wikipedia.org/wiki/Varieties_of_Arabic>large corpora</a> and are noisy, being linguistically disparate with no <a href=https://en.wikipedia.org/wiki/Standard_language>standardized spelling</a>. We make three contributions to address this noise. First, we describe simple but effective adaptations to word embedding tools to maximize the informative content leveraged in each training sentence. Second, we analyze methods for representing disparate dialects in one embedding space, either by mapping individual dialects into a shared space or learning a joint model of all dialects. Finally, we evaluate via dictionary induction, showing that two metrics not typically reported in the task enable us to analyze our contributions&#8217; effects on low and high frequency words. In addition to boosting performance between 2-53 %, we specifically improve on noisy, low frequency forms without compromising <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on high frequency forms.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Alexander+Erdmann" title="Search for 'Alexander Erdmann' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/n/nizar-habash/ class=align-middle>Nizar Habash</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/m/micha-elsner/ class=align-middle>Micha Elsner</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/n/nasser-zalmout/ class=align-middle>Nasser Zalmout</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/shijie-wu/ class=align-middle>Shijie Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ryan-cotterell/ class=align-middle>Ryan Cotterell</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/t/tom-kenter/ class=align-middle>Tom Kenter</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/markus-becker/ class=align-middle>Markus Becker</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christian-schallhart/ class=align-middle>Christian Schallhart</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/salam-khalifa/ class=align-middle>Salam Khalifa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mai-oudah/ class=align-middle>Mai Oudah</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/houda-bouamor/ class=align-middle>Houda Bouamor</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/david-joseph-wrisley/ class=align-middle>David Joseph Wrisley</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/benjamin-allen/ class=align-middle>Benjamin Allen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christopher-brown/ class=align-middle>Christopher Brown</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sophie-cohen-bodenes/ class=align-middle>Sophie Cohen-Bodénès</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yukun-feng/ class=align-middle>Yukun Feng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/brian-joseph/ class=align-middle>Brian Joseph</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/beatrice-joyeux-prunel/ class=align-middle>Béatrice Joyeux-Prunel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marie-catherine-de-marneffe/ class=align-middle>Marie-Catherine de Marneffe</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>