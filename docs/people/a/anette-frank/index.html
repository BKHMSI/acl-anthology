<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Anette Frank - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Anette</span> <span class=font-weight-bold>Frank</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.395.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--395 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.395 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.395" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.395/>COINS : Dynamically Generating COntextualized Inference Rules for Narrative Story Completion<span class=acl-fixed-case>COINS</span>: Dynamically Generating <span class=acl-fixed-case>CO</span>ntextualized Inference Rules for Narrative Story Completion</a></strong><br><a href=/people/d/debjit-paul/>Debjit Paul</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--395><div class="card-body p-3 small">Despite recent successes of large pre-trained language models in solving reasoning tasks, their inference capabilities remain opaque. We posit that such models can be made more interpretable by explicitly generating interim inference rules, and using them to guide the generation of task-specific textual outputs. In this paper we present Coins, a recursive inference framework that i) iteratively reads context sentences, ii) dynamically generates contextualized inference rules, encodes them, and iii) uses them to guide task-specific output generation. We apply to a Narrative Story Completion task that asks a model to complete a story with missing sentences, to produce a coherent story with plausible logical connections, causal relationships, and temporal dependencies. By modularizing <a href=https://en.wikipedia.org/wiki/Inference>inference</a> and sentence generation steps in a recurrent model, we aim to make reasoning steps and their effects on next sentence generation transparent. Our automatic and manual evaluations show that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> generates better <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>story sentences</a> than SOTA baselines, especially in terms of <a href=https://en.wikipedia.org/wiki/Coherence_(linguistics)>coherence</a>. We further demonstrate improved performance over strong pre-trained LMs in generating commonsense inference rules. The recursive nature of holds the potential for <a href=https://en.wikipedia.org/wiki/Control_theory>controlled generation of longer sequences</a>.<i>Narrative Story Completion</i> task that asks a model to complete a story with missing sentences, to produce a coherent story with plausible logical connections, causal relationships, and temporal dependencies. By modularizing inference and sentence generation steps in a recurrent model, we aim to make reasoning steps and their effects on next sentence generation transparent. Our automatic and manual evaluations show that the model generates better story sentences than SOTA baselines, especially in terms of coherence. We further demonstrate improved performance over strong pre-trained LMs in generating commonsense inference rules. The recursive nature of holds the potential for controlled generation of longer sequences.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.alvr-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--alvr-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.alvr-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.alvr-1.4/>Grounding Plural Phrases : Countering Evaluation Biases by Individuation</a></strong><br><a href=/people/j/julia-suter/>Julia Suter</a>
|
<a href=/people/l/letitia-parcalabescu/>Letitia Parcalabescu</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a><br><a href=/volumes/2021.alvr-1/ class=text-muted>Proceedings of the Second Workshop on Advances in Language and Vision Research</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--alvr-1--4><div class="card-body p-3 small">Phrase grounding (PG) is a <a href=https://en.wikipedia.org/wiki/Multimodal_interaction>multimodal task</a> that grounds language in images. PG systems are evaluated on well-known <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a>, using Intersection over Union (IoU) as evaluation metric. This work highlights a disconcerting bias in the evaluation of grounded plural phrases, which arises from representing sets of objects as a union box covering all component bounding boxes, in conjunction with the IoU metric. We detect, analyze and quantify an evaluation bias in the grounding of plural phrases and define a novel <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a>, c-IoU, based on a union box&#8217;s component boxes. We experimentally show that our new <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> greatly alleviates this bias and recommend using it for fairer evaluation of plural phrases in PG tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-main.129.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-main--129 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-main.129 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.eacl-main.129" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-main.129/>Towards a Decomposable Metric for Explainable Evaluation of Text Generation from AMR<span class=acl-fixed-case>AMR</span></a></strong><br><a href=/people/j/juri-opitz/>Juri Opitz</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a><br><a href=/volumes/2021.eacl-main/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-main--129><div class="card-body p-3 small">Systems that generate natural language text from abstract meaning representations such as AMR are typically evaluated using automatic surface matching metrics that compare the generated texts to reference texts from which the input meaning representations were constructed. We show that besides well-known issues from which such <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> suffer, an additional problem arises when applying these <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> for AMR-to-text evaluation, since an abstract meaning representation allows for numerous surface realizations. In this work we aim to alleviate these issues by proposing _, a decomposable metric that builds on two pillars. The first is the principle of meaning preservation : it measures to what extent a given <a href=https://en.wikipedia.org/wiki/Abstract_syntax_tree>AMR</a> can be reconstructed from the generated sentence using SOTA AMR parsers and applying (fine-grained) AMR evaluation metrics to measure the distance between the original and the reconstructed <a href=https://en.wikipedia.org/wiki/Abstract_syntax_tree>AMR</a>. The second pillar builds on a principle of (grammatical) form that measures the linguistic quality of the generated text, which we implement using SOTA language models. In two extensive pilot studies we show that fulfillment of both principles offers benefits for AMR-to-text evaluation, including explainability of scores. Since _ does not necessarily rely on gold AMRs, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> may extend to other text generation tasks.<tex-math>\\mathcal{M}\\mathcal{F}_\\beta</tex-math>, a decomposable metric that builds on two pillars. The first is the <b>principle of meaning preservation <tex-math>\\mathcal{M}</tex-math>\n </b>: it measures to what extent a given AMR can be reconstructed from the generated sentence using SOTA AMR parsers and applying (fine-grained) AMR evaluation metrics to measure the distance between the original and the reconstructed AMR. The second pillar builds on a <b>principle of (grammatical) form <tex-math>\\mathcal{F}</tex-math>\n</b> that measures the linguistic quality of the generated text, which we implement using SOTA language models. In two extensive pilot studies we show that fulfillment of both principles offers benefits for AMR-to-text evaluation, including explainability of scores. Since <tex-math>\\mathcal{M}\\mathcal{F}_\\beta</tex-math> does not necessarily rely on gold AMRs, it may extend to other text generation tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.argmining-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--argmining-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.argmining-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.argmining-1.3" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.argmining-1.3/>Explainable Unsupervised Argument Similarity Rating with Abstract Meaning Representation and Conclusion Generation<span class=acl-fixed-case>A</span>bstract <span class=acl-fixed-case>M</span>eaning <span class=acl-fixed-case>R</span>epresentation and Conclusion Generation</a></strong><br><a href=/people/j/juri-opitz/>Juri Opitz</a>
|
<a href=/people/p/philipp-heinisch/>Philipp Heinisch</a>
|
<a href=/people/p/philipp-wiesenbach/>Philipp Wiesenbach</a>
|
<a href=/people/p/philipp-cimiano/>Philipp Cimiano</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a><br><a href=/volumes/2021.argmining-1/ class=text-muted>Proceedings of the 8th Workshop on Argument Mining</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--argmining-1--3><div class="card-body p-3 small">When assessing the similarity of arguments, researchers typically use approaches that do not provide interpretable evidence or justifications for their ratings. Hence, the <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> that determine argument similarity remain elusive. We address this issue by introducing novel argument similarity metrics that aim at high performance and explainability. We show that Abstract Meaning Representation (AMR) graphs can be useful for representing arguments, and that novel AMR graph metrics can offer explanations for argument similarity ratings. We start from the hypothesis that similar premises often lead to similar conclusionsand extend an approach for AMR-based argument similarity rating by estimating, in addition, the similarity of conclusions that we automatically infer from the arguments used as premises. We show that AMR similarity metrics make argument similarity judgements more interpretable and may even support argument quality judgements. Our approach provides significant performance improvements over strong <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> in a fully unsupervised setting. Finally, we make first steps to address the problem of reference-less evaluation of argumentative conclusion generations.<i>novel argument similarity metrics</i> that aim at high performance and explainability. We show that Abstract Meaning Representation (AMR) graphs can be useful for representing arguments, and that novel AMR graph metrics can offer explanations for argument similarity ratings. We start from the hypothesis that <i>similar premises</i> often lead to <i>similar conclusions</i>&#8212;and extend an approach for <i>AMR-based argument similarity rating</i> by estimating, in addition, the similarity of <i>conclusions</i> that we automatically infer from the arguments used as premises. We show that AMR similarity metrics make argument similarity judgements more <i>interpretable</i> and may even support <i>argument quality judgements</i>. Our approach provides significant performance improvements over strong baselines in a <i>fully unsupervised</i> setting. Finally, we make first steps to address the problem of reference-less evaluation of argumentative conclusion generations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mmsr-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mmsr-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mmsr-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mmsr-1.1/>What is Multimodality?</a></strong><br><a href=/people/l/letitia-parcalabescu/>Letitia Parcalabescu</a>
|
<a href=/people/n/nils-trost/>Nils Trost</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a><br><a href=/volumes/2021.mmsr-1/ class=text-muted>Proceedings of the 1st Workshop on Multimodal Semantic Representations (MMSR)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mmsr-1--1><div class="card-body p-3 small">The last years have shown rapid developments in the field of multimodal machine learning, combining e.g., <a href=https://en.wikipedia.org/wiki/Computer_vision>vision</a>, <a href=https://en.wikipedia.org/wiki/Written_language>text</a> or <a href=https://en.wikipedia.org/wiki/Speech>speech</a>. In this position paper we explain how the <a href=https://en.wikipedia.org/wiki/Field_(mathematics)>field</a> uses outdated definitions of <a href=https://en.wikipedia.org/wiki/Multimodality>multimodality</a> that prove unfit for the <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning era</a>. We propose a new task-relative definition of (multi)modality in the context of multimodal machine learning that focuses on representations and information that are relevant for a given machine learning task. With our new definition of <a href=https://en.wikipedia.org/wiki/Multimodality>multimodality</a> we aim to provide a missing foundation for multimodal research, an important component of language grounding and a crucial milestone towards <a href=https://en.wikipedia.org/wiki/Natural_language_understanding>NLU</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mmsr-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mmsr-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mmsr-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mmsr-1.4/>Seeing past words : Testing the cross-modal capabilities of pretrained V&L models on counting tasks<span class=acl-fixed-case>V</span>&<span class=acl-fixed-case>L</span> models on counting tasks</a></strong><br><a href=/people/l/letitia-parcalabescu/>Letitia Parcalabescu</a>
|
<a href=/people/a/albert-gatt/>Albert Gatt</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a>
|
<a href=/people/i/iacer-calixto/>Iacer Calixto</a><br><a href=/volumes/2021.mmsr-1/ class=text-muted>Proceedings of the 1st Workshop on Multimodal Semantic Representations (MMSR)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mmsr-1--4><div class="card-body p-3 small">We investigate the reasoning ability of pretrained vision and language (V&L) models in two tasks that require multimodal integration : (1) discriminating a correct image-sentence pair from an incorrect one, and (2) counting entities in an image. We evaluate three pretrained V&L models on these tasks : ViLBERT, ViLBERT 12-in-1 and LXMERT, in zero-shot and finetuned settings. Our results show that <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> solve task (1) very well, as expected, since all <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are pretrained on task (1). However, none of the pretrained V&L models is able to adequately solve task (2), our counting probe, and they can not generalise to out-of-distribution quantities. We propose a number of explanations for these findings : LXMERT (and to some extent ViLBERT 12-in-1) show some evidence of catastrophic forgetting on task (1). Concerning our results on the counting probe, we find evidence that all models are impacted by dataset bias, and also fail to individuate entities in the visual input. While a selling point of pretrained V&L models is their ability to solve complex tasks, our findings suggest that understanding their reasoning and grounding capabilities requires more targeted investigations on specific phenomena.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1056.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1056 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1056 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1056.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1056" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1056/>Translate and Label ! An Encoder-Decoder Approach for Cross-lingual Semantic Role Labeling</a></strong><br><a href=/people/a/angel-daza/>Angel Daza</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1056><div class="card-body p-3 small">We propose a Cross-lingual Encoder-Decoder model that simultaneously translates and generates sentences with Semantic Role Labeling annotations in a resource-poor target language. Unlike annotation projection techniques, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> does not need parallel data during inference time. Our approach can be applied in monolingual, multilingual and cross-lingual settings and is able to produce dependency-based and span-based SRL annotations. We benchmark the labeling performance of our model in different monolingual and multilingual settings using well-known SRL datasets. We then train our <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> in a cross-lingual setting to generate new SRL labeled data. Finally, we measure the effectiveness of our method by using the generated data to augment the training basis for resource-poor languages and perform manual evaluation to show that it produces high-quality sentences and assigns accurate semantic role annotations. Our proposed <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> offers a flexible method for leveraging SRL data in multiple languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1257.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1257 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1257 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1257.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1257" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1257/>Discourse-Aware Semantic Self-Attention for Narrative Reading Comprehension</a></strong><br><a href=/people/t/todor-mihaylov/>Todor Mihaylov</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1257><div class="card-body p-3 small">In this work, we propose to use linguistic annotations as a basis for a Discourse-Aware Semantic Self-Attention encoder that we employ for <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> on narrative texts. We extract relations between discourse units, <a href=https://en.wikipedia.org/wiki/Event_(philosophy)>events</a>, and their arguments as well as coreferring mentions, using available annotation tools. Our empirical evaluation shows that the investigated structures improve the overall performance (up to +3.4 Rouge-L), especially intra-sentential and cross-sentential discourse relations, sentence-internal semantic role relations, and long-distance coreference relations. We show that dedicating self-attention heads to intra-sentential relations and relations connecting neighboring sentences is beneficial for finding answers to questions in longer contexts. Our findings encourage the use of discourse-semantic annotations to enhance the generalization capacity of self-attention models for <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S19-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-S19-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-1024/>Automatic Accuracy Prediction for AMR Parsing<span class=acl-fixed-case>AMR</span> Parsing</a></strong><br><a href=/people/j/juri-opitz/>Juri Opitz</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a><br><a href=/volumes/S19-1/ class=text-muted>Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S19-1024><div class="card-body p-3 small">Abstract Meaning Representation (AMR) represents sentences as directed, acyclic and rooted graphs, aiming at capturing their meaning in a machine readable format. AMR parsing converts natural language sentences into such <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graphs</a>. However, evaluating a <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> on new data by means of comparison to manually created AMR graphs is very costly. Also, we would like to be able to detect <a href=https://en.wikipedia.org/wiki/Parsing>parses</a> of questionable quality, or preferring results of alternative systems by selecting the ones for which we can assess good quality. We propose AMR accuracy prediction as the task of predicting several metrics of correctness for an automatically generated AMR parse in absence of the corresponding gold parse. We develop a neural end-to-end multi-output regression model and perform three case studies : firstly, we evaluate the model&#8217;s capacity of predicting AMR parse accuracies and test whether it can reliably assign high scores to gold parses. Secondly, we perform parse selection based on predicted parse accuracies of candidate parses from alternative systems, with the aim of improving overall results. Finally, we predict system ranks for submissions from two AMR shared tasks on the basis of their predicted parse accuracy averages. All experiments are carried out across two different domains and show that our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> is effective.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-1025.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S19-1025 data-toggle=collapse aria-expanded=false aria-controls=abstract-S19-1025 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-1025/>An Argument-Marker Model for Syntax-Agnostic Proto-Role Labeling</a></strong><br><a href=/people/j/juri-opitz/>Juri Opitz</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a><br><a href=/volumes/S19-1/ class=text-muted>Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S19-1025><div class="card-body p-3 small">Semantic proto-role labeling (SPRL) is an alternative to semantic role labeling (SRL) that moves beyond a categorical definition of roles, following Dowty&#8217;s feature-based view of proto-roles. This <a href=https://en.wikipedia.org/wiki/Theory>theory</a> determines agenthood vs. patienthood based on a participant&#8217;s instantiation of more or less typical agent vs. patient properties, such as, for example, <a href=https://en.wikipedia.org/wiki/Volition_(psychology)>volition</a> in an event. To perform SPRL, we develop an ensemble of hierarchical models with self-attention and concurrently learned predicate-argument markers. Our method is competitive with the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the art</a>, overall outperforming previous work in two formulations of the task (multi-label and multi-variate Likert scale pre- diction). In contrast to previous work, our results do not depend on gold argument heads derived from supplementary gold tree banks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4503.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4503 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4503 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4503/>Dissecting Content and Context in Argumentative Relation Analysis</a></strong><br><a href=/people/j/juri-opitz/>Juri Opitz</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a><br><a href=/volumes/W19-45/ class=text-muted>Proceedings of the 6th Workshop on Argument Mining</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4503><div class="card-body p-3 small">When assessing relations between argumentative units (e.g., support or attack), computational systems often exploit disclosing indicators or markers that are not part of elementary argumentative units (EAUs) themselves, but are gained from their context (position in paragraph, preceding tokens, etc.). We show that this dependency is much stronger than previously assumed. In fact, we show that by completely masking the EAU text spans and only feeding information from their context, a competitive system may function even better. We argue that an argument analysis system that relies more on discourse context than the argument&#8217;s content is unsafe, since it can easily be tricked. To alleviate this issue, we separate argumentative units from their context such that the <a href=https://en.wikipedia.org/wiki/System>system</a> is forced to model and rely on an EAU&#8217;s content. We show that the resulting classification system is more robust, and argue that such <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are better suited for predicting argumentative relations across documents.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3027.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3027 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3027 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3027/>A Sequence-to-Sequence Model for Semantic Role Labeling</a></strong><br><a href=/people/a/angel-daza/>Angel Daza</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a><br><a href=/volumes/W18-30/ class=text-muted>Proceedings of The Third Workshop on Representation Learning for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3027><div class="card-body p-3 small">We explore a novel approach for Semantic Role Labeling (SRL) by casting it as a sequence-to-sequence process. We employ an attention-based model enriched with a copying mechanism to ensure faithful regeneration of the input sequence, while enabling interleaved generation of argument role labels. We apply this <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in a monolingual setting, performing PropBank SRL on English language data. The constrained sequence generation set-up enforced with the copying mechanism allows us to analyze the performance and special properties of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on manually labeled data and benchmarking against state-of-the-art sequence labeling models. We show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is able to solve the SRL argument labeling task on English data, yet further structural decoding constraints will need to be added to make the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> truly competitive. Our work represents the first step towards more advanced, generative SRL labeling setups.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1054.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1054 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1054 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1054.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1054" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1054/>SRL4ORL : Improving Opinion Role Labeling Using Multi-Task Learning with Semantic Role Labeling<span class=acl-fixed-case>SRL</span>4<span class=acl-fixed-case>ORL</span>: Improving Opinion Role Labeling Using Multi-Task Learning with Semantic Role Labeling</a></strong><br><a href=/people/a/ana-marasovic/>Ana Marasović</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1054><div class="card-body p-3 small">For over a decade, <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a> has been used to extract opinion-holder-target structures from text to answer the question Who expressed what kind of sentiment towards what?. Recent neural approaches do not outperform the state-of-the-art feature-based models for Opinion Role Labeling (ORL). We suspect this is due to the scarcity of <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>labeled training data</a> and address this issue using different multi-task learning (MTL) techniques with a related <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> which has substantially more data, i.e. Semantic Role Labeling (SRL). We show that two MTL models improve significantly over the single-task model for labeling of both holders and targets, on the development and the test sets. We found that the vanilla MTL model, which makes predictions using only shared ORL and SRL features, performs the best. With deeper analysis we determine what works and what might be done to make further improvements for ORL.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-0814.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-0814 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-0814 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-0814/>Assessing SRL Frameworks with Automatic Training Data Expansion<span class=acl-fixed-case>SRL</span> Frameworks with Automatic Training Data Expansion</a></strong><br><a href=/people/s/silvana-hartmann/>Silvana Hartmann</a>
|
<a href=/people/e/eva-mujdricza-maydt/>Éva Mújdricza-Maydt</a>
|
<a href=/people/i/ilia-kuznetsov/>Ilia Kuznetsov</a>
|
<a href=/people/i/iryna-gurevych/>Iryna Gurevych</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a><br><a href=/volumes/W17-08/ class=text-muted>Proceedings of the 11th Linguistic Annotation Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-0814><div class="card-body p-3 small">We present the first experiment-based study that explicitly contrasts the three major semantic role labeling frameworks. As a prerequisite, we create a dataset labeled with parallel FrameNet-, PropBank-, and VerbNet-style labels for <a href=https://en.wikipedia.org/wiki/German_language>German</a>. We train a state-of-the-art SRL tool for <a href=https://en.wikipedia.org/wiki/German_language>German</a> for the different annotation styles and provide a comparative analysis across frameworks. We further explore the behavior of the <a href=https://en.wikipedia.org/wiki/Software_framework>frameworks</a> with automatic training data generation. VerbNet provides larger semantic expressivity than <a href=https://en.wikipedia.org/wiki/PropBank>PropBank</a>, and we find that its generalization capacity approaches <a href=https://en.wikipedia.org/wiki/PropBank>PropBank</a> in SRL training, but it benefits less from training data expansion than the sparse-data affected FrameNet.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-0913.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-0913 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-0913 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-0913/>Story Cloze Ending Selection Baselines and Data Examination</a></strong><br><a href=/people/t/todor-mihaylov/>Todor Mihaylov</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a><br><a href=/volumes/W17-09/ class=text-muted>Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-0913><div class="card-body p-3 small">This paper describes two supervised baseline systems for the Story Cloze Test Shared Task (Mostafazadeh et al., 2016a). We first build a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> using <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> based on <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> and <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic similarity computation</a>. We further implement a neural LSTM system with different encoding strategies that try to model the relation between the story and the provided endings. Our experiments show that a model using representation features based on average word embedding vectors over the given story words and the candidate ending sentences words, joint with similarity features between the story and candidate ending representations performed better than the neural models. Our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> based on achieves an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 72.42, ranking 3rd in the official evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4117.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4117 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4117 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4117/>What do we need to know about an unknown word when parsing German<span class=acl-fixed-case>G</span>erman</a></strong><br><a href=/people/b/bich-ngoc-do/>Bich-Ngoc Do</a>
|
<a href=/people/i/ines-rehbein/>Ines Rehbein</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a><br><a href=/volumes/W17-41/ class=text-muted>Proceedings of the First Workshop on Subword and Character Level Models in NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4117><div class="card-body p-3 small">We propose a new type of subword embedding designed to provide more information about unknown compounds, a major source for OOV words in <a href=https://en.wikipedia.org/wiki/German_language>German</a>. We present an extrinsic evaluation where we use the compound embeddings as input to a neural dependency parser and compare the results to the ones obtained with other types of <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a>. Our evaluation shows that adding compound embeddings yields a significant improvement of 2 % LAS over using word embeddings when no POS information is available. When adding POS embeddings to the input, however, the effect levels out. This suggests that it is not the missing information about the <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> of the unknown words that causes problems for parsing <a href=https://en.wikipedia.org/wiki/German_language>German</a>, but the lack of morphological information for unknown words. To augment our evaluation, we also test the new embeddings in a language modelling task that requires both syntactic and semantic information.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-1027.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-1027 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-1027 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-1027/>Classifying Semantic Clause Types : Modeling Context and Genre Characteristics with Recurrent Neural Networks and Attention</a></strong><br><a href=/people/m/maria-becker/>Maria Becker</a>
|
<a href=/people/m/michael-staniek/>Michael Staniek</a>
|
<a href=/people/v/vivi-nastase/>Vivi Nastase</a>
|
<a href=/people/a/alexis-palmer/>Alexis Palmer</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a><br><a href=/volumes/S17-1/ class=text-muted>Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-1027><div class="card-body p-3 small">Detecting aspectual properties of clauses in the form of situation entity types has been shown to depend on a combination of syntactic-semantic and contextual features. We explore this task in a deep-learning framework, where tuned word representations capture lexical, syntactic and semantic features. We introduce an attention mechanism that pinpoints relevant context not only for the current instance, but also for the larger context. Apart from implicitly capturing task relevant features, the advantage of our neural model is that it avoids the need to reproduce linguistic features for other languages and is thus more easily transferable. We present experiments for <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/German_language>German</a> that achieve competitive performance. We present a novel take on modeling and exploiting genre information and showcase the adaptation of our <a href=https://en.wikipedia.org/wiki/System>system</a> from one language to another.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Anette+Frank" title="Search for 'Anette Frank' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/j/juri-opitz/ class=align-middle>Juri Opitz</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/l/letitia-parcalabescu/ class=align-middle>Letitia Parcalabescu</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/t/todor-mihaylov/ class=align-middle>Todor Mihaylov</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/angel-daza/ class=align-middle>Angel Daza</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/debjit-paul/ class=align-middle>Debjit Paul</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/j/julia-suter/ class=align-middle>Julia Suter</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/silvana-hartmann/ class=align-middle>Silvana Hartmann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eva-mujdricza-maydt/ class=align-middle>Éva Mújdricza-Maydt</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ilia-kuznetsov/ class=align-middle>Ilia Kuznetsov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/iryna-gurevych/ class=align-middle>Iryna Gurevych</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bich-ngoc-do/ class=align-middle>Bich-Ngoc Do</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ines-rehbein/ class=align-middle>Ines Rehbein</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maria-becker/ class=align-middle>Maria Becker</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-staniek/ class=align-middle>Michael Staniek</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vivi-nastase/ class=align-middle>Vivi Nastase</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexis-palmer/ class=align-middle>Alexis Palmer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/philipp-heinisch/ class=align-middle>Philipp Heinisch</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/philipp-wiesenbach/ class=align-middle>Philipp Wiesenbach</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/philipp-cimiano/ class=align-middle>Philipp Cimiano</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ana-marasovic/ class=align-middle>Ana Marasović</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nils-trost/ class=align-middle>Nils Trost</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/albert-gatt/ class=align-middle>Albert Gatt</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/iacer-calixto/ class=align-middle>Iacer Calixto</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/mmsr/ class=align-middle>MMSR</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/alvr/ class=align-middle>ALVR</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/argmining/ class=align-middle>ArgMining</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>