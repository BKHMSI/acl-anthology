<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Asif Ekbal - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Asif</span> <span class=font-weight-bold>Ekbal</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-main.255.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-main--255 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-main.255 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-main.255/>Modelling Context Emotions using Multi-task Learning for Emotion Controlled Dialog Generation</a></strong><br><a href=/people/d/deeksha-varshney/>Deeksha Varshney</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/2021.eacl-main/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-main--255><div class="card-body p-3 small">A recent topic of research in <a href=https://en.wikipedia.org/wiki/Natural_language_generation>natural language generation</a> has been the development of automatic response generation modules that can automatically respond to a user&#8217;s utterance in an empathetic manner. Previous research has tackled this task using neural generative methods by augmenting <a href=https://en.wikipedia.org/wiki/Emotion_classification>emotion classes</a> with the input sequences. However, the outputs by these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> may be inconsistent. We employ <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a> to predict the emotion label and to generate a viable response for a given utterance using a common encoder with multiple decoders. Our proposed encoder-decoder model consists of a self-attention based encoder and a decoder with dot product attention mechanism to generate response with a specified emotion. We use the focal loss to handle imbalanced data distribution, and utilize the consistency loss to allow coherent decoding by the <a href=https://en.wikipedia.org/wiki/Code>decoders</a>. Human evaluation reveals that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> produces more emotionally pertinent responses. In addition, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms multiple strong baselines on automatic evaluation measures such as F1 and BLEU scores, thus resulting in more fluent and adequate responses.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wat-1.18.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wat-1--18 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wat-1.18 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wat-1.18/>IITP at WAT 2021 : System description for English-Hindi Multimodal Translation Task<span class=acl-fixed-case>IITP</span> at <span class=acl-fixed-case>WAT</span> 2021: System description for <span class=acl-fixed-case>E</span>nglish-<span class=acl-fixed-case>H</span>indi Multimodal Translation Task</a></strong><br><a href=/people/b/baban-gain/>Baban Gain</a>
|
<a href=/people/d/dibyanayan-bandyopadhyay/>Dibyanayan Bandyopadhyay</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a><br><a href=/volumes/2021.wat-1/ class=text-muted>Proceedings of the 8th Workshop on Asian Translation (WAT2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wat-1--18><div class="card-body p-3 small">Neural Machine Translation (NMT) is a predominant machine translation technology nowadays because of its end-to-end trainable flexibility. However, NMT still struggles to translate properly in low-resource settings specifically on distant language pairs. One way to overcome this is to use the information from other modalities if available. The idea is that despite differences in languages, both the source and target language speakers see the same thing and the visual representation of both the source and target is the same, which can positively assist the system. Multimodal information can help the NMT system to improve the <a href=https://en.wikipedia.org/wiki/Translation>translation</a> by removing <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguity</a> on some phrases or words. We participate in the 8th Workshop on Asian Translation (WAT-2021) for English-Hindi multimodal translation task and achieve 42.47 and 37.50 <a href=https://en.wikipedia.org/wiki/BLEU>BLEU points</a> for Evaluation and Challenge subset, respectively.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.eamt-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--eamt-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.eamt-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.eamt-1.21/>Modelling Source- and Target- Language Syntactic Information as Conditional Context in Interactive Neural Machine Translation</a></strong><br><a href=/people/k/kamal-kumar-gupta/>Kamal Kumar Gupta</a>
|
<a href=/people/r/rejwanul-haque/>Rejwanul Haque</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/2020.eamt-1/ class=text-muted>Proceedings of the 22nd Annual Conference of the European Association for Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--eamt-1--21><div class="card-body p-3 small">In interactive machine translation (MT), human translators correct errors in automatic translations in collaboration with the MT systems, which is seen as an effective way to improve the productivity gain in <a href=https://en.wikipedia.org/wiki/Translation>translation</a>. In this study, we model source-language syntactic constituency parse and target-language syntactic descriptions in the form of supertags as conditional context for interactive prediction in neural MT (NMT). We found that the supertags significantly improve productivity gain in <a href=https://en.wikipedia.org/wiki/Translation>translation</a> in interactive-predictive NMT (INMT), while syntactic parsing somewhat found to be effective in reducing human effort in <a href=https://en.wikipedia.org/wiki/Translation>translation</a>. Furthermore, when we model this source- and target-language syntactic information together as the conditional context, both types complement each other and our fully syntax-informed INMT model statistically significantly reduces human efforts in a FrenchtoEnglish translation task, achieving 4.30 points absolute (corresponding to 9.18 % relative) improvement in terms of word prediction accuracy (WPA) and 4.84 points absolute (corresponding to 9.01 % relative) reduction in terms of word stroke ratio (WSR) over the baseline.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.aacl-main.31.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--aacl-main--31 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.aacl-main.31 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.aacl-main.31/>All-in-One : A Deep Attentive Multi-task Learning Framework for <a href=https://en.wikipedia.org/wiki/Humour>Humour</a>, <a href=https://en.wikipedia.org/wiki/Sarcasm>Sarcasm</a>, Offensive, <a href=https://en.wikipedia.org/wiki/Motivation>Motivation</a>, and Sentiment on Memes</a></strong><br><a href=/people/d/dushyant-singh-chauhan/>Dushyant Singh Chauhan</a>
|
<a href=/people/d/dhanush-s-r/>Dhanush S R</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/2020.aacl-main/ class=text-muted>Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--aacl-main--31><div class="card-body p-3 small">In this paper, we aim at learning the relationships and similarities of a variety of tasks, such as humour detection, sarcasm detection, offensive content detection, motivational content detection and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> on a somewhat complicated form of information, i.e., <a href=https://en.wikipedia.org/wiki/Meme>memes</a>. We propose a multi-task, multi-modal deep learning framework to solve multiple tasks simultaneously. For <a href=https://en.wikipedia.org/wiki/Computer_multitasking>multi-tasking</a>, we propose two attention-like mechanisms viz., Inter-task Relationship Module (iTRM) and Inter-class Relationship Module (iCRM). The main motivation of iTRM is to learn the relationship between the tasks to realize how they help each other. In contrast, <a href=https://en.wikipedia.org/wiki/ICRM>iCRM</a> develops relations between the different classes of tasks. Finally, <a href=https://en.wikipedia.org/wiki/Representation_(arts)>representations</a> from both the attentions are concatenated and shared across the five <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> (i.e., <a href=https://en.wikipedia.org/wiki/Humour>humour</a>, <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a>, offensive, motivational, and sentiment) for <a href=https://en.wikipedia.org/wiki/Computer_multitasking>multi-tasking</a>. We use the recently released dataset in the Memotion Analysis task @ SemEval 2020, which consists of <a href=https://en.wikipedia.org/wiki/Meme>memes</a> annotated for the classes as mentioned above. Empirical results on Memotion dataset show the efficacy of our proposed approach over the existing state-of-the-art systems (Baseline and SemEval 2020 winner). The evaluation also indicates that the proposed multi-task framework yields better performance over the single-task learning.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.aacl-main.90.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--aacl-main--90 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.aacl-main.90 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.aacl-main.90/>A Unified Framework for Multilingual and Code-Mixed Visual Question Answering</a></strong><br><a href=/people/d/deepak-gupta/>Deepak Gupta</a>
|
<a href=/people/p/pabitra-lenka/>Pabitra Lenka</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/2020.aacl-main/ class=text-muted>Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--aacl-main--90><div class="card-body p-3 small">In this paper, we propose an effective deep learning framework for multilingual and code- mixed visual question answering. The pro- posed model is capable of predicting answers from the questions in Hindi, English or Code- mixed (Hinglish : Hindi-English) languages. The majority of the existing techniques on Vi- sual Question Answering (VQA) focus on En- glish questions only. However, many applica- tions such as <a href=https://en.wikipedia.org/wiki/Medical_imaging>medical imaging</a>, <a href=https://en.wikipedia.org/wiki/Tourism>tourism</a>, visual assistants require a multilinguality-enabled module for their widespread usages. As there is no available dataset in English-Hindi VQA, we firstly create Hindi and Code-mixed VQA datasets by exploiting the linguistic properties of these languages. We propose a robust tech- nique capable of handling the multilingual and code-mixed question to provide the answer against the visual information (image). To better encode the multilingual and code-mixed questions, we introduce a hierarchy of shared layers. We control the behaviour of these shared layers by an attention-based soft layer sharing mechanism, which learns how shared layers are applied in different ways for the dif- ferent languages of the question. Further, our model uses bi-linear attention with a residual connection to fuse the language and image fea- tures. We perform extensive evaluation and ablation studies for English, Hindi and Code- mixed VQA. The evaluation shows that the proposed multilingual model achieves state-of- the-art performance in all these settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.249.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--249 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.249 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.249/>Reinforced Multi-task Approach for Multi-hop Question Generation</a></strong><br><a href=/people/d/deepak-gupta/>Deepak Gupta</a>
|
<a href=/people/h/hardik-chauhan/>Hardik Chauhan</a>
|
<a href=/people/r/ravi-tej-akella/>Ravi Tej Akella</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--249><div class="card-body p-3 small">Question generation (QG) attempts to solve the inverse of question answering (QA) problem by generating a natural language question given a document and an answer. While sequence to sequence neural models surpass rule-based systems for QG, they are limited in their capacity to focus on more than one supporting fact. For QG, we often require multiple supporting facts to generate high-quality questions. Inspired by recent works on multi-hop reasoning in <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA</a>, we take up Multi-hop question generation, which aims at generating relevant questions based on supporting facts in the context. We employ <a href=https://en.wikipedia.org/wiki/Multitask_learning>multitask learning</a> with the auxiliary task of answer-aware supporting fact prediction to guide the question generator. In addition, we also proposed a question-aware reward function in a Reinforcement Learning (RL) framework to maximize the utilization of the supporting facts. We demonstrate the effectiveness of our approach through experiments on the multi-hop question answering dataset, HotPotQA. Empirical evaluation shows our model to outperform the single-hop neural question generation models on both automatic evaluation metrics such as <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>, <a href=https://en.wikipedia.org/wiki/METEOR>METEOR</a>, and ROUGE and human evaluation metrics for quality and coverage of the generated questions.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.icon-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--icon-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.icon-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.icon-1.2/>A Deep Ensemble Framework for Fake News Detection and Multi-Class Classification of Short Political Statements</a></strong><br><a href=/people/a/arjun-roy/>Arjun Roy</a>
|
<a href=/people/k/kingshuk-basak/>Kingshuk Basak</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/2019.icon-1/ class=text-muted>Proceedings of the 16th International Conference on Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--icon-1--2><div class="card-body p-3 small">Fake news, <a href=https://en.wikipedia.org/wiki/Rumor>rumor</a>, incorrect information, and misinformation detection are nowadays crucial issues as these might have serious consequences for our social fabrics. Such information is increasing rapidly due to the availability of enormous web information sources including <a href=https://en.wikipedia.org/wiki/Social_media>social media feeds</a>, <a href=https://en.wikipedia.org/wiki/Blog>news blogs</a>, <a href=https://en.wikipedia.org/wiki/Online_newspaper>online newspapers</a> etc. In this paper, we develop various deep learning models for detecting <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a> and classifying them into the pre-defined fine-grained categories. At first, we develop individual models based on Convolutional Neural Network (CNN), and Bi-directional Long Short Term Memory (Bi-LSTM) networks. The <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> obtained from these two <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are fed into a Multi-layer Perceptron Model (MLP) for the final <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a>. Our experiments on a <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmark dataset</a> show promising results with an overall <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 44.87 %, which outperforms the current state of the arts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.icon-1.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--icon-1--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.icon-1.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.icon-1.27/>A Deep Learning Approach for Automatic Detection of Fake News</a></strong><br><a href=/people/t/tanik-saikh/>Tanik Saikh</a>
|
<a href=/people/a/arkadipta-de/>Arkadipta De</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/2019.icon-1/ class=text-muted>Proceedings of the 16th International Conference on Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--icon-1--27><div class="card-body p-3 small">Fake news detection is a very prominent and essential task in the field of <a href=https://en.wikipedia.org/wiki/Journalism>journalism</a>. This challenging <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> is seen so far in the field of <a href=https://en.wikipedia.org/wiki/Politics>politics</a>, but it could be even more challenging when it is to be determined in the multi-domain platform. In this paper, we propose two effective models based on <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> for solving fake news detection problem in online news contents of multiple domains. We evaluate our techniques on the two recently released datasets, namely Fake News AMT and Celebrity for fake news detection. The proposed <a href=https://en.wikipedia.org/wiki/System>systems</a> yield encouraging performance, outperforming the current hand-crafted feature engineering based state-of-the-art system with a significant margin of 3.08 % and 9.3 % by the two <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a>, respectively. In order to exploit the datasets, available for the related tasks, we perform cross-domain analysis (model trained on FakeNews AMT and tested on <a href=https://en.wikipedia.org/wiki/Celebrity>Celebrity</a> and vice versa) to explore the applicability of our systems across the domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5056.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5056 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5056 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5056/>IITP at MEDIQA 2019 : Systems Report for Natural Language Inference, Question Entailment and Question Answering<span class=acl-fixed-case>IITP</span> at <span class=acl-fixed-case>MEDIQA</span> 2019: Systems Report for Natural Language Inference, Question Entailment and Question Answering</a></strong><br><a href=/people/d/dibyanayan-bandyopadhyay/>Dibyanayan Bandyopadhyay</a>
|
<a href=/people/b/baban-gain/>Baban Gain</a>
|
<a href=/people/t/tanik-saikh/>Tanik Saikh</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a><br><a href=/volumes/W19-50/ class=text-muted>Proceedings of the 18th BioNLP Workshop and Shared Task</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5056><div class="card-body p-3 small">This paper presents the experiments accomplished as a part of our participation in the MEDIQA challenge, an (Abacha et al., 2019) shared task. We participated in all the three <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> defined in this particular <a href=https://en.wikipedia.org/wiki/Task_(project_management)>shared task</a>. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> are viz. i. Natural Language Inference (NLI) ii. Recognizing Question Entailment(RQE) and their application in medical Question Answering (QA). We submitted runs using multiple deep learning based systems (runs) for each of these three tasks. We submitted five <a href=https://en.wikipedia.org/wiki/System>system</a> results in each of the NLI and RQE tasks, and four system results for the QA task. The <a href=https://en.wikipedia.org/wiki/System>systems</a> yield encouraging results in all the three <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. The highest performance obtained in NLI, RQE and QA tasks are 81.8 %, 53.2 %, and 71.7 %, respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1034.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1034 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1034 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-1034/>Multi-task Learning for Multi-modal Emotion Recognition and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a></a></strong><br><a href=/people/m/md-shad-akhtar/>Md Shad Akhtar</a>
|
<a href=/people/d/dushyant-chauhan/>Dushyant Chauhan</a>
|
<a href=/people/d/deepanway-ghosal/>Deepanway Ghosal</a>
|
<a href=/people/s/soujanya-poria/>Soujanya Poria</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1034><div class="card-body p-3 small">Related <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> often have inter-dependence on each other and perform better when solved in a joint framework. In this paper, we present a deep multi-task learning framework that jointly performs sentiment and emotion analysis both. The <a href=https://en.wikipedia.org/wiki/Multimodal_interaction>multi-modal inputs</a> (i.e. text, acoustic and visual frames) of a video convey diverse and distinctive information, and usually do not have equal contribution in the <a href=https://en.wikipedia.org/wiki/Decision-making>decision making</a>. We propose a context-level inter-modal attention framework for simultaneously predicting the sentiment and expressed emotions of an utterance. We evaluate our proposed approach on CMU-MOSEI dataset for multi-modal sentiment and emotion analysis. Evaluation results suggest that multi-task learning framework offers improvement over the single-task framework. The proposed approach reports new state-of-the-art performance for both <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> and emotion analysis.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1297.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1297 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1297 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1297/>Multilingual Unsupervised NMT using Shared Encoder and Language-Specific Decoders<span class=acl-fixed-case>NMT</span> using Shared Encoder and Language-Specific Decoders</a></strong><br><a href=/people/s/sukanta-sen/>Sukanta Sen</a>
|
<a href=/people/k/kamal-kumar-gupta/>Kamal Kumar Gupta</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1297><div class="card-body p-3 small">In this paper, we propose a multilingual unsupervised NMT scheme which jointly trains multiple languages with a shared encoder and multiple decoders. Our approach is based on denoising autoencoding of each language and back-translating between English and multiple non-English languages. This results in a universal encoder which can encode any language participating in training into an inter-lingual representation, and language-specific decoders. Our experiments using only monolingual corpora show that multilingual unsupervised model performs better than the separately trained bilingual models achieving improvement of up to 1.48 BLEU points on WMT test sets. We also observe that even if we do not train the <a href=https://en.wikipedia.org/wiki/Computer_network>network</a> for all possible translation directions, the <a href=https://en.wikipedia.org/wiki/Computer_network>network</a> is still able to translate in a many-to-many fashion leveraging encoder&#8217;s ability to generate interlingual representation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1540.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1540 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1540 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1540/>Ordinal and Attribute Aware Response Generation in a Multimodal Dialogue System</a></strong><br><a href=/people/h/hardik-chauhan/>Hardik Chauhan</a>
|
<a href=/people/m/mauajama-firdaus/>Mauajama Firdaus</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1540><div class="card-body p-3 small">Multimodal dialogue systems have opened new frontiers in the traditional goal-oriented dialogue systems. The state-of-the-art dialogue systems are primarily based on unimodal sources, predominantly the text, and hence can not capture the information present in the other sources such as <a href=https://en.wikipedia.org/wiki/Video>videos</a>, <a href=https://en.wikipedia.org/wiki/Videotape>audios</a>, <a href=https://en.wikipedia.org/wiki/Digital_image>images</a> etc. With the availability of large scale multimodal dialogue dataset (MMD) (Saha et al., 2018) on the fashion domain, the visual appearance of the products is essential for understanding the intention of the user. Without capturing the information from both the text and image, the <a href=https://en.wikipedia.org/wiki/System>system</a> will be incapable of generating correct and desirable responses. In this paper, we propose a novel position and attribute aware attention mechanism to learn enhanced image representation conditioned on the user utterance. Our evaluation shows that the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can generate appropriate responses while preserving the position and attribute information. Experimental results also prove that our proposed approach attains superior performance compared to the baseline models, and outperforms the state-of-the-art approaches on text similarity based evaluation metrics.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1042.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1042 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1042 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-1042/>Can <a href=https://en.wikipedia.org/wiki/Taxonomy_(general)>Taxonomy</a> Help? Improving Semantic Question Matching using Question Taxonomy</a></strong><br><a href=/people/d/deepak-gupta/>Deepak Gupta</a>
|
<a href=/people/r/rajkumar-pujari/>Rajkumar Pujari</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a>
|
<a href=/people/a/anutosh-maitra/>Anutosh Maitra</a>
|
<a href=/people/t/tom-jain/>Tom Jain</a>
|
<a href=/people/s/shubhashis-sengupta/>Shubhashis Sengupta</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1042><div class="card-body p-3 small">In this paper, we propose a hybrid technique for semantic question matching. It uses a proposed two-layered taxonomy for English questions by augmenting state-of-the-art <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning models</a> with question classes obtained from a deep learning based question classifier. Experiments performed on three open-domain datasets demonstrate the effectiveness of our proposed approach. We achieve state-of-the-art results on partial ordering question ranking (POQR) benchmark dataset. Our empirical analysis shows that coupling standard distributional features (provided by the question encoder) with knowledge from <a href=https://en.wikipedia.org/wiki/Taxonomy_(general)>taxonomy</a> is more effective than either <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> or <a href=https://en.wikipedia.org/wiki/Taxonomy_(general)>taxonomy-based knowledge</a> alone.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1237.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1237 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1237 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=C18-1237" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/C18-1237/>Novelty Goes Deep. A Deep Neural Solution To Document Level Novelty Detection</a></strong><br><a href=/people/t/tirthankar-ghosal/>Tirthankar Ghosal</a>
|
<a href=/people/v/vignesh-edithal/>Vignesh Edithal</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a>
|
<a href=/people/g/george-tsatsaronis/>George Tsatsaronis</a>
|
<a href=/people/s/srinivasa-satya-sameer-kumar-chivukula/>Srinivasa Satya Sameer Kumar Chivukula</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1237><div class="card-body p-3 small">The rapid growth of documents across the web has necessitated finding means of discarding redundant documents and retaining novel ones. Capturing redundancy is challenging as it may involve investigating at a deep semantic level. Techniques for detecting such semantic redundancy at the document level are scarce. In this work we propose a deep Convolutional Neural Networks (CNN) based model to classify a document as novel or redundant with respect to a set of relevant documents already seen by the system. The <a href=https://en.wikipedia.org/wiki/System>system</a> is simple and do not require any manual feature engineering. Our novel scheme encodes relevant and relative information from both source and target texts to generate an <a href=https://en.wikipedia.org/wiki/Intermediate_representation>intermediate representation</a> which we coin as the Relative Document Vector (RDV). The proposed method outperforms the existing <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> on a document-level novelty detection dataset by a margin of 5 % in terms of <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. We further demonstrate the effectiveness of our approach on a standard paraphrase detection dataset where paraphrased passages closely resemble to semantically redundant documents.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-4408.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-4408 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-4408 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-4408/>An Ensemble Approach for Aggression Identification in English and Hindi Text<span class=acl-fixed-case>E</span>nglish and <span class=acl-fixed-case>H</span>indi Text</a></strong><br><a href=/people/a/arjun-roy/>Arjun Roy</a>
|
<a href=/people/p/prashant-kapil/>Prashant Kapil</a>
|
<a href=/people/k/kingshuk-basak/>Kingshuk Basak</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a><br><a href=/volumes/W18-44/ class=text-muted>Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-4408><div class="card-body p-3 small">This paper describes our <a href=https://en.wikipedia.org/wiki/System>system</a> submitted in the shared task at COLING 2018 TRAC-1 : Aggression Identification. The objective of this task was to predict online aggression spread through online textual post or comment. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> was released in two languages, <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a>. We submitted a single <a href=https://en.wikipedia.org/wiki/System>system</a> for <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> and a single <a href=https://en.wikipedia.org/wiki/System>system</a> for <a href=https://en.wikipedia.org/wiki/English_language>English</a>. Both the systems are based on an <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble architecture</a> where the individual models are based on <a href=https://en.wikipedia.org/wiki/Convoluted_neural_network>Convoluted Neural Network</a> and <a href=https://en.wikipedia.org/wiki/Support_vector_machine>Support Vector Machine</a>. Evaluation shows promising results for both the languages. The total submission for <a href=https://en.wikipedia.org/wiki/English_language>English</a> was 30 and <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> was 15. Our system on <a href=https://en.wikipedia.org/wiki/Facebook>English facebook</a> and social media obtained F1 score of 0.5151 and 0.5099 respectively where <a href=https://en.wikipedia.org/wiki/Facebook>Hindi facebook</a> and <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> obtained F1 score of 0.5599 and 0.3790 respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1053.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1053 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1053 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1053/>Solving Data Sparsity for Aspect Based Sentiment Analysis Using Cross-Linguality and Multi-Linguality</a></strong><br><a href=/people/m/md-shad-akhtar/>Md Shad Akhtar</a>
|
<a href=/people/p/palaash-sawant/>Palaash Sawant</a>
|
<a href=/people/s/sukanta-sen/>Sukanta Sen</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1053><div class="card-body p-3 small">Efficient word representations play an important role in solving various problems related to <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing (NLP)</a>, <a href=https://en.wikipedia.org/wiki/Data_mining>data mining</a>, <a href=https://en.wikipedia.org/wiki/Text_mining>text mining</a> etc. The issue of data sparsity poses a great challenge in creating efficient word representation model for solving the underlying problem. The <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> is more intensified in resource-poor scenario due to the absence of sufficient amount of corpus. In this work we propose to minimize the effect of data sparsity by leveraging bilingual word embeddings learned through a <a href=https://en.wikipedia.org/wiki/Parallel_corpus>parallel corpus</a>. We train and evaluate Long Short Term Memory (LSTM) based architecture for aspect level sentiment classification. The neural network architecture is further assisted by the hand-crafted features for the <a href=https://en.wikipedia.org/wiki/Prediction>prediction</a>. We show the efficacy of the proposed <a href=https://en.wikipedia.org/wiki/Scientific_modelling>model</a> against <a href=https://en.wikipedia.org/wiki/Scientific_method>state-of-the-art methods</a> in two experimental setups i.e. multi-lingual and cross-lingual.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-1012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K18-1012 data-toggle=collapse aria-expanded=false aria-controls=abstract-K18-1012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K18-1012/>Uncovering Code-Mixed Challenges : A Framework for Linguistically Driven Question Generation and Neural Based Question Answering</a></strong><br><a href=/people/d/deepak-gupta/>Deepak Gupta</a>
|
<a href=/people/p/pabitra-lenka/>Pabitra Lenka</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/K18-1/ class=text-muted>Proceedings of the 22nd Conference on Computational Natural Language Learning</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K18-1012><div class="card-body p-3 small">Existing research on question answering (QA) and comprehension reading (RC) are mainly focused on the resource-rich language like <a href=https://en.wikipedia.org/wiki/English_language>English</a>. In recent times, the rapid growth of multi-lingual web content has posed several challenges to the existing <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA systems</a>. Code-mixing is one such challenge that makes the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> more complex. In this paper, we propose a linguistically motivated technique for code-mixed question generation (CMQG) and a neural network based architecture for code-mixed question answering (CMQA). For evaluation, we manually create the code-mixed questions for Hindi-English language pair. In order to show the effectiveness of our neural network based CMQA technique, we utilize two benchmark datasets, SQuAD and MMQA. Experiments show that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves encouraging performance on CMQG and CMQA.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-4031.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-4031 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-4031 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-4031/>IITP at IJCNLP-2017 Task 4 : Auto Analysis of Customer Feedback using CNN and GRU Network<span class=acl-fixed-case>IITP</span> at <span class=acl-fixed-case>IJCNLP</span>-2017 Task 4: Auto Analysis of Customer Feedback using <span class=acl-fixed-case>CNN</span> and <span class=acl-fixed-case>GRU</span> Network</a></strong><br><a href=/people/d/deepak-gupta/>Deepak Gupta</a>
|
<a href=/people/p/pabitra-lenka/>Pabitra Lenka</a>
|
<a href=/people/h/harsimran-bedi/>Harsimran Bedi</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/I17-4/ class=text-muted>Proceedings of the IJCNLP 2017, Shared Tasks</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-4031><div class="card-body p-3 small">Analyzing customer feedback is the best way to channelize the data into new <a href=https://en.wikipedia.org/wiki/Marketing_strategy>marketing strategies</a> that benefit entrepreneurs as well as customers. Therefore an automated system which can analyze the <a href=https://en.wikipedia.org/wiki/Consumer_behaviour>customer behavior</a> is in great demand. Users may write feedbacks in any language, and hence mining appropriate information often becomes intractable. Especially in a traditional feature-based supervised model, it is difficult to build a generic system as one has to understand the concerned language for finding the relevant <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>. In order to overcome this, we propose deep Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) based approaches that do not require handcrafting of features. We evaluate these techniques for analyzing customer feedback sentences on four languages, namely <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/French_language>French</a>, <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. Our empirical analysis shows that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> perform well in all the four languages on the setups of IJCNLP Shared Task on Customer Feedback Analysis. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieved the second rank in <a href=https://en.wikipedia.org/wiki/French_language>French</a>, with an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 71.75 % and third ranks for all the other languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2104.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2104 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2104 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P17-2104/>Temporal Orientation of Tweets for Predicting Income of Users</a></strong><br><a href=/people/m/mohammed-hasanuzzaman/>Mohammed Hasanuzzaman</a>
|
<a href=/people/s/sabyasachi-kamila/>Sabyasachi Kamila</a>
|
<a href=/people/m/mandeep-kaur/>Mandeep Kaur</a>
|
<a href=/people/s/sriparna-saha/>Sriparna Saha</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2104><div class="card-body p-3 small">Automatically estimating a user&#8217;s socio-economic profile from their language use in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> can significantly help <a href=https://en.wikipedia.org/wiki/Social_science>social science research</a> and various downstream applications ranging from <a href=https://en.wikipedia.org/wiki/Business>business</a> to <a href=https://en.wikipedia.org/wiki/Politics>politics</a>. The current paper presents the first study where user cognitive structure is used to build a predictive model of income. In particular, we first develop a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> using a weakly supervised learning framework to automatically time-tag tweets as past, present, or future. We quantify a user&#8217;s overall temporal orientation based on their distribution of tweets, and use it to build a predictive model of income. Our analysis uncovers a correlation between future temporal orientation and <a href=https://en.wikipedia.org/wiki/Income>income</a>. Finally, we measure the predictive power of future temporal orientation on <a href=https://en.wikipedia.org/wiki/Income>income</a> by performing <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2009 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=S17-2009" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/S17-2009/>IIT-UHH at SemEval-2017 Task 3 : Exploring Multiple Features for Community Question Answering and Implicit Dialogue Identification<span class=acl-fixed-case>IIT</span>-<span class=acl-fixed-case>UHH</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 3: Exploring Multiple Features for Community Question Answering and Implicit Dialogue Identification</a></strong><br><a href=/people/t/titas-nandi/>Titas Nandi</a>
|
<a href=/people/c/chris-biemann/>Chris Biemann</a>
|
<a href=/people/s/seid-muhie-yimam/>Seid Muhie Yimam</a>
|
<a href=/people/d/deepak-gupta/>Deepak Gupta</a>
|
<a href=/people/s/sarah-kohail/>Sarah Kohail</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2009><div class="card-body p-3 small">In this paper we present the system for Answer Selection and Ranking in Community Question Answering, which we build as part of our participation in SemEval-2017 Task 3. We develop a Support Vector Machine (SVM) based system that makes use of textual, domain-specific, word-embedding and topic-modeling features. In addition, we propose a novel <a href=https://en.wikipedia.org/wiki/Methodology>method</a> for dialogue chain identification in <a href=https://en.wikipedia.org/wiki/Internet_forum>comment threads</a>. Our primary submission won subtask C, outperforming other systems in all the primary evaluation metrics. We performed well in other English subtasks, ranking third in subtask A and eighth in subtask B. We also developed open source toolkits for all the three English subtasks by the name cQARank [ ].<url>https://github.com/TitasNandi/cQARank</url>].\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2087.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2087 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2087 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2087/>IITP at SemEval-2017 Task 8 : A Supervised Approach for Rumour Evaluation<span class=acl-fixed-case>IITP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 8 : A Supervised Approach for Rumour Evaluation</a></strong><br><a href=/people/v/vikram-singh/>Vikram Singh</a>
|
<a href=/people/s/sunny-narayan/>Sunny Narayan</a>
|
<a href=/people/m/md-shad-akhtar/>Md Shad Akhtar</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2087><div class="card-body p-3 small">This paper describes our <a href=https://en.wikipedia.org/wiki/System>system</a> participation in the SemEval-2017 Task 8 &#8216;RumourEval : Determining rumour veracity and support for rumours&#8217;. The objective of this task was to predict the stance and veracity of the underlying <a href=https://en.wikipedia.org/wiki/Rumor>rumour</a>. We propose a supervised classification approach employing several lexical, content and twitter specific features for learning. Evaluation shows promising results for both the <a href=https://en.wikipedia.org/wiki/Problem_solving>problems</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2154.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2154 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2154 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2154/>IITP at SemEval-2017 Task 5 : An Ensemble of Deep Learning and Feature Based Models for Financial Sentiment Analysis<span class=acl-fixed-case>IITP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 5: An Ensemble of Deep Learning and Feature Based Models for Financial Sentiment Analysis</a></strong><br><a href=/people/d/deepanway-ghosal/>Deepanway Ghosal</a>
|
<a href=/people/s/shobhit-bhatnagar/>Shobhit Bhatnagar</a>
|
<a href=/people/m/md-shad-akhtar/>Md Shad Akhtar</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2154><div class="card-body p-3 small">In this paper we propose an ensemble based model which combines state of the art deep learning sentiment analysis algorithms like Convolution Neural Network (CNN) and Long Short Term Memory (LSTM) along with feature based models to identify optimistic or pessimistic sentiments associated with companies and stocks in financial texts. We build our <a href=https://en.wikipedia.org/wiki/System>system</a> to participate in a competition organized by Semantic Evaluation 2017 International Workshop. We combined predictions from various models using an <a href=https://en.wikipedia.org/wiki/Artificial_neural_network>artificial neural network</a> to determine the opinion towards an entity in (a) Microblog Messages and (b) News Headlines data. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> achieved a cosine similarity score of 0.751 and 0.697 for the above two tracks giving us the rank of 2nd and 7th best team respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-1109.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-1109 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-1109 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-1109/>Entity Extraction in Biomedical Corpora : An Approach to Evaluate Word Embedding Features with PSO based Feature Selection<span class=acl-fixed-case>PSO</span> based Feature Selection</a></strong><br><a href=/people/s/shweta-yadav/>Shweta Yadav</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/s/sriparna-saha/>Sriparna Saha</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/E17-1/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-1109><div class="card-body p-3 small">Text mining has drawn significant attention in recent past due to the rapid growth in biomedical and clinical records. Entity extraction is one of the fundamental components for <a href=https://en.wikipedia.org/wiki/Biomedical_text_mining>biomedical text mining</a>. In this paper, we propose a novel approach of <a href=https://en.wikipedia.org/wiki/Feature_selection>feature selection</a> for <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity extraction</a> that exploits the concept of <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> and Particle Swarm Optimization (PSO). The system utilizes word embedding features along with several other <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> extracted by studying the properties of the <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>. We obtain an interesting observation that compact word embedding features as determined by PSO are more effective compared to the entire word embedding feature set for entity extraction. The proposed system is evaluated on three benchmark biomedical datasets such as GENIA, GENETAG, and AiMed. The effectiveness of the proposed approach is evident with significant performance gains over the baseline models as well as the other existing systems. We observe improvements of 7.86 %, 5.27 % and 7.25 % <a href=https://en.wikipedia.org/wiki/F-measure>F-measure</a> points over the baseline models for GENIA, GENETAG, and AiMed dataset respectively.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Asif+Ekbal" title="Search for 'Asif Ekbal' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/p/pushpak-bhattacharyya/ class=align-middle>Pushpak Bhattacharyya</a>
<span class="badge badge-secondary align-middle ml-2">19</span></li><li class=list-group-item><a href=/people/d/deepak-gupta/ class=align-middle>Deepak Gupta</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/m/md-shad-akhtar/ class=align-middle>Md Shad Akhtar</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/p/pabitra-lenka/ class=align-middle>Pabitra Lenka</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/k/kamal-kumar-gupta/ class=align-middle>Kamal Kumar Gupta</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/s/sriparna-saha/ class=align-middle>Sriparna Saha</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/arjun-roy/ class=align-middle>Arjun Roy</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/kingshuk-basak/ class=align-middle>Kingshuk Basak</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/tanik-saikh/ class=align-middle>Tanik Saikh</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/deepanway-ghosal/ class=align-middle>Deepanway Ghosal</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/baban-gain/ class=align-middle>Baban Gain</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/dibyanayan-bandyopadhyay/ class=align-middle>Dibyanayan Bandyopadhyay</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hardik-chauhan/ class=align-middle>Hardik Chauhan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sukanta-sen/ class=align-middle>Sukanta Sen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/rejwanul-haque/ class=align-middle>Rejwanul Haque</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andy-way/ class=align-middle>Andy Way</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rajkumar-pujari/ class=align-middle>Rajkumar Pujari</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anutosh-maitra/ class=align-middle>Anutosh Maitra</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tom-jain/ class=align-middle>Tom Jain</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shubhashis-sengupta/ class=align-middle>Shubhashis Sengupta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tirthankar-ghosal/ class=align-middle>Tirthankar Ghosal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vignesh-edithal/ class=align-middle>Vignesh Edithal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/george-tsatsaronis/ class=align-middle>George Tsatsaronis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/srinivasa-satya-sameer-kumar-chivukula/ class=align-middle>Srinivasa Satya Sameer Kumar Chivukula</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/harsimran-bedi/ class=align-middle>Harsimran Bedi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mohammed-hasanuzzaman/ class=align-middle>Mohammed Hasanuzzaman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sabyasachi-kamila/ class=align-middle>Sabyasachi Kamila</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mandeep-kaur/ class=align-middle>Mandeep Kaur</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/deeksha-varshney/ class=align-middle>Deeksha Varshney</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/arkadipta-de/ class=align-middle>Arkadipta De</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dushyant-singh-chauhan/ class=align-middle>Dushyant Singh Chauhan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dhanush-s-r/ class=align-middle>Dhanush S R</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/titas-nandi/ class=align-middle>Titas Nandi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chris-biemann/ class=align-middle>Chris Biemann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/seid-muhie-yimam/ class=align-middle>Seid Muhie Yimam</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sarah-kohail/ class=align-middle>Sarah Kohail</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vikram-singh/ class=align-middle>Vikram Singh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sunny-narayan/ class=align-middle>Sunny Narayan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shobhit-bhatnagar/ class=align-middle>Shobhit Bhatnagar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/prashant-kapil/ class=align-middle>Prashant Kapil</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ravi-tej-akella/ class=align-middle>Ravi Tej Akella</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dushyant-chauhan/ class=align-middle>Dushyant Chauhan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/soujanya-poria/ class=align-middle>Soujanya Poria</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/palaash-sawant/ class=align-middle>Palaash Sawant</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shweta-yadav/ class=align-middle>Shweta Yadav</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mauajama-firdaus/ class=align-middle>Mauajama Firdaus</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/icon/ class=align-middle>ICON</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/aacl/ class=align-middle>AACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/eamt/ class=align-middle>EAMT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wat/ class=align-middle>WAT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>