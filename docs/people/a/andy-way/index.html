<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Andy Way - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Andy</span> <span class=font-weight-bold>Way</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mtsummit-research.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mtsummit-research--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mtsummit-research.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mtsummit-research.5/>Transformers for Low-Resource Languages : Is Fidir Linn !</a></strong><br><a href=/people/s/seamus-lankford/>Seamus Lankford</a>
|
<a href=/people/h/haithem-alfi/>Haithem Alfi</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/2021.mtsummit-research/ class=text-muted>Proceedings of Machine Translation Summit XVIII: Research Track</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mtsummit-research--5><div class="card-body p-3 small">The Transformer model is the state-of-the-art in <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a>. However and in general and neural translation models often under perform on language pairs with insufficient training data. As a consequence and relatively few experiments have been carried out using this <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> on low-resource language pairs. In this study and hyperparameter optimization of Transformer models in translating the low-resource English-Irish language pair is evaluated. We demonstrate that choosing appropriate parameters leads to considerable performance improvements. Most importantly and the correct choice of subword model is shown to be the biggest driver of <a href=https://en.wikipedia.org/wiki/Translation>translation</a> performance. SentencePiece models using both unigram and BPE approaches were appraised. Variations on model architectures included modifying the number of layers and testing various <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization techniques</a> and evaluating the optimal number of heads for <a href=https://en.wikipedia.org/wiki/Attention>attention</a>. A generic 55k DGT corpus and an in-domain 88k public admin corpus were used for evaluation. A Transformer optimized model demonstrated a BLEU score improvement of 7.8 points when compared with a baseline <a href=https://en.wikipedia.org/wiki/Real-time_locating_system>RNN model</a>. Improvements were observed across a range of metrics and including TER and indicating a substantially reduced post editing effort for Transformer optimized models with 16k BPE subword models. Bench-marked against <a href=https://en.wikipedia.org/wiki/Google_Translate>Google Translate</a> and our translation engines demonstrated significant improvements. The question of whether or not <a href=https://en.wikipedia.org/wiki/Transformers_(toy_line)>Transformers</a> can be used effectively in a low-resource setting of English-Irish translation has been addressed. Is fidir linn-yes we can.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mtsummit-up--25 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mtsummit-up.25 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.mtsummit-up.25.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.mtsummit-up.25/>Building <span class=acl-fixed-case>MT</span> systems in low resourced languages for Public Sector users in <span class=acl-fixed-case>C</span>roatia, <span class=acl-fixed-case>I</span>celand, <span class=acl-fixed-case>I</span>reland, and <span class=acl-fixed-case>N</span>orway</a></strong><br><a href=/people/r/roisin-moran/>Róisín Moran</a>
|
<a href=/people/c/carla-para-escartin/>Carla Para Escartín</a>
|
<a href=/people/a/akshai-ramesh/>Akshai Ramesh</a>
|
<a href=/people/p/paraic-sheridan/>Páraic Sheridan</a>
|
<a href=/people/j/jane-dunne/>Jane Dunne</a>
|
<a href=/people/f/federico-gaspari/>Federico Gaspari</a>
|
<a href=/people/s/sheila-castilho/>Sheila Castilho</a>
|
<a href=/people/n/natalia-resende/>Natalia Resende</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/2021.mtsummit-up/ class=text-muted>Proceedings of Machine Translation Summit XVIII: Users and Providers Track</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mtsummit-up--25><div class="card-body p-3 small">When developing Machine Translation engines, low resourced language pairs tend to be in a disadvantaged position: less available data means that developing robust MT models can be more challenging.The EU-funded PRINCIPLE project aims at overcoming this challenge for four low resourced European languages: Norwegian, Croatian, Irish and Icelandic. This presentation will give an overview of the project, with a focus on the set of Public Sector users and their use cases for which we have developed MT solutions.We will discuss the range of language resources that have been gathered through contributions from public sector collaborators, and present the extensive evaluations that have been undertaken, including significant user evaluation of MT systems across all of the public sector participants in each of the four countries involved.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wmt-1.63.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wmt-1--63 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wmt-1.63 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wmt-1.63/>DELA Corpus-A Document-Level Corpus Annotated with Context-Related Issues<span class=acl-fixed-case>DELA</span> Corpus - A Document-Level Corpus Annotated with Context-Related Issues</a></strong><br><a href=/people/s/sheila-castilho/>Sheila Castilho</a>
|
<a href=/people/j/joao-lucas-cavalheiro-camargo/>João Lucas Cavalheiro Camargo</a>
|
<a href=/people/m/miguel-menezes/>Miguel Menezes</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/2021.wmt-1/ class=text-muted>Proceedings of the Sixth Conference on Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wmt-1--63><div class="card-body p-3 small">Recently, the Machine Translation (MT) community has become more interested in document-level evaluation especially in light of reactions to claims of human parity, since examining the quality at the level of the document rather than at the sentence level allows for the assessment of suprasentential context, providing a more reliable evaluation. This paper presents a document-level corpus annotated in English with context-aware issues that arise when translating from <a href=https://en.wikipedia.org/wiki/English_language>English</a> into <a href=https://en.wikipedia.org/wiki/Brazilian_Portuguese>Brazilian Portuguese</a>, namely ellipsis, gender, lexical ambiguity, number, reference, and terminology, with six different domains. The <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> can be used as a challenge test set for evaluation and as a training / testing corpus for MT as well as for deep linguistic analysis of context issues. To the best of our knowledge, this is the first corpus of its kind.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.eamt-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--eamt-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.eamt-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.eamt-1.21/>Modelling Source- and Target- Language Syntactic Information as Conditional Context in Interactive Neural Machine Translation</a></strong><br><a href=/people/k/kamal-kumar-gupta/>Kamal Kumar Gupta</a>
|
<a href=/people/r/rejwanul-haque/>Rejwanul Haque</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/2020.eamt-1/ class=text-muted>Proceedings of the 22nd Annual Conference of the European Association for Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--eamt-1--21><div class="card-body p-3 small">In interactive machine translation (MT), human translators correct errors in automatic translations in collaboration with the MT systems, which is seen as an effective way to improve the productivity gain in <a href=https://en.wikipedia.org/wiki/Translation>translation</a>. In this study, we model source-language syntactic constituency parse and target-language syntactic descriptions in the form of supertags as conditional context for interactive prediction in neural MT (NMT). We found that the supertags significantly improve productivity gain in <a href=https://en.wikipedia.org/wiki/Translation>translation</a> in interactive-predictive NMT (INMT), while syntactic parsing somewhat found to be effective in reducing human effort in <a href=https://en.wikipedia.org/wiki/Translation>translation</a>. Furthermore, when we model this source- and target-language syntactic information together as the conditional context, both types complement each other and our fully syntax-informed INMT model statistically significantly reduces human efforts in a FrenchtoEnglish translation task, achieving 4.30 points absolute (corresponding to 9.18 % relative) improvement in terms of word prediction accuracy (WPA) and 4.84 points absolute (corresponding to 9.01 % relative) reduction in terms of word stroke ratio (WSR) over the baseline.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.eamt-1.69.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--eamt-1--69 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.eamt-1.69 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.eamt-1.69/>MTrill project : <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a> impact on language learning<span class=acl-fixed-case>MT</span>rill project: Machine Translation impact on language learning</a></strong><br><a href=/people/n/natalia-resende/>Natália Resende</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/2020.eamt-1/ class=text-muted>Proceedings of the 22nd Annual Conference of the European Association for Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--eamt-1--69><div class="card-body p-3 small">Over the last decades, massive research investments have been made in the development of machine translation (MT) systems (Gupta and Dhawan, 2019). This has brought about a paradigm shift in the performance of these language tools, leading to widespread use of popular MT systems (Gaspari and Hutchins, 2007). Although the first MT engines were used for gisting purposes, in recent years, there has been an increasing interest in using MT tools, especially the freely available online MT tools, for language teaching and learning (Clifford et al., 2013). The literature on MT and Computer Assisted Language Learning (CALL) shows that, over the years, MT systems have been facilitating <a href=https://en.wikipedia.org/wiki/Language_education>language teaching</a> and also <a href=https://en.wikipedia.org/wiki/Language_acquisition>language learning</a> (Nin o, 2006). It has been shown that MT tools can increase awareness of <a href=https://en.wikipedia.org/wiki/Grammaticality>grammatical linguistic features</a> of a foreign language. Research also shows the positive role of MT systems in the development of writing skills in <a href=https://en.wikipedia.org/wiki/English_language>English</a> as well as in improving communication skills in English(Garcia and Pena, 2011). However, to date, the cognitive impact of MT on <a href=https://en.wikipedia.org/wiki/Language_acquisition>language acquisition</a> and on the syntactic aspects of language processing has not yet been investigated and deserves further scrutiny. The MTril project aims at filling this gap in the literature by examining whether MT is contributing to a central aspect of <a href=https://en.wikipedia.org/wiki/Language_acquisition>language acquisition</a> : the so-called <a href=https://en.wikipedia.org/wiki/Language_binding>language binding</a>, i.e., the ability to combine single words properly in a grammatical sentence (Heyselaar et al., 2017 ; Ferreira and Bock, 2006).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4hala-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lt4hala-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lt4hala-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.lt4hala-1.7" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.lt4hala-1.7/>A Tool for Facilitating OCR Postediting in Historical Documents<span class=acl-fixed-case>OCR</span> Postediting in Historical Documents</a></strong><br><a href=/people/a/alberto-poncelas/>Alberto Poncelas</a>
|
<a href=/people/m/mohammad-aboomar/>Mohammad Aboomar</a>
|
<a href=/people/j/jan-buts/>Jan Buts</a>
|
<a href=/people/j/james-hadley/>James Hadley</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/2020.lt4hala-1/ class=text-muted>Proceedings of LT4HALA 2020 - 1st Workshop on Language Technologies for Historical and Ancient Languages</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lt4hala-1--7><div class="card-body p-3 small">Optical character recognition (OCR) for <a href=https://en.wikipedia.org/wiki/Historical_document>historical documents</a> is a complex procedure subject to a unique set of material issues, including inconsistencies in <a href=https://en.wikipedia.org/wiki/Typeface>typefaces</a> and low quality scanning. Consequently, even the most sophisticated <a href=https://en.wikipedia.org/wiki/Optical_character_recognition>OCR engines</a> produce errors. This paper reports on a tool built for postediting the output of Tesseract, more specifically for correcting common errors in digitized historical documents. The proposed <a href=https://en.wikipedia.org/wiki/Tool>tool</a> suggests alternatives for <a href=https://en.wikipedia.org/wiki/Linguistic_description>word forms</a> not found in a specified vocabulary. The assumed error is replaced by a presumably correct alternative in the post-edition based on the scores of a Language Model (LM). The <a href=https://en.wikipedia.org/wiki/Tool>tool</a> is tested on a chapter of the book An Essay Towards Regulating the Trade and Employing the Poor of this Kingdom (Cary, 1719). As demonstrated below, the <a href=https://en.wikipedia.org/wiki/Tool>tool</a> is successful in correcting a number of common errors. If sometimes unreliable, <a href=https://en.wikipedia.org/wiki/It_(2017_film)>it</a> is also transparent and subject to human intervention.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wat-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--wat-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.wat-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.wat-1.17/>The ADAPT Centre’s Neural MT Systems for the WAT 2020 Document-Level Translation Task<span class=acl-fixed-case>ADAPT</span> Centre’s Neural <span class=acl-fixed-case>MT</span> Systems for the <span class=acl-fixed-case>WAT</span> 2020 Document-Level Translation Task</a></strong><br><a href=/people/w/wandri-jooste/>Wandri Jooste</a>
|
<a href=/people/r/rejwanul-haque/>Rejwanul Haque</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/2020.wat-1/ class=text-muted>Proceedings of the 7th Workshop on Asian Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--wat-1--17><div class="card-body p-3 small">In this paper we describe the ADAPT Centre&#8217;s submissions to the WAT 2020 document-level Business Scene Dialogue (BSD) Translation task. We only consider translating from <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> to <a href=https://en.wikipedia.org/wiki/English_language>English</a> for this task and we use the MarianNMT toolkit to train Transformer models. In order to improve the translation quality, we made use of both in-domain and out-of-domain data for training our Machine Translation (MT) systems, as well as various data augmentation techniques for fine-tuning the model parameters. This paper outlines the experiments we ran to train our <a href=https://en.wikipedia.org/wiki/System>systems</a> and report the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> achieved through these various experiments.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.407.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--407 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.407 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.407/>The European Language Technology Landscape in 2020 : Language-Centric and Human-Centric AI for Cross-Cultural Communication in Multilingual Europe<span class=acl-fixed-case>E</span>uropean Language Technology Landscape in 2020: Language-Centric and Human-Centric <span class=acl-fixed-case>AI</span> for Cross-Cultural Communication in Multilingual <span class=acl-fixed-case>E</span>urope</a></strong><br><a href=/people/g/georg-rehm/>Georg Rehm</a>
|
<a href=/people/k/katrin-marheinecke/>Katrin Marheinecke</a>
|
<a href=/people/s/stefanie-hegele/>Stefanie Hegele</a>
|
<a href=/people/s/stelios-piperidis/>Stelios Piperidis</a>
|
<a href=/people/k/kalina-bontcheva/>Kalina Bontcheva</a>
|
<a href=/people/j/jan-hajic/>Jan Hajič</a>
|
<a href=/people/k/khalid-choukri/>Khalid Choukri</a>
|
<a href=/people/a/andrejs-vasiljevs/>Andrejs Vasiļjevs</a>
|
<a href=/people/g/gerhard-backfried/>Gerhard Backfried</a>
|
<a href=/people/c/christoph-prinz/>Christoph Prinz</a>
|
<a href=/people/j/jose-manuel-gomez-perez/>José Manuel Gómez-Pérez</a>
|
<a href=/people/l/luc-meertens/>Luc Meertens</a>
|
<a href=/people/p/paul-lukowicz/>Paul Lukowicz</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a>
|
<a href=/people/a/andrea-losch/>Andrea Lösch</a>
|
<a href=/people/p/philipp-slusallek/>Philipp Slusallek</a>
|
<a href=/people/m/morten-irgens/>Morten Irgens</a>
|
<a href=/people/p/patrick-gatellier/>Patrick Gatellier</a>
|
<a href=/people/j/joachim-kohler/>Joachim Köhler</a>
|
<a href=/people/l/laure-le-bars/>Laure Le Bars</a>
|
<a href=/people/d/dimitra-anastasiou/>Dimitra Anastasiou</a>
|
<a href=/people/a/albina-auksoriute/>Albina Auksoriūtė</a>
|
<a href=/people/n/nuria-bel/>Núria Bel</a>
|
<a href=/people/a/antonio-branco/>António Branco</a>
|
<a href=/people/g/gerhard-budin/>Gerhard Budin</a>
|
<a href=/people/w/walter-daelemans/>Walter Daelemans</a>
|
<a href=/people/k/koenraad-de-smedt/>Koenraad De Smedt</a>
|
<a href=/people/r/radovan-garabik/>Radovan Garabík</a>
|
<a href=/people/m/maria-gavriilidou/>Maria Gavriilidou</a>
|
<a href=/people/d/dagmar-gromann/>Dagmar Gromann</a>
|
<a href=/people/s/svetla-koeva/>Svetla Koeva</a>
|
<a href=/people/s/simon-krek/>Simon Krek</a>
|
<a href=/people/c/cvetana-krstev/>Cvetana Krstev</a>
|
<a href=/people/k/krister-linden/>Krister Lindén</a>
|
<a href=/people/b/bernardo-magnini/>Bernardo Magnini</a>
|
<a href=/people/j/jan-odijk/>Jan Odijk</a>
|
<a href=/people/m/maciej-ogrodniczuk/>Maciej Ogrodniczuk</a>
|
<a href=/people/e/eirikur-rognvaldsson/>Eiríkur Rögnvaldsson</a>
|
<a href=/people/m/michael-rosner/>Mike Rosner</a>
|
<a href=/people/b/bolette-sandford-pedersen/>Bolette Pedersen</a>
|
<a href=/people/i/inguna-skadina/>Inguna Skadiņa</a>
|
<a href=/people/m/marko-tadic/>Marko Tadić</a>
|
<a href=/people/d/dan-tufis/>Dan Tufiș</a>
|
<a href=/people/t/tamas-varadi/>Tamás Váradi</a>
|
<a href=/people/k/kadri-vider/>Kadri Vider</a>
|
<a href=/people/a/andy-way/>Andy Way</a>
|
<a href=/people/f/francois-yvon/>François Yvon</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--407><div class="card-body p-3 small">Multilingualism is a cultural cornerstone of Europe and firmly anchored in the <a href=https://en.wikipedia.org/wiki/Treaties_of_the_European_Union>European treaties</a> including <a href=https://en.wikipedia.org/wiki/Linguistic_rights>full language equality</a>. However, <a href=https://en.wikipedia.org/wiki/Language_barrier>language barriers</a> impacting business, <a href=https://en.wikipedia.org/wiki/Cross-cultural_communication>cross-lingual and cross-cultural communication</a> are still omnipresent. Language Technologies (LTs) are a powerful means to break down these barriers. While the last decade has seen various initiatives that created a multitude of <a href=https://en.wikipedia.org/wiki/Software_development_process>approaches</a> and technologies tailored to Europe&#8217;s specific needs, there is still an immense level of fragmentation. At the same time, AI has become an increasingly important concept in the European Information and Communication Technology area. For a few years now, <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI</a> including many opportunities, synergies but also misconceptions has been overshadowing every other topic. We present an overview of the European LT landscape, describing funding programmes, activities, actions and challenges in the different countries with regard to LT, including the current state of play in industry and the LT market. We present a brief overview of the main LT-related activities on the EU level in the last ten years and develop strategic guidance with regard to four key dimensions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.loresmt-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--loresmt-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.loresmt-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.loresmt-1.15/>Investigating Low-resource Machine Translation for English-to-Tamil<span class=acl-fixed-case>E</span>nglish-to-<span class=acl-fixed-case>T</span>amil</a></strong><br><a href=/people/a/akshai-ramesh/>Akshai Ramesh</a>
|
<a href=/people/v/venkatesh-balavadhani-parthasa/>Venkatesh Balavadhani parthasa</a>
|
<a href=/people/r/rejwanul-haque/>Rejwanul Haque</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/2020.loresmt-1/ class=text-muted>Proceedings of the 3rd Workshop on Technologies for MT of Low Resource Languages</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--loresmt-1--15><div class="card-body p-3 small">Statistical machine translation (SMT) which was the dominant paradigm in machine translation (MT) research for nearly three decades has recently been superseded by the end-to-end deep learning approaches to MT. Although <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural models</a> produce state-of-the-art results in many translation tasks, they are found to under-perform on resource-poor scenarios. Despite some success, none of the present-day benchmarks that have tried to overcome this problem can be regarded as a universal solution to the problem of <a href=https://en.wikipedia.org/wiki/Translation>translation</a> of many low-resource languages. In this work, we investigate the performance of phrase-based SMT (PB-SMT) and neural MT (NMT) on a rarely-tested low-resource language-pair, English-to-Tamil, taking a specialised data domain (software localisation) into consideration. In particular, we produce rankings of our MT systems via a social media platform-based human evaluation scheme, and demonstrate our findings in the low-resource domain-specific text translation task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ngt-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ngt-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929831 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ngt-1.17/>The ADAPT System Description for the STAPLE 2020 English-to-Portuguese Translation Task<span class=acl-fixed-case>ADAPT</span> System Description for the <span class=acl-fixed-case>STAPLE</span> 2020 <span class=acl-fixed-case>E</span>nglish-to-<span class=acl-fixed-case>P</span>ortuguese Translation Task</a></strong><br><a href=/people/r/rejwanul-haque/>Rejwanul Haque</a>
|
<a href=/people/y/yasmin-moslem/>Yasmin Moslem</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/2020.ngt-1/ class=text-muted>Proceedings of the Fourth Workshop on Neural Generation and Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ngt-1--17><div class="card-body p-3 small">This paper describes the ADAPT Centre&#8217;s submission to STAPLE (Simultaneous Translation and Paraphrase for Language Education) 2020, a shared task of the 4th Workshop on Neural Generation and Translation (WNGT), for the English-to-Portuguese translation task. In this shared task, the participants were asked to produce high-coverage sets of plausible translations given English prompts (input source sentences). We present our English-to-Portuguese machine translation (MT) models that were built applying various strategies, e.g. data and sentence selection, monolingual MT for generating alternative translations, and combining multiple n-best translations. Our experiments show that adding the aforementioned techniques to the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> yields an excellent performance in the English-to-Portuguese translation task.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-6600.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-6600/>Proceedings of Machine Translation Summit XVII: Research Track</a></strong><br><a href=/people/m/mikel-l-forcada/>Mikel Forcada</a>
|
<a href=/people/a/andy-way/>Andy Way</a>
|
<a href=/people/b/barry-haddow/>Barry Haddow</a>
|
<a href=/people/r/rico-sennrich/>Rico Sennrich</a><br><a href=/volumes/W19-66/ class=text-muted>Proceedings of Machine Translation Summit XVII: Research Track</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-6700.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-6700/>Proceedings of Machine Translation Summit XVII: Translator, Project and User Tracks</a></strong><br><a href=/people/m/mikel-l-forcada/>Mikel Forcada</a>
|
<a href=/people/a/andy-way/>Andy Way</a>
|
<a href=/people/j/john-tinsley/>John Tinsley</a>
|
<a href=/people/d/dimitar-shterionov/>Dimitar Shterionov</a>
|
<a href=/people/c/celia-rico/>Celia Rico</a>
|
<a href=/people/f/federico-gaspari/>Federico Gaspari</a><br><a href=/volumes/W19-67/ class=text-muted>Proceedings of Machine Translation Summit XVII: Translator, Project and User Tracks</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-7300.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-7300/>Proceedings of the Qualities of Literary Machine Translation</a></strong><br><a href=/people/j/james-hadley/>James Hadley</a>
|
<a href=/people/m/maja-popovic/>Maja Popović</a>
|
<a href=/people/h/haithem-afli/>Haithem Afli</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/W19-73/ class=text-muted>Proceedings of the Qualities of Literary Machine Translation</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1052.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1052 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1052 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1052/>Investigating Terminology Translation in Statistical and Neural Machine Translation : A Case Study on English-to-Hindi and Hindi-to-English<span class=acl-fixed-case>E</span>nglish-to-<span class=acl-fixed-case>H</span>indi and <span class=acl-fixed-case>H</span>indi-to-<span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/r/rejwanul-haque/>Rejwanul Haque</a>
|
<a href=/people/m/md-hasanuzzaman/>Md Hasanuzzaman</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/R19-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1052><div class="card-body p-3 small">Terminology translation plays a critical role in domain-specific machine translation (MT). In this paper, we conduct a comparative qualitative evaluation on terminology translation in phrase-based statistical MT (PB-SMT) and neural MT (NMT) in two translation directions : English-to-Hindi and Hindi-to-English. For this, we select a test set from a legal domain corpus and create a gold standard for evaluating terminology translation in MT. We also propose an error typology taking the terminology translation errors into consideration. We evaluate the MT systems&#8217; performance on terminology translation, and demonstrate our findings, unraveling strengths, weaknesses, and similarities of PB-SMT and NMT in the area of term translation.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1265.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1265 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1265 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-1265/>Tailoring Neural Architectures for Translating from Morphologically Rich Languages</a></strong><br><a href=/people/p/peyman-passban/>Peyman Passban</a>
|
<a href=/people/a/andy-way/>Andy Way</a>
|
<a href=/people/q/qun-liu/>Qun Liu</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1265><div class="card-body p-3 small">A morphologically complex word (MCW) is a hierarchical constituent with meaning-preserving subunits, so word-based models which rely on surface forms might not be powerful enough to translate such structures. When translating from morphologically rich languages (MRLs), a source word could be mapped to several words or even a full sentence on the target side, which means an MCW should not be treated as an atomic unit. In order to provide better translations for <a href=https://en.wikipedia.org/wiki/Machine_translation>MRLs</a>, we boost the existing neural machine translation (NMT) architecture with a double- channel encoder and a double-attentive decoder. The main goal targeted in this research is to provide richer information on the encoder side and redesign the decoder accordingly to benefit from such information. Our experimental results demonstrate that we could achieve our goal as the proposed model outperforms existing subword- and character-based architectures and showed significant improvements on translating from <a href=https://en.wikipedia.org/wiki/German_language>German</a>, <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a>, and <a href=https://en.wikipedia.org/wiki/Turkish_language>Turkish</a> into <a href=https://en.wikipedia.org/wiki/English_language>English</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1321.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1321 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1321 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-1321/>Incorporating <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Visual Features</a> into Multiobjective based Multi-view Search Results Clustering</a></strong><br><a href=/people/s/sayantan-mitra/>Sayantan Mitra</a>
|
<a href=/people/m/mohammed-hasanuzzaman/>Mohammed Hasanuzzaman</a>
|
<a href=/people/s/sriparna-saha/>Sriparna Saha</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1321><div class="card-body p-3 small">Current paper explores the use of multi-view learning for search result clustering. A web-snippet can be represented using multiple views. Apart from textual view cued by both the semantic and syntactic information, a complimentary view extracted from images contained in the web-snippets is also utilized in the current framework. A single consensus partitioning is finally obtained after consulting these two individual views by the deployment of a multiobjective based clustering technique. Several objective functions including the values of a cluster quality measure measuring the goodness of partitionings obtained using different views and an agreement-disagreement index, quantifying the amount of oneness among multiple views in generating <a href=https://en.wikipedia.org/wiki/Partition_of_a_set>partitionings</a> are optimized simultaneously using AMOSA. In order to detect the number of clusters automatically, concepts of variable length solutions and a vast range of permutation operators are introduced in the clustering process. Finally, a set of alternative partitioning are obtained on the final Pareto front by the proposed multi-view based multiobjective technique. Experimental results by the proposed approach on several benchmark test datasets of SRC with respect to different performance metrics evidently establish the power of visual and text-based views in achieving better search result clustering.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1245.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1245 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1245 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1245/>Multi-Level Structured Self-Attentions for Distantly Supervised Relation Extraction</a></strong><br><a href=/people/j/jinhua-du/>Jinhua Du</a>
|
<a href=/people/j/jingguang-han/>Jingguang Han</a>
|
<a href=/people/a/andy-way/>Andy Way</a>
|
<a href=/people/d/dadong-wan/>Dadong Wan</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1245><div class="card-body p-3 small">Attention mechanism is often used in <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural networks</a> for distantly supervised relation extraction (DS-RE) to distinguish valid from noisy instances. However, traditional 1-D vector attention model is insufficient for learning of different contexts in the selection of valid instances to predict the relationship for an entity pair. To alleviate this issue, we propose a novel multi-level structured (2-D matrix) self-attention mechanism for DS-RE in a multi-instance learning (MIL) framework using bidirectional recurrent neural networks (BiRNN). In the proposed method, a structured word-level self-attention learns a <a href=https://en.wikipedia.org/wiki/Matrix_(mathematics)>2-D matrix</a> where each row vector represents a <a href=https://en.wikipedia.org/wiki/Weight_distribution>weight distribution</a> for different aspects of an instance regarding two entities. Targeting the MIL issue, the structured sentence-level attention learns a <a href=https://en.wikipedia.org/wiki/Matrix_(mathematics)>2-D matrix</a> where each row vector represents a <a href=https://en.wikipedia.org/wiki/Weight_distribution>weight distribution</a> on selection of different valid instances. Experiments conducted on two publicly available DS-RE datasets show that the proposed framework with multi-level structured self-attention mechanism significantly outperform baselines in terms of PR curves, P@N and F1 measures.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1334.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1334 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1334 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1334/>Getting Gender Right in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a></a></strong><br><a href=/people/e/eva-vanmassenhove/>Eva Vanmassenhove</a>
|
<a href=/people/c/christian-hardmeier/>Christian Hardmeier</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1334><div class="card-body p-3 small">Speakers of different languages must attend to and encode strikingly different aspects of the world in order to use their language correctly (Sapir, 1921 ; Slobin, 1996). One such difference is related to the way gender is expressed in a language. Saying I am happy in English, does not encode any additional knowledge of the speaker that uttered the sentence. However, many other languages do have <a href=https://en.wikipedia.org/wiki/Grammatical_gender>grammatical gender systems</a> and so such knowledge would be encoded. In order to correctly translate such a sentence into, say, <a href=https://en.wikipedia.org/wiki/French_language>French</a>, the inherent gender information needs to be retained / recovered. The same sentence would become either Je suis heureux, for a male speaker or Je suis heureuse for a female one. Apart from <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphological agreement</a>, <a href=https://en.wikipedia.org/wiki/Demography>demographic factors</a> (gender, age, etc.) also influence our use of language in terms of word choices or syntactic constructions (Tannen, 1991 ; Pennebaker et al., 2003). We integrate <a href=https://en.wikipedia.org/wiki/Gender>gender information</a> into <a href=https://en.wikipedia.org/wiki/Network_topology>NMT systems</a>. Our contribution is two-fold : (1) the compilation of large datasets with speaker information for 20 language pairs, and (2) a simple set of experiments that incorporate gender information into NMT for multiple language pairs. Our experiments show that adding a gender feature to an NMT system significantly improves the translation quality for some language pairs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1006 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276415442 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1006/>Improving Character-Based Decoding Using Target-Side Morphological Information for Neural Machine Translation</a></strong><br><a href=/people/p/peyman-passban/>Peyman Passban</a>
|
<a href=/people/q/qun-liu/>Qun Liu</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1006><div class="card-body p-3 small">Recently, neural machine translation (NMT) has emerged as a powerful alternative to conventional statistical approaches. However, its performance drops considerably in the presence of morphologically rich languages (MRLs). Neural engines usually fail to tackle the large vocabulary and high out-of-vocabulary (OOV) word rate of MRLs. Therefore, it is not suitable to exploit existing word-based models to translate this set of languages. In this paper, we propose an extension to the state-of-the-art model of Chung et al. (2016), which works at the character level and boosts the decoder with target-side morphological information. In our <a href=https://en.wikipedia.org/wiki/Architecture>architecture</a>, an additional morphology table is plugged into the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>. Each time the <a href=https://en.wikipedia.org/wiki/Encoder>decoder</a> samples from a target vocabulary, the table sends auxiliary signals from the most relevant <a href=https://en.wikipedia.org/wiki/Affix>affixes</a> in order to enrich the <a href=https://en.wikipedia.org/wiki/Encoder>decoder</a>&#8217;s current state and constrain it to provide better predictions. We evaluated our model to translate <a href=https://en.wikipedia.org/wiki/English_language>English</a> into <a href=https://en.wikipedia.org/wiki/German_language>German</a>, <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a>, and <a href=https://en.wikipedia.org/wiki/Turkish_language>Turkish</a> as three MRLs and observed significant improvements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-3010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-3010 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-3010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-3010/>SuperNMT : <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> with Semantic Supersenses and Syntactic Supertags<span class=acl-fixed-case>S</span>uper<span class=acl-fixed-case>NMT</span>: Neural Machine Translation with Semantic Supersenses and Syntactic Supertags</a></strong><br><a href=/people/e/eva-vanmassenhove/>Eva Vanmassenhove</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/P18-3/ class=text-muted>Proceedings of ACL 2018, Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-3010><div class="card-body p-3 small">In this paper we incorporate semantic supersensetags and syntactic supertag features into ENFR and ENDE factored NMT systems. In experiments on various test sets, we observe that such <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> (and particularly when combined) help the NMT model training to converge faster and improve the model quality according to the BLEU scores.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2018--iwslt-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2018.iwslt-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2018.iwslt-1.11/>The ADAPT System Description for the IWSLT 2018 Basque to English Translation Task<span class=acl-fixed-case>ADAPT</span> System Description for the <span class=acl-fixed-case>IWSLT</span> 2018 <span class=acl-fixed-case>B</span>asque to <span class=acl-fixed-case>E</span>nglish Translation Task</a></strong><br><a href=/people/a/alberto-poncelas/>Alberto Poncelas</a>
|
<a href=/people/a/andy-way/>Andy Way</a>
|
<a href=/people/k/kepa-sarasola/>Kepa Sarasola</a><br><a href=/volumes/2018.iwslt-1/ class=text-muted>Proceedings of the 15th International Conference on Spoken Language Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2018--iwslt-1--11><div class="card-body p-3 small">In this paper we present the ADAPT system built for the Basque to English Low Resource MT Evaluation Campaign. Basque is a low-resourced, morphologically-rich language. This poses a challenge for Neural Machine Translation models which usually achieve better performance when trained with large sets of data. Accordingly, we used <a href=https://en.wikipedia.org/wiki/Synthetic_data>synthetic data</a> to improve the translation quality produced by a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> built using only authentic data. Our proposal uses back-translated data to : (a) create new sentences, so the system can be trained with more data ; and (b) translate sentences that are close to the test set, so the model can be fine-tuned to the document to be translated.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.26.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2018--iwslt-1--26 data-toggle=collapse aria-expanded=false aria-controls=abstract-2018.iwslt-1.26 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2018.iwslt-1.26/>Data Selection with Feature Decay Algorithms Using an Approximated Target Side</a></strong><br><a href=/people/a/alberto-poncelas/>Alberto Poncelas</a>
|
<a href=/people/g/gideon-maillette-de-buy-wenniger/>Gideon Maillette de Buy Wenniger</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/2018.iwslt-1/ class=text-muted>Proceedings of the 15th International Conference on Spoken Language Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2018--iwslt-1--26><div class="card-body p-3 small">Data selection techniques applied to neural machine translation (NMT) aim to increase the performance of a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> by retrieving a subset of sentences for use as training data. One of the possible data selection techniques are <a href=https://en.wikipedia.org/wiki/Transduction_(machine_learning)>transductive learning methods</a>, which select the data based on the test set, i.e. the document to be translated. A limitation of these methods to date is that using the source-side test set does not by itself guarantee that sentences are selected with correct translations, or translations that are suitable given the test-set domain. Some <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a>, such as subtitle corpora, may contain parallel sentences with inaccurate translations caused by <a href=https://en.wikipedia.org/wiki/Internationalization_and_localization>localization</a> or length restrictions. In order to try to fix this problem, in this paper we propose to use an approximated target-side in addition to the source-side when selecting suitable sentence-pairs for training a model. This approximated target-side is built by pre-translating the source-side. In this work, we explore the performance of this general idea for one specific data selection approach called Feature Decay Algorithms (FDA). We train German-English NMT models on data selected by using the test set (source), the approximated target side, and a mixture of both. Our findings reveal that <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> built using a combination of outputs of <a href=https://en.wikipedia.org/wiki/Food_and_Drug_Administration>FDA</a> (using the <a href=https://en.wikipedia.org/wiki/Test_set>test set</a> and an approximated target side) perform better than those solely using the <a href=https://en.wikipedia.org/wiki/Test_set>test set</a>.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-1093.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-1093 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-1093 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-1093/>Demographic Word Embeddings for Racism Detection on Twitter<span class=acl-fixed-case>T</span>witter</a></strong><br><a href=/people/m/mohammed-hasanuzzaman/>Mohammed Hasanuzzaman</a>
|
<a href=/people/g/gael-dias/>Gaël Dias</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/I17-1/ class=text-muted>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-1093><div class="card-body p-3 small">Most <a href=https://en.wikipedia.org/wiki/Social_media>social media platforms</a> grant users freedom of speech by allowing them to freely express their thoughts, beliefs, and opinions. Although this represents incredible and unique communication opportunities, it also presents important challenges. Online racism is such an example. In this study, we present a supervised learning strategy to detect racist language on <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> based on <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a> that incorporate demographic (Age, Gender, and Location) information. Our <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> achieves reasonable <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification accuracy</a> over a gold standard dataset (F1=76.3 %) and significantly improves over the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance of demographic-agnostic models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-3009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-3009 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-3009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-3009/>Semantics-Enhanced Task-Oriented Dialogue Translation : A Case Study on Hotel Booking</a></strong><br><a href=/people/l/longyue-wang/>Longyue Wang</a>
|
<a href=/people/j/jinhua-du/>Jinhua Du</a>
|
<a href=/people/l/liangyou-li/>Liangyou Li</a>
|
<a href=/people/z/zhaopeng-tu/>Zhaopeng Tu</a>
|
<a href=/people/a/andy-way/>Andy Way</a>
|
<a href=/people/q/qun-liu/>Qun Liu</a><br><a href=/volumes/I17-3/ class=text-muted>Proceedings of the IJCNLP 2017, System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-3009><div class="card-body p-3 small">We showcase TODAY, a semantics-enhanced task-oriented dialogue translation system, whose novelties are : (i) task-oriented named entity (NE) definition and a hybrid strategy for NE recognition and <a href=https://en.wikipedia.org/wiki/Translation>translation</a> ; and (ii) a novel grounded semantic method for dialogue understanding and task-order management. TODAY is a case-study demo which can efficiently and accurately assist customers and agents in different languages to reach an agreement in a dialogue for the hotel booking.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-4027.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-4027 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-4027 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-4027/>ADAPT at IJCNLP-2017 Task 4 : A Multinomial Naive Bayes Classification Approach for Customer Feedback Analysis task<span class=acl-fixed-case>ADAPT</span> at <span class=acl-fixed-case>IJCNLP</span>-2017 Task 4: A Multinomial Naive <span class=acl-fixed-case>B</span>ayes Classification Approach for Customer Feedback Analysis task</a></strong><br><a href=/people/p/pintu-lohar/>Pintu Lohar</a>
|
<a href=/people/k/koel-dutta-chowdhury/>Koel Dutta Chowdhury</a>
|
<a href=/people/h/haithem-afli/>Haithem Afli</a>
|
<a href=/people/m/mohammed-hasanuzzaman/>Mohammed Hasanuzzaman</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/I17-4/ class=text-muted>Proceedings of the IJCNLP 2017, Shared Tasks</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-4027><div class="card-body p-3 small">In this age of the digital economy, promoting organisations attempt their best to engage the customers in the feedback provisioning process. With the assistance of customer insights, an organisation can develop a better product and provide a better service to its customer. In this paper, we analyse the real world samples of customer feedback from Microsoft Office customers in four languages, i.e., <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/French_language>French</a>, <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a> and <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> and conclude a five-plus-one-classes categorisation (comment, request, bug, complaint, meaningless and undetermined) for meaning classification. The task is to % access multilingual corpora annotated by the proposed meaning categorization scheme and develop a system to determine what class(es) the customer feedback sentences should be annotated as in four languages. We propose following approaches to accomplish this task : (i) a multinomial naive bayes (MNB) approach for multi-label classification, (ii) MNB with one-vs-rest classifier approach, and (iii) the combination of the multilabel classification-based and the sentiment classification-based approach. Our best system produces <a href=https://en.wikipedia.org/wiki/F-score>F-scores</a> of 0.67, 0.83, 0.72 and 0.7 for <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, <a href=https://en.wikipedia.org/wiki/French_language>French</a> and <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>, respectively. The results are competitive to the best ones for all languages and secure 3rd and 5th position for <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> and <a href=https://en.wikipedia.org/wiki/French_language>French</a>, respectively, among all submitted systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1313.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1313 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1313 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1313/>Identifying Effective Translations for Cross-lingual Arabic-to-English User-generated Speech Search<span class=acl-fixed-case>A</span>rabic-to-<span class=acl-fixed-case>E</span>nglish User-generated Speech Search</a></strong><br><a href=/people/a/ahmad-khwileh/>Ahmad Khwileh</a>
|
<a href=/people/h/haithem-afli/>Haithem Afli</a>
|
<a href=/people/g/gareth-jones/>Gareth Jones</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/W17-13/ class=text-muted>Proceedings of the Third Arabic Natural Language Processing Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1313><div class="card-body p-3 small">Cross Language Information Retrieval (CLIR) systems are a valuable tool to enable speakers of one language to search for content of interest expressed in a different language. A group for whom this is of particular interest is bilingual Arabic speakers who wish to search for English language content using information needs expressed in Arabic queries. A key challenge in <a href=https://en.wikipedia.org/wiki/CLIR>CLIR</a> is crossing the language barrier between the query and the documents. The most common approach to bridging this gap is automated query translation, which can be unreliable for vague or short queries. In this work, we examine the potential for improving CLIR effectiveness by predicting the translation effectiveness using Query Performance Prediction (QPP) techniques. We propose a novel QPP method to estimate the quality of translation for an Arabic-English Cross-lingual User-generated Speech Search (CLUGS) task. We present an empirical evaluation that demonstrates the quality of our method on alternative translation outputs extracted from an Arabic-to-English Machine Translation system developed for this task. Finally, we show how this <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> can be integrated in CLUGS to find relevant translations for improved retrieval performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1608.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1608 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1608 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1608/>Ethical Considerations in NLP Shared Tasks<span class=acl-fixed-case>NLP</span> Shared Tasks</a></strong><br><a href=/people/c/carla-parra-escartin/>Carla Parra Escartín</a>
|
<a href=/people/w/wessel-reijers/>Wessel Reijers</a>
|
<a href=/people/t/teresa-lynn/>Teresa Lynn</a>
|
<a href=/people/j/joss-moorkens/>Joss Moorkens</a>
|
<a href=/people/a/andy-way/>Andy Way</a>
|
<a href=/people/c/chao-hong-liu/>Chao-Hong Liu</a><br><a href=/volumes/W17-16/ class=text-muted>Proceedings of the First ACL Workshop on Ethics in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1608><div class="card-body p-3 small">Shared tasks are increasingly common in our field, and new challenges are suggested at almost every conference and workshop. However, as this has become an established way of pushing research forward, it is important to discuss how we researchers organise and participate in shared tasks, and make that information available to the community to allow further research improvements. In this paper, we present a number of <a href=https://en.wikipedia.org/wiki/Ethics>ethical issues</a> along with other areas of concern that are related to the competitive nature of shared tasks. As such issues could potentially impact on research ethics in the Natural Language Processing community, we also propose the development of a framework for the organisation of and participation in shared tasks that can help mitigate against these issues arising.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2004 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2004/>Human Evaluation of Multi-modal Neural Machine Translation : A Case-Study on E-Commerce Listing Titles<span class=acl-fixed-case>E</span>-Commerce Listing Titles</a></strong><br><a href=/people/i/iacer-calixto/>Iacer Calixto</a>
|
<a href=/people/d/daniel-stein/>Daniel Stein</a>
|
<a href=/people/e/evgeny-matusov/>Evgeny Matusov</a>
|
<a href=/people/s/sheila-castilho/>Sheila Castilho</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/W17-20/ class=text-muted>Proceedings of the Sixth Workshop on Vision and Language</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2004><div class="card-body p-3 small">In this paper, we study how humans perceive the use of <a href=https://en.wikipedia.org/wiki/Digital_image>images</a> as an additional knowledge source to machine-translate <a href=https://en.wikipedia.org/wiki/User-generated_content>user-generated product listings</a> in an <a href=https://en.wikipedia.org/wiki/E-commerce>e-commerce company</a>. We conduct a human evaluation where we assess how a multi-modal neural machine translation (NMT) model compares to two text-only approaches : a conventional state-of-the-art attention-based NMT and a phrase-based statistical machine translation (PBSMT) model. We evaluate translations obtained with different systems and also discuss the data set of user-generated product listings, which in our case comprises both product listings and associated images. We found that humans preferred translations obtained with a PBSMT system to both text-only and multi-modal NMT over 56 % of the time. Nonetheless, human evaluators ranked translations from a multi-modal NMT model as better than those of a text-only NMT over 88 % of the time, which suggests that <a href=https://en.wikipedia.org/wiki/Digital_image>images</a> do help <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NMT</a> in this use-case.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-2101.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-2101 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-2101 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-2101/>Using Images to Improve Machine-Translating E-Commerce Product Listings.<span class=acl-fixed-case>E</span>-Commerce Product Listings.</a></strong><br><a href=/people/i/iacer-calixto/>Iacer Calixto</a>
|
<a href=/people/d/daniel-stein/>Daniel Stein</a>
|
<a href=/people/e/evgeny-matusov/>Evgeny Matusov</a>
|
<a href=/people/p/pintu-lohar/>Pintu Lohar</a>
|
<a href=/people/s/sheila-castilho/>Sheila Castilho</a>
|
<a href=/people/a/andy-way/>Andy Way</a><br><a href=/volumes/E17-2/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-2101><div class="card-body p-3 small">In this paper we study the impact of using <a href=https://en.wikipedia.org/wiki/Digital_image>images</a> to machine-translate user-generated e-commerce product listings. We study how a multi-modal Neural Machine Translation (NMT) model compares to two text-only approaches : a conventional state-of-the-art attentional NMT and a Statistical Machine Translation (SMT) model. User-generated product listings often do not constitute <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>grammatical or well-formed sentences</a>. More often than not, they consist of the juxtaposition of short phrases or <a href=https://en.wikipedia.org/wiki/Index_term>keywords</a>. We train our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> end-to-end as well as use text-only and multi-modal NMT models for re-ranking n-best lists generated by an SMT model. We qualitatively evaluate our user-generated training data also analyse how adding synthetic data impacts the results. We evaluate our models quantitatively using BLEU and TER and find that (i) additional synthetic data has a general positive impact on text-only and multi-modal NMT models, and that (ii) using a multi-modal NMT model for re-ranking n-best lists improves TER significantly across different n-best list sizes.<tex-math>n</tex-math>-best lists generated by an SMT model. We qualitatively evaluate our user-generated training data also analyse how adding synthetic data impacts the results. We evaluate our models quantitatively using BLEU and TER and find that (i) additional synthetic data has a general positive impact on text-only and multi-modal NMT models, and that (ii) using a multi-modal NMT model for re-ranking n-best lists improves TER significantly across different n-best list sizes.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Andy+Way" title="Search for 'Andy Way' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/r/rejwanul-haque/ class=align-middle>Rejwanul Haque</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/s/sheila-castilho/ class=align-middle>Sheila Castilho</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/q/qun-liu/ class=align-middle>Qun Liu</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/mohammed-hasanuzzaman/ class=align-middle>Mohammed Hasanuzzaman</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/h/haithem-afli/ class=align-middle>Haithem Afli</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/a/alberto-poncelas/ class=align-middle>Alberto Poncelas</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/n/natalia-resende/ class=align-middle>Natália Resende</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/akshai-ramesh/ class=align-middle>Akshai Ramesh</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/f/federico-gaspari/ class=align-middle>Federico Gaspari</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/peyman-passban/ class=align-middle>Peyman Passban</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jinhua-du/ class=align-middle>Jinhua Du</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/pintu-lohar/ class=align-middle>Pintu Lohar</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/i/iacer-calixto/ class=align-middle>Iacer Calixto</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/daniel-stein/ class=align-middle>Daniel Stein</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/evgeny-matusov/ class=align-middle>Evgeny Matusov</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/james-hadley/ class=align-middle>James Hadley</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/eva-vanmassenhove/ class=align-middle>Eva Vanmassenhove</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mikel-l-forcada/ class=align-middle>Mikel L. Forcada</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/kamal-kumar-gupta/ class=align-middle>Kamal Kumar Gupta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/asif-ekbal/ class=align-middle>Asif Ekbal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pushpak-bhattacharyya/ class=align-middle>Pushpak Bhattacharyya</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/seamus-lankford/ class=align-middle>Seamus Lankford</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haithem-alfi/ class=align-middle>Haithem Alfi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/roisin-moran/ class=align-middle>Róisín Moran</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/carla-para-escartin/ class=align-middle>Carla Para Escartín</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paraic-sheridan/ class=align-middle>Páraic Sheridan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jane-dunne/ class=align-middle>Jane Dunne</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sayantan-mitra/ class=align-middle>Sayantan Mitra</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sriparna-saha/ class=align-middle>Sriparna Saha</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gael-dias/ class=align-middle>Gaël Dias</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/longyue-wang/ class=align-middle>Longyue Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/liangyou-li/ class=align-middle>Liangyou Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhaopeng-tu/ class=align-middle>Zhaopeng Tu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/koel-dutta-chowdhury/ class=align-middle>Koel Dutta Chowdhury</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ahmad-khwileh/ class=align-middle>Ahmad Khwileh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gareth-jones/ class=align-middle>Gareth Jones</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/carla-parra-escartin/ class=align-middle>Carla Parra Escartín</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wessel-reijers/ class=align-middle>Wessel Reijers</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/teresa-lynn/ class=align-middle>Teresa Lynn</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joss-moorkens/ class=align-middle>Joss Moorkens</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chao-hong-liu/ class=align-middle>Chao-Hong Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mohammad-aboomar/ class=align-middle>Mohammad Aboomar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jan-buts/ class=align-middle>Jan Buts</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jingguang-han/ class=align-middle>Jingguang Han</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dadong-wan/ class=align-middle>Dadong Wan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christian-hardmeier/ class=align-middle>Christian Hardmeier</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joao-lucas-cavalheiro-camargo/ class=align-middle>João Lucas Cavalheiro Camargo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/miguel-menezes/ class=align-middle>Miguel Menezes</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/barry-haddow/ class=align-middle>Barry Haddow</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rico-sennrich/ class=align-middle>Rico Sennrich</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/john-tinsley/ class=align-middle>John Tinsley</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dimitar-shterionov/ class=align-middle>Dimitar Shterionov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/celia-rico/ class=align-middle>Celia Rico</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maja-popovic/ class=align-middle>Maja Popović</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wandri-jooste/ class=align-middle>Wandri Jooste</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/georg-rehm/ class=align-middle>Georg Rehm</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/katrin-marheinecke/ class=align-middle>Katrin Marheinecke</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stefanie-hegele/ class=align-middle>Stefanie Hegele</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stelios-piperidis/ class=align-middle>Stelios Piperidis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kalina-bontcheva/ class=align-middle>Kalina Bontcheva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jan-hajic/ class=align-middle>Jan Hajic</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/khalid-choukri/ class=align-middle>Khalid Choukri</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrejs-vasiljevs/ class=align-middle>Andrejs Vasiļjevs</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gerhard-backfried/ class=align-middle>Gerhard Backfried</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christoph-prinz/ class=align-middle>Christoph Prinz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jose-manuel-gomez-perez/ class=align-middle>José Manuel Gómez-Pérez</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luc-meertens/ class=align-middle>Luc Meertens</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paul-lukowicz/ class=align-middle>Paul Lukowicz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/josef-van-genabith/ class=align-middle>Josef van Genabith</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrea-losch/ class=align-middle>Andrea Lösch</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/philipp-slusallek/ class=align-middle>Philipp Slusallek</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/morten-irgens/ class=align-middle>Morten Irgens</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/patrick-gatellier/ class=align-middle>Patrick Gatellier</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joachim-kohler/ class=align-middle>Joachim Köhler</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/laure-le-bars/ class=align-middle>Laure Le Bars</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dimitra-anastasiou/ class=align-middle>Dimitra Anastasiou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/albina-auksoriute/ class=align-middle>Albina Auksoriūtė</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nuria-bel/ class=align-middle>Núria Bel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/antonio-branco/ class=align-middle>António Branco</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gerhard-budin/ class=align-middle>Gerhard Budin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/walter-daelemans/ class=align-middle>Walter Daelemans</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/koenraad-de-smedt/ class=align-middle>Koenraad De Smedt</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/radovan-garabik/ class=align-middle>Radovan Garabík</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maria-gavriilidou/ class=align-middle>Maria Gavriilidou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dagmar-gromann/ class=align-middle>Dagmar Gromann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/svetla-koeva/ class=align-middle>Svetla Koeva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/simon-krek/ class=align-middle>Simon Krek</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cvetana-krstev/ class=align-middle>Cvetana Krstev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/krister-linden/ class=align-middle>Krister Lindén</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bernardo-magnini/ class=align-middle>Bernardo Magnini</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jan-odijk/ class=align-middle>Jan Odijk</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maciej-ogrodniczuk/ class=align-middle>Maciej Ogrodniczuk</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eirikur-rognvaldsson/ class=align-middle>Eirikur Rögnvaldsson</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-rosner/ class=align-middle>Michael Rosner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bolette-sandford-pedersen/ class=align-middle>Bolette Sandford Pedersen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/inguna-skadina/ class=align-middle>Inguna Skadiņa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marko-tadic/ class=align-middle>Marko Tadić</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dan-tufis/ class=align-middle>Dan Tufiş</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tamas-varadi/ class=align-middle>Tamás Váradi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kadri-vider/ class=align-middle>Kadri Vider</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/francois-yvon/ class=align-middle>François Yvon</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/md-hasanuzzaman/ class=align-middle>Md Hasanuzzaman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/venkatesh-balavadhani-parthasa/ class=align-middle>Venkatesh Balavadhani parthasa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yasmin-moslem/ class=align-middle>Yasmin Moslem</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kepa-sarasola/ class=align-middle>Kepa Sarasola</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gideon-maillette-de-buy-wenniger/ class=align-middle>Gideon Maillette de Buy Wenniger</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/eamt/ class=align-middle>EAMT</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/mtsummit/ class=align-middle>MTSummit</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/iwslt/ class=align-middle>IWSLT</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/lt4hala/ class=align-middle>LT4HALA</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wmt/ class=align-middle>WMT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wat/ class=align-middle>WAT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ranlp/ class=align-middle>RANLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/loresmt/ class=align-middle>loresmt</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ngt/ class=align-middle>NGT</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>