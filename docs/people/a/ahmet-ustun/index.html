<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Ahmet Üstün - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Ahmet</span> <span class=font-weight-bold>Üstün</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-demos.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-demos--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-demos.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.eacl-demos.22" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-demos.22/>Massive Choice, Ample Tasks (MaChAmp): A Toolkit for Multi-task Learning in NLP<span class=acl-fixed-case>M</span>a<span class=acl-fixed-case>C</span>h<span class=acl-fixed-case>A</span>mp): A Toolkit for Multi-task Learning in <span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/r/rob-van-der-goot/>Rob van der Goot</a>
|
<a href=/people/a/ahmet-ustun/>Ahmet Üstün</a>
|
<a href=/people/a/alan-ramponi/>Alan Ramponi</a>
|
<a href=/people/i/ibrahim-sharaf/>Ibrahim Sharaf</a>
|
<a href=/people/b/barbara-plank/>Barbara Plank</a><br><a href=/volumes/2021.eacl-demos/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-demos--22><div class="card-body p-3 small">Transfer learning, particularly approaches that combine <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a> with pre-trained contextualized embeddings and <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a>, have advanced the field of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a> tremendously in recent years. In this paper we present MaChAmp, a toolkit for easy fine-tuning of contextualized embeddings in multi-task settings. The benefits of MaChAmp are its flexible configuration options, and the support of a variety of natural language processing tasks in a uniform toolkit, from text classification and sequence labeling to dependency parsing, masked language modeling, and text generation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.197.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--197 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.197 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.197" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.197/>From Masked Language Modeling to <a href=https://en.wikipedia.org/wiki/Translation>Translation</a> : Non-English Auxiliary Tasks Improve Zero-shot Spoken Language Understanding<span class=acl-fixed-case>E</span>nglish Auxiliary Tasks Improve Zero-shot Spoken Language Understanding</a></strong><br><a href=/people/r/rob-van-der-goot/>Rob van der Goot</a>
|
<a href=/people/i/ibrahim-sharaf/>Ibrahim Sharaf</a>
|
<a href=/people/a/aizhan-imankulova/>Aizhan Imankulova</a>
|
<a href=/people/a/ahmet-ustun/>Ahmet Üstün</a>
|
<a href=/people/m/marija-stepanovic/>Marija Stepanović</a>
|
<a href=/people/a/alan-ramponi/>Alan Ramponi</a>
|
<a href=/people/s/siti-oryza-khairunnisa/>Siti Oryza Khairunnisa</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a>
|
<a href=/people/b/barbara-plank/>Barbara Plank</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--197><div class="card-body p-3 small">The lack of publicly available evaluation data for low-resource languages limits progress in Spoken Language Understanding (SLU). As key tasks like intent classification and slot filling require abundant training data, it is desirable to reuse existing <a href=https://en.wikipedia.org/wiki/Data>data</a> in high-resource languages to develop models for low-resource scenarios. We introduce xSID, a new benchmark for cross-lingual (x) Slot and Intent Detection in 13 languages from 6 language families, including a very low-resource dialect. To tackle the challenge, we propose a joint learning approach, with English SLU training data and non-English auxiliary tasks from raw text, <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> and <a href=https://en.wikipedia.org/wiki/Translation>translation</a> for transfer. We study two setups which differ by type and language coverage of the pre-trained embeddings. Our results show that jointly learning the main tasks with masked language modeling is effective for slots, while machine translation transfer works best for intent classification.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1140.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1140 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1140 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1140/>Cross-Lingual Word Embeddings for Morphologically Rich Languages</a></strong><br><a href=/people/a/ahmet-ustun/>Ahmet Üstün</a>
|
<a href=/people/g/gosse-bouma/>Gosse Bouma</a>
|
<a href=/people/g/gertjan-van-noord/>Gertjan van Noord</a><br><a href=/volumes/R19-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1140><div class="card-body p-3 small">Cross-lingual word embedding models learn a shared vector space for two or more languages so that words with similar meaning are represented by similar vectors regardless of their language. Although the existing models achieve high performance on pairs of morphologically simple languages, they perform very poorly on morphologically rich languages such as <a href=https://en.wikipedia.org/wiki/Turkish_language>Turkish</a> and <a href=https://en.wikipedia.org/wiki/Finnish_language>Finnish</a>. In this paper, we propose a morpheme-based model in order to increase the performance of cross-lingual word embeddings on morphologically rich languages. Our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> includes a simple extension which enables us to exploit <a href=https://en.wikipedia.org/wiki/Morpheme>morphemes</a> for cross-lingual mapping. We applied our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> for the <a href=https://en.wikipedia.org/wiki/Finnish_language>Turkish-Finnish language pair</a> on the bilingual word translation task. Results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms the baseline models by 2 % in the <a href=https://en.wikipedia.org/wiki/Nearest_neighbour_search>nearest neighbour ranking</a>.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3019.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3019 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3019 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W18-3019.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W18-3019/>Characters or <a href=https://en.wikipedia.org/wiki/Morphemes>Morphemes</a> : How to Represent Words?</a></strong><br><a href=/people/a/ahmet-ustun/>Ahmet Üstün</a>
|
<a href=/people/m/murathan-kurfali/>Murathan Kurfalı</a>
|
<a href=/people/b/burcu-can/>Burcu Can</a><br><a href=/volumes/W18-30/ class=text-muted>Proceedings of The Third Workshop on Representation Learning for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3019><div class="card-body p-3 small">In this paper, we investigate the effects of using subword information in <a href=https://en.wikipedia.org/wiki/Representation_learning>representation learning</a>. We argue that using syntactic subword units effects the quality of the word representations positively. We introduce a morpheme-based model and compare it against to word-based, character-based, and character n-gram level models. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> takes a list of candidate segmentations of a word and learns the representation of the word based on different segmentations that are weighted by an <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanism</a>. We performed experiments on <a href=https://en.wikipedia.org/wiki/Turkish_language>Turkish</a> as a morphologically rich language and <a href=https://en.wikipedia.org/wiki/English_language>English</a> with a comparably poorer morphology. The results show that morpheme-based models are better at learning word representations of morphologically complex languages compared to character-based and character n-gram level models since the morphemes help to incorporate more syntactic knowledge in learning, that makes morpheme-based models better at syntactic tasks.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Ahmet+%C3%9Cst%C3%BCn" title="Search for 'Ahmet Üstün' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/r/rob-van-der-goot/ class=align-middle>Rob van der Goot</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/alan-ramponi/ class=align-middle>Alan Ramponi</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/i/ibrahim-sharaf/ class=align-middle>Ibrahim Sharaf</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/barbara-plank/ class=align-middle>Barbara Plank</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/aizhan-imankulova/ class=align-middle>Aizhan Imankulova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/m/marija-stepanovic/ class=align-middle>Marija Stepanović</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/siti-oryza-khairunnisa/ class=align-middle>Siti Oryza Khairunnisa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mamoru-komachi/ class=align-middle>Mamoru Komachi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/murathan-kurfali/ class=align-middle>Murathan Kurfalı</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/burcu-can/ class=align-middle>Burcu Can</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gosse-bouma/ class=align-middle>Gosse Bouma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gertjan-van-noord/ class=align-middle>Gertjan van Noord</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ranlp/ class=align-middle>RANLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>