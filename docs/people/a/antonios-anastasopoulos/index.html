<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Antonios Anastasopoulos - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Antonios</span> <span class=font-weight-bold>Anastasopoulos</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.239.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--239 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.239 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.239/>Dataset Geography Mapping Language Data to Language Users</a></strong><br><a href=/people/f/fahim-faisal/>Fahim Faisal</a>
|
<a href=/people/y/yinkai-wang/>Yinkai Wang</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--239><div class="card-body p-3 small">As language technologies become more ubiquitous there are increasing efforts towards expanding the <a href=https://en.wikipedia.org/wiki/Language_diversity>language diversity</a> and coverage of natural language processing NLP systems Arguably the most important factor influencing the quality of modern NLP systems is data availability In this work we study the geographical representativeness of NLP datasets aiming to quantify if and by how much do NLP datasets match the expected needs of the language speakers In doing so we use entity recognition and linking systems also making important observations about their cross lingual consistency and giving suggestions for more robust evaluation Last we explore some geographical and economic factors that may explain the observed dataset distributions</div></div><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mrqa-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mrqa-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mrqa-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mrqa-1.14/>Investigating Post-pretraining Representation Alignment for Cross-Lingual Question Answering</a></strong><br><a href=/people/f/fahim-faisal/>Fahim Faisal</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a><br><a href=/volumes/2021.mrqa-1/ class=text-muted>Proceedings of the 3rd Workshop on Machine Reading for Question Answering</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mrqa-1--14><div class="card-body p-3 small">Human knowledge is collectively encoded in the roughly 6500 languages spoken around the world, but <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> is not distributed equally across languages. Hence, for information-seeking question answering (QA) systems to adequately serve speakers of all languages, they need to operate cross-lingually. In this work we investigate the capabilities of multilingually pretrained language models on cross-lingual QA. We find that explicitly aligning the <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representations</a> across languages with a post-hoc finetuning step generally leads to improved performance. We additionally investigate the effect of data size as well as the language choice in this fine-tuning step, also releasing a dataset for evaluating cross-lingual QA systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.553.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--553 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.553 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.553/>When is Wall a Pared and when a Muro? : Extracting Rules Governing Lexical Selection</a></strong><br><a href=/people/a/aditi-chaudhary/>Aditi Chaudhary</a>
|
<a href=/people/k/kayo-yin/>Kayo Yin</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--553><div class="card-body p-3 small">Learning fine-grained distinctions between vocabulary items is a key challenge in learning a new language. For example, the noun wall has different lexical manifestations in <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a> pared refers to an indoor wall while muro refers to an outside wall. However, this variety of lexical distinction may not be obvious to non-native learners unless the distinction is explained in such a way. In this work, we present a method for automatically identifying fine-grained lexical distinctions, and extracting rules explaining these distinctions in a human- and machine-readable format. We confirm the quality of these extracted rules in a language learning setup for two languages, <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a> and <a href=https://en.wikipedia.org/wiki/Greek_language>Greek</a>, where we use the rules to teach non-native speakers when to translate a given ambiguous word into its different possible translations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.570.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--570 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.570 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.570" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.570/>Evaluating the Morphosyntactic Well-formedness of Generated Texts</a></strong><br><a href=/people/a/adithya-pratapa/>Adithya Pratapa</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/s/shruti-rijhwani/>Shruti Rijhwani</a>
|
<a href=/people/a/aditi-chaudhary/>Aditi Chaudhary</a>
|
<a href=/people/d/david-r-mortensen/>David R. Mortensen</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/y/yulia-tsvetkov/>Yulia Tsvetkov</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--570><div class="card-body p-3 small">Text generation systems are ubiquitous in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing applications</a>. However, evaluation of these <a href=https://en.wikipedia.org/wiki/System>systems</a> remains a challenge, especially in multilingual settings. In this paper, we propose L&#8217;AMBRE a <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> to evaluate the morphosyntactic well-formedness of text using its dependency parse and morphosyntactic rules of the language. We present a way to automatically extract various rules governing morphosyntax directly from dependency treebanks. To tackle the noisy outputs from text generation systems, we propose a simple <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> to train robust parsers. We show the effectiveness of our <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> on the task of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> through a diachronic study of systems translating into morphologically-rich languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.iwslt-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--iwslt-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.iwslt-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.iwslt-1.1/>FINDINGS OF THE IWSLT 2021 EVALUATION CAMPAIGN<span class=acl-fixed-case>FINDINGS</span> <span class=acl-fixed-case>OF</span> <span class=acl-fixed-case>THE</span> <span class=acl-fixed-case>IWSLT</span> 2021 <span class=acl-fixed-case>EVALUATION</span> <span class=acl-fixed-case>CAMPAIGN</span></a></strong><br><a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/o/ondrej-bojar/>Ondřej Bojar</a>
|
<a href=/people/j/jacob-bremerman/>Jacob Bremerman</a>
|
<a href=/people/r/roldano-cattoni/>Roldano Cattoni</a>
|
<a href=/people/m/maha-elbayad/>Maha Elbayad</a>
|
<a href=/people/m/marcello-federico/>Marcello Federico</a>
|
<a href=/people/x/xutai-ma/>Xutai Ma</a>
|
<a href=/people/s/satoshi-nakamura/>Satoshi Nakamura</a>
|
<a href=/people/m/matteo-negri/>Matteo Negri</a>
|
<a href=/people/j/jan-niehues/>Jan Niehues</a>
|
<a href=/people/j/juan-pino/>Juan Pino</a>
|
<a href=/people/e/elizabeth-salesky/>Elizabeth Salesky</a>
|
<a href=/people/s/sebastian-stuker/>Sebastian Stüker</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/m/marco-turchi/>Marco Turchi</a>
|
<a href=/people/a/alex-waibel/>Alexander Waibel</a>
|
<a href=/people/c/changhan-wang/>Changhan Wang</a>
|
<a href=/people/m/matthew-wiesner/>Matthew Wiesner</a><br><a href=/volumes/2021.iwslt-1/ class=text-muted>Proceedings of the 18th International Conference on Spoken Language Translation (IWSLT 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--iwslt-1--1><div class="card-body p-3 small">The evaluation campaign of the International Conference on Spoken Language Translation (IWSLT 2021) featured this year four shared tasks : (i) Simultaneous speech translation, (ii) Offline speech translation, (iii) Multilingual speech translation, (iv) Low-resource speech translation. A total of 22 teams participated in at least one of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. This paper describes each shared task, data and evaluation metrics, and reports results of the received submissions.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.422.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--422 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.422 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939038 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.422" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.422/>Automatic Extraction of <a href=https://en.wikipedia.org/wiki/Rule_of_inference>Rules</a> Governing Morphological Agreement</a></strong><br><a href=/people/a/aditi-chaudhary/>Aditi Chaudhary</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/a/adithya-pratapa/>Adithya Pratapa</a>
|
<a href=/people/d/david-r-mortensen/>David R. Mortensen</a>
|
<a href=/people/z/zaid-sheikh/>Zaid Sheikh</a>
|
<a href=/people/y/yulia-tsvetkov/>Yulia Tsvetkov</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--422><div class="card-body p-3 small">Creating a <a href=https://en.wikipedia.org/wiki/Descriptive_grammar>descriptive grammar</a> of a language is an indispensable step for language documentation and preservation. However, at the same time it is a tedious, time-consuming task. In this paper, we take steps towards automating this process by devising an automated framework for extracting a first-pass grammatical specification from raw text in a concise, human- and machine-readable format. We focus on extracting rules describing <a href=https://en.wikipedia.org/wiki/Agreement_(linguistics)>agreement</a>, a morphosyntactic phenomenon at the core of the <a href=https://en.wikipedia.org/wiki/Grammar>grammars</a> of many of the world&#8217;s languages. We apply our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> to all languages included in the Universal Dependencies project, with promising results. Using cross-lingual transfer, even with no expert annotations in the language of interest, our framework extracts a grammatical specification which is nearly equivalent to those created with large amounts of gold-standard annotated data. We confirm this finding with human expert evaluations of the <a href=https://en.wikipedia.org/wiki/Rule_of_inference>rules</a> that our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> produces, which have an average <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 78 %. We release an interface demonstrating the extracted <a href=https://en.wikipedia.org/wiki/Rule-based_programming>rules</a> at https://neulab.github.io/lase/</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.478.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--478 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.478 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939129 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.478" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.478/>OCR Post Correction for Endangered Language Texts<span class=acl-fixed-case>OCR</span> <span class=acl-fixed-case>P</span>ost <span class=acl-fixed-case>C</span>orrection for <span class=acl-fixed-case>E</span>ndangered <span class=acl-fixed-case>L</span>anguage <span class=acl-fixed-case>T</span>exts</a></strong><br><a href=/people/s/shruti-rijhwani/>Shruti Rijhwani</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--478><div class="card-body p-3 small">There is little to no data available to build <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language processing models</a> for most <a href=https://en.wikipedia.org/wiki/Endangered_language>endangered languages</a>. However, <a href=https://en.wikipedia.org/wiki/Text-based_user_interface>textual data</a> in these languages often exists in formats that are not machine-readable, such as <a href=https://en.wikipedia.org/wiki/Paperback>paper books</a> and <a href=https://en.wikipedia.org/wiki/Image_scanner>scanned images</a>. In this work, we address the task of extracting text from these <a href=https://en.wikipedia.org/wiki/Resource_(computing)>resources</a>. We create a benchmark dataset of transcriptions for scanned books in three critically endangered languages and present a systematic analysis of how general-purpose OCR tools are not robust to the data-scarce setting of endangered languages. We develop an OCR post-correction method tailored to ease training in this data-scarce setting, reducing the recognition error rate by 34 % on average across the three languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.479.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--479 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.479 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939158 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.479/>X-FACTR : Multilingual Factual Knowledge Retrieval from Pretrained Language Models<span class=acl-fixed-case>X</span>-<span class=acl-fixed-case>FACTR</span>: Multilingual Factual Knowledge Retrieval from Pretrained Language Models</a></strong><br><a href=/people/z/zhengbao-jiang/>Zhengbao Jiang</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/j/jun-araki/>Jun Araki</a>
|
<a href=/people/h/haibo-ding/>Haibo Ding</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--479><div class="card-body p-3 small">Language models (LMs) have proven surprisingly successful at capturing factual knowledge by completing cloze-style fill-in-the-blank questions such as Punta Cana is located in _. However, while knowledge is both written and queried in many languages, studies on LMs&#8217; factual representation ability have almost invariably been performed on <a href=https://en.wikipedia.org/wiki/English_language>English</a>. To assess factual knowledge retrieval in LMs in different languages, we create a multilingual benchmark of cloze-style probes for typologically diverse languages. To properly handle language variations, we expand probing methods from single- to multi-word entities, and develop several decoding algorithms to generate multi-token predictions. Extensive experimental results provide insights about how well (or poorly) current state-of-the-art LMs perform at this task in languages with more or fewer available resources. We further propose a code-switching-based method to improve the ability of multilingual LMs to access knowledge, and verify its effectiveness on several benchmark languages. Benchmark data and code have be released at https://x-factr.github.io.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigmorphon-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sigmorphon-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sigmorphon-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sigmorphon-1.6/>The CMU-LTI submission to the SIGMORPHON 2020 Shared Task 0 : Language-Specific Cross-Lingual Transfer<span class=acl-fixed-case>CMU</span>-<span class=acl-fixed-case>LTI</span> submission to the <span class=acl-fixed-case>SIGMORPHON</span> 2020 Shared Task 0: Language-Specific Cross-Lingual Transfer</a></strong><br><a href=/people/n/nikitha-murikinati/>Nikitha Murikinati</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a><br><a href=/volumes/2020.sigmorphon-1/ class=text-muted>Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sigmorphon-1--6><div class="card-body p-3 small">This paper describes the CMU-LTI submission to the SIGMORPHON 2020 Shared Task 0 on typologically diverse morphological inflection. The (unrestricted) submission uses the cross-lingual approach of our last year&#8217;s winning submission (Anastasopoulos and Neubig, 2019), but adapted to use specific transfer languages for each test language. Our <a href=https://en.wikipedia.org/wiki/System>system</a>, with fixed non-tuned hyperparameters, achieved a macro-averaged accuracy of 80.65 ranking 20th among 31 systems, but it was still tied for best <a href=https://en.wikipedia.org/wiki/System>system</a> in 25 of the 90 total languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.656.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--656 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.656 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.656/>AlloVera : A Multilingual Allophone Database<span class=acl-fixed-case>A</span>llo<span class=acl-fixed-case>V</span>era: A Multilingual Allophone Database</a></strong><br><a href=/people/d/david-r-mortensen/>David R. Mortensen</a>
|
<a href=/people/x/xinjian-li/>Xinjian Li</a>
|
<a href=/people/p/patrick-littell/>Patrick Littell</a>
|
<a href=/people/a/alexis-michaud/>Alexis Michaud</a>
|
<a href=/people/s/shruti-rijhwani/>Shruti Rijhwani</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/a/alan-w-black/>Alan W Black</a>
|
<a href=/people/f/florian-metze/>Florian Metze</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--656><div class="card-body p-3 small">We introduce a new resource, AlloVera, which provides mappings from 218 <a href=https://en.wikipedia.org/wiki/Allophone>allophones</a> to <a href=https://en.wikipedia.org/wiki/Phoneme>phonemes</a> for 14 languages. Phonemes are contrastive phonological units, and allophones are their various concrete realizations, which are predictable from phonological context. While <a href=https://en.wikipedia.org/wiki/Phoneme>phonemic representations</a> are language specific, <a href=https://en.wikipedia.org/wiki/Phoneme>phonetic representations</a> (stated in terms of (allo)phones) are much closer to a universal (language-independent) transcription. AlloVera allows the training of <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition models</a> that output <a href=https://en.wikipedia.org/wiki/Transcription_(linguistics)>phonetic transcriptions</a> in the <a href=https://en.wikipedia.org/wiki/International_Phonetic_Alphabet>International Phonetic Alphabet (IPA)</a>, regardless of the input language. We show that a universal allophone model, <a href=https://en.wikipedia.org/wiki/Allosaurus>Allosaurus</a>, built with AlloVera, outperforms universal phonemic models and language-specific models on a speech-transcription task. We explore the implications of this <a href=https://en.wikipedia.org/wiki/Technology>technology</a> (and related technologies) for the documentation of endangered and minority languages. We further explore other <a href=https://en.wikipedia.org/wiki/Application_software>applications</a> for which AlloVera will be suitable as <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> grows, including phonological typology.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wnut-1.20.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--wnut-1--20 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.wnut-1.20 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.wnut-1.20" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.wnut-1.20/>Fine-Tuning MT systems for Robustness to Second-Language Speaker Variations<span class=acl-fixed-case>MT</span> systems for Robustness to Second-Language Speaker Variations</a></strong><br><a href=/people/m/md-mahfuz-ibn-alam/>Md Mahfuz Ibn Alam</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a><br><a href=/volumes/2020.wnut-1/ class=text-muted>Proceedings of the Sixth Workshop on Noisy User-generated Text (W-NUT 2020)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--wnut-1--20><div class="card-body p-3 small">The performance of neural machine translation (NMT) systems only trained on a single language variant degrades when confronted with even slightly different language variations. With this work, we build upon previous work to explore how to mitigate this issue. We show that <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> using naturally occurring noise along with pseudo-references (i.e. corrected non-native inputs translated using the baseline NMT system) is a promising solution towards systems robust to such type of input variations. We focus on four translation pairs, from <a href=https://en.wikipedia.org/wiki/English_language>English</a> to <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a>, <a href=https://en.wikipedia.org/wiki/French_language>French</a>, and <a href=https://en.wikipedia.org/wiki/Portuguese_language>Portuguese</a>, with our system achieving improvements of up to 3.1 BLEU points compared to the baselines, establishing a new state-of-the-art on the JFLEG-ES dataset. All datasets and code are publicly available here : https://github.com/mahfuzibnalam/finetuning_for_robustness.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1147.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1147 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1147 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1147" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1147/>Unsupervised Domain Adaptation for <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> with Domain-Aware Feature Embeddings</a></strong><br><a href=/people/z/zi-yi-dou/>Zi-Yi Dou</a>
|
<a href=/people/j/junjie-hu/>Junjie Hu</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1147><div class="card-body p-3 small">The recent success of neural machine translation models relies on the availability of high quality, in-domain data. Domain adaptation is required when domain-specific data is scarce or nonexistent. Previous unsupervised domain adaptation strategies include training the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> with in-domain copied monolingual or back-translated data. However, these methods use generic representations for text regardless of domain shift, which makes it infeasible for translation models to control outputs conditional on a specific domain. In this work, we propose an approach that adapts <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> with domain-aware feature embeddings, which are learned via an auxiliary language modeling task. Our approach allows the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to assign domain-specific representations to words and output sentences in the desired domain. Our empirical results demonstrate the effectiveness of the proposed <a href=https://en.wikipedia.org/wiki/Strategy>strategy</a>, achieving consistent improvements in multiple experimental settings. In addition, we show that combining our method with <a href=https://en.wikipedia.org/wiki/Back_translation>back translation</a> can further improve the performance of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5303.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5303 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5303 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5303" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5303/>Findings of the First Shared Task on Machine Translation Robustness</a></strong><br><a href=/people/x/xian-li/>Xian Li</a>
|
<a href=/people/p/paul-michel/>Paul Michel</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/y/yonatan-belinkov/>Yonatan Belinkov</a>
|
<a href=/people/n/nadir-durrani/>Nadir Durrani</a>
|
<a href=/people/o/orhan-firat/>Orhan Firat</a>
|
<a href=/people/p/philipp-koehn/>Philipp Koehn</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/j/juan-pino/>Juan Pino</a>
|
<a href=/people/h/hassan-sajjad/>Hassan Sajjad</a><br><a href=/volumes/W19-53/ class=text-muted>Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5303><div class="card-body p-3 small">We share the findings of the first shared task on improving <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> of Machine Translation (MT). The task provides a testbed representing challenges facing MT models deployed in the real world, and facilitates new approaches to improve <a href=https://en.wikipedia.org/wiki/Mathematical_model>models&#8217; robustness</a> to noisy input and domain mismatch. We focus on two language pairs (English-French and English-Japanese), and the submitted systems are evaluated on a blind test set consisting of noisy comments on Reddit and professionally sourced translations. As a new task, we received 23 submissions by 11 participating teams from universities, companies, national labs, etc. All submitted <a href=https://en.wikipedia.org/wiki/System>systems</a> achieved large improvements over <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>, with the best improvement having +22.33 <a href=https://en.wikipedia.org/wiki/British_thermal_unit>BLEU</a>. We evaluated submissions by both human judgment and automatic evaluation (BLEU), which shows high correlations (Pearson&#8217;s r = 0.94 and 0.95). Furthermore, we conducted a qualitative analysis of the submitted <a href=https://en.wikipedia.org/wiki/System>systems</a> using compare-mt, which revealed their salient differences in handling challenges in this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. Such analysis provides additional insights when there is occasional disagreement between <a href=https://en.wikipedia.org/wiki/Judgement>human judgment</a> and <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>, e.g. systems better at producing <a href=https://en.wikipedia.org/wiki/Colloquialism>colloquial expressions</a> received higher score from <a href=https://en.wikipedia.org/wiki/Judgement>human judgment</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1301.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1301 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1301 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1301" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1301/>Choosing <a href=https://en.wikipedia.org/wiki/Language_transfer>Transfer Languages</a> for Cross-Lingual Learning</a></strong><br><a href=/people/y/yu-hsiang-lin/>Yu-Hsiang Lin</a>
|
<a href=/people/c/chian-yu-chen/>Chian-Yu Chen</a>
|
<a href=/people/j/jean-lee/>Jean Lee</a>
|
<a href=/people/z/zirui-li/>Zirui Li</a>
|
<a href=/people/y/yuyan-zhang/>Yuyan Zhang</a>
|
<a href=/people/m/mengzhou-xia/>Mengzhou Xia</a>
|
<a href=/people/s/shruti-rijhwani/>Shruti Rijhwani</a>
|
<a href=/people/j/junxian-he/>Junxian He</a>
|
<a href=/people/z/zhisong-zhang/>Zhisong Zhang</a>
|
<a href=/people/x/xuezhe-ma/>Xuezhe Ma</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/p/patrick-littell/>Patrick Littell</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1301><div class="card-body p-3 small">Cross-lingual transfer, where a high-resource transfer language is used to improve the accuracy of a low-resource task language, is now an invaluable tool for improving performance of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a> on low-resource languages. However, given a particular task language, it is not clear which language to transfer from, and the standard strategy is to select languages based on ad hoc criteria, usually the intuition of the experimenter. Since a large number of features contribute to the success of cross-lingual transfer (including <a href=https://en.wikipedia.org/wiki/Phylogenetic_tree>phylogenetic similarity</a>, <a href=https://en.wikipedia.org/wiki/Linguistic_typology>typological properties</a>, lexical overlap, or size of available data), even the most enlightened experimenter rarely considers all these factors for the particular task at hand. In this paper, we consider this task of automatically selecting optimal transfer languages as a ranking problem, and build <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that consider the aforementioned <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> to perform this prediction. In experiments on representative NLP tasks, we demonstrate that our model predicts good transfer languages much better than ad hoc baselines considering single features in isolation, and glean insights on what <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> are most informative for each different NLP tasks, which may inform future ad hoc selection even without use of our method.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1579.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1579 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1579 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385226257 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1579/>Generalized Data Augmentation for Low-Resource Translation</a></strong><br><a href=/people/m/mengzhou-xia/>Mengzhou Xia</a>
|
<a href=/people/x/xiang-kong/>Xiang Kong</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1579><div class="card-body p-3 small">Low-resource language pairs with a paucity of parallel data pose challenges for <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> in terms of both adequacy and <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a>. Data augmentation utilizing a large amount of monolingual data is regarded as an effective way to alleviate the problem. In this paper, we propose a general framework of <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> for low-resource machine translation not only using target-side monolingual data, but also by pivoting through a related high-resource language. Specifically, we experiment with a two-step pivoting method to convert high-resource data to the low-resource language, making best use of available resources to better approximate the true distribution of the low-resource language. First, we inject low-resource words into high-resource sentences through an induced bilingual dictionary. Second, we further edit the high-resource data injected with low-resource words using a modified unsupervised machine translation framework. Extensive experiments on four low-resource datasets show that under extreme low-resource settings, our data augmentation techniques improve translation quality by up to 1.5 to 8 BLEU points compared to supervised back-translation baselines.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6313.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6313 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6313 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-6313" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-6313/>Freezing Subnetworks to Analyze Domain Adaptation in Neural Machine Translation</a></strong><br><a href=/people/b/brian-thompson/>Brian Thompson</a>
|
<a href=/people/h/huda-khayrallah/>Huda Khayrallah</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/a/arya-d-mccarthy/>Arya D. McCarthy</a>
|
<a href=/people/k/kevin-duh/>Kevin Duh</a>
|
<a href=/people/r/rebecca-marvin/>Rebecca Marvin</a>
|
<a href=/people/p/paul-mcnamee/>Paul McNamee</a>
|
<a href=/people/j/jeremy-gwinnup/>Jeremy Gwinnup</a>
|
<a href=/people/t/tim-anderson/>Tim Anderson</a>
|
<a href=/people/p/philipp-koehn/>Philipp Koehn</a><br><a href=/volumes/W18-63/ class=text-muted>Proceedings of the Third Conference on Machine Translation: Research Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6313><div class="card-body p-3 small">To better understand the effectiveness of continued training, we analyze the major components of a neural machine translation system (the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a>, <a href=https://en.wikipedia.org/wiki/Code>decoder</a>, and each embedding space) and consider each component&#8217;s contribution to, and capacity for, domain adaptation. We find that freezing any single component during continued training has minimal impact on performance, and that performance is surprisingly good when a single component is adapted while holding the rest of the model fixed. We also find that continued training does not move the model very far from the out-of-domain model, compared to a sensitivity analysis metric, suggesting that the out-of-domain model can provide a good generic initialization for the new domain.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1008 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276441141 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1008/>Tied Multitask Learning for Neural Speech Translation</a></strong><br><a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/d/david-chiang/>David Chiang</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1008><div class="card-body p-3 small">We explore multitask models for neural translation of speech, augmenting them in order to reflect two intuitive notions. First, we introduce a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> where the second task decoder receives information from the decoder of the first <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>, since higher-level intermediate representations should provide useful information. Second, we apply <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization</a> that encourages transitivity and <a href=https://en.wikipedia.org/wiki/Inverse_problem>invertibility</a>. We show that the application of these notions on jointly trained models improves performance on the tasks of low-resource speech transcription and <a href=https://en.wikipedia.org/wiki/Translation>translation</a>. It also leads to better performance when using <a href=https://en.wikipedia.org/wiki/Attentional_control>attention information</a> for word discovery over unsegmented input.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4607.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4607 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4607 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4607/>Spoken Term Discovery for <a href=https://en.wikipedia.org/wiki/Language_documentation>Language Documentation</a> using Translations</a></strong><br><a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/s/sameer-bansal/>Sameer Bansal</a>
|
<a href=/people/d/david-chiang/>David Chiang</a>
|
<a href=/people/s/sharon-goldwater/>Sharon Goldwater</a>
|
<a href=/people/a/adam-lopez/>Adam Lopez</a><br><a href=/volumes/W17-46/ class=text-muted>Proceedings of the Workshop on Speech-Centric Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4607><div class="card-body p-3 small">Vast amounts of speech data collected for <a href=https://en.wikipedia.org/wiki/Language_documentation>language documentation</a> and research remain untranscribed and unsearchable, but often a small amount of speech may have text translations available. We present a <a href=https://en.wikipedia.org/wiki/Methodology>method</a> for partially labeling additional speech with translations in this <a href=https://en.wikipedia.org/wiki/Scenario>scenario</a>. We modify an unsupervised speech-to-translation alignment model and obtain prototype speech segments that match the translation words, which are in turn used to discover terms in the unlabelled data. We evaluate our method on a Spanish-English speech translation corpus and on two corpora of endangered languages, <a href=https://en.wikipedia.org/wiki/Arapaho_language>Arapaho</a> and Ainu, demonstrating its appropriateness and applicability in an actual very-low-resource scenario.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Antonios+Anastasopoulos" title="Search for 'Antonios Anastasopoulos' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/g/graham-neubig/ class=align-middle>Graham Neubig</a>
<span class="badge badge-secondary align-middle ml-2">10</span></li><li class=list-group-item><a href=/people/s/shruti-rijhwani/ class=align-middle>Shruti Rijhwani</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/a/aditi-chaudhary/ class=align-middle>Aditi Chaudhary</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/d/david-r-mortensen/ class=align-middle>David R. Mortensen</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/f/fahim-faisal/ class=align-middle>Fahim Faisal</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/a/adithya-pratapa/ class=align-middle>Adithya Pratapa</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yulia-tsvetkov/ class=align-middle>Yulia Tsvetkov</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/david-chiang/ class=align-middle>David Chiang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/juan-pino/ class=align-middle>Juan Pino</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/philipp-koehn/ class=align-middle>Philipp Koehn</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/patrick-littell/ class=align-middle>Patrick Littell</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mengzhou-xia/ class=align-middle>Mengzhou Xia</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/zaid-sheikh/ class=align-middle>Zaid Sheikh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhengbao-jiang/ class=align-middle>Zhengbao Jiang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jun-araki/ class=align-middle>Jun Araki</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haibo-ding/ class=align-middle>Haibo Ding</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sameer-bansal/ class=align-middle>Sameer Bansal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sharon-goldwater/ class=align-middle>Sharon Goldwater</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/adam-lopez/ class=align-middle>Adam Lopez</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yinkai-wang/ class=align-middle>Yinkai Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nikitha-murikinati/ class=align-middle>Nikitha Murikinati</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kayo-yin/ class=align-middle>Kayo Yin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zi-yi-dou/ class=align-middle>Zi-Yi Dou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/junjie-hu/ class=align-middle>Junjie Hu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/ondrej-bojar/ class=align-middle>Ondřej Bojar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jacob-bremerman/ class=align-middle>Jacob Bremerman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/roldano-cattoni/ class=align-middle>Roldano Cattoni</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maha-elbayad/ class=align-middle>Maha Elbayad</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marcello-federico/ class=align-middle>Marcello Federico</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xutai-ma/ class=align-middle>Xutai Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/satoshi-nakamura/ class=align-middle>Satoshi Nakamura</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/matteo-negri/ class=align-middle>Matteo Negri</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jan-niehues/ class=align-middle>Jan Niehues</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elizabeth-salesky/ class=align-middle>Elizabeth Salesky</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sebastian-stuker/ class=align-middle>Sebastian Stüker</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/katsuhito-sudoh/ class=align-middle>Katsuhito Sudoh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marco-turchi/ class=align-middle>Marco Turchi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alex-waibel/ class=align-middle>Alex Waibel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/changhan-wang/ class=align-middle>Changhan Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/matthew-wiesner/ class=align-middle>Matthew Wiesner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/brian-thompson/ class=align-middle>Brian Thompson</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/huda-khayrallah/ class=align-middle>Huda Khayrallah</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/arya-d-mccarthy/ class=align-middle>Arya D. McCarthy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kevin-duh/ class=align-middle>Kevin Duh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rebecca-marvin/ class=align-middle>Rebecca Marvin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paul-mcnamee/ class=align-middle>Paul McNamee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jeremy-gwinnup/ class=align-middle>Jeremy Gwinnup</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tim-anderson/ class=align-middle>Tim Anderson</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xian-li/ class=align-middle>Xian Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paul-michel/ class=align-middle>Paul Michel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yonatan-belinkov/ class=align-middle>Yonatan Belinkov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nadir-durrani/ class=align-middle>Nadir Durrani</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/orhan-firat/ class=align-middle>Orhan Firat</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hassan-sajjad/ class=align-middle>Hassan Sajjad</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xinjian-li/ class=align-middle>Xinjian Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexis-michaud/ class=align-middle>Alexis Michaud</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alan-w-black/ class=align-middle>Alan W. Black</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/florian-metze/ class=align-middle>Florian Metze</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/md-mahfuz-ibn-alam/ class=align-middle>Md Mahfuz Ibn Alam</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yu-hsiang-lin/ class=align-middle>Yu-Hsiang Lin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chian-yu-chen/ class=align-middle>Chian-Yu Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jean-lee/ class=align-middle>Jean Lee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zirui-li/ class=align-middle>Zirui Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yuyan-zhang/ class=align-middle>Yuyan Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/junxian-he/ class=align-middle>Junxian He</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhisong-zhang/ class=align-middle>Zhisong Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xuezhe-ma/ class=align-middle>Xuezhe Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiang-kong/ class=align-middle>Xiang Kong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/mrqa/ class=align-middle>MRQA</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/sigmorphon/ class=align-middle>SIGMORPHON</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/iwslt/ class=align-middle>IWSLT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wnut/ class=align-middle>WNUT</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>