<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Ashutosh Modi - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Ashutosh</span> <span class=font-weight-bold>Modi</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-main.71.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-main--71 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-main.71 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.eacl-main.71" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-main.71/>Adv-OLM : Generating Textual Adversaries via OLM<span class=acl-fixed-case>OLM</span>: Generating Textual Adversaries via <span class=acl-fixed-case>OLM</span></a></strong><br><a href=/people/v/vijit-malik/>Vijit Malik</a>
|
<a href=/people/a/ashwani-bhat/>Ashwani Bhat</a>
|
<a href=/people/a/ashutosh-modi/>Ashutosh Modi</a><br><a href=/volumes/2021.eacl-main/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-main--71><div class="card-body p-3 small">Deep learning models are susceptible to adversarial examples that have imperceptible perturbations in the original input, resulting in adversarial attacks against these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Analysis of these attacks on the state of the art transformers in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> can help improve the robustness of these models against such adversarial inputs. In this paper, we present Adv-OLM, a black-box attack method that adapts the idea of Occlusion and Language Models (OLM) to the current state of the art attack methods. OLM is used to rank words of a sentence, which are later substituted using word replacement strategies. We experimentally show that our approach outperforms other attack methods for several text classification tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wassa-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wassa-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wassa-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.wassa-1.9" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.wassa-1.9/>An End-to-End Network for Emotion-Cause Pair Extraction</a></strong><br><a href=/people/a/aaditya-singh/>Aaditya Singh</a>
|
<a href=/people/s/shreeshail-hingane/>Shreeshail Hingane</a>
|
<a href=/people/s/saim-wani/>Saim Wani</a>
|
<a href=/people/a/ashutosh-modi/>Ashutosh Modi</a><br><a href=/volumes/2021.wassa-1/ class=text-muted>Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wassa-1--9><div class="card-body p-3 small">The task of Emotion-Cause Pair Extraction (ECPE) aims to extract all potential clause-pairs of emotions and their corresponding causes in a document. Unlike the more well-studied task of Emotion Cause Extraction (ECE), ECPE does not require the emotion clauses to be provided as annotations. Previous works on ECPE have either followed a multi-stage approach where emotion extraction, cause extraction, and <a href=https://en.wikipedia.org/wiki/Pairing>pairing</a> are done independently or use complex architectures to resolve its limitations. In this paper, we propose an <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end model</a> for the ECPE task. Due to the unavailability of an English language ECPE corpus, we adapt the NTCIR-13 ECE corpus and establish a baseline for the ECPE task on this dataset. On this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, the proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> produces significant performance improvements (6.5 % increase in F1 score) over the multi-stage approach and achieves comparable performance to the <a href=https://en.wikipedia.org/wiki/Methodology>state-of-the-art methods</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.36.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--36 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.36 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.semeval-1.36" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.36/>Humor@IITK at SemEval-2021 Task 7 : Large Language Models for Quantifying Humor and Offensiveness<span class=acl-fixed-case>IITK</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 7: Large Language Models for Quantifying Humor and Offensiveness</a></strong><br><a href=/people/a/aishwarya-gupta/>Aishwarya Gupta</a>
|
<a href=/people/a/avik-pal/>Avik Pal</a>
|
<a href=/people/b/bholeshwar-khurana/>Bholeshwar Khurana</a>
|
<a href=/people/l/lakshay-tyagi/>Lakshay Tyagi</a>
|
<a href=/people/a/ashutosh-modi/>Ashutosh Modi</a><br><a href=/volumes/2021.semeval-1/ class=text-muted>Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--36><div class="card-body p-3 small">Humor and Offense are highly subjective due to multiple <a href=https://en.wikipedia.org/wiki/Word_sense>word senses</a>, <a href=https://en.wikipedia.org/wiki/Cultural_knowledge>cultural knowledge</a>, and pragmatic competence. Hence, accurately detecting humorous and offensive texts has several compelling use cases in <a href=https://en.wikipedia.org/wiki/Recommender_system>Recommendation Systems</a> and Personalized Content Moderation. However, due to the lack of an extensive labeled dataset, most prior works in this domain have n&#8217;t explored large neural models for subjective humor understanding. This paper explores whether large neural models and their ensembles can capture the intricacies associated with humor / offense detection and rating. Our experiments on the SemEval-2021 Task 7 : HaHackathon show that we can develop reasonable humor and offense detection systems with such models. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are ranked 3rd in subtask 1b and consistently ranked around the top 33 % of the leaderboard for the remaining subtasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.53.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--53 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.53 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.53/>IITK at SemEval-2021 Task 10 : Source-Free Unsupervised Domain Adaptation using Class Prototypes<span class=acl-fixed-case>IITK</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 10: Source-Free Unsupervised Domain Adaptation using Class Prototypes</a></strong><br><a href=/people/h/harshit-kumar-iit/>Harshit Kumar</a>
|
<a href=/people/j/jinang-shah/>Jinang Shah</a>
|
<a href=/people/n/nidhi-hegde/>Nidhi Hegde</a>
|
<a href=/people/p/priyanshu-gupta/>Priyanshu Gupta</a>
|
<a href=/people/v/vaibhav-jindal/>Vaibhav Jindal</a>
|
<a href=/people/a/ashutosh-modi/>Ashutosh Modi</a><br><a href=/volumes/2021.semeval-1/ class=text-muted>Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--53><div class="card-body p-3 small">Recent progress in <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> has primarily been fueled by the availability of large amounts of annotated data that is obtained from highly expensive manual annotating pro-cesses. To tackle this issue of availability of annotated data, a lot of research has been done on unsupervised domain adaptation that tries to generate systems for an unlabelled target domain data, given labeled source domain data. However, the availability of annotated or labelled source domain dataset ca n&#8217;t always be guaranteed because of <a href=https://en.wikipedia.org/wiki/Data_privacy>data-privacy issues</a>. This is especially the case with medical data, as <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> may contain sensitive information of the patients. Source-free domain adaptation (SFDA) aims to resolve this issue by us-ing <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on the <a href=https://en.wikipedia.org/wiki/Data>source data</a> instead of using the original annotated source data. In this work, we try to build SFDA systems for <a href=https://en.wikipedia.org/wiki/Semantic_processing>semantic processing</a> by specifically focusing on the negation detection subtask of the SemEval2021 Task 10. We propose two approaches -ProtoAUGandAdapt-ProtoAUGthat use the idea of <a href=https://en.wikipedia.org/wiki/Self-entropy>self-entropy</a> to choose reliable and high confidence samples, which are then used for <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> and subsequent training of the models. Our methods report an improvement of up to 7 % in <a href=https://en.wikipedia.org/wiki/F1_score>F1 score</a> over the <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baseline</a> for the Negation Detection subtask.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.66.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--66 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.66 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.66/>IITK@LCP at SemEval-2021 Task 1 : Classification for Lexical Complexity Regression Task<span class=acl-fixed-case>IITK</span>@<span class=acl-fixed-case>LCP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 1: Classification for Lexical Complexity Regression Task</a></strong><br><a href=/people/n/neil-shirude/>Neil Shirude</a>
|
<a href=/people/s/sagnik-mukherjee/>Sagnik Mukherjee</a>
|
<a href=/people/t/tushar-shandhilya/>Tushar Shandhilya</a>
|
<a href=/people/a/ananta-mukherjee/>Ananta Mukherjee</a>
|
<a href=/people/a/ashutosh-modi/>Ashutosh Modi</a><br><a href=/volumes/2021.semeval-1/ class=text-muted>Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--66><div class="card-body p-3 small">This paper describes our contribution to SemEval 2021 Task 1 (Shardlow et al., 2021): Lexical Complexity Prediction. In our approach, we leverage the ELECTRA model and attempt to mirror the data annotation scheme. Although the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is a <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression task</a>, we show that we can treat it as an aggregation of several <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification and regression models</a>. This somewhat counter-intuitive approach achieved an MAE score of 0.0654 for Sub-Task 1 and MAE of 0.0811 on Sub-Task 2. Additionally, we used the concept of weak supervision signals from Gloss-BERT in our work, and it significantly improved the MAE score in Sub-Task 1.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.semeval-1.162.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--semeval-1--162 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.semeval-1.162 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.semeval-1.162" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.semeval-1.162/>BAKSA at SemEval-2020 Task 9 : Bolstering CNN with Self-Attention for Sentiment Analysis of Code Mixed Text<span class=acl-fixed-case>BAKSA</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2020 Task 9: Bolstering <span class=acl-fixed-case>CNN</span> with Self-Attention for Sentiment Analysis of Code Mixed Text</a></strong><br><a href=/people/a/ayush-kumar/>Ayush Kumar</a>
|
<a href=/people/h/harsh-agarwal/>Harsh Agarwal</a>
|
<a href=/people/k/keshav-bansal/>Keshav Bansal</a>
|
<a href=/people/a/ashutosh-modi/>Ashutosh Modi</a><br><a href=/volumes/2020.semeval-1/ class=text-muted>Proceedings of the Fourteenth Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--semeval-1--162><div class="card-body p-3 small">Sentiment Analysis of code-mixed text has diversified applications in <a href=https://en.wikipedia.org/wiki/Opinion_mining>opinion mining</a> ranging from tagging user reviews to identifying social or political sentiments of a sub-population. In this paper, we present an ensemble architecture of convolutional neural net (CNN) and self-attention based LSTM for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> of code-mixed tweets. While the CNN component helps in the classification of positive and negative tweets, the self-attention based LSTM, helps in the classification of neutral tweets, because of its ability to identify correct <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment</a> among multiple <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment bearing units</a>. We achieved F1 scores of 0.707 (ranked 5th) and 0.725 (ranked 13th) on Hindi-English (Hinglish) and Spanish-English (Spanglish) datasets, respectively. The submissions for Hinglish and Spanglish tasks were made under the usernames ayushk and harsh_6 respectively.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-1032.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S19-1032 data-toggle=collapse aria-expanded=false aria-controls=abstract-S19-1032 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-1032/>Generating Animations from Screenplays</a></strong><br><a href=/people/y/yeyao-zhang/>Yeyao Zhang</a>
|
<a href=/people/e/eleftheria-tsipidi/>Eleftheria Tsipidi</a>
|
<a href=/people/s/sasha-schriber/>Sasha Schriber</a>
|
<a href=/people/m/mubbasir-kapadia/>Mubbasir Kapadia</a>
|
<a href=/people/m/markus-gross/>Markus Gross</a>
|
<a href=/people/a/ashutosh-modi/>Ashutosh Modi</a><br><a href=/volumes/S19-1/ class=text-muted>Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S19-1032><div class="card-body p-3 small">Automatically generating animation from <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language text</a> finds application in a number of areas e.g. movie script writing, instructional videos, and <a href=https://en.wikipedia.org/wiki/Public_security>public safety</a>. However, translating <a href=https://en.wikipedia.org/wiki/Natural_language>natural language text</a> into <a href=https://en.wikipedia.org/wiki/Animation>animation</a> is a challenging task. Existing text-to-animation systems can handle only very simple sentences, which limits their applications. In this paper, we develop a text-to-animation system which is capable of handling <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>complex sentences</a>. We achieve this by introducing a text simplification step into the <a href=https://en.wikipedia.org/wiki/Process_(computing)>process</a>. Building on an existing animation generation system for <a href=https://en.wikipedia.org/wiki/Screenwriting>screenwriting</a>, we create a robust NLP pipeline to extract information from <a href=https://en.wikipedia.org/wiki/Screenplay>screenplays</a> and map them to the system&#8217;s knowledge base. We develop a set of linguistic transformation rules that simplify complex sentences. Information extracted from the simplified sentences is used to generate a rough storyboard and video depicting the text. Our sentence simplification module outperforms existing systems in terms of BLEU and SARI metrics. We further evaluated our <a href=https://en.wikipedia.org/wiki/System>system</a> via a user study : 68 % participants believe that our <a href=https://en.wikipedia.org/wiki/System>system</a> generates reasonable <a href=https://en.wikipedia.org/wiki/Animation>animation</a> from input <a href=https://en.wikipedia.org/wiki/Screenplay>screenplays</a>.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1119.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1119 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1119 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1119/>SemEval-2018 Task 11 : <a href=https://en.wikipedia.org/wiki/Machine_learning>Machine Comprehension</a> Using Commonsense Knowledge<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 11: Machine Comprehension Using Commonsense Knowledge</a></strong><br><a href=/people/s/simon-ostermann/>Simon Ostermann</a>
|
<a href=/people/m/michael-roth/>Michael Roth</a>
|
<a href=/people/a/ashutosh-modi/>Ashutosh Modi</a>
|
<a href=/people/s/stefan-thater/>Stefan Thater</a>
|
<a href=/people/m/manfred-pinkal/>Manfred Pinkal</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1119><div class="card-body p-3 small">This report summarizes the results of the SemEval 2018 task on <a href=https://en.wikipedia.org/wiki/Machine_learning>machine comprehension</a> using <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a>. For this machine comprehension task, we created a new <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, MCScript. It contains a high number of questions that require <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a> for finding the correct answer. 11 teams from 4 different countries participated in this shared <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, most of them used neural approaches. The best performing <a href=https://en.wikipedia.org/wiki/System>system</a> achieves an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 83.95 %, outperforming the <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baselines</a> by a large margin, but still far from the <a href=https://en.wikipedia.org/wiki/Upper_and_lower_bounds>human upper bound</a>, which was found to be at 98 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6236.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6236 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6236 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6236/>Disney at IEST 2018 : Predicting Emotions using an Ensemble<span class=acl-fixed-case>IEST</span> 2018: Predicting Emotions using an Ensemble</a></strong><br><a href=/people/w/wojciech-witon/>Wojciech Witon</a>
|
<a href=/people/p/pierre-colombo/>Pierre Colombo</a>
|
<a href=/people/a/ashutosh-modi/>Ashutosh Modi</a>
|
<a href=/people/m/mubbasir-kapadia/>Mubbasir Kapadia</a><br><a href=/volumes/W18-62/ class=text-muted>Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6236><div class="card-body p-3 small">This paper describes our participating <a href=https://en.wikipedia.org/wiki/System>system</a> in the WASSA 2018 shared task on emotion prediction. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> focuses on implicit emotion prediction in a tweet. In this task, keywords corresponding to the six emotion labels used (anger, fear, disgust, joy, sad, and surprise) have been removed from the tweet text, making emotion prediction implicit and the task challenging. We propose a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> based on an <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble of classifiers</a> for <a href=https://en.wikipedia.org/wiki/Prediction>prediction</a>. Each <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> uses a sequence of Convolutional Neural Network (CNN) architecture blocks and uses ELMo (Embeddings from Language Model) as an input. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves a 66.2 % <a href=https://en.wikipedia.org/wiki/Grading_in_education>F1 score</a> on the test set. The best performing <a href=https://en.wikipedia.org/wiki/System>system</a> in the shared task has reported a 71.4 % <a href=https://en.wikipedia.org/wiki/F1_score>F1 score</a>.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q17-1003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q17-1003 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q17-1003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234958123 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/Q17-1003/>Modeling Semantic Expectation : Using Script Knowledge for Referent Prediction</a></strong><br><a href=/people/a/ashutosh-modi/>Ashutosh Modi</a>
|
<a href=/people/i/ivan-titov/>Ivan Titov</a>
|
<a href=/people/v/vera-demberg/>Vera Demberg</a>
|
<a href=/people/a/asad-sayeed/>Asad Sayeed</a>
|
<a href=/people/m/manfred-pinkal/>Manfred Pinkal</a><br><a href=/volumes/Q17-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 5</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q17-1003><div class="card-body p-3 small">Recent research in <a href=https://en.wikipedia.org/wiki/Psycholinguistics>psycholinguistics</a> has provided increasing evidence that humans predict upcoming content. Prediction also affects <a href=https://en.wikipedia.org/wiki/Perception>perception</a> and might be a key to robustness in <a href=https://en.wikipedia.org/wiki/Language_processing_in_the_brain>human language processing</a>. In this paper, we investigate the factors that affect human prediction by building a <a href=https://en.wikipedia.org/wiki/Computational_model>computational model</a> that can predict upcoming discourse referents based on linguistic knowledge alone vs. linguistic knowledge jointly with common-sense knowledge in the form of scripts. We find that script knowledge significantly improves model estimates of human predictions. In a second study, we test the highly controversial hypothesis that <a href=https://en.wikipedia.org/wiki/Predictability>predictability</a> influences referring expression type but do not find evidence for such an effect.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-1015.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-1015 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-1015 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-1015/>A <a href=https://en.wikipedia.org/wiki/Mixture_model>Mixture Model</a> for Learning Multi-Sense Word Embeddings</a></strong><br><a href=/people/d/dai-quoc-nguyen/>Dai Quoc Nguyen</a>
|
<a href=/people/d/dat-quoc-nguyen/>Dat Quoc Nguyen</a>
|
<a href=/people/a/ashutosh-modi/>Ashutosh Modi</a>
|
<a href=/people/s/stefan-thater/>Stefan Thater</a>
|
<a href=/people/m/manfred-pinkal/>Manfred Pinkal</a><br><a href=/volumes/S17-1/ class=text-muted>Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-1015><div class="card-body p-3 small">Word embeddings are now a standard technique for inducing <a href=https://en.wikipedia.org/wiki/Meaning_(linguistics)>meaning representations</a> for words. For getting good <a href=https://en.wikipedia.org/wiki/Representation_(arts)>representations</a>, it is important to take into account different senses of a word. In this paper, we propose a <a href=https://en.wikipedia.org/wiki/Mixture_model>mixture model</a> for learning multi-sense word embeddings. Our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> generalizes the previous works in that it allows to induce different weights of different senses of a word. The experimental results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms previous <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on standard evaluation tasks.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Ashutosh+Modi" title="Search for 'Ashutosh Modi' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/m/manfred-pinkal/ class=align-middle>Manfred Pinkal</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/stefan-thater/ class=align-middle>Stefan Thater</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mubbasir-kapadia/ class=align-middle>Mubbasir Kapadia</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/v/vijit-malik/ class=align-middle>Vijit Malik</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ashwani-bhat/ class=align-middle>Ashwani Bhat</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/i/ivan-titov/ class=align-middle>Ivan Titov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vera-demberg/ class=align-middle>Vera Demberg</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/asad-sayeed/ class=align-middle>Asad Sayeed</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ayush-kumar/ class=align-middle>Ayush Kumar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/harsh-agarwal/ class=align-middle>Harsh Agarwal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/keshav-bansal/ class=align-middle>Keshav Bansal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dai-quoc-nguyen/ class=align-middle>Dai Quoc Nguyen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dat-quoc-nguyen/ class=align-middle>Dat Quoc Nguyen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yeyao-zhang/ class=align-middle>Yeyao Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eleftheria-tsipidi/ class=align-middle>Eleftheria Tsipidi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sasha-schriber/ class=align-middle>Sasha Schriber</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/markus-gross/ class=align-middle>Markus Gross</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/simon-ostermann/ class=align-middle>Simon Ostermann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-roth/ class=align-middle>Michael Roth</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wojciech-witon/ class=align-middle>Wojciech Witon</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pierre-colombo/ class=align-middle>Pierre Colombo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aaditya-singh/ class=align-middle>Aaditya Singh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shreeshail-hingane/ class=align-middle>Shreeshail Hingane</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/saim-wani/ class=align-middle>Saim Wani</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aishwarya-gupta/ class=align-middle>Aishwarya Gupta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/avik-pal/ class=align-middle>Avik Pal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bholeshwar-khurana/ class=align-middle>Bholeshwar Khurana</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lakshay-tyagi/ class=align-middle>Lakshay Tyagi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/harshit-kumar-iit/ class=align-middle>Harshit Kumar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jinang-shah/ class=align-middle>Jinang Shah</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nidhi-hegde/ class=align-middle>Nidhi Hegde</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/priyanshu-gupta/ class=align-middle>Priyanshu Gupta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vaibhav-jindal/ class=align-middle>Vaibhav Jindal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/neil-shirude/ class=align-middle>Neil Shirude</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sagnik-mukherjee/ class=align-middle>Sagnik Mukherjee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tushar-shandhilya/ class=align-middle>Tushar Shandhilya</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ananta-mukherjee/ class=align-middle>Ananta Mukherjee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/tacl/ class=align-middle>TACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wassa/ class=align-middle>WASSA</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>