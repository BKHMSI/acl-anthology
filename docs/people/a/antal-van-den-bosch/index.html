<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Antal van den Bosch - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Antal</span> <span class=font-weight-bold>van den Bosch</span></h2><hr><div class=row><div class=col-lg-9><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cogalex-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--cogalex-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.cogalex-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.cogalex-1.4" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.cogalex-1.4/>Less is Better : A cognitively inspired unsupervised model for language segmentation</a></strong><br><a href=/people/j/jinbiao-yang/>Jinbiao Yang</a>
|
<a href=/people/s/stefan-l-frank/>Stefan L. Frank</a>
|
<a href=/people/a/antal-van-den-bosch/>Antal van den Bosch</a><br><a href=/volumes/2020.cogalex-1/ class=text-muted>Proceedings of the Workshop on the Cognitive Aspects of the Lexicon</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--cogalex-1--4><div class="card-body p-3 small">Language users process utterances by segmenting them into many cognitive units, which vary in their sizes and <a href=https://en.wikipedia.org/wiki/Linguistic_description>linguistic levels</a>. Although we can do such unitization / segmentation easily, its <a href=https://en.wikipedia.org/wiki/Cognition>cognitive mechanism</a> is still not clear. This paper proposes an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised model</a>, Less-is-Better (LiB), to simulate the human cognitive process with respect to language unitization / segmentation. LiB follows the principle of least effort and aims to build a lexicon which minimizes the number of unit tokens (alleviating the effort of analysis) and number of unit types (alleviating the effort of storage) at the same time on any given corpus. LiB&#8217;s workflow is inspired by empirical cognitive phenomena. The design makes the mechanism of LiB cognitively plausible and the computational requirement light-weight. The lexicon generated by LiB performs the best among different types of lexicons (e.g. ground-truth words) both from an information-theoretical view and a cognitive view, which suggests that the LiB lexicon may be a plausible proxy of the <a href=https://en.wikipedia.org/wiki/Mental_lexicon>mental lexicon</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2903.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2903 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2903 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2903/>Simulating Spanish-English Code-Switching : El Modelo Est Generating Code-Switches<span class=acl-fixed-case>S</span>panish-<span class=acl-fixed-case>E</span>nglish Code-Switching: El Modelo Está Generating Code-Switches</a></strong><br><a href=/people/c/chara-tsoukala/>Chara Tsoukala</a>
|
<a href=/people/s/stefan-l-frank/>Stefan L. Frank</a>
|
<a href=/people/a/antal-van-den-bosch/>Antal van den Bosch</a>
|
<a href=/people/j/jorge-valdes-kroff/>Jorge Valdés Kroff</a>
|
<a href=/people/m/mirjam-broersma/>Mirjam Broersma</a><br><a href=/volumes/W19-29/ class=text-muted>Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2903><div class="card-body p-3 small">Multilingual speakers are able to switch from one language to the other (code-switch) between or within sentences. Because the underlying cognitive mechanisms are not well understood, in this study we use computational cognitive modeling to shed light on the process of <a href=https://en.wikipedia.org/wiki/Code-switching>code-switching</a>. We employed the Bilingual Dual-path model, a Recurrent Neural Network of bilingual sentence production (Tsoukala et al., 2017), and simulated <a href=https://en.wikipedia.org/wiki/Sentence_processing>sentence production</a> in simultaneous Spanish-English bilinguals. Our first goal was to investigate whether the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> would code-switch without being exposed to code-switched training input. The model indeed produced <a href=https://en.wikipedia.org/wiki/Code-switching>code-switches</a> even without any exposure to such <a href=https://en.wikipedia.org/wiki/Input_(computer_science)>input</a> and the patterns of code-switches are in line with earlier linguistic work (Poplack,1980). The second goal of this study was to investigate an auxiliary phrase asymmetry that exists in Spanish-English code-switched production. Using this <a href=https://en.wikipedia.org/wiki/Cognitive_model>cognitive model</a>, we examined a possible cause for this <a href=https://en.wikipedia.org/wiki/Asymmetry>asymmetry</a>. To our knowledge, this is the first computational cognitive model that aims to simulate code-switched sentence production.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2909.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2909 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2909 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2909/>Dependency Parsing with your Eyes : Dependency Structure Predicts Eye Regressions During Reading</a></strong><br><a href=/people/a/alessandro-lopopolo/>Alessandro Lopopolo</a>
|
<a href=/people/s/stefan-l-frank/>Stefan L. Frank</a>
|
<a href=/people/a/antal-van-den-bosch/>Antal van den Bosch</a>
|
<a href=/people/r/roel-willems/>Roel Willems</a><br><a href=/volumes/W19-29/ class=text-muted>Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2909><div class="card-body p-3 small">Backward saccades during <a href=https://en.wikipedia.org/wiki/Reading>reading</a> have been hypothesized to be involved in structural reanalysis, or to be related to the level of text difficulty. We test the hypothesis that backward saccades are involved in online syntactic analysis. If this is the case we expect that <a href=https://en.wikipedia.org/wiki/Saccade>saccades</a> will coincide, at least partially, with the <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>edges</a> of the relations computed by a <a href=https://en.wikipedia.org/wiki/Dependency_grammar>dependency parser</a>. In order to test this, we analyzed a large eye-tracking dataset collected while 102 participants read three short narrative texts. Our results show a relation between backward saccades and the <a href=https://en.wikipedia.org/wiki/Syntax>syntactic structure</a> of sentences.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1070.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1070 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1070 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=R19-1070" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/R19-1070/>Question Similarity in Community Question Answering : A Systematic Exploration of Preprocessing Methods and Models</a></strong><br><a href=/people/f/florian-kunneman/>Florian Kunneman</a>
|
<a href=/people/t/thiago-castro-ferreira/>Thiago Castro Ferreira</a>
|
<a href=/people/e/emiel-krahmer/>Emiel Krahmer</a>
|
<a href=/people/a/antal-van-den-bosch/>Antal van den Bosch</a><br><a href=/volumes/R19-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1070><div class="card-body p-3 small">Community Question Answering forums are popular among Internet users, and a basic problem they encounter is trying to find out if their question has already been posed before. To address this issue, NLP researchers have developed methods to automatically detect question-similarity, which was one of the shared tasks in <a href=https://en.wikipedia.org/wiki/SemEval>SemEval</a>. The best performing systems for this task made use of Syntactic Tree Kernels or the SoftCosine metric. However, it remains unclear why these methods seem to work, whether their performance can be improved by better preprocessing methods and what kinds of errors they (and other methods) make. In this paper, we therefore systematically combine and compare these two approaches with the more traditional BM25 and translation-based models. Moreover, we analyze the impact of preprocessing steps (lowercasing, suppression of punctuation and stop words removal) and word meaning similarity based on different distributions (word translation probability, Word2Vec, fastText and ELMo) on the performance of the task. We conduct an error analysis to gain insight into the differences in performance between the system set-ups. The implementation is made publicly available from https://github.com/fkunneman/DiscoSumo/tree/master/ranlp.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1188.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1188 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1188 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=C18-1188" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/C18-1188/>Aspect-based summarization of pros and cons in unstructured product reviews</a></strong><br><a href=/people/f/florian-kunneman/>Florian Kunneman</a>
|
<a href=/people/s/sander-wubben/>Sander Wubben</a>
|
<a href=/people/a/antal-van-den-bosch/>Antal van den Bosch</a>
|
<a href=/people/e/emiel-krahmer/>Emiel Krahmer</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1188><div class="card-body p-3 small">We developed three <a href=https://en.wikipedia.org/wiki/System>systems</a> for generating pros and cons summaries of product reviews. Automating this task eases the writing of product reviews, and offers readers quick access to the most important information. We compared SynPat, a system based on syntactic phrases selected on the basis of valence scores, against a neural-network-based system trained to map bag-of-words representations of reviews directly to pros and cons, and the same neural system trained on clusters of word-embedding encodings of similar pros and cons. We evaluated the <a href=https://en.wikipedia.org/wiki/System>systems</a> in two ways : first on held-out reviews with gold-standard pros and cons, and second by asking human annotators to rate the <a href=https://en.wikipedia.org/wiki/System>systems</a>&#8217; output on <a href=https://en.wikipedia.org/wiki/Relevance>relevance</a> and <a href=https://en.wikipedia.org/wiki/Completeness_(logic)>completeness</a>. In the second evaluation, the gold-standard pros and cons were assessed along with the system output. We find that the human-generated summaries are not deemed as significantly more relevant or complete than the SynPat systems ; the latter are scored higher than the human-generated summaries on a precision metric. The neural approaches yield a lower performance in the <a href=https://en.wikipedia.org/wiki/Human_factors_and_ergonomics>human assessment</a>, and are outperformed by the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a>.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1224.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1224 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1224 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1224/>Exploring Lexical and Syntactic Features for Language Variety Identification</a></strong><br><a href=/people/c/chris-van-der-lee/>Chris van der Lee</a>
|
<a href=/people/a/antal-van-den-bosch/>Antal van den Bosch</a><br><a href=/volumes/W17-12/ class=text-muted>Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1224><div class="card-body p-3 small">We present a method to discriminate between texts written in either the Netherlandic or the Flemish variant of the <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch language</a>. The method draws on a feature bundle representing text statistics, <a href=https://en.wikipedia.org/wiki/Syntax>syntactic features</a>, and <a href=https://en.wikipedia.org/wiki/N-gram>word n-grams</a>. Text statistics include average word length and <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence length</a>, while syntactic features include ratios of function words and part-of-speech n-grams. The effectiveness of the <a href=https://en.wikipedia.org/wiki/Classifier_(linguistics)>classifier</a> was measured by classifying <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch subtitles</a> developed for either <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a> or <a href=https://en.wikipedia.org/wiki/Vlaamse_Radio-_en_Televisieomroeporganisatie>Flemish television</a>. Several <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning algorithms</a> were compared as well as feature combination methods in order to find the optimal generalization performance. A machine-learning meta classifier based on <a href=https://en.wikipedia.org/wiki/AdaBoost>AdaBoost</a> attained the best <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> of 0.92.<tex-math>n</tex-math>-grams. Text statistics include average word length and sentence length, while syntactic features include ratios of function words and part-of-speech <tex-math>n</tex-math>-grams. The effectiveness of the classifier was measured by classifying Dutch subtitles developed for either Dutch or Flemish television. Several machine learning algorithms were compared as well as feature combination methods in order to find the optimal generalization performance. A machine-learning meta classifier based on AdaBoost attained the best F-score of 0.92.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Antal+van+den+Bosch" title="Search for 'Antal van den Bosch' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/s/stefan-l-frank/ class=align-middle>Stefan L. Frank</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/f/florian-kunneman/ class=align-middle>Florian Kunneman</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/emiel-krahmer/ class=align-middle>Emiel Krahmer</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sander-wubben/ class=align-middle>Sander Wubben</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chris-van-der-lee/ class=align-middle>Chris van der Lee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/j/jinbiao-yang/ class=align-middle>Jinbiao Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chara-tsoukala/ class=align-middle>Chara Tsoukala</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jorge-valdes-kroff/ class=align-middle>Jorge Valdés Kroff</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mirjam-broersma/ class=align-middle>Mirjam Broersma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alessandro-lopopolo/ class=align-middle>Alessandro Lopopolo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/roel-willems/ class=align-middle>Roel Willems</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thiago-castro-ferreira/ class=align-middle>Thiago Castro Ferreira</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/cogalex/ class=align-middle>CogALex</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ranlp/ class=align-middle>RANLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>