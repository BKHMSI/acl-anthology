<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Alexis Conneau - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Alexis</span> <span class=font-weight-bold>Conneau</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.68.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--68 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.68 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.68/>Multilingual Speech Translation from Efficient Finetuning of Pretrained Models</a></strong><br><a href=/people/x/xian-li/>Xian Li</a>
|
<a href=/people/c/changhan-wang/>Changhan Wang</a>
|
<a href=/people/y/yun-tang/>Yun Tang</a>
|
<a href=/people/c/chau-tran/>Chau Tran</a>
|
<a href=/people/y/yuqing-tang/>Yuqing Tang</a>
|
<a href=/people/j/juan-pino/>Juan Pino</a>
|
<a href=/people/a/alexei-baevski/>Alexei Baevski</a>
|
<a href=/people/a/alexis-conneau/>Alexis Conneau</a>
|
<a href=/people/m/michael-auli/>Michael Auli</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--68><div class="card-body p-3 small">We present a simple yet effective approach to build multilingual speech-to-text (ST) translation through efficient <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> from a pretrained speech encoder and text decoder. Our key finding is that a minimalistic LNA (LayerNorm and Attention) finetuning can achieve zero-shot crosslingual and cross-modality transfer ability by only finetuning 10 50 % of the pretrained parameters. This effectively leverages large pretrained models at low training cost such as wav2vec 2.0 for acoustic modeling, and mBART for multilingual text generation. This sets a new <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> for 36 translation directions (and surpassing cascaded ST for 26 of them) on the large-scale multilingual ST benchmark CoVoST 2 (+6.4 BLEU on average for En-X directions and +6.7 BLEU for X-En directions). Our approach demonstrates strong zero-shot performance in a many-to-many multilingual model (+5.6 BLEU on average across 28 non-English directions), making it an appealing approach for attaining high-quality <a href=https://en.wikipedia.org/wiki/Speech_translation>speech translation</a> with improved parameter and data efficiency.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mrl-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mrl-1.0/>Proceedings of the 1st Workshop on Multilingual Representation Learning</a></strong><br><a href=/people/d/duygu-ataman/>Duygu Ataman</a>
|
<a href=/people/a/alexandra-birch/>Alexandra Birch</a>
|
<a href=/people/a/alexis-conneau/>Alexis Conneau</a>
|
<a href=/people/o/orhan-firat/>Orhan Firat</a>
|
<a href=/people/s/sebastian-ruder/>Sebastian Ruder</a>
|
<a href=/people/g/gozde-gul-sahin/>Gozde Gul Sahin</a><br><a href=/volumes/2021.mrl-1/ class=text-muted>Proceedings of the 1st Workshop on Multilingual Representation Learning</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.536.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--536 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.536 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928831 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.536/>Emerging Cross-lingual Structure in Pretrained Language Models</a></strong><br><a href=/people/a/alexis-conneau/>Alexis Conneau</a>
|
<a href=/people/s/shijie-wu/>Shijie Wu</a>
|
<a href=/people/h/haoran-li/>Haoran Li</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a>
|
<a href=/people/v/veselin-stoyanov/>Veselin Stoyanov</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--536><div class="card-body p-3 small">We study the problem of multilingual masked language modeling, i.e. the training of a single <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> on concatenated text from multiple languages, and present a detailed study of several factors that influence why these <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> are so effective for cross-lingual transfer. We show, contrary to what was previously hypothesized, that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains. The only requirement is that there are some shared parameters in the top layers of the multi-lingual encoder. To better understand this result, we also show that representations from monolingual BERT models in different languages can be aligned post-hoc quite effectively, strongly suggesting that, much like for non-contextual word embeddings, there are universal latent symmetries in the learned embedding spaces. For multilingual masked language modeling, these <a href=https://en.wikipedia.org/wiki/Symmetry>symmetries</a> are automatically discovered and aligned during the joint training process.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.747.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--747 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.747 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928776 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.747" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.747/>Unsupervised Cross-lingual Representation Learning at Scale</a></strong><br><a href=/people/a/alexis-conneau/>Alexis Conneau</a>
|
<a href=/people/k/kartikay-khandelwal/>Kartikay Khandelwal</a>
|
<a href=/people/n/naman-goyal/>Naman Goyal</a>
|
<a href=/people/v/vishrav-chaudhary/>Vishrav Chaudhary</a>
|
<a href=/people/g/guillaume-wenzek/>Guillaume Wenzek</a>
|
<a href=/people/f/francisco-guzman/>Francisco Guzmán</a>
|
<a href=/people/e/edouard-grave/>Edouard Grave</a>
|
<a href=/people/m/myle-ott/>Myle Ott</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a>
|
<a href=/people/v/veselin-stoyanov/>Veselin Stoyanov</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--747><div class="card-body p-3 small">This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a wide range of cross-lingual transfer tasks. We train a Transformer-based masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +14.6 % average accuracy on XNLI, +13 % average F1 score on MLQA, and +2.4 % F1 score on NER. XLM-R performs particularly well on low-resource languages, improving 15.7 % in XNLI accuracy for <a href=https://en.wikipedia.org/wiki/Swahili_language>Swahili</a> and 11.4 % for <a href=https://en.wikipedia.org/wiki/Urdu>Urdu</a> over previous XLM models. We also present a detailed empirical analysis of the key factors that are required to achieve these gains, including the trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing per-language performance ; XLM-R is very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We will make our code and models publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.494.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--494 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.494 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.lrec-1.494" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.494/>CCNet : Extracting High Quality Monolingual Datasets from Web Crawl Data<span class=acl-fixed-case>CCN</span>et: Extracting High Quality Monolingual Datasets from Web Crawl Data</a></strong><br><a href=/people/g/guillaume-wenzek/>Guillaume Wenzek</a>
|
<a href=/people/m/marie-anne-lachaux/>Marie-Anne Lachaux</a>
|
<a href=/people/a/alexis-conneau/>Alexis Conneau</a>
|
<a href=/people/v/vishrav-chaudhary/>Vishrav Chaudhary</a>
|
<a href=/people/f/francisco-guzman/>Francisco Guzmán</a>
|
<a href=/people/a/armand-joulin/>Armand Joulin</a>
|
<a href=/people/e/edouard-grave/>Edouard Grave</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--494><div class="card-body p-3 small">Pre-training text representations have led to significant improvements in many areas of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. The quality of these <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> benefits greatly from the size of the pretraining corpora as long as its quality is preserved. In this paper, we describe an automatic pipeline to extract massive high-quality monolingual datasets from <a href=https://en.wikipedia.org/wiki/Common_Crawl>Common Crawl</a> for a variety of languages. Our <a href=https://en.wikipedia.org/wiki/Pipeline_(computing)>pipeline</a> follows the <a href=https://en.wikipedia.org/wiki/Data_processing>data processing</a> introduced in <a href=https://en.wikipedia.org/wiki/FastText>fastText</a> (Mikolov et al., 2017 ; Grave et al., 2018), that deduplicates documents and identifies their language. We augment this <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline</a> with a filtering step to select documents that are close to high quality corpora like <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4300.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4300/>Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)</a></strong><br><a href=/people/i/isabelle-augenstein/>Isabelle Augenstein</a>
|
<a href=/people/s/spandana-gella/>Spandana Gella</a>
|
<a href=/people/s/sebastian-ruder/>Sebastian Ruder</a>
|
<a href=/people/k/katharina-kann/>Katharina Kann</a>
|
<a href=/people/b/burcu-can/>Burcu Can</a>
|
<a href=/people/j/johannes-welbl/>Johannes Welbl</a>
|
<a href=/people/a/alexis-conneau/>Alexis Conneau</a>
|
<a href=/people/x/xiang-ren/>Xiang Ren</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a><br><a href=/volumes/W19-43/ class=text-muted>Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)</a></span></p><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1269.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1269 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1269 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/305665271 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1269" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1269/>XNLI : Evaluating Cross-lingual Sentence Representations<span class=acl-fixed-case>XNLI</span>: Evaluating Cross-lingual Sentence Representations</a></strong><br><a href=/people/a/alexis-conneau/>Alexis Conneau</a>
|
<a href=/people/r/ruty-rinott/>Ruty Rinott</a>
|
<a href=/people/g/guillaume-lample/>Guillaume Lample</a>
|
<a href=/people/a/adina-williams/>Adina Williams</a>
|
<a href=/people/s/samuel-bowman/>Samuel Bowman</a>
|
<a href=/people/h/holger-schwenk/>Holger Schwenk</a>
|
<a href=/people/v/veselin-stoyanov/>Veselin Stoyanov</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1269><div class="card-body p-3 small">State-of-the-art <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing systems</a> rely on <a href=https://en.wikipedia.org/wiki/Supervisor>supervision</a> in the form of <a href=https://en.wikipedia.org/wiki/Annotation>annotated data</a> to learn competent <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a>. These <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> are generally trained on data in a single language (usually English), and can not be directly used beyond that language. Since collecting data in every language is not realistic, there has been a growing interest in cross-lingual language understanding (XLU) and low-resource cross-language transfer. In this work, we construct an evaluation set for XLU by extending the development and test sets of the Multi-Genre Natural Language Inference Corpus (MultiNLI) to 14 languages, including low-resource languages such as <a href=https://en.wikipedia.org/wiki/Swahili_language>Swahili</a> and <a href=https://en.wikipedia.org/wiki/Urdu>Urdu</a>. We hope that our dataset, dubbed XNLI, will catalyze research in cross-lingual sentence understanding by providing an informative standard evaluation task. In addition, we provide several baselines for multilingual sentence understanding, including two based on machine translation systems, and two that use parallel data to train aligned multilingual bag-of-words and LSTM encoders. We find that XNLI represents a practical and challenging evaluation suite, and that directly translating the test data yields the best performance among available <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1198.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1198 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1198 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1198.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1198.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805339 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1198/>What you can cram into a single $ & ! # * vector : Probing sentence embeddings for linguistic properties</a></strong><br><a href=/people/a/alexis-conneau/>Alexis Conneau</a>
|
<a href=/people/g/german-kruszewski/>German Kruszewski</a>
|
<a href=/people/g/guillaume-lample/>Guillaume Lample</a>
|
<a href=/people/l/loic-barrault/>Loïc Barrault</a>
|
<a href=/people/m/marco-baroni/>Marco Baroni</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1198><div class="card-body p-3 small">Although much effort has recently been devoted to training high-quality <a href=https://en.wikipedia.org/wiki/Sentence_embedding>sentence embeddings</a>, we still have a poor understanding of what they are capturing. Downstream tasks, often based on sentence classification, are commonly used to evaluate the quality of sentence representations. The <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a> of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> makes it however difficult to infer what kind of information is present in the <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a>. We introduce here 10 probing tasks designed to capture simple linguistic features of sentences, and we use them to study embeddings generated by three different <a href=https://en.wikipedia.org/wiki/Encoder>encoders</a> trained in eight distinct ways, uncovering intriguing properties of both <a href=https://en.wikipedia.org/wiki/Encoder>encoders</a> and training methods.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1070.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1070 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1070 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238236002 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D17-1070" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1070/>Supervised Learning of Universal Sentence Representations from Natural Language Inference Data</a></strong><br><a href=/people/a/alexis-conneau/>Alexis Conneau</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/h/holger-schwenk/>Holger Schwenk</a>
|
<a href=/people/l/loic-barrault/>Loïc Barrault</a>
|
<a href=/people/a/antoine-bordes/>Antoine Bordes</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1070><div class="card-body p-3 small">Many modern NLP systems rely on <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>, previously trained in an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised manner</a> on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised data</a> of the Stanford Natural Language Inference datasets can consistently outperform <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised methods</a> like SkipThought vectors on a wide range of transfer tasks. Much like how <a href=https://en.wikipedia.org/wiki/Computer_vision>computer vision</a> uses <a href=https://en.wikipedia.org/wiki/ImageNet>ImageNet</a> to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> to other NLP tasks. Our <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> is publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-1104.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-1104 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-1104 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=E17-1104" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/E17-1104/>Very Deep Convolutional Networks for Text Classification</a></strong><br><a href=/people/a/alexis-conneau/>Alexis Conneau</a>
|
<a href=/people/h/holger-schwenk/>Holger Schwenk</a>
|
<a href=/people/l/loic-barrault/>Loïc Barrault</a>
|
<a href=/people/y/yann-lecun/>Yann Lecun</a><br><a href=/volumes/E17-1/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-1104><div class="card-body p-3 small">The dominant approach for many NLP tasks are <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural networks</a>, in particular LSTMs, and <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural networks</a>. However, these <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a> are rather shallow in comparison to the deep convolutional networks which have pushed the state-of-the-art in <a href=https://en.wikipedia.org/wiki/Computer_vision>computer vision</a>. We present a new architecture (VDCNN) for text processing which operates directly at the character level and uses only small convolutions and pooling operations. We are able to show that the performance of this model increases with the depth : using up to 29 convolutional layers, we report improvements over the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> on several public text classification tasks. To the best of our knowledge, this is the first time that very deep convolutional nets have been applied to <a href=https://en.wikipedia.org/wiki/Text_processing>text processing</a>.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Alexis+Conneau" title="Search for 'Alexis Conneau' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/v/veselin-stoyanov/ class=align-middle>Veselin Stoyanov</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/h/holger-schwenk/ class=align-middle>Holger Schwenk</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/loic-barrault/ class=align-middle>Loïc Barrault</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/luke-zettlemoyer/ class=align-middle>Luke Zettlemoyer</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/v/vishrav-chaudhary/ class=align-middle>Vishrav Chaudhary</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/g/guillaume-wenzek/ class=align-middle>Guillaume Wenzek</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/f/francisco-guzman/ class=align-middle>Francisco Guzmán</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/edouard-grave/ class=align-middle>Édouard Grave</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/g/guillaume-lample/ class=align-middle>Guillaume Lample</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sebastian-ruder/ class=align-middle>Sebastian Ruder</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/x/xian-li/ class=align-middle>Xian Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/changhan-wang/ class=align-middle>Changhan Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yun-tang/ class=align-middle>Yun Tang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chau-tran/ class=align-middle>Chau Tran</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yuqing-tang/ class=align-middle>Yuqing Tang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/juan-pino/ class=align-middle>Juan Pino</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexei-baevski/ class=align-middle>Alexei Baevski</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-auli/ class=align-middle>Michael Auli</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shijie-wu/ class=align-middle>Shijie Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haoran-li/ class=align-middle>Haoran Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kartikay-khandelwal/ class=align-middle>Kartikay Khandelwal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/naman-goyal/ class=align-middle>Naman Goyal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/myle-ott/ class=align-middle>Myle Ott</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ruty-rinott/ class=align-middle>Ruty Rinott</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/adina-williams/ class=align-middle>Adina Williams</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/samuel-bowman/ class=align-middle>Samuel Bowman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/duygu-ataman/ class=align-middle>Duygu Ataman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexandra-birch/ class=align-middle>Alexandra Birch</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/orhan-firat/ class=align-middle>Orhan Firat</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gozde-gul-sahin/ class=align-middle>Gözde Gül Şahin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/douwe-kiela/ class=align-middle>Douwe Kiela</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/antoine-bordes/ class=align-middle>Antoine Bordes</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/isabelle-augenstein/ class=align-middle>Isabelle Augenstein</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/spandana-gella/ class=align-middle>Spandana Gella</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/katharina-kann/ class=align-middle>Katharina Kann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/burcu-can/ class=align-middle>Burcu Can</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/johannes-welbl/ class=align-middle>Johannes Welbl</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiang-ren/ class=align-middle>Xiang Ren</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marek-rei/ class=align-middle>Marek Rei</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marie-anne-lachaux/ class=align-middle>Marie-Anne Lachaux</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/armand-joulin/ class=align-middle>Armand Joulin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yann-lecun/ class=align-middle>Yann Lecun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/german-kruszewski/ class=align-middle>Germán Kruszewski</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marco-baroni/ class=align-middle>Marco Baroni</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/mrl/ class=align-middle>MRL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>