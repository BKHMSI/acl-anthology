<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Andreas Vlachos - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Andreas</span> <span class=font-weight-bold>Vlachos</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.678.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--678 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.678 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.678/>Cross-Policy Compliance Detection via Question Answering</a></strong><br><a href=/people/m/marzieh-saeidi/>Marzieh Saeidi</a>
|
<a href=/people/m/majid-yazdani/>Majid Yazdani</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--678><div class="card-body p-3 small">Policy compliance detection is the task of ensuring that a scenario conforms to a <a href=https://en.wikipedia.org/wiki/Policy>policy</a> (e.g. a claim is valid according to government rules or a post in an online platform conforms to community guidelines). This task has been previously instantiated as a form of <a href=https://en.wikipedia.org/wiki/Textual_entailment>textual entailment</a>, which results in poor <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> due to the <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a> of the <a href=https://en.wikipedia.org/wiki/Policy>policies</a>. In this paper we propose to address <a href=https://en.wikipedia.org/wiki/Policy>policy compliance detection</a> via decomposing it into <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>, where questions check whether the conditions stated in the <a href=https://en.wikipedia.org/wiki/Policy>policy</a> apply to the scenario, and an <a href=https://en.wikipedia.org/wiki/Expression_tree>expression tree</a> combines the answers to obtain the label. Despite the initial upfront annotation cost, we demonstrate that this approach results in better <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, especially in the cross-policy setup where the <a href=https://en.wikipedia.org/wiki/Policy>policies</a> during testing are unseen in training. In addition, it allows us to use existing <a href=https://en.wikipedia.org/wiki/Question_answering>question answering models</a> pre-trained on existing <a href=https://en.wikipedia.org/wiki/Data_set>large datasets</a>. Finally, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> explicitly identifies the information missing from a scenario in case policy compliance can not be determined. We conduct our experiments using a recent dataset consisting of government policies, which we augment with expert annotations and find that the cost of annotating question answering decomposition is largely offset by improved inter-annotator agreement and speed.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.fever-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.fever-1.0/>Proceedings of the Fourth Workshop on Fact Extraction and VERification (FEVER)</a></strong><br><a href=/people/r/rami-aly/>Rami Aly</a>
|
<a href=/people/c/christos-christodoulopoulos/>Christos Christodoulopoulos</a>
|
<a href=/people/o/oana-cocarascu/>Oana Cocarascu</a>
|
<a href=/people/z/zhijiang-guo/>Zhijiang Guo</a>
|
<a href=/people/a/arpit-mittal/>Arpit Mittal</a>
|
<a href=/people/m/michael-schlichtkrull/>Michael Schlichtkrull</a>
|
<a href=/people/j/james-thorne/>James Thorne</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a><br><a href=/volumes/2021.fever-1/ class=text-muted>Proceedings of the Fourth Workshop on Fact Extraction and VERification (FEVER)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.fever-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--fever-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.fever-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.fever-1.1/>The Fact Extraction and VERification Over Unstructured and Structured information (FEVEROUS) Shared Task<span class=acl-fixed-case>VER</span>ification Over Unstructured and Structured information (<span class=acl-fixed-case>FEVEROUS</span>) Shared Task</a></strong><br><a href=/people/r/rami-aly/>Rami Aly</a>
|
<a href=/people/z/zhijiang-guo/>Zhijiang Guo</a>
|
<a href=/people/m/michael-sejr-schlichtkrull/>Michael Sejr Schlichtkrull</a>
|
<a href=/people/j/james-thorne/>James Thorne</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a>
|
<a href=/people/c/christos-christodoulopoulos/>Christos Christodoulopoulos</a>
|
<a href=/people/o/oana-cocarascu/>Oana Cocarascu</a>
|
<a href=/people/a/arpit-mittal/>Arpit Mittal</a><br><a href=/volumes/2021.fever-1/ class=text-muted>Proceedings of the Fourth Workshop on Fact Extraction and VERification (FEVER)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--fever-1--1><div class="card-body p-3 small">The Fact Extraction and VERification Over Unstructured and Structured information (FEVEROUS) shared task, asks participating systems to determine whether human-authored claims are Supported or Refuted based on evidence retrieved from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a> (or NotEnoughInfo if the claim can not be verified). Compared to the FEVER 2018 shared task, the main challenge is the addition of structured data (tables and lists) as a source of evidence. The claims in the FEVEROUS dataset can be verified using only structured evidence, only unstructured evidence, or a mixture of both. Submissions are evaluated using the FEVEROUS score that combines label accuracy and evidence retrieval. Unlike FEVER 2018, FEVEROUS requires partial evidence to be returned for NotEnoughInfo claims, and the claims are longer and thus more complex. The shared task received 13 entries, six of which were able to beat the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline system</a>. The winning team was Bust a move !, achieving a FEVEROUS score of 27 % (+9 % compared to the baseline). In this paper we describe the shared task, present the full results and highlight commonalities and innovations among the participating systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.adaptnlp-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--adaptnlp-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.adaptnlp-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.adaptnlp-1.15/>Trajectory-Based Meta-Learning for Out-Of-Vocabulary Word Embedding Learning</a></strong><br><a href=/people/g/gordon-buck/>Gordon Buck</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a><br><a href=/volumes/2021.adaptnlp-1/ class=text-muted>Proceedings of the Second Workshop on Domain Adaptation for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--adaptnlp-1--15><div class="card-body p-3 small">Word embedding learning methods require a large number of occurrences of a word to accurately learn its embedding. However, out-of-vocabulary (OOV) words which do not appear in the training corpus emerge frequently in the smaller downstream data. Recent work formulated OOV embedding learning as a few-shot regression problem and demonstrated that <a href=https://en.wikipedia.org/wiki/Meta-learning>meta-learning</a> can improve results obtained. However, the <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> used, model-agnostic meta-learning (MAML) is known to be unstable and perform worse when a large number of gradient steps are used for parameter updates. In this work, we propose the use of Leap, a meta-learning algorithm which leverages the entire trajectory of the learning process instead of just the beginning and the end points, and thus ameliorates these two issues. In our experiments on a benchmark OOV embedding learning dataset and in an extrinsic evaluation, Leap performs comparably or better than MAML. We go on to examine which contexts are most beneficial to learn an OOV embedding from, and propose that the choice of contexts may matter more than the meta-learning employed.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.spnlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.spnlp-1.0/>Proceedings of the 5th Workshop on Structured Prediction for NLP (SPNLP 2021)</a></strong><br><a href=/people/z/zornitsa-kozareva/>Zornitsa Kozareva</a>
|
<a href=/people/s/sujith-ravi/>Sujith Ravi</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a>
|
<a href=/people/p/priyanka-agrawal/>Priyanka Agrawal</a>
|
<a href=/people/a/andre-f-t-martins/>André Martins</a><br><a href=/volumes/2021.spnlp-1/ class=text-muted>Proceedings of the 5th Workshop on Structured Prediction for NLP (SPNLP 2021)</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.spnlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.spnlp-1.0/>Proceedings of the Fourth Workshop on Structured Prediction for NLP</a></strong><br><a href=/people/p/priyanka-agrawal/>Priyanka Agrawal</a>
|
<a href=/people/z/zornitsa-kozareva/>Zornitsa Kozareva</a>
|
<a href=/people/j/julia-kreutzer/>Julia Kreutzer</a>
|
<a href=/people/g/gerasimos-lampouras/>Gerasimos Lampouras</a>
|
<a href=/people/a/andre-f-t-martins/>André Martins</a>
|
<a href=/people/s/sujith-ravi/>Sujith Ravi</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a><br><a href=/volumes/2020.spnlp-1/ class=text-muted>Proceedings of the Fourth Workshop on Structured Prediction for NLP</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.fever-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.fever-1.0/>Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)</a></strong><br><a href=/people/c/christos-christodoulopoulos/>Christos Christodoulopoulos</a>
|
<a href=/people/j/james-thorne/>James Thorne</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a>
|
<a href=/people/o/oana-cocarascu/>Oana Cocarascu</a>
|
<a href=/people/a/arpit-mittal/>Arpit Mittal</a><br><a href=/volumes/2020.fever-1/ class=text-muted>Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1233.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1233 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1233 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1233/>Neural Generative Rhetorical Structure Parsing</a></strong><br><a href=/people/a/amandla-mabona/>Amandla Mabona</a>
|
<a href=/people/l/laura-rimell/>Laura Rimell</a>
|
<a href=/people/s/stephen-clark/>Stephen Clark</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1233><div class="card-body p-3 small">Rhetorical structure trees have been shown to be useful for several document-level tasks including <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> and <a href=https://en.wikipedia.org/wiki/Document_classification>document classification</a>. Previous approaches to RST parsing have used <a href=https://en.wikipedia.org/wiki/Discriminative_model>discriminative models</a> ; however, these are less sample efficient than <a href=https://en.wikipedia.org/wiki/Generative_model>generative models</a>, and RST parsing datasets are typically small. In this paper, we present the first <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> for RST parsing. Our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is a document-level RNN grammar (RNNG) with a <a href=https://en.wikipedia.org/wiki/Top-down_and_bottom-up_design>bottom-up traversal order</a>. We show that, for our parser&#8217;s traversal order, previous beam search algorithms for RNNGs have a left-branching bias which is ill-suited for RST parsing. We develop a novel beam search algorithm that keeps track of both structure-and word-generating actions without exhibit-ing this branching bias and results in absolute improvements of 6.8 and 2.9 on unlabelled and labelled F1 over previous <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a>. Overall, our <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> outperforms a <a href=https://en.wikipedia.org/wiki/Discriminative_model>discriminative model</a> with the same <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> by 2.6 <a href=https://en.wikipedia.org/wiki/F-number>F1points</a> and achieves performance comparable to the state-of-the-art, outperforming all published parsers from a recent replication study that do not use additional training data</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6600.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6600/>Proceedings of the Second Workshop on Fact Extraction and VERification (FEVER)</a></strong><br><a href=/people/j/james-thorne/>James Thorne</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a>
|
<a href=/people/o/oana-cocarascu/>Oana Cocarascu</a>
|
<a href=/people/c/christos-christodoulopoulos/>Christos Christodoulopoulos</a>
|
<a href=/people/a/arpit-mittal/>Arpit Mittal</a><br><a href=/volumes/D19-66/ class=text-muted>Proceedings of the Second Workshop on Fact Extraction and VERification (FEVER)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-1500.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-1500/>Proceedings of the Third Workshop on Structured Prediction for <span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/a/andre-f-t-martins/>Andre Martins</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a>
|
<a href=/people/z/zornitsa-kozareva/>Zornitsa Kozareva</a>
|
<a href=/people/s/sujith-ravi/>Sujith Ravi</a>
|
<a href=/people/g/gerasimos-lampouras/>Gerasimos Lampouras</a>
|
<a href=/people/v/vlad-niculae/>Vlad Niculae</a>
|
<a href=/people/j/julia-kreutzer/>Julia Kreutzer</a><br><a href=/volumes/W19-15/ class=text-muted>Proceedings of the Third Workshop on Structured Prediction for NLP</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1101.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1101 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1101 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-1101/>Generating Token-Level Explanations for Natural Language Inference</a></strong><br><a href=/people/j/james-thorne/>James Thorne</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a>
|
<a href=/people/c/christos-christodoulopoulos/>Christos Christodoulopoulos</a>
|
<a href=/people/a/arpit-mittal/>Arpit Mittal</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1101><div class="card-body p-3 small">The task of Natural Language Inference (NLI) is widely modeled as supervised sentence pair classification. While there has been a lot of work recently on generating explanations of the predictions of <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> on a single piece of text, there have been no attempts to generate explanations of <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> operating on pairs of sentences. In this paper, we show that it is possible to generate token-level explanations for NLI without the need for training data explicitly annotated for this purpose. We use a simple LSTM architecture and evaluate both LIME and Anchor explanations for this task. We compare these to a Multiple Instance Learning (MIL) method that uses thresholded attention make token-level predictions. The approach we present in this paper is a novel extension of zero-shot single-sentence tagging to sentence pairs for NLI. We conduct our experiments on the well-studied SNLI dataset that was recently augmented with manually annotation of the tokens that explain the <a href=https://en.wikipedia.org/wiki/Logical_consequence>entailment relation</a>. We find that our white-box MIL-based method, while orders of magnitude faster, does not reach the same <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> as the black-box methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1330.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1330 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1330 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1330.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384768559 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1330" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1330/>HighRES : Highlight-based Reference-less Evaluation of Summarization<span class=acl-fixed-case>H</span>igh<span class=acl-fixed-case>RES</span>: Highlight-based Reference-less Evaluation of Summarization</a></strong><br><a href=/people/h/hardy-hardy/>Hardy Hardy</a>
|
<a href=/people/s/shashi-narayan/>Shashi Narayan</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1330><div class="card-body p-3 small">There has been substantial progress in <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> research enabled by the availability of novel, often large-scale, datasets and recent advances on neural network-based approaches. However, manual evaluation of the system generated summaries is inconsistent due to the difficulty the task poses to human non-expert readers. To address this issue, we propose a novel approach for manual evaluation, Highlight-based Reference-less Evaluation of Summarization (HighRES), in which summaries are assessed by multiple annotators against the source document via manually highlighted salient content in the latter. Thus summary assessment on the source document by human judges is facilitated, while the highlights can be used for evaluating multiple systems. To validate our approach we employ crowd-workers to augment with highlights a recently proposed dataset and compare two state-of-the-art systems. We demonstrate that HighRES improves inter-annotator agreement in comparison to using the source document directly, while they help emphasize differences among systems that would be ignored under other evaluation approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1585.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1585 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1585 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385226453 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1585" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1585/>Merge and Label : A Novel Neural Network Architecture for Nested NER<span class=acl-fixed-case>NER</span></a></strong><br><a href=/people/j/joseph-fisher/>Joseph Fisher</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1585><div class="card-body p-3 small">Named entity recognition (NER) is one of the best studied tasks in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. However, most approaches are not capable of handling nested structures which are common in many applications. In this paper we introduce a novel neural network architecture that first merges tokens and/or entities into entities forming nested structures, and then labels each of them independently. Unlike previous work, our merge and label approach predicts real-valued instead of discrete segmentation structures, which allow it to combine word and nested entity embeddings while maintaining differentiability. We evaluate our approach using the ACE 2005 Corpus, where it achieves state-of-the-art F1 of 74.6, further improved with contextual embeddings (BERT) to 82.4, an overall improvement of close to 8 F1 points over previous approaches trained on the same data. Additionally we compare it against BiLSTM-CRFs, the dominant approach for flat NER structures, demonstrating that its ability to predict nested structures does not impact performance in simpler cases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1589.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1589 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1589 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385243188 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1589/>Model-Agnostic Meta-Learning for Relation Classification with Limited Supervision</a></strong><br><a href=/people/a/abiola-obamuyide/>Abiola Obamuyide</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1589><div class="card-body p-3 small">In this paper we frame the task of supervised relation classification as an instance of <a href=https://en.wikipedia.org/wiki/Meta-learning>meta-learning</a>. We propose a model-agnostic meta-learning protocol for training relation classifiers to achieve enhanced predictive performance in limited supervision settings. During <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a>, we aim to not only learn good parameters for classifying relations with sufficient supervision, but also learn model parameters that can be fine-tuned to enhance predictive performance for relations with limited supervision. In experiments conducted on two relation classification datasets, we demonstrate that the proposed meta-learning approach improves the predictive performance of two state-of-the-art supervised relation classification models.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1283.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1283 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1283 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-1283/>Automated Fact Checking : Task Formulations, Methods and Future Directions</a></strong><br><a href=/people/j/james-thorne/>James Thorne</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1283><div class="card-body p-3 small">The recently increased focus on <a href=https://en.wikipedia.org/wiki/Misinformation>misinformation</a> has stimulated research in <a href=https://en.wikipedia.org/wiki/Fact-checking>fact checking</a>, the task of assessing the truthfulness of a claim. Research in automating this task has been conducted in a variety of disciplines including <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>, <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a>, <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>knowledge representation</a>, <a href=https://en.wikipedia.org/wiki/Database>databases</a>, and <a href=https://en.wikipedia.org/wiki/Journalism>journalism</a>. While there has been substantial progress, relevant papers and articles have been published in research communities that are often unaware of each other and use inconsistent terminology, thus impeding understanding and further progress. In this paper we survey automated fact checking research stemming from <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> and related disciplines, unifying the task formulations and methodologies across papers and authors. Furthermore, we highlight the use of evidence as an important distinguishing factor among them cutting across task formulations and methods. We conclude with proposing avenues for future NLP research on automated fact checking.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5500.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5500/>Proceedings of the First Workshop on Fact Extraction and <span class=acl-fixed-case>VER</span>ification (<span class=acl-fixed-case>FEVER</span>)</a></strong><br><a href=/people/j/james-thorne/>James Thorne</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a>
|
<a href=/people/o/oana-cocarascu/>Oana Cocarascu</a>
|
<a href=/people/c/christos-christodoulopoulos/>Christos Christodoulopoulos</a>
|
<a href=/people/a/arpit-mittal/>Arpit Mittal</a><br><a href=/volumes/W18-55/ class=text-muted>Proceedings of the First Workshop on Fact Extraction and VERification (FEVER)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5501.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5501 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5501 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5501/>The Fact Extraction and VERification (FEVER) Shared Task<span class=acl-fixed-case>VER</span>ification (<span class=acl-fixed-case>FEVER</span>) Shared Task</a></strong><br><a href=/people/j/james-thorne/>James Thorne</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a>
|
<a href=/people/o/oana-cocarascu/>Oana Cocarascu</a>
|
<a href=/people/c/christos-christodoulopoulos/>Christos Christodoulopoulos</a>
|
<a href=/people/a/arpit-mittal/>Arpit Mittal</a><br><a href=/volumes/W18-55/ class=text-muted>Proceedings of the First Workshop on Fact Extraction and VERification (FEVER)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5501><div class="card-body p-3 small">We present the results of the first Fact Extraction and VERification (FEVER) Shared Task. The task challenged participants to classify whether human-written factoid claims could be SUPPORTED or REFUTED using evidence retrieved from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>. We received entries from 23 competing teams, 19 of which scored higher than the previously published baseline. The best performing <a href=https://en.wikipedia.org/wiki/System>system</a> achieved a <a href=https://en.wikipedia.org/wiki/Fever>FEVER score</a> of 64.21 %. In this paper, we present the results of the shared task and a summary of the <a href=https://en.wikipedia.org/wiki/System>systems</a>, highlighting commonalities and innovations among participating systems.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4214.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4214 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4214 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4214/>Fake news stance detection using stacked ensemble of classifiers</a></strong><br><a href=/people/j/james-thorne/>James Thorne</a>
|
<a href=/people/m/mingjie-chen/>Mingjie Chen</a>
|
<a href=/people/g/giorgos-myrianthous/>Giorgos Myrianthous</a>
|
<a href=/people/j/jiashu-pu/>Jiashu Pu</a>
|
<a href=/people/x/xiaoxuan-wang/>Xiaoxuan Wang</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a><br><a href=/volumes/W17-42/ class=text-muted>Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4214><div class="card-body p-3 small">Fake news has become a hotly debated topic in <a href=https://en.wikipedia.org/wiki/Journalism>journalism</a>. In this paper, we present our entry to the 2017 Fake News Challenge which models the detection of fake news as a stance classification task that finished in 11th place on the leader board. Our entry is an ensemble system of classifiers developed by students in the context of their coursework. We show how we used the stacking ensemble method for this purpose and obtained improvements in classification accuracy exceeding each of the individual models&#8217; performance on the development data. Finally, we discuss aspects of the experimental setup of the challenge.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2096.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2096 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2096 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2096/>Sheffield at SemEval-2017 Task 9 : Transition-based language generation from AMR.<span class=acl-fixed-case>S</span>heffield at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 9: Transition-based language generation from <span class=acl-fixed-case>AMR</span>.</a></strong><br><a href=/people/g/gerasimos-lampouras/>Gerasimos Lampouras</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2096><div class="card-body p-3 small">This paper describes the submission by the University of Sheffield to the SemEval 2017 Abstract Meaning Representation Parsing and Generation task (SemEval 2017 Task 9, Subtask 2). We cast language generation from AMR as a sequence of <a href=https://en.wikipedia.org/wiki/Action_(philosophy)>actions</a> (e.g., insert / remove / rename edges and nodes) that progressively transform the AMR graph into a dependency parse tree. This transition-based approach relies on the fact that an AMR graph can be considered structurally similar to a dependency tree, with a focus on content rather than <a href=https://en.wikipedia.org/wiki/Function_word>function words</a>. An added benefit to this approach is the greater amount of data we can take advantage of to train the parse-to-text linearizer. Our submitted run on the <a href=https://en.wikipedia.org/wiki/Test_(assessment)>test data</a> achieved a <a href=https://en.wikipedia.org/wiki/BLEU>BLEU score</a> of 3.32 and a Trueskill score of -22.04 on <a href=https://en.wikipedia.org/wiki/Human_factors_and_ergonomics>automatic and human evaluation</a> respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-2043.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-2043 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-2043 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-2043/>Continuous N-gram Representations for Authorship Attribution</a></strong><br><a href=/people/y/yunita-sari/>Yunita Sari</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a>
|
<a href=/people/m/mark-stevenson/>Mark Stevenson</a><br><a href=/volumes/E17-2/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-2043><div class="card-body p-3 small">This paper presents work on using continuous representations for <a href=https://en.wikipedia.org/wiki/Attribution_(copyright)>authorship attribution</a>. In contrast to previous work, which uses discrete feature representations, our model learns continuous representations for <a href=https://en.wikipedia.org/wiki/N-gram>n-gram features</a> via a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> jointly with the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification layer</a>. Experimental results demonstrate that the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> on two datasets, while producing comparable results on the remaining two.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-3010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-3010 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-3010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-3010/>An Extensible Framework for Verification of Numerical Claims</a></strong><br><a href=/people/j/james-thorne/>James Thorne</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a><br><a href=/volumes/E17-3/ class=text-muted>Proceedings of the Software Demonstrations of the 15th Conference of the European Chapter of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-3010><div class="card-body p-3 small">In this paper we present our automated fact checking system demonstration which we developed in order to participate in the Fast and Furious Fact Check challenge. We focused on simple numerical claims such as population of Germany in 2015 was 80 million which comprised a quarter of the test instances in the challenge, achieving 68 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. Our system extends previous work on semantic parsing and claim identification to handle temporal expressions and knowledge bases consisting of multiple tables, while relying solely on automatically generated training data. We demonstrate the extensible nature of our <a href=https://en.wikipedia.org/wiki/System>system</a> by evaluating <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> on relations used in previous work. We make our <a href=https://en.wikipedia.org/wiki/System>system</a> publicly available so that <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> can be used and extended by the community.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-5003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-5003 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-5003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-5003/>Imitation learning for <a href=https://en.wikipedia.org/wiki/Structured_prediction>structured prediction</a> in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a></a></strong><br><a href=/people/a/andreas-vlachos/>Andreas Vlachos</a>
|
<a href=/people/g/gerasimos-lampouras/>Gerasimos Lampouras</a>
|
<a href=/people/s/sebastian-riedel/>Sebastian Riedel</a><br><a href=/volumes/E17-5/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Tutorial Abstracts</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-5003><div class="card-body p-3 small">Imitation learning is a learning paradigm originally developed to learn <a href=https://en.wikipedia.org/wiki/Robot_control>robotic controllers</a> from demonstrations by humans, e.g. autonomous flight from pilot demonstrations. Recently, algorithms for <a href=https://en.wikipedia.org/wiki/Structured_prediction>structured prediction</a> were proposed under this paradigm and have been applied successfully to a number of tasks including syntactic dependency parsing, <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a>, <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a>, dynamic feature selection, semantic parsing and <a href=https://en.wikipedia.org/wiki/Natural-language_generation>natural language generation</a>. Key advantages are the ability to handle large output search spaces and to learn with non-decomposable loss functions. Our aim in this tutorial is to have a unified presentation of the various imitation algorithms for structure prediction, and show how they can be applied to a variety of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP tasks</a>. All material associated with the tutorial will be made available through https://sheffieldnlp.github.io/ImitationLearningTutorialEACL2017/.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Andreas+Vlachos" title="Search for 'Andreas Vlachos' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/j/james-thorne/ class=align-middle>James Thorne</a>
<span class="badge badge-secondary align-middle ml-2">10</span></li><li class=list-group-item><a href=/people/c/christos-christodoulopoulos/ class=align-middle>Christos Christodoulopoulos</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/a/arpit-mittal/ class=align-middle>Arpit Mittal</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/o/oana-cocarascu/ class=align-middle>Oana Cocarascu</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/g/gerasimos-lampouras/ class=align-middle>Gerasimos Lampouras</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/z/zornitsa-kozareva/ class=align-middle>Zornitsa Kozareva</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/andre-f-t-martins/ class=align-middle>André F. T. Martins</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/sujith-ravi/ class=align-middle>Sujith Ravi</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/p/priyanka-agrawal/ class=align-middle>Priyanka Agrawal</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/julia-kreutzer/ class=align-middle>Julia Kreutzer</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/rami-aly/ class=align-middle>Rami Aly</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/zhijiang-guo/ class=align-middle>Zhijiang Guo</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mingjie-chen/ class=align-middle>Mingjie Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/giorgos-myrianthous/ class=align-middle>Giorgos Myrianthous</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiashu-pu/ class=align-middle>Jiashu Pu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaoxuan-wang/ class=align-middle>Xiaoxuan Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marzieh-saeidi/ class=align-middle>Marzieh Saeidi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/majid-yazdani/ class=align-middle>Majid Yazdani</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/amandla-mabona/ class=align-middle>Amandla Mabona</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/laura-rimell/ class=align-middle>Laura Rimell</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stephen-clark/ class=align-middle>Stephen Clark</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vlad-niculae/ class=align-middle>Vlad Niculae</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-schlichtkrull/ class=align-middle>Michael Schlichtkrull</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-sejr-schlichtkrull/ class=align-middle>Michael Sejr Schlichtkrull</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gordon-buck/ class=align-middle>Gordon Buck</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yunita-sari/ class=align-middle>Yunita Sari</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mark-stevenson/ class=align-middle>Mark Stevenson</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sebastian-riedel/ class=align-middle>Sebastian Riedel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hardy-hardy/ class=align-middle>Hardy Hardy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shashi-narayan/ class=align-middle>Shashi Narayan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joseph-fisher/ class=align-middle>Joseph Fisher</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/abiola-obamuyide/ class=align-middle>Abiola Obamuyide</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/fever/ class=align-middle>FEVER</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/spnlp/ class=align-middle>spnlp</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/adaptnlp/ class=align-middle>AdaptNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>