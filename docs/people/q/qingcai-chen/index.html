<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Qingcai Chen - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Qingcai</span> <span class=font-weight-bold>Chen</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.285.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--285 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.285 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.285" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.285/>Leveraging Capsule Routing to Associate Knowledge with Medical Literature Hierarchically</a></strong><br><a href=/people/x/xin-liu/>Xin Liu</a>
|
<a href=/people/q/qingcai-chen/>Qingcai Chen</a>
|
<a href=/people/j/junying-chen/>Junying Chen</a>
|
<a href=/people/w/wenxiu-zhou/>Wenxiu Zhou</a>
|
<a href=/people/t/tingyu-liu/>Tingyu Liu</a>
|
<a href=/people/x/xinlan-yang/>Xinlan Yang</a>
|
<a href=/people/w/weihua-peng/>Weihua Peng</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--285><div class="card-body p-3 small">Integrating knowledge into text is a promising way to enrich text representation, especially in the <a href=https://en.wikipedia.org/wiki/Medicine>medical field</a>. However, undifferentiated knowledge not only confuses the text representation but also imports unexpected noises. In this paper, to alleviate this problem, we propose leveraging capsule routing to associate knowledge with <a href=https://en.wikipedia.org/wiki/Medical_literature>medical literature</a> hierarchically (called HiCapsRKL). Firstly, HiCapsRKL extracts two empirically designed text fragments from <a href=https://en.wikipedia.org/wiki/Medical_literature>medical literature</a> and encodes them into fragment representations respectively. Secondly, the capsule routing algorithm is applied to two fragment representations. Through the capsule computing and <a href=https://en.wikipedia.org/wiki/Dynamic_routing>dynamic routing</a>, each representation is processed into a new representation (denoted as caps-representation), and we integrate the caps-representations as information gain to associate knowledge with <a href=https://en.wikipedia.org/wiki/Medical_literature>medical literature</a> hierarchically. Finally, HiCapsRKL are validated on relevance prediction and medical literature retrieval test sets. The experimental results and analyses show that HiCapsRKLcan more accurately associate knowledge with <a href=https://en.wikipedia.org/wiki/Medical_literature>medical literature</a> than mainstream methods. In summary, HiCapsRKL can efficiently help selecting the most relevant knowledge to the <a href=https://en.wikipedia.org/wiki/Medical_literature>medical literature</a>, which may be an alternative attempt to improve knowledge-based text representation. Source code is released on GitHub.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.214.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--214 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.214 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.214/>MedWriter : Knowledge-Aware Medical Text Generation<span class=acl-fixed-case>M</span>ed<span class=acl-fixed-case>W</span>riter: Knowledge-Aware Medical Text Generation</a></strong><br><a href=/people/y/youcheng-pan/>Youcheng Pan</a>
|
<a href=/people/q/qingcai-chen/>Qingcai Chen</a>
|
<a href=/people/w/weihua-peng/>Weihua Peng</a>
|
<a href=/people/x/xiaolong-wang/>Xiaolong Wang</a>
|
<a href=/people/b/baotian-hu/>Baotian Hu</a>
|
<a href=/people/x/xin-liu/>Xin Liu</a>
|
<a href=/people/j/junying-chen/>Junying Chen</a>
|
<a href=/people/w/wenxiu-zhou/>Wenxiu Zhou</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--214><div class="card-body p-3 small">To exploit the <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain knowledge</a> to guarantee the correctness of generated text has been a hot topic in recent years, especially for high professional domains such as <a href=https://en.wikipedia.org/wiki/Medicine>medical</a>. However, most of recent works only consider the information of unstructured text rather than structured information of the <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graph</a>. In this paper, we focus on the medical topic-to-text generation task and adapt a knowledge-aware text generation model to the medical domain, named MedWriter, which not only introduces the specific knowledge from the external MKG but also is capable of learning graph-level representation. We conduct experiments on a medical literature dataset collected from <a href=https://en.wikipedia.org/wiki/Medical_journal>medical journals</a>, each of which has a set of topic words, an abstract of medical literature and a corresponding <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graph</a> from CMeKG. Experimental results demonstrate incorporating <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graph</a> into generation model can improve the quality of the generated text and has robust superiority over the competitor methods.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5706.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5706 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5706 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5706/>A Deep Learning-Based System for PharmaCoNER<span class=acl-fixed-case>P</span>harma<span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NER</span></a></strong><br><a href=/people/y/ying-xiong/>Ying Xiong</a>
|
<a href=/people/y/yedan-shen/>Yedan Shen</a>
|
<a href=/people/y/yuanhang-huang/>Yuanhang Huang</a>
|
<a href=/people/s/shuai-chen/>Shuai Chen</a>
|
<a href=/people/b/buzhou-tang/>Buzhou Tang</a>
|
<a href=/people/x/xiaolong-wang/>Xiaolong Wang</a>
|
<a href=/people/q/qingcai-chen/>Qingcai Chen</a>
|
<a href=/people/j/jun-yan/>Jun Yan</a>
|
<a href=/people/y/yi-zhou/>Yi Zhou</a><br><a href=/volumes/D19-57/ class=text-muted>Proceedings of The 5th Workshop on BioNLP Open Shared Tasks</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5706><div class="card-body p-3 small">The Biological Text Mining Unit at BSC and CNIO organized the first shared task on chemical & drug mention recognition from Spanish medical texts called PharmaCoNER (Pharmacological Substances, Compounds and proteins and Named Entity Recognition track) in 2019, which includes two tracks : one for NER offset and entity classification (track 1) and the other one for concept indexing (track 2). We developed a pipeline system based on deep learning methods for this shared task, specifically, a subsystem based on BERT (Bidirectional Encoder Representations from Transformers) for NER offset and entity classification and a subsystem based on Bpool (Bi-LSTM with max / mean pooling) for concept indexing. Evaluation conducted on the shared task data showed that our system achieves a micro-average F1-score of 0.9105 on track 1 and a micro-average F1-score of 0.8391 on track 2.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1166.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1166 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1166 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-1166/>LCQMC : A Large-scale Chinese Question Matching Corpus<span class=acl-fixed-case>LCQMC</span>:A Large-scale <span class=acl-fixed-case>C</span>hinese Question Matching Corpus</a></strong><br><a href=/people/x/xin-liu/>Xin Liu</a>
|
<a href=/people/q/qingcai-chen/>Qingcai Chen</a>
|
<a href=/people/c/chong-deng/>Chong Deng</a>
|
<a href=/people/h/huajun-zeng/>Huajun Zeng</a>
|
<a href=/people/j/jing-chen/>Jing Chen</a>
|
<a href=/people/d/dongfang-li/>Dongfang Li</a>
|
<a href=/people/b/buzhou-tang/>Buzhou Tang</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1166><div class="card-body p-3 small">The lack of large-scale question matching corpora greatly limits the development of matching methods in question answering (QA) system, especially for non-English languages. To ameliorate this situation, in this paper, we introduce a large-scale Chinese question matching corpus (named LCQMC), which is released to the public1. LCQMC is more general than paraphrase corpus as it focuses on intent matching rather than <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrase</a>. How to collect a large number of question pairs in variant linguistic forms, which may present the same intent, is the key point for such corpus construction. In this paper, we first use a <a href=https://en.wikipedia.org/wiki/Web_search_engine>search engine</a> to collect large-scale question pairs related to high-frequency words from various domains, then filter irrelevant pairs by the <a href=https://en.wikipedia.org/wiki/Wasserstein_distance>Wasserstein distance</a>, and finally recruit three annotators to manually check the left pairs. After this process, a question matching corpus that contains 260,068 question pairs is constructed. In order to verify the LCQMC corpus, we split it into three parts, i.e., a <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training set</a> containing 238,766 question pairs, a development set with 8,802 question pairs, and a <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>test set</a> with 12,500 question pairs, and test several well-known sentence matching methods on it. The experimental results not only demonstrate the good quality of LCQMC but also provide solid baseline performance for further researches on this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1536.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1536 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1536 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1536/>The BQ Corpus : A Large-scale Domain-specific Chinese Corpus For Sentence Semantic Equivalence Identification<span class=acl-fixed-case>BQ</span> Corpus: A Large-scale Domain-specific <span class=acl-fixed-case>C</span>hinese Corpus For Sentence Semantic Equivalence Identification</a></strong><br><a href=/people/j/jing-chen/>Jing Chen</a>
|
<a href=/people/q/qingcai-chen/>Qingcai Chen</a>
|
<a href=/people/x/xin-liu/>Xin Liu</a>
|
<a href=/people/h/haijun-yang/>Haijun Yang</a>
|
<a href=/people/d/daohe-lu/>Daohe Lu</a>
|
<a href=/people/b/buzhou-tang/>Buzhou Tang</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1536><div class="card-body p-3 small">This paper introduces the Bank Question (BQ) corpus, a Chinese corpus for sentence semantic equivalence identification (SSEI). The BQ corpus contains 120,000 question pairs from 1-year online bank custom service logs. To efficiently process and annotate questions from such a large scale of logs, this paper proposes a clustering based annotation method to achieve questions with the same intent. First, the deduplicated questions with the same answer are clustered into stacks by the Word Mover&#8217;s Distance (WMD) based Affinity Propagation (AP) algorithm. Then, the annotators are asked to assign the clustered questions into different intent categories. Finally, the positive and negative question pairs for SSEI are selected in the same intent category and between different intent categories respectively. We also present six SSEI benchmark performance on our <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, including state-of-the-art algorithms. As the largest manually annotated public Chinese SSEI corpus in the bank domain, the BQ corpus is not only useful for Chinese question semantic matching research, but also a significant resource for cross-lingual and cross-domain SSEI research. The <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>corpus</a> is available in public.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Qingcai+Chen" title="Search for 'Qingcai Chen' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/x/xin-liu/ class=align-middle>Xin Liu</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/b/buzhou-tang/ class=align-middle>Buzhou Tang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/jing-chen/ class=align-middle>Jing Chen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/junying-chen/ class=align-middle>Junying Chen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/w/wenxiu-zhou/ class=align-middle>Wenxiu Zhou</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/w/weihua-peng/ class=align-middle>Weihua Peng</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/x/xiaolong-wang/ class=align-middle>Xiaolong Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/chong-deng/ class=align-middle>Chong Deng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/huajun-zeng/ class=align-middle>Huajun Zeng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dongfang-li/ class=align-middle>Dongfang Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haijun-yang/ class=align-middle>Haijun Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/daohe-lu/ class=align-middle>Daohe Lu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tingyu-liu/ class=align-middle>Tingyu Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xinlan-yang/ class=align-middle>Xinlan Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/ying-xiong/ class=align-middle>Ying Xiong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yedan-shen/ class=align-middle>Yedan Shen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yuanhang-huang/ class=align-middle>Yuanhang Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shuai-chen/ class=align-middle>Shuai Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jun-yan/ class=align-middle>Jun Yan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yi-zhou/ class=align-middle>Yi Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/youcheng-pan/ class=align-middle>Youcheng Pan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/baotian-hu/ class=align-middle>Baotian Hu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">2</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>