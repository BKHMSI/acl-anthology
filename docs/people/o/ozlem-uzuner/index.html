<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Ozlem Uzuner - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Ozlem</span> <span class=font-weight-bold>Uzuner</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Özlem <span class=font-weight-normal>Uzuner</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.bionlp-1.37.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--bionlp-1--37 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.bionlp-1.37 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.bionlp-1.37/>MNLP at MEDIQA 2021 : Fine-Tuning PEGASUS for Consumer Health Question Summarization<span class=acl-fixed-case>MNLP</span> at <span class=acl-fixed-case>MEDIQA</span> 2021: Fine-Tuning <span class=acl-fixed-case>PEGASUS</span> for Consumer Health Question Summarization</a></strong><br><a href=/people/j/jooyeon-lee/>Jooyeon Lee</a>
|
<a href=/people/h/huong-dang/>Huong Dang</a>
|
<a href=/people/o/ozlem-uzuner/>Ozlem Uzuner</a>
|
<a href=/people/s/sam-henry/>Sam Henry</a><br><a href=/volumes/2021.bionlp-1/ class=text-muted>Proceedings of the 20th Workshop on Biomedical Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--bionlp-1--37><div class="card-body p-3 small">This paper details a Consumer Health Question (CHQ) summarization model submitted to MEDIQA 2021 for shared task 1 : Question Summarization. Many CHQs are composed of multiple sentences with typos or unnecessary information, which can interfere with automated question answering systems. Question summarization mitigates this issue by removing this unnecessary information, aiding automated systems in generating a more accurate summary. Our summarization approach focuses on applying multiple pre-processing techniques, including question focus identification on the input and the development of an ensemble method to combine question focus with an abstractive summarization method. We use the state-of-art abstractive summarization model, PEGASUS (Pre-training with Extracted Gap-sentences for Abstractive Summarization), to generate abstractive summaries. Our experiments show that using our ensemble method, which combines abstractive summarization with question focus identification, improves performance over using <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> alone. Our <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> shows a ROUGE-2 F-measure of 11.14 % against the official test dataset.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.smm4h-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--smm4h-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.smm4h-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.smm4h-1.5/>Ensemble BERT for Classifying Medication-mentioning Tweets<span class=acl-fixed-case>BERT</span> for Classifying Medication-mentioning Tweets</a></strong><br><a href=/people/h/huong-dang/>Huong Dang</a>
|
<a href=/people/k/kahyun-lee/>Kahyun Lee</a>
|
<a href=/people/s/sam-henry/>Sam Henry</a>
|
<a href=/people/o/ozlem-uzuner/>Özlem Uzuner</a><br><a href=/volumes/2020.smm4h-1/ class=text-muted>Proceedings of the Fifth Social Media Mining for Health Applications Workshop & Shared Task</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--smm4h-1--5><div class="card-body p-3 small">Twitter is a valuable source of patient-generated data that has been used in various <a href=https://en.wikipedia.org/wiki/Population_study>population health studies</a>. The first step in many of these studies is to identify and capture Twitter messages (tweets) containing medication mentions. In this article, we describe our submission to Task 1 of the Social Media Mining for Health Applications (SMM4H) Shared Task 2020. This task challenged participants to detect tweets that mention <a href=https://en.wikipedia.org/wiki/Medication>medications</a> or <a href=https://en.wikipedia.org/wiki/Dietary_supplement>dietary supplements</a> in a natural, highly imbalance dataset. Our system combined a handcrafted preprocessing step with an ensemble of 20 BERT-based classifiers generated by dividing the training dataset into subsets using 10-fold cross validation and exploiting two BERT embedding models. Our system ranked first in this task, and improved the average F1 score across all participating teams by 19.07 % with a precision, <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a>, and <a href=https://en.wikipedia.org/wiki/F-number>F1</a> on the test set of 83.75 %, 87.01 %, and 85.35 % respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.semeval-1.283.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--semeval-1--283 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.semeval-1.283 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.semeval-1.283/>SalamNET at SemEval-2020 Task 12 : Deep Learning Approach for Arabic Offensive Language Detection<span class=acl-fixed-case>S</span>alam<span class=acl-fixed-case>NET</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2020 Task 12: Deep Learning Approach for <span class=acl-fixed-case>A</span>rabic Offensive Language Detection</a></strong><br><a href=/people/f/fatemah-husain/>Fatemah Husain</a>
|
<a href=/people/j/jooyeon-lee/>Jooyeon Lee</a>
|
<a href=/people/s/sam-henry/>Sam Henry</a>
|
<a href=/people/o/ozlem-uzuner/>Ozlem Uzuner</a><br><a href=/volumes/2020.semeval-1/ class=text-muted>Proceedings of the Fourteenth Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--semeval-1--283><div class="card-body p-3 small">This paper describes SalamNET, an Arabic offensive language detection system that has been submitted to SemEval 2020 shared task 12 : Multilingual Offensive Language Identification in Social Media. Our approach focuses on applying multiple deep learning models and conducting in depth error analysis of results to provide system implications for future development considerations. To pursue our goal, a Recurrent Neural Network (RNN), a Gated Recurrent Unit (GRU), and Long-Short Term Memory (LSTM) models with different design architectures have been developed and evaluated. The SalamNET, a Bi-directional Gated Recurrent Unit (Bi-GRU) based model, reports a macro-F1 score of 0.83 %</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3215.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3215 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3215 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3215/>Deep Learning for Identification of Adverse Effect Mentions In Twitter Data<span class=acl-fixed-case>T</span>witter Data</a></strong><br><a href=/people/p/paul-barry/>Paul Barry</a>
|
<a href=/people/o/ozlem-uzuner/>Ozlem Uzuner</a><br><a href=/volumes/W19-32/ class=text-muted>Proceedings of the Fourth Social Media Mining for Health Applications (#SMM4H) Workshop & Shared Task</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3215><div class="card-body p-3 small">Social Media Mining for Health Applications (SMM4H) Adverse Effect Mentions Shared Task challenges participants to accurately identify spans of text within a tweet that correspond to Adverse Effects (AEs) resulting from medication usage (Weissenbacher et al., 2019). This task features a training data set of 2,367 tweets, in addition to a 1,000 tweet evaluation data set. The solution presented here features a bidirectional Long Short-term Memory Network (bi-LSTM) for the generation of character-level embeddings. It uses a second bi-LSTM trained on both character and token level embeddings to feed a Conditional Random Field (CRF) which provides the final <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a>. This paper further discusses the deep learning algorithms used in our <a href=https://en.wikipedia.org/wiki/Solution>solution</a>.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-4104.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-4104 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-4104 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-4104/>Enhancing Cohesion and Coherence of Fake Text to Improve Believability for Deceiving Cyber Attackers</a></strong><br><a href=/people/p/prakruthi-karuna/>Prakruthi Karuna</a>
|
<a href=/people/h/hemant-purohit/>Hemant Purohit</a>
|
<a href=/people/o/ozlem-uzuner/>Özlem Uzuner</a>
|
<a href=/people/s/sushil-jajodia/>Sushil Jajodia</a>
|
<a href=/people/r/rajesh-ganesan/>Rajesh Ganesan</a><br><a href=/volumes/W18-41/ class=text-muted>Proceedings of the First International Workshop on Language Cognition and Computational Models</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-4104><div class="card-body p-3 small">Ever increasing <a href=https://en.wikipedia.org/wiki/Ransomware>ransomware attacks</a> and thefts of intellectual property demand <a href=https://en.wikipedia.org/wiki/Computer_security>cybersecurity solutions</a> to protect critical documents. One emerging solution is to place fake text documents in the repository of critical documents for deceiving and catching cyber attackers. We can generate fake text documents by obscuring the salient information in legit text documents. However, the obscuring process can result in linguistic inconsistencies, such as broken co-references and illogical flow of ideas across the sentences, which can discern the fake document and render it unbelievable. In this paper, we propose a novel method to generate believable fake text documents by automatically improving the linguistic consistency of computer-generated fake text. Our method focuses on enhancing syntactic cohesion and semantic coherence across <a href=https://en.wikipedia.org/wiki/Discourse_analysis>discourse segments</a>. We conduct experiments with <a href=https://en.wikipedia.org/wiki/Human_subject_research>human subjects</a> to evaluate the effect of believability improvements in distinguishing legit texts from fake texts. Results show that the probability to distinguish legit texts from believable fake texts is consistently lower than from fake texts that have not been improved in believability. This indicates the effectiveness of our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> in generating believable fake text.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Ozlem+Uzuner" title="Search for 'Ozlem Uzuner' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/s/sam-henry/ class=align-middle>Sam Henry</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/h/huong-dang/ class=align-middle>Huong Dang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jooyeon-lee/ class=align-middle>Jooyeon Lee</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/kahyun-lee/ class=align-middle>Kahyun Lee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fatemah-husain/ class=align-middle>Fatemah Husain</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/p/prakruthi-karuna/ class=align-middle>Prakruthi Karuna</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hemant-purohit/ class=align-middle>Hemant Purohit</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sushil-jajodia/ class=align-middle>Sushil Jajodia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rajesh-ganesan/ class=align-middle>Rajesh Ganesan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paul-barry/ class=align-middle>Paul Barry</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/smm4h/ class=align-middle>SMM4H</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/bionlp/ class=align-middle>BioNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>