<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Owen Rambow - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Owen</span> <span class=font-weight-bold>Rambow</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-industry.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-industry.0/>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Papers</a></strong><br><a href=/people/y/young-bum-kim/>Young-bum Kim</a>
|
<a href=/people/y/yunyao-li/>Yunyao Li</a>
|
<a href=/people/o/owen-rambow/>Owen Rambow</a><br><a href=/volumes/2021.naacl-industry/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Papers</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.701.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--701 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.701 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.701.Dataset.tgz data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928793 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.701/>To Test <a href=https://en.wikipedia.org/wiki/Machine_learning>Machine Comprehension</a>, Start by Defining Comprehension</a></strong><br><a href=/people/j/jesse-dunietz/>Jesse Dunietz</a>
|
<a href=/people/g/greg-burnham/>Greg Burnham</a>
|
<a href=/people/a/akash-bharadwaj/>Akash Bharadwaj</a>
|
<a href=/people/o/owen-rambow/>Owen Rambow</a>
|
<a href=/people/j/jennifer-chu-carroll/>Jennifer Chu-Carroll</a>
|
<a href=/people/d/dave-ferrucci/>Dave Ferrucci</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--701><div class="card-body p-3 small">Many <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> aim to measure machine reading comprehension (MRC), often focusing on question types presumed to be difficult. Rarely, however, do task designers start by considering what systems should in fact comprehend. In this paper we make two key contributions. First, we argue that existing approaches do not adequately define <a href=https://en.wikipedia.org/wiki/Comprehension_(logic)>comprehension</a> ; they are too unsystematic about what content is tested. Second, we present a detailed definition of comprehensiona Template of Understandingfor a widely useful class of texts, namely short narratives. We then conduct an experiment that strongly suggests existing <a href=https://en.wikipedia.org/wiki/System>systems</a> are not up to the task of <a href=https://en.wikipedia.org/wiki/Narrative>narrative understanding</a> as we define <a href=https://en.wikipedia.org/wiki/Information_technology>it</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.167.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--167 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.167 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.167/>Email Classification Incorporating <a href=https://en.wikipedia.org/wiki/Social_network>Social Networks</a> and Thread Structure</a></strong><br><a href=/people/s/sakhar-alkhereyf/>Sakhar Alkhereyf</a>
|
<a href=/people/o/owen-rambow/>Owen Rambow</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--167><div class="card-body p-3 small">Existing methods for different document classification tasks in the context of <a href=https://en.wikipedia.org/wiki/List_of_social_networking_websites>social networks</a> typically only capture the semantics of texts, while ignoring the users who exchange the text and the network they form. However, some work has shown that incorporating the social network information in addition to information from language is effective for various NLP applications including <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, inferring user attributes, and predicting inter-personal relations. In this paper, we present an empirical study of email classification into Business and Personal categories. We represent the <a href=https://en.wikipedia.org/wiki/Email>email communication</a> using various <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structures</a>. As <a href=https://en.wikipedia.org/wiki/Software_feature>features</a>, we use both the textual information from the email content and <a href=https://en.wikipedia.org/wiki/Social_network>social network information</a> from the <a href=https://en.wikipedia.org/wiki/Graph_of_a_function>communication graphs</a>. We also model the <a href=https://en.wikipedia.org/wiki/Thread_(computing)>thread structure</a> for <a href=https://en.wikipedia.org/wiki/Email>emails</a>. We focus on detecting personal emails, and we evaluate our methods on two corpora, only one of which we train on. The experimental results reveal that incorporating <a href=https://en.wikipedia.org/wiki/Social_network>social network information</a> improves over the performance of an approach based on <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>textual information</a> only. The results also show that considering the thread structure of emails improves the performance further. Furthermore, our approach improves over a state-of-the-art baseline which uses node embeddings based on both lexical and social network information.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1096.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1096 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1096 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/282327794 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1096/>Author Commitment and Social Power : Automatic Belief Tagging to Infer the Social Context of Interactions</a></strong><br><a href=/people/v/vinodkumar-prabhakaran/>Vinodkumar Prabhakaran</a>
|
<a href=/people/p/premkumar-ganeshkumar/>Premkumar Ganeshkumar</a>
|
<a href=/people/o/owen-rambow/>Owen Rambow</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1096><div class="card-body p-3 small">Understanding how <a href=https://en.wikipedia.org/wiki/Power_(social_and_political)>social power structures</a> affect the way we interact with one another is of great interest to social scientists who want to answer fundamental questions about human behavior, as well as to computer scientists who want to build automatic methods to infer the social contexts of interactions. In this paper, we employ advancements in extra-propositional semantics extraction within <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> to study how author commitment reflects the social context of an interactions. Specifically, we investigate whether the level of <a href=https://en.wikipedia.org/wiki/Commitment>commitment</a> expressed by individuals in an <a href=https://en.wikipedia.org/wiki/Organizational_behavior>organizational interaction</a> reflects the <a href=https://en.wikipedia.org/wiki/Hierarchical_organization>hierarchical power structures</a> they are part of. We find that <a href=https://en.wikipedia.org/wiki/Hierarchy>subordinates</a> use significantly more instances of non-commitment than superiors. More importantly, we also find that subordinates attribute propositions to other agents more often than superiors do an aspect that has not been studied before. Finally, we show that enriching lexical features with commitment labels captures important distinctions in <a href=https://en.wikipedia.org/wiki/Social_relation>social meanings</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1107.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1107 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1107 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276898201 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1107" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1107/>End-to-End Graph-Based TAG Parsing with <a href=https://en.wikipedia.org/wiki/Neural_network>Neural Networks</a><span class=acl-fixed-case>TAG</span> Parsing with Neural Networks</a></strong><br><a href=/people/j/jungo-kasai/>Jungo Kasai</a>
|
<a href=/people/r/robert-frank/>Robert Frank</a>
|
<a href=/people/p/pauli-xu/>Pauli Xu</a>
|
<a href=/people/w/william-merrill/>William Merrill</a>
|
<a href=/people/o/owen-rambow/>Owen Rambow</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1107><div class="card-body p-3 small">We present a graph-based Tree Adjoining Grammar (TAG) parser that uses BiLSTMs, highway connections, and character-level CNNs. Our best end-to-end parser, which jointly performs supertagging, <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>POS tagging</a>, and <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a>, outperforms the previously reported best results by more than 2.2 LAS and UAS points. The graph-based parsing architecture allows for global inference and rich feature representations for TAG parsing, alleviating the fundamental trade-off between transition-based and graph-based parsing systems. We also demonstrate that the proposed <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> achieves state-of-the-art performance in the downstream tasks of Parsing Evaluation using Textual Entailments (PETE) and Unbounded Dependency Recovery. This provides further support for the claim that TAG is a viable <a href=https://en.wikipedia.org/wiki/Formalism_(philosophy_of_mathematics)>formalism</a> for problems that require rich structural analysis of sentences.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4202.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4202 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4202 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4202/>Predicting User Views in Online News</a></strong><br><a href=/people/d/daniel-hardt/>Daniel Hardt</a>
|
<a href=/people/o/owen-rambow/>Owen Rambow</a><br><a href=/volumes/W17-42/ class=text-muted>Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4202><div class="card-body p-3 small">We analyze user viewing behavior on an <a href=https://en.wikipedia.org/wiki/Online_newspaper>online news site</a>. We collect data from 64,000 <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>, and use text features to predict frequency of user views. We compare predictiveness of the headline and teaser (viewed before clicking) and the body (viewed after clicking). Both are predictive of clicking behavior, with the full article text being most predictive.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1180.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1180 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1180 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1180/>TAG Parsing with <a href=https://en.wikipedia.org/wiki/Neural_network>Neural Networks</a> and Vector Representations of Supertags<span class=acl-fixed-case>TAG</span> Parsing with Neural Networks and Vector Representations of Supertags</a></strong><br><a href=/people/j/jungo-kasai/>Jungo Kasai</a>
|
<a href=/people/b/bob-frank/>Bob Frank</a>
|
<a href=/people/t/tom-mccoy/>Tom McCoy</a>
|
<a href=/people/o/owen-rambow/>Owen Rambow</a>
|
<a href=/people/a/alexis-nasr/>Alexis Nasr</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1180><div class="card-body p-3 small">We present supertagging-based models for Tree Adjoining Grammar parsing that use neural network architectures and dense vector representation of supertags (elementary trees) to achieve state-of-the-art performance in unlabeled and labeled attachment scores. The shift-reduce parsing model eschews lexical information entirely, and uses only the 1-best supertags to parse a sentence, providing further support for the claim that supertagging is almost <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a>. We demonstrate that the embedding vector representations the <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> induces for supertags possess linguistically interpretable structure, supporting analogies between grammatical structures like those familiar from recent work in <a href=https://en.wikipedia.org/wiki/Distributional_semantics>distributional semantics</a>. This dense representation of supertags overcomes the drawbacks for statistical models of TAG as compared to CCG parsing, raising the possibility that <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>TAG</a> is a viable alternative for NLP tasks that require the assignment of richer structural descriptions to sentences.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Owen+Rambow" title="Search for 'Owen Rambow' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/j/jungo-kasai/ class=align-middle>Jungo Kasai</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jesse-dunietz/ class=align-middle>Jesse Dunietz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/greg-burnham/ class=align-middle>Greg Burnham</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/akash-bharadwaj/ class=align-middle>Akash Bharadwaj</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jennifer-chu-carroll/ class=align-middle>Jennifer Chu-Carroll</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/d/dave-ferrucci/ class=align-middle>Dave Ferrucci</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/daniel-hardt/ class=align-middle>Daniel Hardt</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bob-frank/ class=align-middle>Bob Frank</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tom-mccoy/ class=align-middle>Tom McCoy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexis-nasr/ class=align-middle>Alexis Nasr</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/young-bum-kim/ class=align-middle>Young-Bum Kim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yunyao-li/ class=align-middle>Yunyao Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vinodkumar-prabhakaran/ class=align-middle>Vinodkumar Prabhakaran</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/premkumar-ganeshkumar/ class=align-middle>Premkumar Ganeshkumar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/robert-frank/ class=align-middle>Robert Frank</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pauli-xu/ class=align-middle>Pauli Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/william-merrill/ class=align-middle>William Merrill</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sakhar-alkhereyf/ class=align-middle>Sakhar Alkhereyf</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>