<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Omid Rohanian - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Omid</span> <span class=font-weight-bold>Rohanian</span></h2><hr><div class=row><div class=col-lg-9><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5119.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5119 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5119 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5119/>Cross-lingual Transfer Learning and <a href=https://en.wikipedia.org/wiki/Multitask_learning>Multitask Learning</a> for Capturing Multiword Expressions</a></strong><br><a href=/people/s/shiva-taslimipoor/>Shiva Taslimipoor</a>
|
<a href=/people/o/omid-rohanian/>Omid Rohanian</a>
|
<a href=/people/l/le-an-ha/>Le An Ha</a><br><a href=/volumes/W19-51/ class=text-muted>Proceedings of the Joint Workshop on Multiword Expressions and WordNet (MWE-WN 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5119><div class="card-body p-3 small">Recent developments in <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> have prompted a surge of interest in the application of multitask and transfer learning to NLP problems. In this study, we explore for the first time, the application of <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning (TRL)</a> and <a href=https://en.wikipedia.org/wiki/Multitask_learning>multitask learning (MTL)</a> to the identification of Multiword Expressions (MWEs). For MTL, we exploit the shared syntactic information between MWE and dependency parsing models to jointly train a single model on both tasks. We specifically predict two types of labels : MWE and dependency parse. Our neural MTL architecture utilises the supervision of dependency parsing in lower layers and predicts MWE tags in upper layers. In the TRL scenario, we overcome the scarcity of data by learning a model on a larger MWE dataset and transferring the knowledge to a resource-poor setting in another language. In both scenarios, the resulting <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> achieved higher performance compared to standard neural approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1275.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1275 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1275 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1275" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N19-1275/>Bridging the Gap : Attending to Discontinuity in Identification of Multiword Expressions<span class=acl-fixed-case>B</span>ridging the Gap: <span class=acl-fixed-case>A</span>ttending to Discontinuity in Identification of Multiword Expressions</a></strong><br><a href=/people/o/omid-rohanian/>Omid Rohanian</a>
|
<a href=/people/s/shiva-taslimipoor/>Shiva Taslimipoor</a>
|
<a href=/people/s/samaneh-kouchaki/>Samaneh Kouchaki</a>
|
<a href=/people/l/le-an-ha/>Le An Ha</a>
|
<a href=/people/r/ruslan-mitkov/>Ruslan Mitkov</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1275><div class="card-body p-3 small">We introduce a new method to tag Multiword Expressions (MWEs) using a linguistically interpretable language-independent deep learning architecture. We specifically target <a href=https://en.wikipedia.org/wiki/Classification_of_discontinuities>discontinuity</a>, an under-explored aspect that poses a significant challenge to computational treatment of MWEs. Two neural architectures are explored : Graph Convolutional Network (GCN) and multi-head self-attention. GCN leverages dependency parse information, and self-attention attends to long-range relations. We finally propose a combined <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that integrates complementary information from both, through a gating mechanism. The experiments on a standard multilingual dataset for verbal MWEs show that our model outperforms the baselines not only in the case of discontinuous MWEs but also in overall F-score.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1090.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1090 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1090 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1090/>WLV at SemEval-2018 Task 3 : Dissecting Tweets in Search of Irony<span class=acl-fixed-case>WLV</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 3: Dissecting Tweets in Search of Irony</a></strong><br><a href=/people/o/omid-rohanian/>Omid Rohanian</a>
|
<a href=/people/s/shiva-taslimipoor/>Shiva Taslimipoor</a>
|
<a href=/people/r/richard-evans/>Richard Evans</a>
|
<a href=/people/r/ruslan-mitkov/>Ruslan Mitkov</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1090><div class="card-body p-3 small">This paper describes the systems submitted to SemEval 2018 Task 3 Irony detection in English tweets for both subtasks A and B. The first system leveraging a combination of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment</a>, distributional semantic, and text surface features is ranked third among 44 teams according to the official leaderboard of the subtask A. The second <a href=https://en.wikipedia.org/wiki/Formal_system>system</a> with slightly different representation of the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> ranked ninth in subtask B. We present a <a href=https://en.wikipedia.org/wiki/Methodology>method</a> that entails decomposing tweets into separate parts. Searching for <a href=https://en.wikipedia.org/wiki/Contrast_(vision)>contrast</a> within the constituents of a tweet is an integral part of our <a href=https://en.wikipedia.org/wiki/System>system</a>. We embrace an extensive definition of <a href=https://en.wikipedia.org/wiki/Contrast_(linguistics)>contrast</a> which leads to a vast coverage in detecting ironic content.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1160.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1160 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1160 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1160/>Wolves at SemEval-2018 Task 10 : Semantic Discrimination based on Knowledge and Association<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 10: Semantic Discrimination based on Knowledge and Association</a></strong><br><a href=/people/s/shiva-taslimipoor/>Shiva Taslimipoor</a>
|
<a href=/people/o/omid-rohanian/>Omid Rohanian</a>
|
<a href=/people/l/le-an-ha/>Le An Ha</a>
|
<a href=/people/g/gloria-corpas-pastor/>Gloria Corpas Pastor</a>
|
<a href=/people/r/ruslan-mitkov/>Ruslan Mitkov</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1160><div class="card-body p-3 small">This paper describes the <a href=https://en.wikipedia.org/wiki/System>system</a> submitted to SemEval 2018 shared task 10 &#8216;Capturing Dicriminative Attributes&#8217;. We use a combination of knowledge-based and co-occurrence features to capture the semantic difference between two words in relation to an attribute. We define scores based on association measures, <a href=https://en.wikipedia.org/wiki/Grammatical_number>ngram counts</a>, word similarity, and ConceptNet relations. The <a href=https://en.wikipedia.org/wiki/System>system</a> is ranked 4th (joint) on the official leaderboard of the task.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5013 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5013/>Combining Multiple Corpora for Readability Assessment for People with Cognitive Disabilities</a></strong><br><a href=/people/v/victoria-yaneva/>Victoria Yaneva</a>
|
<a href=/people/c/constantin-orasan/>Constantin Orăsan</a>
|
<a href=/people/r/richard-evans/>Richard Evans</a>
|
<a href=/people/o/omid-rohanian/>Omid Rohanian</a><br><a href=/volumes/W17-50/ class=text-muted>Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5013><div class="card-body p-3 small">Given the lack of large user-evaluated corpora in disability-related NLP research (e.g. text simplification or readability assessment for people with cognitive disabilities), the question of choosing suitable training data for NLP models is not straightforward. The use of large generic corpora may be problematic because such <a href=https://en.wikipedia.org/wiki/Data>data</a> may not reflect the needs of the target population. The use of the available user-evaluated corpora may be problematic because these <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> are not large enough to be used as training data. In this paper we explore a third approach, in which a large generic corpus is combined with a smaller population-specific corpus to train a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> which is evaluated using two sets of unseen user-evaluated data. One of these <a href=https://en.wikipedia.org/wiki/Set_(mathematics)>sets</a>, the ASD Comprehension corpus, is developed for the purposes of this study and made freely available. We explore the effects of the size and type of the training data used on the performance of the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a>, and the effects of the type of the unseen test datasets on the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Omid+Rohanian" title="Search for 'Omid Rohanian' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/s/shiva-taslimipoor/ class=align-middle>Shiva Taslimipoor</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/r/ruslan-mitkov/ class=align-middle>Ruslan Mitkov</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/le-an-ha/ class=align-middle>Le An Ha</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/r/richard-evans/ class=align-middle>Richard Evans</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/v/victoria-yaneva/ class=align-middle>Victoria Yaneva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/c/constantin-orasan/ class=align-middle>Constantin Orasan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gloria-corpas-pastor/ class=align-middle>Gloria Corpas Pastor</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/samaneh-kouchaki/ class=align-middle>Samaneh Kouchaki</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>