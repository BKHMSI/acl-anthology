<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Omer Levy - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Omer</span> <span class=font-weight-bold>Levy</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.344.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--344 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.344 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.344" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.344/>Cryptonite : A Cryptic Crossword Benchmark for Extreme Ambiguity in Language</a></strong><br><a href=/people/a/avia-efrat/>Avia Efrat</a>
|
<a href=/people/u/uri-shaham/>Uri Shaham</a>
|
<a href=/people/d/dan-kilman/>Dan Kilman</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--344><div class="card-body p-3 small">Current NLP datasets targeting <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguity</a> can be solved by a native speaker with relative ease. We present <a href=https://en.wikipedia.org/wiki/Cryptonite>Cryptonite</a>, a large-scale dataset based on cryptic crosswords, which is both linguistically complex and naturally sourced. Each example in <a href=https://en.wikipedia.org/wiki/Cryptonite>Cryptonite</a> is a cryptic clue, a short phrase or sentence with a misleading surface reading, whose solving requires disambiguating semantic, syntactic, and phonetic wordplays, as well as world knowledge. Cryptic clues pose a challenge even for experienced solvers, though top-tier experts can solve them with almost 100 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. Cryptonite is a challenging task for current <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> ; fine-tuning T5-Large on 470k cryptic clues achieves only 7.6 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, on par with the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of a rule-based clue solver (8.6 %).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.831.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--831 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.831 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.831" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.831/>How to Train BERT with an Academic Budget<span class=acl-fixed-case>BERT</span> with an Academic Budget</a></strong><br><a href=/people/p/peter-izsak/>Peter Izsak</a>
|
<a href=/people/m/moshe-berchansky/>Moshe Berchansky</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--831><div class="card-body p-3 small">While large language models a la BERT are used ubiquitously in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, pretraining them is considered a luxury that only a few well-funded industry labs can afford. How can one train such <a href=https://en.wikipedia.org/wiki/Physical_model>models</a> with a more modest budget? We present a recipe for pretraining a masked language model in 24 hours using a single low-end deep learning server. We demonstrate that through a combination of software optimizations, design choices, and hyperparameter tuning, it is possible to produce models that are competitive with BERT-base on GLUE tasks at a fraction of the original pretraining cost.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.17" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.17/>Neural Machine Translation without Embeddings</a></strong><br><a href=/people/u/uri-shaham/>Uri Shaham</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--17><div class="card-body p-3 small">Many NLP models operate over sequences of subword tokens produced by hand-crafted tokenization rules and heuristic subword induction algorithms. A simple universal alternative is to represent every computerized text as a sequence of bytes via <a href=https://en.wikipedia.org/wiki/UTF-8>UTF-8</a>, obviating the need for an embedding layer since there are fewer token types (256) than dimensions. Surprisingly, replacing the ubiquitous embedding layer with one-hot representations of each byte does not hurt performance ; experiments on byte-to-byte machine translation from <a href=https://en.wikipedia.org/wiki/English_language>English</a> to 10 different languages show a consistent improvement in BLEU, rivaling character-level and even standard subword-level models. A deeper investigation reveals that the combination of embeddingless models with decoder-input dropout amounts to token dropout, which benefits byte-to-byte models in particular.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.209.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--209 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.209 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.209/>Can Latent Alignments Improve Autoregressive Machine Translation?</a></strong><br><a href=/people/a/adi-haviv/>Adi Haviv</a>
|
<a href=/people/l/lior-vassertail/>Lior Vassertail</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--209><div class="card-body p-3 small">Latent alignment objectives such as CTC and AXE significantly improve non-autoregressive machine translation models. Can they improve <a href=https://en.wikipedia.org/wiki/Autoregressive_model>autoregressive models</a> as well? We explore the possibility of training autoregressive machine translation models with latent alignment objectives, and observe that, in practice, this approach results in degenerate models. We provide a theoretical explanation for these empirical results, and prove that latent alignment objectives are incompatible with teacher forcing.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.tacl-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--tacl-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.tacl-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.tacl-1.5" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.tacl-1.5/>SpanBERT : Improving Pre-training by Representing and Predicting Spans<span class=acl-fixed-case>S</span>pan<span class=acl-fixed-case>BERT</span>: Improving Pre-training by Representing and Predicting Spans</a></strong><br><a href=/people/m/mandar-joshi/>Mandar Joshi</a>
|
<a href=/people/d/danqi-chen/>Danqi Chen</a>
|
<a href=/people/y/yinhan-liu/>Yinhan Liu</a>
|
<a href=/people/d/daniel-s-weld/>Daniel S. Weld</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a><br><a href=/volumes/2020.tacl-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 8</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--tacl-1--5><div class="card-body p-3 small">We present SpanBERT, a pre-training method that is designed to better represent and predict spans of text. Our approach extends BERT by (1) masking contiguous random spans, rather than random tokens, and (2) training the span boundary representations to predict the entire content of the masked span, without relying on the individual token representations within it. SpanBERT consistently outperforms <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> and our better-tuned baselines, with substantial gains on span selection tasks such as <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> and <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a>. In particular, with the same training data and model size as BERTlarge, our single <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> obtains 94.6 % and 88.7 % <a href=https://en.wikipedia.org/wiki/F-number>F1</a> on SQuAD 1.1 and 2.0 respectively. We also achieve a new state of the art on the OntoNotes coreference resolution task (79.6 % F1), strong performance on the TACRED relation extraction benchmark, and even gains on GLUE.1</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1588.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1588 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1588 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1588" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1588/>BERT for <a href=https://en.wikipedia.org/wiki/Coreference_resolution>Coreference Resolution</a> : Baselines and Analysis<span class=acl-fixed-case>BERT</span> for Coreference Resolution: Baselines and Analysis</a></strong><br><a href=/people/m/mandar-joshi/>Mandar Joshi</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a>
|
<a href=/people/d/daniel-s-weld/>Daniel Weld</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1588><div class="card-body p-3 small">We apply BERT to <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a>, achieving a new state of the art on the GAP (+11.5 F1) and OntoNotes (+3.9 F1) benchmarks. A qualitative analysis of model predictions indicates that, compared to ELMo and BERT-base, BERT-large is particularly better at distinguishing between related but distinct entities (e.g., President and CEO), but that there is still room for improvement in modeling document-level context, conversations, and mention paraphrasing. We will release all code and trained models upon publication.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1633.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1633 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1633 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1633" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1633/>Mask-Predict : Parallel Decoding of Conditional Masked Language Models</a></strong><br><a href=/people/m/marjan-ghazvininejad/>Marjan Ghazvininejad</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a>
|
<a href=/people/y/yinhan-liu/>Yinhan Liu</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1633><div class="card-body p-3 small">Most <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation systems</a> generate text autoregressively from left to right. We, instead, use a masked language modeling objective to train a model to predict any subset of the target words, conditioned on both the input text and a partially masked target translation. This approach allows for efficient iterative decoding, where we first predict all of the target words non-autoregressively, and then repeatedly mask out and regenerate the subset of words that the model is least confident about. By applying this strategy for a constant number of iterations, our model improves state-of-the-art performance levels for non-autoregressive and parallel decoding translation models by over 4 BLEU on average. It is also able to reach within about 1 BLEU point of a typical left-to-right transformer model, while decoding significantly faster.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5506.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5506 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5506 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5506/>Training on Synthetic Noise Improves Robustness to Natural Noise in Machine Translation</a></strong><br><a href=/people/v/vladimir-karpukhin/>Vladimir Karpukhin</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a>
|
<a href=/people/j/jacob-eisenstein/>Jacob Eisenstein</a>
|
<a href=/people/m/marjan-ghazvininejad/>Marjan Ghazvininejad</a><br><a href=/volumes/D19-55/ class=text-muted>Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5506><div class="card-body p-3 small">Contemporary machine translation systems achieve greater coverage by applying subword models such as BPE and character-level CNNs, but these methods are highly sensitive to orthographical variations such as spelling mistakes. We show how training on a mild amount of random synthetic noise can dramatically improve <a href=https://en.wikipedia.org/wiki/Robust_statistics>robustness</a> to these variations, without diminishing performance on clean text. We focus on <a href=https://en.wikipedia.org/wiki/Translation_(biology)>translation</a> performance on natural typos, and show that robustness to such <a href=https://en.wikipedia.org/wiki/Noise>noise</a> can be achieved using a balanced diet of simple synthetic noises at training time, without access to the natural noise data or distribution.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1362.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1362 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1362 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/356133444 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1362" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-1362/>pair2vec : Compositional Word-Pair Embeddings for Cross-Sentence Inference</a></strong><br><a href=/people/m/mandar-joshi/>Mandar Joshi</a>
|
<a href=/people/e/eunsol-choi/>Eunsol Choi</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a>
|
<a href=/people/d/daniel-s-weld/>Daniel Weld</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1362><div class="card-body p-3 small">Reasoning about implied relationships (e.g. paraphrastic, <a href=https://en.wikipedia.org/wiki/Common_sense>common sense</a>, encyclopedic) between pairs of words is crucial for many cross-sentence inference problems. This paper proposes new methods for learning and using embeddings of word pairs that implicitly represent background knowledge about such relationships. Our pairwise embeddings are computed as a compositional function of each word&#8217;s representation, which is learned by maximizing the pointwise mutual information (PMI) with the contexts in which the the two words co-occur. We add these <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representations</a> to the cross-sentence attention layer of existing <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference models</a> (e.g. BiDAF for <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA</a>, ESIM for NLI), instead of extending or replacing existing <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>. Experiments show a gain of 2.7 % on the recently released SQuAD 2.0 and 1.3 % on MultiNLI. Our representations also aid in better generalization with gains of around 6-7 % on adversarial SQuAD datasets, and 8.8 % on the adversarial entailment test set by Glockner et al.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-1000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-1000/>Proceedings of the Workshop on Generalization in the Age of Deep Learning</a></strong><br><a href=/people/y/yonatan-bisk/>Yonatan Bisk</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a>
|
<a href=/people/m/mark-yatskar/>Mark Yatskar</a><br><a href=/volumes/W18-10/ class=text-muted>Proceedings of the Workshop on Generalization in the Age of Deep Learning</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3024 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3024/>LSTMs Exploit Linguistic Attributes of Data<span class=acl-fixed-case>LSTM</span>s Exploit Linguistic Attributes of Data</a></strong><br><a href=/people/n/nelson-f-liu/>Nelson F. Liu</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a>
|
<a href=/people/r/roy-schwartz/>Roy Schwartz</a>
|
<a href=/people/c/chenhao-tan/>Chenhao Tan</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a><br><a href=/volumes/W18-30/ class=text-muted>Proceedings of The Third Workshop on Representation Learning for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3024><div class="card-body p-3 small">While <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural networks</a> have found success in a variety of natural language processing applications, they are general models of sequential data. We investigate how the properties of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language data</a> affect an LSTM&#8217;s ability to learn a nonlinguistic task : recalling elements from its input. We find that <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on natural language data are able to recall tokens from much longer sequences than <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on non-language sequential data. Furthermore, we show that the LSTM learns to solve the memorization task by explicitly using a subset of its <a href=https://en.wikipedia.org/wiki/Neuron>neurons</a> to count timesteps in the input. We hypothesize that the patterns and structure in natural language data enable LSTMs to learn by providing approximate ways of reducing loss, but understanding the effect of different <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data</a> on the learnability of LSTMs remains an open question.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2017.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-2017 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-2017 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-2017/>Annotation Artifacts in Natural Language Inference Data</a></strong><br><a href=/people/s/suchin-gururangan/>Suchin Gururangan</a>
|
<a href=/people/s/swabha-swayamdipta/>Swabha Swayamdipta</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a>
|
<a href=/people/r/roy-schwartz/>Roy Schwartz</a>
|
<a href=/people/s/samuel-bowman/>Samuel Bowman</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-2017><div class="card-body p-3 small">Large-scale datasets for natural language inference are created by presenting crowd workers with a sentence (premise), and asking them to generate three new sentences (hypotheses) that it entails, contradicts, or is logically neutral with respect to. We show that, in a significant portion of such data, this <a href=https://en.wikipedia.org/wiki/Protocol_(science)>protocol</a> leaves clues that make it possible to identify the label by looking only at the hypothesis, without observing the premise. Specifically, we show that a simple text categorization model can correctly classify the hypothesis alone in about 67 % of <a href=https://en.wikipedia.org/wiki/Single-nucleotide_polymorphism>SNLI</a> (Bowman et. al, 2015) and 53 % of MultiNLI (Williams et. al, 2017). Our analysis reveals that specific linguistic phenomena such as <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>negation</a> and <a href=https://en.wikipedia.org/wiki/Vagueness>vagueness</a> are highly correlated with certain inference classes. Our findings suggest that the success of natural language inference models to date has been overestimated, and that the task remains a hard open problem.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1009 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1009.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285807855 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1009/>Ultra-Fine Entity Typing</a></strong><br><a href=/people/e/eunsol-choi/>Eunsol Choi</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1009><div class="card-body p-3 small">We introduce a new entity typing task : given a sentence with an entity mention, the goal is to predict a set of free-form phrases (e.g. skyscraper, <a href=https://en.wikipedia.org/wiki/Songwriter>songwriter</a>, or criminal) that describe appropriate types for the target entity. This formulation allows us to use a new type of distant supervision at large scale : head words, which indicate the type of the noun phrases they appear in. We show that these ultra-fine types can be crowd-sourced, and introduce new evaluation sets that are much more diverse and fine-grained than existing <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a>. We present a model that can predict ultra-fine types, and is trained using a multitask objective that pools our new head-word supervision with prior supervision from <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity linking</a>. Experimental results demonstrate that our model is effective in predicting entity types at varying granularity ; it achieves state of the art performance on an existing fine-grained entity typing benchmark, and sets baselines for our newly-introduced datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-2003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-2003 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-2003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-2003.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-2003.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-2003/>Deep RNNs Encode Soft Hierarchical Syntax<span class=acl-fixed-case>RNN</span>s Encode Soft Hierarchical Syntax</a></strong><br><a href=/people/t/terra-blevins/>Terra Blevins</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a><br><a href=/volumes/P18-2/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-2003><div class="card-body p-3 small">We present a set of experiments to demonstrate that deep recurrent neural networks (RNNs) learn internal representations that capture soft hierarchical notions of syntax from highly varied supervision. We consider four syntax tasks at different depths of the <a href=https://en.wikipedia.org/wiki/Parse_tree>parse tree</a> ; for each word, we predict its <a href=https://en.wikipedia.org/wiki/Part_of_speech>part of speech</a> as well as the first (parent), second (grandparent) and third level (great-grandparent) constituent labels that appear above it. These predictions are made from representations produced at different depths in networks that are pretrained with one of four objectives : dependency parsing, <a href=https://en.wikipedia.org/wiki/Semantic_role_labeling>semantic role labeling</a>, <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, or <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>. In every case, we find a correspondence between network depth and syntactic depth, suggesting that a soft syntactic hierarchy emerges. This effect is robust across all conditions, indicating that the <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> encode significant amounts of <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> even in the absence of an explicit syntactic training supervision.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-1034.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-1034 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-1034 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K17-1034" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K17-1034/>Zero-Shot Relation Extraction via Reading Comprehension</a></strong><br><a href=/people/o/omer-levy/>Omer Levy</a>
|
<a href=/people/m/minjoon-seo/>Minjoon Seo</a>
|
<a href=/people/e/eunsol-choi/>Eunsol Choi</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a><br><a href=/volumes/K17-1/ class=text-muted>Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-1034><div class="card-body p-3 small">We show that <a href=https://en.wikipedia.org/wiki/Relation_extraction>relation extraction</a> can be reduced to answering simple reading comprehension questions, by associating one or more natural-language questions with each relation slot. This reduction has several advantages : we can (1) learn relation-extraction models by extending recent neural reading-comprehension techniques, (2) build very large training sets for those models by combining relation-specific crowd-sourced questions with distant supervision, and even (3) do zero-shot learning by extracting new relation types that are only specified at test-time, for which we have no labeled training examples. Experiments on a Wikipedia slot-filling task demonstrate that the approach can generalize to new questions for known relation types with high <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, and that zero-shot generalization to unseen relation types is possible, at lower <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy levels</a>, setting the bar for future work on this task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5300.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5300/>Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for <span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/s/samuel-bowman/>Samuel Bowman</a>
|
<a href=/people/y/yoav-goldberg/>Yoav Goldberg</a>
|
<a href=/people/f/felix-hill/>Felix Hill</a>
|
<a href=/people/a/angeliki-lazaridou/>Angeliki Lazaridou</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a>
|
<a href=/people/r/roi-reichart/>Roi Reichart</a>
|
<a href=/people/a/anders-sogaard/>Anders Søgaard</a><br><a href=/volumes/W17-53/ class=text-muted>Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for NLP</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-1072.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-1072 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-1072 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-1072/>A Strong Baseline for Learning Cross-Lingual Word Embeddings from Sentence Alignments</a></strong><br><a href=/people/o/omer-levy/>Omer Levy</a>
|
<a href=/people/a/anders-sogaard/>Anders Søgaard</a>
|
<a href=/people/y/yoav-goldberg/>Yoav Goldberg</a><br><a href=/volumes/E17-1/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-1072><div class="card-body p-3 small">While cross-lingual word embeddings have been studied extensively in recent years, the qualitative differences between the different <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> remain vague. We observe that whether or not an <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> uses a particular feature set (sentence IDs) accounts for a significant performance gap among these <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a>. This feature set is also used by traditional alignment algorithms, such as IBM Model-1, which demonstrate similar performance to state-of-the-art embedding algorithms on a variety of <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a>. Overall, we observe that different algorithmic approaches for utilizing the sentence ID feature space result in similar performance. This paper draws both empirical and theoretical parallels between the embedding and alignment literature, and suggests that adding additional sources of information, which go beyond the traditional signal of bilingual sentence-aligned corpora, may substantially improve cross-lingual word embeddings, and that future baselines should at least take such features into account.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Omer+Levy" title="Search for 'Omer Levy' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/l/luke-zettlemoyer/ class=align-middle>Luke Zettlemoyer</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/e/eunsol-choi/ class=align-middle>Eunsol Choi</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/mandar-joshi/ class=align-middle>Mandar Joshi</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/d/daniel-s-weld/ class=align-middle>Daniel S. Weld</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/samuel-bowman/ class=align-middle>Samuel Bowman</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/y/yoav-goldberg/ class=align-middle>Yoav Goldberg</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/anders-sogaard/ class=align-middle>Anders Søgaard</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/u/uri-shaham/ class=align-middle>Uri Shaham</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/marjan-ghazvininejad/ class=align-middle>Marjan Ghazvininejad</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yinhan-liu/ class=align-middle>Yinhan Liu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/roy-schwartz/ class=align-middle>Roy Schwartz</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/n/noah-a-smith/ class=align-middle>Noah A. Smith</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/minjoon-seo/ class=align-middle>Minjoon Seo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/felix-hill/ class=align-middle>Felix Hill</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/angeliki-lazaridou/ class=align-middle>Angeliki Lazaridou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/roi-reichart/ class=align-middle>Roi Reichart</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/avia-efrat/ class=align-middle>Avia Efrat</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dan-kilman/ class=align-middle>Dan Kilman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/peter-izsak/ class=align-middle>Peter Izsak</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/moshe-berchansky/ class=align-middle>Moshe Berchansky</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vladimir-karpukhin/ class=align-middle>Vladimir Karpukhin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jacob-eisenstein/ class=align-middle>Jacob Eisenstein</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/adi-haviv/ class=align-middle>Adi Haviv</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lior-vassertail/ class=align-middle>Lior Vassertail</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yonatan-bisk/ class=align-middle>Yonatan Bisk</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mark-yatskar/ class=align-middle>Mark Yatskar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nelson-f-liu/ class=align-middle>Nelson F. Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chenhao-tan/ class=align-middle>Chenhao Tan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/suchin-gururangan/ class=align-middle>Suchin Gururangan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/swabha-swayamdipta/ class=align-middle>Swabha Swayamdipta</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/danqi-chen/ class=align-middle>Danqi Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yejin-choi/ class=align-middle>Yejin Choi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/terra-blevins/ class=align-middle>Terra Blevins</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/tacl/ class=align-middle>TACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>