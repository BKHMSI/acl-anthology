<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Orphee De Clercq - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Orphee</span> <span class=font-weight-bold>De Clercq</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Orphée <span class=font-weight-normal>De Clercq</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ranlp-1.40.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ranlp-1--40 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ranlp-1.40 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ranlp-1.40/>Event Prominence Extraction Combining a Knowledge-Based Syntactic Parser and a BERT Classifier for Dutch<span class=acl-fixed-case>BERT</span> Classifier for <span class=acl-fixed-case>D</span>utch</a></strong><br><a href=/people/t/thierry-desot/>Thierry Desot</a>
|
<a href=/people/o/orphee-de-clercq/>Orphee De Clercq</a>
|
<a href=/people/v/veronique-hoste/>Veronique Hoste</a><br><a href=/volumes/2021.ranlp-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ranlp-1--40><div class="card-body p-3 small">A core task in <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a> is event detection that identifies event triggers in sentences that are typically classified into event types. In this study an event is considered as the unit to measure <a href=https://en.wikipedia.org/wiki/Multiculturalism>diversity</a> and similarity in <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a> in the framework of a <a href=https://en.wikipedia.org/wiki/Recommender_system>news recommendation system</a>. Current typology-based event detection approaches fail to handle the variety of events expressed in real-world situations. To overcome this, we aim to perform event salience classification and explore whether a transformer model is capable of classifying new information into less and more general prominence classes. After comparing a Support Vector Machine (SVM) baseline and our transformer-based classifier performances on several event span formats, we conceived multi-word event spans as syntactic clauses. Those are fed into our prominence classifier which is fine-tuned on pre-trained Dutch BERT word embeddings. On top of that we outperform a pipeline of a Conditional Random Field (CRF) approach to event-trigger word detection and the BERT-based classifier. To the best of our knowledge we present the first event extraction approach that combines an expert-based syntactic parser with a transformer-based classifier for <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wassa-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wassa-1.0/>Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></strong><br><a href=/people/o/orphee-de-clercq/>Orphee De Clercq</a>
|
<a href=/people/a/alexandra-balahur/>Alexandra Balahur</a>
|
<a href=/people/j/joao-sedoc/>Joao Sedoc</a>
|
<a href=/people/v/valentin-barriere/>Valentin Barriere</a>
|
<a href=/people/s/shabnam-tafreshi/>Shabnam Tafreshi</a>
|
<a href=/people/s/sven-buechel/>Sven Buechel</a>
|
<a href=/people/v/veronique-hoste/>Veronique Hoste</a><br><a href=/volumes/2021.wassa-1/ class=text-muted>Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wassa-1.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wassa-1--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wassa-1.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wassa-1.27/>Emotional RobBERT and Insensitive BERTje : Combining Transformers and Affect Lexica for Dutch Emotion Detection<span class=acl-fixed-case>R</span>ob<span class=acl-fixed-case>BERT</span> and Insensitive <span class=acl-fixed-case>BERT</span>je: Combining Transformers and Affect Lexica for <span class=acl-fixed-case>D</span>utch Emotion Detection</a></strong><br><a href=/people/l/luna-de-bruyne/>Luna De Bruyne</a>
|
<a href=/people/o/orphee-de-clercq/>Orphee De Clercq</a>
|
<a href=/people/v/veronique-hoste/>Veronique Hoste</a><br><a href=/volumes/2021.wassa-1/ class=text-muted>Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wassa-1--27><div class="card-body p-3 small">In a first step towards improving Dutch emotion detection, we try to combine the Dutch transformer models BERTje and RobBERT with lexicon-based methods. We propose two architectures : one in which lexicon information is directly injected into the transformer model and a meta-learning approach where predictions from transformers are combined with lexicon features. The models are tested on 1,000 Dutch tweets and 1,000 captions from <a href=https://en.wikipedia.org/wiki/Television_show>TV-shows</a> which have been manually annotated with <a href=https://en.wikipedia.org/wiki/Emotion>emotion categories</a> and dimensions. We find that RobBERT clearly outperforms BERTje, but that directly adding lexicon information to transformers does not improve performance. In the meta-learning approach, lexicon information does have a positive effect on BERTje, but not on RobBERT. This suggests that more emotional information is already contained within this latter <a href=https://en.wikipedia.org/wiki/Language_model>language model</a>.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.crac-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--crac-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.crac-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.crac-1.2/>It’s absolutely divine ! Can fine-grained sentiment analysis benefit from <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a>?</a></strong><br><a href=/people/o/orphee-de-clercq/>Orphee De Clercq</a>
|
<a href=/people/v/veronique-hoste/>Veronique Hoste</a><br><a href=/volumes/2020.crac-1/ class=text-muted>Proceedings of the Third Workshop on Computational Models of Reference, Anaphora and Coreference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--crac-1--2><div class="card-body p-3 small">While it has been claimed that anaphora or <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> plays an important role in <a href=https://en.wikipedia.org/wiki/Opinion_mining>opinion mining</a>, it is not clear to what extent <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> actually boosts performance, if at all. In this paper, we investigate the potential added value of <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> for the aspect-based sentiment analysis of restaurant reviews in two languages, <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a>. We focus on the task of aspect category classification and investigate whether including coreference information prior to <a href=https://en.wikipedia.org/wiki/Categorization>classification</a> to resolve implicit aspect mentions is beneficial. Because <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> is not a solved task in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, we rely on both automatically-derived and gold-standard coreference relations, allowing us to investigate the true upper bound. By training a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> on a combination of lexical and semantic features, we show that resolving the coreferential relations prior to <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> is beneficial in a joint optimization setup. However, this is only the case when relying on <a href=https://en.wikipedia.org/wiki/Gold_standard>gold-standard relations</a> and the result is more outspoken for <a href=https://en.wikipedia.org/wiki/English_language>English</a> than for <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a>. When validating the optimal models, however, we found that only the Dutch pipeline is able to achieve a satisfying performance on a held-out test set and does so regardless of whether coreference information was included.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.204.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--204 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.204 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.204/>An Emotional Mess ! Deciding on a Framework for Building a Dutch Emotion-Annotated Corpus<span class=acl-fixed-case>D</span>utch Emotion-Annotated Corpus</a></strong><br><a href=/people/l/luna-de-bruyne/>Luna De Bruyne</a>
|
<a href=/people/o/orphee-de-clercq/>Orphee De Clercq</a>
|
<a href=/people/v/veronique-hoste/>Veronique Hoste</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--204><div class="card-body p-3 small">Seeing the myriad of existing emotion models, with the categorical versus dimensional opposition the most important dividing line, building an emotion-annotated corpus requires some well thought-out strategies concerning framework choice. In our work on automatic emotion detection in Dutch texts, we investigate this problem by means of two case studies. We find that the labels <a href=https://en.wikipedia.org/wiki/Joy>joy</a>, <a href=https://en.wikipedia.org/wiki/Love>love</a>, <a href=https://en.wikipedia.org/wiki/Anger>anger</a>, sadness and <a href=https://en.wikipedia.org/wiki/Fear>fear</a> are well-suited to annotate texts coming from various domains and topics, but that the connotation of the labels strongly depends on the origin of the texts. Moreover, it seems that information is lost when an <a href=https://en.wikipedia.org/wiki/Emotion>emotional state</a> is forcedly classified in a limited set of categories, indicating that a bi-representational format is desirable when creating an emotion corpus.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5536.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5536 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5536 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5536/>Benefits of Data Augmentation for NMT-based Text Normalization of <a href=https://en.wikipedia.org/wiki/User-generated_content>User-Generated Content</a><span class=acl-fixed-case>NMT</span>-based Text Normalization of User-Generated Content</a></strong><br><a href=/people/c/claudia-matos-veliz/>Claudia Matos Veliz</a>
|
<a href=/people/o/orphee-de-clercq/>Orphee De Clercq</a>
|
<a href=/people/v/veronique-hoste/>Veronique Hoste</a><br><a href=/volumes/D19-55/ class=text-muted>Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5536><div class="card-body p-3 small">One of the most persistent characteristics of written user-generated content (UGC) is the use of non-standard words. This characteristic contributes to an increased difficulty to automatically process and analyze UGC. Text normalization is the task of transforming lexical variants to their canonical forms and is often used as a pre-processing step for conventional NLP tasks in order to overcome the performance drop that NLP systems experience when applied to UGC. In this work, we follow a Neural Machine Translation approach to <a href=https://en.wikipedia.org/wiki/Text_normalization>text normalization</a>. To train such an encoder-decoder model, large parallel training corpora of sentence pairs are required. However, obtaining large data sets with UGC and their normalized version is not trivial, especially for languages other than <a href=https://en.wikipedia.org/wiki/English_language>English</a>. In this paper, we explore how to overcome this data bottleneck for <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a>, a low-resource language. We start off with a small publicly available parallel Dutch data set comprising three UGC genres and compare two different approaches. The <a href=https://en.wikipedia.org/wiki/First_law_of_thermodynamics>first</a> is to manually normalize and add training data, a money and time-consuming task. The second approach is a set of data augmentation techniques which increase data size by converting existing resources into synthesized non-standard forms. Our results reveal that, while the different approaches yield similar results regarding the normalization issues in the test set, they also introduce a large amount of over-normalizations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-1300.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-1300/>Proceedings of the Tenth Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></strong><br><a href=/people/a/alexandra-balahur/>Alexandra Balahur</a>
|
<a href=/people/r/roman-klinger/>Roman Klinger</a>
|
<a href=/people/v/veronique-hoste/>Veronique Hoste</a>
|
<a href=/people/c/carlo-strapparava/>Carlo Strapparava</a>
|
<a href=/people/o/orphee-de-clercq/>Orphee De Clercq</a><br><a href=/volumes/W19-13/ class=text-muted>Proceedings of the Tenth Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></span></p><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1016 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1016/>LT3 at SemEval-2018 Task 1 : A classifier chain to detect emotions in tweets<span class=acl-fixed-case>LT</span>3 at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: A classifier chain to detect emotions in tweets</a></strong><br><a href=/people/l/luna-de-bruyne/>Luna De Bruyne</a>
|
<a href=/people/o/orphee-de-clercq/>Orphée De Clercq</a>
|
<a href=/people/v/veronique-hoste/>Véronique Hoste</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1016><div class="card-body p-3 small">This paper presents an emotion classification system for English tweets, submitted for the SemEval shared task on Affect in Tweets, subtask 5 : Detecting Emotions. The system combines <a href=https://en.wikipedia.org/wiki/Lexicon>lexicon</a>, <a href=https://en.wikipedia.org/wiki/N-gram>n-gram</a>, style, syntactic and semantic features. For this multi-class multi-label problem, we created a classifier chain. This is an ensemble of eleven <a href=https://en.wikipedia.org/wiki/Binary_classification>binary classifiers</a>, one for each possible <a href=https://en.wikipedia.org/wiki/Emotion_classification>emotion category</a>, where each model gets the predictions of the preceding models as additional <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>. The predicted labels are combined to get a multi-label representation of the predictions. Our <a href=https://en.wikipedia.org/wiki/System>system</a> was ranked eleventh among thirty five participating teams, with a <a href=https://en.wikipedia.org/wiki/Jaccard>Jaccard accuracy</a> of 52.0 % and macro- and micro-average F1-scores of 49.3 % and 64.0 %, respectively.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5218.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5218 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5218 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5218/>Towards an integrated pipeline for aspect-based sentiment analysis in various domains</a></strong><br><a href=/people/o/orphee-de-clercq/>Orphée De Clercq</a>
|
<a href=/people/e/els-lefever/>Els Lefever</a>
|
<a href=/people/g/gilles-jacobs/>Gilles Jacobs</a>
|
<a href=/people/t/tijl-carpels/>Tijl Carpels</a>
|
<a href=/people/v/veronique-hoste/>Véronique Hoste</a><br><a href=/volumes/W17-52/ class=text-muted>Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5218><div class="card-body p-3 small">This paper presents an integrated ABSA pipeline for <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a> that has been developed and tested on qualitative user feedback coming from three domains : <a href=https://en.wikipedia.org/wiki/Retail>retail</a>, <a href=https://en.wikipedia.org/wiki/Bank>banking</a> and <a href=https://en.wikipedia.org/wiki/Human_resources>human resources</a>. The two latter <a href=https://en.wikipedia.org/wiki/Domain_(software_engineering)>domains</a> provide <a href=https://en.wikipedia.org/wiki/Service-oriented_architecture>service-oriented data</a>, which has not been investigated before in ABSA. By performing in-domain and cross-domain experiments the validity of our approach was investigated. We show promising results for the three ABSA subtasks, aspect term extraction, aspect category classification and aspect polarity classification.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Orphee+De+Clercq" title="Search for 'Orphee De Clercq' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/v/veronique-hoste/ class=align-middle>Veronique Hoste</a>
<span class="badge badge-secondary align-middle ml-2">9</span></li><li class=list-group-item><a href=/people/l/luna-de-bruyne/ class=align-middle>Luna De Bruyne</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/alexandra-balahur/ class=align-middle>Alexandra Balahur</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/thierry-desot/ class=align-middle>Thierry Desot</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/els-lefever/ class=align-middle>Els Lefever</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/g/gilles-jacobs/ class=align-middle>Gilles Jacobs</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tijl-carpels/ class=align-middle>Tijl Carpels</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/claudia-matos-veliz/ class=align-middle>Claudia Matos Veliz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/roman-klinger/ class=align-middle>Roman Klinger</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/carlo-strapparava/ class=align-middle>Carlo Strapparava</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joao-sedoc/ class=align-middle>João Sedoc</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/valentin-barriere/ class=align-middle>Valentin Barriere</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shabnam-tafreshi/ class=align-middle>Shabnam Tafreshi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sven-buechel/ class=align-middle>Sven Buechel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/wassa/ class=align-middle>WASSA</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ranlp/ class=align-middle>RANLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/crac/ class=align-middle>CRAC</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>