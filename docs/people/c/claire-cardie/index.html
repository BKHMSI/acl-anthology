<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Claire Cardie - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Claire</span> <span class=font-weight-bold>Cardie</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.70.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--70 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.70 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.70" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.70/>Template Filling with Generative Transformers</a></strong><br><a href=/people/x/xinya-du/>Xinya Du</a>
|
<a href=/people/a/alexander-m-rush/>Alexander Rush</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--70><div class="card-body p-3 small">Template filling is generally tackled by a pipeline of two separate supervised systems one for role-filler extraction and another for template / event recognition. Since <a href=https://en.wikipedia.org/wiki/Pipeline_transport>pipelines</a> consider events in isolation, they can suffer from <a href=https://en.wikipedia.org/wiki/Error_propagation>error propagation</a>. We introduce a <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> based on end-to-end generative transformers for this task (i.e., GTT). It naturally models the dependence between entities both within a single event and across the multiple events described in a document. Experiments demonstrate that this framework substantially outperforms pipeline-based approaches, and other neural end-to-end baselines that do not model between-event dependencies. We further show that our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> specifically improves performance on documents containing multiple events.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.124.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--124 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.124 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.124/>Adding Chit-Chat to Enhance Task-Oriented Dialogues</a></strong><br><a href=/people/k/kai-sun/>Kai Sun</a>
|
<a href=/people/s/seungwhan-moon/>Seungwhan Moon</a>
|
<a href=/people/p/paul-a-crook/>Paul Crook</a>
|
<a href=/people/s/stephen-roller/>Stephen Roller</a>
|
<a href=/people/b/becka-silvert/>Becka Silvert</a>
|
<a href=/people/b/bing-liu/>Bing Liu</a>
|
<a href=/people/z/zhiguang-wang/>Zhiguang Wang</a>
|
<a href=/people/h/honglei-liu/>Honglei Liu</a>
|
<a href=/people/e/eunjoon-cho/>Eunjoon Cho</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--124><div class="card-body p-3 small">Existing dialogue corpora and <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> are typically designed under two disjoint motives : while task-oriented systems focus on achieving functional goals (e.g., booking hotels), open-domain chatbots aim at making socially engaging conversations. In this work, we propose to integrate both types of systems by Adding <a href=https://en.wikipedia.org/wiki/Chit-chat>Chit-Chat</a> to ENhance Task-ORiented dialogues (ACCENTOR), with the goal of making virtual assistant conversations more engaging and interactive. Specifically, we propose a Human-AI collaborative data collection approach for generating diverse chit-chat responses to augment task-oriented dialogues with minimal annotation effort. We then present our new chit-chat-based annotations to 23.8 K dialogues from two popular <a href=https://en.wikipedia.org/wiki/Task_(computing)>task-oriented datasets</a> (Schema-Guided Dialogue and MultiWOZ 2.1) and demonstrate their advantage over the originals via human evaluation. Lastly, we propose three new models for adding <a href=https://en.wikipedia.org/wiki/Chit-chat>chit-chat</a> to task-oriented dialogues, explicitly trained to predict user goals and to generate contextually relevant chit-chat responses. Automatic and human evaluations show that, compared with the state-of-the-art task-oriented baseline, our models can code-switch between task and chit-chat to be more engaging, interesting, knowledgeable, and humanlike, while maintaining competitive task performance.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.49.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--49 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.49 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938649 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.49" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.49/>Event Extraction by Answering (Almost) Natural Questions</a></strong><br><a href=/people/x/xinya-du/>Xinya Du</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--49><div class="card-body p-3 small">The problem of <a href=https://en.wikipedia.org/wiki/Event_extraction>event extraction</a> requires detecting the event trigger and extracting its corresponding arguments. Existing work in event argument extraction typically relies heavily on <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity recognition</a> as a preprocessing / concurrent step, causing the well-known problem of <a href=https://en.wikipedia.org/wiki/Error_propagation>error propagation</a>. To avoid this issue, we introduce a new <a href=https://en.wikipedia.org/wiki/Paradigm>paradigm</a> for <a href=https://en.wikipedia.org/wiki/Event_extraction>event extraction</a> by formulating it as a question answering (QA) task that extracts the event arguments in an end-to-end manner. Empirical results demonstrate that our framework outperforms <a href=https://en.wikipedia.org/wiki/Prior_probability>prior methods</a> substantially ; in addition, it is capable of extracting <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>event arguments</a> for roles not seen at training time (i.e., in a zero-shot learning setting).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.aacl-main.55.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--aacl-main--55 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.aacl-main.55 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.aacl-main.55/>Leveraging Structured Metadata for Improving <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a> on the Web</a></strong><br><a href=/people/x/xinya-du/>Xinya Du</a>
|
<a href=/people/a/ahmed-hassan/>Ahmed Hassan Awadallah</a>
|
<a href=/people/a/adam-fourney/>Adam Fourney</a>
|
<a href=/people/r/robert-sim/>Robert Sim</a>
|
<a href=/people/p/paul-bennett/>Paul Bennett</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/2020.aacl-main/ class=text-muted>Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--aacl-main--55><div class="card-body p-3 small">We show that leveraging <a href=https://en.wikipedia.org/wiki/Metadata>metadata information</a> from <a href=https://en.wikipedia.org/wiki/Web_page>web pages</a> can improve the performance of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> for answer passage selection / reranking. We propose a neural passage selection model that leverages <a href=https://en.wikipedia.org/wiki/Metadata>metadata information</a> with a fine-grained encoding strategy, which learns the representation for <a href=https://en.wikipedia.org/wiki/Metadata>metadata predicates</a> in a hierarchical way. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are evaluated on the MS MARCO (Nguyen et al., 2016) and Recipe-MARCO datasets. Results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> significantly outperform baseline models, which do not incorporate <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a>. We also show that the fine-grained encoding&#8217;s advantage over other strategies for encoding the <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q19-1014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q19-1014 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q19-1014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q19-1014/>DREAM : A Challenge Data Set and Models for Dialogue-Based Reading Comprehension<span class=acl-fixed-case>DREAM</span>: A Challenge Data Set and Models for Dialogue-Based Reading Comprehension</a></strong><br><a href=/people/k/kai-sun/>Kai Sun</a>
|
<a href=/people/d/dian-yu/>Dian Yu</a>
|
<a href=/people/j/jianshu-chen/>Jianshu Chen</a>
|
<a href=/people/d/dong-yu/>Dong Yu</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/Q19-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 7</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q19-1014><div class="card-body p-3 small">We present <a href=https://en.wikipedia.org/wiki/DREAM>DREAM</a>, the first dialogue-based multiple-choice reading comprehension data set. Collected from English as a Foreign Language examinations designed by human experts to evaluate the comprehension level of Chinese learners of English, our <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> contains 10,197 <a href=https://en.wikipedia.org/wiki/Multiple_choice>multiple-choice questions</a> for 6,444 dialogues. In contrast to existing reading comprehension data sets, DREAM is the first to focus on in-depth multi-turn multi-party dialogue understanding. DREAM is likely to present significant challenges for existing reading comprehension systems : 84 % of answers are non-extractive, 85 % of questions require reasoning beyond a single sentence, and 34 % of questions also involve commonsense knowledge. We apply several popular neural reading comprehension models that primarily exploit surface information within the text and find them to, at best, just barely outperform a rule-based approach. We next investigate the effects of incorporating dialogue structure and different kinds of general world knowledge into both rule-based and (neural and non-neural) machine learning-based reading comprehension models. Experimental results on the DREAM data set show the effectiveness of dialogue structure and <a href=https://en.wikipedia.org/wiki/General_knowledge>general world knowledge</a>. DREAM is available at https://dataset.org/dream/.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1244.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1244 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1244 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1244" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N19-1244/>Be Consistent ! Improving Procedural Text Comprehension using Label Consistency</a></strong><br><a href=/people/x/xinya-du/>Xinya Du</a>
|
<a href=/people/b/bhavana-dalvi/>Bhavana Dalvi</a>
|
<a href=/people/n/niket-tandon/>Niket Tandon</a>
|
<a href=/people/a/antoine-bosselut/>Antoine Bosselut</a>
|
<a href=/people/w/wen-tau-yih/>Wen-tau Yih</a>
|
<a href=/people/p/peter-clark/>Peter Clark</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1244><div class="card-body p-3 small">Our goal is procedural text comprehension, namely tracking how the properties of entities (e.g., their location) change with time given a procedural text (e.g., a paragraph about photosynthesis, a recipe). This <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is challenging as the world is changing throughout the text, and despite recent advances, current <a href=https://en.wikipedia.org/wiki/System>systems</a> still struggle with this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. Our approach is to leverage the fact that, for many procedural texts, multiple independent descriptions are readily available, and that predictions from them should be consistent (label consistency). We present a new learning framework that leverages label consistency during training, allowing consistency bias to be built into the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>. Evaluation on a standard benchmark dataset for procedural text, ProPara (Dalvi et al., 2018), shows that our approach significantly improves prediction performance (F1) over prior state-of-the-art systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1270.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1270 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1270 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/364746823 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1270" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-1270/>Improving Machine Reading Comprehension with General Reading Strategies</a></strong><br><a href=/people/k/kai-sun/>Kai Sun</a>
|
<a href=/people/d/dian-yu/>Dian Yu</a>
|
<a href=/people/d/dong-yu/>Dong Yu</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1270><div class="card-body p-3 small">Reading strategies have been shown to improve <a href=https://en.wikipedia.org/wiki/Sentence_processing>comprehension levels</a>, especially for readers lacking adequate prior knowledge. Just as the process of knowledge accumulation is time-consuming for human readers, it is resource-demanding to impart rich general domain knowledge into a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep language model</a> via pre-training. Inspired by reading strategies identified in <a href=https://en.wikipedia.org/wiki/Cognitive_science>cognitive science</a>, and given limited computational resources-just a pre-trained model and a fixed number of training instances-we propose three general strategies aimed to improve non-extractive machine reading comprehension (MRC): (i) BACK AND FORTH READING that considers both the original and reverse order of an input sequence, (ii) HIGHLIGHTING, which adds a trainable embedding to the text embedding of tokens that are relevant to the question and candidate answers, and (iii) SELF-ASSESSMENT that generates practice questions and candidate answers directly from the text in an unsupervised manner. By fine-tuning a pre-trained language model (Radford et al., 2018) with our proposed strategies on the largest general domain multiple-choice MRC dataset RACE, we obtain a 5.8 % absolute increase in accuracy over the previous best result achieved by the same pre-trained model fine-tuned on RACE without the use of strategies.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1057.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1057 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1057 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1057/>A Corpus for Modeling User and Language Effects in <a href=https://en.wikipedia.org/wiki/Argumentation_theory>Argumentation</a> on Online Debating</a></strong><br><a href=/people/e/esin-durmus/>Esin Durmus</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1057><div class="card-body p-3 small">Existing argumentation datasets have succeeded in allowing researchers to develop <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational methods</a> for analyzing the content, structure and linguistic features of argumentative text. They have been much less successful in fostering studies of the effect of user traits characteristics and beliefs of the participants on the debate / argument outcome as this type of user information is generally not available. This paper presents a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 78,376 <a href=https://en.wikipedia.org/wiki/Debate>debates</a> generated over a 10-year period along with surprisingly comprehensive participant profiles. We also complete an example study using the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> to analyze the effect of selected user traits on the debate outcome in comparison to the <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a> typically employed in studies of this kind.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1407.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1407 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1407 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1407/>Keeping Notes : Conditional Natural Language Generation with a Scratchpad Encoder</a></strong><br><a href=/people/r/ryan-benmalek/>Ryan Benmalek</a>
|
<a href=/people/m/madian-khabsa/>Madian Khabsa</a>
|
<a href=/people/s/suma-desu/>Suma Desu</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a>
|
<a href=/people/m/michele-banko/>Michele Banko</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1407><div class="card-body p-3 small">We introduce the Scratchpad Mechanism, a novel addition to the sequence-to-sequence (seq2seq) neural network architecture and demonstrate its effectiveness in improving the overall fluency of seq2seq models for natural language generation tasks. By enabling the decoder at each time step to write to all of the <a href=https://en.wikipedia.org/wiki/Encoder>encoder output layers</a>, <a href=https://en.wikipedia.org/wiki/Scratchpad>Scratchpad</a> can employ the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> as a <a href=https://en.wikipedia.org/wiki/Scratchpad_memory>scratchpad memory</a> to keep track of what has been generated so far and thereby guide future generation. We evaluate <a href=https://en.wikipedia.org/wiki/Scratchpad>Scratchpad</a> in the context of three well-studied natural language generation tasks <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a>, Question Generation, and Text Summarization and obtain state-of-the-art or comparable performance on standard datasets for each task. Qualitative assessments in the form of human judgements (question generation), attention visualization (MT), and sample output (summarization) provide further evidence of the ability of <a href=https://en.wikipedia.org/wiki/Scratchpad>Scratchpad</a> to generate fluent and expressive output.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1024" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D18-1024/>Unsupervised Multilingual Word Embeddings</a></strong><br><a href=/people/x/xilun-chen/>Xilun Chen</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1024><div class="card-body p-3 small">Multilingual Word Embeddings (MWEs) represent words from multiple languages in a single distributional vector space. Unsupervised MWE (UMWE) methods acquire multilingual embeddings without cross-lingual supervision, which is a significant advantage over traditional supervised approaches and opens many new possibilities for low-resource languages. Prior art for learning UMWEs, however, merely relies on a number of independently trained Unsupervised Bilingual Word Embeddings (UBWEs) to obtain multilingual embeddings. These <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> fail to leverage the interdependencies that exist among many languages. To address this shortcoming, we propose a fully unsupervised framework for learning MWEs that directly exploits the relations between all language pairs. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> substantially outperforms previous approaches in the experiments on multilingual word translation and cross-lingual word similarity. In addition, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> even beats <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised approaches</a> trained with cross-lingual resources.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1108.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1108 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1108 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D18-1108.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/305198410 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1108" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1108/>Towards Dynamic Computation Graphs via Sparse Latent Structure</a></strong><br><a href=/people/v/vlad-niculae/>Vlad Niculae</a>
|
<a href=/people/a/andre-f-t-martins/>André F. T. Martins</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1108><div class="card-body p-3 small">Deep NLP models benefit from underlying structures in the datae.g., parse treestypically extracted using off-the-shelf <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a>. Recent attempts to jointly learn the latent structure encounter a tradeoff : either make factorization assumptions that limit expressiveness, or sacrifice end-to-end differentiability. Using the recently proposed SparseMAP inference, which retrieves a sparse distribution over latent structures, we propose a novel approach for end-to-end learning of latent structure predictors jointly with a downstream predictor. To the best of our knowledge, our method is the first to enable unrestricted dynamic computation graph construction from the global latent structure, while maintaining <a href=https://en.wikipedia.org/wiki/Derivative>differentiability</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1039.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1039 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1039 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/306129914 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1039" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1039/>Adversarial Deep Averaging Networks for Cross-Lingual Sentiment Classification</a></strong><br><a href=/people/x/xilun-chen/>Xilun Chen</a>
|
<a href=/people/y/yu-sun/>Yu Sun</a>
|
<a href=/people/b/ben-athiwaratkun/>Ben Athiwaratkun</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a>
|
<a href=/people/k/kilian-weinberger/>Kilian Weinberger</a><br><a href=/volumes/Q18-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 6</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1039><div class="card-body p-3 small">In recent years great success has been achieved in sentiment classification for <a href=https://en.wikipedia.org/wiki/English_language>English</a>, thanks in part to the availability of copious annotated resources. Unfortunately, most languages do not enjoy such an abundance of <a href=https://en.wikipedia.org/wiki/Data_(computing)>labeled data</a>. To tackle the sentiment classification problem in low-resource languages without adequate annotated data, we propose an Adversarial Deep Averaging Network (ADAN1) to transfer the knowledge learned from labeled data on a resource-rich source language to low-resource languages where only unlabeled data exist. ADAN has two discriminative branches : a sentiment classifier and an adversarial language discriminator. Both branches take input from a shared feature extractor to learn hidden representations that are simultaneously indicative for the classification task and invariant across languages. Experiments on Chinese and Arabic sentiment classification demonstrate that ADAN significantly outperforms state-of-the-art systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-1110.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-1110 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-1110 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-1110/>Understanding the Effect of Gender and Stance in Opinion Expression in Debates on Abortion</a></strong><br><a href=/people/e/esin-durmus/>Esin Durmus</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/W18-11/ class=text-muted>Proceedings of the Second Workshop on Computational Modeling of People’s Opinions, Personality, and Emotions in Social Media</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-1110><div class="card-body p-3 small">In this paper, we focus on understanding linguistic differences across groups with different self-identified gender and stance in expressing opinions about ABORTION. We provide a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> consisting of users&#8217; gender, stance on ABORTION as well as the debates in ABORTION drawn from debate.org. We use the gender and stance information to identify significant linguistic differences across individuals with different gender and stance. We show the importance of considering the stance information along with the gender since we observe significant linguistic differences across individuals with different stance even within the same gender group.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1079.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1079 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1079 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1079/>Nested Named Entity Recognition Revisited</a></strong><br><a href=/people/a/arzoo-katiyar/>Arzoo Katiyar</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1079><div class="card-body p-3 small">We propose a novel recurrent neural network-based approach to simultaneously handle nested named entity recognition and nested entity mention detection. The model learns a <a href=https://en.wikipedia.org/wiki/Hypergraph>hypergraph representation</a> for nested entities using <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> extracted from a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network</a>. In evaluations on three standard <a href=https://en.wikipedia.org/wiki/Data_set>data sets</a>, we show that our approach significantly outperforms existing state-of-the-art methods, which are feature-based. The approach is also efficient : <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> operates linearly in the number of tokens and the number of possible output labels at any token. Finally, we present an extension of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that jointly learns the head of each entity mention.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1094.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1094 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1094 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/282323369 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1094/>Exploring the Role of Prior Beliefs for Argument Persuasion</a></strong><br><a href=/people/e/esin-durmus/>Esin Durmus</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1094><div class="card-body p-3 small">Public debate forums provide a common platform for exchanging opinions on a topic of interest. While recent studies in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a> have provided empirical evidence that the language of the debaters and their patterns of interaction play a key role in changing the mind of a reader, research in <a href=https://en.wikipedia.org/wiki/Psychology>psychology</a> has shown that prior beliefs can affect our interpretation of an argument and could therefore constitute a competing alternative explanation for resistance to changing one&#8217;s stance. To study the actual effect of language use vs. prior beliefs on <a href=https://en.wikipedia.org/wiki/Persuasion>persuasion</a>, we provide a new dataset and propose a controlled setting that takes into consideration two reader-level factors : <a href=https://en.wikipedia.org/wiki/Ideology>political and religious ideology</a>. We find that prior beliefs affected by these reader-level factors play a more important role than language use effects and argue that it is important to account for them in NLP studies of persuasion.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1177.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1177 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1177 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1177.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285804906 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1177" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1177/>Harvesting Paragraph-level Question-Answer Pairs from Wikipedia<span class=acl-fixed-case>W</span>ikipedia</a></strong><br><a href=/people/x/xinya-du/>Xinya Du</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1177><div class="card-body p-3 small">We study the task of generating from Wikipedia articles question-answer pairs that cover content beyond a single sentence. We propose a neural network approach that incorporates coreference knowledge via a novel gating mechanism. As compared to <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> that only take into account sentence-level information (Heilman and Smith, 2010 ; Du et al., 2017 ; Zhou et al., 2017), we find that the linguistic knowledge introduced by the coreference representation aids question generation significantly, producing <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> that outperform the current state-of-the-art. We apply our system (composed of an answer span extraction system and the passage-level QG system) to the 10,000 top ranking Wikipedia articles and create a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of over one million question-answer pairs. We provide qualitative analysis for the this large-scale generated corpus from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1085.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1085 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1085 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234957033 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1085/>Going out on a limb : Joint Extraction of Entity Mentions and Relations without Dependency Trees</a></strong><br><a href=/people/a/arzoo-katiyar/>Arzoo Katiyar</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1085><div class="card-body p-3 small">We present a novel attention-based recurrent neural network for joint extraction of entity mentions and relations. We show that <a href=https://en.wikipedia.org/wiki/Attention>attention</a> along with long short term memory (LSTM) network can extract semantic relations between entity mentions without having access to dependency trees. Experiments on Automatic Content Extraction (ACE) corpora show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> significantly outperforms feature-based joint model by Li and Ji (2014). We also compare our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> with an end-to-end tree-based LSTM model (SPTree) by Miwa and Bansal (2016) and show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performs within 1 % on entity mentions and 2 % on relations. Our fine-grained analysis also shows that our model performs significantly better on Agent-Artifact relations, while SPTree performs better on Physical and Part-Whole relations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1091.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1091 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1091 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234957758 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P17-1091" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1091/>Argument Mining with Structured SVMs and <a href=https://en.wikipedia.org/wiki/Radio-frequency_identification>RNNs</a><span class=acl-fixed-case>SVM</span>s and <span class=acl-fixed-case>RNN</span>s</a></strong><br><a href=/people/v/vlad-niculae/>Vlad Niculae</a>
|
<a href=/people/j/joonsuk-park/>Joonsuk Park</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1091><div class="card-body p-3 small">We propose a novel factor graph model for <a href=https://en.wikipedia.org/wiki/Argument_mining>argument mining</a>, designed for settings in which the argumentative relations in a document do not necessarily form a <a href=https://en.wikipedia.org/wiki/Tree_structure>tree structure</a>. (This is the case in over 20 % of the web comments dataset we release.) Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> jointly learns elementary unit type classification and argumentative relation prediction. Moreover, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> supports <a href=https://en.wikipedia.org/wiki/Symmetric_multiprocessing>SVM and RNN parametrizations</a>, can enforce <a href=https://en.wikipedia.org/wiki/Constraint_(mathematics)>structure constraints</a> (e.g., transitivity), and can express dependencies between adjacent relations and propositions. Our approaches outperform <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured baselines</a> in both web comments and argumentative essay datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1123.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1123 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1123 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P17-1123" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P17-1123/>Learning to Ask : Neural Question Generation for Reading Comprehension</a></strong><br><a href=/people/x/xinya-du/>Xinya Du</a>
|
<a href=/people/j/junru-shao/>Junru Shao</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1123><div class="card-body p-3 small">We study automatic question generation for sentences from text passages in <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>. We introduce an attention-based sequence learning model for the task and investigate the effect of encoding sentence- vs. paragraph-level information. In contrast to all previous work, our model does not rely on hand-crafted rules or a sophisticated NLP pipeline ; it is instead trainable end-to-end via sequence-to-sequence learning. Automatic evaluation results show that our <a href=https://en.wikipedia.org/wiki/System>system</a> significantly outperforms the state-of-the-art rule-based system. In human evaluations, questions generated by our system are also rated as being more natural (i.e.,, <a href=https://en.wikipedia.org/wiki/Grammaticality>grammaticality</a>, fluency) and as more difficult to answer (in terms of syntactic and lexical divergence from the original text and reasoning needed to answer).<i>i.e.,</i>,\n grammaticality, fluency) and as more difficult to answer (in terms of\n syntactic and lexical divergence from the original text and reasoning\n needed to answer).\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5100.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5100/>Proceedings of the 4th Workshop on Argument Mining</a></strong><br><a href=/people/i/ivan-habernal/>Ivan Habernal</a>
|
<a href=/people/i/iryna-gurevych/>Iryna Gurevych</a>
|
<a href=/people/k/kevin-d-ashley/>Kevin Ashley</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a>
|
<a href=/people/n/nancy-green/>Nancy Green</a>
|
<a href=/people/d/diane-litman/>Diane Litman</a>
|
<a href=/people/g/georgios-petasis/>Georgios Petasis</a>
|
<a href=/people/c/chris-reed/>Chris Reed</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a>
|
<a href=/people/v/vern-walker/>Vern Walker</a><br><a href=/volumes/W17-51/ class=text-muted>Proceedings of the 4th Workshop on Argument Mining</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1219.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1219 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1219 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D17-1219.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1219/>Identifying Where to Focus in <a href=https://en.wikipedia.org/wiki/Reading_comprehension>Reading Comprehension</a> for Neural Question Generation</a></strong><br><a href=/people/x/xinya-du/>Xinya Du</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1219><div class="card-body p-3 small">A first step in the task of automatically generating questions for testing <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> is to identify question-worthy sentences, i.e. sentences in a text passage that humans find it worthwhile to ask questions about. We propose a hierarchical neural sentence-level sequence tagging model for this task, which existing approaches to question generation have ignored. The approach is fully data-driven with no sophisticated NLP pipelines or any hand-crafted rules / features and compares favorably to a number of baselines when evaluated on the SQuAD data set. When incorporated into an existing neural question generation system, the resulting end-to-end system achieves state-of-the-art performance for paragraph-level question generation for <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>.<i>question-worthy</i> sentences, i.e.\n sentences in a text passage that humans find it worthwhile to ask\n questions about. We propose a hierarchical neural sentence-level sequence\n tagging model for this task, which existing approaches to question\n generation have ignored. The approach is fully data-driven &#8212; with no\n sophisticated NLP pipelines or any hand-crafted rules/features &#8212; and\n compares favorably to a number of baselines when evaluated on the SQuAD\n data set. When incorporated into an existing neural question generation\n system, the resulting end-to-end system achieves state-of-the-art\n performance for paragraph-level question generation for reading\n comprehension.\n</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Claire+Cardie" title="Search for 'Claire Cardie' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/x/xinya-du/ class=align-middle>Xinya Du</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/k/kai-sun/ class=align-middle>Kai Sun</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/e/esin-durmus/ class=align-middle>Esin Durmus</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/arzoo-katiyar/ class=align-middle>Arzoo Katiyar</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/v/vlad-niculae/ class=align-middle>Vlad Niculae</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/x/xilun-chen/ class=align-middle>Xilun Chen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/dian-yu/ class=align-middle>Dian Yu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/dong-yu/ class=align-middle>Dong Yu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/joonsuk-park/ class=align-middle>Joonsuk Park</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/junru-shao/ class=align-middle>Junru Shao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ivan-habernal/ class=align-middle>Ivan Habernal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/iryna-gurevych/ class=align-middle>Iryna Gurevych</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kevin-d-ashley/ class=align-middle>Kevin D. Ashley</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nancy-green/ class=align-middle>Nancy Green</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/diane-litman/ class=align-middle>Diane Litman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/georgios-petasis/ class=align-middle>Georgios Petasis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chris-reed/ class=align-middle>Chris Reed</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/noam-slonim/ class=align-middle>Noam Slonim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vern-walker/ class=align-middle>Vern Walker</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ahmed-hassan/ class=align-middle>Ahmed Hassan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/adam-fourney/ class=align-middle>Adam Fourney</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/robert-sim/ class=align-middle>Robert Sim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paul-bennett/ class=align-middle>Paul Bennett</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andre-f-t-martins/ class=align-middle>André F. T. Martins</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yu-sun/ class=align-middle>Yu Sun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/ben-athiwaratkun/ class=align-middle>Ben Athiwaratkun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kilian-weinberger/ class=align-middle>Kilian Weinberger</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jianshu-chen/ class=align-middle>Jianshu Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yejin-choi/ class=align-middle>Yejin Choi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexander-m-rush/ class=align-middle>Alexander M. Rush</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/seungwhan-moon/ class=align-middle>Seungwhan Moon</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paul-a-crook/ class=align-middle>Paul A. Crook</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stephen-roller/ class=align-middle>Stephen Roller</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/becka-silvert/ class=align-middle>Becka Silvert</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bing-liu/ class=align-middle>Bing Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhiguang-wang/ class=align-middle>Zhiguang Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/honglei-liu/ class=align-middle>Honglei Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eunjoon-cho/ class=align-middle>Eunjoon Cho</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bhavana-dalvi/ class=align-middle>Bhavana Dalvi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/niket-tandon/ class=align-middle>Niket Tandon</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/antoine-bosselut/ class=align-middle>Antoine Bosselut</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wen-tau-yih/ class=align-middle>Wen-tau Yih</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/peter-clark/ class=align-middle>Peter Clark</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ryan-benmalek/ class=align-middle>Ryan Benmalek</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/madian-khabsa/ class=align-middle>Madian Khabsa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/suma-desu/ class=align-middle>Suma Desu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michele-banko/ class=align-middle>Michele Banko</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/tacl/ class=align-middle>TACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/aacl/ class=align-middle>AACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>