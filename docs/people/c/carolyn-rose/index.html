<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Carolyn Rose - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Carolyn</span> <span class=font-weight-bold>Rose</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Carolyn <span class=font-weight-normal>Rosé</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.82.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--82 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.82 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.82" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.82/>Robust Knowledge Graph Completion with Stacked Convolutions and a Student Re-Ranking Network</a></strong><br><a href=/people/j/justin-lovelace/>Justin Lovelace</a>
|
<a href=/people/d/denis-newman-griffis/>Denis Newman-Griffis</a>
|
<a href=/people/s/shikhar-vashishth/>Shikhar Vashishth</a>
|
<a href=/people/j/jill-fain-lehman/>Jill Fain Lehman</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rosé</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--82><div class="card-body p-3 small">Knowledge Graph (KG) completion research usually focuses on densely connected benchmark datasets that are not representative of real KGs. We curate two KG datasets that include biomedical and encyclopedic knowledge and use an existing commonsense KG dataset to explore KG completion in the more realistic setting where dense connectivity is not guaranteed. We develop a deep convolutional network that utilizes textual entity representations and demonstrate that our model outperforms recent KG completion methods in this challenging setting. We find that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s performance improvements stem primarily from its robustness to sparsity. We then distill the knowledge from the convolutional network into a student network that re-ranks promising candidate entities. This re-ranking stage leads to further improvements in performance and demonstrates the effectiveness of entity re-ranking for KG completion.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.130.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--130 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.130 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.130/>Evaluating the Impact of a Hierarchical Discourse Representation on Entity Coreference Resolution Performance</a></strong><br><a href=/people/s/sopan-khosla/>Sopan Khosla</a>
|
<a href=/people/j/james-fiacco/>James Fiacco</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rosé</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--130><div class="card-body p-3 small">Recent work on entity coreference resolution (CR) follows current trends in <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Learning</a> applied to embeddings and relatively simple task-related features. SOTA models do not make use of hierarchical representations of discourse structure. In this work, we leverage automatically constructed discourse parse trees within a neural approach and demonstrate a significant improvement on two benchmark entity coreference-resolution datasets. We explore how the impact varies depending upon the type of mention.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.codi-sharedtask.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.codi-sharedtask.0/>Proceedings of the CODI-CRAC 2021 Shared Task on Anaphora, Bridging, and Discourse Deixis in Dialogue</a></strong><br><a href=/people/s/sopan-khosla/>Sopan Khosla</a>
|
<a href=/people/r/ramesh-manuvinakurike/>Ramesh Manuvinakurike</a>
|
<a href=/people/v/vincent-ng/>Vincent Ng</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a>
|
<a href=/people/m/michael-strube/>Michael Strube</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rosé</a><br><a href=/volumes/2021.codi-sharedtask/ class=text-muted>Proceedings of the CODI-CRAC 2021 Shared Task on Anaphora, Bridging, and Discourse Deixis in Dialogue</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.140.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--140 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.140 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.140.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938750 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.140/>Incorporating <a href=https://en.wikipedia.org/wiki/Multimodal_interaction>Multimodal Information</a> in Open-Domain Web Keyphrase Extraction</a></strong><br><a href=/people/y/yansen-wang/>Yansen Wang</a>
|
<a href=/people/z/zhen-fan/>Zhen Fan</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rose</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--140><div class="card-body p-3 small">Open-domain Keyphrase extraction (KPE) on the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>Web</a> is a fundamental yet complex NLP task with a wide range of practical applications within the field of <a href=https://en.wikipedia.org/wiki/Information_retrieval>Information Retrieval</a>. In contrast to other document types, <a href=https://en.wikipedia.org/wiki/Web_design>web page designs</a> are intended for easy navigation and <a href=https://en.wikipedia.org/wiki/Information_retrieval>information finding</a>. Effective designs encode within the layout and formatting signals that point to where the important information can be found. In this work, we propose a modeling approach that leverages these multi-modal signals to aid in the KPE task. In particular, we leverage both <a href=https://en.wikipedia.org/wiki/Lexical_analysis>lexical and visual features</a> (e.g., size, <a href=https://en.wikipedia.org/wiki/Font>font</a>, position) at the micro-level to enable effective strategy induction and meta-level features that describe pages at a macro-level to aid in strategy selection. Our evaluation demonstrates that a combination of effective strategy induction and strategy selection within this approach for the KPE task outperforms state-of-the-art models. A qualitative post-hoc analysis illustrates how these <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> function within the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.681.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--681 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.681 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929304 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.681" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.681/>Towards Open Domain Event Trigger Identification using Adversarial Domain Adaptation</a></strong><br><a href=/people/a/aakanksha-naik/>Aakanksha Naik</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rose</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--681><div class="card-body p-3 small">We tackle the task of building supervised event trigger identification models which can generalize better across domains. Our work leverages the adversarial domain adaptation (ADA) framework to introduce domain-invariance. ADA uses adversarial training to construct representations that are predictive for trigger identification, but not predictive of the example&#8217;s domain. It requires no labeled data from the target domain, making <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> completely unsupervised. Experiments with two domains (English literature and news) show that ADA leads to an average F1 score improvement of 3.9 on out-of-domain data. Our best performing <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> (BERT-A) reaches 44-49 <a href=https://en.wikipedia.org/wiki/F-number>F1</a> across both domains, using no labeled target data. Preliminary experiments reveal that <a href=https://en.wikipedia.org/wiki/Finetuning>finetuning</a> on 1 % labeled data, followed by self-training leads to substantial improvement, reaching 51.5 and 67.2 F1 on <a href=https://en.wikipedia.org/wiki/Literature>literature</a> and <a href=https://en.wikipedia.org/wiki/News>news</a> respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigdial-1.31.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sigdial-1--31 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sigdial-1.31 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href="https://youtube.com/watch?v=3uC3ZJSL2Xc" data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.sigdial-1.31/>Agent-Based Dynamic Collaboration Support in a Smart Office Space</a></strong><br><a href=/people/y/yansen-wang/>Yansen Wang</a>
|
<a href=/people/r/r-charles-murray/>R. Charles Murray</a>
|
<a href=/people/h/haogang-bao/>Haogang Bao</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rose</a><br><a href=/volumes/2020.sigdial-1/ class=text-muted>Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sigdial-1--31><div class="card-body p-3 small">For the past 15 years, in computer-supported collaborative learning applications, conversational agents have been used to structure group interactions in online chat-based environments. A series of experimental studies has provided an empirical foundation for the design of chat-based conversational agents that significantly improve learning over no-support control conditions and static-support control conditions. In this demo, we expand upon this foundation, bringing conversational agents to structure group interaction into physical spaces, with the specific goal of facilitating <a href=https://en.wikipedia.org/wiki/Collaboration>collaboration</a> and <a href=https://en.wikipedia.org/wiki/Learning>learning</a> in workplace scenarios.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1575.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1575 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1575 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385434363 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1575/>Deep Neural Model Inspection and Comparison via Functional Neuron Pathways</a></strong><br><a href=/people/j/james-fiacco/>James Fiacco</a>
|
<a href=/people/s/samridhi-choudhary/>Samridhi Choudhary</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rose</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1575><div class="card-body p-3 small">We introduce a general <a href=https://en.wikipedia.org/wiki/Methodology>method</a> for the interpretation and comparison of neural models. The method is used to factor a complex neural model into its functional components, which are comprised of sets of co-firing neurons that cut across layers of the <a href=https://en.wikipedia.org/wiki/Network_architecture>network architecture</a>, and which we call <a href=https://en.wikipedia.org/wiki/Neural_pathway>neural pathways</a>. The function of these pathways can be understood by identifying correlated task level and linguistic heuristics in such a way that this knowledge acts as a lens for approximating what the network has learned to apply to its intended <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. As a case study for investigating the utility of these <a href=https://en.wikipedia.org/wiki/Neural_pathway>pathways</a>, we present an examination of <a href=https://en.wikipedia.org/wiki/Neural_pathway>pathways</a> identified in models trained for two standard tasks, namely <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a> and Recognizing Textual Entailment.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1010 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1010" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1010/>Attentive Interaction Model : Modeling Changes in View in Argumentation</a></strong><br><a href=/people/y/yohan-jo/>Yohan Jo</a>
|
<a href=/people/s/shivani-poddar/>Shivani Poddar</a>
|
<a href=/people/b/byungsoo-jeon/>Byungsoo Jeon</a>
|
<a href=/people/q/qinlan-shen/>Qinlan Shen</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rosé</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1010><div class="card-body p-3 small">We present a neural architecture for modeling argumentative dialogue that explicitly models the interplay between an Opinion Holder&#8217;s (OH&#8217;s) reasoning and a challenger&#8217;s argument, with the goal of predicting if the argument successfully changes the OH&#8217;s view. The model has two components : (1) vulnerable region detection, an attention model that identifies parts of the OH&#8217;s reasoning that are amenable to change, and (2) interaction encoding, which identifies the relationship between the content of the OH&#8217;s reasoning and that of the challenger&#8217;s argument. Based on evaluation on discussions from the Change My View forum on <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a>, the two components work together to predict an OH&#8217;s change in view, outperforming several baselines. A posthoc analysis suggests that sentences picked out by the attention model are addressed more frequently by successful arguments than by unsuccessful ones.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2346.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2346 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2346 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2346/>Extracting Personal Medical Events for User Timeline Construction using Minimal Supervision</a></strong><br><a href=/people/a/aakanksha-naik/>Aakanksha Naik</a>
|
<a href=/people/c/christopher-bogart/>Chris Bogart</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rose</a><br><a href=/volumes/W17-23/ class=text-muted>BioNLP 2017</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2346><div class="card-body p-3 small">In this paper, we describe a <a href=https://en.wikipedia.org/wiki/System>system</a> for automatic construction of user disease progression timelines from their posts in online support groups using minimal supervision. In recent years, several online support groups have been established which has led to a huge increase in the amount of patient-authored text available. Creating systems which can automatically extract important medical events and create disease progression timelines for users from such text can help in patient health monitoring as well as studying links between <a href=https://en.wikipedia.org/wiki/Disease>medical events</a> and users&#8217; participation in <a href=https://en.wikipedia.org/wiki/Support_group>support groups</a>. Prior work in this domain has used manually constructed keyword sets to detect medical events. In this work, our aim is to perform medical event detection using minimal supervision in order to develop a more general timeline construction system. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 55.17 %, which is 92 % of the performance achieved by a supervised baseline system.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2908.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2908 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2908 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2908/>Linguistic Markers of Influence in Informal Interactions</a></strong><br><a href=/people/s/shrimai-prabhumoye/>Shrimai Prabhumoye</a>
|
<a href=/people/s/samridhi-choudhary/>Samridhi Choudhary</a>
|
<a href=/people/e/evangelia-spiliopoulou/>Evangelia Spiliopoulou</a>
|
<a href=/people/c/christopher-bogart/>Christopher Bogart</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rose</a>
|
<a href=/people/a/alan-w-black/>Alan W Black</a><br><a href=/volumes/W17-29/ class=text-muted>Proceedings of the Second Workshop on NLP and Computational Social Science</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2908><div class="card-body p-3 small">There has been a long standing interest in understanding &#8216;<a href=https://en.wikipedia.org/wiki/Social_influence>Social Influence</a>&#8217; both in <a href=https://en.wikipedia.org/wiki/Social_science>Social Sciences</a> and in <a href=https://en.wikipedia.org/wiki/Computational_linguistics>Computational Linguistics</a>. In this paper, we present a novel approach to study and measure <a href=https://en.wikipedia.org/wiki/Interpersonal_influence>interpersonal influence</a> in <a href=https://en.wikipedia.org/wiki/Interpersonal_relationship>daily interactions</a>. Motivated by the basic principles of <a href=https://en.wikipedia.org/wiki/Social_influence>influence</a>, we attempt to identify indicative linguistic features of the posts in an online knitting community. We present the <a href=https://en.wikipedia.org/wiki/Scheme_(mathematics)>scheme</a> used to operationalize and label the posts as influential or non-influential. Experiments with the identified <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> show an improvement in the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification accuracy</a> of <a href=https://en.wikipedia.org/wiki/Social_influence>influence</a> by 3.15 %. Our results illustrate the important correlation between the structure of the language and its potential to influence others.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5538.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5538 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5538 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5538/>Finding Structure in <a href=https://en.wikipedia.org/wiki/Figurative_language>Figurative Language</a> : Metaphor Detection with Topic-based Frames</a></strong><br><a href=/people/h/hyeju-jang/>Hyeju Jang</a>
|
<a href=/people/k/keith-maki/>Keith Maki</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rosé</a><br><a href=/volumes/W17-55/ class=text-muted>Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5538><div class="card-body p-3 small">In this paper, we present a novel and highly effective method for <a href=https://en.wikipedia.org/wiki/Inductive_reasoning>induction</a> and application of metaphor frame templates as a step toward detecting metaphor in extended discourse. We infer implicit facets of a given metaphor frame using a semi-supervised bootstrapping approach on an unlabeled corpus. Our model applies this frame facet information to metaphor detection, and achieves the state-of-the-art performance on a social media dataset when building upon other proven <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> in a nonlinear machine learning model. In addition, we illustrate the mechanism through which the frame and topic information enable the more accurate metaphor detection.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Carolyn+Rose" title="Search for 'Carolyn Rose' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/y/yansen-wang/ class=align-middle>Yansen Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/aakanksha-naik/ class=align-middle>Aakanksha Naik</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/christopher-bogart/ class=align-middle>Christopher Bogart</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/samridhi-choudhary/ class=align-middle>Samridhi Choudhary</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sopan-khosla/ class=align-middle>Sopan Khosla</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/j/james-fiacco/ class=align-middle>James Fiacco</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/justin-lovelace/ class=align-middle>Justin Lovelace</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/denis-newman-griffis/ class=align-middle>Denis Newman-Griffis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shikhar-vashishth/ class=align-middle>Shikhar Vashishth</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jill-fain-lehman/ class=align-middle>Jill Fain Lehman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhen-fan/ class=align-middle>Zhen Fan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shrimai-prabhumoye/ class=align-middle>Shrimai Prabhumoye</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/evangelia-spiliopoulou/ class=align-middle>Evangelia Spiliopoulou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alan-w-black/ class=align-middle>Alan W. Black</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hyeju-jang/ class=align-middle>Hyeju Jang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/keith-maki/ class=align-middle>Keith Maki</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eduard-hovy/ class=align-middle>Eduard Hovy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yohan-jo/ class=align-middle>Yohan Jo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shivani-poddar/ class=align-middle>Shivani Poddar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/byungsoo-jeon/ class=align-middle>Byungsoo Jeon</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qinlan-shen/ class=align-middle>Qinlan Shen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/graham-neubig/ class=align-middle>Graham Neubig</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ramesh-manuvinakurike/ class=align-middle>Ramesh Manuvinakurike</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vincent-ng/ class=align-middle>Vincent Ng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/massimo-poesio/ class=align-middle>Massimo Poesio</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-strube/ class=align-middle>Michael Strube</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/r-charles-murray/ class=align-middle>R. Charles Murray</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haogang-bao/ class=align-middle>Haogang Bao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/codi/ class=align-middle>CODI</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/sigdial/ class=align-middle>SIGDIAL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>