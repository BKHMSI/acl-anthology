<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Claire Gardent - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Claire</span> <span class=font-weight-bold>Gardent</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.586.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--586 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.586 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.586/>Generating Biographies on <span class=acl-fixed-case>W</span>ikipedia: The Impact of Gender Bias on the Retrieval-Based Generation of Women Biographies</a></strong><br><a href=/people/a/angela-fan/>Angela Fan</a>
|
<a href=/people/c/claire-gardent/>Claire Gardent</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--586><div class="card-body p-3 small">Generating factual, long-form text such as Wikipedia articles raises three key challenges: how to gather relevant evidence, how to structure information into well-formed text, and how to ensure that the generated text is factually correct. We address these by developing a model for English text that uses a retrieval mechanism to identify relevant supporting information on the web and a cache-based pre-trained encoder-decoder to generate long-form biographies section by section, including citation information. To assess the impact of available web evidence on the output text, we compare the performance of our approach when generating biographies about women (for which less information is available on the web) vs. biographies generally. To this end, we curate a dataset of 1,500 biographies about women. We analyze our generated text to understand how differences in available web evidence data affect generation. We evaluate the factuality, fluency, and quality of the generated texts using automatic metrics and human evaluation. We hope that these techniques can be used as a starting point for human writers, to aid in reducing the complexity inherent in the creation of long-form, factual text.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nl4xai-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nl4xai-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nl4xai-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nl4xai-1.5/>The Natural Language Pipeline, Neural Text Generation and Explainability</a></strong><br><a href=/people/j/juliette-faille/>Juliette Faille</a>
|
<a href=/people/a/albert-gatt/>Albert Gatt</a>
|
<a href=/people/c/claire-gardent/>Claire Gardent</a><br><a href=/volumes/2020.nl4xai-1/ class=text-muted>2nd Workshop on Interactive Natural Language Technology for Explainable Artificial Intelligence</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nl4xai-1--5><div class="card-body p-3 small">End-to-end encoder-decoder approaches to data-to-text generation are often black boxes whose predictions are difficult to explain. Breaking up the end-to-end model into sub-modules is a natural way to address this problem. The traditional pre-neural Natural Language Generation (NLG) pipeline provides a framework for breaking up the end-to-end encoder-decoder. We survey recent papers that integrate traditional NLG submodules in neural approaches and analyse their explainability. Our survey is a first step towards building explainable neural NLG models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.231.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--231 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.231 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938791 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.231/>Multilingual AMR-to-Text Generation<span class=acl-fixed-case>AMR</span>-to-Text Generation</a></strong><br><a href=/people/a/angela-fan/>Angela Fan</a>
|
<a href=/people/c/claire-gardent/>Claire Gardent</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--231><div class="card-body p-3 small">Generating text from <a href=https://en.wikipedia.org/wiki/Structured_data>structured data</a> is challenging because it requires bridging the gap between (i) structure and natural language (NL) and (ii) semantically underspecified input and fully specified NL output. Multilingual generation brings in an additional challenge : that of generating into languages with varied word order and <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphological properties</a>. In this work, we focus on Abstract Meaning Representations (AMRs) as structured input, where previous research has overwhelmingly focused on generating only into <a href=https://en.wikipedia.org/wiki/English_language>English</a>. We leverage advances in cross-lingual embeddings, pretraining, and multilingual models to create multilingual AMR-to-text models that generate in twenty one different languages. Our multilingual models surpass <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> that generate into one language in eighteen languages, based on <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>automatic metrics</a>. We analyze the ability of our multilingual models to accurately capture <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphology</a> and word order using human evaluation, and find that <a href=https://en.wikipedia.org/wiki/First_language>native speakers</a> judge our generations to be fluent.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1305.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1305 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1305 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1305.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-1305/>Surface Realisation Using Full Delexicalisation</a></strong><br><a href=/people/a/anastasia-shimorina/>Anastasia Shimorina</a>
|
<a href=/people/c/claire-gardent/>Claire Gardent</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1305><div class="card-body p-3 small">Surface realisation (SR) maps a meaning representation to a sentence and can be viewed as consisting of three subtasks : <a href=https://en.wikipedia.org/wiki/Word_order>word ordering</a>, <a href=https://en.wikipedia.org/wiki/Inflection>morphological inflection</a> and <a href=https://en.wikipedia.org/wiki/Contraction_(grammar)>contraction generation</a> (e.g., clitic attachment in Portuguese or elision in French). We propose a modular approach to surface realisation which models each of these components separately, and evaluate our approach on the 10 languages covered by the SR&#8217;18 Surface Realisation Shared Task shallow track. We provide a detailed evaluation of how <a href=https://en.wikipedia.org/wiki/Word_order>word order</a>, <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphological realisation</a> and <a href=https://en.wikipedia.org/wiki/Contraction_(grammar)>contractions</a> are handled by the model and an analysis of the differences in word ordering performance across languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1314.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1314 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1314 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1314.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1314" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1314/>Enhancing AMR-to-Text Generation with Dual Graph Representations<span class=acl-fixed-case>AMR</span>-to-Text Generation with Dual Graph Representations</a></strong><br><a href=/people/l/leonardo-f-r-ribeiro/>Leonardo F. R. Ribeiro</a>
|
<a href=/people/c/claire-gardent/>Claire Gardent</a>
|
<a href=/people/i/iryna-gurevych/>Iryna Gurevych</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1314><div class="card-body p-3 small">Generating text from <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph-based data</a>, such as Abstract Meaning Representation (AMR), is a challenging task due to the inherent difficulty in how to properly encode the structure of a <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a> with labeled edges. To address this difficulty, we propose a novel graph-to-sequence model that encodes different but complementary perspectives of the structural information contained in the AMR graph. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> learns parallel top-down and bottom-up representations of nodes capturing contrasting views of the graph. We also investigate the use of different node message passing strategies, employing different state-of-the-art graph encoders to compute node representations based on incoming and outgoing perspectives. In our experiments, we demonstrate that the dual graph representation leads to improvements in AMR-to-text generation, achieving state-of-the-art results on two AMR datasets</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6312.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-6312 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-6312 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6312/>LORIA / Lorraine University at Multilingual Surface Realisation 2019<span class=acl-fixed-case>LORIA</span> / Lorraine University at Multilingual Surface Realisation 2019</a></strong><br><a href=/people/a/anastasia-shimorina/>Anastasia Shimorina</a>
|
<a href=/people/c/claire-gardent/>Claire Gardent</a><br><a href=/volumes/D19-63/ class=text-muted>Proceedings of the 2nd Workshop on Multilingual Surface Realisation (MSR 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-6312><div class="card-body p-3 small">This paper presents the LORIA / Lorraine University submission at the Multilingual Surface Realisation shared task 2019 for the shallow track. We outline our <a href=https://en.wikipedia.org/wiki/Software_development_process>approach</a> and evaluate <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> on 11 languages covered by the shared task. We provide a separate evaluation of each component of our <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline</a>, concluding on some difficulties and suggesting directions for future work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8635.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8635 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8635 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8635/>Revisiting the Binary Linearization Technique for Surface Realization</a></strong><br><a href=/people/y/yevgeniy-puzikov/>Yevgeniy Puzikov</a>
|
<a href=/people/c/claire-gardent/>Claire Gardent</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a>
|
<a href=/people/i/iryna-gurevych/>Iryna Gurevych</a><br><a href=/volumes/W19-86/ class=text-muted>Proceedings of the 12th International Conference on Natural Language Generation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8635><div class="card-body p-3 small">End-to-end neural approaches have achieved state-of-the-art performance in many natural language processing (NLP) tasks. Yet, they often lack transparency of the underlying <a href=https://en.wikipedia.org/wiki/Decision-making>decision-making process</a>, hindering error analysis and certain model improvements. In this work, we revisit the binary linearization approach to surface realization, which exhibits more interpretable behavior, but was falling short in terms of prediction accuracy. We show how enriching the training data to better capture word order constraints almost doubles the performance of the <a href=https://en.wikipedia.org/wiki/System>system</a>. We further demonstrate that encoding both local and global prediction contexts yields another considerable performance boost. With the proposed modifications, the <a href=https://en.wikipedia.org/wiki/System>system</a> which ranked low in the latest shared task on multilingual surface realization now achieves best results in five out of ten languages, while being on par with the state-of-the-art approaches in others.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1113.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1113 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1113 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/305214075 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1113/>Generating Syntactic Paraphrases</a></strong><br><a href=/people/e/emilie-colin/>Emilie Colin</a>
|
<a href=/people/c/claire-gardent/>Claire Gardent</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1113><div class="card-body p-3 small">We study the automatic generation of syntactic paraphrases using four different models for generation : data-to-text generation, text-to-text generation, text reduction and text expansion, We derive training data for each of these tasks from the WebNLG dataset and we show (i) that conditioning generation on syntactic constraints effectively permits the generation of syntactically distinct paraphrases for the same input and (ii) that exploiting different types of input (data, text or data+text) further increases the number of distinct paraphrases that can be generated for a given input.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6543.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6543 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6543 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-6543" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-6543/>Handling Rare Items in Data-to-Text Generation</a></strong><br><a href=/people/a/anastasia-shimorina/>Anastasia Shimorina</a>
|
<a href=/people/c/claire-gardent/>Claire Gardent</a><br><a href=/volumes/W18-65/ class=text-muted>Proceedings of the 11th International Conference on Natural Language Generation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6543><div class="card-body p-3 small">Neural approaches to data-to-text generation generally handle rare input items using either delexicalisation or a copy mechanism. We investigate the relative impact of these two methods on two datasets (E2E and WebNLG) and using two evaluation settings. We show (i) that rare items strongly impact performance ; (ii) that combining delexicalisation and <a href=https://en.wikipedia.org/wiki/Copying>copying</a> yields the strongest improvement ; (iii) that <a href=https://en.wikipedia.org/wiki/Copying>copying</a> underperforms for rare and unseen items and (iv) that the impact of these two mechanisms greatly varies depending on how the dataset is constructed and on how it is split into train, dev and test.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1017.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1017 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1017 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234952361 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1017/>Creating Training Corpora for NLG Micro-Planners<span class=acl-fixed-case>NLG</span> Micro-Planners</a></strong><br><a href=/people/c/claire-gardent/>Claire Gardent</a>
|
<a href=/people/a/anastasia-shimorina/>Anastasia Shimorina</a>
|
<a href=/people/s/shashi-narayan/>Shashi Narayan</a>
|
<a href=/people/l/laura-perez-beltrachini/>Laura Perez-Beltrachini</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1017><div class="card-body p-3 small">In this paper, we present a novel framework for semi-automatically creating linguistically challenging micro-planning data-to-text corpora from existing Knowledge Bases. Because our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> pairs data of varying size and shape with texts ranging from simple clauses to short texts, a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> created using this <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> provides a challenging benchmark for microplanning. Another feature of this <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> is that it can be applied to any large scale knowledge base and can therefore be used to train and learn KB verbalisers. We apply our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> to <a href=https://en.wikipedia.org/wiki/DBpedia>DBpedia data</a> and compare the resulting <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> with Wen et al. 2016&#8217;s. We show that while Wen et al.&#8217;s dataset is more than twice larger than ours, it is less diverse both in terms of input and in terms of text. We thus propose our corpus generation framework as a novel method for creating challenging data sets from which NLG models can be learned which are capable of handling the complex interactions occurring during in micro-planning between lexicalisation, aggregation, surface realisation, referring expression generation and sentence segmentation. To encourage researchers to take up this challenge, we made available a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 21,855 data / text pairs created using this <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> in the context of the WebNLG shared task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3518.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3518 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3518 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3518/>The WebNLG Challenge : Generating Text from <a href=https://en.wikipedia.org/wiki/Resource_Description_Framework>RDF Data</a><span class=acl-fixed-case>W</span>eb<span class=acl-fixed-case>NLG</span> Challenge: Generating Text from <span class=acl-fixed-case>RDF</span> Data</a></strong><br><a href=/people/c/claire-gardent/>Claire Gardent</a>
|
<a href=/people/a/anastasia-shimorina/>Anastasia Shimorina</a>
|
<a href=/people/s/shashi-narayan/>Shashi Narayan</a>
|
<a href=/people/l/laura-perez-beltrachini/>Laura Perez-Beltrachini</a><br><a href=/volumes/W17-35/ class=text-muted>Proceedings of the 10th International Conference on Natural Language Generation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3518><div class="card-body p-3 small">The WebNLG challenge consists in mapping sets of <a href=https://en.wikipedia.org/wiki/Resource_Description_Framework>RDF triples</a> to text. It provides a common benchmark on which to train, evaluate and compare <a href=https://en.wikipedia.org/wiki/Microplanners>microplanners</a>, i.e. generation systems that verbalise a given content by making a range of complex interacting choices including referring expression generation, aggregation, <a href=https://en.wikipedia.org/wiki/Lexicalization>lexicalisation</a>, surface realisation and <a href=https://en.wikipedia.org/wiki/Sentence_segmentation>sentence segmentation</a>. In this paper, we introduce the microplanning task, describe data preparation, introduce our evaluation methodology, analyse participant results and provide a brief description of the participating systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3537.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3537 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3537 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3537/>Analysing Data-To-Text Generation Benchmarks</a></strong><br><a href=/people/l/laura-perez-beltrachini/>Laura Perez-Beltrachini</a>
|
<a href=/people/c/claire-gardent/>Claire Gardent</a><br><a href=/volumes/W17-35/ class=text-muted>Proceedings of the 10th International Conference on Natural Language Generation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3537><div class="card-body p-3 small">A generation system can only be as good as the data it is trained on. In this short paper, we propose a <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> for analysing data-to-text corpora used for training Natural Language Generation (NLG) systems. We apply this <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> to three existing <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a>. We conclude by eliciting a set of criteria for the creation of a data-to-text benchmark which could help better support the development, evaluation and comparison of linguistically sophisticated data-to-text generators.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6800.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6800/><span class=acl-fixed-case>IWCS</span> 2017 - 12th International Conference on Computational Semantics - Long papers</a></strong><br><a href=/people/c/claire-gardent/>Claire Gardent</a>
|
<a href=/people/c/christian-retore/>Christian Retoré</a><br><a href=/volumes/W17-68/ class=text-muted>IWCS 2017 - 12th International Conference on Computational Semantics - Long papers</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6900.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6900/><span class=acl-fixed-case>IWCS</span> 2017 — 12th International Conference on Computational Semantics — Short papers</a></strong><br><a href=/people/c/claire-gardent/>Claire Gardent</a>
|
<a href=/people/c/christian-retore/>Christian Retoré</a><br><a href=/volumes/W17-69/ class=text-muted>IWCS 2017 — 12th International Conference on Computational Semantics — Short papers</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/J17-1001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-J17-1001 data-toggle=collapse aria-expanded=false aria-controls=abstract-J17-1001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/J17-1001/>A Statistical, Grammar-Based Approach to Microplanning</a></strong><br><a href=/people/c/claire-gardent/>Claire Gardent</a>
|
<a href=/people/l/laura-perez-beltrachini/>Laura Perez-Beltrachini</a><br><a href=/volumes/J17-1/ class=text-muted>Computational Linguistics, Volume 43, Issue 1 - April 2017</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-J17-1001><div class="card-body p-3 small">Although there has been much work in recent years on data-driven natural language generation, little attention has been paid to the fine-grained interactions that arise during microplanning between aggregation, surface realization, and <a href=https://en.wikipedia.org/wiki/Sentence_segmentation>sentence segmentation</a>. In this article, we propose a hybrid symbolic / statistical approach to jointly model the constraints regulating these <a href=https://en.wikipedia.org/wiki/Interaction_(statistics)>interactions</a>. Our approach integrates a small handwritten grammar, a statistical hypertagger, and a surface realization algorithm. It is applied to the verbalization of knowledge base queries and tested on 13 <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge bases</a> to demonstrate domain independence. We evaluate our <a href=https://en.wikipedia.org/wiki/Tactic_(method)>approach</a> in several ways. A quantitative analysis shows that the hybrid approach outperforms a purely symbolic approach in terms of both <a href=https://en.wikipedia.org/wiki/Speed>speed</a> and <a href=https://en.wikipedia.org/wiki/Coverage_(telecommunication)>coverage</a>. Results from a human study indicate that users find the output of this hybrid statistic / symbolic system more fluent than both a template-based and a purely symbolic grammar-based approach. Finally, we illustrate by means of examples that our approach can account for various factors impacting <a href=https://en.wikipedia.org/wiki/Aggregate_data>aggregation</a>, <a href=https://en.wikipedia.org/wiki/Sentence_segmentation>sentence segmentation</a>, and surface realization.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1064.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1064 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1064 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238230265 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D17-1064" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1064/>Split and Rephrase</a></strong><br><a href=/people/s/shashi-narayan/>Shashi Narayan</a>
|
<a href=/people/c/claire-gardent/>Claire Gardent</a>
|
<a href=/people/s/shay-b-cohen/>Shay B. Cohen</a>
|
<a href=/people/a/anastasia-shimorina/>Anastasia Shimorina</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1064><div class="card-body p-3 small">We propose a new sentence simplification task (Split-and-Rephrase) where the aim is to split a complex sentence into a meaning preserving sequence of shorter sentences. Like <a href=https://en.wikipedia.org/wiki/Sentence_simplification>sentence simplification</a>, splitting-and-rephrasing has the potential of benefiting both <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> and societal applications. Because shorter sentences are generally better processed by <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP systems</a>, it could be used as a preprocessing step which facilitates and improves the performance of <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a>, <a href=https://en.wikipedia.org/wiki/Semantic_role_labeling>semantic role labellers</a> and <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation systems</a>. It should also be of use for people with reading disabilities because <a href=https://en.wikipedia.org/wiki/Italian_language>it</a> allows the conversion of longer sentences into shorter ones. This paper makes two contributions towards this new task. First, we create and make available a <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark</a> consisting of 1,066,115 tuples mapping a single complex sentence to a sequence of sentences expressing the same meaning. Second, we propose five <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> (vanilla sequence-to-sequence to semantically-motivated models) to understand the difficulty of the proposed task.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Claire+Gardent" title="Search for 'Claire Gardent' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/a/anastasia-shimorina/ class=align-middle>Anastasia Shimorina</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/l/laura-perez-beltrachini/ class=align-middle>Laura Perez-Beltrachini</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/s/shashi-narayan/ class=align-middle>Shashi Narayan</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/angela-fan/ class=align-middle>Angela Fan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/christian-retore/ class=align-middle>Christian Retoré</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/i/iryna-gurevych/ class=align-middle>Iryna Gurevych</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/juliette-faille/ class=align-middle>Juliette Faille</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/albert-gatt/ class=align-middle>Albert Gatt</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/emilie-colin/ class=align-middle>Emilie Colin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/leonardo-f-r-ribeiro/ class=align-middle>Leonardo F. R. Ribeiro</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shay-b-cohen/ class=align-middle>Shay B. Cohen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yevgeniy-puzikov/ class=align-middle>Yevgeniy Puzikov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ido-dagan/ class=align-middle>Ido Dagan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/nl4xai/ class=align-middle>NL4XAI</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/cl/ class=align-middle>CL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>