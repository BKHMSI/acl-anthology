<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Chunhua Liu - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Chunhua</span> <span class=font-weight-bold>Liu</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.38.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--38 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.38 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.38/>Commonsense Knowledge in <a href=https://en.wikipedia.org/wiki/Word_association>Word Associations</a> and ConceptNet<span class=acl-fixed-case>C</span>oncept<span class=acl-fixed-case>N</span>et</a></strong><br><a href=/people/c/chunhua-liu/>Chunhua Liu</a>
|
<a href=/people/t/trevor-cohn/>Trevor Cohn</a>
|
<a href=/people/l/lea-frermann/>Lea Frermann</a><br><a href=/volumes/2021.conll-1/ class=text-muted>Proceedings of the 25th Conference on Computational Natural Language Learning</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--38><div class="card-body p-3 small">Humans use countless basic, shared facts about the world to efficiently navigate in their environment. This <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a> is rarely communicated explicitly, however, understanding how <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a> is represented in different paradigms is important for (a) a deeper understanding of human cognition and (b) augmenting automatic reasoning systems. This paper presents an in-depth comparison of two large-scale resources of general knowledge : <a href=https://en.wikipedia.org/wiki/ConceptNet>ConceptNet</a>, an engineered relational database, and SWOW, a <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graph</a> derived from crowd-sourced word associations. We examine the structure, overlap and differences between the two <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graphs</a>, as well as the extent of situational commonsense knowledge present in the two <a href=https://en.wikipedia.org/wiki/Factors_of_production>resources</a>. We finally show empirically that both resources improve downstream task performance on commonsense reasoning benchmarks over text-only baselines, suggesting that large-scale word association data, which have been obtained for several languages through crowd-sourcing, can be a valuable complement to curated knowledge graphs.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-6012 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-6012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6012/>BLCU-NLP at COIN-Shared Task1 : Stagewise Fine-tuning BERT for Commonsense Inference in Everyday Narrations<span class=acl-fixed-case>BLCU</span>-<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>COIN</span>-Shared Task1: Stagewise Fine-tuning <span class=acl-fixed-case>BERT</span> for Commonsense Inference in Everyday Narrations</a></strong><br><a href=/people/c/chunhua-liu/>Chunhua Liu</a>
|
<a href=/people/d/dong-yu/>Dong Yu</a><br><a href=/volumes/D19-60/ class=text-muted>Proceedings of the First Workshop on Commonsense Inference in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-6012><div class="card-body p-3 small">This paper describes our <a href=https://en.wikipedia.org/wiki/System>system</a> for COIN Shared Task 1 : Commonsense Inference in Everyday Narrations. To inject more external knowledge to better reason over the narrative passage, question and answer, the <a href=https://en.wikipedia.org/wiki/System>system</a> adopts a stagewise fine-tuning method based on pre-trained BERT model. More specifically, the first stage is to fine-tune on addi- tional machine reading comprehension dataset to learn more <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a>. The second stage is to fine-tune on target-task (MCScript2.0) with MCScript (2018) dataset assisted. Experimental results show that our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves significant improvements over the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline systems</a> with 84.2 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on the official test dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-2191.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S19-2191 data-toggle=collapse aria-expanded=false aria-controls=abstract-S19-2191 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-2191/>BLCU_NLP at SemEval-2019 Task 7 : An Inference Chain-based GPT Model for Rumour Evaluation<span class=acl-fixed-case>BLCU</span>_<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2019 Task 7: An Inference Chain-based <span class=acl-fixed-case>GPT</span> Model for Rumour Evaluation</a></strong><br><a href=/people/r/ruoyao-yang/>Ruoyao Yang</a>
|
<a href=/people/w/wanying-xie/>Wanying Xie</a>
|
<a href=/people/c/chunhua-liu/>Chunhua Liu</a>
|
<a href=/people/d/dong-yu/>Dong Yu</a><br><a href=/volumes/S19-2/ class=text-muted>Proceedings of the 13th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S19-2191><div class="card-body p-3 small">Researchers have been paying increasing attention to rumour evaluation due to the rapid spread of unsubstantiated rumours on <a href=https://en.wikipedia.org/wiki/Social_media>social media platforms</a>, including SemEval 2019 task 7. However, labelled data for learning rumour veracity is scarce, and labels in rumour stance data are highly disproportionate, making it challenging for a model to perform <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised-learning</a> adequately. We propose an inference chain-based system, which fully utilizes conversation structure-based knowledge in the limited data and expand the training data in minority categories to alleviate <a href=https://en.wikipedia.org/wiki/Social_class>class imbalance</a>. Our <a href=https://en.wikipedia.org/wiki/Software_development_process>approach</a> obtains 12.6 % improvement upon the baseline system for subtask A, ranks 1st among 21 systems in subtask A, and ranks 4th among 12 systems in subtask B.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1186.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1186 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1186 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1186/>BLCU_NLP at SemEval-2018 Task 12 : An Ensemble Model for Argument Reasoning Based on Hierarchical Attention<span class=acl-fixed-case>BLCU</span>_<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 12: An Ensemble Model for Argument Reasoning Based on Hierarchical Attention</a></strong><br><a href=/people/m/meiqian-zhao/>Meiqian Zhao</a>
|
<a href=/people/c/chunhua-liu/>Chunhua Liu</a>
|
<a href=/people/l/lu-liu/>Lu Liu</a>
|
<a href=/people/y/yan-zhao/>Yan Zhao</a>
|
<a href=/people/d/dong-yu/>Dong Yu</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1186><div class="card-body p-3 small">To comprehend an argument and fill the gap between claims and reasons, it is vital to find the implicit supporting warrants behind. In this paper, we propose a hierarchical attention model to identify the right warrant which explains why the reason stands for the claim. Our model focuses not only on the similar part between warrants and other information but also on the contradictory part between two opposing warrants. In addition, we use the ensemble method for different <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 61 %, ranking second in this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. Experimental results demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is effective to make correct choices.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-1010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-1010 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-1010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-1010/>Semantic Frame Labeling with Target-based Neural Model</a></strong><br><a href=/people/y/yukun-feng/>Yukun Feng</a>
|
<a href=/people/d/dong-yu/>Dong Yu</a>
|
<a href=/people/j/jian-xu/>Jian Xu</a>
|
<a href=/people/c/chunhua-liu/>Chunhua Liu</a><br><a href=/volumes/S17-1/ class=text-muted>Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-1010><div class="card-body p-3 small">This paper explores the automatic learning of <a href=https://en.wikipedia.org/wiki/Distributed_representation>distributed representations</a> of the target&#8217;s context for semantic frame labeling with target-based neural model. We constrain the whole sentence as the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>&#8217;s input without <a href=https://en.wikipedia.org/wiki/Feature_extraction>feature extraction</a> from the sentence. This is different from many previous works in which local feature extraction of the targets is widely used. This constraint makes the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> harder, especially with long sentences, but also makes our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> easily applicable to a range of resources and other similar tasks. We evaluate our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on several resources and get the state-of-the-art result on subtask 2 of SemEval 2015 task 15. Finally, we extend the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> to word-sense disambiguation task and we also achieve a strong result in comparison to state-of-the-art work.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Chunhua+Liu" title="Search for 'Chunhua Liu' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/d/dong-yu/ class=align-middle>Dong Yu</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/t/trevor-cohn/ class=align-middle>Trevor Cohn</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lea-frermann/ class=align-middle>Lea Frermann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yukun-feng/ class=align-middle>Yukun Feng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jian-xu/ class=align-middle>Jian Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/r/ruoyao-yang/ class=align-middle>Ruoyao Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wanying-xie/ class=align-middle>Wanying Xie</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/meiqian-zhao/ class=align-middle>Meiqian Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lu-liu/ class=align-middle>Lu Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yan-zhao/ class=align-middle>Yan Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>