<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Chen Li - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Chen</span> <span class=font-weight-bold>Li</span></h2><hr><div class=row><div class=col-lg-9><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.aacl-main.61.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--aacl-main--61 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.aacl-main.61 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.aacl-main.61" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.aacl-main.61/>Generating Sports News from Live Commentary : A Chinese Dataset for Sports Game Summarization<span class=acl-fixed-case>C</span>hinese Dataset for Sports Game Summarization</a></strong><br><a href=/people/k/kuan-hao-huang/>Kuan-Hao Huang</a>
|
<a href=/people/c/chen-li/>Chen Li</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a><br><a href=/volumes/2020.aacl-main/ class=text-muted>Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--aacl-main--61><div class="card-body p-3 small">Sports game summarization focuses on generating news articles from <a href=https://en.wikipedia.org/wiki/Sports_commentator>live commentaries</a>. Unlike traditional summarization tasks, the source documents and the target summaries for sports game summarization tasks are written in quite different writing styles. In addition, live commentaries usually contain many <a href=https://en.wikipedia.org/wiki/Named_entity>named entities</a>, which makes summarizing sports games precisely very challenging. To deeply study this task, we present SportsSum, a Chinese sports game summarization dataset which contains 5,428 soccer games of live commentaries and the corresponding <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>. Additionally, we propose a two-step summarization model consisting of a selector and a rewriter for SportsSum. To evaluate the correctness of generated sports summaries, we design two novel score metrics : name matching score and event matching score. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performs better than other summarization baselines on ROUGE scores as well as the two designed scores.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.431.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--431 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.431 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.431/>Understanding User Resistance Strategies in Persuasive Conversations</a></strong><br><a href=/people/y/youzhi-tian/>Youzhi Tian</a>
|
<a href=/people/w/weiyan-shi/>Weiyan Shi</a>
|
<a href=/people/c/chen-li/>Chen Li</a>
|
<a href=/people/z/zhou-yu/>Zhou Yu</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--431><div class="card-body p-3 small">Persuasive dialog systems have various usages, such as donation persuasion and physical exercise persuasion. Previous persuasive dialog systems research mostly focused on analyzing the persuader&#8217;s strategies and paid little attention to the persuadee (user). However, understanding and addressing users&#8217; resistance strategies is an essential job of a persuasive dialog system. So, we adopt a preliminary framework on persuasion resistance in <a href=https://en.wikipedia.org/wiki/Psychology>psychology</a> and design a fine-grained resistance strategy annotation scheme. We annotate the PersuasionForGood dataset with the <a href=https://en.wikipedia.org/wiki/Scheme_(mathematics)>scheme</a>. With the enriched annotations, we build a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> to predict the resistance strategies. Furthermore, we analyze the relationships between <a href=https://en.wikipedia.org/wiki/Persuasion>persuasion strategies</a> and persuasion resistance strategies. Our work lays the ground for developing a persuasive dialogue system that can understand and address user resistance strategy appropriately. The code and data will be released.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3201.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3201 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3201 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3201/>Extracting Kinship from Obituary to Enhance Electronic Health Records for Genetic Research</a></strong><br><a href=/people/k/kai-he/>Kai He</a>
|
<a href=/people/j/jialun-wu/>Jialun Wu</a>
|
<a href=/people/x/xiaoyong-ma/>Xiaoyong Ma</a>
|
<a href=/people/c/chong-zhang/>Chong Zhang</a>
|
<a href=/people/m/ming-huang/>Ming Huang</a>
|
<a href=/people/c/chen-li/>Chen Li</a>
|
<a href=/people/l/lixia-yao/>Lixia Yao</a><br><a href=/volumes/W19-32/ class=text-muted>Proceedings of the Fourth Social Media Mining for Health Applications (#SMM4H) Workshop & Shared Task</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3201><div class="card-body p-3 small">Claims database and electronic health records database do not usually capture kinship or family relationship information, which is imperative for <a href=https://en.wikipedia.org/wiki/Genetic_research>genetic research</a>. We identify online obituaries as a new data source and propose a special named entity recognition and relation extraction solution to extract names and kinships from online obituaries. Built on 1,809 annotated obituaries and a novel tagging scheme, our joint neural model achieved macro-averaged precision, <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a> and <a href=https://en.wikipedia.org/wiki/F-number>F measure</a> of 72.69 %, 78.54 % and 74.93 %, and micro-averaged precision, <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a> and <a href=https://en.wikipedia.org/wiki/F-number>F measure</a> of 95.74 %, 98.25 % and 96.98 % using 57 <a href=https://en.wikipedia.org/wiki/Kinship>kinships</a> with 10 or more examples in a 10-fold cross-validation experiment. The <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> performance improved dramatically when trained with 34 <a href=https://en.wikipedia.org/wiki/Kinship>kinships</a> with 50 or more examples. Leveraging additional information such as age, death date, birth date and residence mentioned by obituaries, we foresee a promising future of supplementing EHR databases with comprehensive and accurate kinship information for genetic research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1212.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1212 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1212 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1212/>BIGPATENT : A Large-Scale Dataset for Abstractive and Coherent Summarization<span class=acl-fixed-case>BIGPATENT</span>: A Large-Scale Dataset for Abstractive and Coherent Summarization</a></strong><br><a href=/people/e/eva-sharma/>Eva Sharma</a>
|
<a href=/people/c/chen-li/>Chen Li</a>
|
<a href=/people/l/lu-wang/>Lu Wang</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1212><div class="card-body p-3 small">Most existing text summarization datasets are compiled from the <a href=https://en.wikipedia.org/wiki/News_media>news domain</a>, where summaries have a flattened discourse structure. In such <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, summary-worthy content often appears in the beginning of input articles. Moreover, large segments from input articles are present verbatim in their respective summaries. These issues impede the learning and evaluation of systems that can understand an article&#8217;s global content structure as well as produce abstractive summaries with high <a href=https://en.wikipedia.org/wiki/Compression_ratio>compression ratio</a>. In this work, we present a novel <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, BIGPATENT, consisting of 1.3 million records of <a href=https://en.wikipedia.org/wiki/United_States_patent_law>U.S. patent documents</a> along with <a href=https://en.wikipedia.org/wiki/Abstract_(summary)>human written abstractive summaries</a>. Compared to existing summarization datasets, BIGPATENT has the following properties : i) summaries contain a richer discourse structure with more recurring entities, ii) salient content is evenly distributed in the input, and iii) lesser and shorter extractive fragments are present in the summaries. Finally, we train and evaluate baselines and popular learning models on BIGPATENT to shed light on new challenges and motivate future directions for summarization research.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1114.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1114 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1114 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1114/>DM_NLP at SemEval-2018 Task 8 : neural sequence labeling with linguistic features<span class=acl-fixed-case>DM</span>_<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 8: neural sequence labeling with linguistic features</a></strong><br><a href=/people/c/chunping-ma/>Chunping Ma</a>
|
<a href=/people/h/huafei-zheng/>Huafei Zheng</a>
|
<a href=/people/p/pengjun-xie/>Pengjun Xie</a>
|
<a href=/people/c/chen-li/>Chen Li</a>
|
<a href=/people/l/linlin-li/>Linlin Li</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1114><div class="card-body p-3 small">This paper describes our submissions for SemEval-2018 Task 8 : Semantic Extraction from CybersecUrity REports using <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. The DM_NLP participated in two subtasks : SubTask 1 classifies if a sentence is useful for inferring malware actions and capabilities, and SubTask 2 predicts token labels (Action, Entity, Modifier and Others) for a given malware-related sentence. Since we leverage results of Subtask 2 directly to infer the result of Subtask 1, the paper focus on the system solving Subtask 2. By taking Subtask 2 as a sequence labeling task, our system relies on a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network</a> named BiLSTM-CNN-CRF with rich linguistic features, such as POS tags, dependency parsing labels, chunking labels, NER labels, Brown clustering. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieved the highest F1 score in both token level and phrase level.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3708.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3708 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3708 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3708/>A Hybrid System for Chinese Grammatical Error Diagnosis and Correction<span class=acl-fixed-case>C</span>hinese Grammatical Error Diagnosis and Correction</a></strong><br><a href=/people/c/chen-li/>Chen Li</a>
|
<a href=/people/j/junpei-zhou/>Junpei Zhou</a>
|
<a href=/people/z/zuyi-bao/>Zuyi Bao</a>
|
<a href=/people/h/hengyou-liu/>Hengyou Liu</a>
|
<a href=/people/g/guangwei-xu/>Guangwei Xu</a>
|
<a href=/people/l/linlin-li/>Linlin Li</a><br><a href=/volumes/W18-37/ class=text-muted>Proceedings of the 5th Workshop on Natural Language Processing Techniques for Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3708><div class="card-body p-3 small">This paper introduces the DM_NLP team&#8217;s system for NLPTEA 2018 shared task of <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese Grammatical Error Diagnosis (CGED)</a>, which can be used to detect and correct grammatical errors in texts written by <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a> as a Foreign Language (CFL) learners. This task aims at not only detecting four types of grammatical errors including redundant words (R), missing words (M), bad word selection (S) and disordered words (W), but also recommending corrections for errors of M and S types. We proposed a <a href=https://en.wikipedia.org/wiki/Hybrid_system>hybrid system</a> including four <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> for this task with two stages : the detection stage and the correction stage. In the detection stage, we first used a BiLSTM-CRF model to tag potential errors by <a href=https://en.wikipedia.org/wiki/Sequence_labeling>sequence labeling</a>, along with some handcraft features. Then we designed three Grammatical Error Correction (GEC) models to generate corrections, which could help to tune the detection result. In the correction stage, candidates were generated by the three GEC models and then merged to output the final corrections for M and S types. Our system reached the highest <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> in the correction subtask, which was the most challenging part of this shared task, and got top 3 on F1 scores for position detection of errors.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2122.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2122 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2122 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2122/>XJSA at SemEval-2017 Task 4 : A Deep System for Sentiment Classification in Twitter<span class=acl-fixed-case>XJSA</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 4: A Deep System for Sentiment Classification in <span class=acl-fixed-case>T</span>witter</a></strong><br><a href=/people/y/yazhou-hao/>Yazhou Hao</a>
|
<a href=/people/y/yangyang-lan/>YangYang Lan</a>
|
<a href=/people/y/yufei-li/>Yufei Li</a>
|
<a href=/people/c/chen-li/>Chen Li</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2122><div class="card-body p-3 small">This paper describes the XJSA System submission from XJTU. Our <a href=https://en.wikipedia.org/wiki/System>system</a> was created for SemEval2017 Task 4 subtask A which is very popular and fundamental. The <a href=https://en.wikipedia.org/wiki/System>system</a> is based on <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural network</a> and <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a>. We used two pre-trained word vectors and adopt a dynamic strategy for k-max pooling.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2178.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2178 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2178 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2178/>XJNLP at SemEval-2017 Task 12 : Clinical temporal information ex-traction with a Hybrid Model<span class=acl-fixed-case>XJNLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 12: Clinical temporal information ex-traction with a Hybrid Model</a></strong><br><a href=/people/y/yu-long/>Yu Long</a>
|
<a href=/people/z/zhijing-li/>Zhijing Li</a>
|
<a href=/people/x/xuan-wang/>Xuan Wang</a>
|
<a href=/people/c/chen-li/>Chen Li</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2178><div class="card-body p-3 small">Temporality is crucial in understanding the course of clinical events from a patient&#8217;s electronic health recordsand temporal processing is becoming more and more important for improving access to content. SemEval 2017 Task 12 (Clinical TempEval) addressed this challenge using the THYME corpus, a corpus of clinical narratives annotated with a schema based on TimeML2 guidelines. We developed and evaluated approaches for : extraction of temporal expressions (TIMEX3) and EVENTs ; EVENT attributes ; document-time relations. Our approach is a hybrid model which is based on rule based methods, <a href=https://en.wikipedia.org/wiki/Semi-supervised_learning>semi-supervised learning</a>, and semantic features with addition of manually crafted rules.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Chen+Li" title="Search for 'Chen Li' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/l/linlin-li/ class=align-middle>Linlin Li</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/kuan-hao-huang/ class=align-middle>Kuan-Hao Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kai-wei-chang/ class=align-middle>Kai-Wei Chang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yazhou-hao/ class=align-middle>Yazhou Hao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yangyang-lan/ class=align-middle>YangYang Lan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/y/yufei-li/ class=align-middle>Yufei Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yu-long/ class=align-middle>Yu Long</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhijing-li/ class=align-middle>Zhijing Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xuan-wang/ class=align-middle>Xuan Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/youzhi-tian/ class=align-middle>Youzhi Tian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/weiyan-shi/ class=align-middle>Weiyan Shi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhou-yu/ class=align-middle>Zhou Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chunping-ma/ class=align-middle>Chunping Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/huafei-zheng/ class=align-middle>Huafei Zheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pengjun-xie/ class=align-middle>Pengjun Xie</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luo-si/ class=align-middle>Luo Si</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/junpei-zhou/ class=align-middle>Junpei Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zuyi-bao/ class=align-middle>Zuyi Bao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hengyou-liu/ class=align-middle>Hengyou Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/guangwei-xu/ class=align-middle>Guangwei Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kai-he/ class=align-middle>Kai He</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jialun-wu/ class=align-middle>Jialun Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaoyong-ma/ class=align-middle>Xiaoyong Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chong-zhang/ class=align-middle>Chong Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/ming-huang/ class=align-middle>Ming Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lixia-yao/ class=align-middle>Lixia Yao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eva-sharma/ class=align-middle>Eva Sharma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lu-wang/ class=align-middle>Lu Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/aacl/ class=align-middle>AACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>