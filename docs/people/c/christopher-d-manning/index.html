<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Christopher D. Manning - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Christopher D.</span> <span class=font-weight-bold>Manning</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Christopher <span class=font-weight-normal>Manning</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.sigdial-1.58.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--sigdial-1--58 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.sigdial-1.58 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href="https://www.youtube.com/watch?v=FLsqwyGx4zM" data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.sigdial-1.58" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.sigdial-1.58/>Large-Scale Quantitative Evaluation of Dialogue Agents’ Response Strategies against Offensive Users</a></strong><br><a href=/people/h/haojun-li/>Haojun Li</a>
|
<a href=/people/d/dilara-soylu/>Dilara Soylu</a>
|
<a href=/people/c/christopher-d-manning/>Christopher Manning</a><br><a href=/volumes/2021.sigdial-1/ class=text-muted>Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--sigdial-1--58><div class="card-body p-3 small">As voice assistants and dialogue agents grow in popularity, so does the abuse they receive. We conducted a large-scale quantitative evaluation of the effectiveness of 4 response types (avoidance, why, empathetic, and counter), and 2 additional factors (using a redirect or a voluntarily provided name) that have not been tested by prior work. We measured their direct effectiveness on real users in-the-wild by the re-offense ratio, length of conversation after the initial response, and number of turns until the next re-offense. Our experiments confirm prior lab studies in showing that <a href=https://en.wikipedia.org/wiki/Empathy>empathetic responses</a> perform better than generic avoidance responses as well as counter responses. We show that dialogue agents should almost always guide offensive users to a new topic through the use of redirects and use the user&#8217;s name if provided. As compared to a baseline avoidance strategy employed by commercial agents, our best <a href=https://en.wikipedia.org/wiki/Strategy>strategy</a> is able to reduce the re-offense ratio from 92 % to 43 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.88.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--88 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.88 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.88/>DReCa : A General Task Augmentation Strategy for Few-Shot Natural Language Inference<span class=acl-fixed-case>DR</span>e<span class=acl-fixed-case>C</span>a: A General Task Augmentation Strategy for Few-Shot Natural Language Inference</a></strong><br><a href=/people/s/shikhar-murty/>Shikhar Murty</a>
|
<a href=/people/t/tatsunori-b-hashimoto/>Tatsunori B. Hashimoto</a>
|
<a href=/people/c/christopher-d-manning/>Christopher Manning</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--88><div class="card-body p-3 small">Meta-learning promises few-shot learners that can adapt to new distributions by repurposing knowledge acquired from previous training. However, we believe <a href=https://en.wikipedia.org/wiki/Meta-learning>meta-learning</a> has not yet succeeded in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> due to the lack of a well-defined task distribution, leading to attempts that treat datasets as tasks. Such an ad hoc task distribution causes problems of quantity and quality. Since there&#8217;s only a handful of datasets for any NLP problem, meta-learners tend to overfit their adaptation mechanism and, since NLP datasets are highly heterogeneous, many learning episodes have poor transfer between their support and query sets, which discourages the meta-learner from adapting. To alleviate these issues, we propose DReCA (Decomposing datasets into Reasoning Categories), a simple method for discovering and using latent reasoning categories in a dataset, to form additional high quality tasks. DReCA works by splitting examples into label groups, embedding them with a finetuned BERT model and then clustering each group into reasoning categories. Across four few-shot NLI problems, we demonstrate that using DReCA improves the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of <a href=https://en.wikipedia.org/wiki/Meta-learning>meta-learners</a> by 1.5-4 %</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.493.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--493 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.493 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929418 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.493" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.493/>Finding <a href=https://en.wikipedia.org/wiki/Universal_grammar>Universal Grammatical Relations</a> in Multilingual BERT<span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/e/ethan-a-chi/>Ethan A. Chi</a>
|
<a href=/people/j/john-hewitt/>John Hewitt</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--493><div class="card-body p-3 small">Recent work has found evidence that Multilingual BERT (mBERT), a transformer-based multilingual masked language model, is capable of zero-shot cross-lingual transfer, suggesting that some aspects of its representations are shared cross-lingually. To better understand this overlap, we extend recent work on finding syntactic trees in neural networks&#8217; internal representations to the multilingual setting. We show that subspaces of mBERT representations recover syntactic tree distances in languages other than English, and that these <a href=https://en.wikipedia.org/wiki/Linear_subspace>subspaces</a> are approximately shared across languages. Motivated by these results, we present an unsupervised analysis method that provides evidence mBERT learns representations of syntactic dependency labels, in the form of clusters which largely agree with the Universal Dependencies taxonomy. This evidence suggests that even without explicit <a href=https://en.wikipedia.org/wiki/Supervisor>supervision</a>, multilingual masked language models learn certain <a href=https://en.wikipedia.org/wiki/Linguistic_universal>linguistic universals</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928620 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-demos.14" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.14/>Stanza : A Python Natural Language Processing Toolkit for Many Human Languages<span class=acl-fixed-case>S</span>tanza: A Python Natural Language Processing Toolkit for Many Human Languages</a></strong><br><a href=/people/p/peng-qi/>Peng Qi</a>
|
<a href=/people/y/yuhao-zhang/>Yuhao Zhang</a>
|
<a href=/people/y/yuhui-zhang/>Yuhui Zhang</a>
|
<a href=/people/j/jason-bolton/>Jason Bolton</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a><br><a href=/volumes/2020.acl-demos/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--14><div class="card-body p-3 small">We introduce Stanza, an open-source Python natural language processing toolkit supporting 66 human languages. Compared to existing widely used toolkits, Stanza features a language-agnostic fully neural pipeline for text analysis, including <a href=https://en.wikipedia.org/wiki/Lexical_analysis>tokenization</a>, multi-word token expansion, <a href=https://en.wikipedia.org/wiki/Lemmatization>lemmatization</a>, part-of-speech and morphological feature tagging, dependency parsing, and <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>. We have trained Stanza on a total of 112 datasets, including the Universal Dependencies treebanks and other multilingual corpora, and show that the same neural architecture generalizes well and achieves competitive performance on all languages tested. Additionally, Stanza includes a native Python interface to the widely used Java Stanford CoreNLP software, which further extends its functionality to cover other tasks such as <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> and <a href=https://en.wikipedia.org/wiki/Relation_extraction>relation extraction</a>. Source code, documentation, and pretrained models for 66 languages are available at https://stanfordnlp.github.io/stanza/.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1419.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1419 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1419 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/361827125 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1419" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-1419/>A Structural Probe for Finding Syntax in Word Representations<span class=acl-fixed-case>A</span> Structural Probe for Finding Syntax in Word Representations</a></strong><br><a href=/people/j/john-hewitt/>John Hewitt</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1419><div class="card-body p-3 small">Recent work has improved our ability to detect linguistic knowledge in <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>word representations</a>. However, current methods for detecting syntactic knowledge do not test whether <a href=https://en.wikipedia.org/wiki/Syntax_tree>syntax trees</a> are represented in their entirety. In this work, we propose a structural probe, which evaluates whether syntax trees are embedded in a <a href=https://en.wikipedia.org/wiki/Linear_map>linear transformation</a> of a neural network&#8217;s word representation space. The probe identifies a <a href=https://en.wikipedia.org/wiki/Linear_map>linear transformation</a> under which squared L2 distance encodes the distance between words in the <a href=https://en.wikipedia.org/wiki/Parse_tree>parse tree</a>, and one in which squared L2 norm encodes depth in the <a href=https://en.wikipedia.org/wiki/Parse_tree>parse tree</a>. Using our probe, we show that such transformations exist for both ELMo and BERT but not in baselines, providing evidence that entire syntax trees are embedded implicitly in deep models&#8217; vector geometry.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1244.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1244 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1244 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D18-1244.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1244" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D18-1244/>Graph Convolution over Pruned Dependency Trees Improves Relation Extraction</a></strong><br><a href=/people/y/yuhao-zhang/>Yuhao Zhang</a>
|
<a href=/people/p/peng-qi/>Peng Qi</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1244><div class="card-body p-3 small">Dependency trees help relation extraction models capture long-range relations between words. However, existing dependency-based models either neglect crucial information (e.g., negation) by pruning the dependency trees too aggressively, or are computationally inefficient because it is difficult to parallelize over different <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>tree structures</a>. We propose an extension of graph convolutional networks that is tailored for <a href=https://en.wikipedia.org/wiki/Relation_extraction>relation extraction</a>, which pools information over arbitrary dependency structures efficiently in parallel. To incorporate relevant information while maximally removing irrelevant content, we further apply a novel pruning strategy to the input <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>trees</a> by keeping words immediately around the shortest path between the two entities among which a relation might hold. The resulting <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves state-of-the-art performance on the large-scale TACRED dataset, outperforming existing sequence and dependency-based neural models. We also show through detailed analysis that this <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> has complementary strengths to sequence models, and combining them further improves the state of the art.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-2077.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-2077 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-2077 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285804230 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-2077" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-2077/>Simpler but More Accurate Semantic Dependency Parsing</a></strong><br><a href=/people/t/timothy-dozat/>Timothy Dozat</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a><br><a href=/volumes/P18-2/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-2077><div class="card-body p-3 small">While syntactic dependency annotations concentrate on the surface or functional structure of a sentence, semantic dependency annotations aim to capture between-word relationships that are more closely related to the meaning of a sentence, using graph-structured representations. We extend the LSTM-based syntactic parser of Dozat and Manning (2017) to train on and generate these graph structures. The resulting <a href=https://en.wikipedia.org/wiki/System>system</a> on its own achieves state-of-the-art performance, beating the previous, substantially more complex state-of-the-art system by 0.6 % labeled F1. Adding linguistically richer input representations pushes the margin even higher, allowing us to beat it by 1.9 % labeled F1.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3001 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3001/>CoNLL 2017 Shared Task : Multilingual Parsing from Raw Text to Universal Dependencies<span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NLL</span> 2017 Shared Task: Multilingual Parsing from Raw Text to <span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependencies</a></strong><br><a href=/people/d/daniel-zeman/>Daniel Zeman</a>
|
<a href=/people/m/martin-popel/>Martin Popel</a>
|
<a href=/people/m/milan-straka/>Milan Straka</a>
|
<a href=/people/j/jan-hajic/>Jan Hajič</a>
|
<a href=/people/j/joakim-nivre/>Joakim Nivre</a>
|
<a href=/people/f/filip-ginter/>Filip Ginter</a>
|
<a href=/people/j/juhani-luotolahti/>Juhani Luotolahti</a>
|
<a href=/people/s/sampo-pyysalo/>Sampo Pyysalo</a>
|
<a href=/people/s/slav-petrov/>Slav Petrov</a>
|
<a href=/people/m/martin-potthast/>Martin Potthast</a>
|
<a href=/people/f/francis-tyers/>Francis Tyers</a>
|
<a href=/people/e/elena-badmaeva/>Elena Badmaeva</a>
|
<a href=/people/m/memduh-gokirmak/>Memduh Gokirmak</a>
|
<a href=/people/a/anna-nedoluzhko/>Anna Nedoluzhko</a>
|
<a href=/people/s/silvie-cinkova/>Silvie Cinková</a>
|
<a href=/people/j/jan-hajic-jr/>Jan Hajič jr.</a>
|
<a href=/people/j/jaroslava-hlavacova/>Jaroslava Hlaváčová</a>
|
<a href=/people/v/vaclava-kettnerova/>Václava Kettnerová</a>
|
<a href=/people/z/zdenka-uresova/>Zdeňka Urešová</a>
|
<a href=/people/j/jenna-kanerva/>Jenna Kanerva</a>
|
<a href=/people/s/stina-ojala/>Stina Ojala</a>
|
<a href=/people/a/anna-missila/>Anna Missilä</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a>
|
<a href=/people/s/sebastian-schuster/>Sebastian Schuster</a>
|
<a href=/people/s/siva-reddy/>Siva Reddy</a>
|
<a href=/people/d/dima-taji/>Dima Taji</a>
|
<a href=/people/n/nizar-habash/>Nizar Habash</a>
|
<a href=/people/h/herman-leung/>Herman Leung</a>
|
<a href=/people/m/marie-catherine-de-marneffe/>Marie-Catherine de Marneffe</a>
|
<a href=/people/m/manuela-sanguinetti/>Manuela Sanguinetti</a>
|
<a href=/people/m/maria-simi/>Maria Simi</a>
|
<a href=/people/h/hiroshi-kanayama/>Hiroshi Kanayama</a>
|
<a href=/people/v/valeria-de-paiva/>Valeria de Paiva</a>
|
<a href=/people/k/kira-droganova/>Kira Droganova</a>
|
<a href=/people/h/hector-martinez-alonso/>Héctor Martínez Alonso</a>
|
<a href=/people/c/cagri-coltekin/>Çağrı Çöltekin</a>
|
<a href=/people/u/umut-sulubacak/>Umut Sulubacak</a>
|
<a href=/people/h/hans-uszkoreit/>Hans Uszkoreit</a>
|
<a href=/people/v/vivien-macketanz/>Vivien Macketanz</a>
|
<a href=/people/a/aljoscha-burchardt/>Aljoscha Burchardt</a>
|
<a href=/people/k/kim-harris/>Kim Harris</a>
|
<a href=/people/k/katrin-marheinecke/>Katrin Marheinecke</a>
|
<a href=/people/g/georg-rehm/>Georg Rehm</a>
|
<a href=/people/t/tolga-kayadelen/>Tolga Kayadelen</a>
|
<a href=/people/m/mohammed-attia/>Mohammed Attia</a>
|
<a href=/people/a/ali-elkahky/>Ali Elkahky</a>
|
<a href=/people/z/zhuoran-yu/>Zhuoran Yu</a>
|
<a href=/people/e/emily-pitler/>Emily Pitler</a>
|
<a href=/people/s/saran-lertpradit/>Saran Lertpradit</a>
|
<a href=/people/m/michael-mandel/>Michael Mandl</a>
|
<a href=/people/j/jesse-kirchner/>Jesse Kirchner</a>
|
<a href=/people/h/hector-fernandez-alcalde/>Hector Fernandez Alcalde</a>
|
<a href=/people/j/jana-strnadova/>Jana Strnadová</a>
|
<a href=/people/e/esha-banerjee/>Esha Banerjee</a>
|
<a href=/people/r/ruli-manurung/>Ruli Manurung</a>
|
<a href=/people/a/antonio-stella/>Antonio Stella</a>
|
<a href=/people/a/atsuko-shimada/>Atsuko Shimada</a>
|
<a href=/people/s/sookyoung-kwak/>Sookyoung Kwak</a>
|
<a href=/people/g/gustavo-mendonca/>Gustavo Mendonça</a>
|
<a href=/people/t/tatiana-lando/>Tatiana Lando</a>
|
<a href=/people/r/rattima-nitisaroj/>Rattima Nitisaroj</a>
|
<a href=/people/j/josie-li/>Josie Li</a><br><a href=/volumes/K17-3/ class=text-muted>Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3001><div class="card-body p-3 small">The Conference on Computational Natural Language Learning (CoNLL) features a shared task, in which participants train and test their <a href=https://en.wikipedia.org/wiki/Machine_learning>learning systems</a> on the same data sets. In 2017, the task was devoted to learning dependency parsers for a large number of languages, in a real-world setting without any gold-standard annotation on input. All <a href=https://en.wikipedia.org/wiki/Test_set>test sets</a> followed a unified annotation scheme, namely that of Universal Dependencies. In this paper, we define the task and evaluation methodology, describe how the data sets were prepared, report and analyze the main results, and provide a brief categorization of the different approaches of the participating systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3002 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3002/>Stanford’s Graph-based Neural Dependency Parser at the CoNLL 2017 Shared Task<span class=acl-fixed-case>S</span>tanford’s Graph-based Neural Dependency Parser at the <span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NLL</span> 2017 Shared Task</a></strong><br><a href=/people/t/timothy-dozat/>Timothy Dozat</a>
|
<a href=/people/p/peng-qi/>Peng Qi</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a><br><a href=/volumes/K17-3/ class=text-muted>Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3002><div class="card-body p-3 small">This paper describes the neural dependency parser submitted by Stanford to the CoNLL 2017 Shared Task on parsing Universal Dependencies. Our system uses relatively simple LSTM networks to produce <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part of speech tags</a> and labeled dependency parses from segmented and tokenized sequences of words. In order to address the rare word problem that abounds in languages with complex morphology, we include a character-based word representation that uses an LSTM to produce embeddings from sequences of characters. Our <a href=https://en.wikipedia.org/wiki/System>system</a> was ranked first according to all five relevant <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> for the <a href=https://en.wikipedia.org/wiki/System>system</a> : UPOS tagging (93.09 %), XPOS tagging (82.27 %), unlabeled attachment score (81.30 %), labeled attachment score (76.30 %), and content word labeled attachment score (72.57 %).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1086.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1086 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1086 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234958455 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P17-1086" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1086/>Naturalizing a <a href=https://en.wikipedia.org/wiki/Programming_language>Programming Language</a> via Interactive Learning</a></strong><br><a href=/people/s/sida-i-wang/>Sida I. Wang</a>
|
<a href=/people/s/samuel-ginn/>Samuel Ginn</a>
|
<a href=/people/p/percy-liang/>Percy Liang</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1086><div class="card-body p-3 small">Our goal is to create a convenient <a href=https://en.wikipedia.org/wiki/Natural-language_user_interface>natural language interface</a> for performing well-specified but complex actions such as <a href=https://en.wikipedia.org/wiki/Data_analysis>analyzing data</a>, manipulating text, and <a href=https://en.wikipedia.org/wiki/Database_query>querying databases</a>. However, existing <a href=https://en.wikipedia.org/wiki/Interface_(computing)>natural language interfaces</a> for such <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a> are quite primitive compared to the power one wields with a <a href=https://en.wikipedia.org/wiki/Programming_language>programming language</a>. To bridge this gap, we start with a core programming language and allow users to naturalize the core language incrementally by defining alternative, more natural syntax and increasingly complex concepts in terms of compositions of simpler ones. In a voxel world, we show that a community of users can simultaneously teach a common system a diverse language and use it to build hundreds of complex voxel structures. Over the course of three days, these users went from using only the core language to using the <a href=https://en.wikipedia.org/wiki/Natural_language>naturalized language</a> in 85.9 % of the last 10 K utterances.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1099.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1099 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1099 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-1099.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-1099.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234956256 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P17-1099" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1099/>Get To The Point : <a href=https://en.wikipedia.org/wiki/Summarization>Summarization</a> with Pointer-Generator Networks</a></strong><br><a href=/people/a/abigail-see/>Abigail See</a>
|
<a href=/people/p/peter-j-liu/>Peter J. Liu</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1099><div class="card-body p-3 small">Neural sequence-to-sequence models have provided a viable new approach for abstractive text summarization (meaning they are not restricted to simply selecting and rearranging passages from the original text). However, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> have two shortcomings : they are liable to reproduce factual details inaccurately, and they tend to repeat themselves. In this work we propose a novel architecture that augments the standard sequence-to-sequence attentional model in two orthogonal ways. First, we use a hybrid pointer-generator network that can copy words from the source text via <a href=https://en.wikipedia.org/wiki/Pointing_device>pointing</a>, which aids accurate reproduction of information, while retaining the ability to produce novel words through the generator. Second, we use <a href=https://en.wikipedia.org/wiki/Coverage_(telecommunication)>coverage</a> to keep track of what has been summarized, which discourages <a href=https://en.wikipedia.org/wiki/Repetition_(rhetorical_device)>repetition</a>. We apply our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to the CNN / Daily Mail summarization task, outperforming the current abstractive state-of-the-art by at least 2 ROUGE points.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2018.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2018 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2018 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234957642 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P17-2018" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-2018/>Arc-swift : A Novel Transition System for Dependency Parsing</a></strong><br><a href=/people/p/peng-qi/>Peng Qi</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2018><div class="card-body p-3 small">Transition-based dependency parsers often need sequences of local shift and reduce operations to produce certain attachments. Correct individual decisions hence require global information about the sentence context and mistakes cause <a href=https://en.wikipedia.org/wiki/Error_propagation>error propagation</a>. This paper proposes a novel <a href=https://en.wikipedia.org/wiki/Transition_(computer_science)>transition system</a>, arc-swift, that enables direct attachments between tokens farther apart with a single <a href=https://en.wikipedia.org/wiki/Transition_(computer_science)>transition</a>. This allows the <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> to leverage <a href=https://en.wikipedia.org/wiki/Lexical_analysis>lexical information</a> more directly in transition decisions. Hence, arc-swift can achieve significantly better performance with a very small <a href=https://en.wikipedia.org/wiki/Beam_diameter>beam size</a>. Our <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a> reduce error by 3.77.6 % relative to those using existing transition systems on the Penn Treebank dependency parsing task and English Universal Dependencies.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5506.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5506 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5506 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-5506" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-5506/>Key-Value Retrieval Networks for Task-Oriented Dialogue</a></strong><br><a href=/people/m/mihail-eric/>Mihail Eric</a>
|
<a href=/people/l/lakshmi-krishnan/>Lakshmi Krishnan</a>
|
<a href=/people/f/francois-charette/>Francois Charette</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a><br><a href=/volumes/W17-55/ class=text-muted>Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5506><div class="card-body p-3 small">Neural task-oriented dialogue systems often struggle to smoothly interface with a <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base</a>. In this work, we seek to address this problem by proposing a new neural dialogue agent that is able to effectively sustain grounded, multi-domain discourse through a novel key-value retrieval mechanism. The <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is end-to-end differentiable and does not need to explicitly model dialogue state or belief trackers. We also release a new dataset of 3,031 dialogues that are grounded through underlying knowledge bases and span three distinct tasks in the in-car personal assistant space : <a href=https://en.wikipedia.org/wiki/Calendaring_software>calendar scheduling</a>, <a href=https://en.wikipedia.org/wiki/Weather_forecasting>weather information retrieval</a>, and point-of-interest navigation. Our architecture is simultaneously trained on data from all domains and significantly outperforms a competitive rule-based system and other existing neural dialogue architectures on the provided domains according to both automatic and human evaluation metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1109.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1109 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1109 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238233745 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1109/>Importance sampling for unbiased on-demand evaluation of knowledge base population</a></strong><br><a href=/people/a/arun-chaganty/>Arun Chaganty</a>
|
<a href=/people/a/ashwin-paranjape/>Ashwin Paranjape</a>
|
<a href=/people/p/percy-liang/>Percy Liang</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1109><div class="card-body p-3 small">Knowledge base population (KBP) systems take in a large document corpus and extract entities and their relations. Thus far, KBP evaluation has relied on judgements on the pooled predictions of existing systems. We show that this <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a> is problematic : when a new system predicts a previously unseen relation, it is penalized even if it is correct. This leads to significant bias against new systems, which counterproductively discourages innovation in the field. Our first contribution is a new importance-sampling based evaluation which corrects for this bias by annotating a new system&#8217;s predictions on-demand via <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a>. We show this eliminates bias and reduces variance using data from the 2015 TAC KBP task. Our second contribution is an implementation of our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> made publicly available as an online KBP evaluation service. We pilot the service by testing diverse state-of-the-art systems on the TAC KBP 2016 corpus and obtain accurate scores in a cost effective manner.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Christopher+D.+Manning" title="Search for 'Christopher D. Manning' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/p/peng-qi/ class=align-middle>Peng Qi</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/j/john-hewitt/ class=align-middle>John Hewitt</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yuhao-zhang/ class=align-middle>Yuhao Zhang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/timothy-dozat/ class=align-middle>Timothy Dozat</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/percy-liang/ class=align-middle>Percy Liang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/k/kaustubh-dhole/ class=align-middle>Kaustubh Dhole</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/ethan-a-chi/ class=align-middle>Ethan A. Chi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yuhui-zhang/ class=align-middle>Yuhui Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jason-bolton/ class=align-middle>Jason Bolton</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/daniel-zeman/ class=align-middle>Daniel Zeman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/martin-popel/ class=align-middle>Martin Popel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/milan-straka/ class=align-middle>Milan Straka</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jan-hajic/ class=align-middle>Jan Hajic</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joakim-nivre/ class=align-middle>Joakim Nivre</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/filip-ginter/ class=align-middle>Filip Ginter</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/juhani-luotolahti/ class=align-middle>Juhani Luotolahti</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sampo-pyysalo/ class=align-middle>Sampo Pyysalo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/slav-petrov/ class=align-middle>Slav Petrov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/martin-potthast/ class=align-middle>Martin Potthast</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/francis-tyers/ class=align-middle>Francis Tyers</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elena-badmaeva/ class=align-middle>Elena Badmaeva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/memduh-gokirmak/ class=align-middle>Memduh Gökırmak</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anna-nedoluzhko/ class=align-middle>Anna Nedoluzhko</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/silvie-cinkova/ class=align-middle>Silvie Cinková</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jan-hajic-jr/ class=align-middle>Jan Hajič jr.</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jaroslava-hlavacova/ class=align-middle>Jaroslava Hlaváčová</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vaclava-kettnerova/ class=align-middle>Václava Kettnerová</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zdenka-uresova/ class=align-middle>Zdenka Uresova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jenna-kanerva/ class=align-middle>Jenna Kanerva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stina-ojala/ class=align-middle>Stina Ojala</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anna-missila/ class=align-middle>Anna Missilä</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sebastian-schuster/ class=align-middle>Sebastian Schuster</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/siva-reddy/ class=align-middle>Siva Reddy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dima-taji/ class=align-middle>Dima Taji</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nizar-habash/ class=align-middle>Nizar Habash</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/herman-leung/ class=align-middle>Herman Leung</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marie-catherine-de-marneffe/ class=align-middle>Marie-Catherine de Marneffe</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/manuela-sanguinetti/ class=align-middle>Manuela Sanguinetti</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maria-simi/ class=align-middle>Maria Simi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hiroshi-kanayama/ class=align-middle>Hiroshi Kanayama</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/valeria-de-paiva/ class=align-middle>Valeria de Paiva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kira-droganova/ class=align-middle>Kira Droganova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hector-martinez-alonso/ class=align-middle>Héctor Martínez Alonso</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cagri-coltekin/ class=align-middle>Çağrı Çöltekin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/u/umut-sulubacak/ class=align-middle>Umut Sulubacak</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hans-uszkoreit/ class=align-middle>Hans Uszkoreit</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vivien-macketanz/ class=align-middle>Vivien Macketanz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aljoscha-burchardt/ class=align-middle>Aljoscha Burchardt</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kim-harris/ class=align-middle>Kim Harris</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/katrin-marheinecke/ class=align-middle>Katrin Marheinecke</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/georg-rehm/ class=align-middle>Georg Rehm</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tolga-kayadelen/ class=align-middle>Tolga Kayadelen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mohammed-attia/ class=align-middle>Mohammed Attia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ali-elkahky/ class=align-middle>Ali Elkahky</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhuoran-yu/ class=align-middle>Zhuoran Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/emily-pitler/ class=align-middle>Emily Pitler</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/saran-lertpradit/ class=align-middle>Saran Lertpradit</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-mandel/ class=align-middle>Michael Mandel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jesse-kirchner/ class=align-middle>Jesse Kirchner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hector-fernandez-alcalde/ class=align-middle>Hector Fernandez Alcalde</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jana-strnadova/ class=align-middle>Jana Strnadová</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/esha-banerjee/ class=align-middle>Esha Banerjee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ruli-manurung/ class=align-middle>Ruli Manurung</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/antonio-stella/ class=align-middle>Antonio Stella</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/atsuko-shimada/ class=align-middle>Atsuko Shimada</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sookyoung-kwak/ class=align-middle>Sookyoung Kwak</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gustavo-mendonca/ class=align-middle>Gustavo Mendonca</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tatiana-lando/ class=align-middle>Tatiana Lando</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rattima-nitisaroj/ class=align-middle>Rattima Nitisaroj</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/josie-li/ class=align-middle>Josie Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sida-i-wang/ class=align-middle>Sida I. Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/samuel-ginn/ class=align-middle>Samuel Ginn</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/abigail-see/ class=align-middle>Abigail See</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/peter-j-liu/ class=align-middle>Peter J. Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haojun-li/ class=align-middle>Haojun Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dilara-soylu/ class=align-middle>Dilara Soylu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mihail-eric/ class=align-middle>Mihail Eric</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lakshmi-krishnan/ class=align-middle>Lakshmi Krishnan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/francois-charette/ class=align-middle>Francois Charette</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/arun-chaganty/ class=align-middle>Arun Chaganty</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ashwin-paranjape/ class=align-middle>Ashwin Paranjape</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shikhar-murty/ class=align-middle>Shikhar Murty</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tatsunori-b-hashimoto/ class=align-middle>Tatsunori B. Hashimoto</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/sigdial/ class=align-middle>SIGDIAL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>