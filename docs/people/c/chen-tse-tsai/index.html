<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Chen-Tse Tsai - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Chen-Tse</span> <span class=font-weight-bold>Tsai</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-main.84.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-main--84 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-main.84 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-main.84/>Identifying Named Entities as they are Typed</a></strong><br><a href=/people/r/ravneet-arora/>Ravneet Arora</a>
|
<a href=/people/c/chen-tse-tsai/>Chen-Tse Tsai</a>
|
<a href=/people/d/daniel-preotiuc-pietro/>Daniel Preotiuc-Pietro</a><br><a href=/volumes/2021.eacl-main/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-main--84><div class="card-body p-3 small">Identifying <a href=https://en.wikipedia.org/wiki/Named_entity>named entities</a> in written text is an essential component of the text processing pipeline used in applications such as <a href=https://en.wikipedia.org/wiki/Text_editor>text editors</a> to gain a better understanding of the semantics of the text. However, the typical experimental setup for evaluating Named Entity Recognition (NER) systems is not directly applicable to <a href=https://en.wikipedia.org/wiki/System>systems</a> that process text in real time as the text is being typed. Evaluation is performed on a sentence level assuming the end-user is willing to wait until the entire sentence is typed for entities to be identified and further linked to identifiers or co-referenced. We introduce a novel experimental setup for NER systems for applications where decisions about named entity boundaries need to be performed in an online fashion. We study how state-of-the-art methods perform under this setup in multiple languages and propose adaptations to these models to suit this new experimental setup. Experimental results show that the best <a href=https://en.wikipedia.org/wiki/System>systems</a> that are evaluated on each token after its typed, reach performance within 15 F1 points of systems that are evaluated at the end of the sentence. These show that entity recognition can be performed in this <a href=https://en.wikipedia.org/wiki/Computer_simulation>setup</a> and open up the development of other NLP tools in a similar setup.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1587.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1587 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1587 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1587.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385242676 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1587/>A Semi-Markov Structured Support Vector Machine Model for High-Precision Named Entity Recognition<span class=acl-fixed-case>M</span>arkov Structured Support Vector Machine Model for High-Precision Named Entity Recognition</a></strong><br><a href=/people/r/ravneet-arora/>Ravneet Arora</a>
|
<a href=/people/c/chen-tse-tsai/>Chen-Tse Tsai</a>
|
<a href=/people/k/ketevan-tsereteli/>Ketevan Tsereteli</a>
|
<a href=/people/p/prabhanjan-kambadur/>Prabhanjan Kambadur</a>
|
<a href=/people/y/yi-yang/>Yi Yang</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1587><div class="card-body p-3 small">Named entity recognition (NER) is the backbone of many <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP solutions</a>. F1 score, the harmonic mean of precision and recall, is often used to select / evaluate the best <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. However, when <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> needs to be prioritized over <a href=https://en.wikipedia.org/wiki/Precision_recall>recall</a>, a state-of-the-art <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> might not be the best choice. There is little in literature that directly addresses training-time modifications to achieve higher precision information extraction. In this paper, we propose a neural semi-Markov structured support vector machine model that controls the precision-recall trade-off by assigning weights to different types of errors in the loss-augmented inference during training. The semi-Markov property provides more accurate phrase-level predictions, thereby improving performance. We empirically demonstrate the advantage of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> when high <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> is required by comparing against strong baselines based on CRF. In our experiments with the CoNLL 2003 dataset, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves a better precision-recall trade-off at various precision levels.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K19-1060.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K19-1060 data-toggle=collapse aria-expanded=false aria-controls=abstract-K19-1060 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K19-1060/>Named Entity Recognition with Partially Annotated Training Data</a></strong><br><a href=/people/s/stephen-mayhew/>Stephen Mayhew</a>
|
<a href=/people/s/snigdha-chaturvedi/>Snigdha Chaturvedi</a>
|
<a href=/people/c/chen-tse-tsai/>Chen-Tse Tsai</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a><br><a href=/volumes/K19-1/ class=text-muted>Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K19-1060><div class="card-body p-3 small">Supervised machine learning assumes the availability of fully-labeled data, but in many cases, such as low-resource languages, the only data available is partially annotated. We study the problem of Named Entity Recognition (NER) with partially annotated training data in which a fraction of the named entities are labeled, and all other tokens, entities or otherwise, are labeled as non-entity by default. In order to train on this <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noisy dataset</a>, we need to distinguish between the true and false negatives. To this end, we introduce a constraint-driven iterative algorithm that learns to detect false negatives in the noisy set and downweigh them, resulting in a weighted training set. With this <a href=https://en.wikipedia.org/wiki/Set_(mathematics)>set</a>, we train a weighted NER model. We evaluate our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> with weighted variants of neural and non-neural NER models on data in 8 languages from several language and script families, showing strong ability to learn from partial data. Finally, to show real-world efficacy, we evaluate on a Bengali NER corpus annotated by non-speakers, outperforming the prior <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> by over 5 points <a href=https://en.wikipedia.org/wiki/F-number>F1</a>.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-3016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-3016 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-3016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-3016/>STCP : Simplified-Traditional Chinese Conversion and Proofreading<span class=acl-fixed-case>STCP</span>: Simplified-Traditional <span class=acl-fixed-case>C</span>hinese Conversion and Proofreading</a></strong><br><a href=/people/j/jiarui-xu/>Jiarui Xu</a>
|
<a href=/people/x/xuezhe-ma/>Xuezhe Ma</a>
|
<a href=/people/c/chen-tse-tsai/>Chen-Tse Tsai</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a><br><a href=/volumes/I17-3/ class=text-muted>Proceedings of the IJCNLP 2017, System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-3016><div class="card-body p-3 small">This paper aims to provide an effective tool for conversion between <a href=https://en.wikipedia.org/wiki/Simplified_Chinese_characters>Simplified Chinese</a> and Traditional Chinese. We present STCP, a customizable system comprising statistical conversion model, and proofreading web interface. Experiments show that our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves comparable character-level conversion performance with the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-art systems</a>. In addition, our proofreading interface can effectively support <a href=https://en.wikipedia.org/wiki/Diagnosis>diagnostics</a> and data annotation. STCP is available at<url>http://lagos.lti.cs.cmu.edu:8002/</url>\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1269.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1269 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1269 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1269/>Cheap Translation for Cross-Lingual Named Entity Recognition</a></strong><br><a href=/people/s/stephen-mayhew/>Stephen Mayhew</a>
|
<a href=/people/c/chen-tse-tsai/>Chen-Tse Tsai</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1269><div class="card-body p-3 small">Recent work in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> has attempted to deal with low-resource languages but still assumed a resource level that is not present for most <a href=https://en.wikipedia.org/wiki/Language>languages</a>, e.g., the availability of <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a> in the target language. We propose a simple method for cross-lingual named entity recognition (NER) that works well in settings with very minimal resources. Our approach makes use of a <a href=https://en.wikipedia.org/wiki/Lexicon>lexicon</a> to translate annotated data available in one or several high resource language(s) into the target language, and learns a standard monolingual NER model there. Further, when <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a> is available in the target language, our method can enhance <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia based methods</a> to yield state-of-the-art NER results ; we evaluate on 7 diverse languages, improving the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> by an average of 5.5 % F1 points. With the minimal resources required, this is an extremely portable cross-lingual NER approach, as illustrated using a truly low-resource language, <a href=https://en.wikipedia.org/wiki/Uyghur_language>Uyghur</a>.<i>very</i> minimal resources. Our approach makes use of a lexicon to &#8220;translate&#8221; annotated data available in one or several high resource language(s) into the target language, and learns a standard monolingual NER model there. Further, when Wikipedia is available in the target language, our method can enhance Wikipedia based methods to yield state-of-the-art NER results; we evaluate on 7 diverse languages, improving the state-of-the-art by an average of 5.5% F1 points. With the minimal resources required, this is an extremely portable cross-lingual NER approach, as illustrated using a truly low-resource language, Uyghur.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Chen-Tse+Tsai" title="Search for 'Chen-Tse Tsai' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/r/ravneet-arora/ class=align-middle>Ravneet Arora</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/stephen-mayhew/ class=align-middle>Stephen Mayhew</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/dan-roth/ class=align-middle>Dan Roth</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jiarui-xu/ class=align-middle>Jiarui Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xuezhe-ma/ class=align-middle>Xuezhe Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/e/eduard-hovy/ class=align-middle>Eduard Hovy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/daniel-preotiuc-pietro/ class=align-middle>Daniel Preoţiuc-Pietro</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/ketevan-tsereteli/ class=align-middle>Ketevan Tsereteli</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/prabhanjan-kambadur/ class=align-middle>Prabhanjan Kambadur</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yi-yang/ class=align-middle>Yi Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/snigdha-chaturvedi/ class=align-middle>Snigdha Chaturvedi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>