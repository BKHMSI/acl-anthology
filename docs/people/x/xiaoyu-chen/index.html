<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Xiaoyu Chen - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Xiaoyu</span> <span class=font-weight-bold>Chen</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wmt-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wmt-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wmt-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wmt-1.21/>HW-TSC’s Participation in the WMT 2021 News Translation Shared Task<span class=acl-fixed-case>HW</span>-<span class=acl-fixed-case>TSC</span>’s Participation in the <span class=acl-fixed-case>WMT</span> 2021 News Translation Shared Task</a></strong><br><a href=/people/d/daimeng-wei/>Daimeng Wei</a>
|
<a href=/people/z/zongyao-li/>Zongyao Li</a>
|
<a href=/people/z/zhanglin-wu/>Zhanglin Wu</a>
|
<a href=/people/z/zhengzhe-yu/>Zhengzhe Yu</a>
|
<a href=/people/x/xiaoyu-chen/>Xiaoyu Chen</a>
|
<a href=/people/h/hengchao-shang/>Hengchao Shang</a>
|
<a href=/people/j/jiaxin-guo/>Jiaxin Guo</a>
|
<a href=/people/m/minghan-wang/>Minghan Wang</a>
|
<a href=/people/l/lizhi-lei/>Lizhi Lei</a>
|
<a href=/people/m/min-zhang/>Min Zhang</a>
|
<a href=/people/h/hao-yang/>Hao Yang</a>
|
<a href=/people/y/ying-qin/>Ying Qin</a><br><a href=/volumes/2021.wmt-1/ class=text-muted>Proceedings of the Sixth Conference on Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wmt-1--21><div class="card-body p-3 small">This paper presents the submission of Huawei Translate Services Center (HW-TSC) to the WMT 2021 News Translation Shared Task. We participate in 7 language pairs, including Zh / En, De / En, Ja / En, Ha / En, Is / En, Hi / Bn, and Xh / Zu in both directions under the constrained condition. We use Transformer architecture and obtain the best performance via multiple variants with larger parameter sizes. We perform detailed pre-processing and filtering on the provided large-scale bilingual and monolingual datasets. Several commonly used strategies are used to train our models, such as <a href=https://en.wikipedia.org/wiki/Back_translation>Back Translation</a>, Forward Translation, Multilingual Translation, Ensemble Knowledge Distillation, etc. Our submission obtains competitive results in the final evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wmt-1.37.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wmt-1--37 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wmt-1.37 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wmt-1.37/>HW-TSC’s Participation in the WMT 2021 Triangular MT Shared Task<span class=acl-fixed-case>HW</span>-<span class=acl-fixed-case>TSC</span>’s Participation in the <span class=acl-fixed-case>WMT</span> 2021 Triangular <span class=acl-fixed-case>MT</span> Shared Task</a></strong><br><a href=/people/z/zongyao-li/>Zongyao Li</a>
|
<a href=/people/d/daimeng-wei/>Daimeng Wei</a>
|
<a href=/people/h/hengchao-shang/>Hengchao Shang</a>
|
<a href=/people/x/xiaoyu-chen/>Xiaoyu Chen</a>
|
<a href=/people/z/zhanglin-wu/>Zhanglin Wu</a>
|
<a href=/people/z/zhengzhe-yu/>Zhengzhe Yu</a>
|
<a href=/people/j/jiaxin-guo/>Jiaxin Guo</a>
|
<a href=/people/m/minghan-wang/>Minghan Wang</a>
|
<a href=/people/l/lizhi-lei/>Lizhi Lei</a>
|
<a href=/people/m/min-zhang/>Min Zhang</a>
|
<a href=/people/h/hao-yang/>Hao Yang</a>
|
<a href=/people/y/ying-qin/>Ying Qin</a><br><a href=/volumes/2021.wmt-1/ class=text-muted>Proceedings of the Sixth Conference on Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wmt-1--37><div class="card-body p-3 small">This paper presents the submission of Huawei Translation Service Center (HW-TSC) to WMT 2021 Triangular MT Shared Task. We participate in the Russian-to-Chinese task under the constrained condition. We use Transformer architecture and obtain the best performance via a variant with larger parameter sizes. We perform detailed data pre-processing and filtering on the provided large-scale bilingual data. Several strategies are used to train our models, such as Multilingual Translation, Back Translation, Forward Translation, Data Denoising, Average Checkpoint, Ensemble, Fine-tuning, etc. Our <a href=https://en.wikipedia.org/wiki/System>system</a> obtains 32.5 <a href=https://en.wikipedia.org/wiki/British_undergraduate_degree_classification>BLEU</a> on the <a href=https://en.wikipedia.org/wiki/British_undergraduate_degree_classification>dev set</a> and 27.7 BLEU on the <a href=https://en.wikipedia.org/wiki/British_undergraduate_degree_classification>test set</a>, the highest score among all submissions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wmt-1.55.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wmt-1--55 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wmt-1.55 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wmt-1.55/>HW-TSC’s Participation in the WMT 2021 Large-Scale Multilingual Translation Task<span class=acl-fixed-case>HW</span>-<span class=acl-fixed-case>TSC</span>’s Participation in the <span class=acl-fixed-case>WMT</span> 2021 Large-Scale Multilingual Translation Task</a></strong><br><a href=/people/z/zhengzhe-yu/>Zhengzhe Yu</a>
|
<a href=/people/d/daimeng-wei/>Daimeng Wei</a>
|
<a href=/people/z/zongyao-li/>Zongyao Li</a>
|
<a href=/people/h/hengchao-shang/>Hengchao Shang</a>
|
<a href=/people/x/xiaoyu-chen/>Xiaoyu Chen</a>
|
<a href=/people/z/zhanglin-wu/>Zhanglin Wu</a>
|
<a href=/people/j/jiaxin-guo/>Jiaxin Guo</a>
|
<a href=/people/m/minghan-wang/>Minghan Wang</a>
|
<a href=/people/l/lizhi-lei/>Lizhi Lei</a>
|
<a href=/people/m/min-zhang/>Min Zhang</a>
|
<a href=/people/h/hao-yang/>Hao Yang</a>
|
<a href=/people/y/ying-qin/>Ying Qin</a><br><a href=/volumes/2021.wmt-1/ class=text-muted>Proceedings of the Sixth Conference on Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wmt-1--55><div class="card-body p-3 small">This paper presents the submission of Huawei Translation Services Center (HW-TSC) to the WMT 2021 Large-Scale Multilingual Translation Task. We participate in Samll Track # 2, including 6 languages : <a href=https://en.wikipedia.org/wiki/Javanese_language>Javanese (Jv)</a>, <a href=https://en.wikipedia.org/wiki/Indonesian_language>Indonesian (I d)</a>, <a href=https://en.wikipedia.org/wiki/Malay_language>Malay (Ms)</a>, <a href=https://en.wikipedia.org/wiki/Tagalog_language>Tagalog (Tl)</a>, <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil (Ta)</a> and <a href=https://en.wikipedia.org/wiki/English_language>English (En)</a> with 30 directions under the constrained condition. We use Transformer architecture and obtain the best performance via multiple variants with larger parameter sizes. We train a single multilingual model to translate all the 30 directions. We perform detailed pre-processing and filtering on the provided large-scale bilingual and monolingual datasets. Several commonly used strategies are used to train our models, such as <a href=https://en.wikipedia.org/wiki/Back_translation>Back Translation</a>, Forward Translation, Ensemble Knowledge Distillation, Adapter Fine-tuning. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> obtains competitive results in the end.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wat-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--wat-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.wat-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.wat-1.8/>HW-TSC’s Participation in the WAT 2020 Indic Languages Multilingual Task<span class=acl-fixed-case>HW</span>-<span class=acl-fixed-case>TSC</span>’s Participation in the <span class=acl-fixed-case>WAT</span> 2020 Indic Languages Multilingual Task</a></strong><br><a href=/people/z/zhengzhe-yu/>Zhengzhe Yu</a>
|
<a href=/people/z/zhanglin-wu/>Zhanglin Wu</a>
|
<a href=/people/x/xiaoyu-chen/>Xiaoyu Chen</a>
|
<a href=/people/d/daimeng-wei/>Daimeng Wei</a>
|
<a href=/people/h/hengchao-shang/>Hengchao Shang</a>
|
<a href=/people/j/jiaxin-guo/>Jiaxin Guo</a>
|
<a href=/people/z/zongyao-li/>Zongyao Li</a>
|
<a href=/people/m/minghan-wang/>Minghan Wang</a>
|
<a href=/people/l/liangyou-li/>Liangyou Li</a>
|
<a href=/people/l/lizhi-lei/>Lizhi Lei</a>
|
<a href=/people/h/hao-yang/>Hao Yang</a>
|
<a href=/people/y/ying-qin/>Ying Qin</a><br><a href=/volumes/2020.wat-1/ class=text-muted>Proceedings of the 7th Workshop on Asian Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--wat-1--8><div class="card-body p-3 small">This paper describes our work in the WAT 2020 Indic Multilingual Translation Task. We participated in all 7 language pairs (En-Bn / Hi / Gu / Ml / Mr / Ta / Te) in both directions under the constrained conditionusing only the officially provided data. Using <a href=https://en.wikipedia.org/wiki/Transformer>transformer</a> as a baseline, our Multi-En and En-Multi translation systems achieve the best performances. Detailed data filtering and data domain selection are the keys to performance enhancement in our experiment, with an average improvement of 2.6 BLEU scores for each language pair in the En-Multi system and an average improvement of 4.6 BLEU scores regarding the Multi-En. In addition, we employed language independent adapter to further improve the <a href=https://en.wikipedia.org/wiki/System>system</a> performances. Our submission obtains competitive results in the final evaluation.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Xiaoyu+Chen" title="Search for 'Xiaoyu Chen' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/d/daimeng-wei/ class=align-middle>Daimeng Wei</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/z/zongyao-li/ class=align-middle>Zongyao Li</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/z/zhanglin-wu/ class=align-middle>Zhanglin Wu</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/z/zhengzhe-yu/ class=align-middle>Zhengzhe Yu</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/h/hengchao-shang/ class=align-middle>Hengchao Shang</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/j/jiaxin-guo/ class=align-middle>Jiaxin Guo</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/m/minghan-wang/ class=align-middle>Minghan Wang</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/l/lizhi-lei/ class=align-middle>Lizhi Lei</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/h/hao-yang/ class=align-middle>Hao Yang</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/y/ying-qin/ class=align-middle>Ying Qin</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/m/min-zhang/ class=align-middle>Min Zhang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/liangyou-li/ class=align-middle>Liangyou Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/wmt/ class=align-middle>WMT</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/wat/ class=align-middle>WAT</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>