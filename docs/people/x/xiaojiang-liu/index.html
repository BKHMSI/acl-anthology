<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Xiaojiang Liu - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Xiaojiang</span> <span class=font-weight-bold>Liu</span></h2><hr><div class=row><div class=col-lg-9><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.539.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--539 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.539 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938821 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.539" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.539/>Profile Consistency Identification for Open-domain Dialogue Agents</a></strong><br><a href=/people/h/haoyu-song/>Haoyu Song</a>
|
<a href=/people/y/yan-wang/>Yan Wang</a>
|
<a href=/people/w/weinan-zhang/>Wei-Nan Zhang</a>
|
<a href=/people/z/zhengyu-zhao/>Zhengyu Zhao</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--539><div class="card-body p-3 small">Maintaining a consistent attribute profile is crucial for dialogue agents to naturally converse with humans. Existing studies on improving attribute consistency mainly explored how to incorporate <a href=https://en.wikipedia.org/wiki/Attribute_(computing)>attribute information</a> in the responses, but few efforts have been made to identify the <a href=https://en.wikipedia.org/wiki/Consistency_(database_systems)>consistency relations</a> between response and attribute profile. To facilitate the study of profile consistency identification, we create a large-scale human-annotated dataset with over 110 K single-turn conversations and their key-value attribute profiles. Explicit relation between <a href=https://en.wikipedia.org/wiki/Information_retrieval>response</a> and profile is manually labeled. We also propose a key-value structure information enriched BERT model to identify the profile consistency, and it gained improvements over strong baselines. Further evaluations on <a href=https://en.wikipedia.org/wiki/Downstream_(networking)>downstream tasks</a> demonstrate that the profile consistency identification model is conducive for improving dialogue consistency.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.741.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--741 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.741 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938681 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.741/>The World is Not Binary : Learning to Rank with <a href=https://en.wikipedia.org/wiki/Grayscale>Grayscale Data</a> for Dialogue Response Selection</a></strong><br><a href=/people/z/zibo-lin/>Zibo Lin</a>
|
<a href=/people/d/deng-cai/>Deng Cai</a>
|
<a href=/people/y/yan-wang/>Yan Wang</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a>
|
<a href=/people/h/haitao-zheng/>Haitao Zheng</a>
|
<a href=/people/s/shuming-shi/>Shuming Shi</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--741><div class="card-body p-3 small">Response selection plays a vital role in building retrieval-based conversation systems. Despite that response selection is naturally a learning-to-rank problem, most prior works take a point-wise view and train binary classifiers for this task : each response candidate is labeled either relevant (one) or irrelevant (zero). On the one hand, this <a href=https://en.wikipedia.org/wiki/Formal_system>formalization</a> can be sub-optimal due to its ignorance of the diversity of response quality. On the other hand, annotating <a href=https://en.wikipedia.org/wiki/Grayscale>grayscale data</a> for learning-to-rank can be prohibitively expensive and challenging. In this work, we show that <a href=https://en.wikipedia.org/wiki/Grayscale>grayscale data</a> can be automatically constructed without human effort. Our method employs off-the-shelf response retrieval models and response generation models as automatic grayscale data generators. With the constructed <a href=https://en.wikipedia.org/wiki/Grayscale>grayscale data</a>, we propose multi-level ranking objectives for training, which can (1) teach a matching model to capture more fine-grained context-response relevance difference and (2) reduce the train-test discrepancy in terms of distractor strength. Our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> is simple, effective, and universal. Experiments on three <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark datasets</a> and four state-of-the-art matching models show that the proposed approach brings significant and consistent performance improvements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.61.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--61 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.61 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929327 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.61/>Response-Anticipated Memory for On-Demand Knowledge Integration in Response Generation</a></strong><br><a href=/people/z/zhiliang-tian/>Zhiliang Tian</a>
|
<a href=/people/w/wei-bi/>Wei Bi</a>
|
<a href=/people/d/dongkyu-lee/>Dongkyu Lee</a>
|
<a href=/people/l/lanqing-xue/>Lanqing Xue</a>
|
<a href=/people/y/yiping-song/>Yiping Song</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a>
|
<a href=/people/n/nevin-l-zhang/>Nevin L. Zhang</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--61><div class="card-body p-3 small">Neural conversation models are known to generate appropriate but non-informative responses in general. A scenario where informativeness can be significantly enhanced is Conversing by Reading (CbR), where conversations take place with respect to a given external document. In previous work, the external document is utilized by (1) creating a context-aware document memory that integrates information from the document and the conversational context, and then (2) generating responses referring to the <a href=https://en.wikipedia.org/wiki/Memory>memory</a>. In this paper, we propose to create the document memory with some anticipated responses in mind. This is achieved using a teacher-student framework. The teacher is given the external document, the context, and the ground-truth response, and learns how to build a response-aware document memory from three sources of information. The student learns to construct a response-anticipated document memory from the first two sources, and teacher&#8217;s insight on memory creation. Empirical results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms the previous <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> for the CbR task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.68.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--68 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.68 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928912 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.68" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.68/>Rigid Formats Controlled Text Generation</a></strong><br><a href=/people/p/piji-li/>Piji Li</a>
|
<a href=/people/h/haisong-zhang/>Haisong Zhang</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a>
|
<a href=/people/s/shuming-shi/>Shuming Shi</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--68><div class="card-body p-3 small">Neural text generation has made tremendous progress in various <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a>. One common characteristic of most of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> is that the texts are not restricted to some <a href=https://en.wikipedia.org/wiki/File_format>rigid formats</a> when generating. However, we may confront some special text paradigms such as <a href=https://en.wikipedia.org/wiki/Lyrics>Lyrics</a> (assume the music score is given), <a href=https://en.wikipedia.org/wiki/Sonnet>Sonnet</a>, SongCi (classical Chinese poetry of the Song dynasty), etc. The typical characteristics of these <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>texts</a> are in three folds : (1) They must comply fully with the rigid predefined formats. (2) They must obey some <a href=https://en.wikipedia.org/wiki/Rhyme_scheme>rhyming schemes</a>. (3) Although they are restricted to some formats, the sentence integrity must be guaranteed. To the best of our knowledge, <a href=https://en.wikipedia.org/wiki/Text_generator>text generation</a> based on the predefined rigid formats has not been well investigated. Therefore, we propose a simple and elegant <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> named <a href=https://en.wikipedia.org/wiki/SongNet>SongNet</a> to tackle this problem. The backbone of the <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> is a Transformer-based auto-regressive language model. Sets of symbols are tailor-designed to improve the modeling performance especially on <a href=https://en.wikipedia.org/wiki/File_format>format</a>, <a href=https://en.wikipedia.org/wiki/Rhyme>rhyme</a>, and sentence integrity. We improve the attention mechanism to impel the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to capture some future information on the format. A pre-training and fine-tuning framework is designed to further improve the generation quality. Extensive experiments conducted on two collected corpora demonstrate that our proposed framework generates significantly better results in terms of both automatic metrics and the human evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.235.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--235 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.235 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928824 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.235" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.235/>A Batch Normalized Inference Network Keeps the KL Vanishing Away<span class=acl-fixed-case>KL</span> Vanishing Away</a></strong><br><a href=/people/q/qile-zhu/>Qile Zhu</a>
|
<a href=/people/w/wei-bi/>Wei Bi</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a>
|
<a href=/people/x/xiyao-ma/>Xiyao Ma</a>
|
<a href=/people/x/xiaolin-li/>Xiaolin Li</a>
|
<a href=/people/d/dapeng-wu/>Dapeng Wu</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--235><div class="card-body p-3 small">Variational Autoencoder (VAE) is widely used as a <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> to approximate a model&#8217;s posterior on <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a> by combining the amortized variational inference and <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural networks</a>. However, when paired with strong autoregressive decoders, VAE often converges to a degenerated local optimum known as posterior collapse. Previous approaches consider the KullbackLeibler divergence (KL) individual for each datapoint. We propose to let the KL follow a distribution across the whole dataset, and analyze that it is sufficient to prevent posterior collapse by keeping the expectation of the KL&#8217;s distribution positive. Then we propose Batch Normalized-VAE (BN-VAE), a simple but effective approach to set a lower bound of the expectation by regularizing the distribution of the approximate posterior&#8217;s parameters. Without introducing any new model component or modifying the objective, our approach can avoid the posterior collapse effectively and efficiently. We further show that the proposed BN-VAE can be extended to conditional VAE (CVAE). Empirically, our approach surpasses strong autoregressive baselines on language modeling, text classification and dialogue generation, and rivals more complex approaches while keeping almost the same training time as VAE.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.262.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--262 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.262 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.findings-emnlp.262.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.262/>Enhancing Content Planning for Table-to-Text Generation with Data Understanding and Verification</a></strong><br><a href=/people/h/heng-gong/>Heng Gong</a>
|
<a href=/people/w/wei-bi/>Wei Bi</a>
|
<a href=/people/x/xiaocheng-feng/>Xiaocheng Feng</a>
|
<a href=/people/b/bing-qin/>Bing Qin</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--262><div class="card-body p-3 small">Neural table-to-text models, which select and order salient data, as well as verbalizing them fluently via surface realization, have achieved promising progress. Based on results from previous work, the performance bottleneck of current models lies in the stage of content planing (selecting and ordering salient content from the input). That is, performance drops drastically when an <a href=https://en.wikipedia.org/wiki/Oracle_machine>oracle content plan</a> is replaced by a model-inferred one during surface realization. In this paper, we propose to enhance neural content planning by (1) understanding data values with contextual numerical value representations that bring the sense of value comparison into content planning ; (2) verifying the importance and ordering of the selected sequence of records with policy gradient. We evaluated our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on ROTOWIRE and MLB, two datasets on this task, and results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms existing systems with respect to content planning metrics.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1191.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1191 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1191 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1191/>Improving Open-Domain Dialogue Systems via Multi-Turn Incomplete Utterance Restoration</a></strong><br><a href=/people/z/zhufeng-pan/>Zhufeng Pan</a>
|
<a href=/people/k/kun-bai/>Kun Bai</a>
|
<a href=/people/y/yan-wang/>Yan Wang</a>
|
<a href=/people/l/lianqiang-zhou/>Lianqiang Zhou</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1191><div class="card-body p-3 small">In multi-turn dialogue, utterances do not always take the full form of sentences. These incomplete utterances will greatly reduce the performance of open-domain dialogue systems. Restoring more incomplete utterances from context could potentially help the <a href=https://en.wikipedia.org/wiki/System>systems</a> generate more relevant responses. To facilitate the study of incomplete utterance restoration for open-domain dialogue systems, a large-scale multi-turn dataset Restoration-200 K is collected and manually labeled with the explicit relation between an utterance and its context. We also propose a pick-and-combine model to restore the incomplete utterance from its context. Experimental results demonstrate that the annotated dataset and the proposed approach significantly boost the response quality of both single-turn and multi-turn dialogue systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1195.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1195 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1195 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1195/>Retrieval-guided Dialogue Response Generation via a Matching-to-Generation Framework</a></strong><br><a href=/people/d/deng-cai/>Deng Cai</a>
|
<a href=/people/y/yan-wang/>Yan Wang</a>
|
<a href=/people/w/wei-bi/>Wei Bi</a>
|
<a href=/people/z/zhaopeng-tu/>Zhaopeng Tu</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a>
|
<a href=/people/s/shuming-shi/>Shuming Shi</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1195><div class="card-body p-3 small">End-to-end sequence generation is a popular technique for developing open domain dialogue systems, though they suffer from the safe response problem. Researchers have attempted to tackle this problem by incorporating <a href=https://en.wikipedia.org/wiki/Generative_model>generative models</a> with the returns of <a href=https://en.wikipedia.org/wiki/Information_retrieval>retrieval systems</a>. Recently, a skeleton-then-response framework has been shown promising results for this <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>. Nevertheless, how to precisely extract a <a href=https://en.wikipedia.org/wiki/Skeleton>skeleton</a> and how to effectively train a retrieval-guided response generator are still challenging. This paper presents a novel framework in which the skeleton extraction is made by an interpretable matching model and the following skeleton-guided response generation is accomplished by a separately trained generator. Extensive experiments demonstrate the effectiveness of our model designs.<i>safe response problem</i>. Researchers have attempted to tackle this problem by incorporating generative models with the returns of retrieval systems. Recently, a skeleton-then-response framework has been shown promising results for this task. Nevertheless, how to precisely extract a skeleton and how to effectively train a retrieval-guided response generator are still challenging. This paper presents a novel framework in which the skeleton extraction is made by an interpretable matching model and the following skeleton-guided response generation is accomplished by a separately trained generator. Extensive experiments demonstrate the effectiveness of our model designs.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1132.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1132 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1132 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1132/>Translating a Math Word Problem to a <a href=https://en.wikipedia.org/wiki/Expression_tree>Expression Tree</a></a></strong><br><a href=/people/l/lei-wang/>Lei Wang</a>
|
<a href=/people/y/yan-wang/>Yan Wang</a>
|
<a href=/people/d/deng-cai/>Deng Cai</a>
|
<a href=/people/d/dongxiang-zhang/>Dongxiang Zhang</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1132><div class="card-body p-3 small">Sequence-to-sequence (SEQ2SEQ) models have been successfully applied to automatic math word problem solving. Despite its simplicity, a drawback still remains : a math word problem can be correctly solved by more than one equations. This non-deterministic transduction harms the performance of <a href=https://en.wikipedia.org/wiki/Maximum_likelihood_estimation>maximum likelihood estimation</a>. In this paper, by considering the uniqueness of <a href=https://en.wikipedia.org/wiki/Expression_tree>expression tree</a>, we propose an equation normalization method to normalize the duplicated equations. Moreover, we analyze the performance of three popular SEQ2SEQ models on the math word problem solving. We find that each <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> has its own specialty in solving problems, consequently an ensemble model is then proposed to combine their advantages. Experiments on dataset Math23 K show that the <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble model</a> with equation normalization significantly outperforms the previous state-of-the-art methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1297.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1297 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1297 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/305942945 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1297" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1297/>Towards Less Generic Responses in Neural Conversation Models : A Statistical Re-weighting Method</a></strong><br><a href=/people/y/yahui-liu/>Yahui Liu</a>
|
<a href=/people/w/wei-bi/>Wei Bi</a>
|
<a href=/people/j/jun-gao/>Jun Gao</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a>
|
<a href=/people/j/jian-yao/>Jian Yao</a>
|
<a href=/people/s/shuming-shi/>Shuming Shi</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1297><div class="card-body p-3 small">Sequence-to-sequence neural generation models have achieved promising performance on short text conversation tasks. However, they tend to generate generic / dull responses, leading to unsatisfying dialogue experience. We observe that in the conversation tasks, each query could have multiple responses, which forms a 1-to-n or m-to-n relationship in the view of the total corpus. The <a href=https://en.wikipedia.org/wiki/Loss_function>objective function</a> used in standard sequence-to-sequence models will be dominated by loss terms with generic patterns. Inspired by this observation, we introduce a statistical re-weighting method that assigns different weights for the multiple responses of the same query, and trains the common neural generation model with the weights. Experimental results on a large Chinese dialogue corpus show that our method improves the acceptance rate of generated responses compared with several baseline models and significantly reduces the number of generated generic responses.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1088.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1088 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1088 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1088/>Deep Neural Solver for Math Word Problems</a></strong><br><a href=/people/y/yan-wang/>Yan Wang</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a>
|
<a href=/people/s/shuming-shi/>Shuming Shi</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1088><div class="card-body p-3 small">This paper presents a deep neural solver to automatically solve math word problems. In contrast to previous statistical learning approaches, we directly translate math word problems to equation templates using a recurrent neural network (RNN) model, without sophisticated <a href=https://en.wikipedia.org/wiki/Feature_engineering>feature engineering</a>. We further design a hybrid model that combines the RNN model and a similarity-based retrieval model to achieve additional performance improvement. Experiments conducted on a large dataset show that the RNN model and the hybrid model significantly outperform state-of-the-art statistical learning methods for math word problem solving.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Xiaojiang+Liu" title="Search for 'Xiaojiang Liu' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/y/yan-wang/ class=align-middle>Yan Wang</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/s/shuming-shi/ class=align-middle>Shuming Shi</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/w/wei-bi/ class=align-middle>Wei Bi</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/d/deng-cai/ class=align-middle>Deng Cai</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/t/ting-liu/ class=align-middle>Ting Liu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/h/haoyu-song/ class=align-middle>Haoyu Song</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/weinan-zhang/ class=align-middle>Weinan Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhengyu-zhao/ class=align-middle>Zhengyu Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zibo-lin/ class=align-middle>Zibo Lin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haitao-zheng/ class=align-middle>Haitao Zheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhiliang-tian/ class=align-middle>Zhiliang Tian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dongkyu-lee/ class=align-middle>Dongkyu Lee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lanqing-xue/ class=align-middle>Lanqing Xue</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yiping-song/ class=align-middle>Yiping Song</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nevin-l-zhang/ class=align-middle>Nevin L. Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/piji-li/ class=align-middle>Piji Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haisong-zhang/ class=align-middle>Haisong Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qile-zhu/ class=align-middle>Qile Zhu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiyao-ma/ class=align-middle>Xiyao Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaolin-li/ class=align-middle>Xiaolin Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dapeng-wu/ class=align-middle>Dapeng Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lei-wang/ class=align-middle>Lei Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dongxiang-zhang/ class=align-middle>Dongxiang Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yahui-liu/ class=align-middle>Yahui Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jun-gao/ class=align-middle>Jun Gao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jian-yao/ class=align-middle>Jian Yao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhufeng-pan/ class=align-middle>Zhufeng Pan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kun-bai/ class=align-middle>Kun Bai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lianqiang-zhou/ class=align-middle>Lianqiang Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhaopeng-tu/ class=align-middle>Zhaopeng Tu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/heng-gong/ class=align-middle>Heng Gong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaocheng-feng/ class=align-middle>Xiaocheng Feng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bing-qin/ class=align-middle>Bing Qin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>