<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Xin Luna Dong - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Xin Luna</span> <span class=font-weight-bold>Dong</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Xin <span class=font-weight-normal>Dong</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.362.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--362 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.362 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.362/>AdaTag : Multi-Attribute Value Extraction from Product Profiles with Adaptive Decoding<span class=acl-fixed-case>A</span>da<span class=acl-fixed-case>T</span>ag: Multi-Attribute Value Extraction from Product Profiles with Adaptive Decoding</a></strong><br><a href=/people/j/jun-yan/>Jun Yan</a>
|
<a href=/people/n/nasser-zalmout/>Nasser Zalmout</a>
|
<a href=/people/y/yan-liang/>Yan Liang</a>
|
<a href=/people/c/christan-grant/>Christan Grant</a>
|
<a href=/people/x/xiang-ren/>Xiang Ren</a>
|
<a href=/people/x/xin-luna-dong/>Xin Luna Dong</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--362><div class="card-body p-3 small">Automatic extraction of product attribute values is an important enabling technology in <a href=https://en.wikipedia.org/wiki/E-commerce>e-Commerce platforms</a>. This <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a> is usually modeled using sequence labeling architectures, with several extensions to handle multi-attribute extraction. One line of previous work constructs attribute-specific models, through separate <a href=https://en.wikipedia.org/wiki/Code>decoders</a> or entirely separate models. However, this approach constrains <a href=https://en.wikipedia.org/wiki/Knowledge_sharing>knowledge sharing</a> across different attributes. Other contributions use a single multi-attribute model, with different techniques to embed <a href=https://en.wikipedia.org/wiki/Attribute_(computing)>attribute information</a>. But sharing the entire network parameters across all attributes can limit the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s capacity to capture attribute-specific characteristics. In this paper we present AdaTag, which uses adaptive decoding to handle <a href=https://en.wikipedia.org/wiki/Data_extraction>extraction</a>. We parameterize the decoder with pretrained attribute embeddings, through a hypernetwork and a Mixture-of-Experts (MoE) module. This allows for separate, but semantically correlated, <a href=https://en.wikipedia.org/wiki/Code>decoders</a> to be generated on the fly for different attributes. This approach facilitates <a href=https://en.wikipedia.org/wiki/Knowledge_sharing>knowledge sharing</a>, while maintaining the specificity of each attribute. Our experiments on a real-world e-Commerce dataset show marked improvements over previous methods.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.721.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--721 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.721 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929243 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.721/>ZeroShotCeres : Zero-Shot Relation Extraction from Semi-Structured Webpages<span class=acl-fixed-case>Z</span>ero<span class=acl-fixed-case>S</span>hot<span class=acl-fixed-case>C</span>eres: Zero-Shot Relation Extraction from Semi-Structured Webpages</a></strong><br><a href=/people/c/colin-lockard/>Colin Lockard</a>
|
<a href=/people/p/prashant-shiralkar/>Prashant Shiralkar</a>
|
<a href=/people/x/xin-luna-dong/>Xin Luna Dong</a>
|
<a href=/people/h/hannaneh-hajishirzi/>Hannaneh Hajishirzi</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--721><div class="card-body p-3 small">In many documents, such as semi-structured webpages, textual semantics are augmented with additional information conveyed using visual elements including <a href=https://en.wikipedia.org/wiki/Page_layout>layout</a>, <a href=https://en.wikipedia.org/wiki/Typeface>font size</a>, and <a href=https://en.wikipedia.org/wiki/Color>color</a>. Prior work on <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a> from semi-structured websites has required learning an extraction model specific to a given <a href=https://en.wikipedia.org/wiki/Web_template_system>template</a> via either manually labeled or distantly supervised data from that template. In this work, we propose a solution for zero-shot open-domain relation extraction from webpages with a previously unseen template, including from websites with little overlap with existing sources of knowledge for distant supervision and websites in entirely new subject verticals. Our model uses a graph neural network-based approach to build a rich representation of text fields on a <a href=https://en.wikipedia.org/wiki/Web_page>webpage</a> and the relationships between them, enabling generalization to new templates. Experiments show this approach provides a 31 % F1 gain over a baseline for zero-shot extraction in a new subject vertical.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1658.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1658 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1658 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1658/>A Robust Self-Learning Framework for Cross-Lingual Text Classification</a></strong><br><a href=/people/x/xin-luna-dong/>Xin Dong</a>
|
<a href=/people/g/gerard-de-melo/>Gerard de Melo</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1658><div class="card-body p-3 small">Based on massive amounts of data, recent pretrained contextual representation models have made significant strides in advancing a number of different English NLP tasks. However, for other languages, relevant training data may be lacking, while state-of-the-art deep learning methods are known to be data-hungry. In this paper, we present an elegantly simple robust self-learning framework to include unlabeled non-English samples in the fine-tuning process of pretrained multilingual representation models. We leverage a multilingual model&#8217;s own predictions on unlabeled non-English data in order to obtain additional information that can be used during further <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a>. Compared with original multilingual models and other cross-lingual classification models, we observe significant gains in effectiveness on document and sentiment classification for a range of diverse languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1309.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1309 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1309 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/355837778 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-1309/>OpenCeres : When <a href=https://en.wikipedia.org/wiki/Open_information_extraction>Open Information Extraction</a> Meets the Semi-Structured Web<span class=acl-fixed-case>O</span>pen<span class=acl-fixed-case>C</span>eres: <span class=acl-fixed-case>W</span>hen Open Information Extraction Meets the Semi-Structured Web</a></strong><br><a href=/people/c/colin-lockard/>Colin Lockard</a>
|
<a href=/people/p/prashant-shiralkar/>Prashant Shiralkar</a>
|
<a href=/people/x/xin-luna-dong/>Xin Luna Dong</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1309><div class="card-body p-3 small">Open Information Extraction (OpenIE), the problem of harvesting triples from natural language text whose predicate relations are not aligned to any pre-defined ontology, has been a popular subject of research for the last decade. However, this research has largely ignored the vast quantity of facts available in semi-structured webpages. In this paper, we define the problem of OpenIE from <a href=https://en.wikipedia.org/wiki/Semi-structured_model>semi-structured websites</a> to extract such facts, and present an approach for solving it. We also introduce a labeled evaluation dataset to motivate research in this area. Given a semi-structured website and a set of seed facts for some relations existing on its pages, we employ a semi-supervised label propagation technique to automatically create <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data</a> for the relations present on the site. We then use this <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data</a> to learn a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> for relation extraction. Experimental results of this method on our new benchmark dataset obtained a <a href=https://en.wikipedia.org/wiki/Precision_(statistics)>precision</a> of over 70 %. A larger scale extraction experiment on 31 websites in the movie vertical resulted in the extraction of over 2 million triples.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1024.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1024.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1024/>LinkNBed : Multi-Graph Representation Learning with Entity Linkage<span class=acl-fixed-case>L</span>ink<span class=acl-fixed-case>NB</span>ed: Multi-Graph Representation Learning with Entity Linkage</a></strong><br><a href=/people/r/rakshit-trivedi/>Rakshit Trivedi</a>
|
<a href=/people/b/bunyamin-sisman/>Bunyamin Sisman</a>
|
<a href=/people/x/xin-luna-dong/>Xin Luna Dong</a>
|
<a href=/people/c/christos-faloutsos/>Christos Faloutsos</a>
|
<a href=/people/j/jun-ma/>Jun Ma</a>
|
<a href=/people/h/hongyuan-zha/>Hongyuan Zha</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1024><div class="card-body p-3 small">Knowledge graphs have emerged as an important model for studying complex multi-relational data. This has given rise to the construction of numerous large scale but incomplete knowledge graphs encoding information extracted from various resources. An effective and scalable approach to jointly learn over multiple graphs and eventually construct a unified graph is a crucial next step for the success of knowledge-based inference for many downstream applications. To this end, we propose LinkNBed, a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity linkage</a> and build an efficient multi-task training procedure. Experiments on link prediction and <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity linkage</a> demonstrate substantial improvements over the state-of-the-art relational learning approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1235.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1235 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1235 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-1235/>A Helping Hand : <a href=https://en.wikipedia.org/wiki/Transfer_learning>Transfer Learning</a> for Deep Sentiment Analysis</a></strong><br><a href=/people/x/xin-luna-dong/>Xin Dong</a>
|
<a href=/people/g/gerard-de-melo/>Gerard de Melo</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1235><div class="card-body p-3 small">Deep convolutional neural networks excel at sentiment polarity classification, but tend to require substantial amounts of training data, which moreover differs quite significantly between domains. In this work, we present an approach to feed generic cues into the training process of such <a href=https://en.wikipedia.org/wiki/Neural_network>networks</a>, leading to better generalization abilities given limited training data. We propose to induce sentiment embeddings via supervision on extrinsic data, which are then fed into the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> via a dedicated memory-based component. We observe significant gains in effectiveness on a range of different <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> in seven different languages.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Xin+Luna+Dong" title="Search for 'Xin Luna Dong' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/c/colin-lockard/ class=align-middle>Colin Lockard</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/prashant-shiralkar/ class=align-middle>Prashant Shiralkar</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/g/gerard-de-melo/ class=align-middle>Gerard de Melo</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jun-yan/ class=align-middle>Jun Yan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nasser-zalmout/ class=align-middle>Nasser Zalmout</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/y/yan-liang/ class=align-middle>Yan Liang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christan-grant/ class=align-middle>Christan Grant</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiang-ren/ class=align-middle>Xiang Ren</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hannaneh-hajishirzi/ class=align-middle>Hannaneh Hajishirzi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rakshit-trivedi/ class=align-middle>Rakshit Trivedi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bunyamin-sisman/ class=align-middle>Bunyamin Sisman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christos-faloutsos/ class=align-middle>Christos Faloutsos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jun-ma/ class=align-middle>Jun Ma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hongyuan-zha/ class=align-middle>Hongyuan Zha</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>