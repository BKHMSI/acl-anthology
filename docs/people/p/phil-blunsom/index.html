<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Phil Blunsom - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Phil</span> <span class=font-weight-bold>Blunsom</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.536.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--536 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.536 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.536/>A Generative Framework for Simultaneous Machine Translation</a></strong><br><a href=/people/y/yishu-miao/>Yishu Miao</a>
|
<a href=/people/p/phil-blunsom/>Phil Blunsom</a>
|
<a href=/people/l/lucia-specia/>Lucia Specia</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--536><div class="card-body p-3 small">We propose a generative framework for simultaneous machine translation. Conventional approaches use a fixed number of source words to translate or learn dynamic policies for the number of source words by <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a>. Here we formulate <a href=https://en.wikipedia.org/wiki/Simultaneous_translation>simultaneous translation</a> as a structural sequence-to-sequence learning problem. A <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variable</a> is introduced to model read or translate actions at every time step, which is then integrated out to consider all the possible translation policies. A re-parameterised Poisson prior is used to regularise the policies which allows the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to explicitly balance translation quality and <a href=https://en.wikipedia.org/wiki/Latency_(engineering)>latency</a>. The experiments demonstrate the effectiveness and robustness of the generative framework, which achieves the best BLEU scores given different average translation latencies on benchmark datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.18.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--18 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.18 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.18" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.18/>Counterfactual Data Augmentation for Neural Machine Translation</a></strong><br><a href=/people/q/qi-liu/>Qi Liu</a>
|
<a href=/people/m/matt-kusner/>Matt Kusner</a>
|
<a href=/people/p/phil-blunsom/>Phil Blunsom</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--18><div class="card-body p-3 small">We propose a data augmentation method for <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>. It works by interpreting <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> and phrasal alignment causally. Specifically, it creates augmented parallel translation corpora by generating (path-specific) counterfactual aligned phrases. We generate these by sampling new source phrases from a masked language model, then sampling an aligned counterfactual target phrase by noting that a translation language model can be interpreted as a Gumbel-Max Structural Causal Model (Oberst and Sontag, 2019). Compared to previous work, our method takes both <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context</a> and <a href=https://en.wikipedia.org/wiki/Sequence_alignment>alignment</a> into account to maintain the <a href=https://en.wikipedia.org/wiki/Symmetry>symmetry</a> between source and target sequences. Experiments on IWSLT&#8217;15 English Vietnamese, WMT&#8217;17 English German, WMT&#8217;18 English Turkish, and WMT&#8217;19 robust English French show that the method can improve the performance of <a href=https://en.wikipedia.org/wiki/Translation>translation</a>, backtranslation and <a href=https://en.wikipedia.org/wiki/Translation>translation robustness</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1439.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1439 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1439 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1439.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1439" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1439/>WikiCREM : A Large Unsupervised Corpus for <a href=https://en.wikipedia.org/wiki/Coreference_resolution>Coreference Resolution</a><span class=acl-fixed-case>W</span>iki<span class=acl-fixed-case>CREM</span>: A Large Unsupervised Corpus for Coreference Resolution</a></strong><br><a href=/people/v/vid-kocijan/>Vid Kocijan</a>
|
<a href=/people/o/oana-maria-camburu/>Oana-Maria Camburu</a>
|
<a href=/people/a/ana-maria-cretu/>Ana-Maria Cretu</a>
|
<a href=/people/y/yordan-yordanov/>Yordan Yordanov</a>
|
<a href=/people/p/phil-blunsom/>Phil Blunsom</a>
|
<a href=/people/t/thomas-lukasiewicz/>Thomas Lukasiewicz</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1439><div class="card-body p-3 small">Pronoun resolution is a major area of <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a>. However, large-scale training sets are still scarce, since manually labelling data is costly. In this work, we introduce WikiCREM (Wikipedia CoREferences Masked) a large-scale, yet accurate dataset of pronoun disambiguation instances. We use a language-model-based approach for pronoun resolution in combination with our WikiCREM dataset. We compare a series of models on a collection of diverse and challenging coreference resolution problems, where we match or outperform previous state-of-the-art approaches on 6 out of 7 datasets, such as GAP, DPR, WNLI, PDP, WinoBias, and WinoGender. We release our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to be used off-the-shelf for solving pronoun disambiguation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1645.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1645 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1645 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1645/>Learning to Discover, Ground and Use Words with Segmental Neural Language Models</a></strong><br><a href=/people/k/kazuya-kawakami/>Kazuya Kawakami</a>
|
<a href=/people/c/chris-dyer/>Chris Dyer</a>
|
<a href=/people/p/phil-blunsom/>Phil Blunsom</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1645><div class="card-body p-3 small">We propose a segmental neural language model that combines the generalization power of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> with the ability to discover word-like units that are latent in unsegmented character sequences. In contrast to previous segmentation models that treat <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a> as an isolated task, our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> unifies word discovery, learning how words fit together to form sentences, and, by conditioning the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> on visual context, how words&#8217; meanings ground in representations of nonlinguistic modalities. Experiments show that the unconditional model learns predictive distributions better than character LSTM models, discovers words competitively with nonparametric Bayesian word segmentation models, and that modeling language conditional on visual context improves performance on both.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1023.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1023 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1023 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285804931 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1023/>The NarrativeQA Reading Comprehension Challenge<span class=acl-fixed-case>N</span>arrative<span class=acl-fixed-case>QA</span> Reading Comprehension Challenge</a></strong><br><a href=/people/t/tomas-kocisky/>Tomáš Kočiský</a>
|
<a href=/people/j/jonathan-schwarz/>Jonathan Schwarz</a>
|
<a href=/people/p/phil-blunsom/>Phil Blunsom</a>
|
<a href=/people/c/chris-dyer/>Chris Dyer</a>
|
<a href=/people/k/karl-moritz-hermann/>Karl Moritz Hermann</a>
|
<a href=/people/g/gabor-melis/>Gábor Melis</a>
|
<a href=/people/e/edward-grefenstette/>Edward Grefenstette</a><br><a href=/volumes/Q18-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 6</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1023><div class="card-body p-3 small">Reading comprehension (RC)in contrast to information retrievalrequires integrating information and reasoning about events, <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entities</a>, and their relations across a full document. Question answering is conventionally used to assess RC ability, in both <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>artificial agents</a> and children learning to read. However, existing RC datasets and <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> are dominated by questions that can be solved by selecting answers using superficial information (e.g., local context similarity or global term frequency) ; they thus fail to test for the essential integrative aspect of RC. To encourage progress on deeper comprehension of language, we present a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and set of <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> in which the reader must answer questions about stories by reading entire books or <a href=https://en.wikipedia.org/wiki/Screenplay>movie scripts</a>. These tasks are designed so that successfully answering their questions requires understanding the underlying narrative rather than relying on shallow pattern matching or <a href=https://en.wikipedia.org/wiki/Salience_(neuroscience)>salience</a>. We show that although humans solve the <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a> easily, standard RC models struggle on the <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a> presented here. We provide an analysis of the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and the challenges it presents.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1086.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1086 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1086 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1086/>Neural Syntactic Generative Models with Exact Marginalization</a></strong><br><a href=/people/j/jan-buys/>Jan Buys</a>
|
<a href=/people/p/phil-blunsom/>Phil Blunsom</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1086><div class="card-body p-3 small">We present neural syntactic generative models with exact marginalization that support both <a href=https://en.wikipedia.org/wiki/Dependency_grammar>dependency parsing</a> and <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>. Exact marginalization is made tractable through <a href=https://en.wikipedia.org/wiki/Dynamic_programming>dynamic programming</a> over <a href=https://en.wikipedia.org/wiki/Shift-reduce>shift-reduce parsing</a> and minimal RNN-based feature sets. Our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> complement previous approaches by supporting batched training and enabling online computation of next word probabilities. For supervised dependency parsing, our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> achieves a state-of-the-art result among generative approaches. We also report empirical results on unsupervised syntactic models and their role in <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>. We find that our model formulation of latent dependencies with exact marginalization do not lead to better intrinsic language modeling performance than vanilla RNNs, and that parsing accuracy is not correlated with language modeling perplexity in stack-based models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1132.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1132 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1132 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1132.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285803729 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1132/>LSTMs Can Learn Syntax-Sensitive Dependencies Well, But <a href=https://en.wikipedia.org/wiki/Structure_(mathematical_logic)>Modeling Structure</a> Makes Them Better<span class=acl-fixed-case>LSTM</span>s Can Learn Syntax-Sensitive Dependencies Well, But Modeling Structure Makes Them Better</a></strong><br><a href=/people/a/adhiguna-kuncoro/>Adhiguna Kuncoro</a>
|
<a href=/people/c/chris-dyer/>Chris Dyer</a>
|
<a href=/people/j/john-hale/>John Hale</a>
|
<a href=/people/d/dani-yogatama/>Dani Yogatama</a>
|
<a href=/people/s/stephen-clark/>Stephen Clark</a>
|
<a href=/people/p/phil-blunsom/>Phil Blunsom</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1132><div class="card-body p-3 small">Language exhibits hierarchical structure, but recent work using a subject-verb agreement diagnostic argued that state-of-the-art language models, LSTMs, fail to learn long-range syntax sensitive dependencies. Using the same diagnostic, we show that, in fact, LSTMs do succeed in learning such dependenciesprovided they have enough capacity. We then explore whether <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> that have access to explicit syntactic information learn <a href=https://en.wikipedia.org/wiki/Agreement_(linguistics)>agreement</a> more effectively, and how the way in which this structural information is incorporated into the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> impacts performance. We find that the mere presence of syntactic information does not improve <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, but when model architecture is determined by <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a>, <a href=https://en.wikipedia.org/wiki/Agreement_(linguistics)>number agreement</a> is improved. Further, we find that the choice of how syntactic structure is built affects how well <a href=https://en.wikipedia.org/wiki/Agreement_(linguistics)>number agreement</a> is learned : <a href=https://en.wikipedia.org/wiki/Top-down_and_bottom-up_design>top-down construction</a> outperforms <a href=https://en.wikipedia.org/wiki/Top-down_and_bottom-up_design>left-corner and bottom-up variants</a> in capturing non-local structural dependencies.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1112.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1112 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1112 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P17-1112" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P17-1112/>Robust Incremental Neural Semantic Graph Parsing</a></strong><br><a href=/people/j/jan-buys/>Jan Buys</a>
|
<a href=/people/p/phil-blunsom/>Phil Blunsom</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1112><div class="card-body p-3 small">Parsing sentences to linguistically-expressive semantic representations is a key goal of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a>. Yet <a href=https://en.wikipedia.org/wiki/Statistical_parsing>statistical parsing</a> has focussed almost exclusively on bilexical dependencies or domain-specific logical forms. We propose a neural encoder-decoder transition-based parser which is the first full-coverage semantic graph parser for Minimal Recursion Semantics (MRS). The model architecture uses stack-based embedding features, predicting graphs jointly with <a href=https://en.wikipedia.org/wiki/Lexical_analysis>unlexicalized predicates</a> and their <a href=https://en.wikipedia.org/wiki/Lexical_analysis>token alignments</a>. Our <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> is more accurate than attention-based baselines on MRS, and on an additional Abstract Meaning Representation (AMR) benchmark, and GPU batch processing makes it an order of magnitude faster than a high-precision grammar-based parser. Further, the 86.69 % Smatch score of our MRS parser is higher than the upper-bound on AMR parsing, making MRS an attractive choice as a semantic representation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1137.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1137 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1137 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-1137.Datasets.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1137/>Learning to Create and Reuse Words in Open-Vocabulary Neural Language Modeling</a></strong><br><a href=/people/k/kazuya-kawakami/>Kazuya Kawakami</a>
|
<a href=/people/c/chris-dyer/>Chris Dyer</a>
|
<a href=/people/p/phil-blunsom/>Phil Blunsom</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1137><div class="card-body p-3 small">Fixed-vocabulary language models fail to account for one of the most characteristic statistical facts of <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a> : the frequent creation and reuse of new word types. Although character-level language models offer a partial solution in that they can create word types not attested in the training corpus, they do not capture the bursty distribution of such words. In this paper, we augment a hierarchical LSTM language model that generates sequences of word tokens character by character with a caching mechanism that learns to reuse previously generated words. To validate our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> we construct a new open-vocabulary language modeling corpus (the Multilingual Wikipedia Corpus ; MWC) from comparable Wikipedia articles in 7 typologically diverse languages and demonstrate the effectiveness of our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> across this range of languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2600.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2600/>Proceedings of the 2nd Workshop on Representation Learning for <span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/p/phil-blunsom/>Phil Blunsom</a>
|
<a href=/people/a/antoine-bordes/>Antoine Bordes</a>
|
<a href=/people/k/kyunghyun-cho/>Kyunghyun Cho</a>
|
<a href=/people/s/shay-b-cohen/>Shay Cohen</a>
|
<a href=/people/c/chris-dyer/>Chris Dyer</a>
|
<a href=/people/e/edward-grefenstette/>Edward Grefenstette</a>
|
<a href=/people/k/karl-moritz-hermann/>Karl Moritz Hermann</a>
|
<a href=/people/l/laura-rimell/>Laura Rimell</a>
|
<a href=/people/j/jason-weston/>Jason Weston</a>
|
<a href=/people/s/scott-yih/>Scott Yih</a><br><a href=/volumes/W17-26/ class=text-muted>Proceedings of the 2nd Workshop on Representation Learning for NLP</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1197.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1197 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1197 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D17-1197.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1197/>Reference-Aware Language Models</a></strong><br><a href=/people/z/zichao-yang/>Zichao Yang</a>
|
<a href=/people/p/phil-blunsom/>Phil Blunsom</a>
|
<a href=/people/c/chris-dyer/>Chris Dyer</a>
|
<a href=/people/w/wang-ling/>Wang Ling</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1197><div class="card-body p-3 small">We propose a general class of <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> that treat <a href=https://en.wikipedia.org/wiki/Reference>reference</a> as discrete stochastic latent variables. This decision allows for the creation of entity mentions by accessing external databases of referents (required by, e.g., dialogue generation) or past internal state (required to explicitly model coreferentiality). Beyond simple copying, our coreference model can additionally refer to a referent using <a href=https://en.wikipedia.org/wiki/Variation_(linguistics)>varied mention forms</a> (e.g., a reference to Jane can be realized as she), a characteristic feature of reference in <a href=https://en.wikipedia.org/wiki/Natural_language>natural languages</a>. Experiments on three representative applications show our model variants outperform models based on deterministic attention and standard language modeling baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-1000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-1000/>Proceedings of the 15th Conference of the <span class=acl-fixed-case>E</span>uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</a></strong><br><a href=/people/m/mirella-lapata/>Mirella Lapata</a>
|
<a href=/people/p/phil-blunsom/>Phil Blunsom</a>
|
<a href=/people/a/alexander-koller/>Alexander Koller</a><br><a href=/volumes/E17-1/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-2000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-2000/>Proceedings of the 15th Conference of the <span class=acl-fixed-case>E</span>uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</a></strong><br><a href=/people/m/mirella-lapata/>Mirella Lapata</a>
|
<a href=/people/p/phil-blunsom/>Phil Blunsom</a>
|
<a href=/people/a/alexander-koller/>Alexander Koller</a><br><a href=/volumes/E17-2/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</a></span></p></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Phil+Blunsom" title="Search for 'Phil Blunsom' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/c/chris-dyer/ class=align-middle>Chris Dyer</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/j/jan-buys/ class=align-middle>Jan Buys</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/kazuya-kawakami/ class=align-middle>Kazuya Kawakami</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/edward-grefenstette/ class=align-middle>Edward Grefenstette</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/karl-moritz-hermann/ class=align-middle>Karl Moritz Hermann</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/m/mirella-lapata/ class=align-middle>Mirella Lapata</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/alexander-koller/ class=align-middle>Alexander Koller</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/antoine-bordes/ class=align-middle>Antoine Bordes</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kyunghyun-cho/ class=align-middle>Kyunghyun Cho</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shay-b-cohen/ class=align-middle>Shay B. Cohen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/laura-rimell/ class=align-middle>Laura Rimell</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jason-weston/ class=align-middle>Jason Weston</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/scott-yih/ class=align-middle>Scott Yih</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yishu-miao/ class=align-middle>Yishu Miao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lucia-specia/ class=align-middle>Lucia Specia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vid-kocijan/ class=align-middle>Vid Kocijan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/oana-maria-camburu/ class=align-middle>Oana-Maria Camburu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ana-maria-cretu/ class=align-middle>Ana-Maria Cretu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yordan-yordanov/ class=align-middle>Yordan Yordanov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thomas-lukasiewicz/ class=align-middle>Thomas Lukasiewicz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tomas-kocisky/ class=align-middle>Tomáš Kočiský</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jonathan-schwarz/ class=align-middle>Jonathan Schwarz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gabor-melis/ class=align-middle>Gábor Melis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zichao-yang/ class=align-middle>Zichao Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wang-ling/ class=align-middle>Wang Ling</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qi-liu/ class=align-middle>Qi Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/matt-kusner/ class=align-middle>Matt Kusner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/adhiguna-kuncoro/ class=align-middle>Adhiguna Kuncoro</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/john-hale/ class=align-middle>John Hale</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dani-yogatama/ class=align-middle>Dani Yogatama</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stephen-clark/ class=align-middle>Stephen Clark</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/tacl/ class=align-middle>TACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>