<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Piek Vossen - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Piek</span> <span class=font-weight-bold>Vossen</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.iwcs-1.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--iwcs-1--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.iwcs-1.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.iwcs-1.22" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.iwcs-1.22/>Variation in framing as a function of temporal reporting distance</a></strong><br><a href=/people/l/levi-remijnse/>Levi Remijnse</a>
|
<a href=/people/m/marten-postma/>Marten Postma</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a><br><a href=/volumes/2021.iwcs-1/ class=text-muted>Proceedings of the 14th International Conference on Computational Semantics (IWCS)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--iwcs-1--22><div class="card-body p-3 small">In this paper, we measure variation in <a href=https://en.wikipedia.org/wiki/Framing_(social_sciences)>framing</a> as a function of <a href=https://en.wikipedia.org/wiki/Framing_(social_sciences)>foregrounding</a> and <a href=https://en.wikipedia.org/wiki/Framing_(social_sciences)>backgrounding</a> in a co-referential corpus with a range of temporal distance. In one type of experiment, frame-annotated corpora grouped under event types were contrasted, resulting in a ranking of frames with typicality rates. In contrasting between publication dates, a different ranking of frames emerged for documents that are close to or far from the event instance. In the second type of analysis, we trained a diagnostic classifier with frame occurrences in order to let it differentiate documents based on their temporal distance class (close to or far from the event instance). The <a href=https://en.wikipedia.org/wiki/Classifier_(linguistics)>classifier</a> performs above chance and outperforms <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> with words.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.latechclfl-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--latechclfl-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.latechclfl-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.latechclfl-1.3/>Batavia asked for advice. Pretrained language models for <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a> in historical texts.</a></strong><br><a href=/people/s/sophie-i-arnoult/>Sophie I. Arnoult</a>
|
<a href=/people/l/lodewijk-petram/>Lodewijk Petram</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a><br><a href=/volumes/2021.latechclfl-1/ class=text-muted>Proceedings of the 5th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--latechclfl-1--3><div class="card-body p-3 small">Pretrained language models like <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> have advanced the state of the art for many NLP tasks. For resource-rich languages, one has the choice between a number of language-specific models, while multilingual models are also worth considering. These <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> are well known for their crosslingual performance, but have also shown competitive in-language performance on some tasks. We consider monolingual and multilingual models from the perspective of historical texts, and in particular for <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>texts</a> enriched with editorial notes : how do language models deal with the historical and editorial content in these texts? We present a new Named Entity Recognition dataset for <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a> based on 17th and 18th century United East India Company (VOC) reports extended with modern editorial notes. Our experiments with multilingual and Dutch pretrained language models confirm the crosslingual abilities of multilingual models while showing that all <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> can leverage mixed-variant data. In particular, <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> successfully incorporate <a href=https://en.wikipedia.org/wiki/Note_(typography)>notes</a> for the prediction of entities in <a href=https://en.wikipedia.org/wiki/History>historical texts</a>. We also find that multilingual models outperform monolingual models on our data, but that this superiority is linked to the task at hand : multilingual models lose their advantage when confronted with more semantical tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mmsr-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mmsr-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mmsr-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.mmsr-1.6" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.mmsr-1.6/>EMISSOR : A platform for capturing multimodal interactions as Episodic Memories and Interpretations with Situated Scenario-based Ontological References<span class=acl-fixed-case>EMISSOR</span>: A platform for capturing multimodal interactions as Episodic Memories and Interpretations with Situated Scenario-based Ontological References</a></strong><br><a href=/people/s/selene-baez-santamaria/>Selene Baez Santamaria</a>
|
<a href=/people/t/thomas-baier/>Thomas Baier</a>
|
<a href=/people/t/taewoon-kim/>Taewoon Kim</a>
|
<a href=/people/l/lea-krause/>Lea Krause</a>
|
<a href=/people/j/jaap-kruijt/>Jaap Kruijt</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a><br><a href=/volumes/2021.mmsr-1/ class=text-muted>Proceedings of the 1st Workshop on Multimodal Semantic Representations (MMSR)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mmsr-1--6><div class="card-body p-3 small">We present EMISSOR : a platform to capture multimodal interactions as recordings of episodic experiences with explicit referential interpretations that also yield an episodic Knowledge Graph (eKG). The <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a> stores streams of multiple modalities as <a href=https://en.wikipedia.org/wiki/Parallel_communication>parallel signals</a>. Each signal is segmented and annotated independently with interpretation. Annotations are eventually mapped to explicit identities and relations in the <a href=https://en.wikipedia.org/wiki/Electrocardiography>eKG</a>. As we ground signal segments from different modalities to the same instance representations, we also ground different modalities across each other. Unique to our <a href=https://en.wikipedia.org/wiki/Electrocardiography>eKG</a> is that it accepts different interpretations across modalities, sources and experiences and supports reasoning over conflicting information and uncertainties that may result from multimodal experiences. EMISSOR can record and annotate experiments in virtual and real-world, combine data, evaluate system behavior and their performance for preset goals but also model the accumulation of knowledge and interpretations in the Knowledge Graph as a result of these episodic experiences.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.gwc-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.gwc-1.0/>Proceedings of the 11th Global Wordnet Conference</a></strong><br><a href=/people/p/piek-vossen/>Piek Vossen</a>
|
<a href=/people/c/christiane-fellbaum/>Christiane Fellbaum</a><br><a href=/volumes/2021.gwc-1/ class=text-muted>Proceedings of the 11th Global Wordnet Conference</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.611.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--611 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.611 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.611/>Annotating Perspectives on Vaccination</a></strong><br><a href=/people/r/roser-morante/>Roser Morante</a>
|
<a href=/people/c/chantal-van-son/>Chantal van Son</a>
|
<a href=/people/i/isa-maks/>Isa Maks</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--611><div class="card-body p-3 small">In this paper we present the Vaccination Corpus, a corpus of texts related to the online vaccination debate that has been annotated with three layers of information about perspectives : attribution, claims and opinions. Additionally, events related to the vaccination debate are also annotated. The <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> contains 294 documents from the Internet which reflect different views on vaccinations. It has been compiled to study the language of online debates, with the final goal of experimenting with methodologies to extract and contrast perspectives in the framework of the vaccination debate.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.gwc-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.gwc-1.0/>Proceedings of the 10th Global Wordnet Conference</a></strong><br><a href=/people/p/piek-vossen/>Piek Vossen</a>
|
<a href=/people/c/christiane-fellbaum/>Christiane Fellbaum</a><br><a href=/volumes/2019.gwc-1/ class=text-muted>Proceedings of the 10th Global Wordnet Conference</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.gwc-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--gwc-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.gwc-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.gwc-1.12/>Towards interpretable, data-derived distributional meaning representations for <a href=https://en.wikipedia.org/wiki/Reason>reasoning</a> : A dataset of properties and concepts</a></strong><br><a href=/people/p/pia-sommerauer/>Pia Sommerauer</a>
|
<a href=/people/a/antske-fokkens/>Antske Fokkens</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a><br><a href=/volumes/2019.gwc-1/ class=text-muted>Proceedings of the 10th Global Wordnet Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--gwc-1--12><div class="card-body p-3 small">This paper proposes a <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> for investigating which types of <a href=https://en.wikipedia.org/wiki/Semantic_property>semantic properties</a> are represented by <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distributional data</a>. The core of our <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> consists of relations between concepts and properties. We provide hypotheses on which <a href=https://en.wikipedia.org/wiki/Property_(philosophy)>properties</a> are reflected in <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distributional data</a> or not based on the type of relation. We outline strategies for creating a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of positive and negative examples for various semantic properties, which can not easily be separated on the basis of general similarity (e.g. fly : seagull, penguin). This way, a <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distributional model</a> can only distinguish between positive and negative examples through evidence for a target property. Once completed, this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> can be used to test our hypotheses and work towards data-derived interpretable representations.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1056.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1056 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1056 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-1056/>Systematic Study of Long Tail Phenomena in Entity Linking</a></strong><br><a href=/people/f/filip-ilievski/>Filip Ilievski</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a>
|
<a href=/people/s/stefan-schlobach/>Stefan Schlobach</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1056><div class="card-body p-3 small">State-of-the-art entity linkers achieve high accuracy scores with probabilistic methods. However, these <a href=https://en.wikipedia.org/wiki/Score_(statistics)>scores</a> should be considered in relation to the properties of the datasets they are evaluated on. Until now, there has not been a systematic investigation of the properties of entity linking datasets and their impact on system performance. In this paper we report on a series of hypotheses regarding the long tail phenomena in entity linking datasets, their interaction, and their impact on <a href=https://en.wikipedia.org/wiki/System>system</a> performance. Our systematic study of these hypotheses shows that evaluation datasets mainly capture head entities and only incidentally cover data from the tail, thus encouraging systems to overfit to popular / frequent and non-ambiguous cases. We find the most difficult cases of <a href=https://en.wikipedia.org/wiki/Entity_linking>entity linking</a> among the infrequent candidates of ambiguous forms. With our findings, we hope to inspire future designs of both <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity linking systems</a> and <a href=https://en.wikipedia.org/wiki/Data_set>evaluation datasets</a>. To support this goal, we provide a list of recommended actions for better inclusion of tail cases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1147.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1147 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1147 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=C18-1147" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/C18-1147/>Measuring the Diversity of Automatic Image Descriptions</a></strong><br><a href=/people/e/emiel-van-miltenburg/>Emiel van Miltenburg</a>
|
<a href=/people/d/desmond-elliott/>Desmond Elliott</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1147><div class="card-body p-3 small">Automatic image description systems typically produce generic sentences that only make use of a small subset of the vocabulary available to them. In this paper, we consider the production of generic descriptions as a lack of diversity in the output, which we quantify using established <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> and two new <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> that frame image description as a word recall task. This framing allows us to evaluate <a href=https://en.wikipedia.org/wiki/System>system</a> performance on the head of the vocabulary, as well as on the long tail, where <a href=https://en.wikipedia.org/wiki/System>system</a> performance degrades. We use these <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> to examine the <a href=https://en.wikipedia.org/wiki/Diversity_index>diversity</a> of the sentences generated by nine state-of-the-art systems on the MS COCO data set. We find that the systems trained with maximum likelihood objectives produce less diverse output than those trained with additional adversarial objectives. However, the adversarially-trained models only produce more types from the head of the vocabulary and not the tail. Besides vocabulary-based methods, we also look at the compositional capacity of the systems, specifically their ability to create <a href=https://en.wikipedia.org/wiki/Compound_(linguistics)>compound nouns</a> and <a href=https://en.wikipedia.org/wiki/Preposition_and_postposition>prepositional phrases</a> of different lengths. We conclude that there is still much room for improvement, and offer a toolkit to measure progress towards the goal of generating more diverse image descriptions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1191.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1191 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1191 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=C18-1191" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/C18-1191/>Scoring and Classifying Implicit Positive Interpretations : A Challenge of Class Imbalance</a></strong><br><a href=/people/c/chantal-van-son/>Chantal van Son</a>
|
<a href=/people/r/roser-morante/>Roser Morante</a>
|
<a href=/people/l/lora-aroyo/>Lora Aroyo</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1191><div class="card-body p-3 small">This paper reports on a reimplementation of a <a href=https://en.wikipedia.org/wiki/System>system</a> on detecting implicit positive meaning from negated statements. In the original <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression</a> experiment, different positive interpretations per negation are scored according to their likelihood. We convert the scores to classes and report our results on both the regression and classification tasks. We show that a baseline taking the mean score or most frequent class is hard to beat because of class imbalance in the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. Our error analysis indicates that an approach that takes the <a href=https://en.wikipedia.org/wiki/Information_structure>information structure</a> into account (i.e. which information is new or contrastive) may be promising, which requires looking beyond the syntactic and semantic characteristics of negated statements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.gwc-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2018.gwc-1.0/>Proceedings of the 9th Global Wordnet Conference</a></strong><br><a href=/people/f/francis-bond/>Francis Bond</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a>
|
<a href=/people/c/christiane-fellbaum/>Christiane Fellbaum</a><br><a href=/volumes/2018.gwc-1/ class=text-muted>Proceedings of the 9th Global Wordnet Conference</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1108.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1108 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1108 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1108/>NewsReader at SemEval-2018 Task 5 : Counting events by reasoning over event-centric-knowledge-graphs<span class=acl-fixed-case>N</span>ews<span class=acl-fixed-case>R</span>eader at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 5: Counting events by reasoning over event-centric-knowledge-graphs</a></strong><br><a href=/people/p/piek-vossen/>Piek Vossen</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1108><div class="card-body p-3 small">In this paper, we describe the participation of the NewsReader system in the SemEval-2018 Task 5 on Counting Events and Participants in the Long Tail. NewsReader is a generic <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised text processing system</a> that detects events with participants, time and place to generate Event Centric Knowledge Graphs (ECKGs). We minimally adapted these ECKGs to establish a baseline performance for the <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>. We first use the ECKGs to establish which documents report on the same incident and what event mentions are coreferential. Next, we aggregate ECKGs across coreferential mentions and use the aggregated knowledge to answer the questions of the task. Our participation tests the quality of NewsReader to create ECKGs, as well as the potential of ECKGs to establish event identity and reason over the result to answer the task queries.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1154.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1154 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1154 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1154/>Meaning_space at SemEval-2018 Task 10 : Combining explicitly encoded knowledge with information extracted from word embeddings<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 10: Combining explicitly encoded knowledge with information extracted from word embeddings</a></strong><br><a href=/people/p/pia-sommerauer/>Pia Sommerauer</a>
|
<a href=/people/a/antske-fokkens/>Antske Fokkens</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1154><div class="card-body p-3 small">This paper presents the two systems submitted by the meaning space team in Task 10 of the SemEval competition 2018 entitled Capturing discriminative attributes. The systems consist of combinations of approaches exploiting explicitly encoded knowledge about concepts in <a href=https://en.wikipedia.org/wiki/WordNet>WordNet</a> and information encoded in distributional semantic vectors. Rather than aiming for high performance, we explore which kind of <a href=https://en.wikipedia.org/wiki/Semantic_property>semantic knowledge</a> is best captured by different methods. The results indicate that WordNet glosses on different levels of the <a href=https://en.wikipedia.org/wiki/Hierarchy>hierarchy</a> capture many attributes relevant for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. In combination with exploiting word embedding similarities, this source of information yielded our best results. Our best performing <a href=https://en.wikipedia.org/wiki/System>system</a> ranked 5th out of 13 final ranks. Our analysis yields insights into the different kinds of attributes represented by different sources of knowledge.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-4300.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-4300/>Proceedings of the Workshop Events and Stories in the News 2018</a></strong><br><a href=/people/t/tommaso-caselli/>Tommaso Caselli</a>
|
<a href=/people/b/ben-miller/>Ben Miller</a>
|
<a href=/people/m/marieke-van-erp/>Marieke van Erp</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a>
|
<a href=/people/t/teruko-mitamura/>Teruko Mitamura</a>
|
<a href=/people/d/david-caswell/>David Caswell</a>
|
<a href=/people/s/susan-windisch-brown/>Susan W. Brown</a>
|
<a href=/people/c/claire-bonial/>Claire Bonial</a><br><a href=/volumes/W18-43/ class=text-muted>Proceedings of the Workshop Events and Stories in the News 2018</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6550.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6550 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6550 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-6550" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-6550/>Talking about other people : an endless range of possibilities</a></strong><br><a href=/people/e/emiel-van-miltenburg/>Emiel van Miltenburg</a>
|
<a href=/people/d/desmond-elliott/>Desmond Elliott</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a><br><a href=/volumes/W18-65/ class=text-muted>Proceedings of the 11th International Conference on Natural Language Generation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6550><div class="card-body p-3 small">Image description datasets, such as Flickr30 K and MS COCO, show a high degree of variation in the ways that crowd-workers talk about the world. Although this gives us a rich and diverse collection of data to work with, it also introduces uncertainty about how the world should be described. This paper shows the extent of this <a href=https://en.wikipedia.org/wiki/Uncertainty>uncertainty</a> in the PEOPLE-domain. We present a <a href=https://en.wikipedia.org/wiki/Taxonomy_(general)>taxonomy</a> of different ways to talk about other people. This <a href=https://en.wikipedia.org/wiki/Taxonomy_(biology)>taxonomy</a> serves as a reference point to think about how other people should be described, and can be used to classify and compute statistics about labels applied to people.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2700.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2700/>Proceedings of the Events and Stories in the News Workshop</a></strong><br><a href=/people/t/tommaso-caselli/>Tommaso Caselli</a>
|
<a href=/people/b/ben-miller/>Ben Miller</a>
|
<a href=/people/m/marieke-van-erp/>Marieke van Erp</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a>
|
<a href=/people/t/teruko-mitamura/>Teruko Mitamura</a>
|
<a href=/people/d/david-caswell/>David Caswell</a><br><a href=/volumes/W17-27/ class=text-muted>Proceedings of the Events and Stories in the News Workshop</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2711.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2711 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2711 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2711/>The Event StoryLine Corpus : A New Benchmark for Causal and Temporal Relation Extraction<span class=acl-fixed-case>S</span>tory<span class=acl-fixed-case>L</span>ine Corpus: A New Benchmark for Causal and Temporal Relation Extraction</a></strong><br><a href=/people/t/tommaso-caselli/>Tommaso Caselli</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a><br><a href=/volumes/W17-27/ class=text-muted>Proceedings of the Events and Stories in the News Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2711><div class="card-body p-3 small">This paper reports on the Event StoryLine Corpus (ESC) v1.0, a new benchmark dataset for the temporal and causal relation detection. By developing this dataset, we also introduce a new task, the StoryLine Extraction from news data, which aims at extracting and classifying events relevant for stories, from across news documents spread in time and clustered around a single seminal event or topic. In addition to describing the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, we also report on three baselines systems whose results show the <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a> of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> and suggest directions for the development of more robust systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4207.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4207 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4207 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4207/>Storyteller : Visual Analytics of Perspectives on Rich Text Interpretations<span class=acl-fixed-case>S</span>toryteller: Visual Analytics of Perspectives on Rich Text Interpretations</a></strong><br><a href=/people/m/maarten-van-meersbergen/>Maarten van Meersbergen</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a>
|
<a href=/people/j/janneke-van-der-zwaan/>Janneke van der Zwaan</a>
|
<a href=/people/a/antske-fokkens/>Antske Fokkens</a>
|
<a href=/people/w/willem-robert-van-hage/>Willem van Hage</a>
|
<a href=/people/i/inger-leemans/>Inger Leemans</a>
|
<a href=/people/i/isa-maks/>Isa Maks</a><br><a href=/volumes/W17-42/ class=text-muted>Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4207><div class="card-body p-3 small">Complexity of <a href=https://en.wikipedia.org/wiki/Event_data>event data</a> in texts makes it difficult to assess its content, especially when considering larger collections in which different sources report on the same or similar situations. We present a system that makes it possible to visually analyze complex event and emotion data extracted from texts. We show that we can abstract from different data models for events and emotions to a single <a href=https://en.wikipedia.org/wiki/Data_model>data model</a> that can show the complex relations in four dimensions. The <a href=https://en.wikipedia.org/wiki/Visualization_(graphics)>visualization</a> has been applied to analyze 1) dynamic developments in how people both conceive and express emotions in theater plays and 2) how stories are told from the perspectyive of their sources based on rich event data extracted from news or biographies.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Piek+Vossen" title="Search for 'Piek Vossen' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/t/tommaso-caselli/ class=align-middle>Tommaso Caselli</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/antske-fokkens/ class=align-middle>Antske Fokkens</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/c/christiane-fellbaum/ class=align-middle>Christiane Fellbaum</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/e/emiel-van-miltenburg/ class=align-middle>Emiel Van Miltenburg</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/desmond-elliott/ class=align-middle>Desmond Elliott</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/c/chantal-van-son/ class=align-middle>Chantal van Son</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/roser-morante/ class=align-middle>Roser Morante</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/ben-miller/ class=align-middle>Ben Miller</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/marieke-van-erp/ class=align-middle>Marieke van Erp</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/martha-palmer/ class=align-middle>Martha Palmer</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/eduard-hovy/ class=align-middle>Eduard Hovy</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/teruko-mitamura/ class=align-middle>Teruko Mitamura</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/david-caswell/ class=align-middle>David Caswell</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/i/isa-maks/ class=align-middle>Isa Maks</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/pia-sommerauer/ class=align-middle>Pia Sommerauer</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/f/filip-ilievski/ class=align-middle>Filip Ilievski</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stefan-schlobach/ class=align-middle>Stefan Schlobach</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lora-aroyo/ class=align-middle>Lora Aroyo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maarten-van-meersbergen/ class=align-middle>Maarten van Meersbergen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/janneke-van-der-zwaan/ class=align-middle>Janneke van der Zwaan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/willem-robert-van-hage/ class=align-middle>Willem Robert van Hage</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/inger-leemans/ class=align-middle>Inger Leemans</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/francis-bond/ class=align-middle>Francis Bond.</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/levi-remijnse/ class=align-middle>Levi Remijnse</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marten-postma/ class=align-middle>Marten Postma</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sophie-i-arnoult/ class=align-middle>Sophie I. Arnoult</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lodewijk-petram/ class=align-middle>Lodewijk Petram</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/susan-windisch-brown/ class=align-middle>Susan Windisch Brown</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/claire-bonial/ class=align-middle>Claire Bonial</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/selene-baez-santamaria/ class=align-middle>Selene Baez Santamaria</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thomas-baier/ class=align-middle>Thomas Baier</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/taewoon-kim/ class=align-middle>Taewoon Kim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lea-krause/ class=align-middle>Lea Krause</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jaap-kruijt/ class=align-middle>Jaap Kruijt</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/gwc/ class=align-middle>GWC</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/iwcs/ class=align-middle>IWCS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/latechclfl/ class=align-middle>LaTeCHCLfL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/mmsr/ class=align-middle>MMSR</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>