<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Paweł Budzianowski - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Paweł</span> <span class=font-weight-bold>Budzianowski</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.nlp4convai-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.nlp4convai-1.0/>Proceedings of the 3rd Workshop on Natural Language Processing for Conversational AI</a></strong><br><a href=/people/a/alexandros-papangelis/>Alexandros Papangelis</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/b/bing-liu/>Bing Liu</a>
|
<a href=/people/e/elnaz-nouri/>Elnaz Nouri</a>
|
<a href=/people/a/abhinav-rastogi/>Abhinav Rastogi</a>
|
<a href=/people/y/yun-nung-chen/>Yun-Nung Chen</a><br><a href=/volumes/2021.nlp4convai-1/ class=text-muted>Proceedings of the 3rd Workshop on Natural Language Processing for Conversational AI</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.88.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--88 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.88 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.88/>ConvFiT : Conversational Fine-Tuning of Pretrained Language Models<span class=acl-fixed-case>ConvFiT:</span> <span class=acl-fixed-case>C</span>onversational Fine-Tuning of Pretrained Language Models</a></strong><br><a href=/people/i/ivan-vulic/>Ivan Vulić</a>
|
<a href=/people/p/pei-hao-su/>Pei-Hao Su</a>
|
<a href=/people/s/samuel-coope/>Samuel Coope</a>
|
<a href=/people/d/daniela-gerz/>Daniela Gerz</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/n/nikola-mrksic/>Nikola Mrkšić</a>
|
<a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--88><div class="card-body p-3 small">Transformer-based language models (LMs) pretrained on large text collections are proven to store a wealth of semantic knowledge. However, 1) they are not effective as sentence encoders when used off-the-shelf, and 2) thus typically lag behind conversationally pretrained (e.g., via response selection) encoders on conversational tasks such as intent detection (ID). In this work, we propose ConvFiT, a simple and efficient two-stage procedure which turns any pretrained LM into a universal conversational encoder (after Stage 1 ConvFiT-ing) and task-specialised sentence encoder (after Stage 2). We demonstrate that 1) full-blown conversational pretraining is not required, and that LMs can be quickly transformed into effective conversational encoders with much smaller amounts of unannotated data ; 2) pretrained LMs can be fine-tuned into task-specialised sentence encoders, optimised for the fine-grained semantics of a particular task. Consequently, such specialised sentence encoders allow for treating ID as a simple semantic similarity task based on interpretable nearest neighbours retrieval. We validate the robustness and versatility of the ConvFiT framework with such similarity-based inference on the standard ID evaluation sets : ConvFiT-ed LMs achieve state-of-the-art ID performance across the board, with particular gains in the most challenging, few-shot setups.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1125.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1125 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1125 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1125/>Semi-Supervised Bootstrapping of Dialogue State Trackers for Task-Oriented Modelling</a></strong><br><a href=/people/b/bo-hsiang-tseng/>Bo-Hsiang Tseng</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/r/richard-turner/>Richard Turner</a>
|
<a href=/people/b/bill-byrne/>Bill Byrne</a>
|
<a href=/people/a/anna-korhonen/>Anna Korhonen</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1125><div class="card-body p-3 small">Dialogue systems benefit greatly from optimizing on detailed annotations, such as <a href=https://en.wikipedia.org/wiki/Transcription_(linguistics)>transcribed utterances</a>, internal dialogue state representations and dialogue act labels. However, collecting these <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> is expensive and time-consuming, holding back development in the area of dialogue modelling. In this paper, we investigate semi-supervised learning methods that are able to reduce the amount of required intermediate labelling. We find that by leveraging un-annotated data instead, the amount of turn-level annotations of dialogue state can be significantly reduced when building a neural dialogue system. Our analysis on the MultiWOZ corpus, covering a range of domains and topics, finds that annotations can be reduced by up to 30 % while maintaining equivalent system performance. We also describe and evaluate the first end-to-end dialogue model created for the MultiWOZ corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-info align-middle mr-1" href=#abstract-D19-2003 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-2003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-2003/>Data Collection and End-to-End Learning for Conversational <span class=acl-fixed-case>AI</span></a></strong><br><a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a>
|
<a href=/people/p/pei-hao-su/>Pei-Hao Su</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vulić</a><br><a href=/volumes/D19-2/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): Tutorial Abstracts</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-2003><div class="card-body p-3 small">A fundamental long-term goal of conversational AI is to merge two main dialogue system paradigms into a standalone multi-purpose system. Such a system should be capable of conversing about arbitrary topics (Paradigm 1: open-domain dialogue systems), and simultaneously assist humans with completing a wide range of tasks with well-defined semantics such as restaurant search and booking, customer service applications, or ticket bookings (Paradigm 2: task-based dialogue systems).\n\nThe recent developmental leaps in conversational AI technology are undoubtedly linked to more and more sophisticated deep learning algorithms that capture patterns in increasing amounts of data generated by various data collection mechanisms. The goal of this tutorial is therefore twofold. First, it aims at familiarising the research community with the recent advances in algorithmic design of statistical dialogue systems for both open-domain and task-based dialogue paradigms. The focus of the tutorial is on recently introduced end-to-end learning for dialogue systems and their relation to more common modular systems. In theory, learning end-to-end from data offers seamless and unprecedented portability of dialogue systems to a wide spectrum of tasks and languages. From a practical point of view, there are still plenty of research challenges and opportunities remaining: in this tutorial we analyse this gap between theory and practice, and introduce the research community with the main advantages as well as with key practical limitations of current end-to-end dialogue learning.\n\nThe critical requirement of each statistical dialogue system is the data at hand. The system cannot provide assistance for the task without having appropriate task-related data to learn from. Therefore, the second major goal of this tutorial is to provide a comprehensive overview of the current approaches to data collection for dialogue, and analyse the current gaps and challenges with diverse data collection protocols, as well as their relation to and current limitations of data-driven end-to-end dialogue modeling. We will again analyse this relation and limitations both from research and industry perspective, and provide key insights on the application of state-of-the-art methodology into industry-scale conversational AI systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-3031.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-3031 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-3031 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-3031/>PolyResponse : A Rank-based Approach to Task-Oriented Dialogue with Application in Restaurant Search and Booking<span class=acl-fixed-case>P</span>oly<span class=acl-fixed-case>R</span>esponse: A Rank-based Approach to Task-Oriented Dialogue with Application in Restaurant Search and Booking</a></strong><br><a href=/people/m/matthew-henderson/>Matthew Henderson</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vulić</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/d/daniela-gerz/>Daniela Gerz</a>
|
<a href=/people/s/sam-coope/>Sam Coope</a>
|
<a href=/people/g/georgios-spithourakis/>Georgios Spithourakis</a>
|
<a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a>
|
<a href=/people/n/nikola-mrksic/>Nikola Mrkšić</a>
|
<a href=/people/p/pei-hao-su/>Pei-Hao Su</a><br><a href=/volumes/D19-3/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-3031><div class="card-body p-3 small">We present PolyResponse, a conversational search engine that supports task-oriented dialogue. It is a retrieval-based approach that bypasses the complex multi-component design of traditional task-oriented dialogue systems and the use of explicit semantics in the form of task-specific ontologies. The PolyResponse engine is trained on hundreds of millions of examples extracted from real conversations : it learns what responses are appropriate in different conversational contexts. It then ranks a large index of text and visual responses according to their similarity to the given context, and narrows down the list of relevant entities during the multi-turn conversation. We introduce a restaurant search and booking system powered by the PolyResponse engine, currently available in 8 different languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4101.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4101 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4101 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-4101" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-4101/>A Repository of Conversational Datasets</a></strong><br><a href=/people/m/matthew-henderson/>Matthew Henderson</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/s/sam-coope/>Sam Coope</a>
|
<a href=/people/d/daniela-gerz/>Daniela Gerz</a>
|
<a href=/people/g/girish-kumar/>Girish Kumar</a>
|
<a href=/people/n/nikola-mrksic/>Nikola Mrkšić</a>
|
<a href=/people/g/georgios-spithourakis/>Georgios Spithourakis</a>
|
<a href=/people/p/pei-hao-su/>Pei-Hao Su</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vulić</a>
|
<a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a><br><a href=/volumes/W19-41/ class=text-muted>Proceedings of the First Workshop on NLP for Conversational AI</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4101><div class="card-body p-3 small">Progress in <a href=https://en.wikipedia.org/wiki/Machine_learning>Machine Learning</a> is often driven by the availability of large datasets, and consistent evaluation metrics for comparing modeling approaches. To this end, we present a repository of conversational datasets consisting of hundreds of millions of examples, and a standardised evaluation procedure for conversational response selection models using 1-of-100 accuracy. The <a href=https://en.wikipedia.org/wiki/Disciplinary_repository>repository</a> contains scripts that allow researchers to reproduce the standard <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, or to adapt the pre-processing and data filtering steps to their needs. We introduce and evaluate several competitive baselines for conversational response selection, whose implementations are shared in the repository, as well as a neural encoder model that is trained on the entire training set.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5920.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5920 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5920 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5920/>Tree-Structured Semantic Encoder with Knowledge Sharing for Domain Adaptation in Natural Language Generation</a></strong><br><a href=/people/b/bo-hsiang-tseng/>Bo-Hsiang Tseng</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/y/yen-chen-wu/>Yen-chen Wu</a>
|
<a href=/people/m/milica-gasic/>Milica Gasic</a><br><a href=/volumes/W19-59/ class=text-muted>Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5920><div class="card-body p-3 small">Domain adaptation in natural language generation (NLG) remains challenging because of the high complexity of input semantics across domains and limited data of a target domain. This is particularly the case for dialogue systems, where we want to be able to seamlessly include new domains into the conversation. Therefore, it is crucial for generation models to share knowledge across domains for the effective <a href=https://en.wikipedia.org/wiki/Adaptation>adaptation</a> from one domain to another. In this study, we exploit a tree-structured semantic encoder to capture the internal structure of complex semantic representations required for multi-domain dialogues in order to facilitate knowledge sharing across domains. In addition, a layer-wise attention mechanism between the <a href=https://en.wikipedia.org/wiki/Tree_traversal>tree encoder</a> and the <a href=https://en.wikipedia.org/wiki/Tree_traversal>decoder</a> is adopted to further improve the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s capability. The automatic evaluation results show that our model outperforms previous methods in terms of the BLEU score and the slot error rate, in particular when the <a href=https://en.wikipedia.org/wiki/Adaptation_data>adaptation data</a> is limited. In subjective evaluation, human judges tend to prefer the sentences generated by our model, rating them more highly on informativeness and <a href=https://en.wikipedia.org/wiki/Naturalness_(philosophy)>naturalness</a> than other <a href=https://en.wikipedia.org/wiki/System>systems</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1536.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1536 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1536 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1536/>Training Neural Response Selection for Task-Oriented Dialogue Systems</a></strong><br><a href=/people/m/matthew-henderson/>Matthew Henderson</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vulić</a>
|
<a href=/people/d/daniela-gerz/>Daniela Gerz</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/s/sam-coope/>Sam Coope</a>
|
<a href=/people/g/georgios-spithourakis/>Georgios Spithourakis</a>
|
<a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a>
|
<a href=/people/n/nikola-mrksic/>Nikola Mrkšić</a>
|
<a href=/people/p/pei-hao-su/>Pei-Hao Su</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1536><div class="card-body p-3 small">Despite their popularity in the chatbot literature, retrieval-based models have had modest impact on task-oriented dialogue systems, with the main obstacle to their application being the low-data regime of most task-oriented dialogue tasks. Inspired by the recent success of pretraining in language modelling, we propose an effective method for deploying response selection in task-oriented dialogue. To train response selection models for task-oriented dialogue tasks, we propose a novel method which : 1) pretrains the response selection model on large general-domain conversational corpora ; and then 2) fine-tunes the pretrained model for the target dialogue domain, relying only on the small in-domain dataset to capture the nuances of the given dialogue domain. Our evaluation on five diverse application domains, ranging from <a href=https://en.wikipedia.org/wiki/E-commerce>e-commerce</a> to <a href=https://en.wikipedia.org/wiki/Bank>banking</a>, demonstrates the effectiveness of the proposed training method.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1547.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1547 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1547 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D18-1547.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/306141298 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1547" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1547/>MultiWOZ-A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling<span class=acl-fixed-case>M</span>ulti<span class=acl-fixed-case>WOZ</span> - A Large-Scale Multi-Domain <span class=acl-fixed-case>W</span>izard-of-<span class=acl-fixed-case>O</span>z Dataset for Task-Oriented Dialogue Modelling</a></strong><br><a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a>
|
<a href=/people/b/bo-hsiang-tseng/>Bo-Hsiang Tseng</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/o/osman-ramadan/>Osman Ramadan</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1547><div class="card-body p-3 small">Even though <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a> has become the major scene in dialogue research community, the real breakthrough has been blocked by the scale of data available. To address this fundamental obstacle, we introduce the Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics. At a size of 10k dialogues, it is at least one order of magnitude larger than all previous annotated task-oriented corpora. The contribution of this work apart from the open-sourced dataset is two-fold : firstly, a detailed description of the data collection procedure along with a summary of data structure and analysis is provided. The proposed data-collection pipeline is entirely based on <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowd-sourcing</a> without the need of hiring professional annotators;secondly, a set of benchmark results of belief tracking, dialogue act and response generation is reported, which shows the usability of the data and sets a baseline for future studies.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5007 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5007/>Neural User Simulation for Corpus-based Policy Optimisation of Spoken Dialogue Systems</a></strong><br><a href=/people/f/florian-kreyssig/>Florian Kreyssig</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a><br><a href=/volumes/W18-50/ class=text-muted>Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5007><div class="card-body p-3 small">User Simulators are one of the major tools that enable offline training of task-oriented dialogue systems. For this <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a> the Agenda-Based User Simulator (ABUS) is often used. The ABUS is based on hand-crafted rules and its output is in semantic form. Issues arise from both properties such as limited diversity and the inability to interface a text-level belief tracker. This paper introduces the Neural User Simulator (NUS) whose behaviour is learned from a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> and which generates <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>, hence needing a less labelled dataset than simulators generating a semantic output. In comparison to much of the past work on this topic, which evaluates user simulators on corpus-based metrics, we use the <a href=https://en.wikipedia.org/wiki/National_University_of_Singapore>NUS</a> to train the policy of a reinforcement learning based Spoken Dialogue System. The <a href=https://en.wikipedia.org/wiki/National_University_of_Singapore>NUS</a> is compared to the ABUS by evaluating the <a href=https://en.wikipedia.org/wiki/Policy>policies</a> that were trained using the <a href=https://en.wikipedia.org/wiki/Simulation>simulators</a>. Cross-model evaluation is performed i.e. training on one <a href=https://en.wikipedia.org/wiki/Simulation>simulator</a> and testing on the other. Furthermore, the trained <a href=https://en.wikipedia.org/wiki/Policy>policies</a> are tested on real users. In both evaluation tasks the <a href=https://en.wikipedia.org/wiki/NUS>NUS</a> outperformed the <a href=https://en.wikipedia.org/wiki/ABUS>ABUS</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5032.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5032 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5032 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W18-5032.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W18-5032/>Addressing Objects and Their Relations : The Conversational Entity Dialogue Model</a></strong><br><a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/l/lina-m-rojas-barahona/>Lina M. Rojas-Barahona</a>
|
<a href=/people/b/bo-hsiang-tseng/>Bo-Hsiang Tseng</a>
|
<a href=/people/y/yen-chen-wu/>Yen-Chen Wu</a>
|
<a href=/people/s/steve-young/>Steve Young</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a><br><a href=/volumes/W18-50/ class=text-muted>Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5032><div class="card-body p-3 small">Statistical spoken dialogue systems usually rely on a single- or multi-domain dialogue model that is restricted in its capabilities of modelling complex dialogue structures, e.g., <a href=https://en.wikipedia.org/wiki/Interpersonal_relationship>relations</a>. In this work, we propose a novel dialogue model that is centred around entities and is able to model <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a> as well as multiple entities of the same type. We demonstrate in a prototype implementation benefits of relation modelling on the dialogue level and show that a trained <a href=https://en.wikipedia.org/wiki/Policy>policy</a> using these <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a> outperforms the multi-domain baseline. Furthermore, we show that by modelling the <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a> on the dialogue level, the <a href=https://en.wikipedia.org/wiki/System>system</a> is capable of processing <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a> present in the user input and even learns to address them in the system response.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5038.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5038 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5038 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5038/>Feudal Dialogue Management with Jointly Learned Feature Extractors</a></strong><br><a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/f/florian-kreyssig/>Florian Kreyssig</a>
|
<a href=/people/b/bo-hsiang-tseng/>Bo-Hsiang Tseng</a>
|
<a href=/people/y/yen-chen-wu/>Yen-chen Wu</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a><br><a href=/volumes/W18-50/ class=text-muted>Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5038><div class="card-body p-3 small">Reinforcement learning (RL) is a promising dialogue policy optimisation approach, but traditional RL algorithms fail to scale to large domains. Recently, Feudal Dialogue Management (FDM), has shown to increase the scalability to large domains by decomposing the dialogue management decision into two steps, making use of the domain ontology to abstract the dialogue state in each step. In order to abstract the <a href=https://en.wikipedia.org/wiki/State_space>state space</a>, however, previous work on <a href=https://en.wikipedia.org/wiki/Finite-state_machine>FDM</a> relies on handcrafted feature functions. In this work, we show that these <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature functions</a> can be learned jointly with the <a href=https://en.wikipedia.org/wiki/Policy_model>policy model</a> while obtaining similar performance, even outperforming the handcrafted features in several environments and domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5039.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5039 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5039 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5039/>Variational Cross-domain Natural Language Generation for Spoken Dialogue Systems</a></strong><br><a href=/people/b/bo-hsiang-tseng/>Bo-Hsiang Tseng</a>
|
<a href=/people/f/florian-kreyssig/>Florian Kreyssig</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/y/yen-chen-wu/>Yen-Chen Wu</a>
|
<a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a><br><a href=/volumes/W18-50/ class=text-muted>Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5039><div class="card-body p-3 small">Cross-domain natural language generation (NLG) is still a difficult task within spoken dialogue modelling. Given a <a href=https://en.wikipedia.org/wiki/Semantics>semantic representation</a> provided by the <a href=https://en.wikipedia.org/wiki/Dialogue_manager>dialogue manager</a>, the language generator should generate sentences that convey desired information. Traditional template-based generators can produce sentences with all necessary information, but these sentences are not sufficiently diverse. With RNN-based models, the diversity of the generated sentences can be high, however, in the process some information is lost. In this work, we improve an RNN-based generator by considering latent information at the sentence level during generation using conditional variational auto-encoder architecture. We demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms the original RNN-based generator, while yielding highly diverse sentences. In addition, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performs better when the training data is limited.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2112.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-2112 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-2112 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-2112/>Feudal Reinforcement Learning for <a href=https://en.wikipedia.org/wiki/Dialogue_management>Dialogue Management</a> in Large Domains</a></strong><br><a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/p/pei-hao-su/>Pei-Hao Su</a>
|
<a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/l/lina-m-rojas-barahona/>Lina M. Rojas-Barahona</a>
|
<a href=/people/b/bo-hsiang-tseng/>Bo-Hsiang Tseng</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-2112><div class="card-body p-3 small">Reinforcement learning (RL) is a promising approach to solve dialogue policy optimisation. Traditional RL algorithms, however, fail to scale to large domains due to the curse of dimensionality. We propose a novel Dialogue Management architecture, based on Feudal RL, which decomposes the decision into two steps ; a first step where a master policy selects a subset of primitive actions, and a second step where a primitive action is chosen from the selected subset. The structural information included in the <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>domain ontology</a> is used to abstract the dialogue state space, taking the decisions at each step using different parts of the abstracted state. This, combined with an information sharing mechanism between slots, increases the scalability to <a href=https://en.wikipedia.org/wiki/Domain_(software_engineering)>large domains</a>. We show that an implementation of this approach, based on Deep-Q Networks, significantly outperforms previous state of the art in several dialogue domains and environments, without the need of any additional reward signal.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5509.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5509 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5509 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5509/>Reward-Balancing for Statistical Spoken Dialogue Systems using Multi-objective Reinforcement Learning</a></strong><br><a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/n/nikola-mrksic/>Nikola Mrkšić</a>
|
<a href=/people/l/lina-m-rojas-barahona/>Lina M. Rojas-Barahona</a>
|
<a href=/people/p/pei-hao-su/>Pei-Hao Su</a>
|
<a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a>
|
<a href=/people/s/steve-young/>Steve Young</a><br><a href=/volumes/W17-55/ class=text-muted>Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5509><div class="card-body p-3 small">Reinforcement learning is widely used for dialogue policy optimization where the <a href=https://en.wikipedia.org/wiki/Reward_system>reward function</a> often consists of more than one <a href=https://en.wikipedia.org/wiki/Function_(mathematics)>component</a>, e.g., the dialogue success and the dialogue length. In this work, we propose a structured method for finding a good balance between these components by searching for the optimal reward component weighting. To render this search feasible, we use multi-objective reinforcement learning to significantly reduce the number of training dialogues required. We apply our proposed method to find optimized component weights for six domains and compare them to a default baseline.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5512.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5512 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5512 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5512/>Sub-domain Modelling for <a href=https://en.wikipedia.org/wiki/Dialogue_management>Dialogue Management</a> with Hierarchical Reinforcement Learning</a></strong><br><a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/p/pei-hao-su/>Pei-Hao Su</a>
|
<a href=/people/n/nikola-mrksic/>Nikola Mrkšić</a>
|
<a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/l/lina-m-rojas-barahona/>Lina M. Rojas-Barahona</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a><br><a href=/volumes/W17-55/ class=text-muted>Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5512><div class="card-body p-3 small">Human conversation is inherently complex, often spanning many different topics / domains. This makes <a href=https://en.wikipedia.org/wiki/Policy_learning>policy learning</a> for <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a> very challenging. Standard flat reinforcement learning methods do not provide an efficient <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> for modelling such <a href=https://en.wikipedia.org/wiki/Dialogue>dialogues</a>. In this paper, we focus on the under-explored problem of multi-domain dialogue management. First, we propose a new <a href=https://en.wikipedia.org/wiki/Methodology>method</a> for hierarchical reinforcement learning using the option framework. Next, we show that the proposed <a href=https://en.wikipedia.org/wiki/Architecture>architecture</a> learns faster and arrives at a better <a href=https://en.wikipedia.org/wiki/Policy>policy</a> than the existing flat ones do. Moreover, we show how pretrained policies can be adapted to more complex systems with an additional set of new actions. In doing that, we show that our approach has the potential to facilitate policy optimisation for more sophisticated multi-domain dialogue systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5518.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5518 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5518 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5518/>Sample-efficient Actor-Critic Reinforcement Learning with Supervised Data for Dialogue Management</a></strong><br><a href=/people/p/pei-hao-su/>Pei-Hao Su</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a>
|
<a href=/people/s/steve-young/>Steve Young</a><br><a href=/volumes/W17-55/ class=text-muted>Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5518><div class="card-body p-3 small">Deep reinforcement learning (RL) methods have significant potential for dialogue policy optimisation. However, <a href=https://en.wikipedia.org/wiki/They_(2017_film)>they</a> suffer from a poor performance in the early stages of learning. This is especially problematic for <a href=https://en.wikipedia.org/wiki/Educational_technology>on-line learning</a> with real users. Two <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>approaches</a> are introduced to tackle this problem. Firstly, to speed up the learning process, two sample-efficient neural networks algorithms : trust region actor-critic with experience replay (TRACER) and episodic natural actor-critic with experience replay (eNACER) are presented. For TRACER, the <a href=https://en.wikipedia.org/wiki/Trust_region>trust region</a> helps to control the learning step size and avoid catastrophic model changes. For eNACER, the natural gradient identifies the steepest ascent direction in policy space to speed up the <a href=https://en.wikipedia.org/wiki/Convergence_of_random_variables>convergence</a>. Both models employ off-policy learning with experience replay to improve sample-efficiency. Secondly, to mitigate the cold start issue, a corpus of demonstration data is utilised to pre-train the models prior to on-line reinforcement learning. Combining these two approaches, we demonstrate a practical approach to learn deep RL-based dialogue policies and demonstrate their effectiveness in a task-oriented information seeking domain.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Pawe%C5%82+Budzianowski" title="Search for 'Paweł Budzianowski' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/i/inigo-casanueva/ class=align-middle>Iñigo Casanueva</a>
<span class="badge badge-secondary align-middle ml-2">13</span></li><li class=list-group-item><a href=/people/m/milica-gasic/ class=align-middle>Milica Gasic</a>
<span class="badge badge-secondary align-middle ml-2">10</span></li><li class=list-group-item><a href=/people/p/pei-hao-su/ class=align-middle>Pei-Hao Su</a>
<span class="badge badge-secondary align-middle ml-2">9</span></li><li class=list-group-item><a href=/people/s/stefan-ultes/ class=align-middle>Stefan Ultes</a>
<span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/people/t/tsung-hsien-wen/ class=align-middle>Tsung-Hsien Wen</a>
<span class="badge badge-secondary align-middle ml-2">8</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/b/bo-hsiang-tseng/ class=align-middle>Bo-Hsiang Tseng</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/n/nikola-mrksic/ class=align-middle>Nikola Mrkšić</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/i/ivan-vulic/ class=align-middle>Ivan Vulić</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/l/lina-m-rojas-barahona/ class=align-middle>Lina M. Rojas Barahona</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/d/daniela-gerz/ class=align-middle>Daniela Gerz</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/y/yen-chen-wu/ class=align-middle>Yen-Chen Wu</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/s/steve-young/ class=align-middle>Steve Young</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/matthew-henderson/ class=align-middle>Matthew Henderson</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/sam-coope/ class=align-middle>Sam Coope</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/g/georgios-spithourakis/ class=align-middle>Georgios Spithourakis</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/f/florian-kreyssig/ class=align-middle>Florian Kreyssig</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/alexandros-papangelis/ class=align-middle>Alexandros Papangelis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bing-liu/ class=align-middle>Bing Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elnaz-nouri/ class=align-middle>Elnaz Nouri</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/abhinav-rastogi/ class=align-middle>Abhinav Rastogi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yun-nung-chen/ class=align-middle>Yun-Nung Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/osman-ramadan/ class=align-middle>Osman Ramadan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/samuel-coope/ class=align-middle>Samuel Coope</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marek-rei/ class=align-middle>Marek Rei</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/richard-turner/ class=align-middle>Richard Turner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bill-byrne/ class=align-middle>Bill Byrne</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anna-korhonen/ class=align-middle>Anna Korhonen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/girish-kumar/ class=align-middle>Girish Kumar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">9</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/nlp4convai/ class=align-middle>NLP4ConvAI</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>