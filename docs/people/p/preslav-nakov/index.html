<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Preslav Nakov - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Preslav</span> <span class=font-weight-bold>Nakov</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.0/>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></strong><br><a href=/people/s/smaranda-muresan/>Smaranda Muresan</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/a/aline-villavicencio/>Aline Villavicencio</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-short.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2022.acl-short.0/>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></strong><br><a href=/people/s/smaranda-muresan/>Smaranda Muresan</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/a/aline-villavicencio/>Aline Villavicencio</a><br><a href=/volumes/2022.acl-short/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.findings-acl.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2022.findings-acl.0/>Findings of the Association for Computational Linguistics: ACL 2022</a></strong><br><a href=/people/s/smaranda-muresan/>Smaranda Muresan</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/a/aline-villavicencio/>Aline Villavicencio</a><br><a href=/volumes/2022.findings-acl/ class=text-muted>Findings of the Association for Computational Linguistics: ACL 2022</a></span></p><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.vardial-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.vardial-1.0/>Proceedings of the Eighth Workshop on NLP for Similar Languages, Varieties and Dialects</a></strong><br><a href=/people/m/marcos-zampieri/>Marcos Zampieri</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/n/nikola-ljubesic/>Nikola Ljubešić</a>
|
<a href=/people/j/jorg-tiedemann/>Jörg Tiedemann</a>
|
<a href=/people/y/yves-scherrer/>Yves Scherrer</a>
|
<a href=/people/t/tommi-jauhiainen/>Tommi Jauhiainen</a><br><a href=/volumes/2021.vardial-1/ class=text-muted>Proceedings of the Eighth Workshop on NLP for Similar Languages, Varieties and Dialects</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ranlp-1.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ranlp-1--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ranlp-1.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ranlp-1.22/>Predicting the Factuality of Reporting of News Media Using Observations about User Attention in Their YouTube Channels<span class=acl-fixed-case>Y</span>ou<span class=acl-fixed-case>T</span>ube Channels</a></strong><br><a href=/people/k/krasimira-bozhanova/>Krasimira Bozhanova</a>
|
<a href=/people/y/yoan-dinkov/>Yoan Dinkov</a>
|
<a href=/people/i/ivan-koychev/>Ivan Koychev</a>
|
<a href=/people/m/maria-castaldo/>Maria Castaldo</a>
|
<a href=/people/t/tommaso-venturini/>Tommaso Venturini</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/2021.ranlp-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ranlp-1--22><div class="card-body p-3 small">We propose a novel framework for predicting the factuality of reporting of news media outlets by studying the user attention cycles in their YouTube channels. In particular, we design a rich set of features derived from the temporal evolution of the number of views, likes, dislikes, and comments for a video, which we then aggregate to the channel level. We develop and release a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for the task, containing observations of user attention on YouTube channels for 489 <a href=https://en.wikipedia.org/wiki/News_media>news media</a>. Our experiments demonstrate both complementarity and sizable improvements over state-of-the-art textual representations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.nlp4if-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.nlp4if-1.0/>Proceedings of the Fourth Workshop on NLP for Internet Freedom: Censorship, Disinformation, and Propaganda</a></strong><br><a href=/people/a/anna-feldman/>Anna Feldman</a>
|
<a href=/people/g/giovanni-da-san-martino/>Giovanni Da San Martino</a>
|
<a href=/people/c/chris-leberknight/>Chris Leberknight</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/2021.nlp4if-1/ class=text-muted>Proceedings of the Fourth Workshop on NLP for Internet Freedom: Censorship, Disinformation, and Propaganda</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.110.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--110 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.110 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.110" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.110/>RuleBERT : Teaching Soft Rules to Pre-Trained Language Models<span class=acl-fixed-case>R</span>ule<span class=acl-fixed-case>BERT</span>: Teaching Soft Rules to Pre-Trained Language Models</a></strong><br><a href=/people/m/mohammed-saeed/>Mohammed Saeed</a>
|
<a href=/people/n/naser-ahmadi/>Naser Ahmadi</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/p/paolo-papotti/>Paolo Papotti</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--110><div class="card-body p-3 small">While pre-trained language models (PLMs) are the go-to solution to tackle many natural language processing problems, they are still very limited in their ability to capture and to use common-sense knowledge. In fact, even if information is available in the form of approximate (soft) logical rules, it is not clear how to transfer <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> to a PLM in order to improve its performance for deductive reasoning tasks. Here, we aim to bridge this gap by teaching PLMs how to reason with soft Horn rules. We introduce a classification task where, given facts and soft rules, the PLM should return a prediction with a probability for a given hypothesis. We release the first <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, and we propose a revised <a href=https://en.wikipedia.org/wiki/Loss_function>loss function</a> that enables the PLM to learn how to predict precise probabilities for the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. Our evaluation results show that the resulting fine-tuned models achieve very high performance, even on logical rules that were unseen at training. Moreover, we demonstrate that logical notions expressed by the rules are transferred to the fine-tuned model, yielding state-of-the-art results on external datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.710.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--710 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.710 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.710" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.710/>Cross-Domain Label-Adaptive Stance Detection</a></strong><br><a href=/people/m/momchil-hardalov/>Momchil Hardalov</a>
|
<a href=/people/a/arnav-arora/>Arnav Arora</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/i/isabelle-augenstein/>Isabelle Augenstein</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--710><div class="card-body p-3 small">Stance detection concerns the classification of a writer&#8217;s viewpoint towards a target. There are different task variants, e.g., stance of a tweet vs. a full article, or stance with respect to a claim vs. an (implicit) topic. Moreover, task definitions vary, which includes the label inventory, the <a href=https://en.wikipedia.org/wiki/Data_collection>data collection</a>, and the annotation protocol. All these aspects hinder cross-domain studies, as they require changes to standard domain adaptation approaches. In this paper, we perform an in-depth analysis of 16 stance detection datasets, and we explore the possibility for cross-domain learning from them. Moreover, we propose an end-to-end unsupervised framework for out-of-domain prediction of unseen, user-defined labels. In particular, we combine domain adaptation techniques such as mixture of experts and domain-adversarial training with label embeddings, and we demonstrate sizable performance gains over strong <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>, both (i) in-domain, i.e., for seen targets, and (ii) out-of-domain, i.e., for unseen targets. Finally, we perform an exhaustive analysis of the cross-domain results, and we highlight the important factors influencing the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.bsnlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.bsnlp-1.0/>Proceedings of the 8th Workshop on Balto-Slavic Natural Language Processing</a></strong><br><a href=/people/b/bogdan-babych/>Bogdan Babych</a>
|
<a href=/people/o/olga-kanishcheva/>Olga Kanishcheva</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/j/jakub-piskorski/>Jakub Piskorski</a>
|
<a href=/people/l/lidia-pivovarova/>Lidia Pivovarova</a>
|
<a href=/people/v/vasyl-starko/>Vasyl Starko</a>
|
<a href=/people/j/josef-steinberger/>Josef Steinberger</a>
|
<a href=/people/r/roman-yangarber/>Roman Yangarber</a>
|
<a href=/people/m/michal-marcinczuk/>Michał Marcińczuk</a>
|
<a href=/people/s/senja-pollak/>Senja Pollak</a>
|
<a href=/people/p/pavel-priban/>Pavel Přibáň</a>
|
<a href=/people/m/marko-robnik-sikonja/>Marko Robnik-Šikonja</a><br><a href=/volumes/2021.bsnlp-1/ class=text-muted>Proceedings of the 8th Workshop on Balto-Slavic Natural Language Processing</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.bsnlp-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--bsnlp-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.bsnlp-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.bsnlp-1.15/>Slav-NER : the 3rd Cross-lingual Challenge on Recognition, Normalization, <a href=https://en.wikipedia.org/wiki/Language_classification>Classification</a>, and Linking of Named Entities across <a href=https://en.wikipedia.org/wiki/Slavic_languages>Slavic Languages</a><span class=acl-fixed-case>NER</span>: the 3rd Cross-lingual Challenge on Recognition, Normalization, Classification, and Linking of Named Entities across <span class=acl-fixed-case>S</span>lavic Languages</a></strong><br><a href=/people/j/jakub-piskorski/>Jakub Piskorski</a>
|
<a href=/people/b/bogdan-babych/>Bogdan Babych</a>
|
<a href=/people/z/zara-kancheva/>Zara Kancheva</a>
|
<a href=/people/o/olga-kanishcheva/>Olga Kanishcheva</a>
|
<a href=/people/m/maria-lebedeva/>Maria Lebedeva</a>
|
<a href=/people/m/michal-marcinczuk/>Michał Marcińczuk</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/p/petya-osenova/>Petya Osenova</a>
|
<a href=/people/l/lidia-pivovarova/>Lidia Pivovarova</a>
|
<a href=/people/s/senja-pollak/>Senja Pollak</a>
|
<a href=/people/p/pavel-priban/>Pavel Přibáň</a>
|
<a href=/people/i/ivaylo-radev/>Ivaylo Radev</a>
|
<a href=/people/m/marko-robnik-sikonja/>Marko Robnik-Sikonja</a>
|
<a href=/people/v/vasyl-starko/>Vasyl Starko</a>
|
<a href=/people/j/josef-steinberger/>Josef Steinberger</a>
|
<a href=/people/r/roman-yangarber/>Roman Yangarber</a><br><a href=/volumes/2021.bsnlp-1/ class=text-muted>Proceedings of the 8th Workshop on Balto-Slavic Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--bsnlp-1--15><div class="card-body p-3 small">This paper describes Slav-NER : the 3rd Multilingual Named Entity Challenge in <a href=https://en.wikipedia.org/wiki/Slavic_languages>Slavic languages</a>. The tasks involve recognizing mentions of named entities in <a href=https://en.wikipedia.org/wiki/Web_page>Web documents</a>, normalization of the names, and cross-lingual linking. The Challenge covers six languages and five entity types, and is organized as part of the 8th Balto-Slavic Natural Language Processing Workshop, co-located with the EACL 2021 Conference. Ten teams participated in the competition. Performance for the named entity recognition task reached 90 % <a href=https://en.wikipedia.org/wiki/F-measure>F-measure</a>, much higher than reported in the first edition of the Challenge. Seven teams covered all six languages, and five teams participated in the cross-lingual entity linking task. Detailed valuation information is available on the shared task web page.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.7/>SemEval-2021 Task 6 : Detection of Persuasion Techniques in Texts and Images<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 6: Detection of Persuasion Techniques in Texts and Images</a></strong><br><a href=/people/d/dimitar-dimitrov/>Dimitar Dimitrov</a>
|
<a href=/people/b/bishr-bin-ali/>Bishr Bin Ali</a>
|
<a href=/people/s/shaden-shaar/>Shaden Shaar</a>
|
<a href=/people/f/firoj-alam/>Firoj Alam</a>
|
<a href=/people/f/fabrizio-silvestri/>Fabrizio Silvestri</a>
|
<a href=/people/h/hamed-firooz/>Hamed Firooz</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/g/giovanni-da-san-martino/>Giovanni Da San Martino</a><br><a href=/volumes/2021.semeval-1/ class=text-muted>Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--7><div class="card-body p-3 small">We describe SemEval-2021 task 6 on Detection of Persuasion Techniques in Texts and Images : the data, the annotation guidelines, the evaluation setup, the results, and the participating systems. The task focused on <a href=https://en.wikipedia.org/wiki/Meme>memes</a> and had three subtasks : (i) detecting the techniques in the <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text</a>, (ii) detecting the text spans where the techniques are used, and (iii) detecting techniques in the entire meme, i.e., both in the text and in the image. It was a popular <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, attracting 71 registrations, and 22 teams that eventually made an official submission on the test set. The evaluation results for the third subtask confirmed the importance of both <a href=https://en.wikipedia.org/wiki/Modality_(semiotics)>modalities</a>, the <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text</a> and the image. Moreover, some teams reported benefits when not just combining the two modalities, e.g., by using early or late fusion, but rather modeling the interaction between them in a joint model.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.438.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--438 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.438 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938985 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.438" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.438/>EXAMS : A Multi-subject High School Examinations Dataset for Cross-lingual and Multilingual Question Answering<span class=acl-fixed-case>EXAMS</span>: A Multi-subject High School Examinations Dataset for Cross-lingual and Multilingual Question Answering</a></strong><br><a href=/people/m/momchil-hardalov/>Momchil Hardalov</a>
|
<a href=/people/t/todor-mihaylov/>Todor Mihaylov</a>
|
<a href=/people/d/dimitrina-zlatkova/>Dimitrina Zlatkova</a>
|
<a href=/people/y/yoan-dinkov/>Yoan Dinkov</a>
|
<a href=/people/i/ivan-koychev/>Ivan Koychev</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--438><div class="card-body p-3 small">We propose EXAMS a new benchmark dataset for cross-lingual and multilingual question answering for high school examinations. We collected more than 24,000 high-quality high school exam questions in 16 languages, covering 8 language families and 24 school subjects from Natural Sciences and Social Sciences, among others. EXAMS offers unique fine-grained evaluation framework across multiple languages and subjects, which allows precise analysis and comparison of the proposed models. We perform various experiments with existing top-performing multilingual pre-trained models and show that EXAMS offers multiple challenges that require multilingual knowledge and reasoning in multiple domains. We hope that EXAMS will enable researchers to explore challenging reasoning and knowledge transfer methods and pre-trained models for school question answering in various languages which was not possible by now. The data, code, pre-trained models, and evaluation are available at http://github.com/mhardalov/exams-qa.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.308.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--308 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.308 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929381 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.308" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.308/>What Was Written vs. Who Read It : News Media Profiling Using <a href=https://en.wikipedia.org/wiki/Text_mining>Text Analysis</a> and Social Media Context</a></strong><br><a href=/people/r/ramy-baly/>Ramy Baly</a>
|
<a href=/people/g/georgi-karadzhov/>Georgi Karadzhov</a>
|
<a href=/people/j/jisun-an/>Jisun An</a>
|
<a href=/people/h/haewoon-kwak/>Haewoon Kwak</a>
|
<a href=/people/y/yoan-dinkov/>Yoan Dinkov</a>
|
<a href=/people/a/ahmed-ali/>Ahmed Ali</a>
|
<a href=/people/j/james-glass/>James Glass</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--308><div class="card-body p-3 small">Predicting the political bias and the factuality of reporting of entire news outlets are critical elements of media profiling, which is an understudied but an increasingly important research direction. The present level of proliferation of fake, biased, and propagandistic content online has made it impossible to fact-check every single suspicious claim, either manually or automatically. Thus, it has been proposed to profile entire <a href=https://en.wikipedia.org/wiki/News_media>news outlets</a> and to look for those that are likely to publish fake or biased content. This makes it possible to detect likely <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a> the moment they are published, by simply checking the reliability of their source. From a practical perspective, political bias and factuality of reporting have a linguistic aspect but also a <a href=https://en.wikipedia.org/wiki/Social_environment>social context</a>. Here, we study the impact of both, namely (i) what was written (i.e., what was published by the target medium, and how it describes itself in Twitter) vs. (ii) who reads it (i.e., analyzing the target medium&#8217;s audience on social media). We further study (iii) what was written about the target medium (in Wikipedia). The evaluation results show that what was written matters most, and we further show that putting all information sources together yields huge improvements over the current state-of-the-art.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.32.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--32 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.32 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><span class="align-middle mr-1" data-toggle=tooltip data-placement=bottom title="Honorable Mention for Best Demonstration Paper"><i class="fas fa-award"></i></span><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928622 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.32/>Prta : A System to Support the Analysis of Propaganda Techniques in the News<span class=acl-fixed-case>P</span>rta: A System to Support the Analysis of Propaganda Techniques in the News</a></strong><br><a href=/people/g/giovanni-da-san-martino/>Giovanni Da San Martino</a>
|
<a href=/people/s/shaden-shaar/>Shaden Shaar</a>
|
<a href=/people/y/yifan-zhang/>Yifan Zhang</a>
|
<a href=/people/s/seunghak-yu/>Seunghak Yu</a>
|
<a href=/people/a/alberto-barron-cedeno/>Alberto Barrón-Cedeño</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/2020.acl-demos/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--32><div class="card-body p-3 small">Recent events, such as the 2016 US Presidential Campaign, <a href=https://en.wikipedia.org/wiki/Brexit>Brexit</a> and the COVID-19 infodemic, have brought into the spotlight the dangers of online disinformation. There has been a lot of research focusing on <a href=https://en.wikipedia.org/wiki/Fact-checking>fact-checking</a> and disinformation detection. However, little attention has been paid to the specific <a href=https://en.wikipedia.org/wiki/Rhetorical_techniques>rhetorical and psychological techniques</a> used to convey <a href=https://en.wikipedia.org/wiki/Propaganda>propaganda messages</a>. Revealing the use of such techniques can help promote <a href=https://en.wikipedia.org/wiki/Media_literacy>media literacy</a> and <a href=https://en.wikipedia.org/wiki/Critical_thinking>critical thinking</a>, and eventually contribute to limiting the impact of fake news and <a href=https://en.wikipedia.org/wiki/Disinformation>disinformation campaigns</a>. Prta (Propaganda Persuasion Techniques Analyzer) allows users to explore the articles crawled on a regular basis by highlighting the spans in which propaganda techniques occur and to compare them on the basis of their use of propaganda techniques. The system further reports statistics about the use of such techniques, overall and over time, or according to filtering criteria specified by the user based on time interval, <a href=https://en.wikipedia.org/wiki/Index_term>keywords</a>, and/or political orientation of the media. Moreover, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> allows users to analyze any text or URL through a dedicated interface or via an API. The <a href=https://en.wikipedia.org/wiki/System>system</a> is available online : https://www.tanbih.org/prta.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.semeval-1.188.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--semeval-1--188 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.semeval-1.188 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.semeval-1.188/>SemEval-2020 Task 12 : Multilingual Offensive Language Identification in Social Media (OffensEval 2020)<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2020 Task 12: Multilingual Offensive Language Identification in Social Media (<span class=acl-fixed-case>O</span>ffens<span class=acl-fixed-case>E</span>val 2020)</a></strong><br><a href=/people/m/marcos-zampieri/>Marcos Zampieri</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/s/sara-rosenthal/>Sara Rosenthal</a>
|
<a href=/people/p/pepa-atanasova/>Pepa Atanasova</a>
|
<a href=/people/g/georgi-karadzhov/>Georgi Karadzhov</a>
|
<a href=/people/h/hamdy-mubarak/>Hamdy Mubarak</a>
|
<a href=/people/l/leon-derczynski/>Leon Derczynski</a>
|
<a href=/people/z/zeses-pitenis/>Zeses Pitenis</a>
|
<a href=/people/c/cagri-coltekin/>Çağrı Çöltekin</a><br><a href=/volumes/2020.semeval-1/ class=text-muted>Proceedings of the Fourteenth Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--semeval-1--188><div class="card-body p-3 small">We present the results and the main findings of SemEval-2020 Task 12 on Multilingual Offensive Language Identification in Social Media (OffensEval-2020). The task included three subtasks corresponding to the hierarchical taxonomy of the OLID schema from OffensEval-2019, and it was offered in five languages : <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a>, <a href=https://en.wikipedia.org/wiki/Danish_language>Danish</a>, <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Greek_language>Greek</a>, and <a href=https://en.wikipedia.org/wiki/Turkish_language>Turkish</a>. OffensEval-2020 was one of the most popular tasks at SemEval-2020, attracting a large number of participants across all subtasks and languages : a total of 528 teams signed up to participate in the task, 145 teams submitted official runs on the test data, and 70 teams submitted system description papers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.semeval-1.191.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--semeval-1--191 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.semeval-1.191 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.semeval-1.191" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.semeval-1.191/>Aschern at SemEval-2020 Task 11 : It Takes Three to Tango : RoBERTa, CRF, and Transfer Learning<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2020 Task 11: It Takes Three to Tango: <span class=acl-fixed-case>R</span>o<span class=acl-fixed-case>BERT</span>a, <span class=acl-fixed-case>CRF</span>, and Transfer Learning</a></strong><br><a href=/people/a/anton-chernyavskiy/>Anton Chernyavskiy</a>
|
<a href=/people/d/dmitry-ilvovsky/>Dmitry Ilvovsky</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/2020.semeval-1/ class=text-muted>Proceedings of the Fourteenth Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--semeval-1--191><div class="card-body p-3 small">We describe our <a href=https://en.wikipedia.org/wiki/System>system</a> for SemEval-2020 Task 11 on Detection of Propaganda Techniques in News Articles. We developed ensemble models using RoBERTa-based neural architectures, additional CRF layers, <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> between the two subtasks, and advanced post-processing to handle the multi-label nature of the task, the consistency between nested spans, repetitions, and labels from similar spans in training. We achieved sizable improvements over baseline fine-tuned RoBERTa models, and the official evaluation ranked our system 3rd (almost tied with the 2nd) out of 36 teams on the span identification subtask with an F1 score of 0.491, and 2nd (almost tied with the 1st) out of 31 teams on the technique classification subtask with an F1 score of 0.62.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4if-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nlp4if-1.0/>Proceedings of the 3rd NLP4IF Workshop on NLP for Internet Freedom: Censorship, Disinformation, and Propaganda</a></strong><br><a href=/people/g/giovanni-da-san-martino/>Giovanni Da San Martino</a>
|
<a href=/people/c/chris-brew/>Chris Brew</a>
|
<a href=/people/g/giovanni-luca-ciampaglia/>Giovanni Luca Ciampaglia</a>
|
<a href=/people/a/anna-feldman/>Anna Feldman</a>
|
<a href=/people/c/chris-leberknight/>Chris Leberknight</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/2020.nlp4if-1/ class=text-muted>Proceedings of the 3rd NLP4IF Workshop on NLP for Internet Freedom: Censorship, Disinformation, and Propaganda</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.vardial-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.vardial-1.0/>Proceedings of the 7th Workshop on NLP for Similar Languages, Varieties and Dialects</a></strong><br><a href=/people/m/marcos-zampieri/>Marcos Zampieri</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/n/nikola-ljubesic/>Nikola Ljubešić</a>
|
<a href=/people/j/jorg-tiedemann/>Jörg Tiedemann</a>
|
<a href=/people/y/yves-scherrer/>Yves Scherrer</a><br><a href=/volumes/2020.vardial-1/ class=text-muted>Proceedings of the 7th Workshop on NLP for Similar Languages, Varieties and Dialects</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1216.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1216 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1216 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1216" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1216/>Fact-Checking Meets Fauxtography : Verifying Claims About Images</a></strong><br><a href=/people/d/dimitrina-zlatkova/>Dimitrina Zlatkova</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/i/ivan-koychev/>Ivan Koychev</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1216><div class="card-body p-3 small">The recent explosion of false claims in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> and on the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>Web</a> in general has given rise to a lot of manual fact-checking initiatives. Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually. Thus, there has been a lot of research aiming at automating the process. Interestingly, previous work has largely ignored the growing number of claims about <a href=https://en.wikipedia.org/wiki/Image>images</a>. This is despite the fact that <a href=https://en.wikipedia.org/wiki/Visual_imagery>visual imagery</a> is more influential than <a href=https://en.wikipedia.org/wiki/Writing>text</a> and naturally appears alongside <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a>. Here we aim at bridging this gap. In particular, we create a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for this problem, and we explore a variety of <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> modeling the claim, the <a href=https://en.wikipedia.org/wiki/Image>image</a>, and the relationship between the claim and the image. The evaluation results show sizable improvements over the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a>. We release our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, hoping to enable further research on fact-checking claims about <a href=https://en.wikipedia.org/wiki/Digital_image>images</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1294.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1294 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1294 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1294.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1294" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1294/>Evaluating Pronominal Anaphora in <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a> : An Evaluation Measure and a Test Suite</a></strong><br><a href=/people/p/prathyusha-jwalapuram/>Prathyusha Jwalapuram</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/i/irina-temnikova/>Irina Temnikova</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1294><div class="card-body p-3 small">The ongoing neural revolution in <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> has made it easier to model larger contexts beyond the sentence-level, which can potentially help resolve some discourse-level ambiguities such as pronominal anaphora, thus enabling better translations. Unfortunately, even when the resulting improvements are seen as substantial by humans, they remain virtually unnoticed by traditional automatic evaluation measures like <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>, as only a few words end up being affected. Thus, specialized <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation measures</a> are needed. With this aim in mind, we contribute an extensive, targeted dataset that can be used as a test suite for pronoun translation, covering multiple source languages and different pronoun errors drawn from real system translations, for <a href=https://en.wikipedia.org/wiki/English_language>English</a>. We further propose an evaluation measure to differentiate good and bad pronoun translations. We also conduct a <a href=https://en.wikipedia.org/wiki/User_study>user study</a> to report correlations with <a href=https://en.wikipedia.org/wiki/Judgement>human judgments</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1452.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1452 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1452 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1452/>Contrastive Language Adaptation for Cross-Lingual Stance Detection</a></strong><br><a href=/people/m/mitra-mohtarami/>Mitra Mohtarami</a>
|
<a href=/people/j/james-glass/>James Glass</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1452><div class="card-body p-3 small">We study cross-lingual stance detection, which aims to leverage labeled data in one language to identify the relative perspective (or stance) of a given document with respect to a claim in a different target language. In particular, we introduce a novel contrastive language adaptation approach applied to memory networks, which ensures accurate alignment of stances in the source and target languages, and can effectively deal with the challenge of limited labeled data in the target language. The evaluation results on public benchmark datasets and comparison against current state-of-the-art approaches demonstrate the effectiveness of our approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5000/>Proceedings of the Second Workshop on Natural Language Processing for Internet Freedom: Censorship, Disinformation, and Propaganda</a></strong><br><a href=/people/a/anna-feldman/>Anna Feldman</a>
|
<a href=/people/g/giovanni-da-san-martino/>Giovanni Da San Martino</a>
|
<a href=/people/a/alberto-barron-cedeno/>Alberto Barrón-Cedeño</a>
|
<a href=/people/c/chris-brew/>Chris Brew</a>
|
<a href=/people/c/chris-leberknight/>Chris Leberknight</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/D19-50/ class=text-muted>Proceedings of the Second Workshop on Natural Language Processing for Internet Freedom: Censorship, Disinformation, and Propaganda</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-2010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S19-2010 data-toggle=collapse aria-expanded=false aria-controls=abstract-S19-2010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-2010/>SemEval-2019 Task 6 : Identifying and Categorizing <a href=https://en.wikipedia.org/wiki/Offensive_language>Offensive Language</a> in <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a> (OffensEval)<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media (<span class=acl-fixed-case>O</span>ffens<span class=acl-fixed-case>E</span>val)</a></strong><br><a href=/people/m/marcos-zampieri/>Marcos Zampieri</a>
|
<a href=/people/s/shervin-malmasi/>Shervin Malmasi</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/s/sara-rosenthal/>Sara Rosenthal</a>
|
<a href=/people/n/noura-farra/>Noura Farra</a>
|
<a href=/people/r/ritesh-kumar/>Ritesh Kumar</a><br><a href=/volumes/S19-2/ class=text-muted>Proceedings of the 13th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S19-2010><div class="card-body p-3 small">We present the results and the main findings of SemEval-2019 Task 6 on Identifying and Categorizing Offensive Language in Social Media (OffensEval). The task was based on a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, the Offensive Language Identification Dataset (OLID), which contains over 14,000 English tweets, and it featured three sub-tasks. In sub-task A, systems were asked to discriminate between offensive and non-offensive posts. In sub-task B, systems had to identify the type of offensive content in the post. Finally, in sub-task C, systems had to detect the target of the offensive posts. OffensEval attracted a large number of participants and <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> was one of the most popular <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> in SemEval-2019. In total, nearly 800 teams signed up to participate in the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> and 115 of them submitted results, which are presented and analyzed in this report.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-2176.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S19-2176 data-toggle=collapse aria-expanded=false aria-controls=abstract-S19-2176 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-2176/>Team Jack Ryder at SemEval-2019 Task 4 : Using BERT Representations for Detecting Hyperpartisan News<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2019 Task 4: Using <span class=acl-fixed-case>BERT</span> Representations for Detecting Hyperpartisan News</a></strong><br><a href=/people/d/daniel-shaprin/>Daniel Shaprin</a>
|
<a href=/people/g/giovanni-da-san-martino/>Giovanni Da San Martino</a>
|
<a href=/people/a/alberto-barron-cedeno/>Alberto Barrón-Cedeño</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/S19-2/ class=text-muted>Proceedings of the 13th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S19-2176><div class="card-body p-3 small">We describe the system submitted by the Jack Ryder team to SemEval-2019 Task 4 on Hyperpartisan News Detection. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> asked participants to predict whether a given article is hyperpartisan, i.e., <a href=https://en.wikipedia.org/wiki/Far-left_politics>extreme-left</a> or <a href=https://en.wikipedia.org/wiki/Far-right_politics>extreme-right</a>. We proposed an approach based on BERT with fine-tuning, which was ranked 7th out 28 teams on the distantly supervised dataset, where all articles from a hyperpartisan / non-hyperpartisan news outlet are considered to be hyperpartisan / non-hyperpartisan. On a manually annotated test dataset, where human annotators double-checked the labels, we were ranked 29th out of 42 teams.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-1400.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-1400/>Proceedings of the Sixth Workshop on <span class=acl-fixed-case>NLP</span> for Similar Languages, Varieties and Dialects</a></strong><br><a href=/people/m/marcos-zampieri/>Marcos Zampieri</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/s/shervin-malmasi/>Shervin Malmasi</a>
|
<a href=/people/n/nikola-ljubesic/>Nikola Ljubešić</a>
|
<a href=/people/j/jorg-tiedemann/>Jörg Tiedemann</a>
|
<a href=/people/a/ahmed-ali/>Ahmed Ali</a><br><a href=/volumes/W19-14/ class=text-muted>Proceedings of the Sixth Workshop on NLP for Similar Languages, Varieties and Dialects</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3700.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3700/>Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing</a></strong><br><a href=/people/t/tomaz-erjavec/>Tomaž Erjavec</a>
|
<a href=/people/m/michal-marcinczuk/>Michał Marcińczuk</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/j/jakub-piskorski/>Jakub Piskorski</a>
|
<a href=/people/l/lidia-pivovarova/>Lidia Pivovarova</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a>
|
<a href=/people/j/josef-steinberger/>Josef Steinberger</a>
|
<a href=/people/r/roman-yangarber/>Roman Yangarber</a><br><a href=/volumes/W19-37/ class=text-muted>Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1154.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1154 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1154 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/360694967 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-1154/>One Size Does Not Fit All : Comparing NMT Representations of Different Granularities<span class=acl-fixed-case>NMT</span> Representations of Different Granularities</a></strong><br><a href=/people/n/nadir-durrani/>Nadir Durrani</a>
|
<a href=/people/f/fahim-dalvi/>Fahim Dalvi</a>
|
<a href=/people/h/hassan-sajjad/>Hassan Sajjad</a>
|
<a href=/people/y/yonatan-belinkov/>Yonatan Belinkov</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1154><div class="card-body p-3 small">Recent work has shown that contextualized word representations derived from <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a> are a viable alternative to such from simple word predictions tasks. This is because the internal understanding that needs to be built in order to be able to translate from one language to another is much more comprehensive. Unfortunately, computational and memory limitations as of present prevent NMT models from using large word vocabularies, and thus alternatives such as subword units (BPE and morphological segmentations) and <a href=https://en.wikipedia.org/wiki/Character_(symbol)>characters</a> have been used. Here we study the impact of using different kinds of units on the quality of the resulting representations when used to model <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphology</a>, <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a>, and <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a>. We found that while representations derived from subwords are slightly better for modeling <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a>, character-based representations are superior for modeling <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphology</a> and are also more robust to noisy input.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1029.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1029 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1029 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=R19-1029" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/R19-1029/>Detecting Toxicity in <a href=https://en.wikipedia.org/wiki/Article_(publishing)>News Articles</a> : Application to Bulgarian<span class=acl-fixed-case>B</span>ulgarian</a></strong><br><a href=/people/y/yoan-dinkov/>Yoan Dinkov</a>
|
<a href=/people/i/ivan-koychev/>Ivan Koychev</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/R19-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1029><div class="card-body p-3 small">Online media aim for reaching ever bigger audience and for attracting ever longer attention span. This competition creates an environment that rewards sensational, fake, and toxic news. To help limit their spread and impact, we propose and develop a news toxicity detector that can recognize various types of toxic content. While previous research primarily focused on <a href=https://en.wikipedia.org/wiki/English_language>English</a>, here we target <a href=https://en.wikipedia.org/wiki/Bulgarian_language>Bulgarian</a>. We created a new dataset by crawling a website that for five years has been collecting Bulgarian news articles that were manually categorized into eight toxicity groups. Then we trained a multi-class classifier with nine categories : eight toxic and one non-toxic. We experimented with different representations based on ElMo, BERT, and XLM, as well as with a variety of domain-specific features. Due to the small size of our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, we created a separate <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> for each feature type, and we ultimately combined these <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> into a meta-classifier. The evaluation results show an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 59.0 % and a macro-F1 score of 39.7 %, which represent sizable improvements over the majority-class baseline (Acc=30.3 %, macro-F1=5.2 %).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1053.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1053 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1053 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=R19-1053" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/R19-1053/>Beyond English-Only Reading Comprehension : Experiments in Zero-shot Multilingual Transfer for Bulgarian<span class=acl-fixed-case>E</span>nglish-Only Reading Comprehension: Experiments in Zero-shot Multilingual Transfer for <span class=acl-fixed-case>B</span>ulgarian</a></strong><br><a href=/people/m/momchil-hardalov/>Momchil Hardalov</a>
|
<a href=/people/i/ivan-koychev/>Ivan Koychev</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/R19-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1053><div class="card-body p-3 small">Recently, reading comprehension models achieved near-human performance on large-scale datasets such as SQuAD, CoQA, MS Macro, RACE, etc. This is largely due to the release of pre-trained contextualized representations such as <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> and ELMo, which can be fine-tuned for the target task. Despite those advances and the creation of more challenging datasets, most of the work is still done for <a href=https://en.wikipedia.org/wiki/English_language>English</a>. Here, we study the effectiveness of multilingual BERT fine-tuned on large-scale English datasets for <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> (e.g., for RACE), and we apply it to Bulgarian multiple-choice reading comprehension. We propose a new dataset containing 2,221 questions from <a href=https://en.wikipedia.org/wiki/Matriculation_examination>matriculation exams</a> for twelfth grade in various subjects history, biology, geography and philosophy, and 412 additional questions from online quizzes in history. While the quiz authors gave no relevant context, we incorporate knowledge from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, retrieving documents matching the combination of question + each answer option. Moreover, we experiment with different indexing and pre-training strategies. The evaluation results show accuracy of 42.23 %, which is well above the <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baseline</a> of 24.89 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1127.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1127 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1127 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1127/>A Morpho-Syntactically Informed LSTM-CRF Model for Named Entity Recognition<span class=acl-fixed-case>LSTM</span>-<span class=acl-fixed-case>CRF</span> Model for Named Entity Recognition</a></strong><br><a href=/people/l/lilia-simeonova/>Lilia Simeonova</a>
|
<a href=/people/k/kiril-simov/>Kiril Simov</a>
|
<a href=/people/p/petya-osenova/>Petya Osenova</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/R19-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1127><div class="card-body p-3 small">We propose a morphologically informed model for <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>, which is based on LSTM-CRF architecture and combines word embeddings, Bi-LSTM character embeddings, part-of-speech (POS) tags, and morphological information. While previous work has focused on learning from raw word input, using word and character embeddings only, we show that for morphologically rich languages, such as <a href=https://en.wikipedia.org/wiki/Bulgarian_language>Bulgarian</a>, access to POS information contributes more to the performance gains than the detailed morphological information. Thus, we show that <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a> needs only coarse-grained POS tags, but at the same time it can benefit from simultaneously using some POS information of different granularity. Our evaluation results over a standard <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> show sizeable improvements over the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> for Bulgarian NER.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-4000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-4000/>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts</a></strong><br><a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/a/alexis-palmer/>Alexis Palmer</a><br><a href=/volumes/P19-4/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K19-1096.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K19-1096 data-toggle=collapse aria-expanded=false aria-controls=abstract-K19-1096 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/K19-1096.Attachment.txt data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K19-1096" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K19-1096/>Predicting the Role of Political Trolls in <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a></a></strong><br><a href=/people/a/atanas-atanasov/>Atanas Atanasov</a>
|
<a href=/people/g/gianmarco-de-francisci-morales/>Gianmarco De Francisci Morales</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/K19-1/ class=text-muted>Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K19-1096><div class="card-body p-3 small">We investigate the political roles of <a href=https://en.wikipedia.org/wiki/Internet_troll>Internet trolls</a> in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. Political trolls, such as the ones linked to the Russian Internet Research Agency (IRA), have recently gained enormous attention for their ability to sway public opinion and even influence elections. Analysis of the online traces of trolls has shown different behavioral patterns, which target different slices of the population. However, this <a href=https://en.wikipedia.org/wiki/Analysis>analysis</a> is manual and labor-intensive, thus making it impractical as a first-response tool for newly-discovered troll farms. In this paper, we show how to automate this <a href=https://en.wikipedia.org/wiki/Analysis>analysis</a> by using <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a> in a realistic setting. In particular, we show how to classify <a href=https://en.wikipedia.org/wiki/Internet_troll>trolls</a> according to their political role left, <a href=https://en.wikipedia.org/wiki/Web_feed>news feed</a>, right by using features extracted from <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, i.e., <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>, in two scenarios : (i) in a traditional supervised learning scenario, where labels for <a href=https://en.wikipedia.org/wiki/Internet_troll>trolls</a> are available, and (ii) in a distant supervision scenario, where labels for <a href=https://en.wikipedia.org/wiki/Internet_troll>trolls</a> are not available, and we rely on more-commonly-available labels for news outlets mentioned by the trolls. Technically, we leverage the community structure and the text of the messages in the online social network of trolls represented as a <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a>, from which we extract several types of learned representations, i.e., <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a>, for the <a href=https://en.wikipedia.org/wiki/Internet_troll>trolls</a>. Experiments on the IRA Russian Troll dataset show that our methodology improves over the state-of-the-art in the first scenario, while providing a compelling case for the second scenario, which has not been explored in the literature thus far.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1389.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1389 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1389 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1389" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D18-1389/>Predicting Factuality of Reporting and Bias of News Media Sources</a></strong><br><a href=/people/r/ramy-baly/>Ramy Baly</a>
|
<a href=/people/g/georgi-karadzhov/>Georgi Karadzhov</a>
|
<a href=/people/d/dimitar-alexandrov/>Dimitar Alexandrov</a>
|
<a href=/people/j/james-glass/>James Glass</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1389><div class="card-body p-3 small">We present a study on predicting the factuality of reporting and bias of <a href=https://en.wikipedia.org/wiki/News_media>news media</a>. While previous work has focused on studying the veracity of claims or documents, here we are interested in characterizing entire <a href=https://en.wikipedia.org/wiki/News_media>news media</a>. This is an under-studied, but arguably important research problem, both in its own right and as a prior for <a href=https://en.wikipedia.org/wiki/Fact-checking>fact-checking systems</a>. We experiment with a large list of news websites and with a rich set of features derived from (i) a sample of articles from the target <a href=https://en.wikipedia.org/wiki/News_media>news media</a>, (ii) its Wikipedia page, (iii) its Twitter account, (iv) the structure of its URL, and (v) information about the Web traffic it attracts. The experimental results show sizable performance gains over the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a>, and reveal the importance of each feature type.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1452.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1452 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1452 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/306149753 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1452/>Joint Multitask Learning for Community Question Answering Using Task-Specific Embeddings</a></strong><br><a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/l/lluis-marquez/>Lluís Màrquez</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1452><div class="card-body p-3 small">We address jointly two important tasks for Question Answering in community forums : given a new question, (i) find related existing questions, and (ii) find relevant answers to this new question. We further use an auxiliary task to complement the previous two, i.e., (iii) find good answers with respect to the thread question in a question-comment thread. We use deep neural networks (DNNs) to learn meaningful task-specific embeddings, which we then incorporate into a conditional random field (CRF) model for the multitask setting, performing joint learning over a complex graph structure. While <a href=https://en.wikipedia.org/wiki/Deep_learning>DNNs</a> alone achieve competitive results when trained to produce the embeddings, the CRF, which makes use of the embeddings and the dependencies between the tasks, improves the results significantly and consistently across a variety of evaluation metrics, thus showing the complementarity of <a href=https://en.wikipedia.org/wiki/Deep_learning>DNNs</a> and <a href=https://en.wikipedia.org/wiki/Structured_learning>structured learning</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3900.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3900/>Proceedings of the Fifth Workshop on <span class=acl-fixed-case>NLP</span> for Similar Languages, Varieties and Dialects (<span class=acl-fixed-case>V</span>ar<span class=acl-fixed-case>D</span>ial 2018)</a></strong><br><a href=/people/m/marcos-zampieri/>Marcos Zampieri</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/n/nikola-ljubesic/>Nikola Ljubešić</a>
|
<a href=/people/j/jorg-tiedemann/>Jörg Tiedemann</a>
|
<a href=/people/s/shervin-malmasi/>Shervin Malmasi</a>
|
<a href=/people/a/ahmed-ali/>Ahmed Ali</a><br><a href=/volumes/W18-39/ class=text-muted>Proceedings of the Fifth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial 2018)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1070.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1070 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1070 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1070/>Automatic Stance Detection Using End-to-End Memory Networks</a></strong><br><a href=/people/m/mitra-mohtarami/>Mitra Mohtarami</a>
|
<a href=/people/r/ramy-baly/>Ramy Baly</a>
|
<a href=/people/j/james-glass/>James Glass</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/l/lluis-marquez/>Lluís Màrquez</a>
|
<a href=/people/a/alessandro-moschitti/>Alessandro Moschitti</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1070><div class="card-body p-3 small">We present an effective end-to-end memory network model that jointly (i) predicts whether a given document can be considered as relevant evidence for a given claim, and (ii) extracts snippets of evidence that can be used to reason about the factuality of the target claim. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> combines the advantages of convolutional and recurrent neural networks as part of a memory network. We further introduce a <a href=https://en.wikipedia.org/wiki/Similarity_matrix>similarity matrix</a> at the inference level of the memory network in order to extract snippets of evidence for input claims more accurately. Our experiments on a public benchmark dataset, FakeNewsChallenge, demonstrate the effectiveness of our approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-5006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-5006 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-5006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-5006/>ClaimRank : Detecting Check-Worthy Claims in <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a> and English<span class=acl-fixed-case>C</span>laim<span class=acl-fixed-case>R</span>ank: Detecting Check-Worthy Claims in <span class=acl-fixed-case>A</span>rabic and <span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/i/israa-jaradat/>Israa Jaradat</a>
|
<a href=/people/p/pepa-gencheva/>Pepa Gencheva</a>
|
<a href=/people/a/alberto-barron-cedeno/>Alberto Barrón-Cedeño</a>
|
<a href=/people/l/lluis-marquez/>Lluís Màrquez</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/N18-5/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-5006><div class="card-body p-3 small">We present ClaimRank, an online system for detecting check-worthy claims. While originally trained on political debates, the <a href=https://en.wikipedia.org/wiki/System>system</a> can work for any kind of text, e.g., <a href=https://en.wikipedia.org/wiki/Interview>interviews</a> or just regular news articles. Its aim is to facilitate manual fact-checking efforts by prioritizing the claims that <a href=https://en.wikipedia.org/wiki/Fact-checking>fact-checkers</a> should consider first. ClaimRank supports both <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a> and <a href=https://en.wikipedia.org/wiki/English_language>English</a>, it is trained on actual annotations from nine reputable fact-checking organizations (PolitiFact, FactCheck, ABC, CNN, NPR, NYT, Chicago Tribune, The Guardian, and Washington Post), and thus it can mimic the claim selection strategies for each and any of them, as well as for the union of them all.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-4000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-4000/>Proceedings of the <span class=acl-fixed-case>IJCNLP</span> 2017, Shared Tasks</a></strong><br><a href=/people/c/chao-hong-liu/>Chao-Hong Liu</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/n/nianwen-xue/>Nianwen Xue</a><br><a href=/volumes/I17-4/ class=text-muted>Proceedings of the IJCNLP 2017, Shared Tasks</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-1024/>Cross-language Learning with Adversarial Neural Networks</a></strong><br><a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/l/lluis-marquez/>Lluís Màrquez</a>
|
<a href=/people/i/israa-jaradat/>Israa Jaradat</a><br><a href=/volumes/K17-1/ class=text-muted>Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-1024><div class="card-body p-3 small">We address the problem of cross-language adaptation for question-question similarity reranking in community question answering, with the objective to port a system trained on one input language to another input language given labeled training data for the first language and only unlabeled data for the second language. In particular, we propose to use adversarial training of neural networks to learn high-level features that are discriminative for the main learning task, and at the same time are invariant across the input languages. The evaluation results show sizable improvements for our cross-language adversarial neural network (CLANN) model over a strong non-adversarial system.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1200.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1200/>Proceedings of the Fourth Workshop on <span class=acl-fixed-case>NLP</span> for Similar Languages, Varieties and Dialects (<span class=acl-fixed-case>V</span>ar<span class=acl-fixed-case>D</span>ial)</a></strong><br><a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/m/marcos-zampieri/>Marcos Zampieri</a>
|
<a href=/people/n/nikola-ljubesic/>Nikola Ljubešić</a>
|
<a href=/people/j/jorg-tiedemann/>Jörg Tiedemann</a>
|
<a href=/people/s/shervin-malmasi/>Shevin Malmasi</a>
|
<a href=/people/a/ahmed-ali/>Ahmed Ali</a><br><a href=/volumes/W17-12/ class=text-muted>Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1201.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1201 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1201 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1201/>Findings of the VarDial Evaluation Campaign 2017<span class=acl-fixed-case>V</span>ar<span class=acl-fixed-case>D</span>ial Evaluation Campaign 2017</a></strong><br><a href=/people/m/marcos-zampieri/>Marcos Zampieri</a>
|
<a href=/people/s/shervin-malmasi/>Shervin Malmasi</a>
|
<a href=/people/n/nikola-ljubesic/>Nikola Ljubešić</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/a/ahmed-ali/>Ahmed Ali</a>
|
<a href=/people/j/jorg-tiedemann/>Jörg Tiedemann</a>
|
<a href=/people/y/yves-scherrer/>Yves Scherrer</a>
|
<a href=/people/n/noemi-aepli/>Noëmi Aepli</a><br><a href=/volumes/W17-12/ class=text-muted>Proceedings of the Fourth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1201><div class="card-body p-3 small">We present the results of the VarDial Evaluation Campaign on Natural Language Processing (NLP) for Similar Languages, Varieties and Dialects, which we organized as part of the fourth edition of the VarDial workshop at EACL&#8217;2017. This year, we included four shared tasks : Discriminating between Similar Languages (DSL), Arabic Dialect Identification (ADI), German Dialect Identification (GDI), and Cross-lingual Dependency Parsing (CLP). A total of 19 teams submitted runs across the four <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>, and 15 of them wrote system description papers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4801.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4801 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4801 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-4801.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W17-4801/>Findings of the 2017 DiscoMT Shared Task on Cross-lingual Pronoun Prediction<span class=acl-fixed-case>D</span>isco<span class=acl-fixed-case>MT</span> Shared Task on Cross-lingual Pronoun Prediction</a></strong><br><a href=/people/s/sharid-loaiciga/>Sharid Loáiciga</a>
|
<a href=/people/s/sara-stymne/>Sara Stymne</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/c/christian-hardmeier/>Christian Hardmeier</a>
|
<a href=/people/j/jorg-tiedemann/>Jörg Tiedemann</a>
|
<a href=/people/m/mauro-cettolo/>Mauro Cettolo</a>
|
<a href=/people/y/yannick-versley/>Yannick Versley</a><br><a href=/volumes/W17-48/ class=text-muted>Proceedings of the Third Workshop on Discourse in Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4801><div class="card-body p-3 small">We describe the design, the setup, and the evaluation results of the DiscoMT 2017 shared task on cross-lingual pronoun prediction. The task asked participants to predict a <a href=https://en.wikipedia.org/wiki/Pronoun>target-language pronoun</a> given a <a href=https://en.wikipedia.org/wiki/Pronoun>source-language pronoun</a> in the context of a sentence. We further provided a lemmatized target-language human-authored translation of the source sentence, and automatic word alignments between the source sentence words and the target-language lemmata. The aim of the task was to predict, for each target-language pronoun placeholder, the word that should replace it from a small, closed set of classes, using any type of information that can be extracted from the entire document. We offered four subtasks, each for a different language pair and translation direction : <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>English-to-French</a>, <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>English-to-German</a>, German-to-English, and <a href=https://en.wikipedia.org/wiki/Spanish_as_a_second_or_foreign_language>Spanish-to-English</a>. Five teams participated in the shared task, making submissions for all language pairs. The evaluation results show that most participating teams outperformed two strong n-gram-based language model-based baseline systems by a sizable margin.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/J17-4001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-J17-4001 data-toggle=collapse aria-expanded=false aria-controls=abstract-J17-4001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/J17-4001/>Discourse Structure in Machine Translation Evaluation</a></strong><br><a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/f/francisco-guzman/>Francisco Guzmán</a>
|
<a href=/people/l/lluis-marquez/>Lluís Màrquez</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/J17-4/ class=text-muted>Computational Linguistics, Volume 43, Issue 4 - December 2017</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-J17-4001><div class="card-body p-3 small">In this article, we explore the potential of using sentence-level discourse structure for machine translation evaluation. We first design discourse-aware similarity measures, which use all-subtree kernels to compare discourse parse trees in accordance with the Rhetorical Structure Theory (RST). Then, we show that a simple <a href=https://en.wikipedia.org/wiki/Linear_combination>linear combination</a> with these measures can help improve various existing machine translation evaluation metrics regarding correlation with human judgments both at the segment level and at the system level. This suggests that discourse information is complementary to the information used by many of the existing evaluation metrics, and thus it could be taken into account when developing richer evaluation metrics, such as the WMT-14 winning combined metric DiscoTKparty. We also provide a detailed analysis of the relevance of various discourse elements and relations from the RST parse trees for machine translation evaluation. In particular, we show that (i) all aspects of the RST tree are relevant, (ii) <a href=https://en.wikipedia.org/wiki/Nuclearity>nuclearity</a> is more useful than relation type, and (iii) the similarity of the translation RST tree to the reference RST tree is positively correlated with translation quality.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2003 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=S17-2003" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/S17-2003/>SemEval-2017 Task 3 : Community Question Answering<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 3: Community Question Answering</a></strong><br><a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/d/doris-hoogeveen/>Doris Hoogeveen</a>
|
<a href=/people/l/lluis-marquez/>Lluís Màrquez</a>
|
<a href=/people/a/alessandro-moschitti/>Alessandro Moschitti</a>
|
<a href=/people/h/hamdy-mubarak/>Hamdy Mubarak</a>
|
<a href=/people/t/timothy-baldwin/>Timothy Baldwin</a>
|
<a href=/people/k/karin-verspoor/>Karin Verspoor</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2003><div class="card-body p-3 small">We describe SemEval2017 Task 3 on Community Question Answering. This year, we reran the four subtasks from SemEval-2016 : (A) QuestionComment Similarity, (B) QuestionQuestion Similarity, (C) QuestionExternal Comment Similarity, and (D) Rerank the correct answers for a new question in Arabic, providing all the data from 2015 and 2016 for training, and fresh data for testing. Additionally, we added a new subtask E in order to enable experimentation with Multi-domain Question Duplicate Detection in a larger-scale scenario, using StackExchange subforums. A total of 23 teams participated in the task, and submitted a total of 85 runs (36 primary and 49 contrastive) for subtasks AD. Unfortunately, no teams participated in subtask E. A variety of <a href=https://en.wikipedia.org/wiki/Software_development_process>approaches</a> and <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> were used by the participating <a href=https://en.wikipedia.org/wiki/System>systems</a> to address the different subtasks. The best systems achieved an official score (MAP) of 88.43, 47.22, 15.46, and 61.16 in subtasks A, B, C, and D, respectively. These scores are better than the <a href=https://en.wikipedia.org/wiki/Baseline_(surveying)>baselines</a>, especially for subtasks AC.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-2088.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-2088 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-2088 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-2088/>SemEval-2017 Task 4 : <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a> in Twitter<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2017 Task 4: Sentiment Analysis in <span class=acl-fixed-case>T</span>witter</a></strong><br><a href=/people/s/sara-rosenthal/>Sara Rosenthal</a>
|
<a href=/people/n/noura-farra/>Noura Farra</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/S17-2/ class=text-muted>Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-2088><div class="card-body p-3 small">This paper describes the fifth year of the <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a> in Twitter task. SemEval-2017 Task 4 continues with a rerun of the subtasks of SemEval-2016 Task 4, which include identifying the overall sentiment of the tweet, sentiment towards a topic with classification on a two-point and on a five-point ordinal scale, and quantification of the distribution of sentiment towards a topic across a number of tweets : again on a two-point and on a five-point ordinal scale. Compared to 2016, we made two changes : (i) we introduced a new language, <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a>, for all subtasks, and (ii) we made available information from the profiles of the Twitter users who posted the target tweets. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> continues to be very popular, with a total of 48 teams participating this year.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Preslav+Nakov" title="Search for 'Preslav Nakov' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/m/marcos-zampieri/ class=align-middle>Marcos Zampieri</a>
<span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/people/j/jorg-tiedemann/ class=align-middle>Jörg Tiedemann</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/n/nikola-ljubesic/ class=align-middle>Nikola Ljubešić</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/g/giovanni-da-san-martino/ class=align-middle>Giovanni Da San Martino</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/l/lluis-marquez/ class=align-middle>Lluís Màrquez</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/i/ivan-koychev/ class=align-middle>Ivan Koychev</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/a/ahmed-ali/ class=align-middle>Ahmed Ali</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/s/shervin-malmasi/ class=align-middle>Shervin Malmasi</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/y/yoan-dinkov/ class=align-middle>Yoan Dinkov</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/j/james-glass/ class=align-middle>James Glass</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/a/alberto-barron-cedeno/ class=align-middle>Alberto Barrón-Cedeño</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/s/shafiq-joty/ class=align-middle>Shafiq Joty</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/y/yves-scherrer/ class=align-middle>Yves Scherrer</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/momchil-hardalov/ class=align-middle>Momchil Hardalov</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/r/ramy-baly/ class=align-middle>Ramy Baly</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/g/georgi-karadzhov/ class=align-middle>Georgi Karadzhov</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/anna-feldman/ class=align-middle>Anna Feldman</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/c/chris-leberknight/ class=align-middle>Chris Leberknight</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/smaranda-muresan/ class=align-middle>Smaranda Muresan</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/aline-villavicencio/ class=align-middle>Aline Villavicencio</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/sara-rosenthal/ class=align-middle>Sara Rosenthal</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/jakub-piskorski/ class=align-middle>Jakub Piskorski</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/lidia-pivovarova/ class=align-middle>Lidia Pivovarova</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/josef-steinberger/ class=align-middle>Josef Steinberger</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/r/roman-yangarber/ class=align-middle>Roman Yangarber</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/michal-marcinczuk/ class=align-middle>Michał Marcińczuk</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/d/dimitrina-zlatkova/ class=align-middle>Dimitrina Zlatkova</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/shaden-shaar/ class=align-middle>Shaden Shaar</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/i/israa-jaradat/ class=align-middle>Israa Jaradat</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hamdy-mubarak/ class=align-middle>Hamdy Mubarak</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mitra-mohtarami/ class=align-middle>Mitra Mohtarami</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/chris-brew/ class=align-middle>Chris Brew</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/alessandro-moschitti/ class=align-middle>Alessandro Moschitti</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/n/noura-farra/ class=align-middle>Noura Farra</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/bogdan-babych/ class=align-middle>Bogdan Babych</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/o/olga-kanishcheva/ class=align-middle>Olga Kanishcheva</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/v/vasyl-starko/ class=align-middle>Vasyl Starko</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/senja-pollak/ class=align-middle>Senja Pollak</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/pavel-priban/ class=align-middle>Pavel Přibáň</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/marko-robnik-sikonja/ class=align-middle>Marko Robnik-Šikonja</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/petya-osenova/ class=align-middle>Petya Osenova</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/tommi-jauhiainen/ class=align-middle>Tommi Jauhiainen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/krasimira-bozhanova/ class=align-middle>Krasimira Bozhanova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maria-castaldo/ class=align-middle>Maria Castaldo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tommaso-venturini/ class=align-middle>Tommaso Venturini</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chao-hong-liu/ class=align-middle>Chao-Hong Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nianwen-xue/ class=align-middle>Nianwen Xue</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/todor-mihaylov/ class=align-middle>Todor Mihaylov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jisun-an/ class=align-middle>Jisun An</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haewoon-kwak/ class=align-middle>Haewoon Kwak</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yifan-zhang/ class=align-middle>Yifan Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/seunghak-yu/ class=align-middle>Seunghak Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/noemi-aepli/ class=align-middle>Noëmi Aepli</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sharid-loaiciga/ class=align-middle>Sharid Loáiciga</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sara-stymne/ class=align-middle>Sara Stymne</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christian-hardmeier/ class=align-middle>Christian Hardmeier</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mauro-cettolo/ class=align-middle>Mauro Cettolo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yannick-versley/ class=align-middle>Yannick Versley</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/francisco-guzman/ class=align-middle>Francisco Guzmán</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dimitar-alexandrov/ class=align-middle>Dimitar Alexandrov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mohammed-saeed/ class=align-middle>Mohammed Saeed</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/naser-ahmadi/ class=align-middle>Naser Ahmadi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paolo-papotti/ class=align-middle>Paolo Papotti</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/arnav-arora/ class=align-middle>Arnav Arora</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/isabelle-augenstein/ class=align-middle>Isabelle Augenstein</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pepa-atanasova/ class=align-middle>Pepa Atanasova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/leon-derczynski/ class=align-middle>Leon Derczynski</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zeses-pitenis/ class=align-middle>Zeses Pitenis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cagri-coltekin/ class=align-middle>Çağrı Çöltekin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anton-chernyavskiy/ class=align-middle>Anton Chernyavskiy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dmitry-ilvovsky/ class=align-middle>Dmitry Ilvovsky</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/prathyusha-jwalapuram/ class=align-middle>Prathyusha Jwalapuram</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/irina-temnikova/ class=align-middle>Irina Temnikova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/doris-hoogeveen/ class=align-middle>Doris Hoogeveen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/timothy-baldwin/ class=align-middle>Timothy Baldwin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/karin-verspoor/ class=align-middle>Karin Verspoor</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ritesh-kumar/ class=align-middle>Ritesh Kumar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/daniel-shaprin/ class=align-middle>Daniel Shaprin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/giovanni-luca-ciampaglia/ class=align-middle>Giovanni Luca Ciampaglia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zara-kancheva/ class=align-middle>Zara Kancheva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maria-lebedeva/ class=align-middle>Maria Lebedeva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ivaylo-radev/ class=align-middle>Ivaylo Radev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tomaz-erjavec/ class=align-middle>Tomaž Erjavec</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jan-snajder/ class=align-middle>Jan Šnajder</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nadir-durrani/ class=align-middle>Nadir Durrani</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fahim-dalvi/ class=align-middle>Fahim Dalvi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hassan-sajjad/ class=align-middle>Hassan Sajjad</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yonatan-belinkov/ class=align-middle>Yonatan Belinkov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pepa-gencheva/ class=align-middle>Pepa Gencheva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lilia-simeonova/ class=align-middle>Lilia Simeonova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kiril-simov/ class=align-middle>Kiril Simov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dimitar-dimitrov/ class=align-middle>Dimitar Dimitrov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bishr-bin-ali/ class=align-middle>Bishr Bin Ali</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/firoj-alam/ class=align-middle>Firoj Alam</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fabrizio-silvestri/ class=align-middle>Fabrizio Silvestri</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hamed-firooz/ class=align-middle>Hamed Firooz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexis-palmer/ class=align-middle>Alexis Palmer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/atanas-atanasov/ class=align-middle>Atanas Atanasov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gianmarco-de-francisci-morales/ class=align-middle>Gianmarco De Francisci Morales</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">9</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/ranlp/ class=align-middle>RANLP</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/vardial/ class=align-middle>VarDial</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/nlp4if/ class=align-middle>NLP4IF</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/bsnlp/ class=align-middle>BSNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/cl/ class=align-middle>CL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>