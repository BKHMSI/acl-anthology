<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Ido Dagan - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Ido</span> <span class=font-weight-bold>Dagan</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.25.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--25 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.25 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.conll-1.25" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.25/>Summary-Source Proposition-level Alignment : Task, Datasets and Supervised Baseline</a></strong><br><a href=/people/o/ori-ernst/>Ori Ernst</a>
|
<a href=/people/o/ori-shapira/>Ori Shapira</a>
|
<a href=/people/r/ramakanth-pasunuru/>Ramakanth Pasunuru</a>
|
<a href=/people/m/michael-lepioshkin/>Michael Lepioshkin</a>
|
<a href=/people/j/jacob-goldberger/>Jacob Goldberger</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a><br><a href=/volumes/2021.conll-1/ class=text-muted>Proceedings of the 25th Conference on Computational Natural Language Learning</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--25><div class="card-body p-3 small">Aligning sentences in a reference summary with their counterparts in source documents was shown as a useful auxiliary summarization task, notably for generating training data for <a href=https://en.wikipedia.org/wiki/Salience_(neuroscience)>salience detection</a>. Despite its assessed utility, the alignment step was mostly approached with heuristic unsupervised methods, typically ROUGE-based, and was never independently optimized or evaluated. In this paper, we propose establishing summary-source alignment as an explicit task, while introducing two major novelties : (1) applying it at the more accurate proposition span level, and (2) approaching it as a supervised classification task. To that end, we created a novel <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training dataset</a> for proposition-level alignment, derived automatically from available summarization evaluation data. In addition, we crowdsourced dev and test datasets, enabling model development and proper evaluation. Utilizing these data, we present a supervised proposition alignment baseline model, showing improved alignment-quality over the unsupervised approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-main.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-main--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-main.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-main.21/>CD2CR : Co-reference resolution across documents and domains<span class=acl-fixed-case>CD</span>Ë†2<span class=acl-fixed-case>CR</span>: Co-reference resolution across documents and domains</a></strong><br><a href=/people/j/james-ravenscroft/>James Ravenscroft</a>
|
<a href=/people/a/amanda-clare/>Amanda Clare</a>
|
<a href=/people/a/arie-cattan/>Arie Cattan</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a>
|
<a href=/people/m/maria-liakata/>Maria Liakata</a><br><a href=/volumes/2021.eacl-main/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-main--21><div class="card-body p-3 small">Cross-document co-reference resolution (CDCR) is the task of identifying and linking mentions to entities and concepts across many <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text documents</a>. Current state-of-the-art <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> assume that all documents are of the same type (e.g. news articles) or fall under the same theme. However, it is also desirable to perform CDCR across different domains (type or theme). A particular use case we focus on in this paper is the resolution of entities mentioned across <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific work</a> and <a href=https://en.wikipedia.org/wiki/Article_(publishing)>newspaper articles</a> that discuss them. Identifying the same entities and corresponding concepts in both <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific articles</a> and <a href=https://en.wikipedia.org/wiki/News>news</a> can help scientists understand how their work is represented in mainstream media. We propose a new task and English language dataset for cross-document cross-domain co-reference resolution (CD2CR). The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> aims to identify links between entities across heterogeneous document types. We show that in this cross-domain, cross-document setting, existing CDCR models do not perform well and we provide a baseline model that outperforms current state-of-the-art CDCR models on CD2CR. Our data set, annotation tool and guidelines as well as our model for cross-document cross-domain co-reference are all supplied as open access open source resources.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.778.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--778 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.778 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.778" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.778/>QA-Align : Representing Cross-Text Content Overlap by Aligning Question-Answer Propositions<span class=acl-fixed-case>QA</span>-Align: Representing Cross-Text Content Overlap by Aligning Question-Answer Propositions</a></strong><br><a href=/people/d/daniela-brook-weiss/>Daniela Brook Weiss</a>
|
<a href=/people/p/paul-roit/>Paul Roit</a>
|
<a href=/people/a/ayal-klein/>Ayal Klein</a>
|
<a href=/people/o/ori-ernst/>Ori Ernst</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--778><div class="card-body p-3 small">Multi-text applications, such as <a href=https://en.wikipedia.org/wiki/Multi-document_summarization>multi-document summarization</a>, are typically required to model redundancies across related texts. Current methods confronting <a href=https://en.wikipedia.org/wiki/Consolidation_(business)>consolidation</a> struggle to fuse overlapping information. In order to explicitly represent content overlap, we propose to align predicate-argument relations across texts, providing a potential scaffold for information consolidation. We go beyond clustering coreferring mentions, and instead model overlap with respect to redundancy at a propositional level, rather than merely detecting shared referents. Our <a href=https://en.wikipedia.org/wiki/Setting_(narrative)>setting</a> exploits QA-SRL, utilizing question-answer pairs to capture predicate-argument relations, facilitating laymen annotation of cross-text alignments. We employ crowd-workers for constructing a dataset of QA-based alignments, and present a baseline QA alignment model trained over our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. Analyses show that our new task is semantically challenging, capturing content overlap beyond <a href=https://en.wikipedia.org/wiki/Lexical_similarity>lexical similarity</a> and complements cross-document coreference with proposition-level links, offering potential use for downstream tasks.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-demos.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-demos--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-demos.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-demos.27" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-demos.27/>CoRefi : A Crowd Sourcing Suite for Coreference Annotation<span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>R</span>efi: A Crowd Sourcing Suite for Coreference Annotation</a></strong><br><a href=/people/a/ari-bornstein/>Ari Bornstein</a>
|
<a href=/people/a/arie-cattan/>Arie Cattan</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a><br><a href=/volumes/2020.emnlp-demos/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-demos--27><div class="card-body p-3 small">Coreference annotation is an important, yet expensive and time consuming, task, which often involved expert annotators trained on complex decision guidelines. To enable cheaper and more efficient <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a>, we present CoRefi, a web-based coreference annotation suite, oriented for <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a>. Beyond the core coreference annotation tool, CoRefi provides guided onboarding for the task as well as a novel <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> for a reviewing phase. CoRefi is open source and directly embeds into any website, including popular <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing platforms</a>. CoRefi Demo : aka.ms/corefi Video Tour : aka.ms/corefivideo Github Repo : https://github.com/aribornstein/corefi</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.knlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.knlp-1.0/>Proceedings of Knowledgeable NLP: the First Workshop on Integrating Structured Knowledge and Neural Networks for NLP</a></strong><br><a href=/people/o/oren-sar-shalom/>Oren Sar Shalom</a>
|
<a href=/people/a/alexander-panchenko/>Alexander Panchenko</a>
|
<a href=/people/c/cicero-dos-santos/>Cicero dos Santos</a>
|
<a href=/people/v/varvara-logacheva/>Varvara Logacheva</a>
|
<a href=/people/a/alessandro-moschitti/>Alessandro Moschitti</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a><br><a href=/volumes/2020.knlp-1/ class=text-muted>Proceedings of Knowledgeable NLP: the First Workshop on Integrating Structured Knowledge and Neural Networks for NLP</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2303.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2303 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2303 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2303/>How to Compare Summarizers without Target Length? Pitfalls, Solutions and Re-Examination of the Neural Summarization Literature</a></strong><br><a href=/people/s/simeng-sun/>Simeng Sun</a>
|
<a href=/people/o/ori-shapira/>Ori Shapira</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a>
|
<a href=/people/a/ani-nenkova/>Ani Nenkova</a><br><a href=/volumes/W19-23/ class=text-muted>Proceedings of the Workshop on Methods for Optimizing and Evaluating Neural Language Generation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2303><div class="card-body p-3 small">We show that plain ROUGE F1 scores are not ideal for comparing current neural systems which on average produce different lengths. This is due to a <a href=https://en.wikipedia.org/wiki/Nonlinear_system>non-linear pattern</a> between ROUGE F1 and summary length. To alleviate the effect of <a href=https://en.wikipedia.org/wiki/Length>length</a> during evaluation, we have proposed a new method which normalizes the ROUGE F1 scores of a <a href=https://en.wikipedia.org/wiki/System>system</a> by that of a random system with same average output length. A pilot human evaluation has shown that humans prefer short summaries in terms of the verbosity of a summary but overall consider longer summaries to be of higher quality. While human evaluations are more expensive in time and resources, it is clear that <a href=https://en.wikipedia.org/wiki/Normalization_(statistics)>normalization</a>, such as the one we proposed for automatic evaluation, will make human evaluations more meaningful.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8635.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8635 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8635 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8635/>Revisiting the Binary Linearization Technique for Surface Realization</a></strong><br><a href=/people/y/yevgeniy-puzikov/>Yevgeniy Puzikov</a>
|
<a href=/people/c/claire-gardent/>Claire Gardent</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a>
|
<a href=/people/i/iryna-gurevych/>Iryna Gurevych</a><br><a href=/volumes/W19-86/ class=text-muted>Proceedings of the 12th International Conference on Natural Language Generation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8635><div class="card-body p-3 small">End-to-end neural approaches have achieved state-of-the-art performance in many natural language processing (NLP) tasks. Yet, they often lack transparency of the underlying <a href=https://en.wikipedia.org/wiki/Decision-making>decision-making process</a>, hindering error analysis and certain model improvements. In this work, we revisit the binary linearization approach to surface realization, which exhibits more interpretable behavior, but was falling short in terms of prediction accuracy. We show how enriching the training data to better capture word order constraints almost doubles the performance of the <a href=https://en.wikipedia.org/wiki/System>system</a>. We further demonstrate that encoding both local and global prediction contexts yields another considerable performance boost. With the proposed modifications, the <a href=https://en.wikipedia.org/wiki/System>system</a> which ranked low in the latest shared task on multilingual surface realization now achieves best results in five out of ten languages, while being on par with the state-of-the-art approaches in others.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8645.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8645 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8645 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W19-8645.Supplementary_Attachment.pdf data-toggle=tooltip data-placement=top title="Supplementary attachment"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W19-8645/>Improving Quality and Efficiency in Plan-based Neural Data-to-text Generation</a></strong><br><a href=/people/a/amit-moryossef/>Amit Moryossef</a>
|
<a href=/people/y/yoav-goldberg/>Yoav Goldberg</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a><br><a href=/volumes/W19-86/ class=text-muted>Proceedings of the 12th International Conference on Natural Language Generation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8645><div class="card-body p-3 small">We follow the step-by-step approach to neural data-to-text generation proposed by Moryossef et al (2019), in which the generation process is divided into a text planning stage followed by a plan realization stage. We suggest four extensions to that framework : (1) we introduce a trainable neural planning component that can generate effective plans several orders of magnitude faster than the original planner ; (2) we incorporate typing hints that improve the model&#8217;s ability to deal with unseen relations and entities ; (3) we introduce a verification-by-reranking stage that substantially improves the faithfulness of the resulting texts ; (4) we incorporate a simple but effective referring expression generation module. These <a href=https://en.wikipedia.org/wiki/Plug-in_(computing)>extensions</a> result in a generation process that is faster, more fluent, and more accurate.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1072.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1072 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1072 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/353467177 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1072" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-1072/>Crowdsourcing Lightweight Pyramids for Manual Summary Evaluation</a></strong><br><a href=/people/o/ori-shapira/>Ori Shapira</a>
|
<a href=/people/d/david-gabay/>David Gabay</a>
|
<a href=/people/y/yang-gao/>Yang Gao</a>
|
<a href=/people/h/hadar-ronen/>Hadar Ronen</a>
|
<a href=/people/r/ramakanth-pasunuru/>Ramakanth Pasunuru</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a>
|
<a href=/people/y/yael-amsterdamer/>Yael Amsterdamer</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1072><div class="card-body p-3 small">Conducting a manual evaluation is considered an essential part of summary evaluation methodology. Traditionally, the Pyramid protocol, which exhaustively compares system summaries to references, has been perceived as very reliable, providing objective scores. Yet, due to the high cost of the Pyramid method and the required expertise, researchers resorted to cheaper and less thorough manual evaluation methods, such as <a href=https://en.wikipedia.org/wiki/Responsiveness>Responsiveness</a> and <a href=https://en.wikipedia.org/wiki/Pairwise_comparison>pairwise comparison</a>, attainable via <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a>. We revisit the Pyramid approach, proposing a lightweight sampling-based version that is crowdsourcable. We analyze the performance of our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> in comparison to original expert-based Pyramid evaluations, showing higher <a href=https://en.wikipedia.org/wiki/Correlation_and_dependence>correlation</a> relative to the common Responsiveness method. We release our crowdsourced Summary-Content-Units, along with all crowdsourcing scripts, for future evaluations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1213.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1213 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1213 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1213/>Ranking Generated Summaries by Correctness : An Interesting but Challenging Application for Natural Language Inference</a></strong><br><a href=/people/t/tobias-falke/>Tobias Falke</a>
|
<a href=/people/l/leonardo-f-r-ribeiro/>Leonardo F. R. Ribeiro</a>
|
<a href=/people/p/prasetya-ajie-utama/>Prasetya Ajie Utama</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a>
|
<a href=/people/i/iryna-gurevych/>Iryna Gurevych</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1213><div class="card-body p-3 small">While recent progress on abstractive summarization has led to remarkably fluent summaries, factual errors in generated summaries still severely limit their use in practice. In this paper, we evaluate summaries produced by state-of-the-art <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> via <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a> and show that such <a href=https://en.wikipedia.org/wiki/Errors-in-variables_models>errors</a> occur frequently, in particular with more abstractive models. We study whether textual entailment predictions can be used to detect such errors and if they can be reduced by reranking alternative predicted summaries. That leads to an interesting downstream application for <a href=https://en.wikipedia.org/wiki/Logical_consequence>entailment models</a>. In our experiments, we find that out-of-the-box entailment models trained on NLI datasets do not yet offer the desired performance for the downstream task and we therefore release our annotations as additional test data for future extrinsic evaluations of NLI.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K19-1019.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K19-1019 data-toggle=collapse aria-expanded=false aria-controls=abstract-K19-1019 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K19-1019" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K19-1019/>Diversify Your Datasets : Analyzing Generalization via Controlled Variance in Adversarial Datasets</a></strong><br><a href=/people/o/ohad-rozen/>Ohad Rozen</a>
|
<a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/r/roee-aharoni/>Roee Aharoni</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a><br><a href=/volumes/K19-1/ class=text-muted>Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K19-1019><div class="card-body p-3 small">Phenomenon-specific adversarial datasets have been recently designed to perform targeted stress-tests for particular inference types. Recent work (Liu et al., 2019a) proposed that such datasets can be utilized for training NLI and other types of models, often allowing to learn the phenomenon in focus and improve on the challenge dataset, indicating a blind spot in the original training data. Yet, although a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can improve in such a training process, it might still be vulnerable to other challenge datasets targeting the same phenomenon but drawn from a different distribution, such as having a different syntactic complexity level. In this work, we extend this method to drive conclusions about a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>&#8217;s ability to learn and generalize a target phenomenon rather than to learn a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, by controlling additional aspects in the adversarial datasets. We demonstrate our approach on two inference phenomena dative alternation and numerical reasoning, elaborating, and in some cases contradicting, the results of Liu et al.. Our methodology enables building better challenge datasets for creating more robust models, and may yield better model understanding and subsequent overarching improvements.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-2013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-2013 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-2013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-2013/>SetExpander : End-to-end Term Set Expansion Based on Multi-Context Term Embeddings<span class=acl-fixed-case>S</span>et<span class=acl-fixed-case>E</span>xpander: End-to-end Term Set Expansion Based on Multi-Context Term Embeddings</a></strong><br><a href=/people/j/jonathan-mamou/>Jonathan Mamou</a>
|
<a href=/people/o/oren-pereg/>Oren Pereg</a>
|
<a href=/people/m/moshe-wasserblat/>Moshe Wasserblat</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a>
|
<a href=/people/y/yoav-goldberg/>Yoav Goldberg</a>
|
<a href=/people/a/alon-eirew/>Alon Eirew</a>
|
<a href=/people/y/yael-green/>Yael Green</a>
|
<a href=/people/s/shira-guskin/>Shira Guskin</a>
|
<a href=/people/p/peter-izsak/>Peter Izsak</a>
|
<a href=/people/d/daniel-korat/>Daniel Korat</a><br><a href=/volumes/C18-2/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-2013><div class="card-body p-3 small">We present SetExpander, a corpus-based system for expanding a seed set of terms into a more complete set of terms that belong to the same <a href=https://en.wikipedia.org/wiki/Semantic_class>semantic class</a>. SetExpander implements an <a href=https://en.wikipedia.org/wiki/Workflow>iterative end-to end workflow</a> for term set expansion. It enables users to easily select a seed set of terms, expand <a href=https://en.wikipedia.org/wiki/Information_technology>it</a>, view the expanded set, validate it, re-expand the validated set and store it, thus simplifying the extraction of domain-specific fine-grained semantic classes. SetExpander has been used for solving real-life use cases including integration in an automated recruitment system and an issues and defects resolution system. A video demo of SetExpander is available at https://drive.google.com/open?id=1e545bB87Autsch36DjnJHmq3HWfSd1Rv.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1263.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1263 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1263 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/306045906 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1263/>Semantics as a Foreign Language</a></strong><br><a href=/people/g/gabriel-stanovsky/>Gabriel Stanovsky</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1263><div class="card-body p-3 small">We propose a novel approach to semantic dependency parsing (SDP) by casting the task as an instance of multi-lingual machine translation, where each semantic representation is a different foreign dialect. To that end, we first generalize syntactic linearization techniques to account for the richer semantic dependency graph structure. Following, we design a neural sequence-to-sequence framework which can effectively recover our graph linearizations, performing almost on-par with previous SDP state-of-the-art while requiring less parallel training annotations. Beyond SDP, our linearization technique opens the door to integration of graph-based semantic representations as <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> in neural models for downstream applications.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1081.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1081 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1081 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1081/>Supervised Open Information Extraction</a></strong><br><a href=/people/g/gabriel-stanovsky/>Gabriel Stanovsky</a>
|
<a href=/people/j/julian-michael/>Julian Michael</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1081><div class="card-body p-3 small">We present data and methods that enable a supervised learning approach to Open Information Extraction (Open IE). Central to the approach is a novel formulation of <a href=https://en.wikipedia.org/wiki/Open_IE>Open IE</a> as a sequence tagging problem, addressing challenges such as encoding multiple extractions for a predicate. We also develop a bi-LSTM transducer, extending recent deep Semantic Role Labeling models to extract Open IE tuples and provide confidence scores for tuning their precision-recall tradeoff. Furthermore, we show that the recently released Question-Answer Meaning Representation dataset can be automatically converted into an Open IE corpus which significantly increases the amount of available training data. Our <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised model</a> outperforms the existing state-of-the-art Open IE systems on <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark datasets</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2089.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-2089 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-2089 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-2089" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-2089/>Crowdsourcing Question-Answer Meaning Representations</a></strong><br><a href=/people/j/julian-michael/>Julian Michael</a>
|
<a href=/people/g/gabriel-stanovsky/>Gabriel Stanovsky</a>
|
<a href=/people/l/luheng-he/>Luheng He</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-2089><div class="card-body p-3 small">We introduce Question-Answer Meaning Representations (QAMRs), which represent the predicate-argument structure of a sentence as a set of question-answer pairs. We develop a crowdsourcing scheme to show that QAMRs can be labeled with very little training, and gather a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> with over 5,000 sentences and 100,000 questions. A qualitative analysis demonstrates that the crowd-generated question-answer pairs cover the vast majority of predicate-argument relationships in existing datasets (including <a href=https://en.wikipedia.org/wiki/PropBank>PropBank</a>, NomBank, and QA-SRL) along with many previously under-resourced ones, including implicit arguments and relations. We also report baseline models for question generation and answering, and summarize a recent approach for using QAMR labels to improve an Open IE system. These results suggest the freely available QAMR data and annotation scheme should support significant future work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1201.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1201 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1201 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1201.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805384 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1201" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1201/>Zero-Shot Transfer Learning for Event Extraction</a></strong><br><a href=/people/l/lifu-huang/>Lifu Huang</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/k/kyunghyun-cho/>Kyunghyun Cho</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a>
|
<a href=/people/s/sebastian-riedel/>Sebastian Riedel</a>
|
<a href=/people/c/clare-voss/>Clare Voss</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1201><div class="card-body p-3 small">Most previous supervised event extraction methods have relied on features derived from manual annotations, and thus can not be applied to new event types without extra annotation effort. We take a fresh look at <a href=https://en.wikipedia.org/wiki/Event_extraction>event extraction</a> and model it as a generic grounding problem : mapping each event mention to a specific type in a target event ontology. We design a transferable architecture of structural and compositional neural networks to jointly represent and map event mentions and types into a shared semantic space. Based on this new framework, we can select, for each event mention, the event type which is semantically closest in this space as its type. By leveraging manual annotations available for a small set of existing <a href=https://en.wikipedia.org/wiki/Event_(computing)>event types</a>, our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> can be applied to new unseen event types without additional manual annotations. When tested on 23 unseen event types, our zero-shot framework, without manual annotations, achieved performance comparable to a <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised model</a> trained from 3,000 sentences annotated with 500 event mentions.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2056.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2056 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2056 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P17-2056/>Integrating <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Linguistic Features</a> in Factuality Prediction over Unified Datasets</a></strong><br><a href=/people/g/gabriel-stanovsky/>Gabriel Stanovsky</a>
|
<a href=/people/j/judith-eckle-kohler/>Judith Eckle-Kohler</a>
|
<a href=/people/y/yevgeniy-puzikov/>Yevgeniy Puzikov</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a>
|
<a href=/people/i/iryna-gurevych/>Iryna Gurevych</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2056><div class="card-body p-3 small">Previous models for the assessment of commitment towards a predicate in a sentence (also known as factuality prediction) were trained and tested against a specific annotated dataset, subsequently limiting the generality of their results. In this work we propose an intuitive method for mapping three previously annotated corpora onto a single factuality scale, thereby enabling <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> to be tested across these <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a>. In addition, we design a novel model for factuality prediction by first extending a previous rule-based factuality prediction system and applying it over an abstraction of dependency trees, and then using the output of this system in a <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised classifier</a>. We show that this <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms previous <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> on all three <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>. We make both the unified factuality corpus and our new model publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-0902.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-0902 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-0902 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-0902" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-0902/>A Consolidated Open Knowledge Representation for Multiple Texts</a></strong><br><a href=/people/r/rachel-wities/>Rachel Wities</a>
|
<a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/g/gabriel-stanovsky/>Gabriel Stanovsky</a>
|
<a href=/people/m/meni-adler/>Meni Adler</a>
|
<a href=/people/o/ori-shapira/>Ori Shapira</a>
|
<a href=/people/s/shyam-upadhyay/>Shyam Upadhyay</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a>
|
<a href=/people/e/eugenio-martinez-camara/>Eugenio Martinez Camara</a>
|
<a href=/people/i/iryna-gurevych/>Iryna Gurevych</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a><br><a href=/volumes/W17-09/ class=text-muted>Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-0902><div class="card-body p-3 small">We propose to move from Open Information Extraction (OIE) ahead to Open Knowledge Representation (OKR), aiming to represent information conveyed jointly in a set of texts in an open text-based manner. We do so by consolidating OIE extractions using entity and predicate coreference, while modeling information containment between coreferring elements via lexical entailment. We suggest that generating OKR structures can be a useful step in the NLP pipeline, to give semantic applications an easy handle on consolidated information across multiple texts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S17-1019.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S17-1019 data-toggle=collapse aria-expanded=false aria-controls=abstract-S17-1019 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S17-1019/>Acquiring Predicate Paraphrases from News Tweets</a></strong><br><a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/g/gabriel-stanovsky/>Gabriel Stanovsky</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a><br><a href=/volumes/S17-1/ class=text-muted>Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S17-1019><div class="card-body p-3 small">We present a simple method for ever-growing extraction of predicate paraphrases from <a href=https://en.wikipedia.org/wiki/Headline>news headlines</a> in <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>. Analysis of the output of ten weeks of collection shows that the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrases</a> with different support levels is estimated between 60-86 %. We also demonstrate that our <a href=https://en.wikipedia.org/wiki/Resource>resource</a> is to a large extent complementary to existing resources, providing many novel <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrases</a>. Our <a href=https://en.wikipedia.org/wiki/Resource>resource</a> is publicly available, continuously expanding based on <a href=https://en.wikipedia.org/wiki/News>daily news</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1198.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1198 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1198 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1198/>A Simple <a href=https://en.wikipedia.org/wiki/Language_model>Language Model</a> based on PMI Matrix Approximations<span class=acl-fixed-case>PMI</span> Matrix Approximations</a></strong><br><a href=/people/o/oren-melamud/>Oren Melamud</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a>
|
<a href=/people/j/jacob-goldberger/>Jacob Goldberger</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1198><div class="card-body p-3 small">In this study, we introduce a new approach for learning language models by training them to estimate word-context pointwise mutual information (PMI), and then deriving the desired <a href=https://en.wikipedia.org/wiki/Conditional_probability>conditional probabilities</a> from PMI at test time. Specifically, we show that with minor modifications to word2vec&#8217;s algorithm, we get principled <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> that are closely related to the well-established Noise Contrastive Estimation (NCE) based language models. A compelling aspect of our approach is that our models are trained with the same simple negative sampling objective function that is commonly used in <a href=https://en.wikipedia.org/wiki/Word2vec>word2vec</a> to learn word embeddings.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Ido+Dagan" title="Search for 'Ido Dagan' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/g/gabriel-stanovsky/ class=align-middle>Gabriel Stanovsky</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/o/ori-shapira/ class=align-middle>Ori Shapira</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/i/iryna-gurevych/ class=align-middle>Iryna Gurevych</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/v/vered-shwartz/ class=align-middle>Vered Shwartz</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/y/yoav-goldberg/ class=align-middle>Yoav Goldberg</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/a/arie-cattan/ class=align-middle>Arie Cattan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/o/ori-ernst/ class=align-middle>Ori Ernst</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/ramakanth-pasunuru/ class=align-middle>Ramakanth Pasunuru</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jacob-goldberger/ class=align-middle>Jacob Goldberger</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/mohit-bansal/ class=align-middle>Mohit Bansal</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yevgeniy-puzikov/ class=align-middle>Yevgeniy Puzikov</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/julian-michael/ class=align-middle>Julian Michael</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/luke-zettlemoyer/ class=align-middle>Luke Zettlemoyer</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jonathan-mamou/ class=align-middle>Jonathan Mamou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/oren-pereg/ class=align-middle>Oren Pereg</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/moshe-wasserblat/ class=align-middle>Moshe Wasserblat</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alon-eirew/ class=align-middle>Alon Eirew</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yael-green/ class=align-middle>Yael Green</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shira-guskin/ class=align-middle>Shira Guskin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/peter-izsak/ class=align-middle>Peter Izsak</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/daniel-korat/ class=align-middle>Daniel Korat</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ari-bornstein/ class=align-middle>Ari Bornstein</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-lepioshkin/ class=align-middle>Michael Lepioshkin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/judith-eckle-kohler/ class=align-middle>Judith Eckle-Kohler</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/james-ravenscroft/ class=align-middle>James Ravenscroft</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/amanda-clare/ class=align-middle>Amanda Clare</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maria-liakata/ class=align-middle>Maria Liakata</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rachel-wities/ class=align-middle>Rachel Wities</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/meni-adler/ class=align-middle>Meni Adler</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shyam-upadhyay/ class=align-middle>Shyam Upadhyay</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dan-roth/ class=align-middle>Dan Roth</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eugenio-martinez-camara/ class=align-middle>Eugenio MartÃ­nez-CÃ¡mara</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/daniela-brook-weiss/ class=align-middle>Daniela Brook Weiss</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paul-roit/ class=align-middle>Paul Roit</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ayal-klein/ class=align-middle>Ayal Klein</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/oren-sar-shalom/ class=align-middle>Oren Sar Shalom</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexander-panchenko/ class=align-middle>Alexander Panchenko</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cicero-dos-santos/ class=align-middle>Cicero dos Santos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/varvara-logacheva/ class=align-middle>Varvara Logacheva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alessandro-moschitti/ class=align-middle>Alessandro Moschitti</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/oren-melamud/ class=align-middle>Oren Melamud</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/simeng-sun/ class=align-middle>Simeng Sun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ani-nenkova/ class=align-middle>Ani Nenkova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/claire-gardent/ class=align-middle>Claire Gardent</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/amit-moryossef/ class=align-middle>Amit Moryossef</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/david-gabay/ class=align-middle>David Gabay</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yang-gao/ class=align-middle>Yang Gao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hadar-ronen/ class=align-middle>Hadar Ronen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yael-amsterdamer/ class=align-middle>Yael Amsterdamer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luheng-he/ class=align-middle>Luheng He</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lifu-huang/ class=align-middle>Lifu Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/heng-ji/ class=align-middle>Heng Ji</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kyunghyun-cho/ class=align-middle>Kyunghyun Cho</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sebastian-riedel/ class=align-middle>Sebastian Riedel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/clare-voss/ class=align-middle>Clare Voss</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tobias-falke/ class=align-middle>Tobias Falke</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/leonardo-f-r-ribeiro/ class=align-middle>Leonardo F. R. Ribeiro</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/prasetya-ajie-utama/ class=align-middle>Prasetya Ajie Utama</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/ohad-rozen/ class=align-middle>Ohad Rozen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/roee-aharoni/ class=align-middle>Roee Aharoni</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/knlp/ class=align-middle>knlp</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>