<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Ivan Koychev - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Ivan</span> <span class=font-weight-bold>Koychev</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ranlp-1.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ranlp-1--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ranlp-1.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ranlp-1.22/>Predicting the Factuality of Reporting of News Media Using Observations about User Attention in Their YouTube Channels<span class=acl-fixed-case>Y</span>ou<span class=acl-fixed-case>T</span>ube Channels</a></strong><br><a href=/people/k/krasimira-bozhanova/>Krasimira Bozhanova</a>
|
<a href=/people/y/yoan-dinkov/>Yoan Dinkov</a>
|
<a href=/people/i/ivan-koychev/>Ivan Koychev</a>
|
<a href=/people/m/maria-castaldo/>Maria Castaldo</a>
|
<a href=/people/t/tommaso-venturini/>Tommaso Venturini</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/2021.ranlp-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ranlp-1--22><div class="card-body p-3 small">We propose a novel framework for predicting the factuality of reporting of news media outlets by studying the user attention cycles in their YouTube channels. In particular, we design a rich set of features derived from the temporal evolution of the number of views, likes, dislikes, and comments for a video, which we then aggregate to the channel level. We develop and release a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for the task, containing observations of user attention on YouTube channels for 489 <a href=https://en.wikipedia.org/wiki/News_media>news media</a>. Our experiments demonstrate both complementarity and sizable improvements over state-of-the-art textual representations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ranlp-1.162.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ranlp-1--162 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ranlp-1.162 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ranlp-1.162/>Comparative Analysis of Fine-tuned Deep Learning Language Models for ICD-10 Classification Task for Bulgarian Language<span class=acl-fixed-case>ICD</span>-10 Classification Task for <span class=acl-fixed-case>B</span>ulgarian Language</a></strong><br><a href=/people/b/boris-velichkov/>Boris Velichkov</a>
|
<a href=/people/s/sylvia-vassileva/>Sylvia Vassileva</a>
|
<a href=/people/s/simeon-gerginov/>Simeon Gerginov</a>
|
<a href=/people/b/boris-kraychev/>Boris Kraychev</a>
|
<a href=/people/i/ivaylo-ivanov/>Ivaylo Ivanov</a>
|
<a href=/people/p/philip-ivanov/>Philip Ivanov</a>
|
<a href=/people/i/ivan-koychev/>Ivan Koychev</a>
|
<a href=/people/s/svetla-boytcheva/>Svetla Boytcheva</a><br><a href=/volumes/2021.ranlp-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ranlp-1--162><div class="card-body p-3 small">The task of automatic diagnosis encoding into standard medical classifications and <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontologies</a>, is of great importance in medicine-both to support the daily tasks of physicians in the preparation and reporting of clinical documentation, and for automatic processing of clinical reports. In this paper we investigate the application and performance of different deep learning transformers for automatic encoding in <a href=https://en.wikipedia.org/wiki/ICD-10>ICD-10</a> of clinical texts in Bulgarian. The comparative analysis attempts to find which approach is more efficient to be used for fine-tuning of pretrained BERT family transformer to deal with a specific domain terminology on a rare language as <a href=https://en.wikipedia.org/wiki/Bulgarian_language>Bulgarian</a>. On the one side are used SlavicBERT and MultiligualBERT, that are pretrained for common vocabulary in Bulgarian, but lack <a href=https://en.wikipedia.org/wiki/Medical_terminology>medical terminology</a>. On the other hand in the analysis are used BioBERT, ClinicalBERT, SapBERT, BlueBERT, that are pretrained for medical terminology in English, but lack training for language models in <a href=https://en.wikipedia.org/wiki/Bulgarian_language>Bulgarian</a>, and more over for vocabulary in <a href=https://en.wikipedia.org/wiki/Cyrillic_script>Cyrillic</a>. In our research study all BERT models are fine-tuned with additional medical texts in Bulgarian and then applied to the classification task for encoding <a href=https://en.wikipedia.org/wiki/Medical_diagnosis>medical diagnoses</a> in Bulgarian into <a href=https://en.wikipedia.org/wiki/ICD-10>ICD-10 codes</a>. Big corpora of diagnosis in Bulgarian annotated with ICD-10 codes is used for the classification task. Such an analysis gives a good idea of which of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> would be suitable for <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> of a similar type and domain. The experiments and evaluation results show that both <a href=https://en.wikipedia.org/wiki/Methodology>approaches</a> have comparable accuracy.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.438.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--438 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.438 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938985 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.438" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.438/>EXAMS : A Multi-subject High School Examinations Dataset for Cross-lingual and Multilingual Question Answering<span class=acl-fixed-case>EXAMS</span>: A Multi-subject High School Examinations Dataset for Cross-lingual and Multilingual Question Answering</a></strong><br><a href=/people/m/momchil-hardalov/>Momchil Hardalov</a>
|
<a href=/people/t/todor-mihaylov/>Todor Mihaylov</a>
|
<a href=/people/d/dimitrina-zlatkova/>Dimitrina Zlatkova</a>
|
<a href=/people/y/yoan-dinkov/>Yoan Dinkov</a>
|
<a href=/people/i/ivan-koychev/>Ivan Koychev</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--438><div class="card-body p-3 small">We propose EXAMS a new benchmark dataset for cross-lingual and multilingual question answering for high school examinations. We collected more than 24,000 high-quality high school exam questions in 16 languages, covering 8 language families and 24 school subjects from Natural Sciences and Social Sciences, among others. EXAMS offers unique fine-grained evaluation framework across multiple languages and subjects, which allows precise analysis and comparison of the proposed models. We perform various experiments with existing top-performing multilingual pre-trained models and show that EXAMS offers multiple challenges that require multilingual knowledge and reasoning in multiple domains. We hope that EXAMS will enable researchers to explore challenging reasoning and knowledge transfer methods and pre-trained models for school question answering in various languages which was not possible by now. The data, code, pre-trained models, and evaluation are available at http://github.com/mhardalov/exams-qa.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1216.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1216 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1216 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1216" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1216/>Fact-Checking Meets Fauxtography : Verifying Claims About Images</a></strong><br><a href=/people/d/dimitrina-zlatkova/>Dimitrina Zlatkova</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/i/ivan-koychev/>Ivan Koychev</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1216><div class="card-body p-3 small">The recent explosion of false claims in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> and on the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>Web</a> in general has given rise to a lot of manual fact-checking initiatives. Unfortunately, the number of claims that need to be fact-checked is several orders of magnitude larger than what humans can handle manually. Thus, there has been a lot of research aiming at automating the process. Interestingly, previous work has largely ignored the growing number of claims about <a href=https://en.wikipedia.org/wiki/Image>images</a>. This is despite the fact that <a href=https://en.wikipedia.org/wiki/Visual_imagery>visual imagery</a> is more influential than <a href=https://en.wikipedia.org/wiki/Writing>text</a> and naturally appears alongside <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a>. Here we aim at bridging this gap. In particular, we create a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for this problem, and we explore a variety of <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> modeling the claim, the <a href=https://en.wikipedia.org/wiki/Image>image</a>, and the relationship between the claim and the image. The evaluation results show sizable improvements over the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a>. We release our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, hoping to enable further research on fact-checking claims about <a href=https://en.wikipedia.org/wiki/Digital_image>images</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1029.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1029 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1029 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=R19-1029" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/R19-1029/>Detecting Toxicity in <a href=https://en.wikipedia.org/wiki/Article_(publishing)>News Articles</a> : Application to Bulgarian<span class=acl-fixed-case>B</span>ulgarian</a></strong><br><a href=/people/y/yoan-dinkov/>Yoan Dinkov</a>
|
<a href=/people/i/ivan-koychev/>Ivan Koychev</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/R19-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1029><div class="card-body p-3 small">Online media aim for reaching ever bigger audience and for attracting ever longer attention span. This competition creates an environment that rewards sensational, fake, and toxic news. To help limit their spread and impact, we propose and develop a news toxicity detector that can recognize various types of toxic content. While previous research primarily focused on <a href=https://en.wikipedia.org/wiki/English_language>English</a>, here we target <a href=https://en.wikipedia.org/wiki/Bulgarian_language>Bulgarian</a>. We created a new dataset by crawling a website that for five years has been collecting Bulgarian news articles that were manually categorized into eight toxicity groups. Then we trained a multi-class classifier with nine categories : eight toxic and one non-toxic. We experimented with different representations based on ElMo, BERT, and XLM, as well as with a variety of domain-specific features. Due to the small size of our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, we created a separate <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> for each feature type, and we ultimately combined these <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> into a meta-classifier. The evaluation results show an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 59.0 % and a macro-F1 score of 39.7 %, which represent sizable improvements over the majority-class baseline (Acc=30.3 %, macro-F1=5.2 %).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1053.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1053 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1053 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=R19-1053" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/R19-1053/>Beyond English-Only Reading Comprehension : Experiments in Zero-shot Multilingual Transfer for Bulgarian<span class=acl-fixed-case>E</span>nglish-Only Reading Comprehension: Experiments in Zero-shot Multilingual Transfer for <span class=acl-fixed-case>B</span>ulgarian</a></strong><br><a href=/people/m/momchil-hardalov/>Momchil Hardalov</a>
|
<a href=/people/i/ivan-koychev/>Ivan Koychev</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a><br><a href=/volumes/R19-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1053><div class="card-body p-3 small">Recently, reading comprehension models achieved near-human performance on large-scale datasets such as SQuAD, CoQA, MS Macro, RACE, etc. This is largely due to the release of pre-trained contextualized representations such as <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> and ELMo, which can be fine-tuned for the target task. Despite those advances and the creation of more challenging datasets, most of the work is still done for <a href=https://en.wikipedia.org/wiki/English_language>English</a>. Here, we study the effectiveness of multilingual BERT fine-tuned on large-scale English datasets for <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> (e.g., for RACE), and we apply it to Bulgarian multiple-choice reading comprehension. We propose a new dataset containing 2,221 questions from <a href=https://en.wikipedia.org/wiki/Matriculation_examination>matriculation exams</a> for twelfth grade in various subjects history, biology, geography and philosophy, and 412 additional questions from online quizzes in history. While the quiz authors gave no relevant context, we incorporate knowledge from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, retrieving documents matching the combination of question + each answer option. Moreover, we experiment with different indexing and pre-training strategies. The evaluation results show accuracy of 42.23 %, which is well above the <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baseline</a> of 24.89 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1142.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1142 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1142 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1142/>Deep learning contextual models for prediction of sport event outcome from sportsman’s interviews</a></strong><br><a href=/people/b/boris-velichkov/>Boris Velichkov</a>
|
<a href=/people/i/ivan-koychev/>Ivan Koychev</a>
|
<a href=/people/s/svetla-boytcheva/>Svetla Boytcheva</a><br><a href=/volumes/R19-1/ class=text-muted>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1142><div class="card-body p-3 small">This paper presents an approach for prediction of results for <a href=https://en.wikipedia.org/wiki/Sport>sport events</a>. Usually the sport forecasting approaches are based on <a href=https://en.wikipedia.org/wiki/Structured_data>structured data</a>. We test the hypothesis that the sports results can be predicted by using <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> and machine learning techniques applied over interviews with the players shortly before the sport events. The proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> uses deep learning contextual models, applied over <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured textual documents</a>. Several experiments were performed for interviews with players in individual sports like <a href=https://en.wikipedia.org/wiki/Boxing>boxing</a>, <a href=https://en.wikipedia.org/wiki/Martial_arts>martial arts</a>, and <a href=https://en.wikipedia.org/wiki/Tennis>tennis</a>. The results from the conducted experiment confirmed our initial assumption that an interview from a sportsman before a match contains information that can be used for prediction the outcome from it. Furthermore, the results provide strong evidence in support of our research hypothesis, that is, we can predict the outcome from a sport match analyzing an interview, given before it.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Ivan+Koychev" title="Search for 'Ivan Koychev' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/p/preslav-nakov/ class=align-middle>Preslav Nakov</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/y/yoan-dinkov/ class=align-middle>Yoan Dinkov</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/b/boris-velichkov/ class=align-middle>Boris Velichkov</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/svetla-boytcheva/ class=align-middle>Svetla Boytcheva</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/momchil-hardalov/ class=align-middle>Momchil Hardalov</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/d/dimitrina-zlatkova/ class=align-middle>Dimitrina Zlatkova</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/krasimira-bozhanova/ class=align-middle>Krasimira Bozhanova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maria-castaldo/ class=align-middle>Maria Castaldo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tommaso-venturini/ class=align-middle>Tommaso Venturini</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sylvia-vassileva/ class=align-middle>Sylvia Vassileva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/simeon-gerginov/ class=align-middle>Simeon Gerginov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/boris-kraychev/ class=align-middle>Boris Kraychev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ivaylo-ivanov/ class=align-middle>Ivaylo Ivanov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/philip-ivanov/ class=align-middle>Philip Ivanov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/todor-mihaylov/ class=align-middle>Todor Mihaylov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ranlp/ class=align-middle>RANLP</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>