<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Wei Xu - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Wei</span> <span class=font-weight-bold>Xu</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.gem-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.gem-1.0/>Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)</a></strong><br><a href=/people/a/antoine-bosselut/>Antoine Bosselut</a>
|
<a href=/people/e/esin-durmus/>Esin Durmus</a>
|
<a href=/people/v/varun-prashant-gangal/>Varun Prashant Gangal</a>
|
<a href=/people/s/sebastian-gehrmann/>Sebastian Gehrmann</a>
|
<a href=/people/y/yacine-jernite/>Yacine Jernite</a>
|
<a href=/people/l/laura-perez-beltrachini/>Laura Perez-Beltrachini</a>
|
<a href=/people/s/samira-shaikh/>Samira Shaikh</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a><br><a href=/volumes/2021.gem-1/ class=text-muted>Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.gem-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--gem-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.gem-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.gem-1.10/>The GEM Benchmark : <a href=https://en.wikipedia.org/wiki/Natural-language_generation>Natural Language Generation</a>, its Evaluation and Metrics<span class=acl-fixed-case>GEM</span> Benchmark: Natural Language Generation, its Evaluation and Metrics</a></strong><br><a href=/people/s/sebastian-gehrmann/>Sebastian Gehrmann</a>
|
<a href=/people/t/tosin-adewumi/>Tosin Adewumi</a>
|
<a href=/people/k/karmanya-aggarwal/>Karmanya Aggarwal</a>
|
<a href=/people/p/pawan-sasanka-ammanamanchi/>Pawan Sasanka Ammanamanchi</a>
|
<a href=/people/a/anuoluwapo-aremu/>Anuoluwapo Aremu</a>
|
<a href=/people/a/antoine-bosselut/>Antoine Bosselut</a>
|
<a href=/people/k/khyathi-raghavi-chandu/>Khyathi Raghavi Chandu</a>
|
<a href=/people/m/miruna-clinciu/>Miruna-Adriana Clinciu</a>
|
<a href=/people/d/dipanjan-das/>Dipanjan Das</a>
|
<a href=/people/k/kaustubh-dhole/>Kaustubh Dhole</a>
|
<a href=/people/w/wanyu-du/>Wanyu Du</a>
|
<a href=/people/e/esin-durmus/>Esin Durmus</a>
|
<a href=/people/o/ondrej-dusek/>Ondřej Dušek</a>
|
<a href=/people/c/chris-chinenye-emezue/>Chris Chinenye Emezue</a>
|
<a href=/people/v/varun-gangal/>Varun Gangal</a>
|
<a href=/people/c/cristina-garbacea/>Cristina Garbacea</a>
|
<a href=/people/t/tatsunori-b-hashimoto/>Tatsunori Hashimoto</a>
|
<a href=/people/y/yufang-hou/>Yufang Hou</a>
|
<a href=/people/y/yacine-jernite/>Yacine Jernite</a>
|
<a href=/people/h/harsh-jhamtani/>Harsh Jhamtani</a>
|
<a href=/people/y/yangfeng-ji/>Yangfeng Ji</a>
|
<a href=/people/s/shailza-jolly/>Shailza Jolly</a>
|
<a href=/people/m/mihir-kale/>Mihir Kale</a>
|
<a href=/people/d/dhruv-kumar/>Dhruv Kumar</a>
|
<a href=/people/f/faisal-ladhak/>Faisal Ladhak</a>
|
<a href=/people/a/aman-madaan/>Aman Madaan</a>
|
<a href=/people/m/mounica-maddela/>Mounica Maddela</a>
|
<a href=/people/k/khyati-mahajan/>Khyati Mahajan</a>
|
<a href=/people/s/saad-mahamood/>Saad Mahamood</a>
|
<a href=/people/b/bodhisattwa-prasad-majumder/>Bodhisattwa Prasad Majumder</a>
|
<a href=/people/p/pedro-henrique-martins/>Pedro Henrique Martins</a>
|
<a href=/people/a/angelina-mcmillan-major/>Angelina McMillan-Major</a>
|
<a href=/people/s/simon-mille/>Simon Mille</a>
|
<a href=/people/e/emiel-van-miltenburg/>Emiel van Miltenburg</a>
|
<a href=/people/m/moin-nadeem/>Moin Nadeem</a>
|
<a href=/people/s/shashi-narayan/>Shashi Narayan</a>
|
<a href=/people/v/vitaly-nikolaev/>Vitaly Nikolaev</a>
|
<a href=/people/a/andre-niyongabo-rubungo/>Andre Niyongabo Rubungo</a>
|
<a href=/people/s/salomey-osei/>Salomey Osei</a>
|
<a href=/people/a/ankur-parikh/>Ankur Parikh</a>
|
<a href=/people/l/laura-perez-beltrachini/>Laura Perez-Beltrachini</a>
|
<a href=/people/n/niranjan-ramesh-rao/>Niranjan Ramesh Rao</a>
|
<a href=/people/v/vikas-raunak/>Vikas Raunak</a>
|
<a href=/people/j/juan-diego-rodriguez/>Juan Diego Rodriguez</a>
|
<a href=/people/s/sashank-santhanam/>Sashank Santhanam</a>
|
<a href=/people/j/joao-sedoc/>João Sedoc</a>
|
<a href=/people/t/thibault-sellam/>Thibault Sellam</a>
|
<a href=/people/s/samira-shaikh/>Samira Shaikh</a>
|
<a href=/people/a/anastasia-shimorina/>Anastasia Shimorina</a>
|
<a href=/people/m/marco-antonio-sobrevilla-cabezudo/>Marco Antonio Sobrevilla Cabezudo</a>
|
<a href=/people/h/hendrik-strobelt/>Hendrik Strobelt</a>
|
<a href=/people/n/nishant-subramani/>Nishant Subramani</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a>
|
<a href=/people/d/diyi-yang/>Diyi Yang</a>
|
<a href=/people/a/akhila-yerukola/>Akhila Yerukola</a>
|
<a href=/people/j/jiawei-zhou/>Jiawei Zhou</a><br><a href=/volumes/2021.gem-1/ class=text-muted>Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--gem-1--10><div class="card-body p-3 small">We introduce GEM, a living benchmark for natural language Generation (NLG), its Evaluation, and Metrics. Measuring progress in NLG relies on a constantly evolving ecosystem of automated metrics, <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, and human evaluation standards. Due to this moving target, new <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> often still evaluate on divergent anglo-centric corpora with well-established, but flawed, <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a>. This disconnect makes it challenging to identify the limitations of current <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> and opportunities for progress. Addressing this limitation, <a href=https://en.wikipedia.org/wiki/Graphics_Environment_Manager>GEM</a> provides an environment in which <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> can easily be applied to a wide set of <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> and in which <a href=https://en.wikipedia.org/wiki/Evaluation_strategy>evaluation strategies</a> can be tested. Regular updates to the <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark</a> will help NLG research become more multilingual and evolve the challenge alongside <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. This paper serves as the description of the data for the 2021 shared task at the associated GEM Workshop.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.409.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--409 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.409 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.409" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.409/>Pre-train or Annotate? Domain Adaptation with a Constrained Budget</a></strong><br><a href=/people/f/fan-bai/>Fan Bai</a>
|
<a href=/people/a/alan-ritter/>Alan Ritter</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--409><div class="card-body p-3 small">Recent work has demonstrated that pre-training in-domain language models can boost performance when adapting to a new domain. However, the costs associated with pre-training raise an important question : given a fixed budget, what steps should an NLP practitioner take to maximize performance? In this paper, we study domain adaptation under budget constraints, and approach it as a customer choice problem between data annotation and pre-training. Specifically, we measure the annotation cost of three procedural text datasets and the pre-training cost of three in-domain language models. Then we evaluate the utility of different combinations of pre-training and <a href=https://en.wikipedia.org/wiki/Annotation>data annotation</a> under varying <a href=https://en.wikipedia.org/wiki/Budget_constraint>budget constraints</a> to assess which combination strategy works best. We find that, for small budgets, spending all funds on <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a> leads to the best performance ; once the budget becomes large enough, a combination of data annotation and in-domain pre-training works more optimally. We therefore suggest that task-specific data annotation should be part of an economical strategy when adapting an NLP model to a new domain.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.500.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--500 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.500 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.500" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.500/>BiSECT : Learning to Split and Rephrase Sentences with Bitexts<span class=acl-fixed-case>B</span>i<span class=acl-fixed-case>SECT</span>: Learning to Split and Rephrase Sentences with Bitexts</a></strong><br><a href=/people/j/joongwon-kim/>Joongwon Kim</a>
|
<a href=/people/m/mounica-maddela/>Mounica Maddela</a>
|
<a href=/people/r/reno-kriz/>Reno Kriz</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a>
|
<a href=/people/c/chris-callison-burch/>Chris Callison-Burch</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--500><div class="card-body p-3 small">An important task in NLP applications such as <a href=https://en.wikipedia.org/wiki/Sentence_simplification>sentence simplification</a> is the ability to take a long, complex sentence and split it into shorter sentences, rephrasing as necessary. We introduce a novel <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and a new <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> for this &#8216;split and rephrase&#8217; task. Our BiSECT training data consists of 1 million long English sentences paired with shorter, meaning-equivalent English sentences. We obtain these by extracting 1-2 sentence alignments in bilingual parallel corpora and then using <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> to convert both sides of the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> into the same language. BiSECT contains higher quality training examples than the previous Split and Rephrase corpora, with sentence splits that require more significant modifications. We categorize examples in our <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> and use these categories in a novel model that allows us to target specific regions of the input sentence to be split and edited. Moreover, we show that models trained on BiSECT can perform a wider variety of split operations and improve upon previous state-of-the-art approaches in automatic and human evaluations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.0/>Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021)</a></strong><br><a href=/people/w/wei-xu/>Wei Xu</a>
|
<a href=/people/a/alan-ritter/>Alan Ritter</a>
|
<a href=/people/t/timothy-baldwin/>Tim Baldwin</a>
|
<a href=/people/a/afshin-rahimi/>Afshin Rahimi</a><br><a href=/volumes/2021.wnut-1/ class=text-muted>Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021)</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.382.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--382 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.382 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939107 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.382" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.382/>An Empirical Study of Pre-trained Transformers for Arabic Information Extraction<span class=acl-fixed-case>A</span>rabic Information Extraction</a></strong><br><a href=/people/w/wuwei-lan/>Wuwei Lan</a>
|
<a href=/people/y/yang-chen/>Yang Chen</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a>
|
<a href=/people/a/alan-ritter/>Alan Ritter</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--382><div class="card-body p-3 small">Multilingual pre-trained Transformers, such as mBERT (Devlin et al., 2019) and XLM-RoBERTa (Conneau et al., 2020a), have been shown to enable effective cross-lingual zero-shot transfer. However, their performance on Arabic information extraction (IE) tasks is not very well studied. In this paper, we pre-train a customized bilingual BERT, dubbed GigaBERT, that is designed specifically for Arabic NLP and English-to-Arabic zero-shot transfer learning. We study GigaBERT&#8217;s effectiveness on zero-short transfer across four IE tasks : <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>, <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a>, argument role labeling, and relation extraction. Our best model significantly outperforms mBERT, XLM-RoBERTa, and AraBERT (Antoun et al., 2020) in both the supervised and zero-shot transfer settings. We have made our pre-trained models publicly available at : https://github.com/lanwuwei/GigaBERT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wnut-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.wnut-1.0/>Proceedings of the Sixth Workshop on Noisy User-generated Text (W-NUT 2020)</a></strong><br><a href=/people/w/wei-xu/>Wei Xu</a>
|
<a href=/people/a/alan-ritter/>Alan Ritter</a>
|
<a href=/people/t/timothy-baldwin/>Tim Baldwin</a>
|
<a href=/people/a/afshin-rahimi/>Afshin Rahimi</a><br><a href=/volumes/2020.wnut-1/ class=text-muted>Proceedings of the Sixth Workshop on Noisy User-generated Text (W-NUT 2020)</a></span></p><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1032.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1032 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1032 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1032.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1032" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1032/>Doc2EDAG : An End-to-End Document-level Framework for Chinese Financial Event Extraction<span class=acl-fixed-case>D</span>oc2<span class=acl-fixed-case>EDAG</span>: An End-to-End Document-level Framework for <span class=acl-fixed-case>C</span>hinese Financial Event Extraction</a></strong><br><a href=/people/s/shun-zheng/>Shun Zheng</a>
|
<a href=/people/w/wei-cao/>Wei Cao</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a>
|
<a href=/people/j/jiang-bian/>Jiang Bian</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1032><div class="card-body p-3 small">Most existing event extraction (EE) methods merely extract event arguments within the sentence scope. However, such sentence-level EE methods struggle to handle soaring amounts of documents from emerging applications, such as <a href=https://en.wikipedia.org/wiki/Finance>finance</a>, <a href=https://en.wikipedia.org/wiki/Legislation>legislation</a>, <a href=https://en.wikipedia.org/wiki/Health>health</a>, etc., where event arguments always scatter across different sentences, and even multiple such event mentions frequently co-exist in the same document. To address these challenges, we propose a novel end-to-end model, Doc2EDAG, which can generate an entity-based directed acyclic graph to fulfill the document-level EE (DEE) effectively. Moreover, we reformalize a DEE task with the no-trigger-words design to ease the document-level event labeling. To demonstrate the effectiveness of Doc2EDAG, we build a large-scale real-world dataset consisting of Chinese financial announcements with the challenges mentioned above. Extensive experiments with comprehensive analyses illustrate the superiority of Doc2EDAG over state-of-the-art methods. Data and codes can be found at https://github.com/dolphin-zs/Doc2EDAG.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5500.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5500/>Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)</a></strong><br><a href=/people/w/wei-xu/>Wei Xu</a>
|
<a href=/people/a/alan-ritter/>Alan Ritter</a>
|
<a href=/people/t/timothy-baldwin/>Tim Baldwin</a>
|
<a href=/people/a/afshin-rahimi/>Afshin Rahimi</a><br><a href=/volumes/D19-55/ class=text-muted>Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1137.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1137 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1137 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1137" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1137/>DIAG-NRE : A Neural Pattern Diagnosis Framework for Distantly Supervised Neural Relation Extraction<span class=acl-fixed-case>DIAG</span>-<span class=acl-fixed-case>NRE</span>: A Neural Pattern Diagnosis Framework for Distantly Supervised Neural Relation Extraction</a></strong><br><a href=/people/s/shun-zheng/>Shun Zheng</a>
|
<a href=/people/x/xu-han/>Xu Han</a>
|
<a href=/people/y/yankai-lin/>Yankai Lin</a>
|
<a href=/people/p/peilin-yu/>Peilin Yu</a>
|
<a href=/people/l/lu-chen/>Lu Chen</a>
|
<a href=/people/l/ling-huang/>Ling Huang</a>
|
<a href=/people/z/zhiyuan-liu/>Zhiyuan Liu</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1137><div class="card-body p-3 small">Pattern-based labeling methods have achieved promising results in alleviating the inevitable labeling noises of distantly supervised neural relation extraction. However, these methods require significant expert labor to write relation-specific patterns, which makes them too sophisticated to generalize quickly. To ease the labor-intensive workload of pattern writing and enable the quick generalization to new relation types, we propose a neural pattern diagnosis framework, DIAG-NRE, that can automatically summarize and refine high-quality relational patterns from noise data with human experts in the loop. To demonstrate the effectiveness of DIAG-NRE, we apply it to two real-world datasets and present both significant and interpretable improvements over state-of-the-art methods.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1328.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1328 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1328 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=C18-1328" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/C18-1328/>Neural Network Models for Paraphrase Identification, <a href=https://en.wikipedia.org/wiki/Semantic_similarity>Semantic Textual Similarity</a>, <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>Natural Language Inference</a>, and <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a></a></strong><br><a href=/people/w/wuwei-lan/>Wuwei Lan</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1328><div class="card-body p-3 small">In this paper, we analyze several neural network designs (and their variations) for sentence pair modeling and compare their performance extensively across eight datasets, including paraphrase identification, <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic textual similarity</a>, <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language inference</a>, and <a href=https://en.wikipedia.org/wiki/Question_answering>question answering tasks</a>. Although most of these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> have claimed state-of-the-art performance, the original papers often reported on only one or two selected datasets. We provide a systematic study and show that (i) encoding contextual information by LSTM and inter-sentence interactions are critical, (ii) Tree-LSTM does not help as much as previously claimed but surprisingly improves performance on Twitter datasets, (iii) the Enhanced Sequential Inference Model is the best so far for larger datasets, while the Pairwise Word Interaction Model achieves the best performance when less data is available. We release our <a href=https://en.wikipedia.org/wiki/Implementation>implementations</a> as an open-source toolkit.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1410.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1410 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1410 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/306116474 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1410" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1410/>A Word-Complexity Lexicon and A Neural Readability Ranking Model for Lexical Simplification</a></strong><br><a href=/people/m/mounica-maddela/>Mounica Maddela</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1410><div class="card-body p-3 small">Current lexical simplification approaches rely heavily on <a href=https://en.wikipedia.org/wiki/Heuristics_in_judgment_and_decision-making>heuristics</a> and corpus level features that do not always align with <a href=https://en.wikipedia.org/wiki/Judgement>human judgment</a>. We create a human-rated word-complexity lexicon of 15,000 English words and propose a novel neural readability ranking model with a Gaussian-based feature vectorization layer that utilizes these human ratings to measure the complexity of any given word or phrase. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performs better than the state-of-the-art systems for different lexical simplification tasks and evaluation datasets. Additionally, we also produce SimplePPDB++, a lexical resource of over 10 million simplifying paraphrase rules, by applying our model to the Paraphrase Database (PPDB).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6100.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6100/>Proceedings of the 2018 <span class=acl-fixed-case>EMNLP</span> Workshop W-<span class=acl-fixed-case>NUT</span>: The 4th Workshop on Noisy User-generated Text</a></strong><br><a href=/people/w/wei-xu/>Wei Xu</a>
|
<a href=/people/a/alan-ritter/>Alan Ritter</a>
|
<a href=/people/t/timothy-baldwin/>Tim Baldwin</a>
|
<a href=/people/a/afshin-rahimi/>Afshin Rahimi</a><br><a href=/volumes/W18-61/ class=text-muted>Proceedings of the 2018 EMNLP Workshop W-NUT: The 4th Workshop on Noisy User-generated Text</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-2016 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-2016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-2016.Datasets.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-2016/>An Annotated Corpus for Machine Reading of Instructions in Wet Lab Protocols</a></strong><br><a href=/people/c/chaitanya-kulkarni/>Chaitanya Kulkarni</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a>
|
<a href=/people/a/alan-ritter/>Alan Ritter</a>
|
<a href=/people/r/raghu-machiraju/>Raghu Machiraju</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-2016><div class="card-body p-3 small">We describe an effort to annotate a corpus of natural language instructions consisting of 622 wet lab protocols to facilitate automatic or semi-automatic conversion of protocols into a machine-readable format and benefit biological research. Experimental results demonstrate the utility of our <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> for developing machine learning approaches to shallow semantic parsing of instructional texts. We make our annotated Wet Lab Protocol Corpus available to the research community.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2025.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-2025 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-2025 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-2025/>Character-Based Neural Networks for Sentence Pair Modeling</a></strong><br><a href=/people/w/wuwei-lan/>Wuwei Lan</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-2025><div class="card-body p-3 small">Sentence pair modeling is critical for many NLP tasks, such as paraphrase identification, <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic textual similarity</a>, and natural language inference. Most state-of-the-art neural models for these tasks rely on pretrained word embedding and compose sentence-level semantics in varied ways ; however, few works have attempted to verify whether we really need pretrained embeddings in these tasks. In this paper, we study how effective subword-level (character and character n-gram) representations are in sentence pair modeling. Though it is well-known that subword models are effective in tasks with single sentence input, including <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a> and <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, they have not been systematically studied in sentence pair modeling tasks where the semantic and string similarities between texts matter. Our experiments show that subword models without any pretrained word embedding can achieve new state-of-the-art results on two social media datasets and competitive results on news data for paraphrase identification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1243.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1243 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1243 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1243.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1243.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1243" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1243/>Interactive Language Acquisition with One-shot Visual Concept Learning through a Conversational Game</a></strong><br><a href=/people/h/haichao-zhang/>Haichao Zhang</a>
|
<a href=/people/h/haonan-yu/>Haonan Yu</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1243><div class="card-body p-3 small">Building <a href=https://en.wikipedia.org/wiki/Intelligent_agent>intelligent agents</a> that can communicate with and learn from humans in <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a> is of great value. Supervised language learning is limited by the ability of capturing mainly the statistics of training data, and is hardly adaptive to new scenarios or flexible for acquiring new knowledge without inefficient retraining or catastrophic forgetting. We highlight the perspective that conversational interaction serves as a natural interface both for <a href=https://en.wikipedia.org/wiki/Language_acquisition>language learning</a> and for novel <a href=https://en.wikipedia.org/wiki/Knowledge_acquisition>knowledge acquisition</a> and propose a joint imitation and reinforcement approach for grounded language learning through an interactive conversational game. The <a href=https://en.wikipedia.org/wiki/Intelligent_agent>agent</a> trained with this approach is able to actively acquire information by asking questions about novel objects and use the just-learned knowledge in subsequent conversations in a one-shot fashion. Results compared with other methods verified the effectiveness of the proposed approach.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4400.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4400/>Proceedings of the 3rd Workshop on Noisy User-generated Text</a></strong><br><a href=/people/l/leon-derczynski/>Leon Derczynski</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a>
|
<a href=/people/a/alan-ritter/>Alan Ritter</a>
|
<a href=/people/t/timothy-baldwin/>Tim Baldwin</a><br><a href=/volumes/W17-44/ class=text-muted>Proceedings of the 3rd Workshop on Noisy User-generated Text</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4901.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4901 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4901 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4901/>From Shakespeare to <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> : What are Language Styles all about?<span class=acl-fixed-case>T</span>witter: What are Language Styles all about?</a></strong><br><a href=/people/w/wei-xu/>Wei Xu</a><br><a href=/volumes/W17-49/ class=text-muted>Proceedings of the Workshop on Stylistic Variation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4901><div class="card-body p-3 small">As <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> research is growing and largely driven by the availability of data, we expanded research from news and small-scale dialog corpora to web and social media. User-generated data and <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a> opened the door for investigating <a href=https://en.wikipedia.org/wiki/Human_language>human language</a> of various styles with more statistical power and real-world applications. In this position / survey paper, I will review and discuss seven language styles that I believe to be important and interesting to study : influential work in the past, challenges at the present, and potential impact for the future.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1126.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1126 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1126 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1126/>A Continuously Growing Dataset of Sentential Paraphrases</a></strong><br><a href=/people/w/wuwei-lan/>Wuwei Lan</a>
|
<a href=/people/s/siyu-qiu/>Siyu Qiu</a>
|
<a href=/people/h/hua-he/>Hua He</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1126><div class="card-body p-3 small">A major challenge in paraphrase research is the lack of <a href=https://en.wikipedia.org/wiki/Parallel_text>parallel corpora</a>. In this paper, we present a new method to collect large-scale sentential paraphrases from <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> by linking tweets through shared URLs. The main advantage of our method is its simplicity, as it gets rid of the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> or human in the loop needed to select data before <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a> and subsequent application of paraphrase identification algorithms in the previous work. We present the largest human-labeled paraphrase corpus to date of 51,524 sentence pairs and the first cross-domain benchmarking for automatic paraphrase identification. In addition, we show that more than 30,000 new sentential paraphrases can be easily and continuously captured every month at ~70 % precision, and demonstrate their utility for downstream NLP tasks through phrasal paraphrase extraction. We make our code and data freely available.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Wei+Xu" title="Search for 'Wei Xu' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/a/alan-ritter/ class=align-middle>Alan Ritter</a>
<span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/people/t/timothy-baldwin/ class=align-middle>Timothy Baldwin</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/w/wuwei-lan/ class=align-middle>Wuwei Lan</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/a/afshin-rahimi/ class=align-middle>Afshin Rahimi</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/m/mounica-maddela/ class=align-middle>Mounica Maddela</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/a/antoine-bosselut/ class=align-middle>Antoine Bosselut</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/esin-durmus/ class=align-middle>Esin Durmus</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sebastian-gehrmann/ class=align-middle>Sebastian Gehrmann</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yacine-jernite/ class=align-middle>Yacine Jernite</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/laura-perez-beltrachini/ class=align-middle>Laura Perez-Beltrachini</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/samira-shaikh/ class=align-middle>Samira Shaikh</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/shun-zheng/ class=align-middle>Shun Zheng</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yang-chen/ class=align-middle>Yang Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/leon-derczynski/ class=align-middle>Leon Derczynski</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/varun-prashant-gangal/ class=align-middle>Varun Prashant Gangal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tosin-adewumi/ class=align-middle>Tosin Adewumi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/karmanya-aggarwal/ class=align-middle>Karmanya Aggarwal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pawan-sasanka-ammanamanchi/ class=align-middle>Pawan Sasanka Ammanamanchi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anuoluwapo-aremu/ class=align-middle>Anuoluwapo Aremu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/khyathi-raghavi-chandu/ class=align-middle>Khyathi Raghavi Chandu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/miruna-clinciu/ class=align-middle>Miruna Clinciu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dipanjan-das/ class=align-middle>Dipanjan Das</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kaustubh-dhole/ class=align-middle>Kaustubh Dhole</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wanyu-du/ class=align-middle>Wanyu Du</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/ondrej-dusek/ class=align-middle>Ondřej Dušek</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chris-chinenye-emezue/ class=align-middle>Chris Chinenye Emezue</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/varun-gangal/ class=align-middle>Varun Gangal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cristina-garbacea/ class=align-middle>Cristina Garbacea</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tatsunori-b-hashimoto/ class=align-middle>Tatsunori B. Hashimoto</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yufang-hou/ class=align-middle>Yufang Hou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/harsh-jhamtani/ class=align-middle>Harsh Jhamtani</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yangfeng-ji/ class=align-middle>Yangfeng Ji</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shailza-jolly/ class=align-middle>Shailza Jolly</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mihir-kale/ class=align-middle>Mihir Kale</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dhruv-kumar/ class=align-middle>Dhruv Kumar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/faisal-ladhak/ class=align-middle>Faisal Ladhak</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aman-madaan/ class=align-middle>Aman Madaan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/khyati-mahajan/ class=align-middle>Khyati Mahajan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/saad-mahamood/ class=align-middle>Saad Mahamood</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bodhisattwa-prasad-majumder/ class=align-middle>Bodhisattwa Prasad Majumder</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pedro-henrique-martins/ class=align-middle>Pedro Henrique Martins</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/angelina-mcmillan-major/ class=align-middle>Angelina McMillan-Major</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/simon-mille/ class=align-middle>Simon Mille</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/emiel-van-miltenburg/ class=align-middle>Emiel Van Miltenburg</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/moin-nadeem/ class=align-middle>Moin Nadeem</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shashi-narayan/ class=align-middle>Shashi Narayan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vitaly-nikolaev/ class=align-middle>Vitaly Nikolaev</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andre-niyongabo-rubungo/ class=align-middle>Andre Niyongabo Rubungo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/salomey-osei/ class=align-middle>Salomey Osei</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ankur-parikh/ class=align-middle>Ankur Parikh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/niranjan-ramesh-rao/ class=align-middle>Niranjan Ramesh Rao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vikas-raunak/ class=align-middle>Vikas Raunak</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/juan-diego-rodriguez/ class=align-middle>Juan Diego Rodriguez</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sashank-santhanam/ class=align-middle>Sashank Santhanam</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joao-sedoc/ class=align-middle>João Sedoc</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thibault-sellam/ class=align-middle>Thibault Sellam</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anastasia-shimorina/ class=align-middle>Anastasia Shimorina</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marco-antonio-sobrevilla-cabezudo/ class=align-middle>Marco Antonio Sobrevilla Cabezudo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hendrik-strobelt/ class=align-middle>Hendrik Strobelt</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nishant-subramani/ class=align-middle>Nishant Subramani</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/diyi-yang/ class=align-middle>Diyi Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/akhila-yerukola/ class=align-middle>Akhila Yerukola</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiawei-zhou/ class=align-middle>Jiawei Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fan-bai/ class=align-middle>Fan Bai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joongwon-kim/ class=align-middle>Joongwon Kim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/reno-kriz/ class=align-middle>Reno Kriz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chris-callison-burch/ class=align-middle>Chris Callison-Burch</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wei-cao/ class=align-middle>Wei Cao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiang-bian/ class=align-middle>Jiang Bian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/siyu-qiu/ class=align-middle>Siyu Qiu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hua-he/ class=align-middle>Hua He</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chaitanya-kulkarni/ class=align-middle>Chaitanya Kulkarni</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/raghu-machiraju/ class=align-middle>Raghu Machiraju</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haichao-zhang/ class=align-middle>Haichao Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haonan-yu/ class=align-middle>Haonan Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xu-han/ class=align-middle>Xu Han</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yankai-lin/ class=align-middle>Yankai Lin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/peilin-yu/ class=align-middle>Peilin Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lu-chen/ class=align-middle>Lu Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/ling-huang/ class=align-middle>Ling Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhiyuan-liu/ class=align-middle>Zhiyuan Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/gem/ class=align-middle>GEM</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/wnut/ class=align-middle>WNUT</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>