<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Wei Lu - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Wei</span> <span class=font-weight-bold>Lu</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.204.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--204 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.204 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.204" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.204/>Exploring Task Difficulty for Few-Shot Relation Extraction</a></strong><br><a href=/people/j/jiale-han/>Jiale Han</a>
|
<a href=/people/b/bo-cheng/>Bo Cheng</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--204><div class="card-body p-3 small">Few-shot relation extraction (FSRE) focuses on recognizing novel relations by learning with merely a handful of annotated instances. Meta-learning has been widely adopted for such a <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, which trains on randomly generated few-shot tasks to learn generic data representations. Despite impressive results achieved, existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> still perform suboptimally when handling hard FSRE tasks, where the relations are fine-grained and similar to each other. We argue this is largely because existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> do not distinguish <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>hard tasks</a> from easy ones in the <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>learning process</a>. In this paper, we introduce a novel approach based on contrastive learning that learns better <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> by exploiting relation label information. We further design a <a href=https://en.wikipedia.org/wiki/Methodology>method</a> that allows the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to adaptively learn how to focus on hard tasks. Experiments on two standard datasets demonstrate the effectiveness of our <a href=https://en.wikipedia.org/wiki/Methodology>method</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.317.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--317 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.317 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.emnlp-main.317.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.317" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.317/>To be Closer : Learning to Link up Aspects with Opinions</a></strong><br><a href=/people/y/yuxiang-zhou/>Yuxiang Zhou</a>
|
<a href=/people/l/lejian-liao/>Lejian Liao</a>
|
<a href=/people/y/yang-gao/>Yang Gao</a>
|
<a href=/people/z/zhanming-jie/>Zhanming Jie</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--317><div class="card-body p-3 small">Dependency parse trees are helpful for discovering the opinion words in aspect-based sentiment analysis (ABSA) (CITATION). However, the <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>trees</a> obtained from off-the-shelf dependency parsers are static, and could be sub-optimal in ABSA. This is because the syntactic trees are not designed for capturing the interactions between opinion words and aspect words. In this work, we aim to shorten the distance between <a href=https://en.wikipedia.org/wiki/Grammatical_aspect>aspects</a> and corresponding opinion words by learning an aspect-centric tree structure. The aspect and opinion words are expected to be closer along such <a href=https://en.wikipedia.org/wiki/Tree_structure>tree structure</a> compared to the standard dependency parse tree. The learning process allows the <a href=https://en.wikipedia.org/wiki/Tree_structure>tree structure</a> to adaptively correlate the aspect and opinion words, enabling us to better identify the polarity in the ABSA task. We conduct experiments on five aspect-based sentiment datasets, and the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> significantly outperforms recent strong baselines. Furthermore, our thorough analysis demonstrates the average distance between aspect and opinion words are shortened by at least 19 % on the standard SemEval Restaurant14 (CITATION) dataset.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.90.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--90 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.90 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938972 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.90" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.90/>ENT-DESC : Entity Description Generation by Exploring Knowledge Graph<span class=acl-fixed-case>ENT</span>-<span class=acl-fixed-case>DESC</span>: Entity Description Generation by Exploring Knowledge Graph</a></strong><br><a href=/people/l/liying-cheng/>Liying Cheng</a>
|
<a href=/people/d/dekun-wu/>Dekun Wu</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/y/yan-zhang/>Yan Zhang</a>
|
<a href=/people/z/zhanming-jie/>Zhanming Jie</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--90><div class="card-body p-3 small">Previous works on knowledge-to-text generation take as input a few <a href=https://en.wikipedia.org/wiki/Resource_Description_Framework>RDF triples</a> or key-value pairs conveying the knowledge of some entities to generate a <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language description</a>. Existing datasets, such as WIKIBIO, WebNLG, and <a href=https://en.wikipedia.org/wiki/E2E>E2E</a>, basically have a good alignment between an input triple / pair set and its output text. However, in practice, the input knowledge could be more than enough, since the output description may only cover the most significant knowledge. In this paper, we introduce a large-scale and challenging dataset to facilitate the study of such a practical scenario in KG-to-text. Our dataset involves retrieving abundant knowledge of various types of main entities from a large knowledge graph (KG), which makes the current graph-to-sequence models severely suffer from the problems of <a href=https://en.wikipedia.org/wiki/Information_loss>information loss</a> and parameter explosion while generating the descriptions. We address these challenges by proposing a multi-graph structure that is able to represent the original <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph information</a> more comprehensively. Furthermore, we also incorporate aggregation methods that learn to extract the rich graph information. Extensive experiments demonstrate the effectiveness of our model architecture.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.183.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--183 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.183 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.183.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939300 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.183" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.183/>Position-Aware Tagging for Aspect Sentiment Triplet Extraction</a></strong><br><a href=/people/l/lu-xu/>Lu Xu</a>
|
<a href=/people/h/hao-li/>Hao Li</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--183><div class="card-body p-3 small">Aspect Sentiment Triplet Extraction (ASTE) is the task of extracting the triplets of target entities, their associated sentiment, and opinion spans explaining the reason for the sentiment. Existing research efforts mostly solve this problem using pipeline approaches, which break the triplet extraction process into several stages. Our observation is that the three elements within a triplet are highly related to each other, and this motivates us to build a joint model to extract such triplets using a sequence tagging approach. However, how to effectively design a tagging approach to extract the triplets that can capture the rich interactions among the elements is a challenging research question. In this work, we propose the first <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end model</a> with a novel position-aware tagging scheme that is capable of jointly extracting the <a href=https://en.wikipedia.org/wiki/Multiple_birth>triplets</a>. Our experimental results on several existing datasets show that jointly capturing elements in the triplet using our approach leads to improved performance over the existing approaches. We also conducted extensive experiments to investigate the model effectiveness and robustness.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.569.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--569 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.569 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939058 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.569" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.569/>APE : Argument Pair Extraction from Peer Review and Rebuttal via <a href=https://en.wikipedia.org/wiki/Multi-task_learning>Multi-task Learning</a><span class=acl-fixed-case>APE</span>: Argument Pair Extraction from Peer Review and Rebuttal via Multi-task Learning</a></strong><br><a href=/people/l/liying-cheng/>Liying Cheng</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/q/qian-yu/>Qian Yu</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--569><div class="card-body p-3 small">Peer review and rebuttal, with rich interactions and argumentative discussions in between, are naturally a good resource to mine arguments. However, few works study both of <a href=https://en.wikipedia.org/wiki/List_of_Latin_phrases_(I)>them</a> simultaneously. In this paper, we introduce a new argument pair extraction (APE) task on peer review and rebuttal in order to study the contents, the structure and the connections between them. We prepare a challenging <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> that contains 4,764 fully annotated review-rebuttal passage pairs from an open review platform to facilitate the study of this task. To automatically detect argumentative propositions and extract argument pairs from this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, we cast it as the combination of a sequence labeling task and a text relation classification task. Thus, we propose a multitask learning framework based on hierarchical LSTM networks. Extensive experiments and analysis demonstrate the effectiveness of our multi-task framework, and also show the challenges of the new <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> as well as motivate future research directions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.312.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--312 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.312 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929360 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.312/>Understanding Attention for <a href=https://en.wikipedia.org/wiki/Text_classification>Text Classification</a></a></strong><br><a href=/people/x/xiaobing-sun/>Xiaobing Sun</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--312><div class="card-body p-3 small">Attention has been proven successful in many <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP) tasks</a>. Recently, many researchers started to investigate the interpretability of <a href=https://en.wikipedia.org/wiki/Attention>attention</a> on NLP tasks. Many existing approaches focused on examining whether the local attention weights could reflect the importance of input representations. In this work, we present a study on understanding the internal mechanism of attention by looking into the gradient update process, checking its behavior when approaching a <a href=https://en.wikipedia.org/wiki/Maxima_and_minima>local minimum</a> during <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a>. We propose to analyze for each word token the following two quantities : its polarity score and its attention score, where the latter is a global assessment on the token&#8217;s significance. We discuss conditions under which the attention mechanism may become more (or less) interpretable, and show how the interplay between the two quantities can contribute towards model performance.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1451.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1451 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1451 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1451" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1451/>Aligning Cross-Lingual Entities with Multi-Aspect Information</a></strong><br><a href=/people/h/hsiu-wei-yang/>Hsiu-Wei Yang</a>
|
<a href=/people/y/yanyan-zou/>Yanyan Zou</a>
|
<a href=/people/p/peng-shi/>Peng Shi</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/j/jimmy-lin/>Jimmy Lin</a>
|
<a href=/people/x/xu-sun/>Xu Sun</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1451><div class="card-body p-3 small">Multilingual knowledge graphs (KGs), such as YAGO and DBpedia, represent entities in different languages. The task of cross-lingual entity alignment is to match entities in a source language with their counterparts in target languages. In this work, we investigate embedding-based approaches to encode <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entities</a> from multilingual KGs into the same <a href=https://en.wikipedia.org/wiki/Vector_space>vector space</a>, where equivalent entities are close to each other. Specifically, we apply graph convolutional networks (GCNs) to combine multi-aspect information of entities, including topological connections, relations, and attributes of entities, to learn entity embeddings. To exploit the literal descriptions of entities expressed in different languages, we propose two uses of a pretrained multilingual BERT model to bridge cross-lingual gaps. We further propose two strategies to integrate GCN-based and BERT-based modules to boost performance. Extensive experiments on two benchmark datasets demonstrate that our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> significantly outperforms existing <a href=https://en.wikipedia.org/wiki/System>systems</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-3041.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-3041 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-3041 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-3041" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-3041/>UER : An Open-Source Toolkit for Pre-training Models<span class=acl-fixed-case>UER</span>: An Open-Source Toolkit for Pre-training Models</a></strong><br><a href=/people/z/zhe-zhao/>Zhe Zhao</a>
|
<a href=/people/h/hui-chen/>Hui Chen</a>
|
<a href=/people/j/jinbin-zhang/>Jinbin Zhang</a>
|
<a href=/people/w/wayne-xin-zhao/>Xin Zhao</a>
|
<a href=/people/t/tao-liu/>Tao Liu</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/x/xi-chen/>Xi Chen</a>
|
<a href=/people/h/haotang-deng/>Haotang Deng</a>
|
<a href=/people/q/qi-ju/>Qi Ju</a>
|
<a href=/people/x/xiaoyong-du/>Xiaoyong Du</a><br><a href=/volumes/D19-3/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-3041><div class="card-body p-3 small">Existing works, including <a href=https://en.wikipedia.org/wiki/ELMO>ELMO</a> and <a href=https://en.wikipedia.org/wiki/BERT>BERT</a>, have revealed the importance of pre-training for NLP tasks. While there does not exist a single pre-training model that works best in all cases, it is of necessity to develop a <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> that is able to deploy various pre-training models efficiently. For this purpose, we propose an assemble-on-demand pre-training toolkit, namely Universal Encoder Representations (UER). UER is loosely coupled, and encapsulated with <a href=https://en.wikipedia.org/wiki/Modular_programming>rich modules</a>. By assembling modules on demand, users can either reproduce a state-of-the-art pre-training model or develop a pre-training model that remains unexplored. With UER, we have built a model zoo, which contains pre-trained models based on different corpora, encoders, and targets (objectives). With proper pre-trained models, we could achieve new state-of-the-art results on a range of downstream datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1079.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1079 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1079 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N19-1079.Supplementary.zip data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N19-1079.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/360565437 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-1079/>Better Modeling of Incomplete Annotations for Named Entity Recognition</a></strong><br><a href=/people/z/zhanming-jie/>Zhanming Jie</a>
|
<a href=/people/p/pengjun-xie/>Pengjun Xie</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/r/ruixue-ding/>Ruixue Ding</a>
|
<a href=/people/l/linlin-li/>Linlin Li</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1079><div class="card-body p-3 small">Supervised approaches to named entity recognition (NER) are largely developed based on the assumption that the training data is fully annotated with named entity information. However, in practice, annotated data can often be imperfect with one typical issue being the training data may contain incomplete annotations. We highlight several pitfalls associated with learning under such a setup in the context of <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>NER</a> and identify limitations associated with existing approaches, proposing a novel yet easy-to-implement approach for recognizing named entities with incomplete data annotations. We demonstrate the effectiveness of our <a href=https://en.wikipedia.org/wiki/Scientific_method>approach</a> through extensive experiments.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1217.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1217 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1217 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/355805085 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1217" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-1217/>Joint Detection and Location of English Puns<span class=acl-fixed-case>E</span>nglish Puns</a></strong><br><a href=/people/y/yanyan-zou/>Yanyan Zou</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1217><div class="card-body p-3 small">A pun is a form of <a href=https://en.wikipedia.org/wiki/Word_play>wordplay</a> for an intended humorous or rhetorical effect, where a word suggests two or more meanings by exploiting <a href=https://en.wikipedia.org/wiki/Polysemy>polysemy</a> (homographic pun) or phonological similarity to another word (heterographic pun). This paper presents an approach that addresses pun detection and pun location jointly from a sequence labeling perspective. We employ a new tagging scheme such that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is capable of performing such a joint task, where useful structural information can be properly captured. We show that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is effective in handling both homographic and heterographic puns. Empirical results on the benchmark datasets demonstrate that our approach can achieve new state-of-the-art results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383992004 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1024" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1024/>Attention Guided Graph Convolutional Networks for Relation Extraction</a></strong><br><a href=/people/z/zhijiang-guo/>Zhijiang Guo</a>
|
<a href=/people/y/yan-zhang/>Yan Zhang</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1024><div class="card-body p-3 small">Dependency trees convey rich structural information that is proven useful for extracting relations among entities in text. However, how to effectively make use of relevant information while ignoring irrelevant information from the dependency trees remains a challenging research question. Existing approaches employing rule based hard-pruning strategies for selecting relevant partial dependency structures may not always yield optimal results. In this work, we propose Attention Guided Graph Convolutional Networks (AGGCNs), a novel model which directly takes full dependency trees as inputs. Our model can be understood as a soft-pruning approach that automatically learns how to selectively attend to the relevant sub-structures useful for the relation extraction task. Extensive results on various tasks including cross-sentence n-ary relation extraction and large-scale sentence-level relation extraction show that our model is able to better leverage the structural information of the full dependency trees, giving significantly better results than previous approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1141.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1141 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1141 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1141.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1141.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1141" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1141/>A Neural Multi-digraph Model for Chinese NER with Gazetteers<span class=acl-fixed-case>C</span>hinese <span class=acl-fixed-case>NER</span> with Gazetteers</a></strong><br><a href=/people/r/ruixue-ding/>Ruixue Ding</a>
|
<a href=/people/p/pengjun-xie/>Pengjun Xie</a>
|
<a href=/people/x/xiaoyan-zhang/>Xiaoyan Zhang</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/l/linlin-li/>Linlin Li</a>
|
<a href=/people/l/luo-si/>Luo Si</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1141><div class="card-body p-3 small">Gazetteers were shown to be useful resources for named entity recognition (NER). Many existing approaches to incorporating <a href=https://en.wikipedia.org/wiki/Gazetteer>gazetteers</a> into machine learning based NER systems rely on manually defined selection strategies or handcrafted templates, which may not always lead to optimal effectiveness, especially when multiple gazetteers are involved. This is especially the case for the task of Chinese NER, where the words are not naturally tokenized, leading to additional <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguities</a>. To automatically learn how to incorporate multiple <a href=https://en.wikipedia.org/wiki/Gazetteer>gazetteers</a> into an NER system, we propose a novel approach based on graph neural networks with a multi-digraph structure that captures the information that the <a href=https://en.wikipedia.org/wiki/Gazetteer>gazetteers</a> offer. Experiments on various datasets show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is effective in incorporating rich gazetteer information while resolving <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguities</a>, outperforming previous approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1252.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1252 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1252 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1252.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1252" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1252/>Twitter Homophily : Network Based Prediction of User’s Occupation<span class=acl-fixed-case>T</span>witter Homophily: Network Based Prediction of User’s Occupation</a></strong><br><a href=/people/j/jiaqi-pan/>Jiaqi Pan</a>
|
<a href=/people/r/rishabh-bhardwaj/>Rishabh Bhardwaj</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/h/hai-leong-chieu/>Hai Leong Chieu</a>
|
<a href=/people/x/xinghao-pan/>Xinghao Pan</a>
|
<a href=/people/n/ni-yi-puay/>Ni Yi Puay</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1252><div class="card-body p-3 small">In this paper, we investigate the importance of <a href=https://en.wikipedia.org/wiki/Social_network>social network information</a> compared to <a href=https://en.wikipedia.org/wiki/Content_(media)>content information</a> in the prediction of a Twitter user&#8217;s occupational class. We show that the content information of a user&#8217;s tweets, the profile descriptions of a user&#8217;s follower / following community, and the user&#8217;s social network provide useful information for classifying a user&#8217;s occupational group. In our study, we extend an existing <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> for this <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a>, and we achieve significantly better performance by using social network homophily that has not been fully exploited in previous work. In our analysis, we found that by using the graph convolutional network to exploit social homophily, we can achieve competitive performance on this <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> with just a small fraction of the training data.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1226.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1226 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1226 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1226/>Neural Adaptation Layers for Cross-domain Named Entity Recognition</a></strong><br><a href=/people/b/bill-yuchen-lin/>Bill Yuchen Lin</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1226><div class="card-body p-3 small">Recent research efforts have shown that neural architectures can be effective in conventional information extraction tasks such as <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>, yielding state-of-the-art results on standard newswire datasets. However, despite significant resources required for training such models, the performance of a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> trained on one domain typically degrades dramatically when applied to a different domain, yet extracting entities from new emerging domains such as <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> can be of significant interest. In this paper, we empirically investigate effective methods for conveniently adapting an existing, well-trained neural NER model for a new domain. Unlike existing approaches, we propose lightweight yet effective <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> for performing <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> for neural models. Specifically, we introduce adaptation layers on top of existing neural architectures, where no re-training using the source domain data is required. We conduct extensive empirical studies and show that our approach significantly outperforms state-of-the-art methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1265.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1265 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1265 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D18-1265.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/306052219 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1265/>Dependency-based Hybrid Trees for Semantic Parsing</a></strong><br><a href=/people/z/zhanming-jie/>Zhanming Jie</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1265><div class="card-body p-3 small">We propose a novel dependency-based hybrid tree model for <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a>, which converts natural language utterance into machine interpretable meaning representations. Unlike previous state-of-the-art models, the semantic information is interpreted as the latent dependency between the natural language words in our joint representation. Such dependency information can capture the interactions between the <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> and <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language words</a>. We integrate a neural component into our model and propose an efficient dynamic-programming algorithm to perform tractable inference. Through extensive experiments on the standard multilingual GeoQuery dataset with eight languages, we demonstrate that our proposed approach is able to achieve state-of-the-art performance across several languages. Analysis also justifies the effectiveness of using our new dependency-based representation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-2000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-2000/>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</a></strong><br><a href=/people/e/eduardo-blanco/>Eduardo Blanco</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a><br><a href=/volumes/D18-2/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1113.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1113 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1113 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1113/>SemEval-2018 Task 8 : Semantic Extraction from CybersecUrity REports using Natural Language Processing (SecureNLP)<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 8: Semantic Extraction from <span class=acl-fixed-case>C</span>ybersec<span class=acl-fixed-case>U</span>rity <span class=acl-fixed-case>RE</span>ports using Natural Language Processing (<span class=acl-fixed-case>S</span>ecure<span class=acl-fixed-case>NLP</span>)</a></strong><br><a href=/people/p/peter-phandi/>Peter Phandi</a>
|
<a href=/people/a/amila-silva/>Amila Silva</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1113><div class="card-body p-3 small">This paper describes the <a href=https://en.wikipedia.org/wiki/SemEval>SemEval 2018 shared task</a> on semantic extraction from cybersecurity reports, which is introduced for the first time as a shared task on <a href=https://en.wikipedia.org/wiki/SemEval>SemEval</a>. This task comprises four SubTasks done incrementally to predict the characteristics of a specific malware using cybersecurity reports. To the best of our knowledge, we introduce the world&#8217;s largest publicly available dataset of annotated malware reports in this task. This <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> received in total 18 submissions from 9 participating teams.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-2085.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-2085 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-2085 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-2085.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-2085.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-2085/>Learning with Structured Representations for Negation Scope Extraction</a></strong><br><a href=/people/h/hao-li/>Hao Li</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a><br><a href=/volumes/P18-2/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-2085><div class="card-body p-3 small">We report an empirical study on the task of negation scope extraction given the negation cue. Our key observation is that certain useful information such as <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> related to negation cue, long-distance dependencies as well as some latent structural information can be exploited for such a task. We design approaches based on conditional random fields (CRF), semi-Markov CRF, as well as latent-variable CRF models to capture such information. Extensive experiments on several standard datasets demonstrate that our approaches are able to achieve better results than existing approaches reported in the literature.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1143.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1143 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1143 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-1143.Notes.zip data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-1143.Datasets.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1143/>MalwareTextDB : A Database for Annotated Malware Articles<span class=acl-fixed-case>M</span>alware<span class=acl-fixed-case>T</span>ext<span class=acl-fixed-case>DB</span>: A Database for Annotated Malware Articles</a></strong><br><a href=/people/s/swee-kiat-lim/>Swee Kiat Lim</a>
|
<a href=/people/a/aldrian-obaja-muis/>Aldrian Obaja Muis</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/c/chen-hui-ong/>Chen Hui Ong</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1143><div class="card-body p-3 small">Cybersecurity risks and malware threats are becoming increasingly dangerous and common. Despite the severity of the problem, there has been few NLP efforts focused on tackling <a href=https://en.wikipedia.org/wiki/Computer_security>cybersecurity</a>. In this paper, we discuss the construction of a new <a href=https://en.wikipedia.org/wiki/Database>database</a> for annotated malware texts. An annotation framework is introduced based on the MAEC vocabulary for defining malware characteristics, along with a database consisting of 39 annotated APT reports with a total of 6,819 sentences. We also use the <a href=https://en.wikipedia.org/wiki/Database>database</a> to construct <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> that can potentially help <a href=https://en.wikipedia.org/wiki/Computer_security>cybersecurity researchers</a> in their data collection and analytics efforts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1165.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1165 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1165 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P17-1165" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P17-1165/>Topical Coherence in LDA-based Models through Induced Segmentation<span class=acl-fixed-case>LDA</span>-based Models through Induced Segmentation</a></strong><br><a href=/people/h/hesam-amoualian/>Hesam Amoualian</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/e/eric-gaussier/>Eric Gaussier</a>
|
<a href=/people/g/georgios-balikas/>Georgios Balikas</a>
|
<a href=/people/m/massih-r-amini/>Massih R. Amini</a>
|
<a href=/people/m/marianne-clausel/>Marianne Clausel</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1165><div class="card-body p-3 small">This paper presents an LDA-based model that generates topically coherent segments within documents by jointly segmenting documents and assigning topics to their words. The coherence between topics is ensured through a <a href=https://en.wikipedia.org/wiki/Copula_(linguistics)>copula</a>, binding the topics associated to the words of a segment. In addition, this <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> relies on both document and segment specific topic distributions so as to capture fine grained differences in topic assignments. We show that the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> naturally encompasses other state-of-the-art LDA-based models designed for similar tasks. Furthermore, our experiments, conducted on six different publicly available datasets, show the effectiveness of our model in terms of perplexity, Normalized Pointwise Mutual Information, which captures the coherence between the generated topics, and the Micro F1 measure for text classification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1276.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1276 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1276 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D17-1276.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1276/>Labeling Gaps Between Words : Recognizing Overlapping Mentions with Mention Separators</a></strong><br><a href=/people/a/aldrian-obaja-muis/>Aldrian Obaja Muis</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1276><div class="card-body p-3 small">In this paper, we propose a new <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> that is capable of recognizing overlapping mentions. We introduce a novel notion of mention separators that can be effectively used to capture how mentions overlap with one another. On top of a novel multigraph representation that we introduce, we show that efficient and exact <a href=https://en.wikipedia.org/wiki/Inference>inference</a> can still be performed. We present some theoretical analysis on the differences between our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> and a recently proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> for recognizing overlapping mentions, and discuss the possible implications of the differences. Through extensive empirical analysis on standard datasets, we demonstrate the effectiveness of our approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1312.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1312 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1312 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238231213 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1312/>A Simple <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>Regularization-based Algorithm</a> for Learning Cross-Domain Word Embeddings</a></strong><br><a href=/people/w/wei-yang/>Wei Yang</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/v/vincent-zheng/>Vincent Zheng</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1312><div class="card-body p-3 small">Learning word embeddings has received a significant amount of attention recently. Often, <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> are learned in an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised manner</a> from a large collection of text. The genre of the text typically plays an important role in the effectiveness of the resulting <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a>. How to effectively train word embedding models using data from different domains remains a problem that is less explored. In this paper, we present a simple yet effective method for learning <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> based on text from different domains. We demonstrate the effectiveness of our approach through extensive experiments on various down-stream NLP tasks.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Wei+Lu" title="Search for 'Wei Lu' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/z/zhanming-jie/ class=align-middle>Zhanming Jie</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/l/lidong-bing/ class=align-middle>Lidong Bing</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/luo-si/ class=align-middle>Luo Si</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/liying-cheng/ class=align-middle>Liying Cheng</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yan-zhang/ class=align-middle>Yan Zhang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/h/hao-li/ class=align-middle>Hao Li</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/aldrian-obaja-muis/ class=align-middle>Aldrian Obaja Muis</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yanyan-zou/ class=align-middle>Yanyan Zou</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/pengjun-xie/ class=align-middle>Pengjun Xie</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/r/ruixue-ding/ class=align-middle>Ruixue Ding</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/linlin-li/ class=align-middle>Linlin Li</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/dekun-wu/ class=align-middle>Dekun Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lu-xu/ class=align-middle>Lu Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qian-yu/ class=align-middle>Qian Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaobing-sun/ class=align-middle>Xiaobing Sun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/swee-kiat-lim/ class=align-middle>Swee Kiat Lim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chen-hui-ong/ class=align-middle>Chen Hui Ong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hesam-amoualian/ class=align-middle>Hesam Amoualian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eric-gaussier/ class=align-middle>Eric Gaussier</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/georgios-balikas/ class=align-middle>Georgios Balikas</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/massih-r-amini/ class=align-middle>Massih R. Amini</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marianne-clausel/ class=align-middle>Marianne Clausel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bill-yuchen-lin/ class=align-middle>Bill Yuchen Lin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eduardo-blanco/ class=align-middle>Eduardo Blanco</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiale-han/ class=align-middle>Jiale Han</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bo-cheng/ class=align-middle>Bo Cheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yuxiang-zhou/ class=align-middle>Yuxiang Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lejian-liao/ class=align-middle>Lejian Liao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yang-gao/ class=align-middle>Yang Gao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hsiu-wei-yang/ class=align-middle>Hsiu-Wei Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/peng-shi/ class=align-middle>Peng Shi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jimmy-lin/ class=align-middle>Jimmy Lin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xu-sun/ class=align-middle>Xu Sun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhe-zhao/ class=align-middle>Zhe Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hui-chen/ class=align-middle>Hui Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jinbin-zhang/ class=align-middle>Jinbin Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wayne-xin-zhao/ class=align-middle>Wayne Xin Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tao-liu/ class=align-middle>Tao Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xi-chen/ class=align-middle>Xi Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haotang-deng/ class=align-middle>Haotang Deng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qi-ju/ class=align-middle>Qi Ju</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaoyong-du/ class=align-middle>Xiaoyong Du</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wei-yang/ class=align-middle>Wei Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vincent-zheng/ class=align-middle>Vincent Zheng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/peter-phandi/ class=align-middle>Peter Phandi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/amila-silva/ class=align-middle>Amila Silva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhijiang-guo/ class=align-middle>Zhijiang Guo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaoyan-zhang/ class=align-middle>Xiaoyan Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiaqi-pan/ class=align-middle>Jiaqi Pan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rishabh-bhardwaj/ class=align-middle>Rishabh Bhardwaj</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hai-leong-chieu/ class=align-middle>Hai Leong Chieu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xinghao-pan/ class=align-middle>Xinghao Pan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/ni-yi-puay/ class=align-middle>Ni Yi Puay</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">12</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>