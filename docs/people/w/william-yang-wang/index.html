<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>William Yang Wang - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>William Yang</span> <span class=font-weight-bold>Wang</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.339.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--339 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.339 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.339/>Neural Stylistic Response Generation with Disentangled Latent Variables</a></strong><br><a href=/people/q/qingfu-zhu/>Qingfu Zhu</a>
|
<a href=/people/w/weinan-zhang/>Wei-Nan Zhang</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--339><div class="card-body p-3 small">Generating open-domain conversational responses in the desired style usually suffers from the lack of parallel data in the style. Meanwhile, using monolingual stylistic data to increase style intensity often leads to the expense of decreasing content relevance. In this paper, we propose to disentangle the content and style in latent space by diluting sentence-level information in style representations. Combining the desired style representation and a response content representation will then obtain a stylistic response. Our approach achieves a higher BERT-based style intensity score and comparable BLEU scores, compared with baselines. Human evaluation results show that our approach significantly improves style intensity and maintains content relevance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-short.61.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-short--61 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-short.61 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-short.61" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-short.61/>Zero-shot Fact Verification by Claim Generation</a></strong><br><a href=/people/l/liangming-pan/>Liangming Pan</a>
|
<a href=/people/w/wenhu-chen/>Wenhu Chen</a>
|
<a href=/people/w/wenhan-xiong/>Wenhan Xiong</a>
|
<a href=/people/m/min-yen-kan/>Min-Yen Kan</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/2021.acl-short/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-short--61><div class="card-body p-3 small">Neural models for automated fact verification have achieved promising results thanks to the availability of large, human-annotated datasets. However, for each new domain that requires <a href=https://en.wikipedia.org/wiki/Fact-checking>fact verification</a>, creating a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> by manually writing claims and linking them to their supporting evidence is expensive. We develop QACG, a framework for training a robust fact verification model by using automatically generated claims that can be supported, refuted, or unverifiable from evidence from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>. QACG generates question-answer pairs from the evidence and then converts them into different types of claims. Experiments on the FEVER dataset show that our QACG framework significantly reduces the demand for human-annotated training data. In a zero-shot scenario, QACG improves a RoBERTa model&#8217;s F1 from 50 % to 77 %, equivalent in performance to 2K+ manually-curated examples. Our QACG code is publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eacl-main.244.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--eacl-main--244 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.eacl-main.244 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.eacl-main.244" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.eacl-main.244/>Progressively Pretrained Dense Corpus Index for <a href=https://en.wikipedia.org/wiki/Open-domain_question_answering>Open-Domain Question Answering</a></a></strong><br><a href=/people/w/wenhan-xiong/>Wenhan Xiong</a>
|
<a href=/people/h/hong-wang/>Hong Wang</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/2021.eacl-main/ class=text-muted>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--eacl-main--244><div class="card-body p-3 small">Commonly used information retrieval methods such as TF-IDF in open-domain question answering (QA) systems are insufficient to capture deep semantic matching that goes beyond lexical overlaps. Some recent studies consider the retrieval process as maximum inner product search (MIPS) using dense question and paragraph representations, achieving promising results on several information-seeking QA datasets. However, the pretraining of the <a href=https://en.wikipedia.org/wiki/Sparse_matrix>dense vector representations</a> is highly resource-demanding, e.g., requires a very large <a href=https://en.wikipedia.org/wiki/Batch_processing>batch size</a> and lots of <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training steps</a>. In this work, we propose a <a href=https://en.wikipedia.org/wiki/Sampling_(statistics)>sample-efficient method</a> to pretrain the paragraph encoder. First, instead of using heuristically created pseudo question-paragraph pairs for pretraining, we use an existing pretrained sequence-to-sequence model to build a strong question generator that creates high-quality pretraining data. Second, we propose a simple progressive pretraining algorithm to ensure the existence of effective negative samples in each batch. Across three open-domain QA datasets, our method consistently outperforms a strong dense retrieval baseline that uses 6 times more computation for training. On two of the <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> achieves more than 4-point absolute improvement in terms of answer exact match.<i>e.g.</i>, requires a very large batch size and lots of training steps. In this work, we propose a sample-efficient method to pretrain the paragraph encoder. First, instead of using heuristically created pseudo question-paragraph pairs for pretraining, we use an existing pretrained sequence-to-sequence model to build a strong question generator that creates high-quality pretraining data. Second, we propose a simple progressive pretraining algorithm to ensure the existence of effective negative samples in each batch. Across three open-domain QA datasets, our method consistently outperforms a strong dense retrieval baseline that uses 6 times more computation for training. On two of the datasets, our method achieves more than 4-point absolute improvement in terms of answer exact match.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.153.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--153 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.153 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.153" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.153/>Modeling Disclosive Transparency in NLP Application Descriptions<span class=acl-fixed-case>NLP</span> Application Descriptions</a></strong><br><a href=/people/m/michael-saxon/>Michael Saxon</a>
|
<a href=/people/s/sharon-levy/>Sharon Levy</a>
|
<a href=/people/x/xinyi-wang/>Xinyi Wang</a>
|
<a href=/people/a/alon-albalak/>Alon Albalak</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--153><div class="card-body p-3 small">Broader disclosive transparencytruth and clarity in communication regarding the function of AI systemsis widely considered desirable. Unfortunately, it is a nebulous concept, difficult to both define and quantify. This is problematic, as previous work has demonstrated possible trade-offs and negative consequences to disclosive transparency, such as a confusion effect, where too much information clouds a reader&#8217;s understanding of what a system description means. Disclosive transparency&#8217;s subjective nature has rendered deep study into these problems and their remedies difficult. To improve this state of affairs, We introduce neural language model-based probabilistic metrics to directly model disclosive transparency, and demonstrate that they correlate with user and expert opinions of system transparency, making them a valid objective proxy. Finally, we demonstrate the use of these metrics in a pilot study quantifying the relationships between <a href=https://en.wikipedia.org/wiki/Transparency_(behavior)>transparency</a>, <a href=https://en.wikipedia.org/wiki/Confusion>confusion</a>, and user perceptions in a corpus of real NLP system descriptions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.300.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--300 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.300 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.300" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.300/>FinQA : A Dataset of <a href=https://en.wikipedia.org/wiki/Numerical_analysis>Numerical Reasoning</a> over Financial Data<span class=acl-fixed-case>F</span>in<span class=acl-fixed-case>QA</span>: A Dataset of Numerical Reasoning over Financial Data</a></strong><br><a href=/people/z/zhiyu-chen/>Zhiyu Chen</a>
|
<a href=/people/w/wenhu-chen/>Wenhu Chen</a>
|
<a href=/people/c/charese-smiley/>Charese Smiley</a>
|
<a href=/people/s/sameena-shah/>Sameena Shah</a>
|
<a href=/people/i/iana-borova/>Iana Borova</a>
|
<a href=/people/d/dylan-langdon/>Dylan Langdon</a>
|
<a href=/people/r/reema-moussa/>Reema Moussa</a>
|
<a href=/people/m/matt-beane/>Matt Beane</a>
|
<a href=/people/t/ting-hao-huang/>Ting-Hao Huang</a>
|
<a href=/people/b/bryan-r-routledge/>Bryan Routledge</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--300><div class="card-body p-3 small">The sheer volume of <a href=https://en.wikipedia.org/wiki/Financial_statement>financial statements</a> makes it difficult for humans to access and analyze a business&#8217;s financials. Robust <a href=https://en.wikipedia.org/wiki/Numerical_analysis>numerical reasoning</a> likewise faces unique challenges in this <a href=https://en.wikipedia.org/wiki/Domain_of_a_function>domain</a>. In this work, we focus on answering deep questions over financial data, aiming to automate the analysis of a large corpus of financial documents. In contrast to existing tasks on general domain, the <a href=https://en.wikipedia.org/wiki/Mathematical_finance>finance domain</a> includes complex numerical reasoning and understanding of heterogeneous representations. To facilitate analytical progress, we propose a new large-scale dataset, FinQA, with Question-Answering pairs over Financial reports, written by financial experts. We also annotate the gold reasoning programs to ensure full explainability. We further introduce <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> and conduct comprehensive experiments in our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. The results demonstrate that popular, large, pre-trained models fall far short of expert humans in acquiring finance knowledge and in complex multi-step numerical reasoning on that knowledge. Our dataset the first of its kind should therefore enable significant, new community research into complex application domains. The dataset and code are publicly available at https://github.com/czyssrs/FinQA.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.469.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--469 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.469 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.469" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.469/>Unsupervised Multi-hop Question Answering by Question Generation</a></strong><br><a href=/people/l/liangming-pan/>Liangming Pan</a>
|
<a href=/people/w/wenhu-chen/>Wenhu Chen</a>
|
<a href=/people/w/wenhan-xiong/>Wenhan Xiong</a>
|
<a href=/people/m/min-yen-kan/>Min-Yen Kan</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--469><div class="card-body p-3 small">Obtaining training data for multi-hop question answering (QA) is time-consuming and resource-intensive. We explore the possibility to train a well-performed multi-hop QA model without referencing any human-labeled multi-hop question-answer pairs, i.e., unsupervised multi-hop QA. We propose MQA-QG, an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised framework</a> that can generate human-like multi-hop training data from both homogeneous and heterogeneous data sources. MQA-QG generates questions by first selecting / generating relevant information from each data source and then integrating the multiple information to form a multi-hop question. Using only generated training data, we can train a competent multi-hop QA which achieves 61 % and 83 % of the <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised learning</a> performance for the HybridQA and the HotpotQA dataset, respectively. We also show that pretraining the QA system with the generated data would greatly reduce the demand for human-annotated training data. Our codes are publicly available at https://github.com/teacherpeterpan/Unsupervised-Multi-hop-QA.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.697.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--697 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.697 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938913 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.697" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.697/>KGPT : Knowledge-Grounded Pre-Training for Data-to-Text Generation<span class=acl-fixed-case>KGPT</span>: Knowledge-Grounded Pre-Training for Data-to-Text Generation</a></strong><br><a href=/people/w/wenhu-chen/>Wenhu Chen</a>
|
<a href=/people/y/yu-su/>Yu Su</a>
|
<a href=/people/x/xifeng-yan/>Xifeng Yan</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--697><div class="card-body p-3 small">Data-to-text generation has recently attracted substantial interests due to its wide applications. Existing methods have shown impressive performance on an array of <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a>. However, they rely on a significant amount of labeled data for each <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>, which is costly to acquire and thus limits their application to new <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a> and domains. In this paper, we propose to leverage pre-training and transfer learning to address this issue. We propose a knowledge-grounded pre-training (KGPT), which consists of two parts, 1) a general knowledge-grounded generation model to generate knowledge-enriched text. 2) a pre-training paradigm on a massive knowledge-grounded text corpus crawled from the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>web</a>. The pre-trained model can be fine-tuned on various data-to-text generation tasks to generate task-specific text. We adopt three settings, namely fully-supervised, zero-shot, few-shot to evaluate its effectiveness. Under the fully-supervised setting, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can achieve remarkable gains over the known baselines. Under zero-shot setting, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> without seeing any examples achieves over 30 ROUGE-L on WebNLG while all other baselines fail. Under the few-shot setting, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> only needs about one-fifteenth as many labeled examples to achieve the same level of performance as baseline models. These experiments consistently prove the strong generalization ability of our proposed <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.708.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--708 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.708 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939350 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.708/>Towards Understanding Sample Variance in Visually Grounded Language Generation : Evaluations and Observations</a></strong><br><a href=/people/w/wanrong-zhu/>Wanrong Zhu</a>
|
<a href=/people/x/xin-wang/>Xin Wang</a>
|
<a href=/people/p/pradyumna-narayana/>Pradyumna Narayana</a>
|
<a href=/people/k/kazoo-sone/>Kazoo Sone</a>
|
<a href=/people/s/sugato-basu/>Sugato Basu</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--708><div class="card-body p-3 small">A major challenge in visually grounded language generation is to build robust benchmark datasets and <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that can generalize well in real-world settings. To do this, it is critical to ensure that our evaluation protocols are correct, and <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a> are reliable. In this work, we set forth to design a set of experiments to understand an important but often ignored problem in visually grounded language generation : given that humans have different utilities and <a href=https://en.wikipedia.org/wiki/Attention>visual attention</a>, how will the <a href=https://en.wikipedia.org/wiki/Variance>sample variance</a> in multi-reference datasets affect the models&#8217; performance? Empirically, we study several multi-reference datasets and corresponding vision-and-language tasks. We show that it is of paramount importance to report variance in experiments ; that human-generated references could vary drastically in different datasets / tasks, revealing the nature of each task ; that metric-wise, CIDEr has shown systematically larger variances than others. Our evaluations on reference-per-instance shed light on the design of reliable datasets in the future.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.265.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--265 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.265 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.265.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929244 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.265/>Towards Understanding Gender Bias in Relation Extraction</a></strong><br><a href=/people/a/andrew-gaut/>Andrew Gaut</a>
|
<a href=/people/t/tony-sun/>Tony Sun</a>
|
<a href=/people/s/shirlyn-tang/>Shirlyn Tang</a>
|
<a href=/people/y/yuxin-huang/>Yuxin Huang</a>
|
<a href=/people/j/jing-qian/>Jing Qian</a>
|
<a href=/people/m/mai-elsherief/>Mai ElSherief</a>
|
<a href=/people/j/jieyu-zhao/>Jieyu Zhao</a>
|
<a href=/people/d/diba-mirza/>Diba Mirza</a>
|
<a href=/people/e/elizabeth-belding/>Elizabeth Belding</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--265><div class="card-body p-3 small">Recent developments in Neural Relation Extraction (NRE) have made significant strides towards Automated Knowledge Base Construction. While much attention has been dedicated towards improvements in <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, there have been no attempts in the literature to evaluate <a href=https://en.wikipedia.org/wiki/Bias>social biases</a> exhibited in NRE systems. In this paper, we create WikiGenderBias, a distantly supervised dataset composed of over 45,000 sentences including a 10 % human annotated test set for the purpose of analyzing gender bias in relation extraction systems. We find that when extracting spouse-of and hypernym (i.e., occupation) relations, an NRE system performs differently when the gender of the target entity is different. However, such disparity does not appear when extracting relations such as <a href=https://en.wikipedia.org/wiki/Birth_date>birthDate</a> or <a href=https://en.wikipedia.org/wiki/Place_of_birth>birthPlace</a>. We also analyze how existing bias mitigation techniques, such as name anonymization, word embedding debiasing, and <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> affect the NRE system in terms of maintaining the test performance and reducing biases. Unfortunately, due to NRE models rely heavily on surface level cues, we find that existing bias mitigation approaches have a negative effect on NRE. Our analysis lays groundwork for future quantifying and mitigating bias in NRE.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.316.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--316 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.316 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928764 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.316" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.316/>On the Encoder-Decoder Incompatibility in Variational Text Modeling and Beyond</a></strong><br><a href=/people/c/chen-wu/>Chen Wu</a>
|
<a href=/people/p/prince-zizhuang-wang/>Prince Zizhuang Wang</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--316><div class="card-body p-3 small">Variational autoencoders (VAEs) combine <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a> with <a href=https://en.wikipedia.org/wiki/Amortized_analysis>amortized variational inference</a>, whose optimization usually converges into a trivial local optimum termed posterior collapse, especially in text modeling. By tracking the optimization dynamics, we observe the encoder-decoder incompatibility that leads to poor parameterizations of the <a href=https://en.wikipedia.org/wiki/Manifold>data manifold</a>. We argue that the trivial local optimum may be avoided by improving the encoder and decoder parameterizations since the posterior network is part of a transition map between them. To this end, we propose Coupled-VAE, which couples a VAE model with a deterministic autoencoder with the same structure and improves the encoder and decoder parameterizations via encoder weight sharing and decoder signal matching. We apply the proposed Coupled-VAE approach to various VAE models with different <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization</a>, <a href=https://en.wikipedia.org/wiki/Posterior_probability>posterior family</a>, decoder structure, and <a href=https://en.wikipedia.org/wiki/Mathematical_optimization>optimization strategy</a>. Experiments on <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmark datasets</a> (i.e., PTB, <a href=https://en.wikipedia.org/wiki/Yelp>Yelp</a>, and Yahoo) show consistently improved results in terms of <a href=https://en.wikipedia.org/wiki/Probability_estimation>probability estimation</a> and richness of the latent space. We also generalize our method to conditional language modeling and propose Coupled-CVAE, which largely improves the diversity of dialogue generation on the Switchboard dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.alvr-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.alvr-1.0/>Proceedings of the First Workshop on Advances in Language and Vision Research</a></strong><br><a href=/people/x/xin-wang/>Xin Wang</a>
|
<a href=/people/j/jesse-thomason/>Jesse Thomason</a>
|
<a href=/people/r/ronghang-hu/>Ronghang Hu</a>
|
<a href=/people/x/xinlei-chen/>Xinlei Chen</a>
|
<a href=/people/p/peter-anderson/>Peter Anderson</a>
|
<a href=/people/q/qi-wu/>Qi Wu</a>
|
<a href=/people/a/asli-celikyilmaz/>Asli Celikyilmaz</a>
|
<a href=/people/j/jason-baldridge/>Jason Baldridge</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/2020.alvr-1/ class=text-muted>Proceedings of the First Workshop on Advances in Language and Vision Research</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.747.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--747 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.747 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.747/>A Survey on <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a> for Fake News Detection</a></strong><br><a href=/people/r/ray-oshikawa/>Ray Oshikawa</a>
|
<a href=/people/j/jing-qian/>Jing Qian</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--747><div class="card-body p-3 small">Fake news detection is a critical yet challenging problem in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing (NLP)</a>. The rapid rise of <a href=https://en.wikipedia.org/wiki/Social_networking_service>social networking platforms</a> has not only yielded a vast increase in <a href=https://en.wikipedia.org/wiki/Accessibility>information accessibility</a> but has also accelerated the spread of <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a>. Thus, the effect of <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a> has been growing, sometimes extending to the offline world and threatening public safety. Given the massive amount of <a href=https://en.wikipedia.org/wiki/Web_content>Web content</a>, automatic fake news detection is a practical NLP problem useful to all online content providers, in order to reduce the human time and effort to detect and prevent the spread of <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a>. In this paper, we describe the challenges involved in <a href=https://en.wikipedia.org/wiki/Fake_news>fake news detection</a> and also describe related <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. We systematically review and compare the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task formulations</a>, <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> and NLP solutions that have been developed for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, and also discuss the potentials and limitations of them. Based on our insights, we outline promising research directions, including more fine-grained, detailed, fair, and practical detection models. We also highlight the difference between <a href=https://en.wikipedia.org/wiki/Fake_news>fake news detection</a> and other related tasks, and the importance of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP solutions</a> for <a href=https://en.wikipedia.org/wiki/Fake_news>fake news detection</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.755.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--755 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.755 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.755/>Fakeddit : A New Multimodal Benchmark Dataset for Fine-grained Fake News Detection<span class=acl-fixed-case>F</span>akeddit: A New Multimodal Benchmark Dataset for Fine-grained Fake News Detection</a></strong><br><a href=/people/k/kai-nakamura/>Kai Nakamura</a>
|
<a href=/people/s/sharon-levy/>Sharon Levy</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--755><div class="card-body p-3 small">Fake news has altered society in negative ways in politics and culture. It has adversely affected both online social network systems as well as offline communities and conversations. Using automatic machine learning classification models is an efficient way to combat the widespread dissemination of fake news. However, a lack of effective, comprehensive datasets has been a problem for <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a> research and detection model development. Prior fake news datasets do not provide multimodal text and image data, <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a>, comment data, and fine-grained fake news categorization at the scale and breadth of our dataset. We present Fakeddit, a novel multimodal dataset consisting of over 1 million samples from multiple categories of <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a>. After being processed through several stages of review, the samples are labeled according to 2-way, 3-way, and 6-way classification categories through distant supervision. We construct hybrid text+image models and perform extensive experiments for multiple variations of classification, demonstrating the importance of the novel aspect of <a href=https://en.wikipedia.org/wiki/Multimodality>multimodality</a> and fine-grained classification unique to Fakeddit.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpcovid19-acl.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlpcovid19-acl--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlpcovid19-acl.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nlpcovid19-acl.15/>Cross-lingual Transfer Learning for COVID-19 Outbreak Alignment<span class=acl-fixed-case>COVID-19</span> Outbreak Alignment</a></strong><br><a href=/people/s/sharon-levy/>Sharon Levy</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/2020.nlpcovid19-acl/ class=text-muted>Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlpcovid19-acl--15><div class="card-body p-3 small">The spread of COVID-19 has become a significant and troubling aspect of society in 2020. With millions of cases reported across countries, new outbreaks have occurred and followed patterns of previously affected areas. Many disease detection models do not incorporate the wealth of social media data that can be utilized for modeling and predicting its spread. It is useful to ask, can we utilize this knowledge in one country to model the outbreak in another? To answer this, we propose the task of cross-lingual transfer learning for epidemiological alignment. Utilizing both macro and micro text features, we train on Italy&#8217;s early COVID-19 outbreak through <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> and transfer to several other countries. Our experiments show strong results with up to 0.85 <a href=https://en.wikipedia.org/wiki/Spearman_correlation>Spearman correlation</a> in cross-country predictions.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1444.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1444 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1444 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1444/>Learning to Learn and Predict : A Meta-Learning Approach for Multi-Label Classification</a></strong><br><a href=/people/j/jiawei-wu/>Jiawei Wu</a>
|
<a href=/people/w/wenhan-xiong/>Wenhan Xiong</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1444><div class="card-body p-3 small">Many tasks in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> can be viewed as multi-label classification problems. However, most of the existing <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> are trained with the standard cross-entropy loss function and use a <a href=https://en.wikipedia.org/wiki/Linear_prediction>fixed prediction policy</a> (e.g., a threshold of 0.5) for all the labels, which completely ignores the <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>complexity</a> and dependencies among different labels. In this paper, we propose a meta-learning method to capture these complex label dependencies. More specifically, our method utilizes a meta-learner to jointly learn the <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training policies</a> and <a href=https://en.wikipedia.org/wiki/Prediction>prediction policies</a> for different labels. The training policies are then used to train the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> with the cross-entropy loss function, and the <a href=https://en.wikipedia.org/wiki/Prediction>prediction policies</a> are further implemented for <a href=https://en.wikipedia.org/wiki/Prediction>prediction</a>. Experimental results on fine-grained entity typing and text classification demonstrate that our proposed method can obtain more accurate multi-label classification results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1482.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1482 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1482 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1482" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1482/>A Benchmark Dataset for Learning to Intervene in Online Hate Speech</a></strong><br><a href=/people/j/jing-qian/>Jing Qian</a>
|
<a href=/people/a/anna-bethke/>Anna Bethke</a>
|
<a href=/people/y/yinyin-liu/>Yinyin Liu</a>
|
<a href=/people/e/elizabeth-belding/>Elizabeth Belding</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1482><div class="card-body p-3 small">Countering <a href=https://en.wikipedia.org/wiki/Online_hate_speech>online hate speech</a> is a critical yet challenging task, but one which can be aided by the use of Natural Language Processing (NLP) techniques. Previous research has primarily focused on the development of NLP methods to automatically and effectively detect online hate speech while disregarding further action needed to calm and discourage individuals from using <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a> in the future. In addition, most existing hate speech datasets treat each post as an isolated instance, ignoring the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>conversational context</a>. In this paper, we propose a novel task of generative hate speech intervention, where the goal is to automatically generate responses to intervene during online conversations that contain <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a>. As a part of this work, we introduce two fully-labeled large-scale hate speech intervention datasets collected from Gab and <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a>. These datasets provide conversation segments, hate speech labels, as well as intervention responses written by Mechanical Turk Workers. In this paper, we also analyze the <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> to understand the common intervention strategies and explore the performance of common automatic response generation methods on these new <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> to provide a benchmark for future research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1623.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1623 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1623 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1623/>Deep Reinforcement Learning with Distributional Semantic Rewards for Abstractive Summarization</a></strong><br><a href=/people/s/siyao-li/>Siyao Li</a>
|
<a href=/people/d/deren-lei/>Deren Lei</a>
|
<a href=/people/p/pengda-qin/>Pengda Qin</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1623><div class="card-body p-3 small">Deep reinforcement learning (RL) has been a commonly-used strategy for the abstractive summarization task to address both the exposure bias and non-differentiable task issues. However, the conventional reward Rouge-L simply looks for exact n-grams matches between candidates and annotated references, which inevitably makes the generated sentences repetitive and incoherent. In this paper, instead of Rouge-L, we explore the practicability of utilizing the <a href=https://en.wikipedia.org/wiki/Distributional_semantics>distributional semantics</a> to measure the matching degrees. With <a href=https://en.wikipedia.org/wiki/Distributional_semantics>distributional semantics</a>, sentence-level evaluation can be obtained, and semantically-correct phrases can also be generated without being limited to the surface form of the reference sentences. Human judgments on Gigaword and CNN / Daily Mail datasets show that our proposed distributional semantics reward (DSR) has distinct superiority in capturing the lexical and compositional diversity of natural language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1025.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1025 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1025 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N19-1025.Software.tar data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N19-1025.Presentation.pptx data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1025" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N19-1025/>Riemannian Normalizing Flow on Variational Wasserstein Autoencoder for Text Modeling<span class=acl-fixed-case>R</span>iemannian Normalizing Flow on Variational <span class=acl-fixed-case>W</span>asserstein Autoencoder for Text Modeling</a></strong><br><a href=/people/p/prince-zizhuang-wang/>Prince Zizhuang Wang</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1025><div class="card-body p-3 small">Recurrent Variational Autoencoder has been widely used for language modeling and text generation tasks. These models often face a difficult optimization problem, also known as KL vanishing, where the <a href=https://en.wikipedia.org/wiki/Posterior_probability>posterior</a> easily collapses to the <a href=https://en.wikipedia.org/wiki/Prior_probability>prior</a> and model will ignore latent codes in generative tasks. To address this problem, we introduce an improved Variational Wasserstein Autoencoder (WAE) with Riemannian Normalizing Flow (RNF) for text modeling. The RNF transforms a <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variable</a> into a space that respects the geometric characteristics of input space, which makes posterior impossible to collapse to the <a href=https://en.wikipedia.org/wiki/Non-informative_prior>non-informative prior</a>. The Wasserstein objective minimizes the distance between <a href=https://en.wikipedia.org/wiki/Marginal_distribution>marginal distribution</a> and the <a href=https://en.wikipedia.org/wiki/Prior_probability>prior</a> directly and therefore does not force the posterior to match the <a href=https://en.wikipedia.org/wiki/Prior_probability>prior</a>. Empirical experiments show that our model avoids KL vanishing over a range of datasets and has better performance in tasks such as <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>, <a href=https://en.wikipedia.org/wiki/Likelihood_function>likelihood approximation</a>, and text generation. Through a series of experiments and analysis over latent space, we show that our model learns latent distributions that respect latent space geometry and is able to generate sentences that are more diverse.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-5001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-5001 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-5001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N19-5001.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/359555654 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-5001/>Deep Adversarial Learning for <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP</a><span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/w/william-yang-wang/>William Yang Wang</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a>
|
<a href=/people/j/jiwei-li/>Jiwei Li</a><br><a href=/volumes/N19-5/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-5001><div class="card-body p-3 small">Adversarial learning is a game-theoretic learning paradigm, which has achieved huge successes in the field of <a href=https://en.wikipedia.org/wiki/Computer_vision>Computer Vision</a> recently. Adversarial learning is also a general framework that enables a variety of learning models, including the popular Generative Adversarial Networks (GANs). Due to the discrete nature of language, designing adversarial learning models is still challenging for NLP problems. In this tutorial, we provide a gentle introduction to the foundation of deep adversarial learning, as well as some practical problem formulations and solutions in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. We describe recent advances in deep adversarial learning for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, with a special focus on generation, adversarial examples & rules, and <a href=https://en.wikipedia.org/wiki/Dialogue>dialogue</a>. We provide an overview of the research area, categorize different types of <a href=https://en.wikipedia.org/wiki/Adversarial_learning>adversarial learning models</a>, and discuss pros and cons, aiming at providing some practical perspectives on the future of <a href=https://en.wikipedia.org/wiki/Adversarial_learning>adversarial learning</a> for solving real-world NLP problems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1214.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1214 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1214 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1214" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1214/>Self-Supervised Learning for Contextualized Extractive Summarization</a></strong><br><a href=/people/h/hong-wang/>Hong Wang</a>
|
<a href=/people/x/xin-wang/>Xin Wang</a>
|
<a href=/people/w/wenhan-xiong/>Wenhan Xiong</a>
|
<a href=/people/m/mo-yu/>Mo Yu</a>
|
<a href=/people/x/xiaoxiao-guo/>Xiaoxiao Guo</a>
|
<a href=/people/s/shiyu-chang/>Shiyu Chang</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1214><div class="card-body p-3 small">Existing models for extractive summarization are usually trained from scratch with a cross-entropy loss, which does not explicitly capture the global context at the document level. In this paper, we aim to improve this task by introducing three auxiliary pre-training tasks that learn to capture the document-level context in a self-supervised fashion. Experiments on the widely-used CNN / DM dataset validate the effectiveness of the proposed auxiliary tasks. Furthermore, we show that after pre-training, a clean model with simple building blocks is able to outperform previous <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> that are carefully designed.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1360.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1360 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1360 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1360" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1360/>Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention</a></strong><br><a href=/people/w/wenhu-chen/>Wenhu Chen</a>
|
<a href=/people/j/jianshu-chen/>Jianshu Chen</a>
|
<a href=/people/p/pengda-qin/>Pengda Qin</a>
|
<a href=/people/x/xifeng-yan/>Xifeng Yan</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1360><div class="card-body p-3 small">Semantically controlled neural response generation on <a href=https://en.wikipedia.org/wiki/Domain-specific_language>limited-domain</a> has achieved great performance. However, moving towards multi-domain large-scale scenarios are shown to be difficult because the possible combinations of semantic inputs grow exponentially with the number of domains. To alleviate such scalability issue, we exploit the structure of dialog acts to build a multi-layer hierarchical graph, where each act is represented as a root-to-leaf route on the <a href=https://en.wikipedia.org/wiki/Graph_(abstract_data_type)>graph</a>. Then, we incorporate such graph structure prior as an inductive bias to build a hierarchical disentangled self-attention network, where we disentangle attention heads to model designated nodes on the dialog act graph. By activating different (disentangled) heads at each layer, combinatorially many dialog act semantics can be modeled to control the neural response generation. On the large-scale Multi-Domain-WOZ dataset, our model can yield a significant improvement over the baselines on various automatic and human evaluation metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1375.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1375 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1375 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1375/>Self-Supervised Dialogue Learning</a></strong><br><a href=/people/j/jiawei-wu/>Jiawei Wu</a>
|
<a href=/people/x/xin-wang/>Xin Wang</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1375><div class="card-body p-3 small">The sequential order of utterances is often meaningful in coherent dialogues, and the order changes of utterances could lead to low-quality and incoherent conversations. We consider the order information as a crucial supervised signal for dialogue learning, which, however, has been neglected by many previous <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a>. Therefore, in this paper, we introduce a self-supervised learning task, inconsistent order detection, to explicitly capture the flow of conversation in dialogues. Given a sampled utterance pair triple, the task is to predict whether it is ordered or misordered. Then we propose a sampling-based self-supervised network SSN to perform the prediction with sampled triple references from previous dialogue history. Furthermore, we design a joint learning framework where <a href=https://en.wikipedia.org/wiki/Social_security_number>SSN</a> can guide the <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a> towards more coherent and relevant dialogue learning through adversarial training. We demonstrate that the proposed methods can be applied to both open-domain and task-oriented dialogue scenarios, and achieve the new state-of-the-art performance on the OpenSubtitiles and Movie-Ticket Booking datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1417.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1417 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1417 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385198664 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1417" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1417/>Improving <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a> over Incomplete KBs with Knowledge-Aware Reader<span class=acl-fixed-case>KB</span>s with Knowledge-Aware Reader</a></strong><br><a href=/people/w/wenhan-xiong/>Wenhan Xiong</a>
|
<a href=/people/m/mo-yu/>Mo Yu</a>
|
<a href=/people/s/shiyu-chang/>Shiyu Chang</a>
|
<a href=/people/x/xiaoxiao-guo/>Xiaoxiao Guo</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1417><div class="card-body p-3 small">We propose a new end-to-end question answering model, which learns to aggregate answer evidence from an incomplete knowledge base (KB) and a set of retrieved text snippets. Under the assumptions that structured data is easier to query and the acquired knowledge can help the understanding of unstructured text, our model first accumulates knowledge ofKB entities from a question-related KB sub-graph ; then reformulates the question in the latent space and reads the text with the accumulated entity knowledge at hand. The evidence from KB and <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text</a> are finally aggregated to predict answers. On the widely-used KBQA benchmark WebQSP, our model achieves consistent improvements across settings with different extents of KB incompleteness.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1496.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1496 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1496 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385272712 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1496/>TWEETQA : A Social Media Focused Question Answering Dataset<span class=acl-fixed-case>TWEETQA</span>: A Social Media Focused Question Answering Dataset</a></strong><br><a href=/people/w/wenhan-xiong/>Wenhan Xiong</a>
|
<a href=/people/j/jiawei-wu/>Jiawei Wu</a>
|
<a href=/people/h/hong-wang/>Hong Wang</a>
|
<a href=/people/v/vivek-kulkarni/>Vivek Kulkarni</a>
|
<a href=/people/m/mo-yu/>Mo Yu</a>
|
<a href=/people/s/shiyu-chang/>Shiyu Chang</a>
|
<a href=/people/x/xiaoxiao-guo/>Xiaoxiao Guo</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1496><div class="card-body p-3 small">With <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> becoming increasingly popular on which lots of news and real-time events are reported, developing automated question answering systems is critical to the effective-ness of many applications that rely on real-time knowledge. While previous datasets have concentrated on <a href=https://en.wikipedia.org/wiki/Question_answering>question answering (QA)</a> for formal text like <a href=https://en.wikipedia.org/wiki/News>news</a> and <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, we present the first large-scale dataset for QA over <a href=https://en.wikipedia.org/wiki/Social_media>social media data</a>. To ensure that the tweets we collected are useful, we only gather tweets used by journalists to write <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>. We then ask human annotators to write questions and answers upon these tweets. Unlike otherQA datasets like SQuAD in which the answers are extractive, we allow the answers to be abstractive. We show that two recently proposed neural models that perform well on <a href=https://en.wikipedia.org/wiki/Formal_language>formal texts</a> are limited in their performance when applied to our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. In addition, even the fine-tuned BERT model is still lagging behind human performance with a large margin. Our results thus point to the need of improved <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA systems</a> targeting <a href=https://en.wikipedia.org/wiki/Social_media>social media text</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1560.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1560 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1560 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1560/>Towards Explainable NLP : A Generative Explanation Framework for Text Classification<span class=acl-fixed-case>NLP</span>: A Generative Explanation Framework for Text Classification</a></strong><br><a href=/people/h/hui-liu/>Hui Liu</a>
|
<a href=/people/q/qingyu-yin/>Qingyu Yin</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1560><div class="card-body p-3 small">Building explainable systems is a critical problem in the field of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing (NLP)</a>, since most <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning models</a> provide no explanations for the predictions. Existing approaches for explainable machine learning systems tend to focus on interpreting the outputs or the connections between inputs and outputs. However, the fine-grained information (e.g. textual explanations for the labels) is often ignored, and the systems do not explicitly generate the human-readable explanations. To solve this problem, we propose a novel generative explanation framework that learns to make classification decisions and generate fine-grained explanations at the same time. More specifically, we introduce the explainable factor and the minimum risk training approach that learn to generate more reasonable explanations. We construct two new <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> that contain summaries, rating scores, and fine-grained reasons. We conduct experiments on both <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, comparing with several strong neural network baseline systems. Experimental results show that our method surpasses all baselines on both <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, and is able to generate concise explanations at the same time.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1002 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=C18-1002" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/C18-1002/>Zero Pronoun Resolution with Attention-based Neural Network</a></strong><br><a href=/people/q/qingyu-yin/>Qingyu Yin</a>
|
<a href=/people/y/yu-zhang/>Yu Zhang</a>
|
<a href=/people/w/weinan-zhang/>Weinan Zhang</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1002><div class="card-body p-3 small">Recent neural network methods for zero pronoun resolution explore multiple models for generating <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representation vectors</a> for zero pronouns and their candidate antecedents. Typically, <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual information</a> is utilized to encode the zero pronouns since they are simply gaps that contain no actual content. To better utilize contexts of the zero pronouns, we here introduce the self-attention mechanism for encoding zero pronouns. With the help of the multiple hops of attention, our model is able to focus on some informative parts of the associated texts and therefore produces an efficient way of encoding the zero pronouns. In addition, an attention-based recurrent neural network is proposed for encoding candidate antecedents by their contents. Experiment results are encouraging : our proposed attention-based model gains the best performance on the Chinese portion of the OntoNotes corpus, substantially surpasses existing Chinese zero pronoun resolution baseline systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1038.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1038 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1038 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D18-1038.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1038" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D18-1038/>XL-NBT : A Cross-lingual Neural Belief Tracking Framework<span class=acl-fixed-case>XL</span>-<span class=acl-fixed-case>NBT</span>: A Cross-lingual Neural Belief Tracking Framework</a></strong><br><a href=/people/w/wenhu-chen/>Wenhu Chen</a>
|
<a href=/people/j/jianshu-chen/>Jianshu Chen</a>
|
<a href=/people/y/yu-su/>Yu Su</a>
|
<a href=/people/x/xin-wang/>Xin Wang</a>
|
<a href=/people/d/dong-yu/>Dong Yu</a>
|
<a href=/people/x/xifeng-yan/>Xifeng Yan</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1038><div class="card-body p-3 small">Task-oriented dialog systems are becoming pervasive, and many companies heavily rely on them to complement <a href=https://en.wikipedia.org/wiki/Intelligent_agent>human agents</a> for customer service in call centers. With globalization, the need for providing cross-lingual customer support becomes more urgent than ever. However, cross-lingual support poses great challengesit requires a large amount of additional annotated data from <a href=https://en.wikipedia.org/wiki/First_language>native speakers</a>. In order to bypass the expensive human annotation and achieve the first step towards the ultimate goal of building a universal dialog system, we set out to build a cross-lingual state tracking framework. Specifically, we assume that there exists a source language with dialog belief tracking annotations while the target languages have no annotated dialog data of any form. Then, we pre-train a state tracker for the source language as a teacher, which is able to exploit easy-to-access parallel data. We then distill and transfer its own knowledge to the student state tracker in target languages. We specifically discuss two types of common parallel resources : <a href=https://en.wikipedia.org/wiki/Bilingual_corpus>bilingual corpus</a> and <a href=https://en.wikipedia.org/wiki/Bilingual_dictionary>bilingual dictionary</a>, and design different transfer learning strategies accordingly. Experimentally, we successfully use English state tracker as the teacher to transfer its knowledge to both Italian and German trackers and achieve promising results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1223.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1223 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1223 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D18-1223.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1223" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D18-1223/>One-Shot Relational Learning for Knowledge Graphs</a></strong><br><a href=/people/w/wenhan-xiong/>Wenhan Xiong</a>
|
<a href=/people/m/mo-yu/>Mo Yu</a>
|
<a href=/people/s/shiyu-chang/>Shiyu Chang</a>
|
<a href=/people/x/xiaoxiao-guo/>Xiaoxiao Guo</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1223><div class="card-body p-3 small">Knowledge graphs (KG) are the key components of various <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing applications</a>. To further expand KGs&#8217; coverage, previous studies on knowledge graph completion usually require a large number of positive examples for each relation. However, we observe long-tail relations are actually more common in KGs and those newly added relations often do not have many known triples for training. In this work, we aim at predicting new facts under a challenging setting where only one training instance is available. We propose a one-shot relational learning framework, which utilizes the knowledge distilled by embedding models and learns a matching metric by considering both the learned embeddings and one-hop graph structures. Empirically, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> yields considerable performance improvements over existing <a href=https://en.wikipedia.org/wiki/Embedding>embedding models</a>, and also eliminates the need of re-training the <a href=https://en.wikipedia.org/wiki/Embedding>embedding models</a> when dealing with newly added relations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1388.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1388 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1388 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1388/>Multi-view Models for Political Ideology Detection of News Articles</a></strong><br><a href=/people/v/vivek-kulkarni/>Vivek Kulkarni</a>
|
<a href=/people/j/junting-ye/>Junting Ye</a>
|
<a href=/people/s/steven-skiena/>Steve Skiena</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1388><div class="card-body p-3 small">A news article&#8217;s title, content and link structure often reveal its <a href=https://en.wikipedia.org/wiki/Ideology>political ideology</a>. However, most existing works on automatic political ideology detection only leverage textual cues. Drawing inspiration from recent advances in neural inference, we propose a novel attention based multi-view model to leverage cues from all of the above views to identify the <a href=https://en.wikipedia.org/wiki/Ideology>ideology</a> evinced by a <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news article</a>. Our model draws on advances in representation learning in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> and <a href=https://en.wikipedia.org/wiki/Network_science>network science</a> to capture cues from both textual content and the network structure of <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>. We empirically evaluate our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> against a battery of baselines and show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms state of the art by 10 percentage points F1 score.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1113.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1113 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1113 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1113/>Reinforced Co-Training</a></strong><br><a href=/people/j/jiawei-wu/>Jiawei Wu</a>
|
<a href=/people/l/lei-li/>Lei Li</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1113><div class="card-body p-3 small">Co-training is a popular semi-supervised learning framework to utilize a large amount of unlabeled data in addition to a small labeled set. Co-training methods exploit predicted labels on the unlabeled data and select samples based on prediction confidence to augment the training. However, the selection of samples in existing co-training methods is based on a predetermined policy, which ignores the <a href=https://en.wikipedia.org/wiki/Sampling_bias>sampling bias</a> between the unlabeled and the labeled subsets, and fails to explore the data space. In this paper, we propose a novel method, Reinforced Co-Training, to select high-quality unlabeled samples to better co-train on. More specifically, our approach uses <a href=https://en.wikipedia.org/wiki/Q-learning>Q-learning</a> to learn a data selection policy with a small labeled dataset, and then exploits this <a href=https://en.wikipedia.org/wiki/Policy>policy</a> to train the co-training classifiers automatically. Experimental results on clickbait detection and generic text classification tasks demonstrate that our proposed method can obtain more accurate <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a> results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1133.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1133 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1133 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1133.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277671743 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1133" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1133/>KBGAN : <a href=https://en.wikipedia.org/wiki/Adversarial_learning>Adversarial Learning</a> for Knowledge Graph Embeddings<span class=acl-fixed-case>KBGAN</span>: Adversarial Learning for Knowledge Graph Embeddings</a></strong><br><a href=/people/l/liwei-cai/>Liwei Cai</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1133><div class="card-body p-3 small">We introduce KBGAN, an adversarial learning framework to improve the performances of a wide range of existing knowledge graph embedding models. Because <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graphs</a> typically only contain positive facts, sampling useful negative training examples is a nontrivial task. Replacing the head or tail entity of a fact with a uniformly randomly selected entity is a conventional method for generating negative facts, but the majority of the generated negative facts can be easily discriminated from positive facts, and will contribute little towards the training. Inspired by generative adversarial networks (GANs), we use one knowledge graph embedding model as a negative sample generator to assist the training of our desired model, which acts as the discriminator in GANs. This framework is independent of the concrete form of generator and discriminator, and therefore can utilize a wide variety of knowledge graph embedding models as its building blocks. In experiments, we adversarially train two translation-based models, TRANSE and TRANSD, each with assistance from one of the two probability-based models, DISTMULT and COMPLEX. We evaluate the performances of KBGAN on the link prediction task, using three knowledge base completion datasets : FB15k-237, WN18 and WN18RR. Experimental results show that adversarial training substantially improves the performances of target embedding models under various settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1165.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1165 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1165 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277673049 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1165/>Variational Knowledge Graph Reasoning</a></strong><br><a href=/people/w/wenhu-chen/>Wenhu Chen</a>
|
<a href=/people/w/wenhan-xiong/>Wenhan Xiong</a>
|
<a href=/people/x/xifeng-yan/>Xifeng Yan</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1165><div class="card-body p-3 small">Inferring missing links in knowledge graphs (KG) has attracted a lot of attention from the research community. In this paper, we tackle a practical query answering task involving predicting the relation of a given entity pair. We frame this prediction problem as an inference problem in a probabilistic graphical model and aim at resolving it from a variational inference perspective. In order to model the relation between the query entity pair, we assume that there exists an underlying <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variable</a> (paths connecting two nodes) in the KG, which carries the equivalent semantics of their relations. However, due to the intractability of connections in large KGs, we propose to use variation inference to maximize the evidence lower bound. More specifically, our framework (Diva) is composed of three <a href=https://en.wikipedia.org/wiki/Modular_programming>modules</a>, i.e. a posterior approximator, a prior (path finder), and a likelihood (path reasoner). By using <a href=https://en.wikipedia.org/wiki/Variational_inference>variational inference</a>, we are able to incorporate them closely into a unified architecture and jointly optimize them to perform KG reasoning. With active interactions among these sub-modules, Diva is better at handling <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a> and coping with more complex reasoning scenarios. In order to evaluate our method, we conduct the experiment of the link prediction task on multiple datasets and achieve state-of-the-art performances on both datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2125.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-2125 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-2125 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-2125/>Watch, Listen, and Describe : Globally and Locally Aligned Cross-Modal Attentions for Video Captioning</a></strong><br><a href=/people/x/xin-wang/>Xin Wang</a>
|
<a href=/people/y/yuan-fang-wang/>Yuan-Fang Wang</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-2125><div class="card-body p-3 small">A major challenge for video captioning is to combine audio and visual cues. Existing multi-modal fusion methods have shown encouraging results in video understanding. However, the temporal structures of multiple modalities at different granularities are rarely explored, and how to selectively fuse the multi-modal representations at different levels of details remains uncharted. In this paper, we propose a novel hierarchically aligned cross-modal attention (HACA) framework to learn and selectively fuse both global and local temporal dynamics of different modalities. Furthermore, for the first time, we validate the superior performance of the <a href=https://en.wikipedia.org/wiki/Deep_learning>deep audio features</a> on the video captioning task. Finally, our HACA model significantly outperforms the previous best systems and achieves new state-of-the-art results on the widely used MSR-VTT dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-6003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-6003 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-6003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/279154243 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-6003/>Scalable Construction and Reasoning of Massive Knowledge Bases</a></strong><br><a href=/people/x/xiang-ren/>Xiang Ren</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/N18-6/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorial Abstracts</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-6003><div class="card-body p-3 small">In today&#8217;s information-based society, there is abundant knowledge out there carried in the form of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language texts</a> (e.g., <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>, <a href=https://en.wikipedia.org/wiki/Social_media>social media posts</a>, scientific publications), which spans across various domains (e.g., corporate documents, <a href=https://en.wikipedia.org/wiki/Advertising>advertisements</a>, <a href=https://en.wikipedia.org/wiki/Act_of_Parliament>legal acts</a>, medical reports), which grows at an astonishing rate. Yet this knowledge is mostly inaccessible to computers and overwhelming for human experts to absorb. How to turn such massive and unstructured text data into structured, actionable knowledge, and furthermore, how to teach machines learn to reason and complete the extracted knowledge is a grand challenge to the research community. Traditional IE systems assume abundant human annotations for training high quality machine learning models, which is impractical when trying to deploy IE systems to a broad range of domains, settings and languages. In the first part of the tutorial, we introduce how to extract structured facts (i.e., entities and their relations for types of interest) from <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpora</a> to construct <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge bases</a>, with a focus on methods that are weakly-supervised and domain-independent for timely knowledge base construction across various application domains. In the second part, we introduce how to leverage other knowledge, such as the distributional statistics of characters and words, the annotations for other tasks and other domains, and the linguistics and problem structures, to combat the problem of inadequate supervision, and conduct low-resource information extraction. In the third part, we describe recent advances in knowledge base reasoning.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1053.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1053 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1053 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1053.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1053" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1053/>Deep Reinforcement Learning for Chinese Zero Pronoun Resolution<span class=acl-fixed-case>C</span>hinese Zero Pronoun Resolution</a></strong><br><a href=/people/q/qingyu-yin/>Qingyu Yin</a>
|
<a href=/people/y/yu-zhang/>Yu Zhang</a>
|
<a href=/people/w/weinan-zhang/>Wei-Nan Zhang</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1053><div class="card-body p-3 small">Recent neural network models for Chinese zero pronoun resolution gain great performance by capturing semantic information for zero pronouns and candidate antecedents, but tend to be short-sighted, operating solely by making local decisions. They typically predict coreference links between the <a href=https://en.wikipedia.org/wiki/Zero_pronoun>zero pronoun</a> and one single candidate antecedent at a time while ignoring their influence on future decisions. Ideally, modeling useful information of preceding potential antecedents is crucial for classifying later zero pronoun-candidate antecedent pairs, a need which leads traditional models of zero pronoun resolution to draw on <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a>. In this paper, we show how to integrate these goals, applying deep reinforcement learning to deal with the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. With the help of the reinforcement learning agent, our system learns the policy of selecting antecedents in a sequential manner, where useful information provided by earlier predicted antecedents could be utilized for making later coreference decisions. Experimental results on OntoNotes 5.0 show that our approach substantially outperforms the state-of-the-art methods under three experimental settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1083.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1083 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1083 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1083.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1083.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285801215 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1083" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1083/>No Metrics Are Perfect : Adversarial Reward Learning for Visual Storytelling</a></strong><br><a href=/people/x/xin-wang/>Xin Wang</a>
|
<a href=/people/w/wenhu-chen/>Wenhu Chen</a>
|
<a href=/people/y/yuan-fang-wang/>Yuan-Fang Wang</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1083><div class="card-body p-3 small">Though impressive results have been achieved in visual captioning, the task of generating abstract stories from photo streams is still a little-tapped problem. Different from captions, <a href=https://en.wikipedia.org/wiki/Narrative>stories</a> have more expressive language styles and contain many imaginary concepts that do not appear in the <a href=https://en.wikipedia.org/wiki/Image>images</a>. Thus <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> poses challenges to behavioral cloning algorithms. Furthermore, due to the limitations of <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>automatic metrics</a> on evaluating story quality, <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning methods</a> with <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>hand-crafted rewards</a> also face difficulties in gaining an overall performance boost. Therefore, we propose an Adversarial REward Learning (AREL) framework to learn an implicit reward function from human demonstrations, and then optimize policy search with the learned reward function. Though automatic evaluation indicates slight performance boost over state-of-the-art (SOTA) methods in cloning expert behaviors, human evaluation shows that our approach achieves significant improvement in generating more human-like stories than SOTA systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1104.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1104 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1104 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1104.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802339 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1104" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1104/>MojiTalk : Generating Emotional Responses at Scale<span class=acl-fixed-case>M</span>oji<span class=acl-fixed-case>T</span>alk: Generating Emotional Responses at Scale</a></strong><br><a href=/people/x/xianda-zhou/>Xianda Zhou</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1104><div class="card-body p-3 small">Generating emotional language is a key step towards building empathetic natural language processing agents. However, a major challenge for this line of research is the lack of large-scale labeled training data, and previous studies are limited to only small sets of human annotated sentiment labels. Additionally, explicitly controlling the emotion and sentiment of generated text is also difficult. In this paper, we take a more radical approach : we exploit the idea of leveraging Twitter data that are naturally labeled with <a href=https://en.wikipedia.org/wiki/Emoji>emojis</a>. We collect a large corpus of Twitter conversations that include <a href=https://en.wikipedia.org/wiki/Emoji>emojis</a> in the response and assume the <a href=https://en.wikipedia.org/wiki/Emoji>emojis</a> convey the underlying emotions of the sentence. We investigate several conditional variational autoencoders training on these conversations, which allow us to use <a href=https://en.wikipedia.org/wiki/Emoji>emojis</a> to control the emotion of the generated text. Experimentally, we show in our quantitative and qualitative analyses that the proposed models can successfully generate high-quality abstractive conversation responses in accordance with designated emotions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1199.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1199 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1199 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1199.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805358 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1199" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1199/>Robust Distant Supervision Relation Extraction via <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Reinforcement Learning</a></a></strong><br><a href=/people/p/pengda-qin/>Pengda Qin</a>
|
<a href=/people/w/weiran-xu/>Weiran Xu</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1199><div class="card-body p-3 small">Distant supervision has become the standard method for <a href=https://en.wikipedia.org/wiki/Relation_extraction>relation extraction</a>. However, even though <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> is an efficient method, it does not come at no costThe resulted distantly-supervised training samples are often very noisy. To combat the noise, most of the recent state-of-the-art approaches focus on selecting one-best sentence or calculating soft attention weights over the set of the sentences of one specific entity pair. However, these <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> are suboptimal, and the false positive problem is still a key stumbling bottleneck for the performance. We argue that those incorrectly-labeled candidate sentences must be treated with a hard decision, rather than being dealt with soft attention weights. To do this, our paper describes a radical solutionWe explore a deep reinforcement learning strategy to generate the <a href=https://en.wikipedia.org/wiki/False_positives_and_false_negatives>false-positive indicator</a>, where we automatically recognize <a href=https://en.wikipedia.org/wiki/False_positives_and_false_negatives>false positives</a> for each relation type without any <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised information</a>. Unlike the removal operation in the previous studies, we redistribute them into the negative examples. The experimental results show that the proposed <a href=https://en.wikipedia.org/wiki/Strategy>strategy</a> significantly improves the performance of distant supervision comparing to <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art systems</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-5007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-5007 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-5007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-5007/>Deep Reinforcement Learning for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a><span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/w/william-yang-wang/>William Yang Wang</a>
|
<a href=/people/j/jiwei-li/>Jiwei Li</a>
|
<a href=/people/x/xiaodong-he/>Xiaodong He</a><br><a href=/volumes/P18-5/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-5007><div class="card-body p-3 small">Many Natural Language Processing (NLP) tasks (including generation, language grounding, <a href=https://en.wikipedia.org/wiki/Reason>reasoning</a>, <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a>, <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a>, and dialog) can be formulated as deep reinforcement learning (DRL) problems. However, since language is often discrete and the space for all sentences is infinite, there are many challenges for formulating reinforcement learning problems of NLP tasks. In this tutorial, we provide a gentle introduction to the foundation of deep reinforcement learning, as well as some practical DRL solutions in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. We describe recent advances in designing <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>deep reinforcement learning</a> for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, with a special focus on generation, <a href=https://en.wikipedia.org/wiki/Dialogue>dialogue</a>, and <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a>. Finally, we discuss why they succeed, and when they may fail, aiming at providing some practical advice about deep reinforcement learning for solving real-world NLP problems.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2067.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2067 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2067 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P17-2067" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P17-2067/>Liar, Liar Pants on Fire : A New Benchmark Dataset for Fake News Detection</a></strong><br><a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2067><div class="card-body p-3 small">Automatic fake news detection is a challenging problem in deception detection, and it has tremendous real-world political and social impacts. However, statistical approaches to combating <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a> has been dramatically limited by the lack of labeled benchmark datasets. In this paper, we present LIAR : a new, publicly available <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for fake news detection. We collected a decade-long, 12.8 K manually labeled short statements in various contexts from PolitiFact.com, which provides detailed analysis report and links to source documents for each case. This <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> can be used for <a href=https://en.wikipedia.org/wiki/Fact-checking>fact-checking research</a> as well. Notably, this new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is an order of magnitude larger than previously largest public fake news datasets of similar type. Empirically, we investigate automatic fake news detection based on surface-level linguistic patterns. We have designed a novel, hybrid convolutional neural network to integrate <a href=https://en.wikipedia.org/wiki/Meta_data>meta-data</a> with text. We show that this hybrid approach can improve a text-only deep learning model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1060.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1060 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1060 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238232302 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D17-1060" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1060/>DeepPath : A Reinforcement Learning Method for Knowledge Graph Reasoning<span class=acl-fixed-case>D</span>eep<span class=acl-fixed-case>P</span>ath: A Reinforcement Learning Method for Knowledge Graph Reasoning</a></strong><br><a href=/people/w/wenhan-xiong/>Wenhan Xiong</a>
|
<a href=/people/t/thien-hoang/>Thien Hoang</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1060><div class="card-body p-3 small">We study the problem of learning to reason in large scale knowledge graphs (KGs). More specifically, we describe a novel reinforcement learning framework for learning multi-hop relational paths : we use a policy-based agent with continuous states based on knowledge graph embeddings, which reasons in a KG vector-space by sampling the most promising relation to extend its path. In contrast to prior work, our approach includes a <a href=https://en.wikipedia.org/wiki/Reward_system>reward function</a> that takes the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, <a href=https://en.wikipedia.org/wiki/Diversity_(business)>diversity</a>, and <a href=https://en.wikipedia.org/wiki/Efficiency>efficiency</a> into consideration. Experimentally, we show that our proposed method outperforms a path-ranking based algorithm and knowledge graph embedding methods on Freebase and Never-Ending Language Learning datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1191.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1191 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1191 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1191/>Deep Residual Learning for Weakly-Supervised Relation Extraction</a></strong><br><a href=/people/y/yi-yao-huang/>Yi Yao Huang</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1191><div class="card-body p-3 small">Deep residual learning (ResNet) is a new method for training very deep neural networks using <a href=https://en.wikipedia.org/wiki/Identity_mapping>identity mapping</a> for shortcut connections. ResNet has won the ImageNet ILSVRC 2015 classification task, and achieved state-of-the-art performances in many computer vision tasks. However, the effect of residual learning on noisy natural language processing tasks is still not well understood. In this paper, we design a novel convolutional neural network (CNN) with residual learning, and investigate its impacts on the task of distantly supervised noisy relation extraction. In contradictory to popular beliefs that <a href=https://en.wikipedia.org/wiki/ResNet>ResNet</a> only works well for very deep networks, we found that even with 9 layers of CNNs, using <a href=https://en.wikipedia.org/wiki/Identity_mapping>identity mapping</a> could significantly improve the performance for distantly-supervised relation extraction.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=William+Yang+Wang" title="Search for 'William Yang Wang' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/w/wenhan-xiong/ class=align-middle>Wenhan Xiong</a>
<span class="badge badge-secondary align-middle ml-2">10</span></li><li class=list-group-item><a href=/people/w/wenhu-chen/ class=align-middle>Wenhu Chen</a>
<span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/people/x/xin-wang/ class=align-middle>Xin Wang</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/x/xifeng-yan/ class=align-middle>Xifeng Yan</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/m/mo-yu/ class=align-middle>Mo Yu</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/s/shiyu-chang/ class=align-middle>Shiyu Chang</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/x/xiaoxiao-guo/ class=align-middle>Xiaoxiao Guo</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/j/jiawei-wu/ class=align-middle>Jiawei Wu</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/q/qingyu-yin/ class=align-middle>Qingyu Yin</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/w/weinan-zhang/ class=align-middle>Weinan Zhang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/t/ting-liu/ class=align-middle>Ting Liu</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/jing-qian/ class=align-middle>Jing Qian</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/h/hong-wang/ class=align-middle>Hong Wang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/sharon-levy/ class=align-middle>Sharon Levy</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/p/pengda-qin/ class=align-middle>Pengda Qin</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/y/yu-zhang/ class=align-middle>Yu Zhang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/liangming-pan/ class=align-middle>Liangming Pan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/min-yen-kan/ class=align-middle>Min-Yen Kan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yu-su/ class=align-middle>Yu Su</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/elizabeth-belding/ class=align-middle>Elizabeth Belding</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/prince-zizhuang-wang/ class=align-middle>Prince Zizhuang Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jianshu-chen/ class=align-middle>Jianshu Chen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/v/vivek-kulkarni/ class=align-middle>Vivek Kulkarni</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jiwei-li/ class=align-middle>Jiwei Li</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yuan-fang-wang/ class=align-middle>Yuan-Fang Wang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/q/qingfu-zhu/ class=align-middle>Qingfu Zhu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wanrong-zhu/ class=align-middle>Wanrong Zhu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pradyumna-narayana/ class=align-middle>Pradyumna Narayana</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kazoo-sone/ class=align-middle>Kazoo Sone</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sugato-basu/ class=align-middle>Sugato Basu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrew-gaut/ class=align-middle>Andrew Gaut</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tony-sun/ class=align-middle>Tony Sun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shirlyn-tang/ class=align-middle>Shirlyn Tang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yuxin-huang/ class=align-middle>Yuxin Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mai-elsherief/ class=align-middle>Mai ElSherief</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jieyu-zhao/ class=align-middle>Jieyu Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/diba-mirza/ class=align-middle>Diba Mirza</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kai-wei-chang/ class=align-middle>Kai-Wei Chang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chen-wu/ class=align-middle>Chen Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jesse-thomason/ class=align-middle>Jesse Thomason</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ronghang-hu/ class=align-middle>Ronghang Hu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xinlei-chen/ class=align-middle>Xinlei Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/peter-anderson/ class=align-middle>Peter Anderson</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qi-wu/ class=align-middle>Qi Wu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/asli-celikyilmaz/ class=align-middle>Asli Celikyilmaz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jason-baldridge/ class=align-middle>Jason Baldridge</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dong-yu/ class=align-middle>Dong Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/junting-ye/ class=align-middle>Junting Ye</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/steven-skiena/ class=align-middle>Steven Skiena</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-saxon/ class=align-middle>Michael Saxon</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xinyi-wang/ class=align-middle>Xinyi Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alon-albalak/ class=align-middle>Alon Albalak</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhiyu-chen/ class=align-middle>Zhiyu Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/charese-smiley/ class=align-middle>Charese Smiley</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sameena-shah/ class=align-middle>Sameena Shah</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/iana-borova/ class=align-middle>Iana Borova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dylan-langdon/ class=align-middle>Dylan Langdon</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/reema-moussa/ class=align-middle>Reema Moussa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/matt-beane/ class=align-middle>Matt Beane</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/ting-hao-huang/ class=align-middle>Ting-Hao Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bryan-r-routledge/ class=align-middle>Bryan R. Routledge</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anna-bethke/ class=align-middle>Anna Bethke</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yinyin-liu/ class=align-middle>Yinyin Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/siyao-li/ class=align-middle>Siyao Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/deren-lei/ class=align-middle>Deren Lei</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thien-hoang/ class=align-middle>Thien Hoang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yi-yao-huang/ class=align-middle>Yi Yao Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sameer-singh/ class=align-middle>Sameer Singh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lei-li/ class=align-middle>Lei Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/liwei-cai/ class=align-middle>Liwei Cai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiang-ren/ class=align-middle>Xiang Ren</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nanyun-peng/ class=align-middle>Nanyun Peng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ray-oshikawa/ class=align-middle>Ray Oshikawa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kai-nakamura/ class=align-middle>Kai Nakamura</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xianda-zhou/ class=align-middle>Xianda Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/weiran-xu/ class=align-middle>Weiran Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaodong-he/ class=align-middle>Xiaodong He</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hui-liu/ class=align-middle>Hui Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">16</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">12</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/alvr/ class=align-middle>ALVR</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/nlpcovid19/ class=align-middle>NLP-COVID19</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>