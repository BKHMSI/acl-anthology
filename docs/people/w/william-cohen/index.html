<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>William Cohen - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>William</span> <span class=font-weight-bold>Cohen</span></h2><hr><div class=row><div class=col-lg-9><h4>2022</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2022.acl-long.253.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2022--acl-long--253 data-toggle=collapse aria-expanded=false aria-controls=abstract-2022.acl-long.253 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2022.acl-long.253" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2022.acl-long.253/>ConditionalQA A Complex Reading Comprehension Dataset with Conditional Answers<span class=acl-fixed-case>C</span>onditional<span class=acl-fixed-case>QA</span>: A Complex Reading Comprehension Dataset with Conditional Answers</a></strong><br><a href=/people/h/haitian-sun/>Haitian Sun</a>
|
<a href=/people/w/william-cohen/>William Cohen</a>
|
<a href=/people/r/ruslan-salakhutdinov/>Ruslan Salakhutdinov</a><br><a href=/volumes/2022.acl-long/ class=text-muted>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2022--acl-long--253><div class="card-body p-3 small">We describe a Question Answering QA dataset that contains complex questions with conditional answers i.e. the answers are only applicable when certain conditions apply We call this dataset ConditionalQA In addition to conditional answers the dataset also features \n long context documents with information that is related in logically complex ways \n multi hop questions that require compositional logical reasoning \n a combination of extractive questions yes no questions questions with multiple answers and not answerable questions \n questions asked without knowing the answers We show that ConditionalQA is challenging for many of the existing QA models especially in selecting answer conditions We believe that this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> will motivate further research in answering complex questions over long documents</div></div><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.600.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--600 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.600 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.600" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.600/>MATE : Multi-view Attention for Table Transformer Efficiency<span class=acl-fixed-case>MATE</span>: Multi-view Attention for Table Transformer Efficiency</a></strong><br><a href=/people/j/julian-eisenschlos/>Julian Eisenschlos</a>
|
<a href=/people/m/maharshi-gor/>Maharshi Gor</a>
|
<a href=/people/t/thomas-mueller/>Thomas Müller</a>
|
<a href=/people/w/william-cohen/>William Cohen</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--600><div class="card-body p-3 small">This work presents a sparse-attention Transformer architecture for modeling documents that contain large tables. Tables are ubiquitous on the web, and are rich in information. However, more than 20 % of relational tables on the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>web</a> have 20 or more rows (Cafarella et al., 2008), and these large tables present a challenge for current Transformer models, which are typically limited to 512 tokens. Here we propose <a href=https://en.wikipedia.org/wiki/MATE_(software)>MATE</a>, a novel Transformer architecture designed to model the structure of web tables. MATE uses sparse attention in a way that allows heads to efficiently attend to either rows or columns in a table. This <a href=https://en.wikipedia.org/wiki/Computer_architecture>architecture</a> scales linearly with respect to speed and memory, and can handle documents containing more than 8000 tokens with current accelerators. MATE also has a more appropriate <a href=https://en.wikipedia.org/wiki/Inductive_bias>inductive bias</a> for <a href=https://en.wikipedia.org/wiki/Table_(information)>tabular data</a>, and sets a new <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> for three table reasoning datasets. For HybridQA (Chen et al., 2020), a dataset that involves large documents containing tables, we improve the best prior result by 19 points.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.288.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--288 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.288 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.288/>Adaptable and Interpretable Neural MemoryOver Symbolic Knowledge<span class=acl-fixed-case>M</span>emory<span class=acl-fixed-case>O</span>ver Symbolic Knowledge</a></strong><br><a href=/people/p/pat-verga/>Pat Verga</a>
|
<a href=/people/h/haitian-sun/>Haitian Sun</a>
|
<a href=/people/l/livio-baldini-soares/>Livio Baldini Soares</a>
|
<a href=/people/w/william-cohen/>William Cohen</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--288><div class="card-body p-3 small">Past research has demonstrated that large neural language models (LMs) encode surprising amounts of factual information : however, augmenting or modifying this <a href=https://en.wikipedia.org/wiki/Information>information</a> requires modifying a corpus and retraining, which is computationally expensive. To address this problem, we develop a neural LM that includes an interpretable neuro-symbolic KB in the form of a fact memory. Each element of the fact memory is formed from a triple of vectors, where each vector corresponds to a KB entity or relation. Our LM improves performance on knowledge-intensive question-answering tasks, sometimes dramatically, including a 27 point increase in one setting of WebQuestionsSP over a state-of-the-art open-book model, despite using 5 % of the parameters. Most interestingly, we demonstrate that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can be modified, without any <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>re-training</a>, by updating the fact memory.<i>any</i> re-training, by updating the fact memory.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1242.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1242 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1242 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1242/>PullNet : Open Domain Question Answering with Iterative Retrieval on Knowledge Bases and Text<span class=acl-fixed-case>P</span>ull<span class=acl-fixed-case>N</span>et: Open Domain Question Answering with Iterative Retrieval on Knowledge Bases and Text</a></strong><br><a href=/people/h/haitian-sun/>Haitian Sun</a>
|
<a href=/people/t/tania-bedrax-weiss/>Tania Bedrax-Weiss</a>
|
<a href=/people/w/william-cohen/>William Cohen</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1242><div class="card-body p-3 small">We consider open-domain question answering (QA) where answers are drawn from either a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, a knowledge base (KB), or a combination of both of these. We focus on a setting in which a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> is supplemented with a large but incomplete KB, and on questions that require non-trivial (e.g., multi-hop) reasoning. We describe PullNet, an integrated framework for (1) learning what to retrieve and (2) reasoning with this heterogeneous information to find the best answer. PullNet uses an <a href=https://en.wikipedia.org/wiki/Iterative_and_incremental_development>iterative process</a> to construct a question-specific subgraph that contains information relevant to the question. In each iteration, a graph convolutional network (graph CNN) is used to identify subgraph nodes that should be expanded using retrieval (or pull) operations on the corpus and/or KB. After the <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>subgraph</a> is complete, another graph CNN is used to extract the answer from the <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>subgraph</a>. This retrieve-and-reason process allows us to answer multi-hop questions using large KBs and <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpora</a>. PullNet is weakly supervised, requiring question-answer pairs but not gold inference paths. Experimentally PullNet improves over the prior state-of-the art, and in the setting where a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> is used with incomplete KB these improvements are often dramatic. PullNet is also often superior to prior systems in a KB-only setting or a <a href=https://en.wikipedia.org/wiki/Text-based_user_interface>text-only setting</a>.<fixed-case>iterative</fixed-case> process to construct a question-specific subgraph that contains information relevant to the question. In each iteration, a graph convolutional network (graph CNN) is used to identify subgraph nodes that should be expanded using retrieval (or &#8220;pull&#8221;) operations on the corpus and/or KB. After the subgraph is complete, another graph CNN is used to extract the answer from the subgraph. This retrieve-and-reason process allows us to answer multi-hop questions using large KBs and corpora. PullNet is weakly supervised, requiring question-answer pairs but not gold inference paths. Experimentally PullNet improves over the prior state-of-the art, and in the setting where a corpus is used with incomplete KB these improvements are often dramatic. PullNet is also often superior to prior systems in a KB-only setting or a text-only setting.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1259.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1259 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1259 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1259" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1259/>PubMedQA : A Dataset for Biomedical Research Question Answering<span class=acl-fixed-case>P</span>ub<span class=acl-fixed-case>M</span>ed<span class=acl-fixed-case>QA</span>: A Dataset for Biomedical Research Question Answering</a></strong><br><a href=/people/q/qiao-jin/>Qiao Jin</a>
|
<a href=/people/b/bhuwan-dhingra/>Bhuwan Dhingra</a>
|
<a href=/people/z/zhengping-liu/>Zhengping Liu</a>
|
<a href=/people/w/william-cohen/>William Cohen</a>
|
<a href=/people/x/xinghua-lu/>Xinghua Lu</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1259><div class="card-body p-3 small">We introduce PubMedQA, a novel biomedical question answering (QA) dataset collected from PubMed abstracts. The task of PubMedQA is to answer research questions with yes / no / maybe (e.g. : Do preoperative <a href=https://en.wikipedia.org/wiki/Statin>statins</a> reduce <a href=https://en.wikipedia.org/wiki/Atrial_fibrillation>atrial fibrillation</a> after coronary artery bypass grafting?) using the corresponding <a href=https://en.wikipedia.org/wiki/Abstract_(summary)>abstracts</a>. PubMedQA has 1k expert-annotated, 61.2k unlabeled and 211.3k artificially generated QA instances. Each PubMedQA instance is composed of (1) a question which is either an existing research article title or derived from one, (2) a context which is the corresponding abstract without its conclusion, (3) a long answer, which is the conclusion of the abstract and, presumably, answers the research question, and (4) a yes / no / maybe answer which summarizes the conclusion. PubMedQA is the first QA dataset where reasoning over biomedical research texts, especially their quantitative contents, is required to answer the questions. Our best performing <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, multi-phase fine-tuning of BioBERT with long answer bag-of-word statistics as additional supervision, achieves 68.1 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, compared to single human performance of 78.0 % accuracy and majority-baseline of 55.2 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, leaving much room for improvement. PubMedQA is publicly available at https://pubmedqa.github.io.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2011.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2011 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2011 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-2011" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-2011/>Probing Biomedical Embeddings from Language Models</a></strong><br><a href=/people/q/qiao-jin/>Qiao Jin</a>
|
<a href=/people/b/bhuwan-dhingra/>Bhuwan Dhingra</a>
|
<a href=/people/w/william-cohen/>William Cohen</a>
|
<a href=/people/x/xinghua-lu/>Xinghua Lu</a><br><a href=/volumes/W19-20/ class=text-muted>Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2011><div class="card-body p-3 small">Contextualized word embeddings derived from pre-trained language models (LMs) show significant improvements on downstream NLP tasks. Pre-training on domain-specific corpora, such as biomedical articles, further improves their performance. In this paper, we conduct probing experiments to determine what additional information is carried intrinsically by the in-domain trained contextualized embeddings. For this we use the pre-trained <a href=https://en.wikipedia.org/wiki/Linear_model>LMs</a> as fixed feature extractors and restrict the downstream task models to not have additional sequence modeling layers. We compare BERT (Devlin et al. 2018), ELMo (Peters et al., 2018), BioBERT (Lee et al., 2019) and BioELMo, a biomedical version of ELMo trained on 10 M PubMed abstracts. Surprisingly, while fine-tuned BioBERT is better than BioELMo in biomedical NER and NLI tasks, as a fixed feature extractor BioELMo outperforms BioBERT in our probing tasks. We use <a href=https://en.wikipedia.org/wiki/Visualization_(graphics)>visualization</a> and nearest neighbor analysis to show that better encoding of entity-type and relational information leads to this superiority.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5306.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5306 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5306 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5306/>AttentionMeSH : Simple, Effective and Interpretable Automatic MeSH Indexer<span class=acl-fixed-case>A</span>ttention<span class=acl-fixed-case>M</span>e<span class=acl-fixed-case>SH</span>: Simple, Effective and Interpretable Automatic <span class=acl-fixed-case>M</span>e<span class=acl-fixed-case>SH</span> Indexer</a></strong><br><a href=/people/q/qiao-jin/>Qiao Jin</a>
|
<a href=/people/b/bhuwan-dhingra/>Bhuwan Dhingra</a>
|
<a href=/people/w/william-cohen/>William Cohen</a>
|
<a href=/people/x/xinghua-lu/>Xinghua Lu</a><br><a href=/volumes/W18-53/ class=text-muted>Proceedings of the 6th BioASQ Workshop A challenge on large-scale biomedical semantic indexing and question answering</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5306><div class="card-body p-3 small">There are millions of articles in <a href=https://en.wikipedia.org/wiki/PubMed>PubMed database</a>. To facilitate <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a>, curators in the National Library of Medicine (NLM) assign a set of Medical Subject Headings (MeSH) to each article. MeSH is a hierarchically-organized vocabulary, containing about 28 K different concepts, covering the fields from <a href=https://en.wikipedia.org/wiki/Medicine>clinical medicine</a> to <a href=https://en.wikipedia.org/wiki/Information_science>information sciences</a>. Several automatic MeSH indexing models have been developed to improve the time-consuming and financially expensive manual annotation, including the NLM official tool Medical Text Indexer, and the winner of BioASQ Task5a challenge DeepMeSH. However, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are complex and not interpretable. We propose a novel <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end model</a>, AttentionMeSH, which utilizes <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> and attention mechanism to index <a href=https://en.wikipedia.org/wiki/Medical_Subject_Headings>MeSH terms</a> to biomedical text. The attention mechanism enables the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to associate textual evidence with annotations, thus providing <a href=https://en.wikipedia.org/wiki/Interpretability>interpretability</a> at the word level. The <a href=https://en.wikipedia.org/wiki/Physical_model>model</a> also uses a novel masking mechanism to enhance <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and <a href=https://en.wikipedia.org/wiki/Speed>speed</a>. In the final week of BioASQ Chanllenge Task6a, we ranked 2nd by average MiF using an on-construction model. After the contest, we achieve close to state-of-the-art MiF performance of 0.684 using our final model. Human evaluations show AttentionMeSH also provides high level of interpretability, retrieving about 90 % of all expert-labeled relevant words given an MeSH-article pair at 20 output.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6122.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6122 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6122 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6122/>Learning to Define Terms in the Software Domain</a></strong><br><a href=/people/v/vidhisha-balachandran/>Vidhisha Balachandran</a>
|
<a href=/people/d/dheeraj-rajagopal/>Dheeraj Rajagopal</a>
|
<a href=/people/r/rose-catherine-kanjirathinkal/>Rose Catherine Kanjirathinkal</a>
|
<a href=/people/w/william-cohen/>William Cohen</a><br><a href=/volumes/W18-61/ class=text-muted>Proceedings of the 2018 EMNLP Workshop W-NUT: The 4th Workshop on Noisy User-generated Text</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6122><div class="card-body p-3 small">One way to test a person&#8217;s knowledge of a domain is to ask them to define domain-specific terms. Here, we investigate the task of automatically generating definitions of technical terms by reading text from the technical domain. Specifically, we learn definitions of software entities from a large corpus built from the user forum Stack Overflow. To model definitions, we train a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> and incorporate additional domain-specific information like <a href=https://en.wikipedia.org/wiki/Co-occurrence>word co-occurrence</a>, and <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontological category information</a>. Our approach improves previous <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> by 2 <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>BLEU points</a> for the definition generation task. Our experiments also show the additional challenges associated with the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> and the short-comings of language-model based architectures for definition generation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-2007 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-2007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-2007/>Neural Models for Reasoning over Multiple Mentions Using Coreference</a></strong><br><a href=/people/b/bhuwan-dhingra/>Bhuwan Dhingra</a>
|
<a href=/people/q/qiao-jin/>Qiao Jin</a>
|
<a href=/people/z/zhilin-yang/>Zhilin Yang</a>
|
<a href=/people/w/william-cohen/>William Cohen</a>
|
<a href=/people/r/ruslan-salakhutdinov/>Ruslan Salakhutdinov</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-2007><div class="card-body p-3 small">Many problems in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> require aggregating information from multiple mentions of the same entity which may be far apart in the text. Existing Recurrent Neural Network (RNN) layers are biased towards short-term dependencies and hence not suited to such tasks. We present a recurrent layer which is instead biased towards coreferent dependencies. The layer uses coreference annotations extracted from an external system to connect entity mentions belonging to the same cluster. Incorporating this layer into a state-of-the-art reading comprehension model improves performance on three datasets Wikihop, LAMBADA and the bAbi AI tasks with large gains when training data is scarce.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1096.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1096 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1096 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234955469 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1096/>Semi-Supervised QA with Generative Domain-Adaptive Nets<span class=acl-fixed-case>QA</span> with Generative Domain-Adaptive Nets</a></strong><br><a href=/people/z/zhilin-yang/>Zhilin Yang</a>
|
<a href=/people/j/junjie-hu/>Junjie Hu</a>
|
<a href=/people/r/ruslan-salakhutdinov/>Ruslan Salakhutdinov</a>
|
<a href=/people/w/william-cohen/>William Cohen</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1096><div class="card-body p-3 small">We study the problem of semi-supervised question answeringutilizing unlabeled text to boost the performance of question answering models. We propose a novel training framework, the Generative Domain-Adaptive Nets. In this framework, we train a <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> to generate questions based on the unlabeled text, and combine model-generated questions with human-generated questions for training question answering models. We develop novel domain adaptation algorithms, based on <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a>, to alleviate the discrepancy between the model-generated data distribution and the human-generated data distribution. Experiments show that our proposed <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> obtains substantial improvement from unlabeled text.<i>Generative Domain-Adaptive Nets</i>. In this framework, we train a generative model to generate\n questions based on the unlabeled text, and combine model-generated\n questions with human-generated questions for training question answering\n models. We develop novel domain adaptation algorithms, based on\n reinforcement learning, to alleviate the discrepancy between the\n model-generated data distribution and the human-generated data\n distribution. Experiments show that our proposed framework obtains\n substantial improvement from unlabeled text.\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1168.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1168 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1168 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P17-1168" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P17-1168/>Gated-Attention Readers for Text Comprehension</a></strong><br><a href=/people/b/bhuwan-dhingra/>Bhuwan Dhingra</a>
|
<a href=/people/h/hanxiao-liu/>Hanxiao Liu</a>
|
<a href=/people/z/zhilin-yang/>Zhilin Yang</a>
|
<a href=/people/w/william-cohen/>William Cohen</a>
|
<a href=/people/r/ruslan-salakhutdinov/>Ruslan Salakhutdinov</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1168><div class="card-body p-3 small">In this paper we study the problem of answering cloze-style questions over documents. Our model, the Gated-Attention (GA) Reader, integrates a multi-hop architecture with a novel attention mechanism, which is based on multiplicative interactions between the query embedding and the intermediate states of a recurrent neural network document reader. This enables the reader to build query-specific representations of tokens in the document for accurate answer selection. The GA Reader obtains state-of-the-art results on three benchmarks for this taskthe CNN & Daily Mail news stories and the Who Did What dataset. The effectiveness of multiplicative interaction is demonstrated by an ablation study, and by comparing to alternative compositional operators for implementing the gated-attention.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=William+Cohen" title="Search for 'William Cohen' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/b/bhuwan-dhingra/ class=align-middle>Bhuwan Dhingra</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/r/ruslan-salakhutdinov/ class=align-middle>Ruslan Salakhutdinov</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/q/qiao-jin/ class=align-middle>Qiao Jin</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/z/zhilin-yang/ class=align-middle>Zhilin Yang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/h/haitian-sun/ class=align-middle>Haitian Sun</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/x/xinghua-lu/ class=align-middle>Xinghua Lu</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/junjie-hu/ class=align-middle>Junjie Hu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hanxiao-liu/ class=align-middle>Hanxiao Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/julian-eisenschlos/ class=align-middle>Julian Eisenschlos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maharshi-gor/ class=align-middle>Maharshi Gor</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/thomas-mueller/ class=align-middle>Thomas Mueller</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tania-bedrax-weiss/ class=align-middle>Tania Bedrax-Weiss</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhengping-liu/ class=align-middle>Zhengping Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pat-verga/ class=align-middle>Pat Verga</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/livio-baldini-soares/ class=align-middle>Livio Baldini Soares</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vidhisha-balachandran/ class=align-middle>Vidhisha Balachandran</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dheeraj-rajagopal/ class=align-middle>Dheeraj Rajagopal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rose-catherine-kanjirathinkal/ class=align-middle>Rose Catherine Kanjirathinkal</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>