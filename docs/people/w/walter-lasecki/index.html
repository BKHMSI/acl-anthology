<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Walter Lasecki - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Walter</span> <span class=font-weight-bold>Lasecki</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Walter S. <span class=font-weight-normal>Lasecki</span></p><hr><div class=row><div class=col-lg-9><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.38.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--38 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.38 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.findings-emnlp.38.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.findings-emnlp.38" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.38/>A Novel Workflow for Accurately and Efficiently Crowdsourcing Predicate Senses and Argument Labels</a></strong><br><a href=/people/y/youxuan-jiang/>Youxuan Jiang</a>
|
<a href=/people/h/huaiyu-zhu/>Huaiyu Zhu</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/y/yunyao-li/>Yunyao Li</a>
|
<a href=/people/w/walter-lasecki/>Walter Lasecki</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--38><div class="card-body p-3 small">Resources for Semantic Role Labeling (SRL) are typically annotated by experts at great expense. Prior attempts to develop <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing methods</a> have either had low <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> or required substantial <a href=https://en.wikipedia.org/wiki/Annotation>expert annotation</a>. We propose a new multi-stage crowd workflow that substantially reduces expert involvement without sacrificing <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. In particular, we introduce a unique filter stage based on the key observation that crowd workers are able to almost perfectly filter out incorrect options for labels. Our three-stage workflow produces annotations with 95 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> for predicate labels and 93 % for argument labels, which is comparable to expert agreement. Compared to prior work on <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a> for SRL, we decrease expert effort by 4x, from 56 % to 14 % of cases. Our approach enables more scalable annotation of SRL, and could enable annotation of NLP tasks that have previously been considered too complex to effectively crowdsource.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4107.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4107 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4107 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4107/>DSTC7 Task 1 : Noetic End-to-End Response Selection<span class=acl-fixed-case>DSTC</span>7 Task 1: Noetic End-to-End Response Selection</a></strong><br><a href=/people/c/chulaka-gunasekara/>Chulaka Gunasekara</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/l/lazaros-polymenakos/>Lazaros Polymenakos</a>
|
<a href=/people/w/walter-lasecki/>Walter Lasecki</a><br><a href=/volumes/W19-41/ class=text-muted>Proceedings of the First Workshop on NLP for Conversational AI</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4107><div class="card-body p-3 small">Goal-oriented dialogue in complex domains is an extremely challenging problem and there are relatively few datasets. This <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> provided two new resources that presented different challenges : one was focused but small, while the other was large but diverse. We also considered several new variations on the next utterance selection problem : (1) increasing the number of candidates, (2) including paraphrases, and (3) not including a correct option in the candidate set. Twenty teams participated, developing a range of neural network models, including some that successfully incorporated external data to boost performance. Both <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> have been publicly released, enabling future work to build on these results, working towards robust goal-oriented dialogue systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1374.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1374 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1374 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1374.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1374.Software.tgz data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1374" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1374/>A Large-Scale Corpus for Conversation Disentanglement</a></strong><br><a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/s/sai-r-gouravajhala/>Sai R. Gouravajhala</a>
|
<a href=/people/j/joseph-j-peper/>Joseph J. Peper</a>
|
<a href=/people/v/vignesh-athreya/>Vignesh Athreya</a>
|
<a href=/people/c/chulaka-gunasekara/>Chulaka Gunasekara</a>
|
<a href=/people/j/jatin-ganhotra/>Jatin Ganhotra</a>
|
<a href=/people/s/siva-sankalp-patel/>Siva Sankalp Patel</a>
|
<a href=/people/l/lazaros-c-polymenakos/>Lazaros C Polymenakos</a>
|
<a href=/people/w/walter-lasecki/>Walter Lasecki</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1374><div class="card-body p-3 small">Disentangling conversations mixed together in a single stream of messages is a difficult task, made harder by the lack of large manually annotated datasets. We created a new dataset of 77,563 messages manually annotated with reply-structure graphs that both disentangle conversations and define internal conversation structure. Our <a href=https://en.wikipedia.org/wiki/Data>data</a> is 16 times larger than all previously released datasets combined, the first to include adjudication of annotation disagreements, and the first to include <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context</a>. We use our data to re-examine prior work, in particular, finding that 89 % of conversations in a widely used dialogue corpus are either missing messages or contain extra messages. Our manually-annotated data presents an opportunity to develop robust data-driven methods for conversation disentanglement, which will help advance dialogue research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-3023.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-3023 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-3023 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-3023/>HEIDL : Learning <a href=https://en.wikipedia.org/wiki/Linguistic_description>Linguistic Expressions</a> with <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Learning</a> and Human-in-the-Loop<span class=acl-fixed-case>HEIDL</span>: Learning Linguistic Expressions with Deep Learning and Human-in-the-Loop</a></strong><br><a href=/people/p/prithviraj-sen/>Prithviraj Sen</a>
|
<a href=/people/y/yunyao-li/>Yunyao Li</a>
|
<a href=/people/e/eser-kandogan/>Eser Kandogan</a>
|
<a href=/people/y/yiwei-yang/>Yiwei Yang</a>
|
<a href=/people/w/walter-lasecki/>Walter Lasecki</a><br><a href=/volumes/P19-3/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-3023><div class="card-body p-3 small">While the role of humans is increasingly recognized in machine learning community, representation of and interaction with <a href=https://en.wikipedia.org/wiki/Conceptual_model_(computer_science)>models</a> in current human-in-the-loop machine learning (HITL-ML) approaches are too low-level and far-removed from human&#8217;s conceptual models. We demonstrate HEIDL, a prototype HITL-ML system that exposes the machine-learned model through high-level, explainable linguistic expressions formed of predicates representing semantic structure of text. In HEIDL, human&#8217;s role is elevated from simply evaluating model predictions to interpreting and even updating the model logic directly by enabling interaction with rule predicates themselves. Raising the currency of interaction to such semantic levels calls for new interaction paradigms between humans and machines that result in improved productivity for text analytics model development process. Moreover, by involving humans in the process, the human-machine co-created models generalize better to unseen data as domain experts are able to instill their expertise by extrapolating from what has been learned by automated algorithms from few labelled data.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2099.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-2099 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-2099 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-2099.Datasets.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-2099/>Effective <a href=https://en.wikipedia.org/wiki/Crowdsourcing>Crowdsourcing</a> for a New Type of Summarization Task</a></strong><br><a href=/people/y/youxuan-jiang/>Youxuan Jiang</a>
|
<a href=/people/c/catherine-finegan-dollak/>Catherine Finegan-Dollak</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/w/walter-lasecki/>Walter Lasecki</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-2099><div class="card-body p-3 small">Most <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> research focuses on summarizing the entire given text, but in practice readers are often interested in only one aspect of the document or conversation. We propose targeted summarization as an umbrella category for summarization tasks that intentionally consider only parts of the input data. This covers query-based summarization, update summarization, and a new task we propose where the goal is to summarize a particular aspect of a document. However, collecting data for this new task is hard because directly asking annotators (e.g., crowd workers) to write summaries leads to data with low accuracy when there are a large number of facts to include. We introduce a novel crowdsourcing workflow, Pin-Refine, that allows us to collect high-quality summaries for our task, a necessary step for the development of automatic systems.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2017.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2017 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2017 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-2017.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-2017.Datasets.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234958413 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-2017/>Understanding Task Design Trade-offs in Crowdsourced Paraphrase Collection</a></strong><br><a href=/people/y/youxuan-jiang/>Youxuan Jiang</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/w/walter-lasecki/>Walter S. Lasecki</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2017><div class="card-body p-3 small">Linguistically diverse datasets are critical for training and evaluating robust <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning systems</a>, but <a href=https://en.wikipedia.org/wiki/Data_collection>data collection</a> is a costly process that often requires experts. Crowdsourcing the process of <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a> is an effective means of expanding <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language datasets</a>, but there has been limited analysis of the trade-offs that arise when designing tasks. In this paper, we present the first systematic study of the key factors in crowdsourcing paraphrase collection. We consider variations in <a href=https://en.wikipedia.org/wiki/Instruction_set_architecture>instructions</a>, <a href=https://en.wikipedia.org/wiki/Incentive>incentives</a>, <a href=https://en.wikipedia.org/wiki/Data_domain>data domains</a>, and <a href=https://en.wikipedia.org/wiki/Workflow>workflows</a>. We manually analyzed paraphrases for correctness, <a href=https://en.wikipedia.org/wiki/Grammaticality>grammaticality</a>, and <a href=https://en.wikipedia.org/wiki/Linguistic_diversity>linguistic diversity</a>. Our observations provide new insight into the trade-offs between <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and diversity in crowd responses that arise as a result of <a href=https://en.wikipedia.org/wiki/Design_of_experiments>task design</a>, providing guidance for future paraphrase generation procedures.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Walter+Lasecki" title="Search for 'Walter Lasecki' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/j/jonathan-k-kummerfeld/ class=align-middle>Jonathan K. Kummerfeld</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/y/youxuan-jiang/ class=align-middle>Youxuan Jiang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/y/yunyao-li/ class=align-middle>Yunyao Li</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/chulaka-gunasekara/ class=align-middle>Chulaka Gunasekara</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/huaiyu-zhu/ class=align-middle>Huaiyu Zhu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/l/lazaros-polymenakos/ class=align-middle>Lazaros Polymenakos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/catherine-finegan-dollak/ class=align-middle>Catherine Finegan-Dollak</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sai-r-gouravajhala/ class=align-middle>Sai R. Gouravajhala</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joseph-j-peper/ class=align-middle>Joseph J. Peper</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vignesh-athreya/ class=align-middle>Vignesh Athreya</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jatin-ganhotra/ class=align-middle>Jatin Ganhotra</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/siva-sankalp-patel/ class=align-middle>Siva Sankalp Patel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/lazaros-c-polymenakos/ class=align-middle>Lazaros C Polymenakos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/prithviraj-sen/ class=align-middle>Prithviraj Sen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eser-kandogan/ class=align-middle>Eser Kandogan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yiwei-yang/ class=align-middle>Yiwei Yang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>