<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Wei Zhao - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Wei</span> <span class=font-weight-bold>Zhao</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.eval4nlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.eval4nlp-1.0/>Proceedings of the 2nd Workshop on Evaluation and Comparison of NLP Systems</a></strong><br><a href=/people/y/yang-gao/>Yang Gao</a>
|
<a href=/people/s/steffen-eger/>Steffen Eger</a>
|
<a href=/people/w/wei-zhao/>Wei Zhao</a>
|
<a href=/people/p/piyawat-lertvittayakumjorn/>Piyawat Lertvittayakumjorn</a>
|
<a href=/people/m/marina-fomicheva/>Marina Fomicheva</a><br><a href=/volumes/2021.eval4nlp-1/ class=text-muted>Proceedings of the 2nd Workshop on Evaluation and Comparison of NLP Systems</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.179.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--179 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.179 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.179" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.179/>Better than Average : Paired Evaluation of NLP systems<span class=acl-fixed-case>NLP</span> systems</a></strong><br><a href=/people/m/maxime-peyrard/>Maxime Peyrard</a>
|
<a href=/people/w/wei-zhao/>Wei Zhao</a>
|
<a href=/people/s/steffen-eger/>Steffen Eger</a>
|
<a href=/people/r/robert-west/>Robert West</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--179><div class="card-body p-3 small">Evaluation in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> is usually done by comparing the scores of competing systems independently averaged over a common set of test instances. In this work, we question the use of <a href=https://en.wikipedia.org/wiki/Average>averages</a> for aggregating evaluation scores into a final number used to decide which system is best, since the average, as well as alternatives such as the <a href=https://en.wikipedia.org/wiki/Median>median</a>, ignores the pairing arising from the fact that systems are evaluated on the same test instances. We illustrate the importance of taking the instancelevel pairing of evaluation scores into account and demonstrate, both theoretically and empirically, the advantages of aggregation methods based on pairwise comparisons, such as the BradleyTerry (BT) model, a mechanism based on the estimated probability that a given system scores better than another on the test set. By re-evaluating 296 real NLP evaluation setups across four tasks and 18 evaluation metrics, we show that the choice of aggregation mechanism matters and yields different conclusions as to which systems are state of the art in about 30 % of the setups. To facilitate the adoption of pairwise evaluation, we release a practical tool for performing the full analysis of evaluation scores with the mean, median, BT, and two variants of BT (Elo and TrueSkill), alongside functionality for appropriate statistical testing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.309.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--309 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.309 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.309/>Aligning Cross-lingual Sentence Representations with Dual Momentum Contrast</a></strong><br><a href=/people/l/liang-wang/>Liang Wang</a>
|
<a href=/people/w/wei-zhao/>Wei Zhao</a>
|
<a href=/people/j/jingming-liu/>Jingming Liu</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--309><div class="card-body p-3 small">In this paper, we propose to align sentence representations from different languages into a unified embedding space, where semantic similarities (both cross-lingual and monolingual) can be computed with a simple <a href=https://en.wikipedia.org/wiki/Dot_product>dot product</a>. Pre-trained <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> are fine-tuned with the translation ranking task. Existing work (Feng et al., 2020) uses sentences within the same batch as negatives, which can suffer from the issue of easy negatives. We adapt <a href=https://en.wikipedia.org/wiki/Molybdenum_disulfide>MoCo</a> (He et al., 2020) to further improve the quality of <a href=https://en.wikipedia.org/wiki/Sequence_alignment>alignment</a>. As the experimental results show, the sentence representations produced by our model achieve the new state-of-the-art on several tasks, including Tatoeba en-zh similarity search (Artetxe andSchwenk, 2019b), BUCC en-zh bitext mining, and semantic textual similarity on 7 datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.701.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--701 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.701 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.701" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.701/>Global Explainability of BERT-Based Evaluation Metrics by Disentangling along Linguistic Factors<span class=acl-fixed-case>BERT</span>-Based Evaluation Metrics by Disentangling along Linguistic Factors</a></strong><br><a href=/people/m/marvin-kaster/>Marvin Kaster</a>
|
<a href=/people/w/wei-zhao/>Wei Zhao</a>
|
<a href=/people/s/steffen-eger/>Steffen Eger</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--701><div class="card-body p-3 small">Evaluation metrics are a key ingredient for progress of <a href=https://en.wikipedia.org/wiki/Text_generator>text generation systems</a>. In recent years, several BERT-based evaluation metrics have been proposed (including BERTScore, MoverScore, BLEURT, etc.) which correlate much better with human assessment of text generation quality than <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a> or ROUGE, invented two decades ago. However, little is known what these metrics, which are based on black-box language model representations, actually capture (it is typically assumed they model semantic similarity). In this work, we use a simple regression based global explainability technique to disentangle metric scores along linguistic factors, including <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a>, <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a>, <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphology</a>, and lexical overlap. We show that the different <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> capture all aspects to some degree, but that they are all substantially sensitive to <a href=https://en.wikipedia.org/wiki/Lexical_overlap>lexical overlap</a>, just like <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a> and ROUGE. This exposes limitations of these novelly proposed <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a>, which we also highlight in an adversarial test scenario.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.starsem-1.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--starsem-1--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.starsem-1.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.starsem-1.22.OptionalSupplementaryMaterial.pdf data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.starsem-1.22" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.starsem-1.22/>Inducing Language-Agnostic Multilingual Representations</a></strong><br><a href=/people/w/wei-zhao/>Wei Zhao</a>
|
<a href=/people/s/steffen-eger/>Steffen Eger</a>
|
<a href=/people/j/johannes-bjerva/>Johannes Bjerva</a>
|
<a href=/people/i/isabelle-augenstein/>Isabelle Augenstein</a><br><a href=/volumes/2021.starsem-1/ class=text-muted>Proceedings of *SEM 2021: The Tenth Joint Conference on Lexical and Computational Semantics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--starsem-1--22><div class="card-body p-3 small">Cross-lingual representations have the potential to make NLP techniques available to the vast majority of languages in the world. However, they currently require large pretraining corpora or access to typologically similar languages. In this work, we address these obstacles by removing language identity signals from multilingual embeddings. We examine three approaches for this : (i) re-aligning the vector spaces of target languages (all together) to a pivot source language ; (ii) removing language-specific means and variances, which yields better discriminativeness of embeddings as a by-product ; and (iii) increasing input similarity across languages by removing morphological contractions and sentence reordering. We evaluate on XNLI and reference-free MT evaluation across 19 typologically diverse languages. Our findings expose the limitations of these approachesunlike <a href=https://en.wikipedia.org/wiki/Vector_normalization>vector normalization</a>, vector space re-alignment and <a href=https://en.wikipedia.org/wiki/Text_normalization>text normalization</a> do not achieve consistent gains across encoders and languages. Due to the approaches&#8217; additive effects, their combination decreases the cross-lingual transfer gap by 8.9 points (m-BERT) and 18.2 points (XLM-R) on average across all tasks and languages, however.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.eval4nlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.eval4nlp-1.0/>Proceedings of the First Workshop on Evaluation and Comparison of NLP Systems</a></strong><br><a href=/people/s/steffen-eger/>Steffen Eger</a>
|
<a href=/people/y/yang-gao/>Yang Gao</a>
|
<a href=/people/m/maxime-peyrard/>Maxime Peyrard</a>
|
<a href=/people/w/wei-zhao/>Wei Zhao</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a><br><a href=/volumes/2020.eval4nlp-1/ class=text-muted>Proceedings of the First Workshop on Evaluation and Comparison of NLP Systems</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.562.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--562 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.562 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.562/>Regularized Attentive Capsule Network for Overlapped Relation Extraction</a></strong><br><a href=/people/t/tianyi-liu/>Tianyi Liu</a>
|
<a href=/people/x/xiangyu-lin/>Xiangyu Lin</a>
|
<a href=/people/w/weijia-jia/>Weijia Jia</a>
|
<a href=/people/m/mingliang-zhou/>Mingliang Zhou</a>
|
<a href=/people/w/wei-zhao/>Wei Zhao</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--562><div class="card-body p-3 small">Distantly supervised relation extraction has been widely applied in knowledge base construction due to its less requirement of human efforts. However, the automatically established training datasets in distant supervision contain low-quality instances with noisy words and overlapped relations, introducing great challenges to the accurate extraction of relations. To address this problem, we propose a novel Regularized Attentive Capsule Network (RA-CapNet) to better identify highly overlapped relations in each informal sentence. To discover multiple relation features in an instance, we embed multi-head attention into the capsule network as the low-level capsules, where the subtraction of two entities acts as a new form of relation query to select salient features regardless of their positions. To further discriminate overlapped relation features, we devise disagreement regularization to explicitly encourage the diversity among both multiple attention heads and low-level capsules. Extensive experiments conducted on widely used datasets show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves significant improvements in <a href=https://en.wikipedia.org/wiki/Relation_extraction>relation extraction</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1053.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1053 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1053 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1053.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1053" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1053/>MoverScore : Text Generation Evaluating with <a href=https://en.wikipedia.org/wiki/Contextualization>Contextualized Embeddings</a> and <a href=https://en.wikipedia.org/wiki/Earth_mover_distance>Earth Mover Distance</a><span class=acl-fixed-case>M</span>over<span class=acl-fixed-case>S</span>core: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance</a></strong><br><a href=/people/w/wei-zhao/>Wei Zhao</a>
|
<a href=/people/m/maxime-peyrard/>Maxime Peyrard</a>
|
<a href=/people/f/fei-liu-utdallas/>Fei Liu</a>
|
<a href=/people/y/yang-gao/>Yang Gao</a>
|
<a href=/people/c/christian-m-meyer/>Christian M. Meyer</a>
|
<a href=/people/s/steffen-eger/>Steffen Eger</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1053><div class="card-body p-3 small">A robust evaluation metric has a profound impact on the development of text generation systems. A desirable <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> compares system output against references based on their <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> rather than surface forms. In this paper we investigate strategies to encode system and reference texts to devise a <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> that shows a high correlation with human judgment of text quality. We validate our new metric, namely MoverScore, on a number of text generation tasks including <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a>, <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, <a href=https://en.wikipedia.org/wiki/Closed_captioning>image captioning</a>, and data-to-text generation, where the outputs are produced by a variety of neural and non-neural systems. Our findings suggest that <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> combining contextualized representations with a <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>distance measure</a> perform the best. Such <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> also demonstrate strong generalization capability across tasks. For ease-of-use we make our <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> available as <a href=https://en.wikipedia.org/wiki/Web_service>web service</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1014 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/353425373 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-1014" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-1014/>Improving Grammatical Error Correction via Pre-Training a Copy-Augmented Architecture with Unlabeled Data</a></strong><br><a href=/people/w/wei-zhao/>Wei Zhao</a>
|
<a href=/people/l/liang-wang/>Liang Wang</a>
|
<a href=/people/k/kewei-shen/>Kewei Shen</a>
|
<a href=/people/r/ruoyu-jia/>Ruoyu Jia</a>
|
<a href=/people/j/jingming-liu/>Jingming Liu</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1014><div class="card-body p-3 small">Neural machine translation systems have become state-of-the-art approaches for Grammatical Error Correction (GEC) task. In this paper, we propose a copy-augmented architecture for the GEC task by copying the unchanged words from the source sentence to the target sentence. Since the GEC suffers from not having enough labeled training data to achieve high <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. We pre-train the copy-augmented architecture with a denoising auto-encoder using the unlabeled One Billion Benchmark and make comparisons between the fully pre-trained model and a partially pre-trained model. It is the first time copying words from the source context and fully pre-training a sequence to sequence model are experimented on the GEC task. Moreover, We add token-level and sentence-level multi-task learning for the GEC task. The evaluation results on the CoNLL-2014 test set show that our approach outperforms all recently published state-of-the-art results by a large margin.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1350.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1350 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1350 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/305947408 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1350" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1350/>Investigating Capsule Networks with <a href=https://en.wikipedia.org/wiki/Dynamic_routing>Dynamic Routing</a> for Text Classification</a></strong><br><a href=/people/w/wei-zhao/>Wei Zhao</a>
|
<a href=/people/j/jianbo-ye/>Jianbo Ye</a>
|
<a href=/people/m/min-yang/>Min Yang</a>
|
<a href=/people/z/zeyang-lei/>Zeyang Lei</a>
|
<a href=/people/s/suofei-zhang/>Suofei Zhang</a>
|
<a href=/people/z/zhou-zhao/>Zhou Zhao</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1350><div class="card-body p-3 small">In this study, we explore capsule networks with <a href=https://en.wikipedia.org/wiki/Dynamic_routing>dynamic routing</a> for <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a>. We propose three strategies to stabilize the dynamic routing process to alleviate the disturbance of some noise capsules which may contain background information or have not been successfully trained. A series of experiments are conducted with capsule networks on six text classification benchmarks. Capsule networks achieve state of the art on 4 out of 6 datasets, which shows the effectiveness of capsule networks for <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a>. We additionally show that capsule networks exhibit significant improvement when transfer single-label to multi-label text classification over strong baseline methods. To the best of our knowledge, this is the first work that capsule networks have been empirically investigated for text modeling.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1120.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1120 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1120 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=S18-1120" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/S18-1120/>Yuanfudao at SemEval-2018 Task 11 : Three-way Attention and Relational Knowledge for Commonsense Machine Comprehension<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 11: Three-way Attention and Relational Knowledge for Commonsense Machine Comprehension</a></strong><br><a href=/people/l/liang-wang/>Liang Wang</a>
|
<a href=/people/m/meng-sun/>Meng Sun</a>
|
<a href=/people/w/wei-zhao/>Wei Zhao</a>
|
<a href=/people/k/kewei-shen/>Kewei Shen</a>
|
<a href=/people/j/jingming-liu/>Jingming Liu</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1120><div class="card-body p-3 small">This paper describes our <a href=https://en.wikipedia.org/wiki/System>system</a> for SemEval-2018 Task 11 : <a href=https://en.wikipedia.org/wiki/Machine_learning>Machine Comprehension</a> using Commonsense Knowledge. We use Three-way Attentive Networks (TriAN) to model interactions between the passage, question and answers. To incorporate <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a>, we augment the input with relation embedding from the graph of general knowledge ConceptNet. As a result, our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves state-of-the-art performance with 83.95 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on the official test data. Code is publicly available at.<url>https://github.com/intfloat/commonsense-rc</url>.\n</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1055.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1055 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1055 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1055/>Identifying and Tracking Sentiments and Topics from Social Media Texts during Natural Disasters</a></strong><br><a href=/people/m/min-yang/>Min Yang</a>
|
<a href=/people/j/jincheng-mei/>Jincheng Mei</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/w/wei-zhao/>Wei Zhao</a>
|
<a href=/people/z/zhou-zhao/>Zhou Zhao</a>
|
<a href=/people/x/xiaojun-chen/>Xiaojun Chen</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1055><div class="card-body p-3 small">We study the problem of identifying the topics and sentiments and tracking their shifts from social media texts in different geographical regions during emergencies and disasters. We propose a location-based dynamic sentiment-topic model (LDST) which can jointly model topic, sentiment, time and Geolocation information. The experimental results demonstrate that LDST performs very well at discovering topics and sentiments from <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> and tracking their shifts in different geographical regions during emergencies and disasters. We will release the data and source code after this work is published.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Wei+Zhao" title="Search for 'Wei Zhao' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/s/steffen-eger/ class=align-middle>Steffen Eger</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/y/yang-gao/ class=align-middle>Yang Gao</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/maxime-peyrard/ class=align-middle>Maxime Peyrard</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/l/liang-wang/ class=align-middle>Liang Wang</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/j/jingming-liu/ class=align-middle>Jingming Liu</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/m/min-yang/ class=align-middle>Min Yang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/zhou-zhao/ class=align-middle>Zhou Zhao</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/kewei-shen/ class=align-middle>Kewei Shen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/piyawat-lertvittayakumjorn/ class=align-middle>Piyawat Lertvittayakumjorn</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marina-fomicheva/ class=align-middle>Marina Fomicheva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/robert-west/ class=align-middle>Robert West</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eduard-hovy/ class=align-middle>Eduard Hovy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jianbo-ye/ class=align-middle>Jianbo Ye</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zeyang-lei/ class=align-middle>Zeyang Lei</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/suofei-zhang/ class=align-middle>Suofei Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marvin-kaster/ class=align-middle>Marvin Kaster</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fei-liu-utdallas/ class=align-middle>Fei Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christian-m-meyer/ class=align-middle>Christian M. Meyer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jincheng-mei/ class=align-middle>Jincheng Mei</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/heng-ji/ class=align-middle>Heng Ji</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaojun-chen/ class=align-middle>Xiaojun Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/johannes-bjerva/ class=align-middle>Johannes Bjerva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/isabelle-augenstein/ class=align-middle>Isabelle Augenstein</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/meng-sun/ class=align-middle>Meng Sun</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tianyi-liu/ class=align-middle>Tianyi Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiangyu-lin/ class=align-middle>Xiangyu Lin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/weijia-jia/ class=align-middle>Weijia Jia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mingliang-zhou/ class=align-middle>Mingliang Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ruoyu-jia/ class=align-middle>Ruoyu Jia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/eval4nlp/ class=align-middle>Eval4NLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/starsem/ class=align-middle>*SEM</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>