<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Mohit Iyyer - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Mohit</span> <span class=font-weight-bold>Iyyer</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-long.349.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-long--349 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-long.349 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-long.349" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-long.349/>Energy-Based Reranking : Improving Neural Machine Translation Using Energy-Based Models</a></strong><br><a href=/people/s/sumanta-bhattacharyya/>Sumanta Bhattacharyya</a>
|
<a href=/people/a/amirmohammad-rooshenas/>Amirmohammad Rooshenas</a>
|
<a href=/people/s/subhajit-naskar/>Subhajit Naskar</a>
|
<a href=/people/s/simeng-sun/>Simeng Sun</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a><br><a href=/volumes/2021.acl-long/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-long--349><div class="card-body p-3 small">The discrepancy between <a href=https://en.wikipedia.org/wiki/Maximum_likelihood_estimation>maximum likelihood estimation (MLE)</a> and task measures such as BLEU score has been studied before for autoregressive neural machine translation (NMT) and resulted in alternative training algorithms (Ranzato et al., 2016 ; Norouzi et al., 2016 ; Shen et al., 2016 ; Wu et al., 2018). However, MLE training remains the de facto approach for autoregressive NMT because of its computational efficiency and <a href=https://en.wikipedia.org/wiki/Stability_theory>stability</a>. Despite this mismatch between the training objective and task measure, we notice that the samples drawn from an MLE-based trained NMT support the desired distribution there are samples with much higher BLEU score comparing to the beam decoding output. To benefit from this observation, we train an energy-based model to mimic the behavior of the task measure (i.e., the energy-based model assigns lower energy to samples with higher BLEU score), which is resulted in a <a href=https://en.wikipedia.org/wiki/Ranking_(statistics)>re-ranking algorithm</a> based on the samples drawn from NMT : energy-based re-ranking (EBR). We use both marginal energy models (over target sentence) and joint energy models (over both source and target sentences). Our EBR with the joint energy model consistently improves the performance of the Transformer-based NMT : +3.7 BLEU points on IWSLT&#8217;14 German-English, +3.37 BELU points on Sinhala-English, +1.4 BLEU points on WMT&#8217;16 English-German tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.nuse-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.nuse-1.0/>Proceedings of the Third Workshop on Narrative Understanding</a></strong><br><a href=/people/n/nader-akoury/>Nader Akoury</a>
|
<a href=/people/f/faeze-brahman/>Faeze Brahman</a>
|
<a href=/people/s/snigdha-chaturvedi/>Snigdha Chaturvedi</a>
|
<a href=/people/e/elizabeth-clark/>Elizabeth Clark</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/l/lara-j-martin/>Lara J. Martin</a><br><a href=/volumes/2021.nuse-1/ class=text-muted>Proceedings of the Third Workshop on Narrative Understanding</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.62.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--62 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.62 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.62/>Do Long-Range Language Models Actually Use Long-Range Context?</a></strong><br><a href=/people/s/simeng-sun/>Simeng Sun</a>
|
<a href=/people/k/kalpesh-krishna/>Kalpesh Krishna</a>
|
<a href=/people/a/andrew-mattarella-micke/>Andrew Mattarella-Micke</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--62><div class="card-body p-3 small">Language models are generally trained on short, truncated input sequences, which limits their ability to use discourse-level information present in long-range context to improve their predictions. Recent efforts to improve the efficiency of self-attention have led to a proliferation of long-range Transformer language models, which can process much longer sequences than <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> of the past. However, the ways in which such <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> take advantage of the long-range context remain unclear. In this paper, we perform a fine-grained analysis of two long-range Transformer language models (including the Routing Transformer, which achieves state-of-the-art perplexity on the PG-19 long-sequence LM benchmark dataset) that accept input sequences of up to 8 K tokens. Our results reveal that providing long-range context (i.e., beyond the previous 2 K tokens) to these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> only improves their predictions on a small set of tokens (e.g., those that can be copied from the distant context) and does not help at all for sentence-level prediction tasks. Finally, we discover that PG-19 contains a variety of different document types and domains, and that long-range context helps most for literary novels (as opposed to <a href=https://en.wikipedia.org/wiki/Textbook>textbooks</a> or magazines).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.97.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--97 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.97 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.97/>The Perils of Using <a href=https://en.wikipedia.org/wiki/Mechanical_Turk>Mechanical Turk</a> to Evaluate Open-Ended Text Generation<span class=acl-fixed-case>M</span>echanical <span class=acl-fixed-case>T</span>urk to Evaluate Open-Ended Text Generation</a></strong><br><a href=/people/m/marzena-karpinska/>Marzena Karpinska</a>
|
<a href=/people/n/nader-akoury/>Nader Akoury</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--97><div class="card-body p-3 small">Recent text generation research has increasingly focused on open-ended domains such as story and poetry generation. Because models built for such tasks are difficult to evaluate automatically, most researchers in the space justify their modeling choices by collecting crowdsourced human judgments of text quality (e.g., Likert scores of coherence or grammaticality) from Amazon Mechanical Turk (AMT). In this paper, we first conduct a survey of 45 open-ended text generation papers and find that the vast majority of them fail to report crucial details about their AMT tasks, hindering reproducibility. We then run a series of story evaluation experiments with both AMT workers and English teachers and discover that even with strict qualification filters, AMT workers (unlike teachers) fail to distinguish between model-generated text and human-generated references. We show that AMT worker judgments improve when they are shown model-generated output alongside human-generated references, which enables the workers to better calibrate their ratings. Finally, interviews with the <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>English teachers</a> provide deeper insights into the challenges of the evaluation process, particularly when rating model-generated text.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.395.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--395 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.395 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.395" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.395/>Improved Latent Tree Induction with Distant Supervision via Span Constraints</a></strong><br><a href=/people/z/zhiyang-xu/>Zhiyang Xu</a>
|
<a href=/people/a/andrew-drozdov/>Andrew Drozdov</a>
|
<a href=/people/j/jay-yoon-lee/>Jay Yoon Lee</a>
|
<a href=/people/t/tim-ogorman/>Tim O’Gorman</a>
|
<a href=/people/s/subendhu-rongali/>Subendhu Rongali</a>
|
<a href=/people/d/dylan-finkbeiner/>Dylan Finkbeiner</a>
|
<a href=/people/s/shilpa-suresh/>Shilpa Suresh</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--395><div class="card-body p-3 small">For over thirty years, researchers have developed and analyzed <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> for latent tree induction as an approach for unsupervised syntactic parsing. Nonetheless, modern <a href=https://en.wikipedia.org/wiki/System>systems</a> still do not perform well enough compared to their supervised counterparts to have any practical use as structural annotation of text. In this work, we present a technique that uses distant supervision in the form of <a href=https://en.wikipedia.org/wiki/Constraint_(mathematics)>span constraints</a> (i.e. phrase bracketing) to improve performance in unsupervised constituency parsing. Using a relatively small number of span constraints we can substantially improve the output from DIORA, an already competitive unsupervised parsing system. Compared with full parse tree annotation, span constraints can be acquired with minimal effort, such as with a lexicon derived from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, to find exact text matches. Our experiments show span constraints based on entities improves constituency parsing on English WSJ Penn Treebank by more than 5 F1. Furthermore, our method extends to any domain where span constraints are easily attainable, and as a case study we demonstrate its effectiveness by parsing biomedical text from the CRAFT dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.270.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--270 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.270 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.270" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.270/>TABBIE : Pretrained Representations of Tabular Data<span class=acl-fixed-case>TABBIE</span>: Pretrained Representations of Tabular Data</a></strong><br><a href=/people/h/hiroshi-iida/>Hiroshi Iida</a>
|
<a href=/people/d/dung-thai/>Dung Thai</a>
|
<a href=/people/v/varun-manjunatha/>Varun Manjunatha</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--270><div class="card-body p-3 small">Existing work on tabular representation-learning jointly models tables and associated text using self-supervised objective functions derived from pretrained language models such as BERT. While this joint pretraining improves <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> involving paired tables and text (e.g., answering questions about tables), we show that it underperforms on <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> that operate over tables without any associated text (e.g., populating missing cells). We devise a simple pretraining objective (corrupt cell detection) that learns exclusively from tabular data and reaches the state-of-the-art on a suite of table-based prediction tasks. Unlike competing approaches, our model (TABBIE) provides embeddings of all table substructures (cells, rows, and columns), and it also requires far less compute to train. A qualitative analysis of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s learned cell, column, and row representations shows that it understands complex table semantics and numerical trends.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.393.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--393 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.393 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.393.OptionalSupplementaryData.zip data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.393" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.393/>Hurdles to Progress in Long-form Question Answering</a></strong><br><a href=/people/k/kalpesh-krishna/>Kalpesh Krishna</a>
|
<a href=/people/a/aurko-roy/>Aurko Roy</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--393><div class="card-body p-3 small">The task of long-form question answering (LFQA) involves retrieving documents relevant to a given question and using them to generate a paragraph-length answer. While many models have recently been proposed for LFQA, we show in this paper that the task formulation raises fundamental challenges regarding evaluation and dataset creation that currently preclude meaningful modeling progress. To demonstrate these challenges, we first design a new system that relies on sparse attention and contrastive retriever learning to achieve state-of-the-art performance on the ELI5 LFQA dataset. While our system tops the public leaderboard, a detailed analysis reveals several troubling trends : (1) our system&#8217;s generated answers are not actually grounded in the documents that it retrieves ; (2) ELI5 contains significant train / validation overlap, as at least 81 % of ELI5 validation questions occur in paraphrased form in the training set ; (3) ROUGE-L is not an informative metric of generated answer quality and can be easily gamed ; and (4) human evaluations used for other text generation tasks are unreliable for LFQA. We offer suggestions to mitigate each of these issues, which we hope will lead to more rigorous LFQA research and meaningful progress in the future.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dialdoc-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.dialdoc-1.0/>Proceedings of the 1st Workshop on Document-grounded Dialogue and Conversational Question Answering (DialDoc 2021)</a></strong><br><a href=/people/s/song-feng/>Song Feng</a>
|
<a href=/people/s/siva-reddy/>Siva Reddy</a>
|
<a href=/people/m/malihe-alikhani/>Malihe Alikhani</a>
|
<a href=/people/h/he-he/>He He</a>
|
<a href=/people/y/yangfeng-ji/>Yangfeng Ji</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/z/zhou-yu/>Zhou Yu</a><br><a href=/volumes/2021.dialdoc-1/ class=text-muted>Proceedings of the 1st Workshop on Document-grounded Dialogue and Conversational Question Answering (DialDoc 2021)</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nuse-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nuse-1.0/>Proceedings of the First Joint Workshop on Narrative Understanding, Storylines, and Events</a></strong><br><a href=/people/c/claire-bonial/>Claire Bonial</a>
|
<a href=/people/t/tommaso-caselli/>Tommaso Caselli</a>
|
<a href=/people/s/snigdha-chaturvedi/>Snigdha Chaturvedi</a>
|
<a href=/people/e/elizabeth-clark/>Elizabeth Clark</a>
|
<a href=/people/r/ruihong-huang/>Ruihong Huang</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/a/alejandro-jaimes/>Alejandro Jaimes</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/l/lara-j-martin/>Lara J. Martin</a>
|
<a href=/people/b/ben-miller/>Ben Miller</a>
|
<a href=/people/t/teruko-mitamura/>Teruko Mitamura</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/j/joel-tetreault/>Joel Tetreault</a><br><a href=/volumes/2020.nuse-1/ class=text-muted>Proceedings of the First Joint Workshop on Narrative Understanding, Storylines, and Events</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.392.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--392 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.392 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939296 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.392/>Unsupervised Parsing with S-DIORA : Single Tree Encoding for Deep Inside-Outside Recursive Autoencoders<span class=acl-fixed-case>S</span>-<span class=acl-fixed-case>DIORA</span>: Single Tree Encoding for Deep Inside-Outside Recursive Autoencoders</a></strong><br><a href=/people/a/andrew-drozdov/>Andrew Drozdov</a>
|
<a href=/people/s/subendhu-rongali/>Subendhu Rongali</a>
|
<a href=/people/y/yi-pei-chen/>Yi-Pei Chen</a>
|
<a href=/people/t/tim-ogorman/>Tim O’Gorman</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--392><div class="card-body p-3 small">The deep inside-outside recursive autoencoder (DIORA ; Drozdov et al. 2019) is a self-supervised neural model that learns to induce syntactic tree structures for input sentences * without access to labeled training data *. In this paper, we discover that while DIORA exhaustively encodes all possible binary trees of a sentence with a soft dynamic program, its vector averaging approach is locally greedy and can not recover from errors when computing the highest scoring parse tree in bottom-up chart parsing. To fix this issue, we introduce S-DIORA, an improved variant of DIORA that encodes a single tree rather than a softly-weighted mixture of trees by employing a hard argmax operation and a beam at each cell in the chart. Our experiments show that through * fine-tuning * a pre-trained DIORA with our new <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a>, we improve the state of the art in * unsupervised * constituency parsing on the English WSJ Penn Treebank by 2.2-6 % F1, depending on the data used for <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.635.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--635 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.635 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939047 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.635" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.635/>Exploring and Predicting Transferability across NLP Tasks<span class=acl-fixed-case>NLP</span> Tasks</a></strong><br><a href=/people/t/tu-vu/>Tu Vu</a>
|
<a href=/people/t/tong-wang/>Tong Wang</a>
|
<a href=/people/t/tsendsuren-munkhdalai/>Tsendsuren Munkhdalai</a>
|
<a href=/people/a/alessandro-sordoni/>Alessandro Sordoni</a>
|
<a href=/people/a/adam-trischler/>Adam Trischler</a>
|
<a href=/people/a/andrew-mattarella-micke/>Andrew Mattarella-Micke</a>
|
<a href=/people/s/subhransu-maji/>Subhransu Maji</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--635><div class="card-body p-3 small">Recent advances in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> demonstrate the effectiveness of training large-scale language models and transferring them to downstream tasks. Can fine-tuning these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> other than <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a> further improve performance? In this paper, we conduct an extensive study of the transferability between 33 NLP tasks across three broad classes of problems (text classification, <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>, and sequence labeling). Our results show that <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> is more beneficial than previously thought, especially when target task data is scarce, and can improve performance even with low-data source tasks that differ substantially from the target task (e.g., <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a> transfers well to the DROP QA dataset). We also develop task embeddings that can be used to predict the most transferable source tasks for a given target task, and we validate their effectiveness in experiments controlled for source and target data size. Overall, our experiments reveal that factors such as data size, task and domain similarity, and task complexity all play a role in determining transferability.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1161.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1161 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1161 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1161.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D19-1161/>Unsupervised Labeled Parsing with Deep Inside-Outside Recursive Autoencoders</a></strong><br><a href=/people/a/andrew-drozdov/>Andrew Drozdov</a>
|
<a href=/people/p/patrick-verga/>Patrick Verga</a>
|
<a href=/people/y/yi-pei-chen/>Yi-Pei Chen</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1161><div class="card-body p-3 small">Understanding text often requires identifying meaningful <a href=https://en.wikipedia.org/wiki/Constituent_(linguistics)>constituent spans</a> such as <a href=https://en.wikipedia.org/wiki/Noun_phrase>noun phrases</a> and <a href=https://en.wikipedia.org/wiki/Verb_phrase>verb phrases</a>. In this work, we show that we can effectively recover these types of labels using the learned phrase vectors from deep inside-outside recursive autoencoders (DIORA). Specifically, we cluster span representations to induce span labels. Additionally, we improve the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>&#8217;s labeling accuracy by integrating latent code learning into the training procedure. We evaluate this approach empirically through unsupervised labeled constituency parsing. Our method outperforms ELMo and BERT on two versions of the Wall Street Journal (WSJ) dataset and is competitive to prior work that requires additional human annotations, improving over a previous state-of-the-art system that depends on ground-truth part-of-speech tags by 5 absolute F1 points (19 % relative error reduction).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1666.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1666 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1666 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1666.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1666" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1666/>Investigating Sports Commentator Bias within a Large Corpus of American Football Broadcasts<span class=acl-fixed-case>A</span>merican Football Broadcasts</a></strong><br><a href=/people/j/jack-merullo/>Jack Merullo</a>
|
<a href=/people/l/luke-yeh/>Luke Yeh</a>
|
<a href=/people/a/abram-handler/>Abram Handler</a>
|
<a href=/people/a/alvin-grissom-ii/>Alvin Grissom II</a>
|
<a href=/people/b/brendan-oconnor/>Brendan O’Connor</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1666><div class="card-body p-3 small">Sports broadcasters inject drama into <a href=https://en.wikipedia.org/wiki/Sports_commentator>play-by-play commentary</a> by building team and player narratives through <a href=https://en.wikipedia.org/wiki/Subjectivity>subjective analyses</a> and <a href=https://en.wikipedia.org/wiki/Anecdote>anecdotes</a>. Prior studies based on <a href=https://en.wikipedia.org/wiki/Small_data>small datasets</a> and manual coding show that such theatrics evince commentator bias in <a href=https://en.wikipedia.org/wiki/Broadcasting_of_sports_events>sports broadcasts</a>. To examine this phenomenon, we assemble <a href=https://en.wikipedia.org/wiki/American_football>FOOTBALL</a>, which contains 1,455 broadcast transcripts from American football games across six decades that are automatically annotated with 250 K player mentions and linked with <a href=https://en.wikipedia.org/wiki/Race_(human_categorization)>racial metadata</a>. We identify major confounding factors for researchers examining racial bias in FOOTBALL, and perform a computational analysis that supports conclusions from prior social science studies.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2400.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2400/>Proceedings of the First Workshop on Narrative Understanding</a></strong><br><a href=/people/d/david-bamman/>David Bamman</a>
|
<a href=/people/s/snigdha-chaturvedi/>Snigdha Chaturvedi</a>
|
<a href=/people/e/elizabeth-clark/>Elizabeth Clark</a>
|
<a href=/people/m/madalina-fiterau/>Madalina Fiterau</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a><br><a href=/volumes/W19-24/ class=text-muted>Proceedings of the First Workshop on Narrative Understanding</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1116.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1116 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1116 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-1116/>Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Auto-Encoders</a></strong><br><a href=/people/a/andrew-drozdov/>Andrew Drozdov</a>
|
<a href=/people/p/patrick-verga/>Patrick Verga</a>
|
<a href=/people/m/mohit-yadav/>Mohit Yadav</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1116><div class="card-body p-3 small">We introduce the deep inside-outside recursive autoencoder (DIORA), a fully-unsupervised method for discovering <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> that simultaneously learns representations for constituents within the induced tree. Our approach predicts each word in an input sentence conditioned on the rest of the sentence. During training we use <a href=https://en.wikipedia.org/wiki/Dynamic_programming>dynamic programming</a> to consider all possible binary trees over the sentence, and for <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference</a> we use the <a href=https://en.wikipedia.org/wiki/CKY_algorithm>CKY algorithm</a> to extract the highest scoring parse. DIORA outperforms previously reported results for unsupervised binary constituency parsing on the benchmark WSJ dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1130.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1130 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1130 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-1130/>Casting Light on Invisible Cities : Computationally Engaging with Literary Criticism<span class=acl-fixed-case>C</span>asting <span class=acl-fixed-case>L</span>ight on <span class=acl-fixed-case>I</span>nvisible <span class=acl-fixed-case>C</span>ities: <span class=acl-fixed-case>C</span>omputationally <span class=acl-fixed-case>E</span>ngaging with <span class=acl-fixed-case>L</span>iterary <span class=acl-fixed-case>C</span>riticism</a></strong><br><a href=/people/s/shufan-wang/>Shufan Wang</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1130><div class="card-body p-3 small">Literary critics often attempt to uncover meaning in a single work of literature through careful reading and analysis. Applying <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing methods</a> to aid in such <a href=https://en.wikipedia.org/wiki/Literary_criticism>literary analyses</a> remains a challenge in <a href=https://en.wikipedia.org/wiki/Digital_humanities>digital humanities</a>. While most previous work focuses on distant reading by algorithmically discovering high-level patterns from large collections of literary works, here we sharpen the focus of our methods to a single <a href=https://en.wikipedia.org/wiki/Literary_theory>literary theory</a> about Italo Calvino&#8217;s postmodern novel Invisible Cities, which consists of 55 short descriptions of imaginary cities. Calvino has provided a classification of these <a href=https://en.wikipedia.org/wiki/City>cities</a> into eleven thematic groups, but literary scholars disagree as to how trustworthy his categorization is. Due to the unique structure of this novel, we can computationally weigh in on this debate : we leverage pretrained contextualized representations to embed each city&#8217;s description and use <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised methods</a> to cluster these embeddings. Additionally, we compare results of our <a href=https://en.wikipedia.org/wiki/Computational_model>computational approach</a> to similarity judgments generated by <a href=https://en.wikipedia.org/wiki/User_(computing)>human readers</a>. Our work is a first step towards incorporating <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> into <a href=https://en.wikipedia.org/wiki/Literary_criticism>literary criticism</a>.<i>Invisible Cities</i>, which consists of 55 short descriptions of imaginary cities. Calvino has provided a classification of these cities into eleven thematic groups, but literary scholars disagree as to how trustworthy his categorization is. Due to the unique structure of this novel, we can computationally weigh in on this debate: we leverage pretrained contextualized representations to embed each city&#8217;s description and use unsupervised methods to cluster these embeddings. Additionally, we compare results of our computational approach to similarity judgments generated by human readers. Our work is a first step towards incorporating natural language processing into literary criticism.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1122.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1122 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1122 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1122.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1122" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1122/>Syntactically Supervised Transformers for Faster Neural Machine Translation</a></strong><br><a href=/people/n/nader-akoury/>Nader Akoury</a>
|
<a href=/people/k/kalpesh-krishna/>Kalpesh Krishna</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1122><div class="card-body p-3 small">Standard decoders for <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation autoregressively</a> generate a single target token per timestep, which slows <a href=https://en.wikipedia.org/wiki/Inference>inference</a> especially for long outputs. While architectural advances such as the Transformer fully parallelize the decoder computations at training time, <a href=https://en.wikipedia.org/wiki/Inference>inference</a> still proceeds sequentially. Recent developments in non- and semi-autoregressive decoding produce multiple tokens per timestep independently of the others, which improves inference speed but deteriorates translation quality. In this work, we propose the syntactically supervised Transformer (SynST), which first autoregressively predicts a chunked parse tree before generating all of the target tokens in one shot conditioned on the predicted parse. A series of controlled experiments demonstrates that SynST decodes sentences ~5x faster than the baseline autoregressive Transformer while achieving higher BLEU scores than most competing methods on En-De and En-Fr datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1224.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1224 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1224 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1224.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1224.Note.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1224" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1224/>Generating Question-Answer Hierarchies</a></strong><br><a href=/people/k/kalpesh-krishna/>Kalpesh Krishna</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1224><div class="card-body p-3 small">The process of <a href=https://en.wikipedia.org/wiki/Knowledge_acquisition>knowledge acquisition</a> can be viewed as a question-answer game between a student and a teacher in which the student typically starts by asking broad, open-ended questions before drilling down into specifics (Hintikka, 1981 ; Hakkarainen and Sintonen, 2002). This pedagogical perspective motivates a new way of representing documents. In this paper, we present SQUASH (Specificity-controlled Question-Answer Hierarchies), a novel and challenging text generation task that converts an input document into a hierarchy of question-answer pairs. Users can click on high-level questions (e.g., Why did Frodo leave the Fellowship?) to reveal related but more specific questions (e.g., Who did Frodo leave with?). Using a question taxonomy loosely based on Lehnert (1978), we classify questions in existing reading comprehension datasets as either GENERAL or SPECIFIC. We then use these labels as input to a <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipelined system</a> centered around a conditional neural language model. We extensively evaluate the quality of the generated QA hierarchies through crowdsourced experiments and report strong empirical results.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1505.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1505 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1505 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D18-1505.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/306136412 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1505" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1505/>Revisiting the Importance of Encoding Logic Rules in Sentiment Classification</a></strong><br><a href=/people/k/kalpesh-krishna/>Kalpesh Krishna</a>
|
<a href=/people/p/preethi-jyothi/>Preethi Jyothi</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1505><div class="card-body p-3 small">We analyze the performance of different sentiment classification models on syntactically complex inputs like <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>A-but-B sentences</a>. The first contribution of this analysis addresses reproducible research : to meaningfully compare different <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, their accuracies must be averaged over far more random seeds than what has traditionally been reported. With proper averaging in place, we notice that the distillation model described in Hu et al. (2016), which incorporates explicit logic rules for sentiment classification, is ineffective. In contrast, using contextualized ELMo embeddings (Peters et al., 2018a) instead of logic rules yields significantly better performance. Additionally, we provide analysis and visualizations that demonstrate ELMo&#8217;s ability to implicitly learn <a href=https://en.wikipedia.org/wiki/Rule_of_inference>logic rules</a>. Finally, a <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourced analysis</a> reveals how ELMo outperforms baseline models even on sentences with ambiguous sentiment labels.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1170.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1170 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1170 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277673796 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1170" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1170/>Adversarial Example Generation with Syntactically Controlled Paraphrase Networks</a></strong><br><a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/j/john-wieting/>John Wieting</a>
|
<a href=/people/k/kevin-gimpel/>Kevin Gimpel</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1170><div class="card-body p-3 small">We propose syntactically controlled paraphrase networks (SCPNs) and use them to generate adversarial examples. Given a sentence and a target <a href=https://en.wikipedia.org/wiki/Syntax_(programming_languages)>syntactic form</a> (e.g., a <a href=https://en.wikipedia.org/wiki/Constituent_(linguistics)>constituency parse</a>), SCPNs are trained to produce a <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrase</a> of the sentence with the desired <a href=https://en.wikipedia.org/wiki/Syntax_(programming_languages)>syntax</a>. We show it is possible to create <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data</a> for this task by first doing backtranslation at a very large scale, and then using a <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> to label the syntactic transformations that naturally occur during this process. Such data allows us to train a neural encoder-decoder model with extra inputs to specify the target syntax. A combination of automated and human evaluations show that SCPNs generate <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrases</a> that follow their target specifications without decreasing paraphrase quality when compared to baseline (uncontrolled) paraphrase systems. Furthermore, they are more capable of generating syntactically adversarial examples that both (1) fool pretrained models and (2) improve the robustness of these models to syntactic variation when used to augment their training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2120.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-2120 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-2120 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-2120" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-2120/>Learning to Color from Language</a></strong><br><a href=/people/v/varun-manjunatha/>Varun Manjunatha</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/j/jordan-boyd-graber/>Jordan Boyd-Graber</a>
|
<a href=/people/l/larry-davis/>Larry Davis</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-2120><div class="card-body p-3 small">Automatic colorization is the process of adding <a href=https://en.wikipedia.org/wiki/Color>color</a> to <a href=https://en.wikipedia.org/wiki/Grayscale>greyscale images</a>. We condition this <a href=https://en.wikipedia.org/wiki/Process_(computing)>process</a> on <a href=https://en.wikipedia.org/wiki/Language>language</a>, allowing end users to manipulate a colorized image by feeding in different captions. We present two different architectures for language-conditioned colorization, both of which produce more accurate and plausible colorizations than a language-agnostic version. Furthermore, we demonstrate through crowdsourced experiments that we can dramatically alter <a href=https://en.wikipedia.org/wiki/Colorization>colorizations</a> simply by manipulating descriptive color words in captions.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1167.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1167 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1167 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-1167.Presentation.pptx data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1167/>Search-based Neural Structured Learning for Sequential Question Answering</a></strong><br><a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/w/wen-tau-yih/>Wen-tau Yih</a>
|
<a href=/people/m/ming-wei-chang/>Ming-Wei Chang</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1167><div class="card-body p-3 small">Recent work in <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> for <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> has focused on long and complicated questions, many of which would seem unnatural if asked in a normal conversation between two humans. In an effort to explore a conversational QA setting, we present a more realistic task : answering sequences of simple but inter-related questions. We collect a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 6,066 question sequences that inquire about <a href=https://en.wikipedia.org/wiki/Semi-structured_model>semi-structured tables</a> from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, with 17,553 question-answer pairs in total. To solve this sequential question answering task, we propose a novel dynamic neural semantic parsing framework trained using a weakly supervised reward-guided search. Our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> effectively leverages the sequential context to outperform state-of-the-art QA systems that are designed to answer highly complex questions.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Mohit+Iyyer" title="Search for 'Mohit Iyyer' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/a/andrew-mccallum/ class=align-middle>Andrew McCallum</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/k/kalpesh-krishna/ class=align-middle>Kalpesh Krishna</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/a/andrew-drozdov/ class=align-middle>Andrew Drozdov</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/n/nader-akoury/ class=align-middle>Nader Akoury</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/snigdha-chaturvedi/ class=align-middle>Snigdha Chaturvedi</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/e/elizabeth-clark/ class=align-middle>Elizabeth Clark</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/simeng-sun/ class=align-middle>Simeng Sun</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/l/lara-j-martin/ class=align-middle>Lara J. Martin</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/subendhu-rongali/ class=align-middle>Subendhu Rongali</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/yi-pei-chen/ class=align-middle>Yi-Pei Chen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/tim-ogorman/ class=align-middle>Tim O’Gorman</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/andrew-mattarella-micke/ class=align-middle>Andrew Mattarella-Micke</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/patrick-verga/ class=align-middle>Patrick Verga</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/v/varun-manjunatha/ class=align-middle>Varun Manjunatha</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sumanta-bhattacharyya/ class=align-middle>Sumanta Bhattacharyya</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/amirmohammad-rooshenas/ class=align-middle>Amirmohammad Rooshenas</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/subhajit-naskar/ class=align-middle>Subhajit Naskar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/faeze-brahman/ class=align-middle>Faeze Brahman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/claire-bonial/ class=align-middle>Claire Bonial</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tommaso-caselli/ class=align-middle>Tommaso Caselli</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ruihong-huang/ class=align-middle>Ruihong Huang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alejandro-jaimes/ class=align-middle>Alejandro Jaimes</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/heng-ji/ class=align-middle>Heng Ji</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/ben-miller/ class=align-middle>Ben Miller</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/teruko-mitamura/ class=align-middle>Teruko Mitamura</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nanyun-peng/ class=align-middle>Nanyun Peng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/joel-tetreault/ class=align-middle>Joel Tetreault</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tu-vu/ class=align-middle>Tu Vu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tong-wang/ class=align-middle>Tong Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tsendsuren-munkhdalai/ class=align-middle>Tsendsuren Munkhdalai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alessandro-sordoni/ class=align-middle>Alessandro Sordoni</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/adam-trischler/ class=align-middle>Adam Trischler</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/subhransu-maji/ class=align-middle>Subhransu Maji</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wen-tau-yih/ class=align-middle>Wen-tau Yih</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/ming-wei-chang/ class=align-middle>Ming-Wei Chang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/preethi-jyothi/ class=align-middle>Preethi Jyothi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marzena-karpinska/ class=align-middle>Marzena Karpinska</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhiyang-xu/ class=align-middle>Zhiyang Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jay-yoon-lee/ class=align-middle>Jay Yoon Lee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dylan-finkbeiner/ class=align-middle>Dylan Finkbeiner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shilpa-suresh/ class=align-middle>Shilpa Suresh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jack-merullo/ class=align-middle>Jack Merullo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luke-yeh/ class=align-middle>Luke Yeh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/abram-handler/ class=align-middle>Abram Handler</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alvin-grissom-ii/ class=align-middle>Alvin Grissom II</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/brendan-oconnor/ class=align-middle>Brendan O’Connor</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hiroshi-iida/ class=align-middle>Hiroshi Iida</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dung-thai/ class=align-middle>Dung Thai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aurko-roy/ class=align-middle>Aurko Roy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/song-feng/ class=align-middle>Song Feng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/siva-reddy/ class=align-middle>Siva Reddy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/malihe-alikhani/ class=align-middle>Malihe Alikhani</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/he-he/ class=align-middle>He He</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yangfeng-ji/ class=align-middle>Yangfeng Ji</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhou-yu/ class=align-middle>Zhou Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/david-bamman/ class=align-middle>David Bamman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/madalina-fiterau/ class=align-middle>Madalina Fiterau</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mohit-yadav/ class=align-middle>Mohit Yadav</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shufan-wang/ class=align-middle>Shufan Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/john-wieting/ class=align-middle>John Wieting</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kevin-gimpel/ class=align-middle>Kevin Gimpel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luke-zettlemoyer/ class=align-middle>Luke Zettlemoyer</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jordan-boyd-graber/ class=align-middle>Jordan Boyd-Graber</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/larry-davis/ class=align-middle>Larry Davis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/nuse/ class=align-middle>NUSE</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/dialdoc/ class=align-middle>dialdoc</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>