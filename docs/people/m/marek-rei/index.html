<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Marek Rei - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Marek</span> <span class=font-weight-bold>Rei</span></h2><hr><div class=row><div class=col-lg-9><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.0/>Proceedings of the 5th Workshop on Representation Learning for NLP</a></strong><br><a href=/people/s/spandana-gella/>Spandana Gella</a>
|
<a href=/people/j/johannes-welbl/>Johannes Welbl</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/f/fabio-petroni/>Fabio Petroni</a>
|
<a href=/people/p/patrick-lewis/>Patrick Lewis</a>
|
<a href=/people/e/emma-strubell/>Emma Strubell</a>
|
<a href=/people/m/minjoon-seo/>Minjoon Seo</a>
|
<a href=/people/h/hannaneh-hajishirzi/>Hannaneh Hajishirzi</a><br><a href=/volumes/2020.repl4nlp-1/ class=text-muted>Proceedings of the 5th Workshop on Representation Learning for NLP</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.195.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--195 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.195 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.195/>Grammatical error detection in transcriptions of spoken English<span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/a/andrew-caines/>Andrew Caines</a>
|
<a href=/people/c/christian-bentz/>Christian Bentz</a>
|
<a href=/people/k/kate-knill/>Kate Knill</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/p/paula-buttery/>Paula Buttery</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--195><div class="card-body p-3 small">We describe the collection of <a href=https://en.wikipedia.org/wiki/Transcription_(linguistics)>transcription corrections</a> and grammatical error annotations for the CrowdED Corpus of spoken English monologues on business topics. The corpus recordings were crowdsourced from native speakers of English and learners of <a href=https://en.wikipedia.org/wiki/English_language>English</a> with <a href=https://en.wikipedia.org/wiki/German_language>German</a> as their first language. The new transcriptions and annotations are obtained from different crowdworkers : we analyse the 1108 new crowdworker submissions and propose that they can be used for automatic transcription post-editing and grammatical error correction for speech. To further explore the data we train grammatical error detection models with various configurations including pre-trained and contextual word representations as input, additional <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> and auxiliary objectives, and extra <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data</a> from written error-annotated corpora. We find that a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> concatenating pre-trained and contextual word representations as input performs best, and that additional information does not lead to further performance gains.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1125.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1125 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1125 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1125/>Semi-Supervised Bootstrapping of Dialogue State Trackers for Task-Oriented Modelling</a></strong><br><a href=/people/b/bo-hsiang-tseng/>Bo-Hsiang Tseng</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/r/richard-turner/>Richard Turner</a>
|
<a href=/people/b/bill-byrne/>Bill Byrne</a>
|
<a href=/people/a/anna-korhonen/>Anna Korhonen</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1125><div class="card-body p-3 small">Dialogue systems benefit greatly from optimizing on detailed annotations, such as <a href=https://en.wikipedia.org/wiki/Transcription_(linguistics)>transcribed utterances</a>, internal dialogue state representations and dialogue act labels. However, collecting these <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> is expensive and time-consuming, holding back development in the area of dialogue modelling. In this paper, we investigate semi-supervised learning methods that are able to reduce the amount of required intermediate labelling. We find that by leveraging un-annotated data instead, the amount of turn-level annotations of dialogue state can be significantly reduced when building a neural dialogue system. Our analysis on the MultiWOZ corpus, covering a range of domains and topics, finds that annotations can be reduced by up to 30 % while maintaining equivalent system performance. We also describe and evaluate the first end-to-end dialogue model created for the MultiWOZ corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1227.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1227 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1227 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1227/>Modelling the interplay of <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a> and <a href=https://en.wikipedia.org/wiki/Emotion>emotion</a> through <a href=https://en.wikipedia.org/wiki/Multitask_learning>multitask learning</a></a></strong><br><a href=/people/v/verna-dankers/>Verna Dankers</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/m/martha-lewis/>Martha Lewis</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1227><div class="card-body p-3 small">Metaphors allow us to convey <a href=https://en.wikipedia.org/wiki/Emotion>emotion</a> by connecting <a href=https://en.wikipedia.org/wiki/Experience>physical experiences</a> and <a href=https://en.wikipedia.org/wiki/Abstraction>abstract concepts</a>. The results of previous research in <a href=https://en.wikipedia.org/wiki/Linguistics>linguistics</a> and <a href=https://en.wikipedia.org/wiki/Psychology>psychology</a> suggest that metaphorical phrases tend to be more emotionally evocative than their literal counterparts. In this paper, we investigate the relationship between <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a> and <a href=https://en.wikipedia.org/wiki/Emotion>emotion</a> within a <a href=https://en.wikipedia.org/wiki/Software_framework>computational framework</a>, by proposing the first joint model of these <a href=https://en.wikipedia.org/wiki/Phenomenon>phenomena</a>. We experiment with several multitask learning architectures for this purpose, involving both hard and soft parameter sharing. Our results demonstrate that metaphor identification and emotion prediction mutually benefit from joint learning and our models advance the state of the art in both of these tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4300.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4300/>Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)</a></strong><br><a href=/people/i/isabelle-augenstein/>Isabelle Augenstein</a>
|
<a href=/people/s/spandana-gella/>Spandana Gella</a>
|
<a href=/people/s/sebastian-ruder/>Sebastian Ruder</a>
|
<a href=/people/k/katharina-kann/>Katharina Kann</a>
|
<a href=/people/b/burcu-can/>Burcu Can</a>
|
<a href=/people/j/johannes-welbl/>Johannes Welbl</a>
|
<a href=/people/a/alexis-conneau/>Alexis Conneau</a>
|
<a href=/people/x/xiang-ren/>Xiang Ren</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a><br><a href=/volumes/W19-43/ class=text-muted>Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4424.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4424 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4424 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4424/>Neural and FST-based approaches to grammatical error correction<span class=acl-fixed-case>FST</span>-based approaches to grammatical error correction</a></strong><br><a href=/people/z/zheng-yuan/>Zheng Yuan</a>
|
<a href=/people/f/felix-stahlberg/>Felix Stahlberg</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/b/bill-byrne/>Bill Byrne</a>
|
<a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a><br><a href=/volumes/W19-44/ class=text-muted>Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4424><div class="card-body p-3 small">In this paper, we describe our submission to the BEA 2019 shared task on grammatical error correction. We present a <a href=https://en.wikipedia.org/wiki/Pipeline_(computing)>system pipeline</a> that utilises both <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error detection and correction models</a>. The input text is first corrected by two complementary neural machine translation systems : one using convolutional networks and <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a>, and another using a neural Transformer-based system. Training is performed on publicly available data, along with artificial examples generated through <a href=https://en.wikipedia.org/wiki/Back-translation>back-translation</a>. The n-best lists of these two <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation systems</a> are then combined and scored using a <a href=https://en.wikipedia.org/wiki/Finite-state_transducer>finite state transducer (FST)</a>. Finally, an unsupervised re-ranking system is applied to the n-best output of the <a href=https://en.wikipedia.org/wiki/Finite-state_machine>FST</a>. The re-ranker uses a number of <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error detection features</a> to re-rank the FST n-best list and identify the final 1-best correction hypothesis. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves 66.75 % F 0.5 on error correction (ranking 4th), and 82.52 % F 0.5 on token-level error detection (ranking 2nd) in the restricted track of the shared task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1251.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1251 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1251 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-1251/>A Simple and Robust Approach to Detecting Subject-Verb Agreement Errors</a></strong><br><a href=/people/s/simon-flachs/>Simon Flachs</a>
|
<a href=/people/o/ophelie-lacroix/>Ophélie Lacroix</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a>
|
<a href=/people/a/anders-sogaard/>Anders Søgaard</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1251><div class="card-body p-3 small">While rule-based detection of subject-verb agreement (SVA) errors is sensitive to syntactic parsing errors and irregularities and exceptions to the main rules, neural sequential labelers have a tendency to overfit their training data. We observe that rule-based error generation is less sensitive to syntactic parsing errors and irregularities than <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error detection</a> and explore a simple, yet efficient approach to getting the best of both worlds : We train neural sequential labelers on the combination of large volumes of silver standard data, obtained through rule-based error generation, and gold standard data. We show that our simple protocol leads to more robust detection of SVA errors on both in-domain and out-of-domain data, as well as in the context of other errors and long-distance dependencies ; and across four standard benchmarks, the induced model on average achieves a new state of the art.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1028.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1028 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1028 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1028.Datasets.tgz data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276395060 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1028/>Variable Typing : Assigning Meaning to Variables in Mathematical Text</a></strong><br><a href=/people/y/yiannos-stathopoulos/>Yiannos Stathopoulos</a>
|
<a href=/people/s/simon-baker/>Simon Baker</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/s/simone-teufel/>Simone Teufel</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1028><div class="card-body p-3 small">Information about the meaning of mathematical variables in text is useful in NLP / IR tasks such as symbol disambiguation, <a href=https://en.wikipedia.org/wiki/Topic_modeling>topic modeling</a> and mathematical information retrieval (MIR). We introduce variable typing, the task of assigning one mathematical type (multi-word technical terms referring to mathematical concepts) to each variable in a sentence of mathematical text. As part of this work, we also introduce a new annotated data set composed of 33,524 data points extracted from scientific documents published on arXiv. Our intrinsic evaluation demonstrates that our <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> is sufficient to successfully train and evaluate current <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> from three different model architectures. The best performing <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is evaluated on an extrinsic task : MIR, by producing a typed formula index. Our results show that the best performing MIR models make use of our typed index, compared to a formula index only containing raw symbols, thereby demonstrating the usefulness of variable typing.<i>variable typing</i>, the task of assigning one\n <i>mathematical type</i> (multi-word technical terms referring\n to mathematical concepts) to each variable in a sentence of\n mathematical text. As part of this work, we also introduce a new\n annotated data set composed of 33,524 data points extracted from\n scientific documents published on arXiv. Our intrinsic\n evaluation demonstrates that our data set is sufficient to\n successfully train and evaluate current classifiers from three\n different model architectures. The best performing model is\n evaluated on an extrinsic task: MIR, by producing a <i>typed formula index</i>. Our results show that the best performing MIR\n models make use of our typed index, compared to a formula index\n only containing raw symbols, thereby demonstrating the\n usefulness of variable typing.\n</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1194.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1194 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1194 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-1194.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P17-1194" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P17-1194/>Semi-supervised Multitask Learning for Sequence Labeling</a></strong><br><a href=/people/m/marek-rei/>Marek Rei</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1194><div class="card-body p-3 small">We propose a sequence labeling framework with a secondary training objective, learning to predict surrounding words for every word in the dataset. This language modeling objective incentivises the system to learn general-purpose patterns of semantic and syntactic composition, which are also useful for improving accuracy on different sequence labeling tasks. The architecture was evaluated on a range of datasets, covering the tasks of <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error detection</a> in learner texts, <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>, chunking and POS-tagging. The novel language modeling objective provided consistent performance improvements on every <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark</a>, without requiring any additional annotated or unannotated data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5004 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5004/>Auxiliary Objectives for Neural Error Detection Models</a></strong><br><a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a><br><a href=/volumes/W17-50/ class=text-muted>Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5004><div class="card-body p-3 small">We investigate the utility of different auxiliary objectives and training strategies within a neural sequence labeling approach to <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error detection</a> in learner writing. Auxiliary costs provide the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> with additional linguistic information, allowing it to learn general-purpose compositional features that can then be exploited for other objectives. Our experiments show that a joint learning approach trained with parallel labels on in-domain data improves performance over the previous best <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error detection system</a>. While the resulting <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> has the same number of parameters, the additional objectives allow <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> to be optimised more efficiently and achieve better performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5016 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5016/>An Error-Oriented Approach to Word Embedding Pre-Training</a></strong><br><a href=/people/y/youmna-farag/>Youmna Farag</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/t/ted-briscoe/>Ted Briscoe</a><br><a href=/volumes/W17-50/ class=text-muted>Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5016><div class="card-body p-3 small">We propose a novel word embedding pre-training approach that exploits writing errors in learners&#8217; scripts. We compare our method to previous models that tune the embeddings based on script scores and the discrimination between correct and corrupt word contexts in addition to the generic commonly-used embeddings pre-trained on large corpora. The comparison is achieved by using the aforementioned models to bootstrap a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> that learns to predict a holistic score for <a href=https://en.wikipedia.org/wiki/Scripting_language>scripts</a>. Furthermore, we investigate augmenting our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> with <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error corrections</a> and monitor the impact on performance. Our results show that our error-oriented approach outperforms other comparable ones which is further demonstrated when training on more data. Additionally, extending the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> with corrections provides further performance gains when data sparsity is an issue.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5020.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5020 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5020 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5020/>Detecting Off-topic Responses to Visual Prompts</a></strong><br><a href=/people/m/marek-rei/>Marek Rei</a><br><a href=/volumes/W17-50/ class=text-muted>Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5020><div class="card-body p-3 small">Automated methods for essay scoring have made great progress in recent years, achieving accuracies very close to human annotators. However, a known weakness of such automated scorers is not taking into account the semantic relevance of the submitted text. While there is existing work on detecting answer relevance given a textual prompt, very little previous research has been done to incorporate visual writing prompts. We propose a neural architecture and several extensions for detecting off-topic responses to visual prompts and evaluate it on a dataset of texts written by <a href=https://en.wikipedia.org/wiki/Language_acquisition>language learners</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5032.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5032 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5032 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5032/>Artificial Error Generation with Machine Translation and Syntactic Patterns</a></strong><br><a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/m/mariano-felice/>Mariano Felice</a>
|
<a href=/people/z/zheng-yuan/>Zheng Yuan</a>
|
<a href=/people/t/ted-briscoe/>Ted Briscoe</a><br><a href=/volumes/W17-50/ class=text-muted>Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5032><div class="card-body p-3 small">Shortage of available training data is holding back progress in the area of automated error detection. This paper investigates two alternative methods for artificially generating writing errors, in order to create additional resources. We propose treating error generation as a machine translation task, where grammatically correct text is translated to contain errors. In addition, we explore a system for extracting textual patterns from an annotated corpus, which can then be used to insert <a href=https://en.wikipedia.org/wiki/Error_(linguistics)>errors</a> into grammatically correct sentences. Our experiments show that the inclusion of <a href=https://en.wikipedia.org/wiki/Errors-in-variables_models>artificially generated errors</a> significantly improves <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error detection accuracy</a> on both FCE and CoNLL 2014 datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1162.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-1162 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-1162 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/238233405 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/D17-1162/>Grasping the Finer Point : A Supervised Similarity Network for Metaphor Detection</a></strong><br><a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/l/luana-bulat/>Luana Bulat</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-1162><div class="card-body p-3 small">The ubiquity of <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a> in our everyday communication makes <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> an important problem for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a>. Yet, the majority of metaphor processing systems to date rely on hand-engineered features and there is still no consensus in the field as to which features are optimal for this task. In this paper, we present the first deep learning architecture designed to capture metaphorical composition. Our results demonstrate that <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> outperforms the existing <a href=https://en.wikipedia.org/wiki/Psychological_evaluation>approaches</a> in the metaphor identification task.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Marek+Rei" title="Search for 'Marek Rei' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/h/helen-yannakoudakis/ class=align-middle>Helen Yannakoudakis</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/t/ted-briscoe/ class=align-middle>Ted Briscoe</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/z/zheng-yuan/ class=align-middle>Zheng Yuan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/spandana-gella/ class=align-middle>Spandana Gella</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/johannes-welbl/ class=align-middle>Johannes Welbl</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/b/bill-byrne/ class=align-middle>Bill Byrne</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/ekaterina-shutova/ class=align-middle>Ekaterina Shutova</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/y/youmna-farag/ class=align-middle>Youmna Farag</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mariano-felice/ class=align-middle>Mariano Felice</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fabio-petroni/ class=align-middle>Fabio Petroni</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/patrick-lewis/ class=align-middle>Patrick Lewis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/emma-strubell/ class=align-middle>Emma Strubell</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/minjoon-seo/ class=align-middle>Minjoon Seo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hannaneh-hajishirzi/ class=align-middle>Hannaneh Hajishirzi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bo-hsiang-tseng/ class=align-middle>Bo-Hsiang Tseng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pawel-budzianowski/ class=align-middle>Paweł Budzianowski</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/richard-turner/ class=align-middle>Richard Turner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anna-korhonen/ class=align-middle>Anna Korhonen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/verna-dankers/ class=align-middle>Verna Dankers</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/martha-lewis/ class=align-middle>Martha Lewis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/luana-bulat/ class=align-middle>Luana Bulat</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/douwe-kiela/ class=align-middle>Douwe Kiela</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/isabelle-augenstein/ class=align-middle>Isabelle Augenstein</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sebastian-ruder/ class=align-middle>Sebastian Ruder</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/katharina-kann/ class=align-middle>Katharina Kann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/burcu-can/ class=align-middle>Burcu Can</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexis-conneau/ class=align-middle>Alexis Conneau</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiang-ren/ class=align-middle>Xiang Ren</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/felix-stahlberg/ class=align-middle>Felix Stahlberg</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrew-caines/ class=align-middle>Andrew Caines</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christian-bentz/ class=align-middle>Christian Bentz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kate-knill/ class=align-middle>Kate Knill</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paula-buttery/ class=align-middle>Paula Buttery</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/simon-flachs/ class=align-middle>Simon Flachs</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/ophelie-lacroix/ class=align-middle>Ophélie Lacroix</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anders-sogaard/ class=align-middle>Anders Søgaard</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yiannos-stathopoulos/ class=align-middle>Yiannos Stathopoulos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/simon-baker/ class=align-middle>Simon Baker</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/simone-teufel/ class=align-middle>Simone Teufel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/repl4nlp/ class=align-middle>RepL4NLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>